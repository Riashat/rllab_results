2017-07-31 15:19:52.414013 EDT | [Active_RL/Hard_Oracle_DDPG/Experiment_0] observation space: Box(11,)
2017-07-31 15:19:52.415423 EDT | [Active_RL/Hard_Oracle_DDPG/Experiment_0] action space: Box(3,)
2017-07-31 15:19:53.305411 EDT | [Active_RL/Hard_Oracle_DDPG/Experiment_0] Populating workers...
2017-07-31 15:19:53.305974 EDT | [Active_RL/Hard_Oracle_DDPG/Experiment_0] Populated
2017-07-31 15:19:54.377096 EDT | [Active_RL/Hard_Oracle_DDPG/Experiment_0] epoch #0 | Training started
2017-07-31 15:19:55.903781 EDT | [Active_RL/Hard_Oracle_DDPG/Experiment_0] epoch #0 | Training finished
2017-07-31 15:19:55.904083 EDT | [Active_RL/Hard_Oracle_DDPG/Experiment_0] epoch #0 | Trained qf 0 steps, policy 0 steps
2017-07-31 15:19:55.904309 EDT | [Active_RL/Hard_Oracle_DDPG/Experiment_0] epoch #1 | Training started
2017-07-31 15:19:56.917255 EDT | [Active_RL/Hard_Oracle_DDPG/Experiment_0] epoch #1 | Training finished
2017-07-31 15:19:56.917611 EDT | [Active_RL/Hard_Oracle_DDPG/Experiment_0] epoch #1 | Trained qf 0 steps, policy 0 steps
2017-07-31 15:19:56.917826 EDT | [Active_RL/Hard_Oracle_DDPG/Experiment_0] epoch #2 | Training started
2017-07-31 15:19:58.135303 EDT | [Active_RL/Hard_Oracle_DDPG/Experiment_0] epoch #2 | Training finished
2017-07-31 15:19:58.135777 EDT | [Active_RL/Hard_Oracle_DDPG/Experiment_0] epoch #2 | Trained qf 0 steps, policy 0 steps
2017-07-31 15:19:58.136137 EDT | [Active_RL/Hard_Oracle_DDPG/Experiment_0] epoch #3 | Training started
2017-07-31 15:19:59.314193 EDT | [Active_RL/Hard_Oracle_DDPG/Experiment_0] epoch #3 | Training finished
2017-07-31 15:19:59.315193 EDT | [Active_RL/Hard_Oracle_DDPG/Experiment_0] epoch #3 | Trained qf 0 steps, policy 0 steps
2017-07-31 15:19:59.315619 EDT | [Active_RL/Hard_Oracle_DDPG/Experiment_0] epoch #4 | Training started
2017-07-31 15:20:00.540053 EDT | [Active_RL/Hard_Oracle_DDPG/Experiment_0] epoch #4 | Training finished
2017-07-31 15:20:00.540458 EDT | [Active_RL/Hard_Oracle_DDPG/Experiment_0] epoch #4 | Trained qf 0 steps, policy 0 steps
2017-07-31 15:20:00.540827 EDT | [Active_RL/Hard_Oracle_DDPG/Experiment_0] epoch #5 | Training started
2017-07-31 15:20:01.932588 EDT | [Active_RL/Hard_Oracle_DDPG/Experiment_0] epoch #5 | Training finished
2017-07-31 15:20:01.933000 EDT | [Active_RL/Hard_Oracle_DDPG/Experiment_0] epoch #5 | Trained qf 0 steps, policy 0 steps
2017-07-31 15:20:01.933331 EDT | [Active_RL/Hard_Oracle_DDPG/Experiment_0] epoch #6 | Training started
2017-07-31 15:20:03.102932 EDT | [Active_RL/Hard_Oracle_DDPG/Experiment_0] epoch #6 | Training finished
2017-07-31 15:20:03.103319 EDT | [Active_RL/Hard_Oracle_DDPG/Experiment_0] epoch #6 | Trained qf 0 steps, policy 0 steps
2017-07-31 15:20:03.103589 EDT | [Active_RL/Hard_Oracle_DDPG/Experiment_0] epoch #7 | Training started
2017-07-31 15:20:04.317056 EDT | [Active_RL/Hard_Oracle_DDPG/Experiment_0] epoch #7 | Training finished
2017-07-31 15:20:04.317464 EDT | [Active_RL/Hard_Oracle_DDPG/Experiment_0] epoch #7 | Trained qf 0 steps, policy 0 steps
2017-07-31 15:20:04.317648 EDT | [Active_RL/Hard_Oracle_DDPG/Experiment_0] epoch #8 | Training started
2017-07-31 15:20:05.495069 EDT | [Active_RL/Hard_Oracle_DDPG/Experiment_0] epoch #8 | Training finished
2017-07-31 15:20:05.495496 EDT | [Active_RL/Hard_Oracle_DDPG/Experiment_0] epoch #8 | Trained qf 0 steps, policy 0 steps
2017-07-31 15:20:05.495844 EDT | [Active_RL/Hard_Oracle_DDPG/Experiment_0] epoch #9 | Training started
2017-07-31 15:20:06.957256 EDT | [Active_RL/Hard_Oracle_DDPG/Experiment_0] epoch #9 | Training finished
2017-07-31 15:20:06.957500 EDT | [Active_RL/Hard_Oracle_DDPG/Experiment_0] epoch #9 | Trained qf 1 steps, policy 1 steps
2017-07-31 15:20:06.957679 EDT | [Active_RL/Hard_Oracle_DDPG/Experiment_0] epoch #9 | Collecting samples for evaluation
2017-07-31 15:21:05.639737 EDT | [Active_RL/Hard_Oracle_DDPG/Experiment_0] observation space: Box(11,)
2017-07-31 15:21:05.640137 EDT | [Active_RL/Hard_Oracle_DDPG/Experiment_0] action space: Box(3,)
2017-07-31 15:21:06.324873 EDT | [Active_RL/Hard_Oracle_DDPG/Experiment_0] Populating workers...
2017-07-31 15:21:06.325423 EDT | [Active_RL/Hard_Oracle_DDPG/Experiment_0] Populated
2017-07-31 15:21:07.463288 EDT | [Active_RL/Hard_Oracle_DDPG/Experiment_0] epoch #0 | Training started
2017-07-31 15:21:09.053828 EDT | [Active_RL/Hard_Oracle_DDPG/Experiment_0] epoch #0 | Training finished
2017-07-31 15:21:09.054105 EDT | [Active_RL/Hard_Oracle_DDPG/Experiment_0] epoch #0 | Trained qf 0 steps, policy 0 steps
2017-07-31 15:21:09.054330 EDT | [Active_RL/Hard_Oracle_DDPG/Experiment_0] epoch #1 | Training started
2017-07-31 15:21:10.207717 EDT | [Active_RL/Hard_Oracle_DDPG/Experiment_0] epoch #1 | Training finished
2017-07-31 15:21:10.207987 EDT | [Active_RL/Hard_Oracle_DDPG/Experiment_0] epoch #1 | Trained qf 0 steps, policy 0 steps
2017-07-31 15:21:10.208172 EDT | [Active_RL/Hard_Oracle_DDPG/Experiment_0] epoch #2 | Training started
2017-07-31 15:21:11.565450 EDT | [Active_RL/Hard_Oracle_DDPG/Experiment_0] epoch #2 | Training finished
2017-07-31 15:21:11.565838 EDT | [Active_RL/Hard_Oracle_DDPG/Experiment_0] epoch #2 | Trained qf 0 steps, policy 0 steps
2017-07-31 15:21:11.566120 EDT | [Active_RL/Hard_Oracle_DDPG/Experiment_0] epoch #3 | Training started
2017-07-31 15:21:12.828089 EDT | [Active_RL/Hard_Oracle_DDPG/Experiment_0] epoch #3 | Training finished
2017-07-31 15:21:12.828705 EDT | [Active_RL/Hard_Oracle_DDPG/Experiment_0] epoch #3 | Trained qf 0 steps, policy 0 steps
2017-07-31 15:21:12.829206 EDT | [Active_RL/Hard_Oracle_DDPG/Experiment_0] epoch #4 | Training started
2017-07-31 15:21:14.034844 EDT | [Active_RL/Hard_Oracle_DDPG/Experiment_0] epoch #4 | Training finished
2017-07-31 15:21:14.035245 EDT | [Active_RL/Hard_Oracle_DDPG/Experiment_0] epoch #4 | Trained qf 0 steps, policy 0 steps
2017-07-31 15:21:14.035565 EDT | [Active_RL/Hard_Oracle_DDPG/Experiment_0] epoch #5 | Training started
2017-07-31 15:21:15.195270 EDT | [Active_RL/Hard_Oracle_DDPG/Experiment_0] epoch #5 | Training finished
2017-07-31 15:21:15.196435 EDT | [Active_RL/Hard_Oracle_DDPG/Experiment_0] epoch #5 | Trained qf 0 steps, policy 0 steps
2017-07-31 15:21:15.196642 EDT | [Active_RL/Hard_Oracle_DDPG/Experiment_0] epoch #6 | Training started
2017-07-31 15:21:16.511734 EDT | [Active_RL/Hard_Oracle_DDPG/Experiment_0] epoch #6 | Training finished
2017-07-31 15:21:16.512131 EDT | [Active_RL/Hard_Oracle_DDPG/Experiment_0] epoch #6 | Trained qf 0 steps, policy 0 steps
2017-07-31 15:21:16.512436 EDT | [Active_RL/Hard_Oracle_DDPG/Experiment_0] epoch #7 | Training started
2017-07-31 15:21:17.787487 EDT | [Active_RL/Hard_Oracle_DDPG/Experiment_0] epoch #7 | Training finished
2017-07-31 15:21:17.787845 EDT | [Active_RL/Hard_Oracle_DDPG/Experiment_0] epoch #7 | Trained qf 0 steps, policy 0 steps
2017-07-31 15:21:17.788118 EDT | [Active_RL/Hard_Oracle_DDPG/Experiment_0] epoch #8 | Training started
2017-07-31 15:21:19.234575 EDT | [Active_RL/Hard_Oracle_DDPG/Experiment_0] epoch #8 | Training finished
2017-07-31 15:21:19.235076 EDT | [Active_RL/Hard_Oracle_DDPG/Experiment_0] epoch #8 | Trained qf 0 steps, policy 0 steps
2017-07-31 15:21:19.235462 EDT | [Active_RL/Hard_Oracle_DDPG/Experiment_0] epoch #9 | Training started
2017-07-31 15:21:20.964805 EDT | [Active_RL/Hard_Oracle_DDPG/Experiment_0] epoch #9 | Training finished
2017-07-31 15:21:20.965176 EDT | [Active_RL/Hard_Oracle_DDPG/Experiment_0] epoch #9 | Trained qf 1 steps, policy 1 steps
2017-07-31 15:21:20.965538 EDT | [Active_RL/Hard_Oracle_DDPG/Experiment_0] epoch #9 | Collecting samples for evaluation
2017-07-31 15:21:32.452847 EDT | -----------------------  ----------
2017-07-31 15:21:32.456201 EDT | Epoch                     9
2017-07-31 15:21:32.456651 EDT | Iteration                 9
2017-07-31 15:21:32.456974 EDT | AverageReturn             9.23727
2017-07-31 15:21:32.457255 EDT | StdReturn                 0.0449308
2017-07-31 15:21:32.457532 EDT | MaxReturn                 9.35606
2017-07-31 15:21:32.457805 EDT | MinReturn                 9.12413
2017-07-31 15:21:32.458116 EDT | AverageEsReturn           9.75372
2017-07-31 15:21:32.458420 EDT | StdEsReturn               6.19984
2017-07-31 15:21:32.458693 EDT | MaxEsReturn              50.6943
2017-07-31 15:21:32.458998 EDT | MinEsReturn               1.49895
2017-07-31 15:21:32.459284 EDT | AverageDiscountedReturn   8.81148
2017-07-31 15:21:32.459556 EDT | AverageQLoss              3.62989
2017-07-31 15:21:32.459824 EDT | AveragePolicySurr         0.0289694
2017-07-31 15:21:32.460750 EDT | AverageQ                 -0.304265
2017-07-31 15:21:32.461035 EDT | AverageAbsQ               0.353313
2017-07-31 15:21:32.461335 EDT | AverageY                  1.5
2017-07-31 15:21:32.461609 EDT | AverageAbsY               1.5
2017-07-31 15:21:32.461879 EDT | AverageAbsQYDiff          1.80426
2017-07-31 15:21:32.462190 EDT | AverageAction             0.216144
2017-07-31 15:21:32.462468 EDT | PolicyRegParamNorm       11.2293
2017-07-31 15:21:32.462739 EDT | QFunRegParamNorm         11.1303
2017-07-31 15:21:32.463009 EDT | -----------------------  ----------
2017-07-31 15:21:32.463863 EDT | [Active_RL/Hard_Oracle_DDPG/Experiment_0] epoch #10 | Training started
2017-07-31 15:21:49.105280 EDT | [Active_RL/Hard_Oracle_DDPG/Experiment_0] epoch #10 | Training finished
2017-07-31 15:21:49.106331 EDT | [Active_RL/Hard_Oracle_DDPG/Experiment_0] epoch #10 | Trained qf 1000 steps, policy 1000 steps
2017-07-31 15:21:49.106722 EDT | [Active_RL/Hard_Oracle_DDPG/Experiment_0] epoch #10 | Collecting samples for evaluation
2017-07-31 15:22:01.408634 EDT | -----------------------  ----------
2017-07-31 15:22:01.409110 EDT | Epoch                    10
2017-07-31 15:22:01.409362 EDT | Iteration                10
2017-07-31 15:22:01.409622 EDT | AverageReturn             5.29634
2017-07-31 15:22:01.409860 EDT | StdReturn                 0.0426099
2017-07-31 15:22:01.410104 EDT | MaxReturn                 5.40826
2017-07-31 15:22:01.410354 EDT | MinReturn                 5.08001
2017-07-31 15:22:01.410590 EDT | AverageEsReturn           3.64396
2017-07-31 15:22:01.410829 EDT | StdEsReturn               0.762377
2017-07-31 15:22:01.411070 EDT | MaxEsReturn               8.3777
2017-07-31 15:22:01.411304 EDT | MinEsReturn               2.42326
2017-07-31 15:22:01.411537 EDT | AverageDiscountedReturn   5.13535
2017-07-31 15:22:01.411780 EDT | AverageQLoss              0.0569943
2017-07-31 15:22:01.412012 EDT | AveragePolicySurr        -1.23866
2017-07-31 15:22:01.412249 EDT | AverageQ                  1.18263
2017-07-31 15:22:01.412482 EDT | AverageAbsQ               1.18995
2017-07-31 15:22:01.412714 EDT | AverageY                  1.19209
2017-07-31 15:22:01.412953 EDT | AverageAbsY               1.20239
2017-07-31 15:22:01.413186 EDT | AverageAbsQYDiff          0.125258
2017-07-31 15:22:01.413420 EDT | AverageAction             0.99907
2017-07-31 15:22:01.413659 EDT | PolicyRegParamNorm       11.8381
2017-07-31 15:22:01.413892 EDT | QFunRegParamNorm         11.4398
2017-07-31 15:22:01.414124 EDT | -----------------------  ----------
2017-07-31 15:22:01.414555 EDT | [Active_RL/Hard_Oracle_DDPG/Experiment_0] epoch #11 | Training started
2017-07-31 15:22:19.495892 EDT | [Active_RL/Hard_Oracle_DDPG/Experiment_0] epoch #11 | Training finished
2017-07-31 15:22:19.500048 EDT | [Active_RL/Hard_Oracle_DDPG/Experiment_0] epoch #11 | Trained qf 1000 steps, policy 1000 steps
2017-07-31 15:22:19.500365 EDT | [Active_RL/Hard_Oracle_DDPG/Experiment_0] epoch #11 | Collecting samples for evaluation
2017-07-31 15:22:30.833008 EDT | -----------------------  ---------
2017-07-31 15:22:30.833897 EDT | Epoch                    11
2017-07-31 15:22:30.834195 EDT | Iteration                11
2017-07-31 15:22:30.834446 EDT | AverageReturn            38.8149
2017-07-31 15:22:30.834689 EDT | StdReturn                 0.966425
2017-07-31 15:22:30.834927 EDT | MaxReturn                41.7746
2017-07-31 15:22:30.835164 EDT | MinReturn                36.7553
2017-07-31 15:22:30.835397 EDT | AverageEsReturn          12.9781
2017-07-31 15:22:30.835632 EDT | StdEsReturn              13.03
2017-07-31 15:22:30.835864 EDT | MaxEsReturn              55.3857
2017-07-31 15:22:30.836098 EDT | MinEsReturn               4.93198
2017-07-31 15:22:30.836332 EDT | AverageDiscountedReturn  34.4921
2017-07-31 15:22:30.836575 EDT | AverageQLoss              0.013855
2017-07-31 15:22:30.836812 EDT | AveragePolicySurr        -1.46045
2017-07-31 15:22:30.837045 EDT | AverageQ                  1.39084
2017-07-31 15:22:30.837280 EDT | AverageAbsQ               1.40679
2017-07-31 15:22:30.837514 EDT | AverageY                  1.39141
2017-07-31 15:22:30.837748 EDT | AverageAbsY               1.40666
2017-07-31 15:22:30.837981 EDT | AverageAbsQYDiff          0.07122
2017-07-31 15:22:30.838238 EDT | AverageAction             0.999998
2017-07-31 15:22:30.838474 EDT | PolicyRegParamNorm       12.5752
2017-07-31 15:22:30.838709 EDT | QFunRegParamNorm         11.8125
2017-07-31 15:22:30.838944 EDT | -----------------------  ---------
2017-07-31 15:22:30.839348 EDT | [Active_RL/Hard_Oracle_DDPG/Experiment_0] epoch #12 | Training started
2017-07-31 15:22:48.121855 EDT | [Active_RL/Hard_Oracle_DDPG/Experiment_0] epoch #12 | Training finished
2017-07-31 15:22:48.122813 EDT | [Active_RL/Hard_Oracle_DDPG/Experiment_0] epoch #12 | Trained qf 1000 steps, policy 1000 steps
2017-07-31 15:22:48.123053 EDT | [Active_RL/Hard_Oracle_DDPG/Experiment_0] epoch #12 | Collecting samples for evaluation
2017-07-31 15:22:59.992587 EDT | -----------------------  ----------
2017-07-31 15:22:59.993769 EDT | Epoch                    12
2017-07-31 15:22:59.994038 EDT | Iteration                12
2017-07-31 15:22:59.994304 EDT | AverageReturn            38.8001
2017-07-31 15:22:59.994554 EDT | StdReturn                 0.958069
2017-07-31 15:22:59.994791 EDT | MaxReturn                40.5992
2017-07-31 15:22:59.995027 EDT | MinReturn                36.7193
2017-07-31 15:22:59.995264 EDT | AverageEsReturn          42.5362
2017-07-31 15:22:59.995497 EDT | StdEsReturn               7.22556
2017-07-31 15:22:59.995730 EDT | MaxEsReturn              82.5907
2017-07-31 15:22:59.995964 EDT | MinEsReturn              36.5467
2017-07-31 15:22:59.996197 EDT | AverageDiscountedReturn  34.4796
2017-07-31 15:22:59.996433 EDT | AverageQLoss              0.0382284
2017-07-31 15:22:59.996665 EDT | AveragePolicySurr        -2.27101
2017-07-31 15:22:59.996898 EDT | AverageQ                  2.01023
2017-07-31 15:22:59.997133 EDT | AverageAbsQ               2.0333
2017-07-31 15:22:59.997365 EDT | AverageY                  2.01127
2017-07-31 15:22:59.997598 EDT | AverageAbsY               2.03293
2017-07-31 15:22:59.997831 EDT | AverageAbsQYDiff          0.0967726
2017-07-31 15:22:59.998063 EDT | AverageAction             1
2017-07-31 15:22:59.998310 EDT | PolicyRegParamNorm       12.6492
2017-07-31 15:22:59.998548 EDT | QFunRegParamNorm         12.6734
2017-07-31 15:22:59.998783 EDT | -----------------------  ----------
2017-07-31 15:22:59.999175 EDT | [Active_RL/Hard_Oracle_DDPG/Experiment_0] epoch #13 | Training started
2017-07-31 15:23:18.222571 EDT | [Active_RL/Hard_Oracle_DDPG/Experiment_0] epoch #13 | Training finished
2017-07-31 15:23:18.223636 EDT | [Active_RL/Hard_Oracle_DDPG/Experiment_0] epoch #13 | Trained qf 1000 steps, policy 1000 steps
2017-07-31 15:23:18.224029 EDT | [Active_RL/Hard_Oracle_DDPG/Experiment_0] epoch #13 | Collecting samples for evaluation
2017-07-31 15:23:30.446014 EDT | -----------------------  ----------
2017-07-31 15:23:30.448147 EDT | Epoch                    13
2017-07-31 15:23:30.448453 EDT | Iteration                13
2017-07-31 15:23:30.448722 EDT | AverageReturn            38.7745
2017-07-31 15:23:30.448984 EDT | StdReturn                 0.955434
2017-07-31 15:23:30.449249 EDT | MaxReturn                40.7148
2017-07-31 15:23:30.449508 EDT | MinReturn                36.6735
2017-07-31 15:23:30.449764 EDT | AverageEsReturn          42.2954
2017-07-31 15:23:30.450024 EDT | StdEsReturn               8.24677
2017-07-31 15:23:30.451204 EDT | MaxEsReturn              79.2518
2017-07-31 15:23:30.452566 EDT | MinEsReturn              12.8568
2017-07-31 15:23:30.453119 EDT | AverageDiscountedReturn  34.4613
2017-07-31 15:23:30.453635 EDT | AverageQLoss              0.0948491
2017-07-31 15:23:30.454165 EDT | AveragePolicySurr        -3.36438
2017-07-31 15:23:30.454685 EDT | AverageQ                  2.97431
2017-07-31 15:23:30.455212 EDT | AverageAbsQ               2.99753
2017-07-31 15:23:30.455716 EDT | AverageY                  2.97564
2017-07-31 15:23:30.456215 EDT | AverageAbsY               2.99716
2017-07-31 15:23:30.456737 EDT | AverageAbsQYDiff          0.142067
2017-07-31 15:23:30.457409 EDT | AverageAction             1
2017-07-31 15:23:30.458053 EDT | PolicyRegParamNorm       12.6816
2017-07-31 15:23:30.458600 EDT | QFunRegParamNorm         14.1586
2017-07-31 15:23:30.459093 EDT | -----------------------  ----------
2017-07-31 15:23:30.459782 EDT | [Active_RL/Hard_Oracle_DDPG/Experiment_0] epoch #14 | Training started
2017-07-31 15:23:48.180149 EDT | [Active_RL/Hard_Oracle_DDPG/Experiment_0] epoch #14 | Training finished
2017-07-31 15:23:48.181057 EDT | [Active_RL/Hard_Oracle_DDPG/Experiment_0] epoch #14 | Trained qf 1000 steps, policy 1000 steps
2017-07-31 15:23:48.181330 EDT | [Active_RL/Hard_Oracle_DDPG/Experiment_0] epoch #14 | Collecting samples for evaluation
2017-07-31 15:23:59.919310 EDT | -----------------------  ---------
2017-07-31 15:23:59.921014 EDT | Epoch                    14
2017-07-31 15:23:59.921331 EDT | Iteration                14
2017-07-31 15:23:59.921656 EDT | AverageReturn            38.7027
2017-07-31 15:23:59.921940 EDT | StdReturn                 0.920826
2017-07-31 15:23:59.922307 EDT | MaxReturn                41.9509
2017-07-31 15:23:59.922683 EDT | MinReturn                36.6269
2017-07-31 15:23:59.923042 EDT | AverageEsReturn          42.1762
2017-07-31 15:23:59.923395 EDT | StdEsReturn               8.33278
2017-07-31 15:23:59.923732 EDT | MaxEsReturn              72.4686
2017-07-31 15:23:59.924079 EDT | MinEsReturn              16.6716
2017-07-31 15:23:59.924414 EDT | AverageDiscountedReturn  34.4031
2017-07-31 15:23:59.924779 EDT | AverageQLoss              0.160367
2017-07-31 15:23:59.925079 EDT | AveragePolicySurr        -4.53106
2017-07-31 15:23:59.925368 EDT | AverageQ                  4.06787
2017-07-31 15:23:59.925700 EDT | AverageAbsQ               4.08974
2017-07-31 15:23:59.925989 EDT | AverageY                  4.06926
2017-07-31 15:23:59.926443 EDT | AverageAbsY               4.08916
2017-07-31 15:23:59.926923 EDT | AverageAbsQYDiff          0.188184
2017-07-31 15:23:59.927466 EDT | AverageAction             1
2017-07-31 15:23:59.927842 EDT | PolicyRegParamNorm       12.6964
2017-07-31 15:23:59.928271 EDT | QFunRegParamNorm         15.8447
2017-07-31 15:23:59.928640 EDT | -----------------------  ---------
2017-07-31 15:23:59.929249 EDT | [Active_RL/Hard_Oracle_DDPG/Experiment_0] epoch #15 | Training started
2017-07-31 15:24:17.523938 EDT | [Active_RL/Hard_Oracle_DDPG/Experiment_0] epoch #15 | Training finished
2017-07-31 15:24:17.525503 EDT | [Active_RL/Hard_Oracle_DDPG/Experiment_0] epoch #15 | Trained qf 1000 steps, policy 1000 steps
2017-07-31 15:24:17.525806 EDT | [Active_RL/Hard_Oracle_DDPG/Experiment_0] epoch #15 | Collecting samples for evaluation
2017-07-31 15:24:29.167650 EDT | -----------------------  ---------
2017-07-31 15:24:29.168547 EDT | Epoch                    15
2017-07-31 15:24:29.168824 EDT | Iteration                15
2017-07-31 15:24:29.169073 EDT | AverageReturn            38.8643
2017-07-31 15:24:29.169314 EDT | StdReturn                 0.981787
2017-07-31 15:24:29.169574 EDT | MaxReturn                40.7797
2017-07-31 15:24:29.169817 EDT | MinReturn                36.6665
2017-07-31 15:24:29.170062 EDT | AverageEsReturn          40.6912
2017-07-31 15:24:29.170322 EDT | StdEsReturn               4.84727
2017-07-31 15:24:29.170564 EDT | MaxEsReturn              52.4945
2017-07-31 15:24:29.170810 EDT | MinEsReturn              18.3538
2017-07-31 15:24:29.171050 EDT | AverageDiscountedReturn  34.5319
2017-07-31 15:24:29.171291 EDT | AverageQLoss              0.199844
2017-07-31 15:24:29.171536 EDT | AveragePolicySurr        -5.76984
2017-07-31 15:24:29.171781 EDT | AverageQ                  5.2202
2017-07-31 15:24:29.172023 EDT | AverageAbsQ               5.23987
2017-07-31 15:24:29.172268 EDT | AverageY                  5.22132
2017-07-31 15:24:29.172511 EDT | AverageAbsY               5.23873
2017-07-31 15:24:29.172751 EDT | AverageAbsQYDiff          0.215865
2017-07-31 15:24:29.172990 EDT | AverageAction             1
2017-07-31 15:24:29.173229 EDT | PolicyRegParamNorm       12.704
2017-07-31 15:24:29.173472 EDT | QFunRegParamNorm         17.3803
2017-07-31 15:24:29.173721 EDT | -----------------------  ---------
2017-07-31 15:24:29.174124 EDT | [Active_RL/Hard_Oracle_DDPG/Experiment_0] epoch #16 | Training started
2017-07-31 15:24:46.052989 EDT | [Active_RL/Hard_Oracle_DDPG/Experiment_0] epoch #16 | Training finished
2017-07-31 15:24:46.053886 EDT | [Active_RL/Hard_Oracle_DDPG/Experiment_0] epoch #16 | Trained qf 1000 steps, policy 1000 steps
2017-07-31 15:24:46.054247 EDT | [Active_RL/Hard_Oracle_DDPG/Experiment_0] epoch #16 | Collecting samples for evaluation
2017-07-31 15:24:57.744885 EDT | -----------------------  ---------
2017-07-31 15:24:57.745845 EDT | Epoch                    16
2017-07-31 15:24:57.746105 EDT | Iteration                16
2017-07-31 15:24:57.746364 EDT | AverageReturn            38.8076
2017-07-31 15:24:57.746613 EDT | StdReturn                 0.912796
2017-07-31 15:24:57.746843 EDT | MaxReturn                40.7477
2017-07-31 15:24:57.747069 EDT | MinReturn                36.7071
2017-07-31 15:24:57.747319 EDT | AverageEsReturn          40.4725
2017-07-31 15:24:57.747568 EDT | StdEsReturn               4.13524
2017-07-31 15:24:57.747817 EDT | MaxEsReturn              48.7602
2017-07-31 15:24:57.748061 EDT | MinEsReturn              22.207
2017-07-31 15:24:57.748306 EDT | AverageDiscountedReturn  34.4878
2017-07-31 15:24:57.748556 EDT | AverageQLoss              0.200811
2017-07-31 15:24:57.748794 EDT | AveragePolicySurr        -7.10349
2017-07-31 15:24:57.749037 EDT | AverageQ                  6.42841
2017-07-31 15:24:57.749278 EDT | AverageAbsQ               6.44624
2017-07-31 15:24:57.749521 EDT | AverageY                  6.42976
2017-07-31 15:24:57.749765 EDT | AverageAbsY               6.44469
2017-07-31 15:24:57.750006 EDT | AverageAbsQYDiff          0.226075
2017-07-31 15:24:57.750265 EDT | AverageAction             1
2017-07-31 15:24:57.750507 EDT | PolicyRegParamNorm       12.7103
2017-07-31 15:24:57.750752 EDT | QFunRegParamNorm         18.7172
2017-07-31 15:24:57.750992 EDT | -----------------------  ---------
2017-07-31 15:24:57.751417 EDT | [Active_RL/Hard_Oracle_DDPG/Experiment_0] epoch #17 | Training started
2017-07-31 15:25:15.721900 EDT | [Active_RL/Hard_Oracle_DDPG/Experiment_0] epoch #17 | Training finished
2017-07-31 15:25:15.722753 EDT | [Active_RL/Hard_Oracle_DDPG/Experiment_0] epoch #17 | Trained qf 1000 steps, policy 1000 steps
2017-07-31 15:25:15.723034 EDT | [Active_RL/Hard_Oracle_DDPG/Experiment_0] epoch #17 | Collecting samples for evaluation
2017-07-31 15:25:27.810029 EDT | -----------------------  ---------
2017-07-31 15:25:27.811095 EDT | Epoch                    17
2017-07-31 15:25:27.811454 EDT | Iteration                17
2017-07-31 15:25:27.811773 EDT | AverageReturn            38.852
2017-07-31 15:25:27.811946 EDT | StdReturn                 0.875931
2017-07-31 15:25:27.812109 EDT | MaxReturn                40.83
2017-07-31 15:25:27.812265 EDT | MinReturn                36.7007
2017-07-31 15:25:27.812424 EDT | AverageEsReturn          40.5739
2017-07-31 15:25:27.812631 EDT | StdEsReturn               6.60941
2017-07-31 15:25:27.812792 EDT | MaxEsReturn              50.0481
2017-07-31 15:25:27.813004 EDT | MinEsReturn               3.09737
2017-07-31 15:25:27.813317 EDT | AverageDiscountedReturn  34.5217
2017-07-31 15:25:27.813656 EDT | AverageQLoss              0.242168
2017-07-31 15:25:27.813917 EDT | AveragePolicySurr        -8.53088
2017-07-31 15:25:27.814117 EDT | AverageQ                  7.73593
2017-07-31 15:25:27.814405 EDT | AverageAbsQ               7.7513
2017-07-31 15:25:27.814627 EDT | AverageY                  7.73748
2017-07-31 15:25:27.814794 EDT | AverageAbsY               7.74915
2017-07-31 15:25:27.814999 EDT | AverageAbsQYDiff          0.252593
2017-07-31 15:25:27.815261 EDT | AverageAction             1
2017-07-31 15:25:27.815419 EDT | PolicyRegParamNorm       12.7154
2017-07-31 15:25:27.815620 EDT | QFunRegParamNorm         19.8389
2017-07-31 15:25:27.815768 EDT | -----------------------  ---------
2017-07-31 15:25:27.816232 EDT | [Active_RL/Hard_Oracle_DDPG/Experiment_0] epoch #18 | Training started
2017-07-31 15:25:45.796205 EDT | [Active_RL/Hard_Oracle_DDPG/Experiment_0] epoch #18 | Training finished
2017-07-31 15:25:45.797305 EDT | [Active_RL/Hard_Oracle_DDPG/Experiment_0] epoch #18 | Trained qf 1000 steps, policy 1000 steps
2017-07-31 15:25:45.797854 EDT | [Active_RL/Hard_Oracle_DDPG/Experiment_0] epoch #18 | Collecting samples for evaluation
2017-07-31 15:25:57.420480 EDT | -----------------------  ---------
2017-07-31 15:25:57.421378 EDT | Epoch                    18
2017-07-31 15:25:57.421651 EDT | Iteration                18
2017-07-31 15:25:57.421900 EDT | AverageReturn            38.7956
2017-07-31 15:25:57.422163 EDT | StdReturn                 0.896871
2017-07-31 15:25:57.422416 EDT | MaxReturn                41.7204
2017-07-31 15:25:57.422657 EDT | MinReturn                36.7274
2017-07-31 15:25:57.422896 EDT | AverageEsReturn          41.9043
2017-07-31 15:25:57.423131 EDT | StdEsReturn               4.24166
2017-07-31 15:25:57.423378 EDT | MaxEsReturn              57.1202
2017-07-31 15:25:57.423615 EDT | MinEsReturn              36.1589
2017-07-31 15:25:57.423855 EDT | AverageDiscountedReturn  34.4775
2017-07-31 15:25:57.424090 EDT | AverageQLoss              0.234776
2017-07-31 15:25:57.424332 EDT | AveragePolicySurr        -9.95663
2017-07-31 15:25:57.424568 EDT | AverageQ                  9.057
2017-07-31 15:25:57.424804 EDT | AverageAbsQ               9.0701
2017-07-31 15:25:57.425050 EDT | AverageY                  9.05838
2017-07-31 15:25:57.425285 EDT | AverageAbsY               9.06703
2017-07-31 15:25:57.425520 EDT | AverageAbsQYDiff          0.256816
2017-07-31 15:25:57.425754 EDT | AverageAction             1
2017-07-31 15:25:57.425994 EDT | PolicyRegParamNorm       12.7192
2017-07-31 15:25:57.426243 EDT | QFunRegParamNorm         20.7986
2017-07-31 15:25:57.426481 EDT | -----------------------  ---------
2017-07-31 15:25:57.426876 EDT | [Active_RL/Hard_Oracle_DDPG/Experiment_0] epoch #19 | Training started
2017-07-31 15:26:15.060020 EDT | [Active_RL/Hard_Oracle_DDPG/Experiment_0] epoch #19 | Training finished
2017-07-31 15:26:15.062581 EDT | [Active_RL/Hard_Oracle_DDPG/Experiment_0] epoch #19 | Trained qf 1000 steps, policy 1000 steps
2017-07-31 15:26:15.062871 EDT | [Active_RL/Hard_Oracle_DDPG/Experiment_0] epoch #19 | Collecting samples for evaluation
2017-07-31 15:26:26.812287 EDT | -----------------------  ----------
2017-07-31 15:26:26.813102 EDT | Epoch                     19
2017-07-31 15:26:26.813273 EDT | Iteration                 19
2017-07-31 15:26:26.813426 EDT | AverageReturn             38.8046
2017-07-31 15:26:26.813573 EDT | StdReturn                  0.914326
2017-07-31 15:26:26.813723 EDT | MaxReturn                 40.7344
2017-07-31 15:26:26.813867 EDT | MinReturn                 36.6531
2017-07-31 15:26:26.814020 EDT | AverageEsReturn           40.8535
2017-07-31 15:26:26.814192 EDT | StdEsReturn                5.19488
2017-07-31 15:26:26.814342 EDT | MaxEsReturn               58.4632
2017-07-31 15:26:26.814483 EDT | MinEsReturn               20.5936
2017-07-31 15:26:26.814627 EDT | AverageDiscountedReturn   34.4845
2017-07-31 15:26:26.814768 EDT | AverageQLoss               0.260266
2017-07-31 15:26:26.814911 EDT | AveragePolicySurr        -11.3742
2017-07-31 15:26:26.815051 EDT | AverageQ                  10.392
2017-07-31 15:26:26.815192 EDT | AverageAbsQ               10.4055
2017-07-31 15:26:26.815336 EDT | AverageY                  10.3937
2017-07-31 15:26:26.815480 EDT | AverageAbsY               10.4025
2017-07-31 15:26:26.815621 EDT | AverageAbsQYDiff           0.276534
2017-07-31 15:26:26.815762 EDT | AverageAction              1
2017-07-31 15:26:26.815921 EDT | PolicyRegParamNorm        12.7218
2017-07-31 15:26:26.816066 EDT | QFunRegParamNorm          21.7184
2017-07-31 15:26:26.816207 EDT | -----------------------  ----------
2017-07-31 15:26:26.816482 EDT | [Active_RL/Hard_Oracle_DDPG/Experiment_0] epoch #20 | Training started
2017-07-31 15:26:43.559188 EDT | [Active_RL/Hard_Oracle_DDPG/Experiment_0] epoch #20 | Training finished
2017-07-31 15:26:43.561433 EDT | [Active_RL/Hard_Oracle_DDPG/Experiment_0] epoch #20 | Trained qf 1000 steps, policy 1000 steps
2017-07-31 15:26:43.561706 EDT | [Active_RL/Hard_Oracle_DDPG/Experiment_0] epoch #20 | Collecting samples for evaluation
2017-07-31 15:26:55.246725 EDT | -----------------------  ----------
2017-07-31 15:26:55.247704 EDT | Epoch                     20
2017-07-31 15:26:55.247985 EDT | Iteration                 20
2017-07-31 15:26:55.248301 EDT | AverageReturn             38.7996
2017-07-31 15:26:55.248573 EDT | StdReturn                  0.933239
2017-07-31 15:26:55.248868 EDT | MaxReturn                 41.8561
2017-07-31 15:26:55.249193 EDT | MinReturn                 36.6063
2017-07-31 15:26:55.249520 EDT | AverageEsReturn           40.6704
2017-07-31 15:26:55.249822 EDT | StdEsReturn                3.21288
2017-07-31 15:26:55.250128 EDT | MaxEsReturn               52.716
2017-07-31 15:26:55.250455 EDT | MinEsReturn               32.3575
2017-07-31 15:26:55.250773 EDT | AverageDiscountedReturn   34.4813
2017-07-31 15:26:55.251118 EDT | AverageQLoss               0.23964
2017-07-31 15:26:55.251437 EDT | AveragePolicySurr        -12.7891
2017-07-31 15:26:55.251754 EDT | AverageQ                  11.7398
2017-07-31 15:26:55.252043 EDT | AverageAbsQ               11.7515
2017-07-31 15:26:55.252372 EDT | AverageY                  11.7409
2017-07-31 15:26:55.252683 EDT | AverageAbsY               11.7476
2017-07-31 15:26:55.253009 EDT | AverageAbsQYDiff           0.277994
2017-07-31 15:26:55.253338 EDT | AverageAction              1
2017-07-31 15:26:55.253637 EDT | PolicyRegParamNorm        12.7245
2017-07-31 15:26:55.253870 EDT | QFunRegParamNorm          22.6521
2017-07-31 15:26:55.254197 EDT | -----------------------  ----------
2017-07-31 15:26:55.254646 EDT | [Active_RL/Hard_Oracle_DDPG/Experiment_0] epoch #21 | Training started
2017-07-31 15:27:11.623375 EDT | [Active_RL/Hard_Oracle_DDPG/Experiment_0] epoch #21 | Training finished
2017-07-31 15:27:11.624273 EDT | [Active_RL/Hard_Oracle_DDPG/Experiment_0] epoch #21 | Trained qf 1000 steps, policy 1000 steps
2017-07-31 15:27:11.624486 EDT | [Active_RL/Hard_Oracle_DDPG/Experiment_0] epoch #21 | Collecting samples for evaluation
2017-07-31 15:27:23.252633 EDT | -----------------------  ----------
2017-07-31 15:27:23.253439 EDT | Epoch                     21
2017-07-31 15:27:23.253616 EDT | Iteration                 21
2017-07-31 15:27:23.253782 EDT | AverageReturn             38.7505
2017-07-31 15:27:23.253940 EDT | StdReturn                  0.933111
2017-07-31 15:27:23.254087 EDT | MaxReturn                 41.9524
2017-07-31 15:27:23.254285 EDT | MinReturn                 36.7362
2017-07-31 15:27:23.254431 EDT | AverageEsReturn           39.7545
2017-07-31 15:27:23.254586 EDT | StdEsReturn                5.19755
2017-07-31 15:27:23.254802 EDT | MaxEsReturn               51.5171
2017-07-31 15:27:23.254949 EDT | MinEsReturn               12.5926
2017-07-31 15:27:23.255094 EDT | AverageDiscountedReturn   34.4424
2017-07-31 15:27:23.255240 EDT | AverageQLoss               0.312344
2017-07-31 15:27:23.255381 EDT | AveragePolicySurr        -14.1805
2017-07-31 15:27:23.255530 EDT | AverageQ                  13.0562
2017-07-31 15:27:23.255669 EDT | AverageAbsQ               13.0688
2017-07-31 15:27:23.255809 EDT | AverageY                  13.0576
2017-07-31 15:27:23.255947 EDT | AverageAbsY               13.0648
2017-07-31 15:27:23.256087 EDT | AverageAbsQYDiff           0.30661
2017-07-31 15:27:23.256226 EDT | AverageAction              1
2017-07-31 15:27:23.256366 EDT | PolicyRegParamNorm        12.7263
2017-07-31 15:27:23.256511 EDT | QFunRegParamNorm          23.5477
2017-07-31 15:27:23.256687 EDT | -----------------------  ----------
2017-07-31 15:27:23.257178 EDT | [Active_RL/Hard_Oracle_DDPG/Experiment_0] epoch #22 | Training started
2017-07-31 15:27:40.334637 EDT | [Active_RL/Hard_Oracle_DDPG/Experiment_0] epoch #22 | Training finished
2017-07-31 15:27:40.336595 EDT | [Active_RL/Hard_Oracle_DDPG/Experiment_0] epoch #22 | Trained qf 1000 steps, policy 1000 steps
2017-07-31 15:27:40.336914 EDT | [Active_RL/Hard_Oracle_DDPG/Experiment_0] epoch #22 | Collecting samples for evaluation
2017-07-31 15:27:51.393846 EDT | -----------------------  ----------
2017-07-31 15:27:51.394808 EDT | Epoch                     22
2017-07-31 15:27:51.395172 EDT | Iteration                 22
2017-07-31 15:27:51.395470 EDT | AverageReturn             38.7044
2017-07-31 15:27:51.395748 EDT | StdReturn                  0.881275
2017-07-31 15:27:51.395985 EDT | MaxReturn                 40.6465
2017-07-31 15:27:51.396141 EDT | MinReturn                 36.6658
2017-07-31 15:27:51.396393 EDT | AverageEsReturn           40.9812
2017-07-31 15:27:51.396570 EDT | StdEsReturn                4.36429
2017-07-31 15:27:51.396769 EDT | MaxEsReturn               60.0723
2017-07-31 15:27:51.396916 EDT | MinEsReturn               32.0095
2017-07-31 15:27:51.397141 EDT | AverageDiscountedReturn   34.4055
2017-07-31 15:27:51.397317 EDT | AverageQLoss               0.368891
2017-07-31 15:27:51.397626 EDT | AveragePolicySurr        -15.5123
2017-07-31 15:27:51.397780 EDT | AverageQ                  14.3534
2017-07-31 15:27:51.397924 EDT | AverageAbsQ               14.3665
2017-07-31 15:27:51.398066 EDT | AverageY                  14.3552
2017-07-31 15:27:51.398246 EDT | AverageAbsY               14.3616
2017-07-31 15:27:51.398426 EDT | AverageAbsQYDiff           0.337647
2017-07-31 15:27:51.398721 EDT | AverageAction              1
2017-07-31 15:27:51.398965 EDT | PolicyRegParamNorm        12.7284
2017-07-31 15:27:51.399119 EDT | QFunRegParamNorm          24.4304
2017-07-31 15:27:51.399276 EDT | -----------------------  ----------
2017-07-31 15:27:51.399650 EDT | [Active_RL/Hard_Oracle_DDPG/Experiment_0] epoch #23 | Training started
2017-07-31 15:28:08.685260 EDT | [Active_RL/Hard_Oracle_DDPG/Experiment_0] epoch #23 | Training finished
2017-07-31 15:28:08.686205 EDT | [Active_RL/Hard_Oracle_DDPG/Experiment_0] epoch #23 | Trained qf 1000 steps, policy 1000 steps
2017-07-31 15:28:08.686481 EDT | [Active_RL/Hard_Oracle_DDPG/Experiment_0] epoch #23 | Collecting samples for evaluation
2017-07-31 15:28:20.065054 EDT | -----------------------  ----------
2017-07-31 15:28:20.065927 EDT | Epoch                     23
2017-07-31 15:28:20.066198 EDT | Iteration                 23
2017-07-31 15:28:20.066375 EDT | AverageReturn             38.808
2017-07-31 15:28:20.066538 EDT | StdReturn                  0.94473
2017-07-31 15:28:20.066696 EDT | MaxReturn                 40.6888
2017-07-31 15:28:20.066902 EDT | MinReturn                 36.6486
2017-07-31 15:28:20.067054 EDT | AverageEsReturn           40.6186
2017-07-31 15:28:20.067256 EDT | StdEsReturn                2.36473
2017-07-31 15:28:20.067589 EDT | MaxEsReturn               46.7397
2017-07-31 15:28:20.067867 EDT | MinEsReturn               34.0585
2017-07-31 15:28:20.068026 EDT | AverageDiscountedReturn   34.488
2017-07-31 15:28:20.068185 EDT | AverageQLoss               0.440775
2017-07-31 15:28:20.068330 EDT | AveragePolicySurr        -16.69
2017-07-31 15:28:20.068502 EDT | AverageQ                  15.4861
2017-07-31 15:28:20.068659 EDT | AverageAbsQ               15.4969
2017-07-31 15:28:20.068812 EDT | AverageY                  15.4875
2017-07-31 15:28:20.069025 EDT | AverageAbsY               15.4927
2017-07-31 15:28:20.069183 EDT | AverageAbsQYDiff           0.357087
2017-07-31 15:28:20.069344 EDT | AverageAction              1
2017-07-31 15:28:20.069546 EDT | PolicyRegParamNorm        12.7298
2017-07-31 15:28:20.069704 EDT | QFunRegParamNorm          25.3194
2017-07-31 15:28:20.069855 EDT | -----------------------  ----------
2017-07-31 15:28:20.070179 EDT | [Active_RL/Hard_Oracle_DDPG/Experiment_0] epoch #24 | Training started
2017-07-31 15:28:37.732035 EDT | [Active_RL/Hard_Oracle_DDPG/Experiment_0] epoch #24 | Training finished
2017-07-31 15:28:37.732721 EDT | [Active_RL/Hard_Oracle_DDPG/Experiment_0] epoch #24 | Trained qf 1000 steps, policy 1000 steps
2017-07-31 15:28:37.732962 EDT | [Active_RL/Hard_Oracle_DDPG/Experiment_0] epoch #24 | Collecting samples for evaluation
2017-07-31 15:28:48.838862 EDT | -----------------------  ----------
2017-07-31 15:28:48.839798 EDT | Epoch                     24
2017-07-31 15:28:48.840059 EDT | Iteration                 24
2017-07-31 15:28:48.840294 EDT | AverageReturn             38.85
2017-07-31 15:28:48.840526 EDT | StdReturn                  0.939161
2017-07-31 15:28:48.840755 EDT | MaxReturn                 40.7652
2017-07-31 15:28:48.840983 EDT | MinReturn                 36.7001
2017-07-31 15:28:48.841214 EDT | AverageEsReturn           40.7794
2017-07-31 15:28:48.841438 EDT | StdEsReturn                4.77986
2017-07-31 15:28:48.841663 EDT | MaxEsReturn               55.0322
2017-07-31 15:28:48.841892 EDT | MinEsReturn               16.7781
2017-07-31 15:28:48.842126 EDT | AverageDiscountedReturn   34.5202
2017-07-31 15:28:48.842387 EDT | AverageQLoss               0.426867
2017-07-31 15:28:48.842617 EDT | AveragePolicySurr        -17.8415
2017-07-31 15:28:48.842846 EDT | AverageQ                  16.6064
2017-07-31 15:28:48.843076 EDT | AverageAbsQ               16.6171
2017-07-31 15:28:48.843299 EDT | AverageY                  16.6079
2017-07-31 15:28:48.843528 EDT | AverageAbsY               16.6133
2017-07-31 15:28:48.843758 EDT | AverageAbsQYDiff           0.363918
2017-07-31 15:28:48.843983 EDT | AverageAction              1
2017-07-31 15:28:48.844218 EDT | PolicyRegParamNorm        12.7315
2017-07-31 15:28:48.844446 EDT | QFunRegParamNorm          26.126
2017-07-31 15:28:48.844668 EDT | -----------------------  ----------
2017-07-31 15:28:48.845114 EDT | [Active_RL/Hard_Oracle_DDPG/Experiment_0] epoch #25 | Training started
2017-07-31 15:29:06.362717 EDT | [Active_RL/Hard_Oracle_DDPG/Experiment_0] epoch #25 | Training finished
2017-07-31 15:29:06.363725 EDT | [Active_RL/Hard_Oracle_DDPG/Experiment_0] epoch #25 | Trained qf 1000 steps, policy 1000 steps
2017-07-31 15:29:06.364054 EDT | [Active_RL/Hard_Oracle_DDPG/Experiment_0] epoch #25 | Collecting samples for evaluation
2017-07-31 15:29:17.583585 EDT | -----------------------  ----------
2017-07-31 15:29:17.584512 EDT | Epoch                     25
2017-07-31 15:29:17.584778 EDT | Iteration                 25
2017-07-31 15:29:17.584938 EDT | AverageReturn             38.7351
2017-07-31 15:29:17.585100 EDT | StdReturn                  0.988725
2017-07-31 15:29:17.585248 EDT | MaxReturn                 40.8091
2017-07-31 15:29:17.585451 EDT | MinReturn                 36.7305
2017-07-31 15:29:17.585646 EDT | AverageEsReturn           42.3021
2017-07-31 15:29:17.585797 EDT | StdEsReturn                4.51071
2017-07-31 15:29:17.585944 EDT | MaxEsReturn               57.7594
2017-07-31 15:29:17.586123 EDT | MinEsReturn               37.0017
2017-07-31 15:29:17.586291 EDT | AverageDiscountedReturn   34.429
2017-07-31 15:29:17.586446 EDT | AverageQLoss               0.434675
2017-07-31 15:29:17.586594 EDT | AveragePolicySurr        -18.8831
2017-07-31 15:29:17.586738 EDT | AverageQ                  17.6626
2017-07-31 15:29:17.586898 EDT | AverageAbsQ               17.6727
2017-07-31 15:29:17.587039 EDT | AverageY                  17.6643
2017-07-31 15:29:17.587203 EDT | AverageAbsY               17.6687
2017-07-31 15:29:17.587361 EDT | AverageAbsQYDiff           0.378429
2017-07-31 15:29:17.587511 EDT | AverageAction              1
2017-07-31 15:29:17.587662 EDT | PolicyRegParamNorm        12.732
2017-07-31 15:29:17.587814 EDT | QFunRegParamNorm          26.9759
2017-07-31 15:29:17.587967 EDT | -----------------------  ----------
2017-07-31 15:29:17.588520 EDT | [Active_RL/Hard_Oracle_DDPG/Experiment_0] epoch #26 | Training started
2017-07-31 15:29:34.554996 EDT | [Active_RL/Hard_Oracle_DDPG/Experiment_0] epoch #26 | Training finished
2017-07-31 15:29:34.556411 EDT | [Active_RL/Hard_Oracle_DDPG/Experiment_0] epoch #26 | Trained qf 1000 steps, policy 1000 steps
2017-07-31 15:29:34.556972 EDT | [Active_RL/Hard_Oracle_DDPG/Experiment_0] epoch #26 | Collecting samples for evaluation
2017-07-31 15:29:45.705133 EDT | -----------------------  ----------
2017-07-31 15:29:45.705787 EDT | Epoch                     26
2017-07-31 15:29:45.707747 EDT | Iteration                 26
2017-07-31 15:29:45.708053 EDT | AverageReturn             38.7854
2017-07-31 15:29:45.708220 EDT | StdReturn                  0.867058
2017-07-31 15:29:45.708384 EDT | MaxReturn                 41.728
2017-07-31 15:29:45.708613 EDT | MinReturn                 36.6567
2017-07-31 15:29:45.708784 EDT | AverageEsReturn           40.5052
2017-07-31 15:29:45.708941 EDT | StdEsReturn                4.49922
2017-07-31 15:29:45.709123 EDT | MaxEsReturn               57.9273
2017-07-31 15:29:45.709472 EDT | MinEsReturn               25.365
2017-07-31 15:29:45.709804 EDT | AverageDiscountedReturn   34.47
2017-07-31 15:29:45.710122 EDT | AverageQLoss               0.554122
2017-07-31 15:29:45.710336 EDT | AveragePolicySurr        -19.7452
2017-07-31 15:29:45.710510 EDT | AverageQ                  18.554
2017-07-31 15:29:45.710716 EDT | AverageAbsQ               18.5637
2017-07-31 15:29:45.711023 EDT | AverageY                  18.5558
2017-07-31 15:29:45.711214 EDT | AverageAbsY               18.5597
2017-07-31 15:29:45.711367 EDT | AverageAbsQYDiff           0.404655
2017-07-31 15:29:45.711538 EDT | AverageAction              1
2017-07-31 15:29:45.711795 EDT | PolicyRegParamNorm        12.7323
2017-07-31 15:29:45.711960 EDT | QFunRegParamNorm          27.7869
2017-07-31 15:29:45.712124 EDT | -----------------------  ----------
2017-07-31 15:29:45.712477 EDT | [Active_RL/Hard_Oracle_DDPG/Experiment_0] epoch #27 | Training started
2017-07-31 15:30:03.279747 EDT | [Active_RL/Hard_Oracle_DDPG/Experiment_0] epoch #27 | Training finished
2017-07-31 15:30:03.280702 EDT | [Active_RL/Hard_Oracle_DDPG/Experiment_0] epoch #27 | Trained qf 1000 steps, policy 1000 steps
2017-07-31 15:30:03.280991 EDT | [Active_RL/Hard_Oracle_DDPG/Experiment_0] epoch #27 | Collecting samples for evaluation
2017-07-31 15:30:15.004953 EDT | -----------------------  ----------
2017-07-31 15:30:15.005770 EDT | Epoch                     27
2017-07-31 15:30:15.005944 EDT | Iteration                 27
2017-07-31 15:30:15.006095 EDT | AverageReturn             38.7573
2017-07-31 15:30:15.006279 EDT | StdReturn                  0.946311
2017-07-31 15:30:15.006426 EDT | MaxReturn                 40.6527
2017-07-31 15:30:15.006575 EDT | MinReturn                 36.6623
2017-07-31 15:30:15.006717 EDT | AverageEsReturn           40.7678
2017-07-31 15:30:15.006861 EDT | StdEsReturn                7.86206
2017-07-31 15:30:15.007007 EDT | MaxEsReturn               79.7974
2017-07-31 15:30:15.007148 EDT | MinEsReturn               11.9642
2017-07-31 15:30:15.007290 EDT | AverageDiscountedReturn   34.4478
2017-07-31 15:30:15.007432 EDT | AverageQLoss               0.66623
2017-07-31 15:30:15.007572 EDT | AveragePolicySurr        -20.4743
2017-07-31 15:30:15.007712 EDT | AverageQ                  19.3275
2017-07-31 15:30:15.007852 EDT | AverageAbsQ               19.3371
2017-07-31 15:30:15.007996 EDT | AverageY                  19.3284
2017-07-31 15:30:15.008142 EDT | AverageAbsY               19.3316
2017-07-31 15:30:15.008282 EDT | AverageAbsQYDiff           0.423766
2017-07-31 15:30:15.008423 EDT | AverageAction              1
2017-07-31 15:30:15.008562 EDT | PolicyRegParamNorm        12.7323
2017-07-31 15:30:15.008701 EDT | QFunRegParamNorm          28.6017
2017-07-31 15:30:15.008840 EDT | -----------------------  ----------
2017-07-31 15:30:15.009133 EDT | [Active_RL/Hard_Oracle_DDPG/Experiment_0] epoch #28 | Training started
2017-07-31 15:30:32.833169 EDT | [Active_RL/Hard_Oracle_DDPG/Experiment_0] epoch #28 | Training finished
2017-07-31 15:30:32.833994 EDT | [Active_RL/Hard_Oracle_DDPG/Experiment_0] epoch #28 | Trained qf 1000 steps, policy 1000 steps
2017-07-31 15:30:32.834239 EDT | [Active_RL/Hard_Oracle_DDPG/Experiment_0] epoch #28 | Collecting samples for evaluation
2017-07-31 15:30:44.714084 EDT | -----------------------  ----------
2017-07-31 15:30:44.714870 EDT | Epoch                     28
2017-07-31 15:30:44.715191 EDT | Iteration                 28
2017-07-31 15:30:44.715487 EDT | AverageReturn             38.7294
2017-07-31 15:30:44.715755 EDT | StdReturn                  0.872527
2017-07-31 15:30:44.716032 EDT | MaxReturn                 40.8042
2017-07-31 15:30:44.716326 EDT | MinReturn                 36.6847
2017-07-31 15:30:44.716615 EDT | AverageEsReturn           40.2769
2017-07-31 15:30:44.716905 EDT | StdEsReturn                5.52926
2017-07-31 15:30:44.717196 EDT | MaxEsReturn               61.5797
2017-07-31 15:30:44.717482 EDT | MinEsReturn               14.9595
2017-07-31 15:30:44.717749 EDT | AverageDiscountedReturn   34.4246
2017-07-31 15:30:44.718010 EDT | AverageQLoss               0.542064
2017-07-31 15:30:44.718257 EDT | AveragePolicySurr        -20.9987
2017-07-31 15:30:44.718403 EDT | AverageQ                  19.9251
2017-07-31 15:30:44.718544 EDT | AverageAbsQ               19.9347
2017-07-31 15:30:44.718685 EDT | AverageY                  19.9266
2017-07-31 15:30:44.718824 EDT | AverageAbsY               19.9294
2017-07-31 15:30:44.718964 EDT | AverageAbsQYDiff           0.402318
2017-07-31 15:30:44.719103 EDT | AverageAction              1
2017-07-31 15:30:44.719243 EDT | PolicyRegParamNorm        12.7332
2017-07-31 15:30:44.719382 EDT | QFunRegParamNorm          29.2843
2017-07-31 15:30:44.719522 EDT | -----------------------  ----------
2017-07-31 15:30:44.719778 EDT | [Active_RL/Hard_Oracle_DDPG/Experiment_0] epoch #29 | Training started
2017-07-31 15:31:02.814624 EDT | [Active_RL/Hard_Oracle_DDPG/Experiment_0] epoch #29 | Training finished
2017-07-31 15:31:02.815356 EDT | [Active_RL/Hard_Oracle_DDPG/Experiment_0] epoch #29 | Trained qf 1000 steps, policy 1000 steps
2017-07-31 15:31:02.815700 EDT | [Active_RL/Hard_Oracle_DDPG/Experiment_0] epoch #29 | Collecting samples for evaluation
2017-07-31 15:31:14.755965 EDT | -----------------------  ----------
2017-07-31 15:31:14.756396 EDT | Epoch                     29
2017-07-31 15:31:14.756648 EDT | Iteration                 29
2017-07-31 15:31:14.756889 EDT | AverageReturn             38.7978
2017-07-31 15:31:14.757126 EDT | StdReturn                  0.934962
2017-07-31 15:31:14.757363 EDT | MaxReturn                 41.7828
2017-07-31 15:31:14.757599 EDT | MinReturn                 36.6983
2017-07-31 15:31:14.757833 EDT | AverageEsReturn           43.3368
2017-07-31 15:31:14.758072 EDT | StdEsReturn                7.33591
2017-07-31 15:31:14.758322 EDT | MaxEsReturn               70.123
2017-07-31 15:31:14.758558 EDT | MinEsReturn               30.142
2017-07-31 15:31:14.758792 EDT | AverageDiscountedReturn   34.4778
2017-07-31 15:31:14.759034 EDT | AverageQLoss               0.648036
2017-07-31 15:31:14.759265 EDT | AveragePolicySurr        -21.4877
2017-07-31 15:31:14.759500 EDT | AverageQ                  20.4589
2017-07-31 15:31:14.759734 EDT | AverageAbsQ               20.4688
2017-07-31 15:31:14.759967 EDT | AverageY                  20.46
2017-07-31 15:31:14.760199 EDT | AverageAbsY               20.4629
2017-07-31 15:31:14.760436 EDT | AverageAbsQYDiff           0.412982
2017-07-31 15:31:14.760671 EDT | AverageAction              1
2017-07-31 15:31:14.760905 EDT | PolicyRegParamNorm        12.7345
2017-07-31 15:31:14.761139 EDT | QFunRegParamNorm          29.9475
2017-07-31 15:31:14.761371 EDT | -----------------------  ----------
2017-07-31 17:06:27.701249 EDT | [Active_RL/Hard_Oracle_DDPG/Experiment_0] observation space: Box(11,)
2017-07-31 17:06:27.701797 EDT | [Active_RL/Hard_Oracle_DDPG/Experiment_0] action space: Box(3,)
2017-07-31 17:06:28.472577 EDT | [Active_RL/Hard_Oracle_DDPG/Experiment_0] Populating workers...
2017-07-31 17:06:28.473004 EDT | [Active_RL/Hard_Oracle_DDPG/Experiment_0] Populated
2017-07-31 17:06:29.485971 EDT | [Active_RL/Hard_Oracle_DDPG/Experiment_0] epoch #0 | Training started
2017-07-31 17:06:31.161920 EDT | [Active_RL/Hard_Oracle_DDPG/Experiment_0] epoch #0 | Training finished
2017-07-31 17:06:31.162335 EDT | [Active_RL/Hard_Oracle_DDPG/Experiment_0] epoch #0 | Trained qf 0 steps, policy 0 steps
2017-07-31 17:06:31.162637 EDT | [Active_RL/Hard_Oracle_DDPG/Experiment_0] epoch #1 | Training started
2017-07-31 17:06:32.483427 EDT | [Active_RL/Hard_Oracle_DDPG/Experiment_0] epoch #1 | Training finished
2017-07-31 17:06:32.483836 EDT | [Active_RL/Hard_Oracle_DDPG/Experiment_0] epoch #1 | Trained qf 0 steps, policy 0 steps
2017-07-31 17:06:32.484055 EDT | [Active_RL/Hard_Oracle_DDPG/Experiment_0] epoch #2 | Training started
2017-07-31 17:06:33.701354 EDT | [Active_RL/Hard_Oracle_DDPG/Experiment_0] epoch #2 | Training finished
2017-07-31 17:06:33.705017 EDT | [Active_RL/Hard_Oracle_DDPG/Experiment_0] epoch #2 | Trained qf 0 steps, policy 0 steps
2017-07-31 17:06:33.705385 EDT | [Active_RL/Hard_Oracle_DDPG/Experiment_0] epoch #3 | Training started
2017-07-31 17:06:34.892650 EDT | [Active_RL/Hard_Oracle_DDPG/Experiment_0] epoch #3 | Training finished
2017-07-31 17:06:34.893231 EDT | [Active_RL/Hard_Oracle_DDPG/Experiment_0] epoch #3 | Trained qf 0 steps, policy 0 steps
2017-07-31 17:06:34.893735 EDT | [Active_RL/Hard_Oracle_DDPG/Experiment_0] epoch #4 | Training started
2017-07-31 17:06:36.063950 EDT | [Active_RL/Hard_Oracle_DDPG/Experiment_0] epoch #4 | Training finished
2017-07-31 17:06:36.064300 EDT | [Active_RL/Hard_Oracle_DDPG/Experiment_0] epoch #4 | Trained qf 0 steps, policy 0 steps
2017-07-31 17:06:36.064586 EDT | [Active_RL/Hard_Oracle_DDPG/Experiment_0] epoch #5 | Training started
2017-07-31 17:06:37.377691 EDT | [Active_RL/Hard_Oracle_DDPG/Experiment_0] epoch #5 | Training finished
2017-07-31 17:06:37.378080 EDT | [Active_RL/Hard_Oracle_DDPG/Experiment_0] epoch #5 | Trained qf 0 steps, policy 0 steps
2017-07-31 17:06:37.378362 EDT | [Active_RL/Hard_Oracle_DDPG/Experiment_0] epoch #6 | Training started
2017-07-31 17:06:38.656485 EDT | [Active_RL/Hard_Oracle_DDPG/Experiment_0] epoch #6 | Training finished
2017-07-31 17:06:38.656958 EDT | [Active_RL/Hard_Oracle_DDPG/Experiment_0] epoch #6 | Trained qf 0 steps, policy 0 steps
2017-07-31 17:06:38.657276 EDT | [Active_RL/Hard_Oracle_DDPG/Experiment_0] epoch #7 | Training started
2017-07-31 17:06:39.833495 EDT | [Active_RL/Hard_Oracle_DDPG/Experiment_0] epoch #7 | Training finished
2017-07-31 17:06:39.836125 EDT | [Active_RL/Hard_Oracle_DDPG/Experiment_0] epoch #7 | Trained qf 0 steps, policy 0 steps
2017-07-31 17:06:39.836493 EDT | [Active_RL/Hard_Oracle_DDPG/Experiment_0] epoch #8 | Training started
2017-07-31 17:06:40.995838 EDT | [Active_RL/Hard_Oracle_DDPG/Experiment_0] epoch #8 | Training finished
2017-07-31 17:06:40.996120 EDT | [Active_RL/Hard_Oracle_DDPG/Experiment_0] epoch #8 | Trained qf 0 steps, policy 0 steps
2017-07-31 17:06:40.996349 EDT | [Active_RL/Hard_Oracle_DDPG/Experiment_0] epoch #9 | Training started
2017-07-31 17:06:42.702311 EDT | [Active_RL/Hard_Oracle_DDPG/Experiment_0] epoch #9 | Training finished
2017-07-31 17:06:42.702782 EDT | [Active_RL/Hard_Oracle_DDPG/Experiment_0] epoch #9 | Trained qf 1 steps, policy 1 steps
2017-07-31 17:06:42.703091 EDT | [Active_RL/Hard_Oracle_DDPG/Experiment_0] epoch #9 | Collecting samples for evaluation
2017-07-31 17:06:54.039206 EDT | -----------------------  ----------
2017-07-31 17:06:54.040128 EDT | Epoch                     9
2017-07-31 17:06:54.040397 EDT | Iteration                 9
2017-07-31 17:06:54.040646 EDT | AverageReturn             9.21732
2017-07-31 17:06:54.040897 EDT | StdReturn                 0.0479767
2017-07-31 17:06:54.041135 EDT | MaxReturn                 9.34979
2017-07-31 17:06:54.041374 EDT | MinReturn                 9.08556
2017-07-31 17:06:54.041609 EDT | AverageEsReturn           9.6785
2017-07-31 17:06:54.041846 EDT | StdEsReturn               6.89704
2017-07-31 17:06:54.042089 EDT | MaxEsReturn              60.0645
2017-07-31 17:06:54.042343 EDT | MinEsReturn               3.10852
2017-07-31 17:06:54.042579 EDT | AverageDiscountedReturn   8.7931
2017-07-31 17:06:54.042813 EDT | AverageQLoss              3.82421
2017-07-31 17:06:54.043052 EDT | AveragePolicySurr        -0.0136809
2017-07-31 17:06:54.043290 EDT | AverageQ                 -0.232406
2017-07-31 17:06:54.043523 EDT | AverageAbsQ               0.282284
2017-07-31 17:06:54.043756 EDT | AverageY                  1.60002
2017-07-31 17:06:54.043990 EDT | AverageAbsY               1.60002
2017-07-31 17:06:54.044223 EDT | AverageAbsQYDiff          1.83243
2017-07-31 17:06:54.044461 EDT | AverageAction             0.219395
2017-07-31 17:06:54.044695 EDT | PolicyRegParamNorm       11.2289
2017-07-31 17:06:54.044928 EDT | QFunRegParamNorm         11.1297
2017-07-31 17:06:54.045164 EDT | -----------------------  ----------
2017-07-31 17:06:54.045657 EDT | [Active_RL/Hard_Oracle_DDPG/Experiment_0] epoch #10 | Training started
2017-07-31 17:07:11.518750 EDT | [Active_RL/Hard_Oracle_DDPG/Experiment_0] epoch #10 | Training finished
2017-07-31 17:07:11.519706 EDT | [Active_RL/Hard_Oracle_DDPG/Experiment_0] epoch #10 | Trained qf 1000 steps, policy 1000 steps
2017-07-31 17:07:11.519992 EDT | [Active_RL/Hard_Oracle_DDPG/Experiment_0] epoch #10 | Collecting samples for evaluation
2017-07-31 17:07:23.898256 EDT | -----------------------  ----------
2017-07-31 17:07:23.898998 EDT | Epoch                    10
2017-07-31 17:07:23.899235 EDT | Iteration                10
2017-07-31 17:07:23.899396 EDT | AverageReturn             5.29582
2017-07-31 17:07:23.899563 EDT | StdReturn                 0.0401337
2017-07-31 17:07:23.899717 EDT | MaxReturn                 5.41753
2017-07-31 17:07:23.899879 EDT | MinReturn                 5.09119
2017-07-31 17:07:23.900025 EDT | AverageEsReturn           4.96336
2017-07-31 17:07:23.900177 EDT | StdEsReturn               2.75136
2017-07-31 17:07:23.900328 EDT | MaxEsReturn              19.0757
2017-07-31 17:07:23.900476 EDT | MinEsReturn               2.43556
2017-07-31 17:07:23.900625 EDT | AverageDiscountedReturn   5.13479
2017-07-31 17:07:23.900780 EDT | AverageQLoss              0.0580032
2017-07-31 17:07:23.901005 EDT | AveragePolicySurr        -1.25667
2017-07-31 17:07:23.901256 EDT | AverageQ                  1.17541
2017-07-31 17:07:23.901496 EDT | AverageAbsQ               1.1838
2017-07-31 17:07:23.901665 EDT | AverageY                  1.18506
2017-07-31 17:07:23.901963 EDT | AverageAbsY               1.1962
2017-07-31 17:07:23.902327 EDT | AverageAbsQYDiff          0.125352
2017-07-31 17:07:23.902579 EDT | AverageAction             0.999408
2017-07-31 17:07:23.902731 EDT | PolicyRegParamNorm       12.3209
2017-07-31 17:07:23.902884 EDT | QFunRegParamNorm         11.4442
2017-07-31 17:07:23.903049 EDT | -----------------------  ----------
2017-07-31 17:07:23.903463 EDT | [Active_RL/Hard_Oracle_DDPG/Experiment_0] epoch #11 | Training started
2017-07-31 17:07:42.856052 EDT | [Active_RL/Hard_Oracle_DDPG/Experiment_0] epoch #11 | Training finished
2017-07-31 17:07:42.856597 EDT | [Active_RL/Hard_Oracle_DDPG/Experiment_0] epoch #11 | Trained qf 1000 steps, policy 1000 steps
2017-07-31 17:07:42.856946 EDT | [Active_RL/Hard_Oracle_DDPG/Experiment_0] epoch #11 | Collecting samples for evaluation
