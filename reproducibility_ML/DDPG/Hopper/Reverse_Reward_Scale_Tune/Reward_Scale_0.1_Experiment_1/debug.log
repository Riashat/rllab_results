2017-06-10 19:18:10.772176 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] observation space: Box(11,)
2017-06-10 19:18:10.772903 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] action space: Box(3,)
2017-06-10 19:18:11.186425 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] Populating workers...
2017-06-10 19:18:11.187138 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] Populated
2017-06-10 19:18:12.942959 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #0 | Training started
2017-06-10 19:18:14.956860 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #0 | Training finished
2017-06-10 19:18:14.957284 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #0 | Trained qf 0 steps, policy 0 steps
2017-06-10 19:18:14.957635 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1 | Training started
2017-06-10 19:18:16.889069 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1 | Training finished
2017-06-10 19:18:16.889575 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1 | Trained qf 0 steps, policy 0 steps
2017-06-10 19:18:16.889999 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #2 | Training started
2017-06-10 19:18:18.588226 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #2 | Training finished
2017-06-10 19:18:18.588806 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #2 | Trained qf 0 steps, policy 0 steps
2017-06-10 19:18:18.589110 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #3 | Training started
2017-06-10 19:18:20.316358 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #3 | Training finished
2017-06-10 19:18:20.317443 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #3 | Trained qf 0 steps, policy 0 steps
2017-06-10 19:18:20.318010 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #4 | Training started
2017-06-10 19:18:21.924136 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #4 | Training finished
2017-06-10 19:18:21.924503 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #4 | Trained qf 0 steps, policy 0 steps
2017-06-10 19:18:21.924811 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #5 | Training started
2017-06-10 19:18:23.540038 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #5 | Training finished
2017-06-10 19:18:23.540711 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #5 | Trained qf 0 steps, policy 0 steps
2017-06-10 19:18:23.541140 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #6 | Training started
2017-06-10 19:18:25.362027 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #6 | Training finished
2017-06-10 19:18:25.362377 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #6 | Trained qf 0 steps, policy 0 steps
2017-06-10 19:18:25.362660 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #7 | Training started
2017-06-10 19:18:27.105978 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #7 | Training finished
2017-06-10 19:18:27.106351 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #7 | Trained qf 0 steps, policy 0 steps
2017-06-10 19:18:27.106639 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #8 | Training started
2017-06-10 19:18:28.587537 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #8 | Training finished
2017-06-10 19:18:28.587962 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #8 | Trained qf 0 steps, policy 0 steps
2017-06-10 19:18:28.588329 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #9 | Training started
2017-06-10 19:18:30.261174 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #9 | Training finished
2017-06-10 19:18:30.261542 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #9 | Trained qf 1 steps, policy 1 steps
2017-06-10 19:18:30.261887 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #9 | Collecting samples for evaluation
2017-06-10 19:18:48.500932 EDT | -----------------------  ----------
2017-06-10 19:18:48.501865 EDT | Epoch                     9
2017-06-10 19:18:48.502172 EDT | Iteration                 9
2017-06-10 19:18:48.502460 EDT | AverageReturn             9.22997
2017-06-10 19:18:48.502740 EDT | StdReturn                 0.0483383
2017-06-10 19:18:48.503018 EDT | MaxReturn                 9.35924
2017-06-10 19:18:48.503339 EDT | MinReturn                 9.11389
2017-06-10 19:18:48.503659 EDT | AverageEsReturn           9.79132
2017-06-10 19:18:48.503938 EDT | StdEsReturn               6.69409
2017-06-10 19:18:48.504210 EDT | MaxEsReturn              63.4049
2017-06-10 19:18:48.504483 EDT | MinEsReturn               1.33996
2017-06-10 19:18:48.504755 EDT | AverageDiscountedReturn   8.80477
2017-06-10 19:18:48.505029 EDT | AverageQLoss              1.48934
2017-06-10 19:18:48.505301 EDT | AveragePolicySurr         0.010008
2017-06-10 19:18:48.505575 EDT | AverageQ                 -0.251323
2017-06-10 19:18:48.505862 EDT | AverageAbsQ               0.311006
2017-06-10 19:18:48.506140 EDT | AverageY                  0.788707
2017-06-10 19:18:48.506413 EDT | AverageAbsY               0.788707
2017-06-10 19:18:48.506686 EDT | AverageAbsQYDiff          1.04003
2017-06-10 19:18:48.517012 EDT | AverageAction             0.216927
2017-06-10 19:18:48.517470 EDT | PolicyRegParamNorm       11.2289
2017-06-10 19:18:48.520415 EDT | QFunRegParamNorm         11.1297
2017-06-10 19:18:48.521031 EDT | -----------------------  ----------
2017-06-10 19:18:48.524300 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #10 | Training started
2017-06-10 19:19:07.802199 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #10 | Training finished
2017-06-10 19:19:07.803133 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #10 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 19:19:07.803567 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #10 | Collecting samples for evaluation
2017-06-10 19:19:23.991144 EDT | -----------------------  ----------
2017-06-10 19:19:23.996199 EDT | Epoch                    10
2017-06-10 19:19:23.996566 EDT | Iteration                10
2017-06-10 19:19:23.996784 EDT | AverageReturn             3.08561
2017-06-10 19:19:23.996954 EDT | StdReturn                 0.0174157
2017-06-10 19:19:23.997143 EDT | MaxReturn                 3.12161
2017-06-10 19:19:23.997443 EDT | MinReturn                 3.04813
2017-06-10 19:19:23.997679 EDT | AverageEsReturn           3.908
2017-06-10 19:19:23.997870 EDT | StdEsReturn               2.57028
2017-06-10 19:19:23.998048 EDT | MaxEsReturn              33.8704
2017-06-10 19:19:23.998238 EDT | MinEsReturn               2.38529
2017-06-10 19:19:23.998422 EDT | AverageDiscountedReturn   3.03643
2017-06-10 19:19:23.998605 EDT | AverageQLoss              0.0316435
2017-06-10 19:19:23.998787 EDT | AveragePolicySurr        -0.521372
2017-06-10 19:19:23.998970 EDT | AverageQ                  0.418378
2017-06-10 19:19:23.999152 EDT | AverageAbsQ               0.419452
2017-06-10 19:19:23.999333 EDT | AverageY                  0.421725
2017-06-10 19:19:23.999823 EDT | AverageAbsY               0.422609
2017-06-10 19:19:24.000009 EDT | AverageAbsQYDiff          0.0943109
2017-06-10 19:19:24.000194 EDT | AverageAction             0.999978
2017-06-10 19:19:24.000375 EDT | PolicyRegParamNorm       11.6522
2017-06-10 19:19:24.000884 EDT | QFunRegParamNorm         11.3021
2017-06-10 19:19:24.001068 EDT | -----------------------  ----------
2017-06-10 19:19:24.001425 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #11 | Training started
2017-06-10 19:19:40.232955 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #11 | Training finished
2017-06-10 19:19:40.233270 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #11 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 19:19:40.233473 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #11 | Collecting samples for evaluation
2017-06-10 19:19:54.067960 EDT | -----------------------  -----------
2017-06-10 19:19:54.069431 EDT | Epoch                    11
2017-06-10 19:19:54.069826 EDT | Iteration                11
2017-06-10 19:19:54.070175 EDT | AverageReturn             3.08586
2017-06-10 19:19:54.070518 EDT | StdReturn                 0.0179748
2017-06-10 19:19:54.070863 EDT | MaxReturn                 3.12166
2017-06-10 19:19:54.071205 EDT | MinReturn                 3.04898
2017-06-10 19:19:54.071804 EDT | AverageEsReturn           3.63139
2017-06-10 19:19:54.072120 EDT | StdEsReturn               0.680987
2017-06-10 19:19:54.072451 EDT | MaxEsReturn               7.43711
2017-06-10 19:19:54.072795 EDT | MinEsReturn               2.2747
2017-06-10 19:19:54.073137 EDT | AverageDiscountedReturn   3.03668
2017-06-10 19:19:54.073481 EDT | AverageQLoss              0.00420526
2017-06-10 19:19:54.074686 EDT | AveragePolicySurr        -0.396427
2017-06-10 19:19:54.075045 EDT | AverageQ                  0.374021
2017-06-10 19:19:54.075348 EDT | AverageAbsQ               0.376993
2017-06-10 19:19:54.075642 EDT | AverageY                  0.374263
2017-06-10 19:19:54.075963 EDT | AverageAbsY               0.375067
2017-06-10 19:19:54.076305 EDT | AverageAbsQYDiff          0.038405
2017-06-10 19:19:54.076648 EDT | AverageAction             0.999997
2017-06-10 19:19:54.076990 EDT | PolicyRegParamNorm       11.745
2017-06-10 19:19:54.077335 EDT | QFunRegParamNorm         11.3825
2017-06-10 19:19:54.077679 EDT | -----------------------  -----------
2017-06-10 19:19:54.078398 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #12 | Training started
2017-06-10 19:20:10.267972 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #12 | Training finished
2017-06-10 19:20:10.269228 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #12 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 19:20:10.269591 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #12 | Collecting samples for evaluation
2017-06-10 19:20:25.031566 EDT | -----------------------  -----------
2017-06-10 19:20:25.032287 EDT | Epoch                    12
2017-06-10 19:20:25.032477 EDT | Iteration                12
2017-06-10 19:20:25.032639 EDT | AverageReturn             3.08535
2017-06-10 19:20:25.032802 EDT | StdReturn                 0.0174837
2017-06-10 19:20:25.032962 EDT | MaxReturn                 3.12312
2017-06-10 19:20:25.033116 EDT | MinReturn                 3.0481
2017-06-10 19:20:25.033267 EDT | AverageEsReturn           3.88178
2017-06-10 19:20:25.033463 EDT | StdEsReturn               0.854864
2017-06-10 19:20:25.033751 EDT | MaxEsReturn               9.70641
2017-06-10 19:20:25.038886 EDT | MinEsReturn               2.96699
2017-06-10 19:20:25.039057 EDT | AverageDiscountedReturn   3.03618
2017-06-10 19:20:25.039220 EDT | AverageQLoss              0.00189457
2017-06-10 19:20:25.039374 EDT | AveragePolicySurr        -0.373807
2017-06-10 19:20:25.039525 EDT | AverageQ                  0.382438
2017-06-10 19:20:25.039676 EDT | AverageAbsQ               0.386463
2017-06-10 19:20:25.039826 EDT | AverageY                  0.382489
2017-06-10 19:20:25.039975 EDT | AverageAbsY               0.383857
2017-06-10 19:20:25.040124 EDT | AverageAbsQYDiff          0.0280589
2017-06-10 19:20:25.040274 EDT | AverageAction             0.999998
2017-06-10 19:20:25.040424 EDT | PolicyRegParamNorm       11.7845
2017-06-10 19:20:25.040585 EDT | QFunRegParamNorm         11.4832
2017-06-10 19:20:25.040797 EDT | -----------------------  -----------
2017-06-10 19:20:25.041104 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #13 | Training started
2017-06-10 19:20:41.313630 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #13 | Training finished
2017-06-10 19:20:41.314125 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #13 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 19:20:41.314481 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #13 | Collecting samples for evaluation
2017-06-10 19:20:55.541195 EDT | -----------------------  -----------
2017-06-10 19:20:55.542174 EDT | Epoch                    13
2017-06-10 19:20:55.542549 EDT | Iteration                13
2017-06-10 19:20:55.542871 EDT | AverageReturn            38.7856
2017-06-10 19:20:55.543429 EDT | StdReturn                 0.917885
2017-06-10 19:20:55.543756 EDT | MaxReturn                40.8214
2017-06-10 19:20:55.544315 EDT | MinReturn                36.7793
2017-06-10 19:20:55.544646 EDT | AverageEsReturn           5.2692
2017-06-10 19:20:55.545896 EDT | StdEsReturn               7.70285
2017-06-10 19:20:55.546278 EDT | MaxEsReturn              46.8032
2017-06-10 19:20:55.547551 EDT | MinEsReturn               2.56147
2017-06-10 19:20:55.547903 EDT | AverageDiscountedReturn  34.4673
2017-06-10 19:20:55.548226 EDT | AverageQLoss              0.00130563
2017-06-10 19:20:55.548547 EDT | AveragePolicySurr        -0.370077
2017-06-10 19:20:55.550450 EDT | AverageQ                  0.374511
2017-06-10 19:20:55.550712 EDT | AverageAbsQ               0.37866
2017-06-10 19:20:55.550911 EDT | AverageY                  0.37448
2017-06-10 19:20:55.551142 EDT | AverageAbsY               0.376866
2017-06-10 19:20:55.551298 EDT | AverageAbsQYDiff          0.0234922
2017-06-10 19:20:55.551449 EDT | AverageAction             1
2017-06-10 19:20:55.551601 EDT | PolicyRegParamNorm       12.2965
2017-06-10 19:20:55.551767 EDT | QFunRegParamNorm         11.6572
2017-06-10 19:20:55.552038 EDT | -----------------------  -----------
2017-06-10 19:20:55.552468 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #14 | Training started
2017-06-10 19:21:12.217475 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #14 | Training finished
2017-06-10 19:21:12.218288 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #14 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 19:21:12.218771 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #14 | Collecting samples for evaluation
2017-06-10 19:21:27.032009 EDT | -----------------------  -----------
2017-06-10 19:21:27.033225 EDT | Epoch                    14
2017-06-10 19:21:27.033739 EDT | Iteration                14
2017-06-10 19:21:27.034170 EDT | AverageReturn            38.8575
2017-06-10 19:21:27.034441 EDT | StdReturn                 0.981077
2017-06-10 19:21:27.034725 EDT | MaxReturn                40.8175
2017-06-10 19:21:27.034998 EDT | MinReturn                36.6731
2017-06-10 19:21:27.035532 EDT | AverageEsReturn          41.1263
2017-06-10 19:21:27.037355 EDT | StdEsReturn               2.87808
2017-06-10 19:21:27.037774 EDT | MaxEsReturn              53.1109
2017-06-10 19:21:27.037936 EDT | MinEsReturn              36.4791
2017-06-10 19:21:27.038090 EDT | AverageDiscountedReturn  34.5262
2017-06-10 19:21:27.038375 EDT | AverageQLoss              0.00253851
2017-06-10 19:21:27.038534 EDT | AveragePolicySurr        -0.575248
2017-06-10 19:21:27.038719 EDT | AverageQ                  0.467743
2017-06-10 19:21:27.038987 EDT | AverageAbsQ               0.471493
2017-06-10 19:21:27.039185 EDT | AverageY                  0.467933
2017-06-10 19:21:27.039336 EDT | AverageAbsY               0.470008
2017-06-10 19:21:27.039676 EDT | AverageAbsQYDiff          0.0292726
2017-06-10 19:21:27.039935 EDT | AverageAction             1
2017-06-10 19:21:27.040196 EDT | PolicyRegParamNorm       12.3156
2017-06-10 19:21:27.040381 EDT | QFunRegParamNorm         11.921
2017-06-10 19:21:27.040651 EDT | -----------------------  -----------
2017-06-10 19:21:27.041114 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #15 | Training started
2017-06-10 19:21:44.780630 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #15 | Training finished
2017-06-10 19:21:44.782128 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #15 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 19:21:44.782517 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #15 | Collecting samples for evaluation
2017-06-10 19:22:00.612105 EDT | -----------------------  ----------
2017-06-10 19:22:00.613094 EDT | Epoch                    15
2017-06-10 19:22:00.613511 EDT | Iteration                15
2017-06-10 19:22:00.613884 EDT | AverageReturn            38.7626
2017-06-10 19:22:00.614287 EDT | StdReturn                 0.914619
2017-06-10 19:22:00.614679 EDT | MaxReturn                40.651
2017-06-10 19:22:00.615059 EDT | MinReturn                36.6317
2017-06-10 19:22:00.615438 EDT | AverageEsReturn          41.5761
2017-06-10 19:22:00.615819 EDT | StdEsReturn               7.36035
2017-06-10 19:22:00.616199 EDT | MaxEsReturn              60.2816
2017-06-10 19:22:00.616581 EDT | MinEsReturn               4.10333
2017-06-10 19:22:00.616954 EDT | AverageDiscountedReturn  34.452
2017-06-10 19:22:00.617332 EDT | AverageQLoss              0.004196
2017-06-10 19:22:00.617726 EDT | AveragePolicySurr        -0.739614
2017-06-10 19:22:00.618113 EDT | AverageQ                  0.623601
2017-06-10 19:22:00.618500 EDT | AverageAbsQ               0.626551
2017-06-10 19:22:00.618875 EDT | AverageY                  0.623846
2017-06-10 19:22:00.619257 EDT | AverageAbsY               0.624966
2017-06-10 19:22:00.619640 EDT | AverageAbsQYDiff          0.0340657
2017-06-10 19:22:00.620018 EDT | AverageAction             1
2017-06-10 19:22:00.620390 EDT | PolicyRegParamNorm       12.3209
2017-06-10 19:22:00.620765 EDT | QFunRegParamNorm         12.2776
2017-06-10 19:22:00.621136 EDT | -----------------------  ----------
2017-06-10 19:22:00.621710 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #16 | Training started
2017-06-10 19:22:17.043284 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #16 | Training finished
2017-06-10 19:22:17.044304 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #16 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 19:22:17.044710 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #16 | Collecting samples for evaluation
2017-06-10 19:22:31.719685 EDT | -----------------------  -----------
2017-06-10 19:22:31.720629 EDT | Epoch                    16
2017-06-10 19:22:31.721018 EDT | Iteration                16
2017-06-10 19:22:31.721387 EDT | AverageReturn            38.7682
2017-06-10 19:22:31.721757 EDT | StdReturn                 0.933933
2017-06-10 19:22:31.722106 EDT | MaxReturn                41.8314
2017-06-10 19:22:31.722766 EDT | MinReturn                36.7078
2017-06-10 19:22:31.723222 EDT | AverageEsReturn          41.1466
2017-06-10 19:22:31.723642 EDT | StdEsReturn               5.49162
2017-06-10 19:22:31.724091 EDT | MaxEsReturn              54.4028
2017-06-10 19:22:31.724667 EDT | MinEsReturn              15.2664
2017-06-10 19:22:31.725112 EDT | AverageDiscountedReturn  34.4538
2017-06-10 19:22:31.725557 EDT | AverageQLoss              0.00502767
2017-06-10 19:22:31.726125 EDT | AveragePolicySurr        -0.892983
2017-06-10 19:22:31.726541 EDT | AverageQ                  0.766494
2017-06-10 19:22:31.726958 EDT | AverageAbsQ               0.768694
2017-06-10 19:22:31.727406 EDT | AverageY                  0.766782
2017-06-10 19:22:31.728010 EDT | AverageAbsY               0.767476
2017-06-10 19:22:31.728472 EDT | AverageAbsQYDiff          0.0376667
2017-06-10 19:22:31.728828 EDT | AverageAction             1
2017-06-10 19:22:31.729179 EDT | PolicyRegParamNorm       12.3218
2017-06-10 19:22:31.729524 EDT | QFunRegParamNorm         12.7462
2017-06-10 19:22:31.729980 EDT | -----------------------  -----------
2017-06-10 19:22:31.730527 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #17 | Training started
2017-06-10 19:22:48.067427 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #17 | Training finished
2017-06-10 19:22:48.068540 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #17 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 19:22:48.069097 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #17 | Collecting samples for evaluation
2017-06-10 19:23:02.401934 EDT | -----------------------  -----------
2017-06-10 19:23:02.403063 EDT | Epoch                    17
2017-06-10 19:23:02.403532 EDT | Iteration                17
2017-06-10 19:23:02.403981 EDT | AverageReturn            38.7298
2017-06-10 19:23:02.404444 EDT | StdReturn                 0.920275
2017-06-10 19:23:02.404895 EDT | MaxReturn                40.7648
2017-06-10 19:23:02.405347 EDT | MinReturn                36.6494
2017-06-10 19:23:02.405789 EDT | AverageEsReturn          39.9952
2017-06-10 19:23:02.406183 EDT | StdEsReturn               6.55459
2017-06-10 19:23:02.406569 EDT | MaxEsReturn              56.2297
2017-06-10 19:23:02.407007 EDT | MinEsReturn               7.35772
2017-06-10 19:23:02.407455 EDT | AverageDiscountedReturn  34.4259
2017-06-10 19:23:02.407900 EDT | AverageQLoss              0.00525714
2017-06-10 19:23:02.408349 EDT | AveragePolicySurr        -1.05217
2017-06-10 19:23:02.408758 EDT | AverageQ                  0.914249
2017-06-10 19:23:02.409178 EDT | AverageAbsQ               0.916337
2017-06-10 19:23:02.410167 EDT | AverageY                  0.914496
2017-06-10 19:23:02.411152 EDT | AverageAbsY               0.915199
2017-06-10 19:23:02.412310 EDT | AverageAbsQYDiff          0.0387847
2017-06-10 19:23:02.413459 EDT | AverageAction             1
2017-06-10 19:23:02.422065 EDT | PolicyRegParamNorm       12.3188
2017-06-10 19:23:02.423559 EDT | QFunRegParamNorm         13.2241
2017-06-10 19:23:02.424673 EDT | -----------------------  -----------
2017-06-10 19:23:02.425990 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #18 | Training started
2017-06-10 19:23:19.825044 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #18 | Training finished
2017-06-10 19:23:19.825994 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #18 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 19:23:19.826302 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #18 | Collecting samples for evaluation
2017-06-10 19:23:34.831448 EDT | -----------------------  -----------
2017-06-10 19:23:34.834667 EDT | Epoch                    18
2017-06-10 19:23:34.835045 EDT | Iteration                18
2017-06-10 19:23:34.835396 EDT | AverageReturn            38.676
2017-06-10 19:23:34.835739 EDT | StdReturn                 0.896267
2017-06-10 19:23:34.836107 EDT | MaxReturn                40.7722
2017-06-10 19:23:34.836473 EDT | MinReturn                36.743
2017-06-10 19:23:34.836817 EDT | AverageEsReturn          41.459
2017-06-10 19:23:34.837155 EDT | StdEsReturn               6.58886
2017-06-10 19:23:34.837498 EDT | MaxEsReturn              59.5455
2017-06-10 19:23:34.840731 EDT | MinEsReturn              11.2598
2017-06-10 19:23:34.841171 EDT | AverageDiscountedReturn  34.3823
2017-06-10 19:23:34.841625 EDT | AverageQLoss              0.00639997
2017-06-10 19:23:34.843383 EDT | AveragePolicySurr        -1.23863
2017-06-10 19:23:34.843847 EDT | AverageQ                  1.06998
2017-06-10 19:23:34.844296 EDT | AverageAbsQ               1.0719
2017-06-10 19:23:34.846097 EDT | AverageY                  1.07024
2017-06-10 19:23:34.846520 EDT | AverageAbsY               1.07075
2017-06-10 19:23:34.846885 EDT | AverageAbsQYDiff          0.0436195
2017-06-10 19:23:34.848597 EDT | AverageAction             1
2017-06-10 19:23:34.849059 EDT | PolicyRegParamNorm       12.3212
2017-06-10 19:23:34.850975 EDT | QFunRegParamNorm         13.8051
2017-06-10 19:23:34.851441 EDT | -----------------------  -----------
2017-06-10 19:23:34.852088 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #19 | Training started
2017-06-10 19:23:50.831831 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #19 | Training finished
2017-06-10 19:23:50.832423 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #19 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 19:23:50.832634 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #19 | Collecting samples for evaluation
2017-06-10 19:24:05.482563 EDT | -----------------------  ------------
2017-06-10 19:24:05.484361 EDT | Epoch                     19
2017-06-10 19:24:05.484752 EDT | Iteration                 19
2017-06-10 19:24:05.485184 EDT | AverageReturn            103.954
2017-06-10 19:24:05.485560 EDT | StdReturn                 10.4322
2017-06-10 19:24:05.486009 EDT | MaxReturn                121.535
2017-06-10 19:24:05.486402 EDT | MinReturn                 82.8325
2017-06-10 19:24:05.486846 EDT | AverageEsReturn           57.0322
2017-06-10 19:24:05.487283 EDT | StdEsReturn               35.1756
2017-06-10 19:24:05.488017 EDT | MaxEsReturn              171.539
2017-06-10 19:24:05.489051 EDT | MinEsReturn               30.9454
2017-06-10 19:24:05.490751 EDT | AverageDiscountedReturn   77.7466
2017-06-10 19:24:05.491612 EDT | AverageQLoss               0.00594861
2017-06-10 19:24:05.492045 EDT | AveragePolicySurr         -1.40154
2017-06-10 19:24:05.493171 EDT | AverageQ                   1.20934
2017-06-10 19:24:05.493633 EDT | AverageAbsQ                1.2112
2017-06-10 19:24:05.494076 EDT | AverageY                   1.20967
2017-06-10 19:24:05.494494 EDT | AverageAbsY                1.21027
2017-06-10 19:24:05.495006 EDT | AverageAbsQYDiff           0.0448197
2017-06-10 19:24:05.495424 EDT | AverageAction              0.981516
2017-06-10 19:24:05.496022 EDT | PolicyRegParamNorm        13.5449
2017-06-10 19:24:05.496443 EDT | QFunRegParamNorm          14.2693
2017-06-10 19:24:05.497079 EDT | -----------------------  ------------
2017-06-10 19:24:05.497742 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #20 | Training started
2017-06-10 19:24:21.387998 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #20 | Training finished
2017-06-10 19:24:21.388913 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #20 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 19:24:21.389280 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #20 | Collecting samples for evaluation
2017-06-10 19:24:35.677312 EDT | -----------------------  ------------
2017-06-10 19:24:35.678236 EDT | Epoch                     20
2017-06-10 19:24:35.678519 EDT | Iteration                 20
2017-06-10 19:24:35.678770 EDT | AverageReturn            171.927
2017-06-10 19:24:35.679016 EDT | StdReturn                  1.93791
2017-06-10 19:24:35.679281 EDT | MaxReturn                176.09
2017-06-10 19:24:35.679525 EDT | MinReturn                167.422
2017-06-10 19:24:35.679813 EDT | AverageEsReturn           71.7328
2017-06-10 19:24:35.680105 EDT | StdEsReturn               33.1081
2017-06-10 19:24:35.680409 EDT | MaxEsReturn              168.592
2017-06-10 19:24:35.680972 EDT | MinEsReturn               22.7158
2017-06-10 19:24:35.681347 EDT | AverageDiscountedReturn  111.05
2017-06-10 19:24:35.681787 EDT | AverageQLoss               0.00860624
2017-06-10 19:24:35.682131 EDT | AveragePolicySurr         -1.60934
2017-06-10 19:24:35.682580 EDT | AverageQ                   1.36706
2017-06-10 19:24:35.683235 EDT | AverageAbsQ                1.36907
2017-06-10 19:24:35.684084 EDT | AverageY                   1.36754
2017-06-10 19:24:35.684470 EDT | AverageAbsY                1.36817
2017-06-10 19:24:35.684847 EDT | AverageAbsQYDiff           0.0516997
2017-06-10 19:24:35.685315 EDT | AverageAction              0.987194
2017-06-10 19:24:35.686600 EDT | PolicyRegParamNorm        14.273
2017-06-10 19:24:35.687844 EDT | QFunRegParamNorm          14.8108
2017-06-10 19:24:35.688274 EDT | -----------------------  ------------
2017-06-10 19:24:35.693187 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #21 | Training started
2017-06-10 19:24:51.959974 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #21 | Training finished
2017-06-10 19:24:51.960877 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #21 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 19:24:51.961278 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #21 | Collecting samples for evaluation
2017-06-10 19:25:06.891438 EDT | -----------------------  ------------
2017-06-10 19:25:06.892420 EDT | Epoch                     21
2017-06-10 19:25:06.892787 EDT | Iteration                 21
2017-06-10 19:25:06.893125 EDT | AverageReturn            170.092
2017-06-10 19:25:06.893469 EDT | StdReturn                  1.49243
2017-06-10 19:25:06.893810 EDT | MaxReturn                174.15
2017-06-10 19:25:06.894142 EDT | MinReturn                166.788
2017-06-10 19:25:06.894472 EDT | AverageEsReturn          135.483
2017-06-10 19:25:06.894800 EDT | StdEsReturn               41.4845
2017-06-10 19:25:06.895125 EDT | MaxEsReturn              193.598
2017-06-10 19:25:06.895474 EDT | MinEsReturn               53.938
2017-06-10 19:25:06.895859 EDT | AverageDiscountedReturn  110.52
2017-06-10 19:25:06.896240 EDT | AverageQLoss               0.00983436
2017-06-10 19:25:06.896600 EDT | AveragePolicySurr         -1.76729
2017-06-10 19:25:06.896975 EDT | AverageQ                   1.53583
2017-06-10 19:25:06.897361 EDT | AverageAbsQ                1.53748
2017-06-10 19:25:06.897752 EDT | AverageY                   1.53639
2017-06-10 19:25:06.898136 EDT | AverageAbsY                1.53685
2017-06-10 19:25:06.898529 EDT | AverageAbsQYDiff           0.0543418
2017-06-10 19:25:06.898919 EDT | AverageAction              0.856173
2017-06-10 19:25:06.899300 EDT | PolicyRegParamNorm        15.5013
2017-06-10 19:25:06.899680 EDT | QFunRegParamNorm          15.2853
2017-06-10 19:25:06.900064 EDT | -----------------------  ------------
2017-06-10 19:25:06.900544 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #22 | Training started
2017-06-10 19:25:23.025201 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #22 | Training finished
2017-06-10 19:25:23.027441 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #22 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 19:25:23.027659 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #22 | Collecting samples for evaluation
2017-06-10 19:25:38.074460 EDT | -----------------------  -----------
2017-06-10 19:25:38.075558 EDT | Epoch                     22
2017-06-10 19:25:38.075887 EDT | Iteration                 22
2017-06-10 19:25:38.076208 EDT | AverageReturn            172.88
2017-06-10 19:25:38.076536 EDT | StdReturn                  2.27074
2017-06-10 19:25:38.076866 EDT | MaxReturn                177.816
2017-06-10 19:25:38.077176 EDT | MinReturn                167.983
2017-06-10 19:25:38.077485 EDT | AverageEsReturn          129.045
2017-06-10 19:25:38.077812 EDT | StdEsReturn               58.8277
2017-06-10 19:25:38.078137 EDT | MaxEsReturn              194.751
2017-06-10 19:25:38.078428 EDT | MinEsReturn               21.1851
2017-06-10 19:25:38.078632 EDT | AverageDiscountedReturn  111.474
2017-06-10 19:25:38.078950 EDT | AverageQLoss               0.0127648
2017-06-10 19:25:38.079276 EDT | AveragePolicySurr         -1.90533
2017-06-10 19:25:38.079568 EDT | AverageQ                   1.68232
2017-06-10 19:25:38.079818 EDT | AverageAbsQ                1.68426
2017-06-10 19:25:38.080235 EDT | AverageY                   1.6829
2017-06-10 19:25:38.080487 EDT | AverageAbsY                1.68344
2017-06-10 19:25:38.080755 EDT | AverageAbsQYDiff           0.060271
2017-06-10 19:25:38.081083 EDT | AverageAction              0.825433
2017-06-10 19:25:38.081383 EDT | PolicyRegParamNorm        16.3372
2017-06-10 19:25:38.081662 EDT | QFunRegParamNorm          15.7602
2017-06-10 19:25:38.081955 EDT | -----------------------  -----------
2017-06-10 19:25:38.082533 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #23 | Training started
2017-06-10 19:25:55.416522 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #23 | Training finished
2017-06-10 19:25:55.417282 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #23 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 19:25:55.418606 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #23 | Collecting samples for evaluation
2017-06-10 19:26:08.955626 EDT | -----------------------  -----------
2017-06-10 19:26:08.957037 EDT | Epoch                     23
2017-06-10 19:26:08.957383 EDT | Iteration                 23
2017-06-10 19:26:08.957723 EDT | AverageReturn            171.324
2017-06-10 19:26:08.958064 EDT | StdReturn                  1.06396
2017-06-10 19:26:08.958385 EDT | MaxReturn                174.534
2017-06-10 19:26:08.958705 EDT | MinReturn                168.248
2017-06-10 19:26:08.959012 EDT | AverageEsReturn          151.982
2017-06-10 19:26:08.959182 EDT | StdEsReturn               37.3281
2017-06-10 19:26:08.959448 EDT | MaxEsReturn              185.997
2017-06-10 19:26:08.959773 EDT | MinEsReturn               62.4233
2017-06-10 19:26:08.960073 EDT | AverageDiscountedReturn  110.962
2017-06-10 19:26:08.960389 EDT | AverageQLoss               0.0154056
2017-06-10 19:26:08.960719 EDT | AveragePolicySurr         -2.03875
2017-06-10 19:26:08.961028 EDT | AverageQ                   1.81272
2017-06-10 19:26:08.961342 EDT | AverageAbsQ                1.81453
2017-06-10 19:26:08.961643 EDT | AverageY                   1.81334
2017-06-10 19:26:08.962242 EDT | AverageAbsY                1.81395
2017-06-10 19:26:08.962584 EDT | AverageAbsQYDiff           0.0634113
2017-06-10 19:26:08.962906 EDT | AverageAction              0.787977
2017-06-10 19:26:08.963983 EDT | PolicyRegParamNorm        16.8913
2017-06-10 19:26:08.964365 EDT | QFunRegParamNorm          16.2586
2017-06-10 19:26:08.964677 EDT | -----------------------  -----------
2017-06-10 19:26:08.964950 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #24 | Training started
2017-06-10 19:26:25.337852 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #24 | Training finished
2017-06-10 19:26:25.338845 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #24 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 19:26:25.339256 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #24 | Collecting samples for evaluation
2017-06-10 19:26:39.510640 EDT | -----------------------  ----------
2017-06-10 19:26:39.511891 EDT | Epoch                     24
2017-06-10 19:26:39.512181 EDT | Iteration                 24
2017-06-10 19:26:39.512376 EDT | AverageReturn            170.626
2017-06-10 19:26:39.512588 EDT | StdReturn                  1.10645
2017-06-10 19:26:39.512750 EDT | MaxReturn                173.462
2017-06-10 19:26:39.512908 EDT | MinReturn                167.833
2017-06-10 19:26:39.513100 EDT | AverageEsReturn          163.755
2017-06-10 19:26:39.513280 EDT | StdEsReturn               15.6042
2017-06-10 19:26:39.513438 EDT | MaxEsReturn              182.963
2017-06-10 19:26:39.513595 EDT | MinEsReturn              131.545
2017-06-10 19:26:39.513804 EDT | AverageDiscountedReturn  110.669
2017-06-10 19:26:39.513970 EDT | AverageQLoss               0.016663
2017-06-10 19:26:39.514188 EDT | AveragePolicySurr         -2.19442
2017-06-10 19:26:39.514342 EDT | AverageQ                   1.96017
2017-06-10 19:26:39.514491 EDT | AverageAbsQ                1.96197
2017-06-10 19:26:39.514841 EDT | AverageY                   1.96092
2017-06-10 19:26:39.515023 EDT | AverageAbsY                1.96151
2017-06-10 19:26:39.515430 EDT | AverageAbsQYDiff           0.064189
2017-06-10 19:26:39.515812 EDT | AverageAction              0.829925
2017-06-10 19:26:39.516000 EDT | PolicyRegParamNorm        17.5878
2017-06-10 19:26:39.516184 EDT | QFunRegParamNorm          16.7756
2017-06-10 19:26:39.516399 EDT | -----------------------  ----------
2017-06-10 19:26:39.516711 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #25 | Training started
2017-06-10 19:26:55.134972 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #25 | Training finished
2017-06-10 19:26:55.135838 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #25 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 19:26:55.136322 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #25 | Collecting samples for evaluation
2017-06-10 19:27:09.400810 EDT | -----------------------  -----------
2017-06-10 19:27:09.411087 EDT | Epoch                     25
2017-06-10 19:27:09.411528 EDT | Iteration                 25
2017-06-10 19:27:09.411858 EDT | AverageReturn            170.384
2017-06-10 19:27:09.412187 EDT | StdReturn                  1.21333
2017-06-10 19:27:09.412511 EDT | MaxReturn                173.3
2017-06-10 19:27:09.412837 EDT | MinReturn                167.608
2017-06-10 19:27:09.413105 EDT | AverageEsReturn          158.761
2017-06-10 19:27:09.413268 EDT | StdEsReturn               51.2436
2017-06-10 19:27:09.413425 EDT | MaxEsReturn              210.562
2017-06-10 19:27:09.413589 EDT | MinEsReturn                4.82563
2017-06-10 19:27:09.413766 EDT | AverageDiscountedReturn  110.531
2017-06-10 19:27:09.413925 EDT | AverageQLoss               0.0198534
2017-06-10 19:27:09.414164 EDT | AveragePolicySurr         -2.31601
2017-06-10 19:27:09.414469 EDT | AverageQ                   2.08607
2017-06-10 19:27:09.415244 EDT | AverageAbsQ                2.08804
2017-06-10 19:27:09.415745 EDT | AverageY                   2.08667
2017-06-10 19:27:09.416625 EDT | AverageAbsY                2.08729
2017-06-10 19:27:09.416830 EDT | AverageAbsQYDiff           0.0689504
2017-06-10 19:27:09.416991 EDT | AverageAction              0.811865
2017-06-10 19:27:09.417263 EDT | PolicyRegParamNorm        18.2083
2017-06-10 19:27:09.417759 EDT | QFunRegParamNorm          17.3113
2017-06-10 19:27:09.418019 EDT | -----------------------  -----------
2017-06-10 19:27:09.418366 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #26 | Training started
2017-06-10 19:27:25.099562 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #26 | Training finished
2017-06-10 19:27:25.100291 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #26 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 19:27:25.100475 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #26 | Collecting samples for evaluation
2017-06-10 19:27:37.067804 EDT | -----------------------  -----------
2017-06-10 19:27:37.068679 EDT | Epoch                     26
2017-06-10 19:27:37.068859 EDT | Iteration                 26
2017-06-10 19:27:37.069020 EDT | AverageReturn            169.641
2017-06-10 19:27:37.069229 EDT | StdReturn                  3.24949
2017-06-10 19:27:37.069405 EDT | MaxReturn                175.27
2017-06-10 19:27:37.069798 EDT | MinReturn                153.02
2017-06-10 19:27:37.070142 EDT | AverageEsReturn          147.083
2017-06-10 19:27:37.070501 EDT | StdEsReturn               47.2152
2017-06-10 19:27:37.070841 EDT | MaxEsReturn              202.811
2017-06-10 19:27:37.071025 EDT | MinEsReturn               32.9508
2017-06-10 19:27:37.071217 EDT | AverageDiscountedReturn  109.746
2017-06-10 19:27:37.071490 EDT | AverageQLoss               0.0214084
2017-06-10 19:27:37.071784 EDT | AveragePolicySurr         -2.45901
2017-06-10 19:27:37.072070 EDT | AverageQ                   2.22067
2017-06-10 19:27:37.072331 EDT | AverageAbsQ                2.22267
2017-06-10 19:27:37.072502 EDT | AverageY                   2.22129
2017-06-10 19:27:37.072784 EDT | AverageAbsY                2.22194
2017-06-10 19:27:37.073034 EDT | AverageAbsQYDiff           0.0684738
2017-06-10 19:27:37.073303 EDT | AverageAction              0.882037
2017-06-10 19:27:37.073518 EDT | PolicyRegParamNorm        18.9892
2017-06-10 19:27:37.073759 EDT | QFunRegParamNorm          17.7266
2017-06-10 19:27:37.074004 EDT | -----------------------  -----------
2017-06-10 19:27:37.074354 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #27 | Training started
2017-06-10 19:27:52.438333 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #27 | Training finished
2017-06-10 19:27:52.439256 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #27 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 19:27:52.439639 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #27 | Collecting samples for evaluation
2017-06-10 19:28:05.909104 EDT | -----------------------  -----------
2017-06-10 19:28:05.909957 EDT | Epoch                     27
2017-06-10 19:28:05.910202 EDT | Iteration                 27
2017-06-10 19:28:05.910478 EDT | AverageReturn            350.498
2017-06-10 19:28:05.910647 EDT | StdReturn                  2.9985
2017-06-10 19:28:05.910923 EDT | MaxReturn                356.113
2017-06-10 19:28:05.911087 EDT | MinReturn                343.498
2017-06-10 19:28:05.911319 EDT | AverageEsReturn          151.482
2017-06-10 19:28:05.911544 EDT | StdEsReturn               56.7629
2017-06-10 19:28:05.911889 EDT | MaxEsReturn              207.194
2017-06-10 19:28:05.912067 EDT | MinEsReturn               19.2354
2017-06-10 19:28:05.912348 EDT | AverageDiscountedReturn  153.628
2017-06-10 19:28:05.912545 EDT | AverageQLoss               0.0244416
2017-06-10 19:28:05.912756 EDT | AveragePolicySurr         -2.60537
2017-06-10 19:28:05.912917 EDT | AverageQ                   2.36834
2017-06-10 19:28:05.913072 EDT | AverageAbsQ                2.37079
2017-06-10 19:28:05.913256 EDT | AverageY                   2.36912
2017-06-10 19:28:05.913420 EDT | AverageAbsY                2.36986
2017-06-10 19:28:05.913598 EDT | AverageAbsQYDiff           0.0766426
2017-06-10 19:28:05.913785 EDT | AverageAction              0.606934
2017-06-10 19:28:05.913970 EDT | PolicyRegParamNorm        19.7286
2017-06-10 19:28:05.914216 EDT | QFunRegParamNorm          18.2076
2017-06-10 19:28:05.914493 EDT | -----------------------  -----------
2017-06-10 19:28:05.914900 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #28 | Training started
2017-06-10 19:28:20.119041 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #28 | Training finished
2017-06-10 19:28:20.120160 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #28 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 19:28:20.120626 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #28 | Collecting samples for evaluation
2017-06-10 19:28:33.069673 EDT | -----------------------  -----------
2017-06-10 19:28:33.072934 EDT | Epoch                     28
2017-06-10 19:28:33.073357 EDT | Iteration                 28
2017-06-10 19:28:33.074584 EDT | AverageReturn            307.378
2017-06-10 19:28:33.074951 EDT | StdReturn                 48.7353
2017-06-10 19:28:33.075297 EDT | MaxReturn                353.262
2017-06-10 19:28:33.075643 EDT | MinReturn                137.954
2017-06-10 19:28:33.075984 EDT | AverageEsReturn          228.903
2017-06-10 19:28:33.076321 EDT | StdEsReturn              106.985
2017-06-10 19:28:33.076662 EDT | MaxEsReturn              357.929
2017-06-10 19:28:33.077026 EDT | MinEsReturn               74.2719
2017-06-10 19:28:33.077363 EDT | AverageDiscountedReturn  151.509
2017-06-10 19:28:33.077735 EDT | AverageQLoss               0.0234216
2017-06-10 19:28:33.078077 EDT | AveragePolicySurr         -2.77605
2017-06-10 19:28:33.078419 EDT | AverageQ                   2.51405
2017-06-10 19:28:33.078759 EDT | AverageAbsQ                2.51627
2017-06-10 19:28:33.079096 EDT | AverageY                   2.51481
2017-06-10 19:28:33.079463 EDT | AverageAbsY                2.51561
2017-06-10 19:28:33.079808 EDT | AverageAbsQYDiff           0.0749982
2017-06-10 19:28:33.080148 EDT | AverageAction              0.773482
2017-06-10 19:28:33.080486 EDT | PolicyRegParamNorm        20.2914
2017-06-10 19:28:33.080827 EDT | QFunRegParamNorm          18.6557
2017-06-10 19:28:33.081170 EDT | -----------------------  -----------
2017-06-10 19:28:33.081703 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #29 | Training started
2017-06-10 19:28:47.428193 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #29 | Training finished
2017-06-10 19:28:47.429182 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #29 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 19:28:47.429591 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #29 | Collecting samples for evaluation
2017-06-10 19:29:00.043277 EDT | -----------------------  -----------
2017-06-10 19:29:00.044045 EDT | Epoch                     29
2017-06-10 19:29:00.044227 EDT | Iteration                 29
2017-06-10 19:29:00.044479 EDT | AverageReturn            286.46
2017-06-10 19:29:00.044734 EDT | StdReturn                 15.8864
2017-06-10 19:29:00.044960 EDT | MaxReturn                312.403
2017-06-10 19:29:00.045115 EDT | MinReturn                253.569
2017-06-10 19:29:00.045265 EDT | AverageEsReturn          240.592
2017-06-10 19:29:00.045414 EDT | StdEsReturn               46.7511
2017-06-10 19:29:00.045562 EDT | MaxEsReturn              343.366
2017-06-10 19:29:00.045733 EDT | MinEsReturn              179.574
2017-06-10 19:29:00.045891 EDT | AverageDiscountedReturn  133.739
2017-06-10 19:29:00.046046 EDT | AverageQLoss               0.029973
2017-06-10 19:29:00.046200 EDT | AveragePolicySurr         -2.94246
2017-06-10 19:29:00.046361 EDT | AverageQ                   2.69485
2017-06-10 19:29:00.046564 EDT | AverageAbsQ                2.69758
2017-06-10 19:29:00.047184 EDT | AverageY                   2.6958
2017-06-10 19:29:00.047522 EDT | AverageAbsY                2.69653
2017-06-10 19:29:00.048043 EDT | AverageAbsQYDiff           0.0860489
2017-06-10 19:29:00.048471 EDT | AverageAction              0.708034
2017-06-10 19:29:00.051788 EDT | PolicyRegParamNorm        20.8742
2017-06-10 19:29:00.052012 EDT | QFunRegParamNorm          19.1117
2017-06-10 19:29:00.052905 EDT | -----------------------  -----------
2017-06-10 19:29:00.053231 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #30 | Training started
2017-06-10 19:29:14.142793 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #30 | Training finished
2017-06-10 19:29:14.143783 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #30 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 19:29:14.144333 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #30 | Collecting samples for evaluation
2017-06-10 19:29:26.648870 EDT | -----------------------  ------------
2017-06-10 19:29:26.649190 EDT | Epoch                      30
2017-06-10 19:29:26.649360 EDT | Iteration                  30
2017-06-10 19:29:26.649527 EDT | AverageReturn            1200.43
2017-06-10 19:29:26.649686 EDT | StdReturn                 394.875
2017-06-10 19:29:26.649934 EDT | MaxReturn                1562.53
2017-06-10 19:29:26.650227 EDT | MinReturn                 381.579
2017-06-10 19:29:26.650595 EDT | AverageEsReturn           214.2
2017-06-10 19:29:26.650852 EDT | StdEsReturn               115.387
2017-06-10 19:29:26.651010 EDT | MaxEsReturn               370.5
2017-06-10 19:29:26.651306 EDT | MinEsReturn                53.4903
2017-06-10 19:29:26.651557 EDT | AverageDiscountedReturn   154.476
2017-06-10 19:29:26.651832 EDT | AverageQLoss                0.0321136
2017-06-10 19:29:26.652050 EDT | AveragePolicySurr          -3.12085
2017-06-10 19:29:26.652210 EDT | AverageQ                    2.86346
2017-06-10 19:29:26.652598 EDT | AverageAbsQ                 2.86631
2017-06-10 19:29:26.652934 EDT | AverageY                    2.86422
2017-06-10 19:29:26.653202 EDT | AverageAbsY                 2.86495
2017-06-10 19:29:26.653385 EDT | AverageAbsQYDiff            0.0882135
2017-06-10 19:29:26.653562 EDT | AverageAction               0.605138
2017-06-10 19:29:26.653789 EDT | PolicyRegParamNorm         21.3933
2017-06-10 19:29:26.654492 EDT | QFunRegParamNorm           19.5843
2017-06-10 19:29:26.654688 EDT | -----------------------  ------------
2017-06-10 19:29:26.655002 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #31 | Training started
2017-06-10 19:29:41.169596 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #31 | Training finished
2017-06-10 19:29:41.170001 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #31 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 19:29:41.170525 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #31 | Collecting samples for evaluation
2017-06-10 19:29:53.076129 EDT | -----------------------  -----------
2017-06-10 19:29:53.077131 EDT | Epoch                     31
2017-06-10 19:29:53.077381 EDT | Iteration                 31
2017-06-10 19:29:53.078185 EDT | AverageReturn            344.746
2017-06-10 19:29:53.078694 EDT | StdReturn                 12.0118
2017-06-10 19:29:53.078880 EDT | MaxReturn                364.624
2017-06-10 19:29:53.079062 EDT | MinReturn                319.618
2017-06-10 19:29:53.079272 EDT | AverageEsReturn          247.959
2017-06-10 19:29:53.079458 EDT | StdEsReturn               83.3919
2017-06-10 19:29:53.079682 EDT | MaxEsReturn              368.114
2017-06-10 19:29:53.079865 EDT | MinEsReturn              115.549
2017-06-10 19:29:53.080044 EDT | AverageDiscountedReturn  155.35
2017-06-10 19:29:53.080229 EDT | AverageQLoss               0.0344659
2017-06-10 19:29:53.080406 EDT | AveragePolicySurr         -3.29176
2017-06-10 19:29:53.080585 EDT | AverageQ                   3.03126
2017-06-10 19:29:53.080764 EDT | AverageAbsQ                3.03408
2017-06-10 19:29:53.080941 EDT | AverageY                   3.03218
2017-06-10 19:29:53.081118 EDT | AverageAbsY                3.03281
2017-06-10 19:29:53.081304 EDT | AverageAbsQYDiff           0.0911258
2017-06-10 19:29:53.081483 EDT | AverageAction              0.723224
2017-06-10 19:29:53.081660 EDT | PolicyRegParamNorm        21.9014
2017-06-10 19:29:53.081876 EDT | QFunRegParamNorm          20.1198
2017-06-10 19:29:53.082055 EDT | -----------------------  -----------
2017-06-10 19:29:53.082410 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #32 | Training started
2017-06-10 19:30:07.827050 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #32 | Training finished
2017-06-10 19:30:07.828045 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #32 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 19:30:07.828517 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #32 | Collecting samples for evaluation
2017-06-10 19:30:20.123375 EDT | -----------------------  -----------
2017-06-10 19:30:20.124096 EDT | Epoch                     32
2017-06-10 19:30:20.124347 EDT | Iteration                 32
2017-06-10 19:30:20.124605 EDT | AverageReturn            291.523
2017-06-10 19:30:20.124810 EDT | StdReturn                109.783
2017-06-10 19:30:20.124994 EDT | MaxReturn                467.017
2017-06-10 19:30:20.125200 EDT | MinReturn                145.777
2017-06-10 19:30:20.125382 EDT | AverageEsReturn          232.826
2017-06-10 19:30:20.125561 EDT | StdEsReturn              112.146
2017-06-10 19:30:20.125760 EDT | MaxEsReturn              398.854
2017-06-10 19:30:20.125984 EDT | MinEsReturn               86.4916
2017-06-10 19:30:20.126167 EDT | AverageDiscountedReturn  125.274
2017-06-10 19:30:20.126340 EDT | AverageQLoss               0.043507
2017-06-10 19:30:20.126504 EDT | AveragePolicySurr         -3.46569
2017-06-10 19:30:20.126694 EDT | AverageQ                   3.21681
2017-06-10 19:30:20.126865 EDT | AverageAbsQ                3.21975
2017-06-10 19:30:20.127028 EDT | AverageY                   3.21756
2017-06-10 19:30:20.127229 EDT | AverageAbsY                3.21826
2017-06-10 19:30:20.127407 EDT | AverageAbsQYDiff           0.0975915
2017-06-10 19:30:20.127587 EDT | AverageAction              0.696229
2017-06-10 19:30:20.127793 EDT | PolicyRegParamNorm        22.4334
2017-06-10 19:30:20.127952 EDT | QFunRegParamNorm          20.6057
2017-06-10 19:30:20.128206 EDT | -----------------------  -----------
2017-06-10 19:30:20.128614 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #33 | Training started
2017-06-10 19:30:33.758402 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #33 | Training finished
2017-06-10 19:30:33.759250 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #33 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 19:30:33.759619 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #33 | Collecting samples for evaluation
2017-06-10 19:30:45.969283 EDT | -----------------------  -----------
2017-06-10 19:30:45.970604 EDT | Epoch                     33
2017-06-10 19:30:45.970960 EDT | Iteration                 33
2017-06-10 19:30:45.971226 EDT | AverageReturn            366.64
2017-06-10 19:30:45.971470 EDT | StdReturn                 37.0478
2017-06-10 19:30:45.971732 EDT | MaxReturn                443.149
2017-06-10 19:30:45.972011 EDT | MinReturn                268.499
2017-06-10 19:30:45.972290 EDT | AverageEsReturn          208.701
2017-06-10 19:30:45.972569 EDT | StdEsReturn              128.017
2017-06-10 19:30:45.972872 EDT | MaxEsReturn              445.468
2017-06-10 19:30:45.973167 EDT | MinEsReturn               53.8616
2017-06-10 19:30:45.973455 EDT | AverageDiscountedReturn  154.366
2017-06-10 19:30:45.973615 EDT | AverageQLoss               0.0541121
2017-06-10 19:30:45.973801 EDT | AveragePolicySurr         -3.62852
2017-06-10 19:30:45.974019 EDT | AverageQ                   3.36517
2017-06-10 19:30:45.974179 EDT | AverageAbsQ                3.36823
2017-06-10 19:30:45.974329 EDT | AverageY                   3.36626
2017-06-10 19:30:45.974479 EDT | AverageAbsY                3.36718
2017-06-10 19:30:45.974627 EDT | AverageAbsQYDiff           0.106993
2017-06-10 19:30:45.974775 EDT | AverageAction              0.732472
2017-06-10 19:30:45.974922 EDT | PolicyRegParamNorm        22.9072
2017-06-10 19:30:45.975077 EDT | QFunRegParamNorm          21.0524
2017-06-10 19:30:45.975340 EDT | -----------------------  -----------
2017-06-10 19:30:45.975720 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #34 | Training started
2017-06-10 19:31:00.230332 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #34 | Training finished
2017-06-10 19:31:00.231117 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #34 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 19:31:00.231500 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #34 | Collecting samples for evaluation
2017-06-10 19:31:11.623039 EDT | -----------------------  -----------
2017-06-10 19:31:11.623528 EDT | Epoch                      34
2017-06-10 19:31:11.623869 EDT | Iteration                  34
2017-06-10 19:31:11.624068 EDT | AverageReturn             328.006
2017-06-10 19:31:11.624430 EDT | StdReturn                 403.529
2017-06-10 19:31:11.624738 EDT | MaxReturn                1556.84
2017-06-10 19:31:11.625066 EDT | MinReturn                 129.902
2017-06-10 19:31:11.625410 EDT | AverageEsReturn           356.842
2017-06-10 19:31:11.625753 EDT | StdEsReturn               122.489
2017-06-10 19:31:11.626075 EDT | MaxEsReturn               519.738
2017-06-10 19:31:11.626426 EDT | MinEsReturn               167.284
2017-06-10 19:31:11.626742 EDT | AverageDiscountedReturn   109.108
2017-06-10 19:31:11.626998 EDT | AverageQLoss                0.047479
2017-06-10 19:31:11.627314 EDT | AveragePolicySurr          -3.81494
2017-06-10 19:31:11.627626 EDT | AverageQ                    3.54609
2017-06-10 19:31:11.628542 EDT | AverageAbsQ                 3.54961
2017-06-10 19:31:11.628974 EDT | AverageY                    3.54718
2017-06-10 19:31:11.629136 EDT | AverageAbsY                 3.54818
2017-06-10 19:31:11.629297 EDT | AverageAbsQYDiff            0.104018
2017-06-10 19:31:11.629581 EDT | AverageAction               0.737172
2017-06-10 19:31:11.631240 EDT | PolicyRegParamNorm         23.3476
2017-06-10 19:31:11.632073 EDT | QFunRegParamNorm           21.447
2017-06-10 19:31:11.632336 EDT | -----------------------  -----------
2017-06-10 19:31:11.633636 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #35 | Training started
2017-06-10 19:31:26.061855 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #35 | Training finished
2017-06-10 19:31:26.062744 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #35 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 19:31:26.063047 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #35 | Collecting samples for evaluation
2017-06-10 19:31:37.522994 EDT | -----------------------  ------------
2017-06-10 19:31:37.523982 EDT | Epoch                      35
2017-06-10 19:31:37.524235 EDT | Iteration                  35
2017-06-10 19:31:37.524440 EDT | AverageReturn             729.506
2017-06-10 19:31:37.524743 EDT | StdReturn                 326.605
2017-06-10 19:31:37.525150 EDT | MaxReturn                1520.84
2017-06-10 19:31:37.525478 EDT | MinReturn                 338.389
2017-06-10 19:31:37.526304 EDT | AverageEsReturn           222.303
2017-06-10 19:31:37.526670 EDT | StdEsReturn               112.665
2017-06-10 19:31:37.527243 EDT | MaxEsReturn               377.667
2017-06-10 19:31:37.527739 EDT | MinEsReturn                36.1915
2017-06-10 19:31:37.528113 EDT | AverageDiscountedReturn   169.35
2017-06-10 19:31:37.528489 EDT | AverageQLoss                0.0551003
2017-06-10 19:31:37.528991 EDT | AveragePolicySurr          -4.02392
2017-06-10 19:31:37.529346 EDT | AverageQ                    3.74395
2017-06-10 19:31:37.529750 EDT | AverageAbsQ                 3.74755
2017-06-10 19:31:37.530517 EDT | AverageY                    3.74494
2017-06-10 19:31:37.531046 EDT | AverageAbsY                 3.74616
2017-06-10 19:31:37.531517 EDT | AverageAbsQYDiff            0.109451
2017-06-10 19:31:37.531720 EDT | AverageAction               0.767659
2017-06-10 19:31:37.531995 EDT | PolicyRegParamNorm         23.8349
2017-06-10 19:31:37.532204 EDT | QFunRegParamNorm           21.8572
2017-06-10 19:31:37.532399 EDT | -----------------------  ------------
2017-06-10 19:31:37.532905 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #36 | Training started
2017-06-10 19:31:51.742860 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #36 | Training finished
2017-06-10 19:31:51.744194 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #36 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 19:31:51.744608 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #36 | Collecting samples for evaluation
2017-06-10 19:32:04.478026 EDT | -----------------------  -----------
2017-06-10 19:32:04.479014 EDT | Epoch                     36
2017-06-10 19:32:04.479384 EDT | Iteration                 36
2017-06-10 19:32:04.479731 EDT | AverageReturn            335.211
2017-06-10 19:32:04.480078 EDT | StdReturn                 77.5019
2017-06-10 19:32:04.480425 EDT | MaxReturn                527.209
2017-06-10 19:32:04.480767 EDT | MinReturn                158.16
2017-06-10 19:32:04.481107 EDT | AverageEsReturn          215.283
2017-06-10 19:32:04.481449 EDT | StdEsReturn              131.161
2017-06-10 19:32:04.481920 EDT | MaxEsReturn              506.028
2017-06-10 19:32:04.482363 EDT | MinEsReturn               44.4197
2017-06-10 19:32:04.482807 EDT | AverageDiscountedReturn  144.46
2017-06-10 19:32:04.483251 EDT | AverageQLoss               0.0658986
2017-06-10 19:32:04.483694 EDT | AveragePolicySurr         -4.18699
2017-06-10 19:32:04.484134 EDT | AverageQ                   3.90104
2017-06-10 19:32:04.484578 EDT | AverageAbsQ                3.90445
2017-06-10 19:32:04.485072 EDT | AverageY                   3.90168
2017-06-10 19:32:04.485514 EDT | AverageAbsY                3.90251
2017-06-10 19:32:04.485970 EDT | AverageAbsQYDiff           0.117312
2017-06-10 19:32:04.486409 EDT | AverageAction              0.767448
2017-06-10 19:32:04.486848 EDT | PolicyRegParamNorm        24.2026
2017-06-10 19:32:04.487288 EDT | QFunRegParamNorm          22.3092
2017-06-10 19:32:04.487726 EDT | -----------------------  -----------
2017-06-10 19:32:04.488351 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #37 | Training started
2017-06-10 19:32:18.325919 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #37 | Training finished
2017-06-10 19:32:18.326779 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #37 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 19:32:18.327152 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #37 | Collecting samples for evaluation
2017-06-10 19:32:31.010256 EDT | -----------------------  -----------
2017-06-10 19:32:31.011148 EDT | Epoch                     37
2017-06-10 19:32:31.011379 EDT | Iteration                 37
2017-06-10 19:32:31.011704 EDT | AverageReturn            314.712
2017-06-10 19:32:31.011958 EDT | StdReturn                 48.2263
2017-06-10 19:32:31.012174 EDT | MaxReturn                359.693
2017-06-10 19:32:31.012493 EDT | MinReturn                155.678
2017-06-10 19:32:31.012732 EDT | AverageEsReturn          185.752
2017-06-10 19:32:31.012921 EDT | StdEsReturn              115.714
2017-06-10 19:32:31.013099 EDT | MaxEsReturn              346.986
2017-06-10 19:32:31.013293 EDT | MinEsReturn                4.53473
2017-06-10 19:32:31.013479 EDT | AverageDiscountedReturn  142.049
2017-06-10 19:32:31.013734 EDT | AverageQLoss               0.0684391
2017-06-10 19:32:31.014042 EDT | AveragePolicySurr         -4.37024
2017-06-10 19:32:31.014243 EDT | AverageQ                   4.08521
2017-06-10 19:32:31.014415 EDT | AverageAbsQ                4.08863
2017-06-10 19:32:31.014585 EDT | AverageY                   4.08661
2017-06-10 19:32:31.014754 EDT | AverageAbsY                4.0874
2017-06-10 19:32:31.014922 EDT | AverageAbsQYDiff           0.117564
2017-06-10 19:32:31.015088 EDT | AverageAction              0.713515
2017-06-10 19:32:31.015263 EDT | PolicyRegParamNorm        24.522
2017-06-10 19:32:31.015662 EDT | QFunRegParamNorm          22.7117
2017-06-10 19:32:31.015850 EDT | -----------------------  -----------
2017-06-10 19:32:31.022111 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #38 | Training started
2017-06-10 19:32:45.433179 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #38 | Training finished
2017-06-10 19:32:45.434058 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #38 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 19:32:45.434318 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #38 | Collecting samples for evaluation
2017-06-10 19:32:58.201311 EDT | -----------------------  -----------
2017-06-10 19:32:58.202403 EDT | Epoch                     38
2017-06-10 19:32:58.202876 EDT | Iteration                 38
2017-06-10 19:32:58.203326 EDT | AverageReturn            388.808
2017-06-10 19:32:58.203784 EDT | StdReturn                 51.8016
2017-06-10 19:32:58.204233 EDT | MaxReturn                466.507
2017-06-10 19:32:58.204677 EDT | MinReturn                151.339
2017-06-10 19:32:58.205120 EDT | AverageEsReturn          205.652
2017-06-10 19:32:58.205566 EDT | StdEsReturn              115.674
2017-06-10 19:32:58.206022 EDT | MaxEsReturn              359.249
2017-06-10 19:32:58.206473 EDT | MinEsReturn               19.8046
2017-06-10 19:32:58.206919 EDT | AverageDiscountedReturn  139.798
2017-06-10 19:32:58.207379 EDT | AverageQLoss               0.0752386
2017-06-10 19:32:58.207822 EDT | AveragePolicySurr         -4.53589
2017-06-10 19:32:58.208265 EDT | AverageQ                   4.26285
2017-06-10 19:32:58.208710 EDT | AverageAbsQ                4.26674
2017-06-10 19:32:58.209153 EDT | AverageY                   4.26398
2017-06-10 19:32:58.209599 EDT | AverageAbsY                4.26502
2017-06-10 19:32:58.210069 EDT | AverageAbsQYDiff           0.121496
2017-06-10 19:32:58.210517 EDT | AverageAction              0.716592
2017-06-10 19:32:58.210964 EDT | PolicyRegParamNorm        24.8093
2017-06-10 19:32:58.211412 EDT | QFunRegParamNorm          23.1291
2017-06-10 19:32:58.211863 EDT | -----------------------  -----------
2017-06-10 19:32:58.212486 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #39 | Training started
2017-06-10 19:33:12.325067 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #39 | Training finished
2017-06-10 19:33:12.325319 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #39 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 19:33:12.325505 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #39 | Collecting samples for evaluation
2017-06-10 19:33:25.179770 EDT | -----------------------  -----------
2017-06-10 19:33:25.180721 EDT | Epoch                     39
2017-06-10 19:33:25.180949 EDT | Iteration                 39
2017-06-10 19:33:25.181127 EDT | AverageReturn            277.472
2017-06-10 19:33:25.181323 EDT | StdReturn                 36.075
2017-06-10 19:33:25.181507 EDT | MaxReturn                356.604
2017-06-10 19:33:25.181688 EDT | MinReturn                133.173
2017-06-10 19:33:25.181887 EDT | AverageEsReturn          218.347
2017-06-10 19:33:25.182068 EDT | StdEsReturn              145.333
2017-06-10 19:33:25.182301 EDT | MaxEsReturn              422.392
2017-06-10 19:33:25.182531 EDT | MinEsReturn               69.9252
2017-06-10 19:33:25.182714 EDT | AverageDiscountedReturn  138.139
2017-06-10 19:33:25.182890 EDT | AverageQLoss               0.0767852
2017-06-10 19:33:25.183117 EDT | AveragePolicySurr         -4.70745
2017-06-10 19:33:25.183390 EDT | AverageQ                   4.42746
2017-06-10 19:33:25.183702 EDT | AverageAbsQ                4.43161
2017-06-10 19:33:25.184027 EDT | AverageY                   4.42831
2017-06-10 19:33:25.184357 EDT | AverageAbsY                4.42942
2017-06-10 19:33:25.184953 EDT | AverageAbsQYDiff           0.124946
2017-06-10 19:33:25.185291 EDT | AverageAction              0.86499
2017-06-10 19:33:25.185625 EDT | PolicyRegParamNorm        25.265
2017-06-10 19:33:25.186145 EDT | QFunRegParamNorm          23.5514
2017-06-10 19:33:25.186438 EDT | -----------------------  -----------
2017-06-10 19:33:25.186899 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #40 | Training started
2017-06-10 19:33:40.459818 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #40 | Training finished
2017-06-10 19:33:40.461106 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #40 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 19:33:40.461474 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #40 | Collecting samples for evaluation
2017-06-10 19:33:52.797397 EDT | -----------------------  -----------
2017-06-10 19:33:52.798413 EDT | Epoch                     40
2017-06-10 19:33:52.798777 EDT | Iteration                 40
2017-06-10 19:33:52.799074 EDT | AverageReturn            311.083
2017-06-10 19:33:52.799304 EDT | StdReturn                 70.6589
2017-06-10 19:33:52.799930 EDT | MaxReturn                659.004
2017-06-10 19:33:52.800525 EDT | MinReturn                199.231
2017-06-10 19:33:52.800878 EDT | AverageEsReturn          177.601
2017-06-10 19:33:52.801995 EDT | StdEsReturn               87.8722
2017-06-10 19:33:52.802354 EDT | MaxEsReturn              301.69
2017-06-10 19:33:52.802688 EDT | MinEsReturn               18.0212
2017-06-10 19:33:52.803025 EDT | AverageDiscountedReturn  145.065
2017-06-10 19:33:52.803358 EDT | AverageQLoss               0.0816182
2017-06-10 19:33:52.803687 EDT | AveragePolicySurr         -4.88684
2017-06-10 19:33:52.804012 EDT | AverageQ                   4.59906
2017-06-10 19:33:52.804344 EDT | AverageAbsQ                4.60337
2017-06-10 19:33:52.804680 EDT | AverageY                   4.60009
2017-06-10 19:33:52.805005 EDT | AverageAbsY                4.60155
2017-06-10 19:33:52.805413 EDT | AverageAbsQYDiff           0.128248
2017-06-10 19:33:52.806346 EDT | AverageAction              0.840186
2017-06-10 19:33:52.806684 EDT | PolicyRegParamNorm        25.6824
2017-06-10 19:33:52.807101 EDT | QFunRegParamNorm          23.9781
2017-06-10 19:33:52.807407 EDT | -----------------------  -----------
2017-06-10 19:33:52.807901 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #41 | Training started
2017-06-10 19:34:06.701420 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #41 | Training finished
2017-06-10 19:34:06.702452 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #41 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 19:34:06.702779 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #41 | Collecting samples for evaluation
2017-06-10 19:34:19.572191 EDT | -----------------------  ------------
2017-06-10 19:34:19.573182 EDT | Epoch                      41
2017-06-10 19:34:19.573453 EDT | Iteration                  41
2017-06-10 19:34:19.573671 EDT | AverageReturn             413.203
2017-06-10 19:34:19.574117 EDT | StdReturn                 135.167
2017-06-10 19:34:19.574695 EDT | MaxReturn                1055.11
2017-06-10 19:34:19.575260 EDT | MinReturn                 313.933
2017-06-10 19:34:19.575725 EDT | AverageEsReturn           271.699
2017-06-10 19:34:19.576160 EDT | StdEsReturn                67.6583
2017-06-10 19:34:19.576532 EDT | MaxEsReturn               366.471
2017-06-10 19:34:19.577139 EDT | MinEsReturn               143.398
2017-06-10 19:34:19.577834 EDT | AverageDiscountedReturn   147.058
2017-06-10 19:34:19.579028 EDT | AverageQLoss                0.0965273
2017-06-10 19:34:19.579379 EDT | AveragePolicySurr          -5.0755
2017-06-10 19:34:19.579750 EDT | AverageQ                    4.78048
2017-06-10 19:34:19.580081 EDT | AverageAbsQ                 4.7848
2017-06-10 19:34:19.580459 EDT | AverageY                    4.78157
2017-06-10 19:34:19.580807 EDT | AverageAbsY                 4.78338
2017-06-10 19:34:19.581253 EDT | AverageAbsQYDiff            0.134287
2017-06-10 19:34:19.581717 EDT | AverageAction               0.810539
2017-06-10 19:34:19.582171 EDT | PolicyRegParamNorm         26.177
2017-06-10 19:34:19.583596 EDT | QFunRegParamNorm           24.3449
2017-06-10 19:34:19.584401 EDT | -----------------------  ------------
2017-06-10 19:34:19.585000 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #42 | Training started
2017-06-10 19:34:33.683998 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #42 | Training finished
2017-06-10 19:34:33.684746 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #42 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 19:34:33.684935 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #42 | Collecting samples for evaluation
2017-06-10 19:34:45.383769 EDT | -----------------------  -----------
2017-06-10 19:34:45.388171 EDT | Epoch                     42
2017-06-10 19:34:45.388702 EDT | Iteration                 42
2017-06-10 19:34:45.389178 EDT | AverageReturn            246.914
2017-06-10 19:34:45.389537 EDT | StdReturn                 63.908
2017-06-10 19:34:45.389973 EDT | MaxReturn                378.626
2017-06-10 19:34:45.390340 EDT | MinReturn                146.485
2017-06-10 19:34:45.390706 EDT | AverageEsReturn          274.266
2017-06-10 19:34:45.391061 EDT | StdEsReturn              149.291
2017-06-10 19:34:45.391433 EDT | MaxEsReturn              624.955
2017-06-10 19:34:45.391789 EDT | MinEsReturn              100.947
2017-06-10 19:34:45.392546 EDT | AverageDiscountedReturn  127.75
2017-06-10 19:34:45.394939 EDT | AverageQLoss               0.0924601
2017-06-10 19:34:45.396287 EDT | AveragePolicySurr         -5.24513
2017-06-10 19:34:45.396637 EDT | AverageQ                   4.95768
2017-06-10 19:34:45.397097 EDT | AverageAbsQ                4.96252
2017-06-10 19:34:45.397505 EDT | AverageY                   4.95871
2017-06-10 19:34:45.397930 EDT | AverageAbsY                4.96066
2017-06-10 19:34:45.398352 EDT | AverageAbsQYDiff           0.134774
2017-06-10 19:34:45.398720 EDT | AverageAction              0.765066
2017-06-10 19:34:45.399072 EDT | PolicyRegParamNorm        26.4784
2017-06-10 19:34:45.399429 EDT | QFunRegParamNorm          24.7219
2017-06-10 19:34:45.399908 EDT | -----------------------  -----------
2017-06-10 19:34:45.400453 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #43 | Training started
2017-06-10 19:35:00.509992 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #43 | Training finished
2017-06-10 19:35:00.510717 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #43 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 19:35:00.510942 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #43 | Collecting samples for evaluation
2017-06-10 19:35:12.287389 EDT | -----------------------  -----------
2017-06-10 19:35:12.287833 EDT | Epoch                      43
2017-06-10 19:35:12.288041 EDT | Iteration                  43
2017-06-10 19:35:12.288229 EDT | AverageReturn             223.162
2017-06-10 19:35:12.288413 EDT | StdReturn                 229.643
2017-06-10 19:35:12.288599 EDT | MaxReturn                1468.79
2017-06-10 19:35:12.288780 EDT | MinReturn                 121.882
2017-06-10 19:35:12.288982 EDT | AverageEsReturn           267.554
2017-06-10 19:35:12.289175 EDT | StdEsReturn               132.204
2017-06-10 19:35:12.289355 EDT | MaxEsReturn               508.779
2017-06-10 19:35:12.289535 EDT | MinEsReturn                59.1115
2017-06-10 19:35:12.289838 EDT | AverageDiscountedReturn   106.756
2017-06-10 19:35:12.290045 EDT | AverageQLoss                0.107233
2017-06-10 19:35:12.290206 EDT | AveragePolicySurr          -5.43043
2017-06-10 19:35:12.290640 EDT | AverageQ                    5.13176
2017-06-10 19:35:12.290974 EDT | AverageAbsQ                 5.13679
2017-06-10 19:35:12.291260 EDT | AverageY                    5.1332
2017-06-10 19:35:12.291550 EDT | AverageAbsY                 5.13491
2017-06-10 19:35:12.291835 EDT | AverageAbsQYDiff            0.143445
2017-06-10 19:35:12.292017 EDT | AverageAction               0.764168
2017-06-10 19:35:12.292282 EDT | PolicyRegParamNorm         26.9515
2017-06-10 19:35:12.292473 EDT | QFunRegParamNorm           25.1048
2017-06-10 19:35:12.292672 EDT | -----------------------  -----------
2017-06-10 19:35:12.293055 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #44 | Training started
2017-06-10 19:35:26.977983 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #44 | Training finished
2017-06-10 19:35:26.978910 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #44 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 19:35:26.979294 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #44 | Collecting samples for evaluation
2017-06-10 19:35:38.648927 EDT | -----------------------  -----------
2017-06-10 19:35:38.650029 EDT | Epoch                      44
2017-06-10 19:35:38.650320 EDT | Iteration                  44
2017-06-10 19:35:38.650657 EDT | AverageReturn             372.071
2017-06-10 19:35:38.650995 EDT | StdReturn                 278.626
2017-06-10 19:35:38.651304 EDT | MaxReturn                1072.04
2017-06-10 19:35:38.651566 EDT | MinReturn                 114.086
2017-06-10 19:35:38.651895 EDT | AverageEsReturn           334.77
2017-06-10 19:35:38.652228 EDT | StdEsReturn               214.908
2017-06-10 19:35:38.652540 EDT | MaxEsReturn               738.991
2017-06-10 19:35:38.652872 EDT | MinEsReturn                73.9926
2017-06-10 19:35:38.653206 EDT | AverageDiscountedReturn   129.446
2017-06-10 19:35:38.653535 EDT | AverageQLoss                0.105764
2017-06-10 19:35:38.653886 EDT | AveragePolicySurr          -5.58792
2017-06-10 19:35:38.655157 EDT | AverageQ                    5.29484
2017-06-10 19:35:38.655462 EDT | AverageAbsQ                 5.29967
2017-06-10 19:35:38.655740 EDT | AverageY                    5.29618
2017-06-10 19:35:38.656241 EDT | AverageAbsY                 5.29775
2017-06-10 19:35:38.656577 EDT | AverageAbsQYDiff            0.14427
2017-06-10 19:35:38.658734 EDT | AverageAction               0.818429
2017-06-10 19:35:38.659088 EDT | PolicyRegParamNorm         27.3569
2017-06-10 19:35:38.659353 EDT | QFunRegParamNorm           25.4726
2017-06-10 19:35:38.659652 EDT | -----------------------  -----------
2017-06-10 19:35:38.660113 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #45 | Training started
2017-06-10 19:35:53.615046 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #45 | Training finished
2017-06-10 19:35:53.615983 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #45 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 19:35:53.616348 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #45 | Collecting samples for evaluation
2017-06-10 19:36:05.698924 EDT | -----------------------  ----------
2017-06-10 19:36:05.699865 EDT | Epoch                     45
2017-06-10 19:36:05.700215 EDT | Iteration                 45
2017-06-10 19:36:05.700550 EDT | AverageReturn            316.012
2017-06-10 19:36:05.700902 EDT | StdReturn                149.266
2017-06-10 19:36:05.701286 EDT | MaxReturn                903.966
2017-06-10 19:36:05.701727 EDT | MinReturn                 94.3156
2017-06-10 19:36:05.702259 EDT | AverageEsReturn          237.859
2017-06-10 19:36:05.702601 EDT | StdEsReturn              119.989
2017-06-10 19:36:05.703055 EDT | MaxEsReturn              451.388
2017-06-10 19:36:05.703397 EDT | MinEsReturn              118.261
2017-06-10 19:36:05.703893 EDT | AverageDiscountedReturn  147.874
2017-06-10 19:36:05.704223 EDT | AverageQLoss               0.123477
2017-06-10 19:36:05.704566 EDT | AveragePolicySurr         -5.79437
2017-06-10 19:36:05.705053 EDT | AverageQ                   5.50022
2017-06-10 19:36:05.705473 EDT | AverageAbsQ                5.50549
2017-06-10 19:36:05.706090 EDT | AverageY                   5.50171
2017-06-10 19:36:05.706533 EDT | AverageAbsY                5.50346
2017-06-10 19:36:05.706920 EDT | AverageAbsQYDiff           0.153364
2017-06-10 19:36:05.707250 EDT | AverageAction              0.821849
2017-06-10 19:36:05.707586 EDT | PolicyRegParamNorm        27.777
2017-06-10 19:36:05.707994 EDT | QFunRegParamNorm          25.7855
2017-06-10 19:36:05.708331 EDT | -----------------------  ----------
2017-06-10 19:36:05.708917 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #46 | Training started
2017-06-10 19:36:20.056664 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #46 | Training finished
2017-06-10 19:36:20.057680 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #46 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 19:36:20.058113 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #46 | Collecting samples for evaluation
2017-06-10 19:36:32.284016 EDT | -----------------------  ----------
2017-06-10 19:36:32.284902 EDT | Epoch                     46
2017-06-10 19:36:32.285379 EDT | Iteration                 46
2017-06-10 19:36:32.285682 EDT | AverageReturn            276.569
2017-06-10 19:36:32.286688 EDT | StdReturn                 70.8662
2017-06-10 19:36:32.287127 EDT | MaxReturn                825.739
2017-06-10 19:36:32.287418 EDT | MinReturn                180.067
2017-06-10 19:36:32.287628 EDT | AverageEsReturn          286.648
2017-06-10 19:36:32.287871 EDT | StdEsReturn               89.7143
2017-06-10 19:36:32.288056 EDT | MaxEsReturn              445.714
2017-06-10 19:36:32.288240 EDT | MinEsReturn              174.584
2017-06-10 19:36:32.288437 EDT | AverageDiscountedReturn  142.657
2017-06-10 19:36:32.288637 EDT | AverageQLoss               0.125541
2017-06-10 19:36:32.288832 EDT | AveragePolicySurr         -5.97098
2017-06-10 19:36:32.289013 EDT | AverageQ                   5.67112
2017-06-10 19:36:32.289192 EDT | AverageAbsQ                5.67628
2017-06-10 19:36:32.289369 EDT | AverageY                   5.67266
2017-06-10 19:36:32.289596 EDT | AverageAbsY                5.67428
2017-06-10 19:36:32.289821 EDT | AverageAbsQYDiff           0.1574
2017-06-10 19:36:32.290086 EDT | AverageAction              0.854105
2017-06-10 19:36:32.290322 EDT | PolicyRegParamNorm        28.197
2017-06-10 19:36:32.290503 EDT | QFunRegParamNorm          26.1174
2017-06-10 19:36:32.290719 EDT | -----------------------  ----------
2017-06-10 19:36:32.291029 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #47 | Training started
2017-06-10 19:36:46.766512 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #47 | Training finished
2017-06-10 19:36:46.766869 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #47 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 19:36:46.767156 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #47 | Collecting samples for evaluation
2017-06-10 19:36:58.271645 EDT | -----------------------  ----------
2017-06-10 19:36:58.273102 EDT | Epoch                     47
2017-06-10 19:36:58.273780 EDT | Iteration                 47
2017-06-10 19:36:58.274129 EDT | AverageReturn            377.401
2017-06-10 19:36:58.274503 EDT | StdReturn                 10.0717
2017-06-10 19:36:58.274847 EDT | MaxReturn                417.045
2017-06-10 19:36:58.275190 EDT | MinReturn                361.65
2017-06-10 19:36:58.275555 EDT | AverageEsReturn          258.876
2017-06-10 19:36:58.275897 EDT | StdEsReturn              138.807
2017-06-10 19:36:58.276237 EDT | MaxEsReturn              431.952
2017-06-10 19:36:58.278629 EDT | MinEsReturn               67.1836
2017-06-10 19:36:58.279002 EDT | AverageDiscountedReturn  182.878
2017-06-10 19:36:58.279968 EDT | AverageQLoss               0.124593
2017-06-10 19:36:58.280316 EDT | AveragePolicySurr         -6.15901
2017-06-10 19:36:58.280661 EDT | AverageQ                   5.83423
2017-06-10 19:36:58.283973 EDT | AverageAbsQ                5.83957
2017-06-10 19:36:58.284833 EDT | AverageY                   5.83533
2017-06-10 19:36:58.286085 EDT | AverageAbsY                5.83703
2017-06-10 19:36:58.286544 EDT | AverageAbsQYDiff           0.160396
2017-06-10 19:36:58.287966 EDT | AverageAction              0.896818
2017-06-10 19:36:58.288427 EDT | PolicyRegParamNorm        28.5097
2017-06-10 19:36:58.289257 EDT | QFunRegParamNorm          26.4805
2017-06-10 19:36:58.289962 EDT | -----------------------  ----------
2017-06-10 19:36:58.290632 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #48 | Training started
2017-06-10 19:37:14.168481 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #48 | Training finished
2017-06-10 19:37:14.169776 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #48 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 19:37:14.170193 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #48 | Collecting samples for evaluation
2017-06-10 19:37:25.364398 EDT | -----------------------  -----------
2017-06-10 19:37:25.366423 EDT | Epoch                      48
2017-06-10 19:37:25.366826 EDT | Iteration                  48
2017-06-10 19:37:25.367149 EDT | AverageReturn             513.54
2017-06-10 19:37:25.367458 EDT | StdReturn                 214.514
2017-06-10 19:37:25.367837 EDT | MaxReturn                1799.27
2017-06-10 19:37:25.368175 EDT | MinReturn                 297.035
2017-06-10 19:37:25.368634 EDT | AverageEsReturn           327.076
2017-06-10 19:37:25.369025 EDT | StdEsReturn               197.762
2017-06-10 19:37:25.369331 EDT | MaxEsReturn               608.213
2017-06-10 19:37:25.369627 EDT | MinEsReturn                55.8831
2017-06-10 19:37:25.370000 EDT | AverageDiscountedReturn   177.029
2017-06-10 19:37:25.370300 EDT | AverageQLoss                0.139267
2017-06-10 19:37:25.370593 EDT | AveragePolicySurr          -6.39973
2017-06-10 19:37:25.370886 EDT | AverageQ                    6.07256
2017-06-10 19:37:25.371179 EDT | AverageAbsQ                 6.07753
2017-06-10 19:37:25.371470 EDT | AverageY                    6.07431
2017-06-10 19:37:25.371759 EDT | AverageAbsY                 6.07536
2017-06-10 19:37:25.372047 EDT | AverageAbsQYDiff            0.166148
2017-06-10 19:37:25.372489 EDT | AverageAction               0.839182
2017-06-10 19:37:25.372783 EDT | PolicyRegParamNorm         28.81
2017-06-10 19:37:25.373074 EDT | QFunRegParamNorm           26.8235
2017-06-10 19:37:25.373461 EDT | -----------------------  -----------
2017-06-10 19:37:25.373905 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #49 | Training started
2017-06-10 19:37:39.656416 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #49 | Training finished
2017-06-10 19:37:39.657717 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #49 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 19:37:39.658126 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #49 | Collecting samples for evaluation
2017-06-10 19:37:52.337439 EDT | -----------------------  ----------
2017-06-10 19:37:52.338373 EDT | Epoch                     49
2017-06-10 19:37:52.338727 EDT | Iteration                 49
2017-06-10 19:37:52.339228 EDT | AverageReturn            516.672
2017-06-10 19:37:52.339656 EDT | StdReturn                 89.8737
2017-06-10 19:37:52.339978 EDT | MaxReturn                915.329
2017-06-10 19:37:52.340263 EDT | MinReturn                374.188
2017-06-10 19:37:52.340588 EDT | AverageEsReturn          365.721
2017-06-10 19:37:52.341822 EDT | StdEsReturn              195.835
2017-06-10 19:37:52.342166 EDT | MaxEsReturn              725.84
2017-06-10 19:37:52.342654 EDT | MinEsReturn              131.57
2017-06-10 19:37:52.342979 EDT | AverageDiscountedReturn  174.026
2017-06-10 19:37:52.343312 EDT | AverageQLoss               0.152179
2017-06-10 19:37:52.343636 EDT | AveragePolicySurr         -6.54536
2017-06-10 19:37:52.343956 EDT | AverageQ                   6.22289
2017-06-10 19:37:52.344357 EDT | AverageAbsQ                6.22808
2017-06-10 19:37:52.344642 EDT | AverageY                   6.22447
2017-06-10 19:37:52.344954 EDT | AverageAbsY                6.22538
2017-06-10 19:37:52.345644 EDT | AverageAbsQYDiff           0.16763
2017-06-10 19:37:52.345965 EDT | AverageAction              0.878726
2017-06-10 19:37:52.346534 EDT | PolicyRegParamNorm        29.0148
2017-06-10 19:37:52.346854 EDT | QFunRegParamNorm          27.2112
2017-06-10 19:37:52.347415 EDT | -----------------------  ----------
2017-06-10 19:37:52.349062 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #50 | Training started
2017-06-10 19:38:06.331024 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #50 | Training finished
2017-06-10 19:38:06.331870 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #50 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 19:38:06.332191 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #50 | Collecting samples for evaluation
2017-06-10 19:38:18.639030 EDT | -----------------------  ----------
2017-06-10 19:38:18.639504 EDT | Epoch                     50
2017-06-10 19:38:18.639853 EDT | Iteration                 50
2017-06-10 19:38:18.640197 EDT | AverageReturn            279.214
2017-06-10 19:38:18.640539 EDT | StdReturn                104.766
2017-06-10 19:38:18.640880 EDT | MaxReturn                779.875
2017-06-10 19:38:18.641219 EDT | MinReturn                202.7
2017-06-10 19:38:18.641597 EDT | AverageEsReturn          267.687
2017-06-10 19:38:18.641953 EDT | StdEsReturn              204.764
2017-06-10 19:38:18.642296 EDT | MaxEsReturn              579.258
2017-06-10 19:38:18.642638 EDT | MinEsReturn               43.506
2017-06-10 19:38:18.642979 EDT | AverageDiscountedReturn  135.838
2017-06-10 19:38:18.643319 EDT | AverageQLoss               0.193196
2017-06-10 19:38:18.643661 EDT | AveragePolicySurr         -6.74347
2017-06-10 19:38:18.644002 EDT | AverageQ                   6.41623
2017-06-10 19:38:18.644347 EDT | AverageAbsQ                6.42189
2017-06-10 19:38:18.644689 EDT | AverageY                   6.41813
2017-06-10 19:38:18.645027 EDT | AverageAbsY                6.41933
2017-06-10 19:38:18.645653 EDT | AverageAbsQYDiff           0.179546
2017-06-10 19:38:18.646020 EDT | AverageAction              0.793836
2017-06-10 19:38:18.646361 EDT | PolicyRegParamNorm        29.3474
2017-06-10 19:38:18.647355 EDT | QFunRegParamNorm          27.532
2017-06-10 19:38:18.649971 EDT | -----------------------  ----------
2017-06-10 19:38:18.650478 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #51 | Training started
2017-06-10 19:38:33.025065 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #51 | Training finished
2017-06-10 19:38:33.025948 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #51 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 19:38:33.026263 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #51 | Collecting samples for evaluation
2017-06-10 19:38:44.811296 EDT | -----------------------  -----------
2017-06-10 19:38:44.812116 EDT | Epoch                      51
2017-06-10 19:38:44.812583 EDT | Iteration                  51
2017-06-10 19:38:44.814478 EDT | AverageReturn             726.617
2017-06-10 19:38:44.814995 EDT | StdReturn                 241.821
2017-06-10 19:38:44.815450 EDT | MaxReturn                1491.49
2017-06-10 19:38:44.815893 EDT | MinReturn                 276.58
2017-06-10 19:38:44.816464 EDT | AverageEsReturn           298.615
2017-06-10 19:38:44.818784 EDT | StdEsReturn               121.876
2017-06-10 19:38:44.819292 EDT | MaxEsReturn               488.234
2017-06-10 19:38:44.819837 EDT | MinEsReturn                42.3745
2017-06-10 19:38:44.820287 EDT | AverageDiscountedReturn   181.499
2017-06-10 19:38:44.820722 EDT | AverageQLoss                0.166976
2017-06-10 19:38:44.821160 EDT | AveragePolicySurr          -6.94022
2017-06-10 19:38:44.822570 EDT | AverageQ                    6.61465
2017-06-10 19:38:44.823039 EDT | AverageAbsQ                 6.62129
2017-06-10 19:38:44.824624 EDT | AverageY                    6.61545
2017-06-10 19:38:44.825082 EDT | AverageAbsY                 6.61696
2017-06-10 19:38:44.826204 EDT | AverageAbsQYDiff            0.174406
2017-06-10 19:38:44.827900 EDT | AverageAction               0.811301
2017-06-10 19:38:44.829902 EDT | PolicyRegParamNorm         29.534
2017-06-10 19:38:44.830824 EDT | QFunRegParamNorm           27.9104
2017-06-10 19:38:44.831841 EDT | -----------------------  -----------
2017-06-10 19:38:44.832453 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #52 | Training started
2017-06-10 19:38:59.885084 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #52 | Training finished
2017-06-10 19:38:59.885904 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #52 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 19:38:59.886108 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #52 | Collecting samples for evaluation
2017-06-10 19:39:11.766951 EDT | -----------------------  ----------
2017-06-10 19:39:11.767854 EDT | Epoch                     52
2017-06-10 19:39:11.768153 EDT | Iteration                 52
2017-06-10 19:39:11.768429 EDT | AverageReturn            341.736
2017-06-10 19:39:11.768816 EDT | StdReturn                 75.5999
2017-06-10 19:39:11.769132 EDT | MaxReturn                713.985
2017-06-10 19:39:11.769338 EDT | MinReturn                276.977
2017-06-10 19:39:11.769505 EDT | AverageEsReturn          265.67
2017-06-10 19:39:11.769711 EDT | StdEsReturn              157.333
2017-06-10 19:39:11.769931 EDT | MaxEsReturn              444.718
2017-06-10 19:39:11.770274 EDT | MinEsReturn                9.26997
2017-06-10 19:39:11.770436 EDT | AverageDiscountedReturn  160.639
2017-06-10 19:39:11.770631 EDT | AverageQLoss               0.18121
2017-06-10 19:39:11.770905 EDT | AveragePolicySurr         -7.13625
2017-06-10 19:39:11.771227 EDT | AverageQ                   6.79016
2017-06-10 19:39:11.771387 EDT | AverageAbsQ                6.79689
2017-06-10 19:39:11.771619 EDT | AverageY                   6.79172
2017-06-10 19:39:11.771904 EDT | AverageAbsY                6.79357
2017-06-10 19:39:11.772225 EDT | AverageAbsQYDiff           0.181957
2017-06-10 19:39:11.772566 EDT | AverageAction              0.819386
2017-06-10 19:39:11.772817 EDT | PolicyRegParamNorm        29.7602
2017-06-10 19:39:11.773019 EDT | QFunRegParamNorm          28.2985
2017-06-10 19:39:11.773340 EDT | -----------------------  ----------
2017-06-10 19:39:11.773855 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #53 | Training started
2017-06-10 19:39:26.347333 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #53 | Training finished
2017-06-10 19:39:26.348267 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #53 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 19:39:26.348658 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #53 | Collecting samples for evaluation
2017-06-10 19:39:38.129058 EDT | -----------------------  ----------
2017-06-10 19:39:38.130080 EDT | Epoch                     53
2017-06-10 19:39:38.130409 EDT | Iteration                 53
2017-06-10 19:39:38.130710 EDT | AverageReturn            302.566
2017-06-10 19:39:38.131007 EDT | StdReturn                  9.14898
2017-06-10 19:39:38.131299 EDT | MaxReturn                359.898
2017-06-10 19:39:38.131595 EDT | MinReturn                282.979
2017-06-10 19:39:38.131879 EDT | AverageEsReturn          336.113
2017-06-10 19:39:38.132147 EDT | StdEsReturn              222.214
2017-06-10 19:39:38.132424 EDT | MaxEsReturn              850.162
2017-06-10 19:39:38.132713 EDT | MinEsReturn               87.4257
2017-06-10 19:39:38.133010 EDT | AverageDiscountedReturn  154.428
2017-06-10 19:39:38.133305 EDT | AverageQLoss               0.173247
2017-06-10 19:39:38.133597 EDT | AveragePolicySurr         -7.38743
2017-06-10 19:39:38.133872 EDT | AverageQ                   7.03357
2017-06-10 19:39:38.134135 EDT | AverageAbsQ                7.03974
2017-06-10 19:39:38.134428 EDT | AverageY                   7.03487
2017-06-10 19:39:38.134703 EDT | AverageAbsY                7.03595
2017-06-10 19:39:38.134968 EDT | AverageAbsQYDiff           0.181216
2017-06-10 19:39:38.135415 EDT | AverageAction              0.80016
2017-06-10 19:39:38.135755 EDT | PolicyRegParamNorm        30.0979
2017-06-10 19:39:38.136067 EDT | QFunRegParamNorm          28.6995
2017-06-10 19:39:38.136388 EDT | -----------------------  ----------
2017-06-10 19:39:38.137187 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #54 | Training started
2017-06-10 19:39:52.416681 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #54 | Training finished
2017-06-10 19:39:52.417499 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #54 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 19:39:52.418038 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #54 | Collecting samples for evaluation
2017-06-10 19:40:04.821611 EDT | -----------------------  ----------
2017-06-10 19:40:04.822710 EDT | Epoch                     54
2017-06-10 19:40:04.823160 EDT | Iteration                 54
2017-06-10 19:40:04.823519 EDT | AverageReturn            300.574
2017-06-10 19:40:04.823947 EDT | StdReturn                  5.28165
2017-06-10 19:40:04.824376 EDT | MaxReturn                320.264
2017-06-10 19:40:04.824730 EDT | MinReturn                289.321
2017-06-10 19:40:04.825143 EDT | AverageEsReturn          336.26
2017-06-10 19:40:04.825485 EDT | StdEsReturn              178.897
2017-06-10 19:40:04.825891 EDT | MaxEsReturn              676.043
2017-06-10 19:40:04.826172 EDT | MinEsReturn               25.476
2017-06-10 19:40:04.826594 EDT | AverageDiscountedReturn  156.71
2017-06-10 19:40:04.827021 EDT | AverageQLoss               0.200777
2017-06-10 19:40:04.827377 EDT | AveragePolicySurr         -7.57647
2017-06-10 19:40:04.827958 EDT | AverageQ                   7.21222
2017-06-10 19:40:04.828776 EDT | AverageAbsQ                7.21782
2017-06-10 19:40:04.829215 EDT | AverageY                   7.21408
2017-06-10 19:40:04.837860 EDT | AverageAbsY                7.21499
2017-06-10 19:40:04.838398 EDT | AverageAbsQYDiff           0.196023
2017-06-10 19:40:04.838815 EDT | AverageAction              0.830557
2017-06-10 19:40:04.839142 EDT | PolicyRegParamNorm        30.3803
2017-06-10 19:40:04.839470 EDT | QFunRegParamNorm          29.1167
2017-06-10 19:40:04.839805 EDT | -----------------------  ----------
2017-06-10 19:40:04.840242 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #55 | Training started
2017-06-10 19:40:18.821100 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #55 | Training finished
2017-06-10 19:40:18.822057 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #55 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 19:40:18.822477 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #55 | Collecting samples for evaluation
2017-06-10 19:40:31.438546 EDT | -----------------------  ----------
2017-06-10 19:40:31.441208 EDT | Epoch                     55
2017-06-10 19:40:31.441416 EDT | Iteration                 55
2017-06-10 19:40:31.441583 EDT | AverageReturn            350.609
2017-06-10 19:40:31.441790 EDT | StdReturn                  8.15888
2017-06-10 19:40:31.442104 EDT | MaxReturn                372.1
2017-06-10 19:40:31.442295 EDT | MinReturn                332.465
2017-06-10 19:40:31.442528 EDT | AverageEsReturn          285.85
2017-06-10 19:40:31.442827 EDT | StdEsReturn               75.6085
2017-06-10 19:40:31.443160 EDT | MaxEsReturn              435.397
2017-06-10 19:40:31.443445 EDT | MinEsReturn              143.937
2017-06-10 19:40:31.443686 EDT | AverageDiscountedReturn  171.303
2017-06-10 19:40:31.443841 EDT | AverageQLoss               0.191773
2017-06-10 19:40:31.443993 EDT | AveragePolicySurr         -7.79611
2017-06-10 19:40:31.444234 EDT | AverageQ                   7.44817
2017-06-10 19:40:31.444390 EDT | AverageAbsQ                7.45466
2017-06-10 19:40:31.444545 EDT | AverageY                   7.44984
2017-06-10 19:40:31.444815 EDT | AverageAbsY                7.45075
2017-06-10 19:40:31.445006 EDT | AverageAbsQYDiff           0.193025
2017-06-10 19:40:31.445190 EDT | AverageAction              0.825574
2017-06-10 19:40:31.445373 EDT | PolicyRegParamNorm        30.6738
2017-06-10 19:40:31.445553 EDT | QFunRegParamNorm          29.4907
2017-06-10 19:40:31.445752 EDT | -----------------------  ----------
2017-06-10 19:40:31.446234 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #56 | Training started
2017-06-10 19:40:46.455948 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #56 | Training finished
2017-06-10 19:40:46.456870 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #56 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 19:40:46.457275 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #56 | Collecting samples for evaluation
2017-06-10 19:40:57.235963 EDT | -----------------------  ----------
2017-06-10 19:40:57.236255 EDT | Epoch                     56
2017-06-10 19:40:57.236483 EDT | Iteration                 56
2017-06-10 19:40:57.236641 EDT | AverageReturn            314.877
2017-06-10 19:40:57.236849 EDT | StdReturn                  3.53136
2017-06-10 19:40:57.237024 EDT | MaxReturn                329.008
2017-06-10 19:40:57.237248 EDT | MinReturn                307.794
2017-06-10 19:40:57.237494 EDT | AverageEsReturn          215.592
2017-06-10 19:40:57.237755 EDT | StdEsReturn               85.6326
2017-06-10 19:40:57.237994 EDT | MaxEsReturn              304.332
2017-06-10 19:40:57.238231 EDT | MinEsReturn                5.2423
2017-06-10 19:40:57.238437 EDT | AverageDiscountedReturn  161.516
2017-06-10 19:40:57.238645 EDT | AverageQLoss               0.214128
2017-06-10 19:40:57.238883 EDT | AveragePolicySurr         -7.99519
2017-06-10 19:40:57.239275 EDT | AverageQ                   7.63938
2017-06-10 19:40:57.239561 EDT | AverageAbsQ                7.64605
2017-06-10 19:40:57.239791 EDT | AverageY                   7.6412
2017-06-10 19:40:57.239943 EDT | AverageAbsY                7.64223
2017-06-10 19:40:57.240278 EDT | AverageAbsQYDiff           0.20239
2017-06-10 19:40:57.240737 EDT | AverageAction              0.813498
2017-06-10 19:40:57.241127 EDT | PolicyRegParamNorm        30.9937
2017-06-10 19:40:57.241389 EDT | QFunRegParamNorm          29.8726
2017-06-10 19:40:57.241670 EDT | -----------------------  ----------
2017-06-10 19:40:57.242108 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #57 | Training started
2017-06-10 19:41:11.790355 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #57 | Training finished
2017-06-10 19:41:11.791238 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #57 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 19:41:11.791484 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #57 | Collecting samples for evaluation
2017-06-10 19:41:23.902090 EDT | -----------------------  ----------
2017-06-10 19:41:23.902863 EDT | Epoch                     57
2017-06-10 19:41:23.903214 EDT | Iteration                 57
2017-06-10 19:41:23.903574 EDT | AverageReturn            320.851
2017-06-10 19:41:23.903877 EDT | StdReturn                  5.55705
2017-06-10 19:41:23.904200 EDT | MaxReturn                341.047
2017-06-10 19:41:23.905795 EDT | MinReturn                309.666
2017-06-10 19:41:23.906272 EDT | AverageEsReturn          200.676
2017-06-10 19:41:23.906848 EDT | StdEsReturn              119.072
2017-06-10 19:41:23.907172 EDT | MaxEsReturn              365.941
2017-06-10 19:41:23.907492 EDT | MinEsReturn               46.4422
2017-06-10 19:41:23.907870 EDT | AverageDiscountedReturn  163.737
2017-06-10 19:41:23.908199 EDT | AverageQLoss               0.182133
2017-06-10 19:41:23.908786 EDT | AveragePolicySurr         -8.18753
2017-06-10 19:41:23.908959 EDT | AverageQ                   7.82464
2017-06-10 19:41:23.909174 EDT | AverageAbsQ                7.8298
2017-06-10 19:41:23.909369 EDT | AverageY                   7.82584
2017-06-10 19:41:23.909651 EDT | AverageAbsY                7.82658
2017-06-10 19:41:23.909873 EDT | AverageAbsQYDiff           0.190838
2017-06-10 19:41:23.910026 EDT | AverageAction              0.846615
2017-06-10 19:41:23.910177 EDT | PolicyRegParamNorm        31.2046
2017-06-10 19:41:23.910402 EDT | QFunRegParamNorm          30.2231
2017-06-10 19:41:23.910720 EDT | -----------------------  ----------
2017-06-10 19:41:23.911187 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #58 | Training started
2017-06-10 19:41:37.173033 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #58 | Training finished
2017-06-10 19:41:37.174060 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #58 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 19:41:37.174525 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #58 | Collecting samples for evaluation
2017-06-10 19:41:49.700132 EDT | -----------------------  ----------
2017-06-10 19:41:49.702628 EDT | Epoch                     58
2017-06-10 19:41:49.704630 EDT | Iteration                 58
2017-06-10 19:41:49.705062 EDT | AverageReturn            316.815
2017-06-10 19:41:49.705415 EDT | StdReturn                 10.8625
2017-06-10 19:41:49.705774 EDT | MaxReturn                346.131
2017-06-10 19:41:49.706112 EDT | MinReturn                296.143
2017-06-10 19:41:49.706599 EDT | AverageEsReturn          295.426
2017-06-10 19:41:49.707130 EDT | StdEsReturn               90.619
2017-06-10 19:41:49.707481 EDT | MaxEsReturn              389.078
2017-06-10 19:41:49.708024 EDT | MinEsReturn               78.9937
2017-06-10 19:41:49.708544 EDT | AverageDiscountedReturn  159.954
2017-06-10 19:41:49.708894 EDT | AverageQLoss               0.196396
2017-06-10 19:41:49.709277 EDT | AveragePolicySurr         -8.42666
2017-06-10 19:41:49.709965 EDT | AverageQ                   8.05848
2017-06-10 19:41:49.710314 EDT | AverageAbsQ                8.06519
2017-06-10 19:41:49.710607 EDT | AverageY                   8.05993
2017-06-10 19:41:49.710961 EDT | AverageAbsY                8.06066
2017-06-10 19:41:49.711288 EDT | AverageAbsQYDiff           0.197865
2017-06-10 19:41:49.711564 EDT | AverageAction              0.80396
2017-06-10 19:41:49.711837 EDT | PolicyRegParamNorm        31.4408
2017-06-10 19:41:49.712135 EDT | QFunRegParamNorm          30.6051
2017-06-10 19:41:49.712406 EDT | -----------------------  ----------
2017-06-10 19:41:49.712876 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #59 | Training started
2017-06-10 19:42:03.716787 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #59 | Training finished
2017-06-10 19:42:03.717719 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #59 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 19:42:03.718086 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #59 | Collecting samples for evaluation
2017-06-10 19:42:15.359686 EDT | -----------------------  ----------
2017-06-10 19:42:15.360920 EDT | Epoch                     59
2017-06-10 19:42:15.361123 EDT | Iteration                 59
2017-06-10 19:42:15.361303 EDT | AverageReturn            352.756
2017-06-10 19:42:15.361479 EDT | StdReturn                 81.3942
2017-06-10 19:42:15.361740 EDT | MaxReturn                755.994
2017-06-10 19:42:15.361943 EDT | MinReturn                272.538
2017-06-10 19:42:15.362295 EDT | AverageEsReturn          253.982
2017-06-10 19:42:15.362520 EDT | StdEsReturn              103.288
2017-06-10 19:42:15.362704 EDT | MaxEsReturn              345.545
2017-06-10 19:42:15.363302 EDT | MinEsReturn               27.7989
2017-06-10 19:42:15.363526 EDT | AverageDiscountedReturn  162.701
2017-06-10 19:42:15.363716 EDT | AverageQLoss               0.236549
2017-06-10 19:42:15.363879 EDT | AveragePolicySurr         -8.58767
2017-06-10 19:42:15.364054 EDT | AverageQ                   8.22497
2017-06-10 19:42:15.364216 EDT | AverageAbsQ                8.23108
2017-06-10 19:42:15.364424 EDT | AverageY                   8.22674
2017-06-10 19:42:15.364627 EDT | AverageAbsY                8.22721
2017-06-10 19:42:15.364788 EDT | AverageAbsQYDiff           0.212681
2017-06-10 19:42:15.365064 EDT | AverageAction              0.861691
2017-06-10 19:42:15.365229 EDT | PolicyRegParamNorm        31.8183
2017-06-10 19:42:15.365412 EDT | QFunRegParamNorm          30.9528
2017-06-10 19:42:15.365603 EDT | -----------------------  ----------
2017-06-10 19:42:15.365870 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #60 | Training started
2017-06-10 19:42:30.522352 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #60 | Training finished
2017-06-10 19:42:30.523638 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #60 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 19:42:30.523856 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #60 | Collecting samples for evaluation
2017-06-10 19:42:42.377033 EDT | -----------------------  ----------
2017-06-10 19:42:42.377929 EDT | Epoch                     60
2017-06-10 19:42:42.378135 EDT | Iteration                 60
2017-06-10 19:42:42.378461 EDT | AverageReturn            349.465
2017-06-10 19:42:42.378983 EDT | StdReturn                 11.5928
2017-06-10 19:42:42.379767 EDT | MaxReturn                366.528
2017-06-10 19:42:42.380068 EDT | MinReturn                311.943
2017-06-10 19:42:42.380749 EDT | AverageEsReturn          165.26
2017-06-10 19:42:42.381121 EDT | StdEsReturn              132.73
2017-06-10 19:42:42.381524 EDT | MaxEsReturn              467.413
2017-06-10 19:42:42.381929 EDT | MinEsReturn               19.1295
2017-06-10 19:42:42.382169 EDT | AverageDiscountedReturn  171.121
2017-06-10 19:42:42.382804 EDT | AverageQLoss               0.246403
2017-06-10 19:42:42.383145 EDT | AveragePolicySurr         -8.83375
2017-06-10 19:42:42.383480 EDT | AverageQ                   8.4537
2017-06-10 19:42:42.383698 EDT | AverageAbsQ                8.46003
2017-06-10 19:42:42.384095 EDT | AverageY                   8.45562
2017-06-10 19:42:42.384461 EDT | AverageAbsY                8.45609
2017-06-10 19:42:42.385437 EDT | AverageAbsQYDiff           0.216085
2017-06-10 19:42:42.386352 EDT | AverageAction              0.829238
2017-06-10 19:42:42.386767 EDT | PolicyRegParamNorm        32.1081
2017-06-10 19:42:42.387102 EDT | QFunRegParamNorm          31.3258
2017-06-10 19:42:42.387450 EDT | -----------------------  ----------
2017-06-10 19:42:42.389392 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #61 | Training started
2017-06-10 19:42:57.301957 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #61 | Training finished
2017-06-10 19:42:57.302388 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #61 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 19:42:57.302733 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #61 | Collecting samples for evaluation
2017-06-10 19:43:09.146919 EDT | -----------------------  ----------
2017-06-10 19:43:09.148613 EDT | Epoch                     61
2017-06-10 19:43:09.148986 EDT | Iteration                 61
2017-06-10 19:43:09.149416 EDT | AverageReturn            280.278
2017-06-10 19:43:09.149732 EDT | StdReturn                 11.4203
2017-06-10 19:43:09.150167 EDT | MaxReturn                306.012
2017-06-10 19:43:09.150593 EDT | MinReturn                259.173
2017-06-10 19:43:09.151070 EDT | AverageEsReturn          237.44
2017-06-10 19:43:09.151453 EDT | StdEsReturn              127.748
2017-06-10 19:43:09.151826 EDT | MaxEsReturn              355.571
2017-06-10 19:43:09.152246 EDT | MinEsReturn               11.691
2017-06-10 19:43:09.152675 EDT | AverageDiscountedReturn  147.371
2017-06-10 19:43:09.153128 EDT | AverageQLoss               0.246452
2017-06-10 19:43:09.153530 EDT | AveragePolicySurr         -9.04317
2017-06-10 19:43:09.153972 EDT | AverageQ                   8.66642
2017-06-10 19:43:09.154392 EDT | AverageAbsQ                8.67179
2017-06-10 19:43:09.154721 EDT | AverageY                   8.66813
2017-06-10 19:43:09.155157 EDT | AverageAbsY                8.66865
2017-06-10 19:43:09.155637 EDT | AverageAbsQYDiff           0.21582
2017-06-10 19:43:09.156037 EDT | AverageAction              0.883038
2017-06-10 19:43:09.156379 EDT | PolicyRegParamNorm        32.4601
2017-06-10 19:43:09.156902 EDT | QFunRegParamNorm          31.6141
2017-06-10 19:43:09.157239 EDT | -----------------------  ----------
2017-06-10 19:43:09.157825 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #62 | Training started
2017-06-10 19:43:22.675965 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #62 | Training finished
2017-06-10 19:43:22.676978 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #62 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 19:43:22.677368 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #62 | Collecting samples for evaluation
2017-06-10 19:43:35.466436 EDT | -----------------------  ----------
2017-06-10 19:43:35.467479 EDT | Epoch                     62
2017-06-10 19:43:35.467854 EDT | Iteration                 62
2017-06-10 19:43:35.468117 EDT | AverageReturn            474.834
2017-06-10 19:43:35.468374 EDT | StdReturn                114.481
2017-06-10 19:43:35.468689 EDT | MaxReturn                731.26
2017-06-10 19:43:35.468944 EDT | MinReturn                302.557
2017-06-10 19:43:35.469188 EDT | AverageEsReturn          268.027
2017-06-10 19:43:35.469431 EDT | StdEsReturn               89.6949
2017-06-10 19:43:35.469796 EDT | MaxEsReturn              389.122
2017-06-10 19:43:35.470060 EDT | MinEsReturn               55.7439
2017-06-10 19:43:35.470315 EDT | AverageDiscountedReturn  189.115
2017-06-10 19:43:35.470566 EDT | AverageQLoss               0.273765
2017-06-10 19:43:35.470817 EDT | AveragePolicySurr         -9.20549
2017-06-10 19:43:35.471142 EDT | AverageQ                   8.83566
2017-06-10 19:43:35.473078 EDT | AverageAbsQ                8.84243
2017-06-10 19:43:35.473569 EDT | AverageY                   8.83724
2017-06-10 19:43:35.473913 EDT | AverageAbsY                8.83791
2017-06-10 19:43:35.474255 EDT | AverageAbsQYDiff           0.227336
2017-06-10 19:43:35.474583 EDT | AverageAction              0.865395
2017-06-10 19:43:35.475761 EDT | PolicyRegParamNorm        32.7689
2017-06-10 19:43:35.477278 EDT | QFunRegParamNorm          32.0395
2017-06-10 19:43:35.477560 EDT | -----------------------  ----------
2017-06-10 19:43:35.478750 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #63 | Training started
2017-06-10 19:43:49.203353 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #63 | Training finished
2017-06-10 19:43:49.204230 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #63 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 19:43:49.204523 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #63 | Collecting samples for evaluation
2017-06-10 19:44:01.660847 EDT | -----------------------  ----------
2017-06-10 19:44:01.661731 EDT | Epoch                     63
2017-06-10 19:44:01.662183 EDT | Iteration                 63
2017-06-10 19:44:01.662517 EDT | AverageReturn            343.867
2017-06-10 19:44:01.662843 EDT | StdReturn                  9.55171
2017-06-10 19:44:01.663178 EDT | MaxReturn                366.006
2017-06-10 19:44:01.663479 EDT | MinReturn                321.991
2017-06-10 19:44:01.663790 EDT | AverageEsReturn          267.855
2017-06-10 19:44:01.664503 EDT | StdEsReturn               92.1578
2017-06-10 19:44:01.664901 EDT | MaxEsReturn              367.324
2017-06-10 19:44:01.665380 EDT | MinEsReturn               61.6024
2017-06-10 19:44:01.665774 EDT | AverageDiscountedReturn  163.257
2017-06-10 19:44:01.666105 EDT | AverageQLoss               0.261765
2017-06-10 19:44:01.667073 EDT | AveragePolicySurr         -9.42159
2017-06-10 19:44:01.667524 EDT | AverageQ                   9.0393
2017-06-10 19:44:01.667798 EDT | AverageAbsQ                9.04577
2017-06-10 19:44:01.668125 EDT | AverageY                   9.04007
2017-06-10 19:44:01.668656 EDT | AverageAbsY                9.04128
2017-06-10 19:44:01.669083 EDT | AverageAbsQYDiff           0.221757
2017-06-10 19:44:01.669583 EDT | AverageAction              0.821225
2017-06-10 19:44:01.669887 EDT | PolicyRegParamNorm        33.1049
2017-06-10 19:44:01.670070 EDT | QFunRegParamNorm          32.3466
2017-06-10 19:44:01.670343 EDT | -----------------------  ----------
2017-06-10 19:44:01.671006 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #64 | Training started
2017-06-10 19:44:17.087240 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #64 | Training finished
2017-06-10 19:44:17.088363 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #64 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 19:44:17.088734 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #64 | Collecting samples for evaluation
2017-06-10 19:44:28.437320 EDT | -----------------------  ----------
2017-06-10 19:44:28.438204 EDT | Epoch                     64
2017-06-10 19:44:28.438430 EDT | Iteration                 64
2017-06-10 19:44:28.438621 EDT | AverageReturn            330.613
2017-06-10 19:44:28.439125 EDT | StdReturn                  4.0523
2017-06-10 19:44:28.439637 EDT | MaxReturn                339.656
2017-06-10 19:44:28.440263 EDT | MinReturn                321.132
2017-06-10 19:44:28.440709 EDT | AverageEsReturn          264.16
2017-06-10 19:44:28.441135 EDT | StdEsReturn              162.88
2017-06-10 19:44:28.441925 EDT | MaxEsReturn              625.251
2017-06-10 19:44:28.442965 EDT | MinEsReturn               21.3563
2017-06-10 19:44:28.443412 EDT | AverageDiscountedReturn  163.503
2017-06-10 19:44:28.443832 EDT | AverageQLoss               0.27946
2017-06-10 19:44:28.444358 EDT | AveragePolicySurr         -9.59672
2017-06-10 19:44:28.444778 EDT | AverageQ                   9.21963
2017-06-10 19:44:28.445201 EDT | AverageAbsQ                9.22784
2017-06-10 19:44:28.445700 EDT | AverageY                   9.221
2017-06-10 19:44:28.446121 EDT | AverageAbsY                9.222
2017-06-10 19:44:28.446598 EDT | AverageAbsQYDiff           0.235313
2017-06-10 19:44:28.447029 EDT | AverageAction              0.828854
2017-06-10 19:44:28.447448 EDT | PolicyRegParamNorm        33.3765
2017-06-10 19:44:28.447986 EDT | QFunRegParamNorm          32.6828
2017-06-10 19:44:28.448504 EDT | -----------------------  ----------
2017-06-10 19:44:28.449095 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #65 | Training started
2017-06-10 19:44:43.545370 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #65 | Training finished
2017-06-10 19:44:43.546425 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #65 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 19:44:43.546818 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #65 | Collecting samples for evaluation
2017-06-10 19:44:55.820561 EDT | -----------------------  ----------
2017-06-10 19:44:55.821666 EDT | Epoch                     65
2017-06-10 19:44:55.822091 EDT | Iteration                 65
2017-06-10 19:44:55.822387 EDT | AverageReturn            338.622
2017-06-10 19:44:55.822731 EDT | StdReturn                  8.00738
2017-06-10 19:44:55.823057 EDT | MaxReturn                351.8
2017-06-10 19:44:55.823459 EDT | MinReturn                312.777
2017-06-10 19:44:55.823788 EDT | AverageEsReturn          273.44
2017-06-10 19:44:55.824241 EDT | StdEsReturn               86.1115
2017-06-10 19:44:55.824515 EDT | MaxEsReturn              362.81
2017-06-10 19:44:55.824836 EDT | MinEsReturn               85.5122
2017-06-10 19:44:55.825167 EDT | AverageDiscountedReturn  167.931
2017-06-10 19:44:55.825488 EDT | AverageQLoss               0.290125
2017-06-10 19:44:55.825817 EDT | AveragePolicySurr         -9.84412
2017-06-10 19:44:55.826082 EDT | AverageQ                   9.46942
2017-06-10 19:44:55.826299 EDT | AverageAbsQ                9.47651
2017-06-10 19:44:55.826614 EDT | AverageY                   9.47131
2017-06-10 19:44:55.826808 EDT | AverageAbsY                9.47275
2017-06-10 19:44:55.827129 EDT | AverageAbsQYDiff           0.236988
2017-06-10 19:44:55.827620 EDT | AverageAction              0.812254
2017-06-10 19:44:55.828213 EDT | PolicyRegParamNorm        33.6194
2017-06-10 19:44:55.828725 EDT | QFunRegParamNorm          33.0634
2017-06-10 19:44:55.829134 EDT | -----------------------  ----------
2017-06-10 19:44:55.829987 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #66 | Training started
2017-06-10 19:45:10.039551 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #66 | Training finished
2017-06-10 19:45:10.040356 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #66 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 19:45:10.040863 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #66 | Collecting samples for evaluation
2017-06-10 19:45:23.034602 EDT | -----------------------  ----------
2017-06-10 19:45:23.035406 EDT | Epoch                     66
2017-06-10 19:45:23.035754 EDT | Iteration                 66
2017-06-10 19:45:23.036113 EDT | AverageReturn            350.872
2017-06-10 19:45:23.036286 EDT | StdReturn                 10.7794
2017-06-10 19:45:23.036442 EDT | MaxReturn                374.698
2017-06-10 19:45:23.036596 EDT | MinReturn                335.02
2017-06-10 19:45:23.036747 EDT | AverageEsReturn          233.256
2017-06-10 19:45:23.036933 EDT | StdEsReturn              132.239
2017-06-10 19:45:23.037211 EDT | MaxEsReturn              370.875
2017-06-10 19:45:23.037498 EDT | MinEsReturn               20.9247
2017-06-10 19:45:23.037725 EDT | AverageDiscountedReturn  172.49
2017-06-10 19:45:23.037883 EDT | AverageQLoss               0.291999
2017-06-10 19:45:23.038037 EDT | AveragePolicySurr        -10.0337
2017-06-10 19:45:23.038189 EDT | AverageQ                   9.64245
2017-06-10 19:45:23.038380 EDT | AverageAbsQ                9.65069
2017-06-10 19:45:23.038533 EDT | AverageY                   9.64411
2017-06-10 19:45:23.038683 EDT | AverageAbsY                9.64502
2017-06-10 19:45:23.038833 EDT | AverageAbsQYDiff           0.242503
2017-06-10 19:45:23.038983 EDT | AverageAction              0.833276
2017-06-10 19:45:23.039133 EDT | PolicyRegParamNorm        33.9113
2017-06-10 19:45:23.039282 EDT | QFunRegParamNorm          33.3938
2017-06-10 19:45:23.039432 EDT | -----------------------  ----------
2017-06-10 19:45:23.039685 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #67 | Training started
2017-06-10 19:45:37.086119 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #67 | Training finished
2017-06-10 19:45:37.087282 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #67 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 19:45:37.087947 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #67 | Collecting samples for evaluation
2017-06-10 19:45:49.738391 EDT | -----------------------  ----------
2017-06-10 19:45:49.739149 EDT | Epoch                     67
2017-06-10 19:45:49.739877 EDT | Iteration                 67
2017-06-10 19:45:49.740292 EDT | AverageReturn            335.137
2017-06-10 19:45:49.740639 EDT | StdReturn                  4.88487
2017-06-10 19:45:49.742491 EDT | MaxReturn                344.487
2017-06-10 19:45:49.743005 EDT | MinReturn                321.057
2017-06-10 19:45:49.743425 EDT | AverageEsReturn          226.918
2017-06-10 19:45:49.743795 EDT | StdEsReturn              115.06
2017-06-10 19:45:49.744184 EDT | MaxEsReturn              361.906
2017-06-10 19:45:49.744539 EDT | MinEsReturn               26.1932
2017-06-10 19:45:49.745038 EDT | AverageDiscountedReturn  169.173
2017-06-10 19:45:49.745767 EDT | AverageQLoss               0.288856
2017-06-10 19:45:49.746131 EDT | AveragePolicySurr        -10.2534
2017-06-10 19:45:49.746504 EDT | AverageQ                   9.86534
2017-06-10 19:45:49.746817 EDT | AverageAbsQ                9.87304
2017-06-10 19:45:49.747187 EDT | AverageY                   9.86723
2017-06-10 19:45:49.747550 EDT | AverageAbsY                9.86834
2017-06-10 19:45:49.747906 EDT | AverageAbsQYDiff           0.238803
2017-06-10 19:45:49.748246 EDT | AverageAction              0.752571
2017-06-10 19:45:49.748608 EDT | PolicyRegParamNorm        34.049
2017-06-10 19:45:49.748895 EDT | QFunRegParamNorm          33.6501
2017-06-10 19:45:49.749063 EDT | -----------------------  ----------
2017-06-10 19:45:49.749346 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #68 | Training started
2017-06-10 19:46:04.386019 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #68 | Training finished
2017-06-10 19:46:04.386866 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #68 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 19:46:04.387323 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #68 | Collecting samples for evaluation
2017-06-10 19:46:16.104290 EDT | -----------------------  ----------
2017-06-10 19:46:16.107754 EDT | Epoch                     68
2017-06-10 19:46:16.108197 EDT | Iteration                 68
2017-06-10 19:46:16.108634 EDT | AverageReturn            351.804
2017-06-10 19:46:16.109051 EDT | StdReturn                  5.7435
2017-06-10 19:46:16.109473 EDT | MaxReturn                366.692
2017-06-10 19:46:16.109865 EDT | MinReturn                337.853
2017-06-10 19:46:16.110393 EDT | AverageEsReturn          245.943
2017-06-10 19:46:16.110814 EDT | StdEsReturn              126.798
2017-06-10 19:46:16.111236 EDT | MaxEsReturn              407.731
2017-06-10 19:46:16.111655 EDT | MinEsReturn               11.2026
2017-06-10 19:46:16.112134 EDT | AverageDiscountedReturn  170.793
2017-06-10 19:46:16.112552 EDT | AverageQLoss               0.351344
2017-06-10 19:46:16.112972 EDT | AveragePolicySurr        -10.47
2017-06-10 19:46:16.113406 EDT | AverageQ                  10.0771
2017-06-10 19:46:16.113834 EDT | AverageAbsQ               10.0863
2017-06-10 19:46:16.114507 EDT | AverageY                  10.0783
2017-06-10 19:46:16.114990 EDT | AverageAbsY               10.0795
2017-06-10 19:46:16.115310 EDT | AverageAbsQYDiff           0.255727
2017-06-10 19:46:16.117282 EDT | AverageAction              0.720384
2017-06-10 19:46:16.117506 EDT | PolicyRegParamNorm        34.2793
2017-06-10 19:46:16.118067 EDT | QFunRegParamNorm          33.9349
2017-06-10 19:46:16.118459 EDT | -----------------------  ----------
2017-06-10 19:46:16.119003 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #69 | Training started
2017-06-10 19:46:31.312560 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #69 | Training finished
2017-06-10 19:46:31.315623 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #69 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 19:46:31.315949 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #69 | Collecting samples for evaluation
2017-06-10 19:46:43.202761 EDT | -----------------------  ----------
2017-06-10 19:46:43.203717 EDT | Epoch                     69
2017-06-10 19:46:43.204005 EDT | Iteration                 69
2017-06-10 19:46:43.204180 EDT | AverageReturn            292.031
2017-06-10 19:46:43.204347 EDT | StdReturn                  8.72219
2017-06-10 19:46:43.204540 EDT | MaxReturn                307.435
2017-06-10 19:46:43.204817 EDT | MinReturn                267.407
2017-06-10 19:46:43.205368 EDT | AverageEsReturn          209.292
2017-06-10 19:46:43.205607 EDT | StdEsReturn              123.649
2017-06-10 19:46:43.205888 EDT | MaxEsReturn              366.196
2017-06-10 19:46:43.206141 EDT | MinEsReturn                6.71776
2017-06-10 19:46:43.206347 EDT | AverageDiscountedReturn  154.515
2017-06-10 19:46:43.206552 EDT | AverageQLoss               0.278544
2017-06-10 19:46:43.206774 EDT | AveragePolicySurr        -10.6785
2017-06-10 19:46:43.206932 EDT | AverageQ                  10.2701
2017-06-10 19:46:43.207095 EDT | AverageAbsQ               10.2774
2017-06-10 19:46:43.207318 EDT | AverageY                  10.2717
2017-06-10 19:46:43.207477 EDT | AverageAbsY               10.2734
2017-06-10 19:46:43.207666 EDT | AverageAbsQYDiff           0.242937
2017-06-10 19:46:43.207877 EDT | AverageAction              0.732167
2017-06-10 19:46:43.208089 EDT | PolicyRegParamNorm        34.4734
2017-06-10 19:46:43.208344 EDT | QFunRegParamNorm          34.2363
2017-06-10 19:46:43.208564 EDT | -----------------------  ----------
2017-06-10 19:46:43.208933 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #70 | Training started
2017-06-10 19:46:58.224516 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #70 | Training finished
2017-06-10 19:46:58.225396 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #70 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 19:46:58.225792 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #70 | Collecting samples for evaluation
2017-06-10 19:47:10.683965 EDT | -----------------------  ----------
2017-06-10 19:47:10.684957 EDT | Epoch                     70
2017-06-10 19:47:10.685322 EDT | Iteration                 70
2017-06-10 19:47:10.685577 EDT | AverageReturn            305.762
2017-06-10 19:47:10.685780 EDT | StdReturn                  7.3985
2017-06-10 19:47:10.685966 EDT | MaxReturn                320.973
2017-06-10 19:47:10.686178 EDT | MinReturn                291.387
2017-06-10 19:47:10.686346 EDT | AverageEsReturn          171.379
2017-06-10 19:47:10.686570 EDT | StdEsReturn              124.599
2017-06-10 19:47:10.686732 EDT | MaxEsReturn              347.194
2017-06-10 19:47:10.686922 EDT | MinEsReturn                3.8938
2017-06-10 19:47:10.687084 EDT | AverageDiscountedReturn  157.953
2017-06-10 19:47:10.687242 EDT | AverageQLoss               0.334862
2017-06-10 19:47:10.687405 EDT | AveragePolicySurr        -10.9373
2017-06-10 19:47:10.687587 EDT | AverageQ                  10.5158
2017-06-10 19:47:10.687746 EDT | AverageAbsQ               10.5252
2017-06-10 19:47:10.687943 EDT | AverageY                  10.5173
2017-06-10 19:47:10.688101 EDT | AverageAbsY               10.5182
2017-06-10 19:47:10.688263 EDT | AverageAbsQYDiff           0.259604
2017-06-10 19:47:10.688466 EDT | AverageAction              0.73169
2017-06-10 19:47:10.688640 EDT | PolicyRegParamNorm        34.6836
2017-06-10 19:47:10.688797 EDT | QFunRegParamNorm          34.6108
2017-06-10 19:47:10.688959 EDT | -----------------------  ----------
2017-06-10 19:47:10.689218 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #71 | Training started
2017-06-10 19:47:24.368604 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #71 | Training finished
2017-06-10 19:47:24.369604 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #71 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 19:47:24.369941 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #71 | Collecting samples for evaluation
2017-06-10 19:47:36.785187 EDT | -----------------------  ----------
2017-06-10 19:47:36.787336 EDT | Epoch                     71
2017-06-10 19:47:36.787856 EDT | Iteration                 71
2017-06-10 19:47:36.788340 EDT | AverageReturn            313.705
2017-06-10 19:47:36.788824 EDT | StdReturn                  3.71368
2017-06-10 19:47:36.789210 EDT | MaxReturn                321.336
2017-06-10 19:47:36.789588 EDT | MinReturn                303.459
2017-06-10 19:47:36.792562 EDT | AverageEsReturn          218.311
2017-06-10 19:47:36.792981 EDT | StdEsReturn               97.9466
2017-06-10 19:47:36.793364 EDT | MaxEsReturn              300.785
2017-06-10 19:47:36.793752 EDT | MinEsReturn               12.123
2017-06-10 19:47:36.794205 EDT | AverageDiscountedReturn  160.132
2017-06-10 19:47:36.795015 EDT | AverageQLoss               0.309673
2017-06-10 19:47:36.795403 EDT | AveragePolicySurr        -11.1121
2017-06-10 19:47:36.795781 EDT | AverageQ                  10.719
2017-06-10 19:47:36.797166 EDT | AverageAbsQ               10.7256
2017-06-10 19:47:36.797570 EDT | AverageY                  10.7213
2017-06-10 19:47:36.797964 EDT | AverageAbsY               10.7223
2017-06-10 19:47:36.798341 EDT | AverageAbsQYDiff           0.251822
2017-06-10 19:47:36.798719 EDT | AverageAction              0.748253
2017-06-10 19:47:36.799101 EDT | PolicyRegParamNorm        34.9103
2017-06-10 19:47:36.799480 EDT | QFunRegParamNorm          34.9298
2017-06-10 19:47:36.799859 EDT | -----------------------  ----------
2017-06-10 19:47:36.800414 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #72 | Training started
2017-06-10 19:47:51.883217 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #72 | Training finished
2017-06-10 19:47:51.885041 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #72 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 19:47:51.885297 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #72 | Collecting samples for evaluation
2017-06-10 19:48:03.764958 EDT | -----------------------  ----------
2017-06-10 19:48:03.765842 EDT | Epoch                     72
2017-06-10 19:48:03.766191 EDT | Iteration                 72
2017-06-10 19:48:03.766627 EDT | AverageReturn            280.639
2017-06-10 19:48:03.767068 EDT | StdReturn                  8.35476
2017-06-10 19:48:03.767478 EDT | MaxReturn                295.955
2017-06-10 19:48:03.767788 EDT | MinReturn                264.071
2017-06-10 19:48:03.768592 EDT | AverageEsReturn          201.988
2017-06-10 19:48:03.769019 EDT | StdEsReturn              116.967
2017-06-10 19:48:03.769482 EDT | MaxEsReturn              324.347
2017-06-10 19:48:03.769920 EDT | MinEsReturn               11.0168
2017-06-10 19:48:03.770276 EDT | AverageDiscountedReturn  149.142
2017-06-10 19:48:03.770755 EDT | AverageQLoss               0.331143
2017-06-10 19:48:03.771185 EDT | AveragePolicySurr        -11.3148
2017-06-10 19:48:03.771517 EDT | AverageQ                  10.9119
2017-06-10 19:48:03.771803 EDT | AverageAbsQ               10.9197
2017-06-10 19:48:03.772697 EDT | AverageY                  10.9127
2017-06-10 19:48:03.773041 EDT | AverageAbsY               10.9137
2017-06-10 19:48:03.773566 EDT | AverageAbsQYDiff           0.255276
2017-06-10 19:48:03.773954 EDT | AverageAction              0.728657
2017-06-10 19:48:03.774142 EDT | PolicyRegParamNorm        35.1212
2017-06-10 19:48:03.774491 EDT | QFunRegParamNorm          35.1911
2017-06-10 19:48:03.774815 EDT | -----------------------  ----------
2017-06-10 19:48:03.775396 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #73 | Training started
2017-06-10 19:48:18.902280 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #73 | Training finished
2017-06-10 19:48:18.903060 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #73 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 19:48:18.903271 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #73 | Collecting samples for evaluation
2017-06-10 19:48:30.892626 EDT | -----------------------  ----------
2017-06-10 19:48:30.893945 EDT | Epoch                     73
2017-06-10 19:48:30.894596 EDT | Iteration                 73
2017-06-10 19:48:30.894770 EDT | AverageReturn            292.651
2017-06-10 19:48:30.894967 EDT | StdReturn                  9.12106
2017-06-10 19:48:30.895152 EDT | MaxReturn                310.289
2017-06-10 19:48:30.895336 EDT | MinReturn                273.787
2017-06-10 19:48:30.895517 EDT | AverageEsReturn          178.292
2017-06-10 19:48:30.895697 EDT | StdEsReturn              112.64
2017-06-10 19:48:30.895879 EDT | MaxEsReturn              333.746
2017-06-10 19:48:30.896058 EDT | MinEsReturn               11.9332
2017-06-10 19:48:30.896238 EDT | AverageDiscountedReturn  154.284
2017-06-10 19:48:30.896417 EDT | AverageQLoss               0.427386
2017-06-10 19:48:30.896596 EDT | AveragePolicySurr        -11.5236
2017-06-10 19:48:30.896775 EDT | AverageQ                  11.1012
2017-06-10 19:48:30.896954 EDT | AverageAbsQ               11.1107
2017-06-10 19:48:30.897131 EDT | AverageY                  11.1035
2017-06-10 19:48:30.897310 EDT | AverageAbsY               11.1047
2017-06-10 19:48:30.897488 EDT | AverageAbsQYDiff           0.295854
2017-06-10 19:48:30.897665 EDT | AverageAction              0.77659
2017-06-10 19:48:30.897918 EDT | PolicyRegParamNorm        35.341
2017-06-10 19:48:30.898240 EDT | QFunRegParamNorm          35.6415
2017-06-10 19:48:30.898648 EDT | -----------------------  ----------
2017-06-10 19:48:30.899197 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #74 | Training started
2017-06-10 19:48:45.481193 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #74 | Training finished
2017-06-10 19:48:45.481493 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #74 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 19:48:45.481689 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #74 | Collecting samples for evaluation
2017-06-10 19:48:57.867937 EDT | -----------------------  ----------
2017-06-10 19:48:57.869010 EDT | Epoch                     74
2017-06-10 19:48:57.869471 EDT | Iteration                 74
2017-06-10 19:48:57.869659 EDT | AverageReturn            315.066
2017-06-10 19:48:57.869980 EDT | StdReturn                  7.47309
2017-06-10 19:48:57.870279 EDT | MaxReturn                332.707
2017-06-10 19:48:57.870603 EDT | MinReturn                295.422
2017-06-10 19:48:57.870975 EDT | AverageEsReturn          160.495
2017-06-10 19:48:57.871327 EDT | StdEsReturn              121.475
2017-06-10 19:48:57.871669 EDT | MaxEsReturn              334.438
2017-06-10 19:48:57.871989 EDT | MinEsReturn                9.65343
2017-06-10 19:48:57.872301 EDT | AverageDiscountedReturn  158.61
2017-06-10 19:48:57.872637 EDT | AverageQLoss               0.375319
2017-06-10 19:48:57.872809 EDT | AveragePolicySurr        -11.7245
2017-06-10 19:48:57.873009 EDT | AverageQ                  11.3108
2017-06-10 19:48:57.873178 EDT | AverageAbsQ               11.3194
2017-06-10 19:48:57.873358 EDT | AverageY                  11.3133
2017-06-10 19:48:57.873516 EDT | AverageAbsY               11.3153
2017-06-10 19:48:57.873673 EDT | AverageAbsQYDiff           0.268817
2017-06-10 19:48:57.873846 EDT | AverageAction              0.775523
2017-06-10 19:48:57.874028 EDT | PolicyRegParamNorm        35.6084
2017-06-10 19:48:57.874583 EDT | QFunRegParamNorm          35.9814
2017-06-10 19:48:57.874922 EDT | -----------------------  ----------
2017-06-10 19:48:57.875214 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #75 | Training started
2017-06-10 19:49:11.495211 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #75 | Training finished
2017-06-10 19:49:11.497749 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #75 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 19:49:11.498059 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #75 | Collecting samples for evaluation
2017-06-10 19:49:24.524550 EDT | -----------------------  ----------
2017-06-10 19:49:24.525872 EDT | Epoch                     75
2017-06-10 19:49:24.526141 EDT | Iteration                 75
2017-06-10 19:49:24.526338 EDT | AverageReturn            288.414
2017-06-10 19:49:24.526524 EDT | StdReturn                 10.2982
2017-06-10 19:49:24.526922 EDT | MaxReturn                311.659
2017-06-10 19:49:24.527101 EDT | MinReturn                264.331
2017-06-10 19:49:24.527330 EDT | AverageEsReturn          228.56
2017-06-10 19:49:24.527652 EDT | StdEsReturn              114.476
2017-06-10 19:49:24.527880 EDT | MaxEsReturn              333.399
2017-06-10 19:49:24.528063 EDT | MinEsReturn                8.18322
2017-06-10 19:49:24.528312 EDT | AverageDiscountedReturn  151.533
2017-06-10 19:49:24.528490 EDT | AverageQLoss               0.444535
2017-06-10 19:49:24.528685 EDT | AveragePolicySurr        -11.9806
2017-06-10 19:49:24.528863 EDT | AverageQ                  11.5401
2017-06-10 19:49:24.529064 EDT | AverageAbsQ               11.5494
2017-06-10 19:49:24.529245 EDT | AverageY                  11.5417
2017-06-10 19:49:24.529423 EDT | AverageAbsY               11.5423
2017-06-10 19:49:24.529601 EDT | AverageAbsQYDiff           0.291437
2017-06-10 19:49:24.529822 EDT | AverageAction              0.771341
2017-06-10 19:49:24.530004 EDT | PolicyRegParamNorm        35.882
2017-06-10 19:49:24.530183 EDT | QFunRegParamNorm          36.3346
2017-06-10 19:49:24.530362 EDT | -----------------------  ----------
2017-06-10 19:49:24.531590 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #76 | Training started
2017-06-10 19:49:38.975274 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #76 | Training finished
2017-06-10 19:49:38.976085 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #76 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 19:49:38.976460 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #76 | Collecting samples for evaluation
2017-06-10 19:49:51.242045 EDT | -----------------------  ----------
2017-06-10 19:49:51.243006 EDT | Epoch                     76
2017-06-10 19:49:51.243458 EDT | Iteration                 76
2017-06-10 19:49:51.243886 EDT | AverageReturn            297.012
2017-06-10 19:49:51.244236 EDT | StdReturn                  5.72553
2017-06-10 19:49:51.244663 EDT | MaxReturn                306.895
2017-06-10 19:49:51.245094 EDT | MinReturn                282.192
2017-06-10 19:49:51.245497 EDT | AverageEsReturn          273.266
2017-06-10 19:49:51.246329 EDT | StdEsReturn               75.3261
2017-06-10 19:49:51.246762 EDT | MaxEsReturn              351.812
2017-06-10 19:49:51.247838 EDT | MinEsReturn              110.299
2017-06-10 19:49:51.248334 EDT | AverageDiscountedReturn  150.098
2017-06-10 19:49:51.252529 EDT | AverageQLoss               0.416611
2017-06-10 19:49:51.252950 EDT | AveragePolicySurr        -12.0975
2017-06-10 19:49:51.253396 EDT | AverageQ                  11.6632
2017-06-10 19:49:51.253821 EDT | AverageAbsQ               11.6724
2017-06-10 19:49:51.254172 EDT | AverageY                  11.6647
2017-06-10 19:49:51.254601 EDT | AverageAbsY               11.6656
2017-06-10 19:49:51.255035 EDT | AverageAbsQYDiff           0.286712
2017-06-10 19:49:51.255416 EDT | AverageAction              0.774939
2017-06-10 19:49:51.255769 EDT | PolicyRegParamNorm        36.1762
2017-06-10 19:49:51.256385 EDT | QFunRegParamNorm          36.6649
2017-06-10 19:49:51.258914 EDT | -----------------------  ----------
2017-06-10 19:49:51.260196 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #77 | Training started
2017-06-10 19:50:05.916023 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #77 | Training finished
2017-06-10 19:50:05.953097 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #77 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 19:50:05.953369 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #77 | Collecting samples for evaluation
2017-06-10 19:50:17.415095 EDT | -----------------------  ----------
2017-06-10 19:50:17.415546 EDT | Epoch                     77
2017-06-10 19:50:17.415891 EDT | Iteration                 77
2017-06-10 19:50:17.416222 EDT | AverageReturn            293.949
2017-06-10 19:50:17.416556 EDT | StdReturn                  8.87383
2017-06-10 19:50:17.416893 EDT | MaxReturn                308.628
2017-06-10 19:50:17.417191 EDT | MinReturn                274.26
2017-06-10 19:50:17.417450 EDT | AverageEsReturn          256.658
2017-06-10 19:50:17.417789 EDT | StdEsReturn               78.0071
2017-06-10 19:50:17.418116 EDT | MaxEsReturn              321.48
2017-06-10 19:50:17.418449 EDT | MinEsReturn               46.0915
2017-06-10 19:50:17.418780 EDT | AverageDiscountedReturn  154.473
2017-06-10 19:50:17.419101 EDT | AverageQLoss               0.384596
2017-06-10 19:50:17.419441 EDT | AveragePolicySurr        -12.3992
2017-06-10 19:50:17.419765 EDT | AverageQ                  11.9652
2017-06-10 19:50:17.420095 EDT | AverageAbsQ               11.9731
2017-06-10 19:50:17.420426 EDT | AverageY                  11.9668
2017-06-10 19:50:17.420796 EDT | AverageAbsY               11.9678
2017-06-10 19:50:17.421178 EDT | AverageAbsQYDiff           0.284109
2017-06-10 19:50:17.421504 EDT | AverageAction              0.812641
2017-06-10 19:50:17.421849 EDT | PolicyRegParamNorm        36.3686
2017-06-10 19:50:17.422169 EDT | QFunRegParamNorm          36.9927
2017-06-10 19:50:17.422503 EDT | -----------------------  ----------
2017-06-10 19:50:17.422981 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #78 | Training started
2017-06-10 19:50:32.573138 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #78 | Training finished
2017-06-10 19:50:32.574046 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #78 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 19:50:32.574456 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #78 | Collecting samples for evaluation
2017-06-10 19:50:45.332001 EDT | -----------------------  ----------
2017-06-10 19:50:45.332848 EDT | Epoch                     78
2017-06-10 19:50:45.333200 EDT | Iteration                 78
2017-06-10 19:50:45.333465 EDT | AverageReturn            301.914
2017-06-10 19:50:45.333781 EDT | StdReturn                 10.8216
2017-06-10 19:50:45.334122 EDT | MaxReturn                322.408
2017-06-10 19:50:45.334454 EDT | MinReturn                280.163
2017-06-10 19:50:45.334720 EDT | AverageEsReturn          225.726
2017-06-10 19:50:45.335009 EDT | StdEsReturn              107.247
2017-06-10 19:50:45.335336 EDT | MaxEsReturn              354.818
2017-06-10 19:50:45.335672 EDT | MinEsReturn               12.1181
2017-06-10 19:50:45.335946 EDT | AverageDiscountedReturn  156.686
2017-06-10 19:50:45.336222 EDT | AverageQLoss               0.398511
2017-06-10 19:50:45.336547 EDT | AveragePolicySurr        -12.6645
2017-06-10 19:50:45.336884 EDT | AverageQ                  12.232
2017-06-10 19:50:45.337173 EDT | AverageAbsQ               12.241
2017-06-10 19:50:45.337436 EDT | AverageY                  12.2339
2017-06-10 19:50:45.337771 EDT | AverageAbsY               12.2346
2017-06-10 19:50:45.338108 EDT | AverageAbsQYDiff           0.290319
2017-06-10 19:50:45.338406 EDT | AverageAction              0.830497
2017-06-10 19:50:45.338665 EDT | PolicyRegParamNorm        36.5944
2017-06-10 19:50:45.338996 EDT | QFunRegParamNorm          37.2835
2017-06-10 19:50:45.339330 EDT | -----------------------  ----------
2017-06-10 19:50:45.339767 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #79 | Training started
2017-06-10 19:50:59.410204 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #79 | Training finished
2017-06-10 19:50:59.411080 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #79 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 19:50:59.411319 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #79 | Collecting samples for evaluation
2017-06-10 19:51:11.996485 EDT | -----------------------  ----------
2017-06-10 19:51:11.997738 EDT | Epoch                     79
2017-06-10 19:51:11.998037 EDT | Iteration                 79
2017-06-10 19:51:11.998295 EDT | AverageReturn            307.991
2017-06-10 19:51:11.998638 EDT | StdReturn                 27.5738
2017-06-10 19:51:11.998812 EDT | MaxReturn                390.734
2017-06-10 19:51:11.998966 EDT | MinReturn                264.695
2017-06-10 19:51:11.999173 EDT | AverageEsReturn          163.94
2017-06-10 19:51:11.999339 EDT | StdEsReturn              122.277
2017-06-10 19:51:11.999505 EDT | MaxEsReturn              320.477
2017-06-10 19:51:11.999660 EDT | MinEsReturn                8.9105
2017-06-10 19:51:11.999884 EDT | AverageDiscountedReturn  158.831
2017-06-10 19:51:12.000036 EDT | AverageQLoss               0.441315
2017-06-10 19:51:12.000186 EDT | AveragePolicySurr        -12.7981
2017-06-10 19:51:12.000393 EDT | AverageQ                  12.3686
2017-06-10 19:51:12.000546 EDT | AverageAbsQ               12.3779
2017-06-10 19:51:12.000695 EDT | AverageY                  12.3711
2017-06-10 19:51:12.000843 EDT | AverageAbsY               12.3721
2017-06-10 19:51:12.001036 EDT | AverageAbsQYDiff           0.295459
2017-06-10 19:51:12.001188 EDT | AverageAction              0.807074
2017-06-10 19:51:12.001345 EDT | PolicyRegParamNorm        36.7417
2017-06-10 19:51:12.001495 EDT | QFunRegParamNorm          37.6065
2017-06-10 19:51:12.001643 EDT | -----------------------  ----------
2017-06-10 19:51:12.002092 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #80 | Training started
2017-06-10 19:51:26.805799 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #80 | Training finished
2017-06-10 19:51:26.818313 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #80 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 19:51:26.818782 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #80 | Collecting samples for evaluation
2017-06-10 19:51:38.716115 EDT | -----------------------  ----------
2017-06-10 19:51:38.716949 EDT | Epoch                     80
2017-06-10 19:51:38.717237 EDT | Iteration                 80
2017-06-10 19:51:38.717495 EDT | AverageReturn            384.098
2017-06-10 19:51:38.717757 EDT | StdReturn                 32.1664
2017-06-10 19:51:38.718008 EDT | MaxReturn                448.227
2017-06-10 19:51:38.718256 EDT | MinReturn                322.131
2017-06-10 19:51:38.718503 EDT | AverageEsReturn          210.943
2017-06-10 19:51:38.718750 EDT | StdEsReturn              101.997
2017-06-10 19:51:38.718997 EDT | MaxEsReturn              386.916
2017-06-10 19:51:38.719243 EDT | MinEsReturn               52.1042
2017-06-10 19:51:38.719490 EDT | AverageDiscountedReturn  180.472
2017-06-10 19:51:38.719737 EDT | AverageQLoss               0.452081
2017-06-10 19:51:38.719982 EDT | AveragePolicySurr        -13.0387
2017-06-10 19:51:38.720227 EDT | AverageQ                  12.5697
2017-06-10 19:51:38.720472 EDT | AverageAbsQ               12.5796
2017-06-10 19:51:38.720718 EDT | AverageY                  12.5713
2017-06-10 19:51:38.720962 EDT | AverageAbsY               12.5719
2017-06-10 19:51:38.721206 EDT | AverageAbsQYDiff           0.304457
2017-06-10 19:51:38.721455 EDT | AverageAction              0.795282
2017-06-10 19:51:38.721707 EDT | PolicyRegParamNorm        36.9056
2017-06-10 19:51:38.721959 EDT | QFunRegParamNorm          37.9442
2017-06-10 19:51:38.722205 EDT | -----------------------  ----------
2017-06-10 19:51:38.722574 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #81 | Training started
2017-06-10 19:51:54.590120 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #81 | Training finished
2017-06-10 19:51:54.590520 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #81 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 19:51:54.590860 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #81 | Collecting samples for evaluation
2017-06-10 19:52:06.568865 EDT | -----------------------  ----------
2017-06-10 19:52:06.569661 EDT | Epoch                     81
2017-06-10 19:52:06.569939 EDT | Iteration                 81
2017-06-10 19:52:06.570190 EDT | AverageReturn            340.448
2017-06-10 19:52:06.570438 EDT | StdReturn                 11.7329
2017-06-10 19:52:06.570684 EDT | MaxReturn                367.417
2017-06-10 19:52:06.570928 EDT | MinReturn                309.904
2017-06-10 19:52:06.571172 EDT | AverageEsReturn          288.555
2017-06-10 19:52:06.571414 EDT | StdEsReturn              111.813
2017-06-10 19:52:06.571656 EDT | MaxEsReturn              425.234
2017-06-10 19:52:06.571897 EDT | MinEsReturn                9.56235
2017-06-10 19:52:06.572138 EDT | AverageDiscountedReturn  169.393
2017-06-10 19:52:06.572379 EDT | AverageQLoss               0.537056
2017-06-10 19:52:06.572619 EDT | AveragePolicySurr        -13.3152
2017-06-10 19:52:06.572860 EDT | AverageQ                  12.8423
2017-06-10 19:52:06.573101 EDT | AverageAbsQ               12.8515
2017-06-10 19:52:06.573351 EDT | AverageY                  12.8444
2017-06-10 19:52:06.573594 EDT | AverageAbsY               12.8456
2017-06-10 19:52:06.573869 EDT | AverageAbsQYDiff           0.319718
2017-06-10 19:52:06.574183 EDT | AverageAction              0.793261
2017-06-10 19:52:06.574489 EDT | PolicyRegParamNorm        37.0751
2017-06-10 19:52:06.574755 EDT | QFunRegParamNorm          38.2581
2017-06-10 19:52:06.575005 EDT | -----------------------  ----------
2017-06-10 19:52:06.575367 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #82 | Training started
2017-06-10 19:52:22.230187 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #82 | Training finished
2017-06-10 19:52:22.231137 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #82 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 19:52:22.231520 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #82 | Collecting samples for evaluation
2017-06-10 19:52:35.104384 EDT | -----------------------  ----------
2017-06-10 19:52:35.105350 EDT | Epoch                     82
2017-06-10 19:52:35.105736 EDT | Iteration                 82
2017-06-10 19:52:35.106089 EDT | AverageReturn            362.923
2017-06-10 19:52:35.106436 EDT | StdReturn                 29.4988
2017-06-10 19:52:35.106778 EDT | MaxReturn                461.571
2017-06-10 19:52:35.107120 EDT | MinReturn                303.234
2017-06-10 19:52:35.107463 EDT | AverageEsReturn          223.547
2017-06-10 19:52:35.107809 EDT | StdEsReturn               88.95
2017-06-10 19:52:35.108151 EDT | MaxEsReturn              319.147
2017-06-10 19:52:35.108597 EDT | MinEsReturn               10.3872
2017-06-10 19:52:35.109047 EDT | AverageDiscountedReturn  174.412
2017-06-10 19:52:35.109400 EDT | AverageQLoss               0.521231
2017-06-10 19:52:35.109860 EDT | AveragePolicySurr        -13.5392
2017-06-10 19:52:35.110311 EDT | AverageQ                  13.0676
2017-06-10 19:52:35.110665 EDT | AverageAbsQ               13.0775
2017-06-10 19:52:35.111008 EDT | AverageY                  13.0693
2017-06-10 19:52:35.111453 EDT | AverageAbsY               13.0704
2017-06-10 19:52:35.122652 EDT | AverageAbsQYDiff           0.316714
2017-06-10 19:52:35.123198 EDT | AverageAction              0.77257
2017-06-10 19:52:35.123654 EDT | PolicyRegParamNorm        37.2164
2017-06-10 19:52:35.124103 EDT | QFunRegParamNorm          38.5466
2017-06-10 19:52:35.124553 EDT | -----------------------  ----------
2017-06-10 19:52:35.125149 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #83 | Training started
2017-06-10 19:52:49.713358 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #83 | Training finished
2017-06-10 19:52:49.714369 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #83 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 19:52:49.714737 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #83 | Collecting samples for evaluation
2017-06-10 19:53:02.282484 EDT | -----------------------  ----------
2017-06-10 19:53:02.283298 EDT | Epoch                     83
2017-06-10 19:53:02.283566 EDT | Iteration                 83
2017-06-10 19:53:02.283815 EDT | AverageReturn            291.448
2017-06-10 19:53:02.284060 EDT | StdReturn                  3.64924
2017-06-10 19:53:02.284398 EDT | MaxReturn                302.269
2017-06-10 19:53:02.284729 EDT | MinReturn                284.219
2017-06-10 19:53:02.285063 EDT | AverageEsReturn          257.789
2017-06-10 19:53:02.285390 EDT | StdEsReturn              104.855
2017-06-10 19:53:02.285729 EDT | MaxEsReturn              361.123
2017-06-10 19:53:02.286057 EDT | MinEsReturn               12.128
2017-06-10 19:53:02.286380 EDT | AverageDiscountedReturn  154.2
2017-06-10 19:53:02.286709 EDT | AverageQLoss               0.563838
2017-06-10 19:53:02.287033 EDT | AveragePolicySurr        -13.7818
2017-06-10 19:53:02.287356 EDT | AverageQ                  13.3071
2017-06-10 19:53:02.287678 EDT | AverageAbsQ               13.316
2017-06-10 19:53:02.288213 EDT | AverageY                  13.3095
2017-06-10 19:53:02.288550 EDT | AverageAbsY               13.31
2017-06-10 19:53:02.288874 EDT | AverageAbsQYDiff           0.323817
2017-06-10 19:53:02.289350 EDT | AverageAction              0.770886
2017-06-10 19:53:02.289602 EDT | PolicyRegParamNorm        37.4068
2017-06-10 19:53:02.289854 EDT | QFunRegParamNorm          38.874
2017-06-10 19:53:02.290174 EDT | -----------------------  ----------
2017-06-10 19:53:02.292802 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #84 | Training started
2017-06-10 19:53:17.341924 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #84 | Training finished
2017-06-10 19:53:17.343050 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #84 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 19:53:17.343336 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #84 | Collecting samples for evaluation
2017-06-10 19:53:30.463425 EDT | -----------------------  ----------
2017-06-10 19:53:30.464395 EDT | Epoch                     84
2017-06-10 19:53:30.464749 EDT | Iteration                 84
2017-06-10 19:53:30.465087 EDT | AverageReturn            347.268
2017-06-10 19:53:30.465486 EDT | StdReturn                  9.07958
2017-06-10 19:53:30.465843 EDT | MaxReturn                369.675
2017-06-10 19:53:30.466176 EDT | MinReturn                326.656
2017-06-10 19:53:30.466512 EDT | AverageEsReturn          175.103
2017-06-10 19:53:30.466842 EDT | StdEsReturn              132.98
2017-06-10 19:53:30.467169 EDT | MaxEsReturn              326.261
2017-06-10 19:53:30.467506 EDT | MinEsReturn                7.51319
2017-06-10 19:53:30.467835 EDT | AverageDiscountedReturn  171.268
2017-06-10 19:53:30.468162 EDT | AverageQLoss               0.608356
2017-06-10 19:53:30.468490 EDT | AveragePolicySurr        -14.0491
2017-06-10 19:53:30.468817 EDT | AverageQ                  13.5695
2017-06-10 19:53:30.469145 EDT | AverageAbsQ               13.5797
2017-06-10 19:53:30.469471 EDT | AverageY                  13.5716
2017-06-10 19:53:30.469810 EDT | AverageAbsY               13.5724
2017-06-10 19:53:30.470365 EDT | AverageAbsQYDiff           0.329222
2017-06-10 19:53:30.472170 EDT | AverageAction              0.779754
2017-06-10 19:53:30.473095 EDT | PolicyRegParamNorm        37.6464
2017-06-10 19:53:30.474032 EDT | QFunRegParamNorm          39.1748
2017-06-10 19:53:30.474941 EDT | -----------------------  ----------
2017-06-10 19:53:30.475954 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #85 | Training started
2017-06-10 19:53:45.395129 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #85 | Training finished
2017-06-10 19:53:45.395917 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #85 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 19:53:45.396121 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #85 | Collecting samples for evaluation
2017-06-10 19:53:56.896593 EDT | -----------------------  ----------
2017-06-10 19:53:56.897498 EDT | Epoch                     85
2017-06-10 19:53:56.897751 EDT | Iteration                 85
2017-06-10 19:53:56.898051 EDT | AverageReturn            354.748
2017-06-10 19:53:56.898399 EDT | StdReturn                 21.0513
2017-06-10 19:53:56.898752 EDT | MaxReturn                411.578
2017-06-10 19:53:56.899095 EDT | MinReturn                309.072
2017-06-10 19:53:56.899445 EDT | AverageEsReturn          141.735
2017-06-10 19:53:56.899801 EDT | StdEsReturn              121.211
2017-06-10 19:53:56.900123 EDT | MaxEsReturn              335.226
2017-06-10 19:53:56.900388 EDT | MinEsReturn               10.4043
2017-06-10 19:53:56.900715 EDT | AverageDiscountedReturn  171.685
2017-06-10 19:53:56.901063 EDT | AverageQLoss               0.638403
2017-06-10 19:53:56.901370 EDT | AveragePolicySurr        -14.2247
2017-06-10 19:53:56.901711 EDT | AverageQ                  13.7416
2017-06-10 19:53:56.902068 EDT | AverageAbsQ               13.7514
2017-06-10 19:53:56.902399 EDT | AverageY                  13.7437
2017-06-10 19:53:56.902724 EDT | AverageAbsY               13.7443
2017-06-10 19:53:56.903060 EDT | AverageAbsQYDiff           0.344006
2017-06-10 19:53:56.904558 EDT | AverageAction              0.75606
2017-06-10 19:53:56.904905 EDT | PolicyRegParamNorm        37.7894
2017-06-10 19:53:56.905222 EDT | QFunRegParamNorm          39.4361
2017-06-10 19:53:56.905569 EDT | -----------------------  ----------
2017-06-10 19:53:56.906057 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #86 | Training started
2017-06-10 19:54:12.161035 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #86 | Training finished
2017-06-10 19:54:12.162783 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #86 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 19:54:12.163002 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #86 | Collecting samples for evaluation
2017-06-10 19:54:23.958127 EDT | -----------------------  ----------
2017-06-10 19:54:23.958650 EDT | Epoch                     86
2017-06-10 19:54:23.959023 EDT | Iteration                 86
2017-06-10 19:54:23.959400 EDT | AverageReturn            414.614
2017-06-10 19:54:23.959771 EDT | StdReturn                 47.2902
2017-06-10 19:54:23.960146 EDT | MaxReturn                535.958
2017-06-10 19:54:23.960463 EDT | MinReturn                346.099
2017-06-10 19:54:23.960834 EDT | AverageEsReturn          260.362
2017-06-10 19:54:23.961202 EDT | StdEsReturn              122.107
2017-06-10 19:54:23.961576 EDT | MaxEsReturn              351.142
2017-06-10 19:54:23.961911 EDT | MinEsReturn                9.13738
2017-06-10 19:54:23.962270 EDT | AverageDiscountedReturn  187.921
2017-06-10 19:54:23.962634 EDT | AverageQLoss               0.53134
2017-06-10 19:54:23.963001 EDT | AveragePolicySurr        -14.4753
2017-06-10 19:54:23.963380 EDT | AverageQ                  13.9649
2017-06-10 19:54:23.963746 EDT | AverageAbsQ               13.9762
2017-06-10 19:54:23.964113 EDT | AverageY                  13.9667
2017-06-10 19:54:23.964472 EDT | AverageAbsY               13.9679
2017-06-10 19:54:23.964791 EDT | AverageAbsQYDiff           0.328446
2017-06-10 19:54:23.965156 EDT | AverageAction              0.72438
2017-06-10 19:54:23.965526 EDT | PolicyRegParamNorm        37.9497
2017-06-10 19:54:23.965911 EDT | QFunRegParamNorm          39.6617
2017-06-10 19:54:23.966218 EDT | -----------------------  ----------
2017-06-10 19:54:23.966756 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #87 | Training started
2017-06-10 19:54:37.913681 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #87 | Training finished
2017-06-10 19:54:37.916089 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #87 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 19:54:37.916652 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #87 | Collecting samples for evaluation
2017-06-10 19:54:50.171329 EDT | -----------------------  ----------
2017-06-10 19:54:50.172377 EDT | Epoch                     87
2017-06-10 19:54:50.172579 EDT | Iteration                 87
2017-06-10 19:54:50.172772 EDT | AverageReturn            377.498
2017-06-10 19:54:50.172967 EDT | StdReturn                 37.7879
2017-06-10 19:54:50.173147 EDT | MaxReturn                491.727
2017-06-10 19:54:50.173337 EDT | MinReturn                329.637
2017-06-10 19:54:50.173519 EDT | AverageEsReturn          181.641
2017-06-10 19:54:50.173727 EDT | StdEsReturn              154.842
2017-06-10 19:54:50.173905 EDT | MaxEsReturn              432.967
2017-06-10 19:54:50.174064 EDT | MinEsReturn                7.58272
2017-06-10 19:54:50.174221 EDT | AverageDiscountedReturn  177.338
2017-06-10 19:54:50.174377 EDT | AverageQLoss               0.677304
2017-06-10 19:54:50.174563 EDT | AveragePolicySurr        -14.6289
2017-06-10 19:54:50.174729 EDT | AverageQ                  14.1278
2017-06-10 19:54:50.174913 EDT | AverageAbsQ               14.1385
2017-06-10 19:54:50.175093 EDT | AverageY                  14.1301
2017-06-10 19:54:50.175273 EDT | AverageAbsY               14.1313
2017-06-10 19:54:50.175444 EDT | AverageAbsQYDiff           0.355847
2017-06-10 19:54:50.175601 EDT | AverageAction              0.765325
2017-06-10 19:54:50.175757 EDT | PolicyRegParamNorm        38.0552
2017-06-10 19:54:50.175934 EDT | QFunRegParamNorm          40.0094
2017-06-10 19:54:50.176098 EDT | -----------------------  ----------
2017-06-10 19:54:50.176367 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #88 | Training started
2017-06-10 19:55:04.081373 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #88 | Training finished
2017-06-10 19:55:04.082321 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #88 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 19:55:04.082715 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #88 | Collecting samples for evaluation
2017-06-10 19:55:16.093771 EDT | -----------------------  ----------
2017-06-10 19:55:16.094818 EDT | Epoch                     88
2017-06-10 19:55:16.095268 EDT | Iteration                 88
2017-06-10 19:55:16.096456 EDT | AverageReturn            343.465
2017-06-10 19:55:16.096702 EDT | StdReturn                  8.00093
2017-06-10 19:55:16.097034 EDT | MaxReturn                363.263
2017-06-10 19:55:16.097361 EDT | MinReturn                325.456
2017-06-10 19:55:16.097602 EDT | AverageEsReturn          180.398
2017-06-10 19:55:16.098342 EDT | StdEsReturn              135.523
2017-06-10 19:55:16.098649 EDT | MaxEsReturn              341.769
2017-06-10 19:55:16.098837 EDT | MinEsReturn                9.4745
2017-06-10 19:55:16.099081 EDT | AverageDiscountedReturn  168.45
2017-06-10 19:55:16.099397 EDT | AverageQLoss               0.632072
2017-06-10 19:55:16.099692 EDT | AveragePolicySurr        -14.9075
2017-06-10 19:55:16.100106 EDT | AverageQ                  14.3917
2017-06-10 19:55:16.100541 EDT | AverageAbsQ               14.4017
2017-06-10 19:55:16.100870 EDT | AverageY                  14.3939
2017-06-10 19:55:16.101202 EDT | AverageAbsY               14.3954
2017-06-10 19:55:16.101610 EDT | AverageAbsQYDiff           0.347937
2017-06-10 19:55:16.102425 EDT | AverageAction              0.730586
2017-06-10 19:55:16.102979 EDT | PolicyRegParamNorm        38.2328
2017-06-10 19:55:16.103296 EDT | QFunRegParamNorm          40.2974
2017-06-10 19:55:16.103725 EDT | -----------------------  ----------
2017-06-10 19:55:16.104262 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #89 | Training started
2017-06-10 19:55:30.529518 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #89 | Training finished
2017-06-10 19:55:30.530351 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #89 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 19:55:30.530716 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #89 | Collecting samples for evaluation
2017-06-10 19:55:42.270839 EDT | -----------------------  ----------
2017-06-10 19:55:42.272394 EDT | Epoch                     89
2017-06-10 19:55:42.272710 EDT | Iteration                 89
2017-06-10 19:55:42.273026 EDT | AverageReturn            320.09
2017-06-10 19:55:42.273371 EDT | StdReturn                  4.14748
2017-06-10 19:55:42.273723 EDT | MaxReturn                330.087
2017-06-10 19:55:42.274062 EDT | MinReturn                309.286
2017-06-10 19:55:42.274399 EDT | AverageEsReturn          226.486
2017-06-10 19:55:42.274707 EDT | StdEsReturn               99.1526
2017-06-10 19:55:42.275038 EDT | MaxEsReturn              315.802
2017-06-10 19:55:42.275371 EDT | MinEsReturn               30.3955
2017-06-10 19:55:42.275697 EDT | AverageDiscountedReturn  160.607
2017-06-10 19:55:42.276030 EDT | AverageQLoss               0.667826
2017-06-10 19:55:42.276364 EDT | AveragePolicySurr        -15.1368
2017-06-10 19:55:42.276649 EDT | AverageQ                  14.6186
2017-06-10 19:55:42.276959 EDT | AverageAbsQ               14.6296
2017-06-10 19:55:42.277305 EDT | AverageY                  14.621
2017-06-10 19:55:42.277649 EDT | AverageAbsY               14.6218
2017-06-10 19:55:42.278003 EDT | AverageAbsQYDiff           0.362807
2017-06-10 19:55:42.278336 EDT | AverageAction              0.726343
2017-06-10 19:55:42.278768 EDT | PolicyRegParamNorm        38.4149
2017-06-10 19:55:42.279207 EDT | QFunRegParamNorm          40.6204
2017-06-10 19:55:42.279486 EDT | -----------------------  ----------
2017-06-10 19:55:42.280026 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #90 | Training started
2017-06-10 19:55:56.798919 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #90 | Training finished
2017-06-10 19:55:56.799362 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #90 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 19:55:56.799733 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #90 | Collecting samples for evaluation
2017-06-10 19:56:09.107775 EDT | -----------------------  ----------
2017-06-10 19:56:09.109008 EDT | Epoch                     90
2017-06-10 19:56:09.109378 EDT | Iteration                 90
2017-06-10 19:56:09.109786 EDT | AverageReturn            284.85
2017-06-10 19:56:09.110120 EDT | StdReturn                  3.98629
2017-06-10 19:56:09.110464 EDT | MaxReturn                295.624
2017-06-10 19:56:09.110896 EDT | MinReturn                275.785
2017-06-10 19:56:09.111238 EDT | AverageEsReturn          157.705
2017-06-10 19:56:09.111651 EDT | StdEsReturn              143.411
2017-06-10 19:56:09.111981 EDT | MaxEsReturn              362.969
2017-06-10 19:56:09.112324 EDT | MinEsReturn               14.7298
2017-06-10 19:56:09.112856 EDT | AverageDiscountedReturn  149.962
2017-06-10 19:56:09.113201 EDT | AverageQLoss               0.647295
2017-06-10 19:56:09.113637 EDT | AveragePolicySurr        -15.3277
2017-06-10 19:56:09.113989 EDT | AverageQ                  14.8234
2017-06-10 19:56:09.114406 EDT | AverageAbsQ               14.8344
2017-06-10 19:56:09.114696 EDT | AverageY                  14.826
2017-06-10 19:56:09.115030 EDT | AverageAbsY               14.8268
2017-06-10 19:56:09.115372 EDT | AverageAbsQYDiff           0.354301
2017-06-10 19:56:09.115765 EDT | AverageAction              0.757987
2017-06-10 19:56:09.116074 EDT | PolicyRegParamNorm        38.5711
2017-06-10 19:56:09.116412 EDT | QFunRegParamNorm          40.8976
2017-06-10 19:56:09.116817 EDT | -----------------------  ----------
2017-06-10 19:56:09.117258 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #91 | Training started
2017-06-10 19:56:24.077948 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #91 | Training finished
2017-06-10 19:56:24.078906 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #91 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 19:56:24.079304 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #91 | Collecting samples for evaluation
2017-06-10 19:56:35.700501 EDT | -----------------------  ----------
2017-06-10 19:56:35.702592 EDT | Epoch                     91
2017-06-10 19:56:35.704227 EDT | Iteration                 91
2017-06-10 19:56:35.704842 EDT | AverageReturn            410.644
2017-06-10 19:56:35.705254 EDT | StdReturn                 38.6036
2017-06-10 19:56:35.705723 EDT | MaxReturn                573.617
2017-06-10 19:56:35.706143 EDT | MinReturn                333.237
2017-06-10 19:56:35.706559 EDT | AverageEsReturn          276.204
2017-06-10 19:56:35.707328 EDT | StdEsReturn               86.6317
2017-06-10 19:56:35.708107 EDT | MaxEsReturn              447.18
2017-06-10 19:56:35.708518 EDT | MinEsReturn              101.756
2017-06-10 19:56:35.708937 EDT | AverageDiscountedReturn  181.095
2017-06-10 19:56:35.709496 EDT | AverageQLoss               0.707867
2017-06-10 19:56:35.709963 EDT | AveragePolicySurr        -15.5852
2017-06-10 19:56:35.710296 EDT | AverageQ                  15.0431
2017-06-10 19:56:35.710635 EDT | AverageAbsQ               15.0554
2017-06-10 19:56:35.710946 EDT | AverageY                  15.0441
2017-06-10 19:56:35.711347 EDT | AverageAbsY               15.0452
2017-06-10 19:56:35.711681 EDT | AverageAbsQYDiff           0.368049
2017-06-10 19:56:35.712247 EDT | AverageAction              0.763874
2017-06-10 19:56:35.712593 EDT | PolicyRegParamNorm        38.745
2017-06-10 19:56:35.714173 EDT | QFunRegParamNorm          41.1735
2017-06-10 19:56:35.714782 EDT | -----------------------  ----------
2017-06-10 19:56:35.715368 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #92 | Training started
2017-06-10 19:56:50.409511 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #92 | Training finished
2017-06-10 19:56:50.411069 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #92 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 19:56:50.411827 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #92 | Collecting samples for evaluation
2017-06-10 19:57:03.047962 EDT | -----------------------  ----------
2017-06-10 19:57:03.048959 EDT | Epoch                     92
2017-06-10 19:57:03.049334 EDT | Iteration                 92
2017-06-10 19:57:03.049676 EDT | AverageReturn            312.087
2017-06-10 19:57:03.049952 EDT | StdReturn                  8.30082
2017-06-10 19:57:03.050204 EDT | MaxReturn                334.091
2017-06-10 19:57:03.050555 EDT | MinReturn                292.428
2017-06-10 19:57:03.050955 EDT | AverageEsReturn          311.859
2017-06-10 19:57:03.051342 EDT | StdEsReturn              120.231
2017-06-10 19:57:03.051766 EDT | MaxEsReturn              501.287
2017-06-10 19:57:03.052175 EDT | MinEsReturn               89.3435
2017-06-10 19:57:03.052515 EDT | AverageDiscountedReturn  159.942
2017-06-10 19:57:03.052823 EDT | AverageQLoss               0.821069
2017-06-10 19:57:03.053086 EDT | AveragePolicySurr        -15.8204
2017-06-10 19:57:03.053245 EDT | AverageQ                  15.2931
2017-06-10 19:57:03.053407 EDT | AverageAbsQ               15.3082
2017-06-10 19:57:03.053737 EDT | AverageY                  15.2961
2017-06-10 19:57:03.054050 EDT | AverageAbsY               15.2975
2017-06-10 19:57:03.054375 EDT | AverageAbsQYDiff           0.389464
2017-06-10 19:57:03.054760 EDT | AverageAction              0.789602
2017-06-10 19:57:03.055088 EDT | PolicyRegParamNorm        38.9864
2017-06-10 19:57:03.061906 EDT | QFunRegParamNorm          41.4581
2017-06-10 19:57:03.062347 EDT | -----------------------  ----------
2017-06-10 19:57:03.062930 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #93 | Training started
2017-06-10 19:57:17.198785 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #93 | Training finished
2017-06-10 19:57:17.201125 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #93 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 19:57:17.201517 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #93 | Collecting samples for evaluation
2017-06-10 19:57:28.759023 EDT | -----------------------  ----------
2017-06-10 19:57:28.774314 EDT | Epoch                     93
2017-06-10 19:57:28.774701 EDT | Iteration                 93
2017-06-10 19:57:28.775006 EDT | AverageReturn            334.926
2017-06-10 19:57:28.775306 EDT | StdReturn                  5.88001
2017-06-10 19:57:28.775608 EDT | MaxReturn                352.58
2017-06-10 19:57:28.775872 EDT | MinReturn                319.041
2017-06-10 19:57:28.776167 EDT | AverageEsReturn          203.712
2017-06-10 19:57:28.776463 EDT | StdEsReturn              111.373
2017-06-10 19:57:28.776755 EDT | MaxEsReturn              337.157
2017-06-10 19:57:28.777053 EDT | MinEsReturn               11.0876
2017-06-10 19:57:28.777449 EDT | AverageDiscountedReturn  167.834
2017-06-10 19:57:28.777843 EDT | AverageQLoss               0.683536
2017-06-10 19:57:28.778224 EDT | AveragePolicySurr        -16.0201
2017-06-10 19:57:28.778610 EDT | AverageQ                  15.5083
2017-06-10 19:57:28.779005 EDT | AverageAbsQ               15.5206
2017-06-10 19:57:28.779398 EDT | AverageY                  15.5105
2017-06-10 19:57:28.779764 EDT | AverageAbsY               15.5121
2017-06-10 19:57:28.780124 EDT | AverageAbsQYDiff           0.369124
2017-06-10 19:57:28.780506 EDT | AverageAction              0.806915
2017-06-10 19:57:28.780770 EDT | PolicyRegParamNorm        39.2055
2017-06-10 19:57:28.781018 EDT | QFunRegParamNorm          41.7338
2017-06-10 19:57:28.781260 EDT | -----------------------  ----------
2017-06-10 19:57:28.781713 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #94 | Training started
2017-06-10 19:57:43.275996 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #94 | Training finished
2017-06-10 19:57:43.276762 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #94 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 19:57:43.277005 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #94 | Collecting samples for evaluation
2017-06-10 19:57:55.383223 EDT | -----------------------  ----------
2017-06-10 19:57:55.383951 EDT | Epoch                     94
2017-06-10 19:57:55.384390 EDT | Iteration                 94
2017-06-10 19:57:55.385036 EDT | AverageReturn            265.968
2017-06-10 19:57:55.385571 EDT | StdReturn                  4.58672
2017-06-10 19:57:55.386167 EDT | MaxReturn                276.476
2017-06-10 19:57:55.386531 EDT | MinReturn                256.836
2017-06-10 19:57:55.387084 EDT | AverageEsReturn          148.382
2017-06-10 19:57:55.387523 EDT | StdEsReturn              134.673
2017-06-10 19:57:55.387958 EDT | MaxEsReturn              381.401
2017-06-10 19:57:55.388390 EDT | MinEsReturn                6.99128
2017-06-10 19:57:55.388826 EDT | AverageDiscountedReturn  144.672
2017-06-10 19:57:55.389434 EDT | AverageQLoss               0.831436
2017-06-10 19:57:55.390118 EDT | AveragePolicySurr        -16.2659
2017-06-10 19:57:55.390563 EDT | AverageQ                  15.7188
2017-06-10 19:57:55.392392 EDT | AverageAbsQ               15.7315
2017-06-10 19:57:55.393114 EDT | AverageY                  15.7207
2017-06-10 19:57:55.393544 EDT | AverageAbsY               15.7231
2017-06-10 19:57:55.393987 EDT | AverageAbsQYDiff           0.393764
2017-06-10 19:57:55.394535 EDT | AverageAction              0.826237
2017-06-10 19:57:55.396172 EDT | PolicyRegParamNorm        39.368
2017-06-10 19:57:55.396628 EDT | QFunRegParamNorm          42.0312
2017-06-10 19:57:55.397147 EDT | -----------------------  ----------
2017-06-10 19:57:55.397781 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #95 | Training started
2017-06-10 19:58:09.433217 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #95 | Training finished
2017-06-10 19:58:09.434167 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #95 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 19:58:09.434555 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #95 | Collecting samples for evaluation
2017-06-10 19:58:21.842893 EDT | -----------------------  ----------
2017-06-10 19:58:21.843736 EDT | Epoch                     95
2017-06-10 19:58:21.844089 EDT | Iteration                 95
2017-06-10 19:58:21.845411 EDT | AverageReturn            315.906
2017-06-10 19:58:21.845782 EDT | StdReturn                 15.0815
2017-06-10 19:58:21.846081 EDT | MaxReturn                347.011
2017-06-10 19:58:21.846393 EDT | MinReturn                281.259
2017-06-10 19:58:21.846659 EDT | AverageEsReturn          256.496
2017-06-10 19:58:21.846912 EDT | StdEsReturn               78.5968
2017-06-10 19:58:21.847162 EDT | MaxEsReturn              323.251
2017-06-10 19:58:21.847417 EDT | MinEsReturn               47.5198
2017-06-10 19:58:21.847626 EDT | AverageDiscountedReturn  161.605
2017-06-10 19:58:21.847899 EDT | AverageQLoss               0.868219
2017-06-10 19:58:21.848074 EDT | AveragePolicySurr        -16.4785
2017-06-10 19:58:21.848282 EDT | AverageQ                  15.9386
2017-06-10 19:58:21.848519 EDT | AverageAbsQ               15.953
2017-06-10 19:58:21.848856 EDT | AverageY                  15.9412
2017-06-10 19:58:21.849252 EDT | AverageAbsY               15.9429
2017-06-10 19:58:21.850664 EDT | AverageAbsQYDiff           0.404001
2017-06-10 19:58:21.851152 EDT | AverageAction              0.797089
2017-06-10 19:58:21.852261 EDT | PolicyRegParamNorm        39.5376
2017-06-10 19:58:21.852733 EDT | QFunRegParamNorm          42.3145
2017-06-10 19:58:21.853148 EDT | -----------------------  ----------
2017-06-10 19:58:21.853841 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #96 | Training started
2017-06-10 19:58:35.320700 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #96 | Training finished
2017-06-10 19:58:35.339760 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #96 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 19:58:35.340031 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #96 | Collecting samples for evaluation
2017-06-10 19:58:47.088356 EDT | -----------------------  ----------
2017-06-10 19:58:47.089453 EDT | Epoch                     96
2017-06-10 19:58:47.089654 EDT | Iteration                 96
2017-06-10 19:58:47.089851 EDT | AverageReturn            337.699
2017-06-10 19:58:47.090036 EDT | StdReturn                  9.80015
2017-06-10 19:58:47.090345 EDT | MaxReturn                379.86
2017-06-10 19:58:47.090512 EDT | MinReturn                314.766
2017-06-10 19:58:47.090730 EDT | AverageEsReturn          198.295
2017-06-10 19:58:47.090986 EDT | StdEsReturn              142.954
2017-06-10 19:58:47.091148 EDT | MaxEsReturn              355.463
2017-06-10 19:58:47.091324 EDT | MinEsReturn                7.10205
2017-06-10 19:58:47.091527 EDT | AverageDiscountedReturn  167.304
2017-06-10 19:58:47.091697 EDT | AverageQLoss               0.618882
2017-06-10 19:58:47.091864 EDT | AveragePolicySurr        -16.7047
2017-06-10 19:58:47.092040 EDT | AverageQ                  16.1849
2017-06-10 19:58:47.092237 EDT | AverageAbsQ               16.196
2017-06-10 19:58:47.092430 EDT | AverageY                  16.1853
2017-06-10 19:58:47.092638 EDT | AverageAbsY               16.1869
2017-06-10 19:58:47.092828 EDT | AverageAbsQYDiff           0.368724
2017-06-10 19:58:47.093023 EDT | AverageAction              0.824626
2017-06-10 19:58:47.093287 EDT | PolicyRegParamNorm        39.6229
2017-06-10 19:58:47.093491 EDT | QFunRegParamNorm          42.5398
2017-06-10 19:58:47.093832 EDT | -----------------------  ----------
2017-06-10 19:58:47.094171 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #97 | Training started
2017-06-10 19:59:01.582213 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #97 | Training finished
2017-06-10 19:59:01.583004 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #97 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 19:59:01.583294 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #97 | Collecting samples for evaluation
2017-06-10 19:59:13.532558 EDT | -----------------------  ----------
2017-06-10 19:59:13.533573 EDT | Epoch                     97
2017-06-10 19:59:13.534110 EDT | Iteration                 97
2017-06-10 19:59:13.534373 EDT | AverageReturn            536.642
2017-06-10 19:59:13.534564 EDT | StdReturn                 51.1433
2017-06-10 19:59:13.535212 EDT | MaxReturn                671.012
2017-06-10 19:59:13.535843 EDT | MinReturn                430.072
2017-06-10 19:59:13.536019 EDT | AverageEsReturn          303.665
2017-06-10 19:59:13.536203 EDT | StdEsReturn              162.683
2017-06-10 19:59:13.536459 EDT | MaxEsReturn              504.58
2017-06-10 19:59:13.536642 EDT | MinEsReturn               81.8402
2017-06-10 19:59:13.536828 EDT | AverageDiscountedReturn  208.39
2017-06-10 19:59:13.537010 EDT | AverageQLoss               0.865595
2017-06-10 19:59:13.537192 EDT | AveragePolicySurr        -16.8514
2017-06-10 19:59:13.537467 EDT | AverageQ                  16.3325
2017-06-10 19:59:13.537653 EDT | AverageAbsQ               16.3451
2017-06-10 19:59:13.537861 EDT | AverageY                  16.3358
2017-06-10 19:59:13.538044 EDT | AverageAbsY               16.3375
2017-06-10 19:59:13.538357 EDT | AverageAbsQYDiff           0.403134
2017-06-10 19:59:13.538541 EDT | AverageAction              0.798339
2017-06-10 19:59:13.538722 EDT | PolicyRegParamNorm        39.8107
2017-06-10 19:59:13.538904 EDT | QFunRegParamNorm          42.7998
2017-06-10 19:59:13.539354 EDT | -----------------------  ----------
2017-06-10 19:59:13.539644 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #98 | Training started
2017-06-10 19:59:28.215331 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #98 | Training finished
2017-06-10 19:59:28.217520 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #98 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 19:59:28.227948 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #98 | Collecting samples for evaluation
2017-06-10 19:59:40.042999 EDT | -----------------------  ----------
2017-06-10 19:59:40.043283 EDT | Epoch                     98
2017-06-10 19:59:40.043514 EDT | Iteration                 98
2017-06-10 19:59:40.043700 EDT | AverageReturn            378.215
2017-06-10 19:59:40.043890 EDT | StdReturn                 56.795
2017-06-10 19:59:40.044067 EDT | MaxReturn                544.884
2017-06-10 19:59:40.044357 EDT | MinReturn                271.58
2017-06-10 19:59:40.044532 EDT | AverageEsReturn          232.313
2017-06-10 19:59:40.044685 EDT | StdEsReturn              148.196
2017-06-10 19:59:40.044866 EDT | MaxEsReturn              503.246
2017-06-10 19:59:40.045027 EDT | MinEsReturn                7.3671
2017-06-10 19:59:40.045210 EDT | AverageDiscountedReturn  176.169
2017-06-10 19:59:40.045362 EDT | AverageQLoss               0.928269
2017-06-10 19:59:40.045518 EDT | AveragePolicySurr        -17.0044
2017-06-10 19:59:40.045736 EDT | AverageQ                  16.504
2017-06-10 19:59:40.046060 EDT | AverageAbsQ               16.5146
2017-06-10 19:59:40.046390 EDT | AverageY                  16.5059
2017-06-10 19:59:40.046713 EDT | AverageAbsY               16.5076
2017-06-10 19:59:40.046986 EDT | AverageAbsQYDiff           0.406576
2017-06-10 19:59:40.047302 EDT | AverageAction              0.81666
2017-06-10 19:59:40.047634 EDT | PolicyRegParamNorm        40.016
2017-06-10 19:59:40.048247 EDT | QFunRegParamNorm          43.0386
2017-06-10 19:59:40.048549 EDT | -----------------------  ----------
2017-06-10 19:59:40.049433 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #99 | Training started
2017-06-10 19:59:55.187793 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #99 | Training finished
2017-06-10 19:59:55.188755 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #99 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 19:59:55.190513 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #99 | Collecting samples for evaluation
2017-06-10 20:00:07.200038 EDT | -----------------------  ----------
2017-06-10 20:00:07.201759 EDT | Epoch                     99
2017-06-10 20:00:07.202066 EDT | Iteration                 99
2017-06-10 20:00:07.202255 EDT | AverageReturn            309.784
2017-06-10 20:00:07.202585 EDT | StdReturn                 20.6762
2017-06-10 20:00:07.202890 EDT | MaxReturn                344.258
2017-06-10 20:00:07.203153 EDT | MinReturn                247.287
2017-06-10 20:00:07.203480 EDT | AverageEsReturn          236.167
2017-06-10 20:00:07.203790 EDT | StdEsReturn              150.486
2017-06-10 20:00:07.204085 EDT | MaxEsReturn              563.833
2017-06-10 20:00:07.204294 EDT | MinEsReturn                7.35545
2017-06-10 20:00:07.204477 EDT | AverageDiscountedReturn  160.157
2017-06-10 20:00:07.204658 EDT | AverageQLoss               0.905507
2017-06-10 20:00:07.204975 EDT | AveragePolicySurr        -17.1658
2017-06-10 20:00:07.205294 EDT | AverageQ                  16.6527
2017-06-10 20:00:07.205622 EDT | AverageAbsQ               16.665
2017-06-10 20:00:07.205949 EDT | AverageY                  16.6552
2017-06-10 20:00:07.206254 EDT | AverageAbsY               16.6569
2017-06-10 20:00:07.206590 EDT | AverageAbsQYDiff           0.418561
2017-06-10 20:00:07.206920 EDT | AverageAction              0.827062
2017-06-10 20:00:07.207245 EDT | PolicyRegParamNorm        40.1477
2017-06-10 20:00:07.207572 EDT | QFunRegParamNorm          43.322
2017-06-10 20:00:07.207887 EDT | -----------------------  ----------
2017-06-10 20:00:07.208350 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #100 | Training started
2017-06-10 20:00:21.067962 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #100 | Training finished
2017-06-10 20:00:21.068946 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #100 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 20:00:21.070327 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #100 | Collecting samples for evaluation
2017-06-10 20:00:33.451789 EDT | -----------------------  ----------
2017-06-10 20:00:33.452686 EDT | Epoch                    100
2017-06-10 20:00:33.453022 EDT | Iteration                100
2017-06-10 20:00:33.453365 EDT | AverageReturn            335.02
2017-06-10 20:00:33.453733 EDT | StdReturn                 62.946
2017-06-10 20:00:33.454154 EDT | MaxReturn                508.479
2017-06-10 20:00:33.454514 EDT | MinReturn                256.35
2017-06-10 20:00:33.454860 EDT | AverageEsReturn          284.326
2017-06-10 20:00:33.455186 EDT | StdEsReturn              113.921
2017-06-10 20:00:33.455503 EDT | MaxEsReturn              485.549
2017-06-10 20:00:33.455780 EDT | MinEsReturn               57.3602
2017-06-10 20:00:33.456118 EDT | AverageDiscountedReturn  166.671
2017-06-10 20:00:33.456533 EDT | AverageQLoss               0.861489
2017-06-10 20:00:33.456860 EDT | AveragePolicySurr        -17.4034
2017-06-10 20:00:33.457128 EDT | AverageQ                  16.8921
2017-06-10 20:00:33.457451 EDT | AverageAbsQ               16.9038
2017-06-10 20:00:33.457894 EDT | AverageY                  16.8941
2017-06-10 20:00:33.458318 EDT | AverageAbsY               16.8961
2017-06-10 20:00:33.459010 EDT | AverageAbsQYDiff           0.40722
2017-06-10 20:00:33.459904 EDT | AverageAction              0.891378
2017-06-10 20:00:33.460299 EDT | PolicyRegParamNorm        40.375
2017-06-10 20:00:33.460785 EDT | QFunRegParamNorm          43.5581
2017-06-10 20:00:33.461559 EDT | -----------------------  ----------
2017-06-10 20:00:33.462544 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #101 | Training started
2017-06-10 20:00:47.424754 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #101 | Training finished
2017-06-10 20:00:47.425523 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #101 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 20:00:47.425910 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #101 | Collecting samples for evaluation
2017-06-10 20:00:59.191592 EDT | -----------------------  ----------
2017-06-10 20:00:59.192360 EDT | Epoch                    101
2017-06-10 20:00:59.192541 EDT | Iteration                101
2017-06-10 20:00:59.192731 EDT | AverageReturn            628.848
2017-06-10 20:00:59.192913 EDT | StdReturn                 75.7069
2017-06-10 20:00:59.193106 EDT | MaxReturn                692.733
2017-06-10 20:00:59.193334 EDT | MinReturn                297.999
2017-06-10 20:00:59.193560 EDT | AverageEsReturn          211.142
2017-06-10 20:00:59.193814 EDT | StdEsReturn              155.405
2017-06-10 20:00:59.194175 EDT | MaxEsReturn              486.551
2017-06-10 20:00:59.194378 EDT | MinEsReturn               19.4336
2017-06-10 20:00:59.194564 EDT | AverageDiscountedReturn  223.338
2017-06-10 20:00:59.194927 EDT | AverageQLoss               0.849071
2017-06-10 20:00:59.195175 EDT | AveragePolicySurr        -17.5041
2017-06-10 20:00:59.195368 EDT | AverageQ                  17.0097
2017-06-10 20:00:59.195633 EDT | AverageAbsQ               17.0256
2017-06-10 20:00:59.197980 EDT | AverageY                  17.0134
2017-06-10 20:00:59.198235 EDT | AverageAbsY               17.0159
2017-06-10 20:00:59.198495 EDT | AverageAbsQYDiff           0.41665
2017-06-10 20:00:59.198680 EDT | AverageAction              0.838719
2017-06-10 20:00:59.198861 EDT | PolicyRegParamNorm        40.6405
2017-06-10 20:00:59.199043 EDT | QFunRegParamNorm          43.8439
2017-06-10 20:00:59.199223 EDT | -----------------------  ----------
2017-06-10 20:00:59.199522 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #102 | Training started
2017-06-10 20:01:14.148120 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #102 | Training finished
2017-06-10 20:01:14.149142 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #102 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 20:01:14.149528 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #102 | Collecting samples for evaluation
2017-06-10 20:01:26.145609 EDT | -----------------------  ----------
2017-06-10 20:01:26.146379 EDT | Epoch                    102
2017-06-10 20:01:26.146574 EDT | Iteration                102
2017-06-10 20:01:26.146803 EDT | AverageReturn            347.512
2017-06-10 20:01:26.146989 EDT | StdReturn                 42.0745
2017-06-10 20:01:26.147181 EDT | MaxReturn                443.504
2017-06-10 20:01:26.147361 EDT | MinReturn                279.773
2017-06-10 20:01:26.147543 EDT | AverageEsReturn          220.888
2017-06-10 20:01:26.147758 EDT | StdEsReturn              160.717
2017-06-10 20:01:26.147938 EDT | MaxEsReturn              581.479
2017-06-10 20:01:26.148145 EDT | MinEsReturn                9.1451
2017-06-10 20:01:26.148326 EDT | AverageDiscountedReturn  170.306
2017-06-10 20:01:26.148507 EDT | AverageQLoss               0.964888
2017-06-10 20:01:26.148686 EDT | AveragePolicySurr        -17.6639
2017-06-10 20:01:26.148865 EDT | AverageQ                  17.1593
2017-06-10 20:01:26.149057 EDT | AverageAbsQ               17.173
2017-06-10 20:01:26.149344 EDT | AverageY                  17.1611
2017-06-10 20:01:26.149870 EDT | AverageAbsY               17.1637
2017-06-10 20:01:26.150135 EDT | AverageAbsQYDiff           0.425861
2017-06-10 20:01:26.150318 EDT | AverageAction              0.852999
2017-06-10 20:01:26.150514 EDT | PolicyRegParamNorm        40.804
2017-06-10 20:01:26.151287 EDT | QFunRegParamNorm          44.07
2017-06-10 20:01:26.151572 EDT | -----------------------  ----------
2017-06-10 20:01:26.151894 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #103 | Training started
2017-06-10 20:01:41.616879 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #103 | Training finished
2017-06-10 20:01:41.617401 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #103 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 20:01:41.617786 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #103 | Collecting samples for evaluation
2017-06-10 20:01:54.273145 EDT | -----------------------  ----------
2017-06-10 20:01:54.273914 EDT | Epoch                    103
2017-06-10 20:01:54.274499 EDT | Iteration                103
2017-06-10 20:01:54.274970 EDT | AverageReturn            355.182
2017-06-10 20:01:54.275411 EDT | StdReturn                107.163
2017-06-10 20:01:54.275899 EDT | MaxReturn                449.899
2017-06-10 20:01:54.276306 EDT | MinReturn                137.342
2017-06-10 20:01:54.276739 EDT | AverageEsReturn          276.905
2017-06-10 20:01:54.277231 EDT | StdEsReturn              169.692
2017-06-10 20:01:54.277687 EDT | MaxEsReturn              613.56
2017-06-10 20:01:54.278159 EDT | MinEsReturn               12.3376
2017-06-10 20:01:54.278626 EDT | AverageDiscountedReturn  168.654
2017-06-10 20:01:54.278937 EDT | AverageQLoss               0.851229
2017-06-10 20:01:54.279395 EDT | AveragePolicySurr        -17.862
2017-06-10 20:01:54.279595 EDT | AverageQ                  17.3299
2017-06-10 20:01:54.279955 EDT | AverageAbsQ               17.3431
2017-06-10 20:01:54.280335 EDT | AverageY                  17.3315
2017-06-10 20:01:54.280695 EDT | AverageAbsY               17.3337
2017-06-10 20:01:54.281046 EDT | AverageAbsQYDiff           0.419885
2017-06-10 20:01:54.281440 EDT | AverageAction              0.869201
2017-06-10 20:01:54.281649 EDT | PolicyRegParamNorm        40.9301
2017-06-10 20:01:54.282161 EDT | QFunRegParamNorm          44.3346
2017-06-10 20:01:54.282652 EDT | -----------------------  ----------
2017-06-10 20:01:54.283112 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #104 | Training started
2017-06-10 20:02:08.373378 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #104 | Training finished
2017-06-10 20:02:08.374195 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #104 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 20:02:08.374407 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #104 | Collecting samples for evaluation
2017-06-10 20:02:20.356241 EDT | -----------------------  ----------
2017-06-10 20:02:20.357223 EDT | Epoch                    104
2017-06-10 20:02:20.357584 EDT | Iteration                104
2017-06-10 20:02:20.358021 EDT | AverageReturn            269.314
2017-06-10 20:02:20.358301 EDT | StdReturn                104.929
2017-06-10 20:02:20.358630 EDT | MaxReturn                553.176
2017-06-10 20:02:20.358951 EDT | MinReturn                144.726
2017-06-10 20:02:20.361794 EDT | AverageEsReturn          251.74
2017-06-10 20:02:20.362757 EDT | StdEsReturn              172.62
2017-06-10 20:02:20.363094 EDT | MaxEsReturn              607.92
2017-06-10 20:02:20.363421 EDT | MinEsReturn                7.87247
2017-06-10 20:02:20.364122 EDT | AverageDiscountedReturn  142.737
2017-06-10 20:02:20.364396 EDT | AverageQLoss               0.859605
2017-06-10 20:02:20.364723 EDT | AveragePolicySurr        -18.0369
2017-06-10 20:02:20.365054 EDT | AverageQ                  17.5096
2017-06-10 20:02:20.365382 EDT | AverageAbsQ               17.5228
2017-06-10 20:02:20.365656 EDT | AverageY                  17.5128
2017-06-10 20:02:20.365953 EDT | AverageAbsY               17.5153
2017-06-10 20:02:20.366358 EDT | AverageAbsQYDiff           0.422624
2017-06-10 20:02:20.366638 EDT | AverageAction              0.850607
2017-06-10 20:02:20.366958 EDT | PolicyRegParamNorm        41.1008
2017-06-10 20:02:20.367285 EDT | QFunRegParamNorm          44.5824
2017-06-10 20:02:20.367604 EDT | -----------------------  ----------
2017-06-10 20:02:20.368053 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #105 | Training started
2017-06-10 20:02:34.373877 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #105 | Training finished
2017-06-10 20:02:34.374669 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #105 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 20:02:34.374859 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #105 | Collecting samples for evaluation
2017-06-10 20:02:46.915893 EDT | -----------------------  ----------
2017-06-10 20:02:46.916967 EDT | Epoch                    105
2017-06-10 20:02:46.917246 EDT | Iteration                105
2017-06-10 20:02:46.917923 EDT | AverageReturn            373.93
2017-06-10 20:02:46.918272 EDT | StdReturn                 32.3621
2017-06-10 20:02:46.918551 EDT | MaxReturn                433.631
2017-06-10 20:02:46.918933 EDT | MinReturn                286.263
2017-06-10 20:02:46.919272 EDT | AverageEsReturn          284.907
2017-06-10 20:02:46.919657 EDT | StdEsReturn              146.706
2017-06-10 20:02:46.921936 EDT | MaxEsReturn              528.002
2017-06-10 20:02:46.922279 EDT | MinEsReturn               46.01
2017-06-10 20:02:46.922666 EDT | AverageDiscountedReturn  176.367
2017-06-10 20:02:46.923087 EDT | AverageQLoss               1.09476
2017-06-10 20:02:46.923484 EDT | AveragePolicySurr        -18.1912
2017-06-10 20:02:46.923890 EDT | AverageQ                  17.672
2017-06-10 20:02:46.924309 EDT | AverageAbsQ               17.6884
2017-06-10 20:02:46.926612 EDT | AverageY                  17.6746
2017-06-10 20:02:46.927089 EDT | AverageAbsY               17.6777
2017-06-10 20:02:46.927644 EDT | AverageAbsQYDiff           0.453989
2017-06-10 20:02:46.928008 EDT | AverageAction              0.848173
2017-06-10 20:02:46.928333 EDT | PolicyRegParamNorm        41.2014
2017-06-10 20:02:46.928811 EDT | QFunRegParamNorm          44.8817
2017-06-10 20:02:46.929105 EDT | -----------------------  ----------
2017-06-10 20:02:46.929873 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #106 | Training started
2017-06-10 20:03:00.991739 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #106 | Training finished
2017-06-10 20:03:00.993122 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #106 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 20:03:00.993506 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #106 | Collecting samples for evaluation
2017-06-10 20:03:12.955641 EDT | -----------------------  ----------
2017-06-10 20:03:12.956259 EDT | Epoch                    106
2017-06-10 20:03:12.956549 EDT | Iteration                106
2017-06-10 20:03:12.956932 EDT | AverageReturn            305.273
2017-06-10 20:03:12.957205 EDT | StdReturn                 51.3869
2017-06-10 20:03:12.957479 EDT | MaxReturn                410.115
2017-06-10 20:03:12.957709 EDT | MinReturn                225.684
2017-06-10 20:03:12.957957 EDT | AverageEsReturn          228.468
2017-06-10 20:03:12.958158 EDT | StdEsReturn               99.9659
2017-06-10 20:03:12.958317 EDT | MaxEsReturn              392.652
2017-06-10 20:03:12.958494 EDT | MinEsReturn               58.7172
2017-06-10 20:03:12.958717 EDT | AverageDiscountedReturn  157.514
2017-06-10 20:03:12.958895 EDT | AverageQLoss               0.873679
2017-06-10 20:03:12.959046 EDT | AveragePolicySurr        -18.3678
2017-06-10 20:03:12.959255 EDT | AverageQ                  17.8572
2017-06-10 20:03:12.959622 EDT | AverageAbsQ               17.8721
2017-06-10 20:03:12.959810 EDT | AverageY                  17.8587
2017-06-10 20:03:12.960228 EDT | AverageAbsY               17.8614
2017-06-10 20:03:12.960445 EDT | AverageAbsQYDiff           0.433031
2017-06-10 20:03:12.960707 EDT | AverageAction              0.879508
2017-06-10 20:03:12.961003 EDT | PolicyRegParamNorm        41.3478
2017-06-10 20:03:12.961206 EDT | QFunRegParamNorm          45.1377
2017-06-10 20:03:12.961365 EDT | -----------------------  ----------
2017-06-10 20:03:12.962993 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #107 | Training started
2017-06-10 20:03:28.183027 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #107 | Training finished
2017-06-10 20:03:28.183906 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #107 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 20:03:28.184229 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #107 | Collecting samples for evaluation
2017-06-10 20:03:39.452529 EDT | -----------------------  ----------
2017-06-10 20:03:39.453437 EDT | Epoch                    107
2017-06-10 20:03:39.453810 EDT | Iteration                107
2017-06-10 20:03:39.454095 EDT | AverageReturn            239.179
2017-06-10 20:03:39.454524 EDT | StdReturn                140.347
2017-06-10 20:03:39.454956 EDT | MaxReturn                534.813
2017-06-10 20:03:39.455298 EDT | MinReturn                131.45
2017-06-10 20:03:39.455639 EDT | AverageEsReturn          184.322
2017-06-10 20:03:39.455971 EDT | StdEsReturn              165.183
2017-06-10 20:03:39.456300 EDT | MaxEsReturn              564.316
2017-06-10 20:03:39.456627 EDT | MinEsReturn                5.61891
2017-06-10 20:03:39.456955 EDT | AverageDiscountedReturn  129.142
2017-06-10 20:03:39.457289 EDT | AverageQLoss               0.871395
2017-06-10 20:03:39.457594 EDT | AveragePolicySurr        -18.5813
2017-06-10 20:03:39.457923 EDT | AverageQ                  18.0494
2017-06-10 20:03:39.458250 EDT | AverageAbsQ               18.0636
2017-06-10 20:03:39.458578 EDT | AverageY                  18.0517
2017-06-10 20:03:39.458902 EDT | AverageAbsY               18.0541
2017-06-10 20:03:39.459235 EDT | AverageAbsQYDiff           0.422381
2017-06-10 20:03:39.459544 EDT | AverageAction              0.872897
2017-06-10 20:03:39.459810 EDT | PolicyRegParamNorm        41.4914
2017-06-10 20:03:39.460138 EDT | QFunRegParamNorm          45.3717
2017-06-10 20:03:39.460469 EDT | -----------------------  ----------
2017-06-10 20:03:39.460956 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #108 | Training started
2017-06-10 20:03:54.112682 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #108 | Training finished
2017-06-10 20:03:54.121609 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #108 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 20:03:54.122028 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #108 | Collecting samples for evaluation
2017-06-10 20:04:06.671006 EDT | -----------------------  ----------
2017-06-10 20:04:06.672593 EDT | Epoch                    108
2017-06-10 20:04:06.672796 EDT | Iteration                108
2017-06-10 20:04:06.672993 EDT | AverageReturn            532.318
2017-06-10 20:04:06.673231 EDT | StdReturn                160.937
2017-06-10 20:04:06.673415 EDT | MaxReturn                846.347
2017-06-10 20:04:06.673596 EDT | MinReturn                272.073
2017-06-10 20:04:06.673943 EDT | AverageEsReturn          253.031
2017-06-10 20:04:06.674388 EDT | StdEsReturn              127.237
2017-06-10 20:04:06.674808 EDT | MaxEsReturn              504.941
2017-06-10 20:04:06.675267 EDT | MinEsReturn              119.986
2017-06-10 20:04:06.675683 EDT | AverageDiscountedReturn  205.703
2017-06-10 20:04:06.676097 EDT | AverageQLoss               0.99668
2017-06-10 20:04:06.676511 EDT | AveragePolicySurr        -18.8149
2017-06-10 20:04:06.676947 EDT | AverageQ                  18.2449
2017-06-10 20:04:06.677139 EDT | AverageAbsQ               18.2593
2017-06-10 20:04:06.677324 EDT | AverageY                  18.2484
2017-06-10 20:04:06.677643 EDT | AverageAbsY               18.251
2017-06-10 20:04:06.677897 EDT | AverageAbsQYDiff           0.460391
2017-06-10 20:04:06.678079 EDT | AverageAction              0.875386
2017-06-10 20:04:06.678260 EDT | PolicyRegParamNorm        41.5999
2017-06-10 20:04:06.678441 EDT | QFunRegParamNorm          45.6136
2017-06-10 20:04:06.678670 EDT | -----------------------  ----------
2017-06-10 20:04:06.678968 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #109 | Training started
2017-06-10 20:04:20.736782 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #109 | Training finished
2017-06-10 20:04:20.737580 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #109 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 20:04:20.737799 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #109 | Collecting samples for evaluation
2017-06-10 20:04:32.591860 EDT | -----------------------  -----------
2017-06-10 20:04:32.592788 EDT | Epoch                     109
2017-06-10 20:04:32.594403 EDT | Iteration                 109
2017-06-10 20:04:32.595164 EDT | AverageReturn             467.013
2017-06-10 20:04:32.595569 EDT | StdReturn                 104.968
2017-06-10 20:04:32.595938 EDT | MaxReturn                1002.07
2017-06-10 20:04:32.596310 EDT | MinReturn                 257.524
2017-06-10 20:04:32.596681 EDT | AverageEsReturn           206.548
2017-06-10 20:04:32.597046 EDT | StdEsReturn               123.142
2017-06-10 20:04:32.597435 EDT | MaxEsReturn               432.424
2017-06-10 20:04:32.597828 EDT | MinEsReturn                11.9448
2017-06-10 20:04:32.598203 EDT | AverageDiscountedReturn   196.024
2017-06-10 20:04:32.598560 EDT | AverageQLoss                1.09749
2017-06-10 20:04:32.598946 EDT | AveragePolicySurr         -18.9196
2017-06-10 20:04:32.599327 EDT | AverageQ                   18.3633
2017-06-10 20:04:32.599707 EDT | AverageAbsQ                18.3776
2017-06-10 20:04:32.600086 EDT | AverageY                   18.3663
2017-06-10 20:04:32.600466 EDT | AverageAbsY                18.3695
2017-06-10 20:04:32.600846 EDT | AverageAbsQYDiff            0.46541
2017-06-10 20:04:32.601225 EDT | AverageAction               0.856487
2017-06-10 20:04:32.601604 EDT | PolicyRegParamNorm         41.7581
2017-06-10 20:04:32.601983 EDT | QFunRegParamNorm           45.9027
2017-06-10 20:04:32.602348 EDT | -----------------------  -----------
2017-06-10 20:04:32.602900 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #110 | Training started
2017-06-10 20:04:46.688260 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #110 | Training finished
2017-06-10 20:04:46.689039 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #110 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 20:04:46.689264 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #110 | Collecting samples for evaluation
2017-06-10 20:04:58.759780 EDT | -----------------------  ----------
2017-06-10 20:04:58.760710 EDT | Epoch                    110
2017-06-10 20:04:58.760926 EDT | Iteration                110
2017-06-10 20:04:58.761162 EDT | AverageReturn            461.189
2017-06-10 20:04:58.761351 EDT | StdReturn                110.801
2017-06-10 20:04:58.761548 EDT | MaxReturn                624.705
2017-06-10 20:04:58.762002 EDT | MinReturn                295.9
2017-06-10 20:04:58.762187 EDT | AverageEsReturn          245.041
2017-06-10 20:04:58.762371 EDT | StdEsReturn              110.745
2017-06-10 20:04:58.762552 EDT | MaxEsReturn              429.702
2017-06-10 20:04:58.762741 EDT | MinEsReturn               10.7704
2017-06-10 20:04:58.762922 EDT | AverageDiscountedReturn  195.84
2017-06-10 20:04:58.763101 EDT | AverageQLoss               1.12183
2017-06-10 20:04:58.763362 EDT | AveragePolicySurr        -19.2034
2017-06-10 20:04:58.763541 EDT | AverageQ                  18.6359
2017-06-10 20:04:58.763722 EDT | AverageAbsQ               18.6501
2017-06-10 20:04:58.763882 EDT | AverageY                  18.6383
2017-06-10 20:04:58.764039 EDT | AverageAbsY               18.6418
2017-06-10 20:04:58.764195 EDT | AverageAbsQYDiff           0.472097
2017-06-10 20:04:58.764356 EDT | AverageAction              0.906811
2017-06-10 20:04:58.764540 EDT | PolicyRegParamNorm        41.9341
2017-06-10 20:04:58.764720 EDT | QFunRegParamNorm          46.151
2017-06-10 20:04:58.764877 EDT | -----------------------  ----------
2017-06-10 20:04:58.765168 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #111 | Training started
2017-06-10 20:05:13.469243 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #111 | Training finished
2017-06-10 20:05:13.470097 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #111 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 20:05:13.470388 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #111 | Collecting samples for evaluation
2017-06-10 20:05:25.557924 EDT | -----------------------  ----------
2017-06-10 20:05:25.558871 EDT | Epoch                    111
2017-06-10 20:05:25.559182 EDT | Iteration                111
2017-06-10 20:05:25.559397 EDT | AverageReturn            387.609
2017-06-10 20:05:25.559572 EDT | StdReturn                 57.9732
2017-06-10 20:05:25.559742 EDT | MaxReturn                493.602
2017-06-10 20:05:25.559991 EDT | MinReturn                295.986
2017-06-10 20:05:25.560385 EDT | AverageEsReturn          230.63
2017-06-10 20:05:25.560696 EDT | StdEsReturn              151.409
2017-06-10 20:05:25.560937 EDT | MaxEsReturn              496.697
2017-06-10 20:05:25.561175 EDT | MinEsReturn               41.2592
2017-06-10 20:05:25.561419 EDT | AverageDiscountedReturn  179.773
2017-06-10 20:05:25.561574 EDT | AverageQLoss               0.85892
2017-06-10 20:05:25.563500 EDT | AveragePolicySurr        -19.507
2017-06-10 20:05:25.563784 EDT | AverageQ                  18.921
2017-06-10 20:05:25.564041 EDT | AverageAbsQ               18.9352
2017-06-10 20:05:25.564295 EDT | AverageY                  18.9234
2017-06-10 20:05:25.564548 EDT | AverageAbsY               18.9261
2017-06-10 20:05:25.564810 EDT | AverageAbsQYDiff           0.437081
2017-06-10 20:05:25.565066 EDT | AverageAction              0.893385
2017-06-10 20:05:25.565317 EDT | PolicyRegParamNorm        42.0675
2017-06-10 20:05:25.565566 EDT | QFunRegParamNorm          46.3727
2017-06-10 20:05:25.565832 EDT | -----------------------  ----------
2017-06-10 20:05:25.566213 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #112 | Training started
2017-06-10 20:05:40.479151 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #112 | Training finished
2017-06-10 20:05:40.479941 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #112 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 20:05:40.480133 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #112 | Collecting samples for evaluation
2017-06-10 20:05:52.281139 EDT | -----------------------  ----------
2017-06-10 20:05:52.282173 EDT | Epoch                    112
2017-06-10 20:05:52.282767 EDT | Iteration                112
2017-06-10 20:05:52.283179 EDT | AverageReturn            482.853
2017-06-10 20:05:52.283521 EDT | StdReturn                 83.8413
2017-06-10 20:05:52.283768 EDT | MaxReturn                687.105
2017-06-10 20:05:52.284006 EDT | MinReturn                313.635
2017-06-10 20:05:52.284249 EDT | AverageEsReturn          166.364
2017-06-10 20:05:52.284584 EDT | StdEsReturn              146.283
2017-06-10 20:05:52.284888 EDT | MaxEsReturn              427.367
2017-06-10 20:05:52.285303 EDT | MinEsReturn                9.47179
2017-06-10 20:05:52.285548 EDT | AverageDiscountedReturn  203.168
2017-06-10 20:05:52.285766 EDT | AverageQLoss               1.15131
2017-06-10 20:05:52.286050 EDT | AveragePolicySurr        -19.6659
2017-06-10 20:05:52.286245 EDT | AverageQ                  19.0795
2017-06-10 20:05:52.286496 EDT | AverageAbsQ               19.0958
2017-06-10 20:05:52.286691 EDT | AverageY                  19.0831
2017-06-10 20:05:52.286914 EDT | AverageAbsY               19.0865
2017-06-10 20:05:52.287107 EDT | AverageAbsQYDiff           0.483134
2017-06-10 20:05:52.287297 EDT | AverageAction              0.875598
2017-06-10 20:05:52.287488 EDT | PolicyRegParamNorm        42.2376
2017-06-10 20:05:52.287806 EDT | QFunRegParamNorm          46.6242
2017-06-10 20:05:52.288001 EDT | -----------------------  ----------
2017-06-10 20:05:52.288372 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #113 | Training started
2017-06-10 20:06:06.782920 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #113 | Training finished
2017-06-10 20:06:06.783957 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #113 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 20:06:06.784340 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #113 | Collecting samples for evaluation
2017-06-10 20:06:18.780514 EDT | -----------------------  ----------
2017-06-10 20:06:18.780990 EDT | Epoch                    113
2017-06-10 20:06:18.781285 EDT | Iteration                113
2017-06-10 20:06:18.781538 EDT | AverageReturn            407.459
2017-06-10 20:06:18.782715 EDT | StdReturn                 72.9309
2017-06-10 20:06:18.782994 EDT | MaxReturn                637.764
2017-06-10 20:06:18.783246 EDT | MinReturn                313.813
2017-06-10 20:06:18.783493 EDT | AverageEsReturn          289.945
2017-06-10 20:06:18.783737 EDT | StdEsReturn              102.799
2017-06-10 20:06:18.783978 EDT | MaxEsReturn              474.236
2017-06-10 20:06:18.784219 EDT | MinEsReturn              116.435
2017-06-10 20:06:18.784459 EDT | AverageDiscountedReturn  184.59
2017-06-10 20:06:18.784698 EDT | AverageQLoss               1.21835
2017-06-10 20:06:18.784938 EDT | AveragePolicySurr        -19.7852
2017-06-10 20:06:18.785185 EDT | AverageQ                  19.1871
2017-06-10 20:06:18.785427 EDT | AverageAbsQ               19.203
2017-06-10 20:06:18.785668 EDT | AverageY                  19.1898
2017-06-10 20:06:18.785926 EDT | AverageAbsY               19.1936
2017-06-10 20:06:18.786168 EDT | AverageAbsQYDiff           0.482556
2017-06-10 20:06:18.786408 EDT | AverageAction              0.894304
2017-06-10 20:06:18.786648 EDT | PolicyRegParamNorm        42.4243
2017-06-10 20:06:18.786889 EDT | QFunRegParamNorm          46.8721
2017-06-10 20:06:18.787130 EDT | -----------------------  ----------
2017-06-10 20:06:18.787523 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #114 | Training started
2017-06-10 20:06:32.053431 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #114 | Training finished
2017-06-10 20:06:32.054398 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #114 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 20:06:32.055082 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #114 | Collecting samples for evaluation
2017-06-10 20:06:44.163263 EDT | -----------------------  ----------
2017-06-10 20:06:44.164166 EDT | Epoch                    114
2017-06-10 20:06:44.164520 EDT | Iteration                114
2017-06-10 20:06:44.164791 EDT | AverageReturn            287.366
2017-06-10 20:06:44.165088 EDT | StdReturn                115.416
2017-06-10 20:06:44.165420 EDT | MaxReturn                612.179
2017-06-10 20:06:44.165770 EDT | MinReturn                115.527
2017-06-10 20:06:44.166087 EDT | AverageEsReturn          206.486
2017-06-10 20:06:44.166419 EDT | StdEsReturn              139.624
2017-06-10 20:06:44.166750 EDT | MaxEsReturn              515.066
2017-06-10 20:06:44.167087 EDT | MinEsReturn               12.4524
2017-06-10 20:06:44.167424 EDT | AverageDiscountedReturn  147.774
2017-06-10 20:06:44.167728 EDT | AverageQLoss               1.12143
2017-06-10 20:06:44.168543 EDT | AveragePolicySurr        -20.0748
2017-06-10 20:06:44.168888 EDT | AverageQ                  19.4857
2017-06-10 20:06:44.169228 EDT | AverageAbsQ               19.5038
2017-06-10 20:06:44.169775 EDT | AverageY                  19.4893
2017-06-10 20:06:44.170051 EDT | AverageAbsY               19.4936
2017-06-10 20:06:44.170384 EDT | AverageAbsQYDiff           0.493144
2017-06-10 20:06:44.170721 EDT | AverageAction              0.868268
2017-06-10 20:06:44.171300 EDT | PolicyRegParamNorm        42.5607
2017-06-10 20:06:44.174418 EDT | QFunRegParamNorm          47.0796
2017-06-10 20:06:44.174745 EDT | -----------------------  ----------
2017-06-10 20:06:44.175191 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #115 | Training started
2017-06-10 20:06:59.326258 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #115 | Training finished
2017-06-10 20:06:59.327013 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #115 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 20:06:59.327229 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #115 | Collecting samples for evaluation
2017-06-10 20:07:09.961545 EDT | -----------------------  -----------
2017-06-10 20:07:09.963744 EDT | Epoch                     115
2017-06-10 20:07:09.964235 EDT | Iteration                 115
2017-06-10 20:07:09.964608 EDT | AverageReturn             739.333
2017-06-10 20:07:09.965028 EDT | StdReturn                 340.762
2017-06-10 20:07:09.965466 EDT | MaxReturn                1895.72
2017-06-10 20:07:09.965836 EDT | MinReturn                 252.185
2017-06-10 20:07:09.966264 EDT | AverageEsReturn           159.804
2017-06-10 20:07:09.966693 EDT | StdEsReturn               121.664
2017-06-10 20:07:09.967126 EDT | MaxEsReturn               558.22
2017-06-10 20:07:09.967474 EDT | MinEsReturn                32.6137
2017-06-10 20:07:09.967761 EDT | AverageDiscountedReturn   213.222
2017-06-10 20:07:09.968060 EDT | AverageQLoss                1.05377
2017-06-10 20:07:09.968402 EDT | AveragePolicySurr         -20.2312
2017-06-10 20:07:09.968749 EDT | AverageQ                   19.6329
2017-06-10 20:07:09.969080 EDT | AverageAbsQ                19.6485
2017-06-10 20:07:09.969346 EDT | AverageY                   19.6359
2017-06-10 20:07:09.969649 EDT | AverageAbsY                19.6392
2017-06-10 20:07:09.969996 EDT | AverageAbsQYDiff            0.469756
2017-06-10 20:07:09.970341 EDT | AverageAction               0.826767
2017-06-10 20:07:09.970674 EDT | PolicyRegParamNorm         42.7303
2017-06-10 20:07:09.970942 EDT | QFunRegParamNorm           47.2685
2017-06-10 20:07:09.971236 EDT | -----------------------  -----------
2017-06-10 20:07:09.971712 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #116 | Training started
2017-06-10 20:07:25.437304 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #116 | Training finished
2017-06-10 20:07:25.438320 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #116 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 20:07:25.438543 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #116 | Collecting samples for evaluation
2017-06-10 20:07:37.689130 EDT | -----------------------  ----------
2017-06-10 20:07:37.690134 EDT | Epoch                    116
2017-06-10 20:07:37.690500 EDT | Iteration                116
2017-06-10 20:07:37.690935 EDT | AverageReturn            453.492
2017-06-10 20:07:37.691299 EDT | StdReturn                 40.6031
2017-06-10 20:07:37.691660 EDT | MaxReturn                620.354
2017-06-10 20:07:37.692098 EDT | MinReturn                351.596
2017-06-10 20:07:37.692544 EDT | AverageEsReturn          253.441
2017-06-10 20:07:37.692987 EDT | StdEsReturn              182.289
2017-06-10 20:07:37.693430 EDT | MaxEsReturn              599.955
2017-06-10 20:07:37.695316 EDT | MinEsReturn               53.9999
2017-06-10 20:07:37.695687 EDT | AverageDiscountedReturn  196.455
2017-06-10 20:07:37.696033 EDT | AverageQLoss               1.1353
2017-06-10 20:07:37.696378 EDT | AveragePolicySurr        -20.3785
2017-06-10 20:07:37.696722 EDT | AverageQ                  19.7887
2017-06-10 20:07:37.697062 EDT | AverageAbsQ               19.8062
2017-06-10 20:07:37.697401 EDT | AverageY                  19.7911
2017-06-10 20:07:37.697750 EDT | AverageAbsY               19.7943
2017-06-10 20:07:37.698094 EDT | AverageAbsQYDiff           0.49057
2017-06-10 20:07:37.698432 EDT | AverageAction              0.876133
2017-06-10 20:07:37.698771 EDT | PolicyRegParamNorm        42.9315
2017-06-10 20:07:37.701779 EDT | QFunRegParamNorm          47.4617
2017-06-10 20:07:37.703341 EDT | -----------------------  ----------
2017-06-10 20:07:37.705097 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #117 | Training started
2017-06-10 20:07:51.829729 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #117 | Training finished
2017-06-10 20:07:51.845799 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #117 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 20:07:51.846388 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #117 | Collecting samples for evaluation
2017-06-10 20:08:04.883227 EDT | -----------------------  ----------
2017-06-10 20:08:04.883664 EDT | Epoch                    117
2017-06-10 20:08:04.883989 EDT | Iteration                117
2017-06-10 20:08:04.884434 EDT | AverageReturn            312.845
2017-06-10 20:08:04.884854 EDT | StdReturn                 49.6798
2017-06-10 20:08:04.885183 EDT | MaxReturn                419.474
2017-06-10 20:08:04.885577 EDT | MinReturn                153.293
2017-06-10 20:08:04.885943 EDT | AverageEsReturn          244.898
2017-06-10 20:08:04.886308 EDT | StdEsReturn              190.743
2017-06-10 20:08:04.886635 EDT | MaxEsReturn              677.999
2017-06-10 20:08:04.886954 EDT | MinEsReturn                5.89479
2017-06-10 20:08:04.887305 EDT | AverageDiscountedReturn  160.321
2017-06-10 20:08:04.887681 EDT | AverageQLoss               1.18977
2017-06-10 20:08:04.888070 EDT | AveragePolicySurr        -20.5034
2017-06-10 20:08:04.888435 EDT | AverageQ                  19.921
2017-06-10 20:08:04.888817 EDT | AverageAbsQ               19.9399
2017-06-10 20:08:04.889125 EDT | AverageY                  19.9249
2017-06-10 20:08:04.889335 EDT | AverageAbsY               19.9292
2017-06-10 20:08:04.889546 EDT | AverageAbsQYDiff           0.501922
2017-06-10 20:08:04.889946 EDT | AverageAction              0.876417
2017-06-10 20:08:04.890325 EDT | PolicyRegParamNorm        43.0409
2017-06-10 20:08:04.890704 EDT | QFunRegParamNorm          47.6743
2017-06-10 20:08:04.891104 EDT | -----------------------  ----------
2017-06-10 20:08:04.891623 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #118 | Training started
2017-06-10 20:08:19.267489 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #118 | Training finished
2017-06-10 20:08:19.268369 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #118 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 20:08:19.268589 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #118 | Collecting samples for evaluation
2017-06-10 20:08:32.009482 EDT | -----------------------  ----------
2017-06-10 20:08:32.010424 EDT | Epoch                    118
2017-06-10 20:08:32.011067 EDT | Iteration                118
2017-06-10 20:08:32.011607 EDT | AverageReturn            309.888
2017-06-10 20:08:32.011803 EDT | StdReturn                 52.8804
2017-06-10 20:08:32.011989 EDT | MaxReturn                379.745
2017-06-10 20:08:32.012171 EDT | MinReturn                151.126
2017-06-10 20:08:32.012353 EDT | AverageEsReturn          267.541
2017-06-10 20:08:32.012534 EDT | StdEsReturn              105.374
2017-06-10 20:08:32.012713 EDT | MaxEsReturn              451.55
2017-06-10 20:08:32.012894 EDT | MinEsReturn               88.0239
2017-06-10 20:08:32.013075 EDT | AverageDiscountedReturn  160.028
2017-06-10 20:08:32.013254 EDT | AverageQLoss               1.12432
2017-06-10 20:08:32.014380 EDT | AveragePolicySurr        -20.8215
2017-06-10 20:08:32.014658 EDT | AverageQ                  20.2144
2017-06-10 20:08:32.014844 EDT | AverageAbsQ               20.2295
2017-06-10 20:08:32.015030 EDT | AverageY                  20.2148
2017-06-10 20:08:32.015206 EDT | AverageAbsY               20.2189
2017-06-10 20:08:32.015373 EDT | AverageAbsQYDiff           0.49824
2017-06-10 20:08:32.015644 EDT | AverageAction              0.885022
2017-06-10 20:08:32.015875 EDT | PolicyRegParamNorm        43.203
2017-06-10 20:08:32.016139 EDT | QFunRegParamNorm          47.9099
2017-06-10 20:08:32.016302 EDT | -----------------------  ----------
2017-06-10 20:08:32.016566 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #119 | Training started
2017-06-10 20:08:46.565402 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #119 | Training finished
2017-06-10 20:08:46.566299 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #119 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 20:08:46.566665 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #119 | Collecting samples for evaluation
2017-06-10 20:08:58.961022 EDT | -----------------------  ----------
2017-06-10 20:08:58.961945 EDT | Epoch                    119
2017-06-10 20:08:58.962305 EDT | Iteration                119
2017-06-10 20:08:58.962624 EDT | AverageReturn            340.884
2017-06-10 20:08:58.962952 EDT | StdReturn                 73.6341
2017-06-10 20:08:58.963271 EDT | MaxReturn                521.838
2017-06-10 20:08:58.963590 EDT | MinReturn                162.882
2017-06-10 20:08:58.963927 EDT | AverageEsReturn          220.585
2017-06-10 20:08:58.964176 EDT | StdEsReturn              136.606
2017-06-10 20:08:58.964506 EDT | MaxEsReturn              548.239
2017-06-10 20:08:58.964841 EDT | MinEsReturn                7.94197
2017-06-10 20:08:58.965104 EDT | AverageDiscountedReturn  167.523
2017-06-10 20:08:58.965430 EDT | AverageQLoss               1.35306
2017-06-10 20:08:58.965769 EDT | AveragePolicySurr        -20.9859
2017-06-10 20:08:58.966454 EDT | AverageQ                  20.3655
2017-06-10 20:08:58.966793 EDT | AverageAbsQ               20.3787
2017-06-10 20:08:58.967094 EDT | AverageY                  20.3692
2017-06-10 20:08:58.967425 EDT | AverageAbsY               20.372
2017-06-10 20:08:58.967763 EDT | AverageAbsQYDiff           0.516435
2017-06-10 20:08:58.968065 EDT | AverageAction              0.896862
2017-06-10 20:08:58.968394 EDT | PolicyRegParamNorm        43.3635
2017-06-10 20:08:58.968724 EDT | QFunRegParamNorm          48.12
2017-06-10 20:08:58.968929 EDT | -----------------------  ----------
2017-06-10 20:08:58.969203 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #120 | Training started
2017-06-10 20:09:14.184324 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #120 | Training finished
2017-06-10 20:09:14.185155 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #120 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 20:09:14.185500 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #120 | Collecting samples for evaluation
2017-06-10 20:09:25.423898 EDT | -----------------------  ----------
2017-06-10 20:09:25.424869 EDT | Epoch                    120
2017-06-10 20:09:25.425274 EDT | Iteration                120
2017-06-10 20:09:25.425740 EDT | AverageReturn            280.888
2017-06-10 20:09:25.426125 EDT | StdReturn                 84.5694
2017-06-10 20:09:25.426501 EDT | MaxReturn                476.718
2017-06-10 20:09:25.426879 EDT | MinReturn                146.432
2017-06-10 20:09:25.427249 EDT | AverageEsReturn          248.464
2017-06-10 20:09:25.427620 EDT | StdEsReturn              170.798
2017-06-10 20:09:25.427994 EDT | MaxEsReturn              603.829
2017-06-10 20:09:25.428364 EDT | MinEsReturn               11.7423
2017-06-10 20:09:25.428731 EDT | AverageDiscountedReturn  148.696
2017-06-10 20:09:25.429100 EDT | AverageQLoss               1.36012
2017-06-10 20:09:25.429468 EDT | AveragePolicySurr        -21.1468
2017-06-10 20:09:25.429953 EDT | AverageQ                  20.5325
2017-06-10 20:09:25.430419 EDT | AverageAbsQ               20.5495
2017-06-10 20:09:25.430966 EDT | AverageY                  20.535
2017-06-10 20:09:25.431352 EDT | AverageAbsY               20.541
2017-06-10 20:09:25.437517 EDT | AverageAbsQYDiff           0.521679
2017-06-10 20:09:25.437912 EDT | AverageAction              0.888227
2017-06-10 20:09:25.440256 EDT | PolicyRegParamNorm        43.5152
2017-06-10 20:09:25.440630 EDT | QFunRegParamNorm          48.3714
2017-06-10 20:09:25.441008 EDT | -----------------------  ----------
2017-06-10 20:09:25.441521 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #121 | Training started
2017-06-10 20:09:40.255083 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #121 | Training finished
2017-06-10 20:09:40.255486 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #121 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 20:09:40.255687 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #121 | Collecting samples for evaluation
2017-06-10 20:09:52.430790 EDT | -----------------------  ----------
2017-06-10 20:09:52.437557 EDT | Epoch                    121
2017-06-10 20:09:52.437827 EDT | Iteration                121
2017-06-10 20:09:52.438010 EDT | AverageReturn            386.154
2017-06-10 20:09:52.438233 EDT | StdReturn                176.605
2017-06-10 20:09:52.438456 EDT | MaxReturn                913.878
2017-06-10 20:09:52.438611 EDT | MinReturn                144.091
2017-06-10 20:09:52.438763 EDT | AverageEsReturn          313.145
2017-06-10 20:09:52.438987 EDT | StdEsReturn              191.044
2017-06-10 20:09:52.439215 EDT | MaxEsReturn              716.592
2017-06-10 20:09:52.439392 EDT | MinEsReturn              102.938
2017-06-10 20:09:52.439547 EDT | AverageDiscountedReturn  170.889
2017-06-10 20:09:52.439753 EDT | AverageQLoss               1.05077
2017-06-10 20:09:52.439954 EDT | AveragePolicySurr        -21.2767
2017-06-10 20:09:52.440227 EDT | AverageQ                  20.6852
2017-06-10 20:09:52.440463 EDT | AverageAbsQ               20.7039
2017-06-10 20:09:52.440646 EDT | AverageY                  20.6871
2017-06-10 20:09:52.440828 EDT | AverageAbsY               20.6914
2017-06-10 20:09:52.441206 EDT | AverageAbsQYDiff           0.489764
2017-06-10 20:09:52.441557 EDT | AverageAction              0.864782
2017-06-10 20:09:52.441988 EDT | PolicyRegParamNorm        43.5777
2017-06-10 20:09:52.442179 EDT | QFunRegParamNorm          48.5697
2017-06-10 20:09:52.442341 EDT | -----------------------  ----------
2017-06-10 20:09:52.442613 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #122 | Training started
2017-06-10 20:10:05.562124 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #122 | Training finished
2017-06-10 20:10:05.562857 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #122 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 20:10:05.563306 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #122 | Collecting samples for evaluation
2017-06-10 20:10:18.256798 EDT | -----------------------  ----------
2017-06-10 20:10:18.262536 EDT | Epoch                    122
2017-06-10 20:10:18.262917 EDT | Iteration                122
2017-06-10 20:10:18.263259 EDT | AverageReturn            284.837
2017-06-10 20:10:18.263592 EDT | StdReturn                 91.3343
2017-06-10 20:10:18.263941 EDT | MaxReturn                465.931
2017-06-10 20:10:18.264360 EDT | MinReturn                146.86
2017-06-10 20:10:18.264790 EDT | AverageEsReturn          275.196
2017-06-10 20:10:18.265221 EDT | StdEsReturn              139.694
2017-06-10 20:10:18.265634 EDT | MaxEsReturn              500.956
2017-06-10 20:10:18.266103 EDT | MinEsReturn               20.6321
2017-06-10 20:10:18.266520 EDT | AverageDiscountedReturn  149.779
2017-06-10 20:10:18.266954 EDT | AverageQLoss               1.19853
2017-06-10 20:10:18.267382 EDT | AveragePolicySurr        -21.4841
2017-06-10 20:10:18.267810 EDT | AverageQ                  20.8598
2017-06-10 20:10:18.268121 EDT | AverageAbsQ               20.8752
2017-06-10 20:10:18.268459 EDT | AverageY                  20.8631
2017-06-10 20:10:18.268774 EDT | AverageAbsY               20.8668
2017-06-10 20:10:18.269107 EDT | AverageAbsQYDiff           0.503249
2017-06-10 20:10:18.269444 EDT | AverageAction              0.898713
2017-06-10 20:10:18.269801 EDT | PolicyRegParamNorm        43.8038
2017-06-10 20:10:18.271173 EDT | QFunRegParamNorm          48.8109
2017-06-10 20:10:18.271755 EDT | -----------------------  ----------
2017-06-10 20:10:18.273892 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #123 | Training started
2017-06-10 20:10:32.743780 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #123 | Training finished
2017-06-10 20:10:32.744778 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #123 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 20:10:32.745197 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #123 | Collecting samples for evaluation
2017-06-10 20:10:44.260060 EDT | -----------------------  -----------
2017-06-10 20:10:44.261053 EDT | Epoch                     123
2017-06-10 20:10:44.261414 EDT | Iteration                 123
2017-06-10 20:10:44.261758 EDT | AverageReturn             533.716
2017-06-10 20:10:44.262083 EDT | StdReturn                 351.584
2017-06-10 20:10:44.262342 EDT | MaxReturn                2539.32
2017-06-10 20:10:44.262655 EDT | MinReturn                 204.212
2017-06-10 20:10:44.262973 EDT | AverageEsReturn           233.322
2017-06-10 20:10:44.263260 EDT | StdEsReturn               159.411
2017-06-10 20:10:44.263576 EDT | MaxEsReturn               606.813
2017-06-10 20:10:44.263896 EDT | MinEsReturn                51.9591
2017-06-10 20:10:44.264220 EDT | AverageDiscountedReturn   195.504
2017-06-10 20:10:44.264533 EDT | AverageQLoss                1.3639
2017-06-10 20:10:44.264857 EDT | AveragePolicySurr         -21.66
2017-06-10 20:10:44.265263 EDT | AverageQ                   21.0298
2017-06-10 20:10:44.265576 EDT | AverageAbsQ                21.0487
2017-06-10 20:10:44.265904 EDT | AverageY                   21.0328
2017-06-10 20:10:44.266242 EDT | AverageAbsY                21.0384
2017-06-10 20:10:44.266447 EDT | AverageAbsQYDiff            0.525882
2017-06-10 20:10:44.266688 EDT | AverageAction               0.847812
2017-06-10 20:10:44.267010 EDT | PolicyRegParamNorm         43.9307
2017-06-10 20:10:44.267317 EDT | QFunRegParamNorm           49.0763
2017-06-10 20:10:44.267592 EDT | -----------------------  -----------
2017-06-10 20:10:44.268772 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #124 | Training started
2017-06-10 20:10:59.395262 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #124 | Training finished
2017-06-10 20:10:59.396160 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #124 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 20:10:59.396382 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #124 | Collecting samples for evaluation
2017-06-10 20:11:11.877992 EDT | -----------------------  -----------
2017-06-10 20:11:11.878817 EDT | Epoch                     124
2017-06-10 20:11:11.879984 EDT | Iteration                 124
2017-06-10 20:11:11.880176 EDT | AverageReturn             472.102
2017-06-10 20:11:11.880360 EDT | StdReturn                 117.419
2017-06-10 20:11:11.880543 EDT | MaxReturn                1126.07
2017-06-10 20:11:11.880723 EDT | MinReturn                 250.721
2017-06-10 20:11:11.880902 EDT | AverageEsReturn           276.412
2017-06-10 20:11:11.881079 EDT | StdEsReturn               256.738
2017-06-10 20:11:11.881257 EDT | MaxEsReturn               962.17
2017-06-10 20:11:11.881513 EDT | MinEsReturn                11.4719
2017-06-10 20:11:11.881812 EDT | AverageDiscountedReturn   198.106
2017-06-10 20:11:11.882059 EDT | AverageQLoss                1.54071
2017-06-10 20:11:11.882299 EDT | AveragePolicySurr         -21.7716
2017-06-10 20:11:11.882541 EDT | AverageQ                   21.149
2017-06-10 20:11:11.882793 EDT | AverageAbsQ                21.1673
2017-06-10 20:11:11.885656 EDT | AverageY                   21.1523
2017-06-10 20:11:11.886069 EDT | AverageAbsY                21.1571
2017-06-10 20:11:11.886404 EDT | AverageAbsQYDiff            0.540499
2017-06-10 20:11:11.886584 EDT | AverageAction               0.861914
2017-06-10 20:11:11.886793 EDT | PolicyRegParamNorm         44.0465
2017-06-10 20:11:11.886980 EDT | QFunRegParamNorm           49.3011
2017-06-10 20:11:11.887170 EDT | -----------------------  -----------
2017-06-10 20:11:11.887448 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #125 | Training started
2017-06-10 20:11:26.771165 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #125 | Training finished
2017-06-10 20:11:26.772113 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #125 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 20:11:26.773498 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #125 | Collecting samples for evaluation
2017-06-10 20:11:39.299853 EDT | -----------------------  -----------
2017-06-10 20:11:39.302051 EDT | Epoch                     125
2017-06-10 20:11:39.302441 EDT | Iteration                 125
2017-06-10 20:11:39.303044 EDT | AverageReturn             976.569
2017-06-10 20:11:39.303384 EDT | StdReturn                 647.612
2017-06-10 20:11:39.303816 EDT | MaxReturn                2256.48
2017-06-10 20:11:39.304335 EDT | MinReturn                 238.288
2017-06-10 20:11:39.304680 EDT | AverageEsReturn           222.313
2017-06-10 20:11:39.305011 EDT | StdEsReturn               215.821
2017-06-10 20:11:39.305336 EDT | MaxEsReturn               781.228
2017-06-10 20:11:39.305827 EDT | MinEsReturn                 8.06719
2017-06-10 20:11:39.306080 EDT | AverageDiscountedReturn   186.238
2017-06-10 20:11:39.306408 EDT | AverageQLoss                1.3973
2017-06-10 20:11:39.306871 EDT | AveragePolicySurr         -22.0303
2017-06-10 20:11:39.307184 EDT | AverageQ                   21.3677
2017-06-10 20:11:39.307506 EDT | AverageAbsQ                21.3848
2017-06-10 20:11:39.307829 EDT | AverageY                   21.3724
2017-06-10 20:11:39.308223 EDT | AverageAbsY                21.3784
2017-06-10 20:11:39.308571 EDT | AverageAbsQYDiff            0.530034
2017-06-10 20:11:39.308773 EDT | AverageAction               0.721741
2017-06-10 20:11:39.309016 EDT | PolicyRegParamNorm         44.1975
2017-06-10 20:11:39.309180 EDT | QFunRegParamNorm           49.5347
2017-06-10 20:11:39.309484 EDT | -----------------------  -----------
2017-06-10 20:11:39.309827 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #126 | Training started
2017-06-10 20:11:54.623942 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #126 | Training finished
2017-06-10 20:11:54.624710 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #126 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 20:11:54.624931 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #126 | Collecting samples for evaluation
2017-06-10 20:12:06.479495 EDT | -----------------------  -----------
2017-06-10 20:12:06.480514 EDT | Epoch                     126
2017-06-10 20:12:06.480870 EDT | Iteration                 126
2017-06-10 20:12:06.481134 EDT | AverageReturn             403.994
2017-06-10 20:12:06.481659 EDT | StdReturn                 363.501
2017-06-10 20:12:06.482147 EDT | MaxReturn                2127.1
2017-06-10 20:12:06.482728 EDT | MinReturn                 189.208
2017-06-10 20:12:06.483201 EDT | AverageEsReturn           371.256
2017-06-10 20:12:06.483475 EDT | StdEsReturn               332.659
2017-06-10 20:12:06.483880 EDT | MaxEsReturn               956.667
2017-06-10 20:12:06.484303 EDT | MinEsReturn                45.0537
2017-06-10 20:12:06.484811 EDT | AverageDiscountedReturn   146.939
2017-06-10 20:12:06.485259 EDT | AverageQLoss                1.28563
2017-06-10 20:12:06.485714 EDT | AveragePolicySurr         -22.2748
2017-06-10 20:12:06.488440 EDT | AverageQ                   21.6444
2017-06-10 20:12:06.488822 EDT | AverageAbsQ                21.6636
2017-06-10 20:12:06.489478 EDT | AverageY                   21.6451
2017-06-10 20:12:06.489852 EDT | AverageAbsY                21.6509
2017-06-10 20:12:06.490197 EDT | AverageAbsQYDiff            0.52039
2017-06-10 20:12:06.490526 EDT | AverageAction               0.738216
2017-06-10 20:12:06.490891 EDT | PolicyRegParamNorm         44.3563
2017-06-10 20:12:06.491166 EDT | QFunRegParamNorm           49.8083
2017-06-10 20:12:06.491519 EDT | -----------------------  -----------
2017-06-10 20:12:06.492052 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #127 | Training started
2017-06-10 20:12:21.051208 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #127 | Training finished
2017-06-10 20:12:21.051920 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #127 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 20:12:21.052266 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #127 | Collecting samples for evaluation
2017-06-10 20:12:33.838423 EDT | -----------------------  -----------
2017-06-10 20:12:33.840388 EDT | Epoch                     127
2017-06-10 20:12:33.840758 EDT | Iteration                 127
2017-06-10 20:12:33.841093 EDT | AverageReturn             900.592
2017-06-10 20:12:33.841425 EDT | StdReturn                 482.125
2017-06-10 20:12:33.841762 EDT | MaxReturn                2064.16
2017-06-10 20:12:33.842090 EDT | MinReturn                 371.326
2017-06-10 20:12:33.842416 EDT | AverageEsReturn           219.034
2017-06-10 20:12:33.842748 EDT | StdEsReturn               170.686
2017-06-10 20:12:33.843073 EDT | MaxEsReturn               492.267
2017-06-10 20:12:33.843402 EDT | MinEsReturn                 8.11946
2017-06-10 20:12:33.843726 EDT | AverageDiscountedReturn   212.383
2017-06-10 20:12:33.844048 EDT | AverageQLoss                1.42226
2017-06-10 20:12:33.844370 EDT | AveragePolicySurr         -22.4237
2017-06-10 20:12:33.844690 EDT | AverageQ                   21.8107
2017-06-10 20:12:33.845012 EDT | AverageAbsQ                21.829
2017-06-10 20:12:33.845332 EDT | AverageY                   21.8135
2017-06-10 20:12:33.845662 EDT | AverageAbsY                21.8198
2017-06-10 20:12:33.845997 EDT | AverageAbsQYDiff            0.533636
2017-06-10 20:12:33.846320 EDT | AverageAction               0.762832
2017-06-10 20:12:33.846645 EDT | PolicyRegParamNorm         44.5239
2017-06-10 20:12:33.846967 EDT | QFunRegParamNorm           50.0107
2017-06-10 20:12:33.847289 EDT | -----------------------  -----------
2017-06-10 20:12:33.847747 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #128 | Training started
2017-06-10 20:12:48.688043 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #128 | Training finished
2017-06-10 20:12:48.688992 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #128 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 20:12:48.689362 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #128 | Collecting samples for evaluation
2017-06-10 20:13:00.298521 EDT | -----------------------  -----------
2017-06-10 20:13:00.299406 EDT | Epoch                     128
2017-06-10 20:13:00.299761 EDT | Iteration                 128
2017-06-10 20:13:00.300038 EDT | AverageReturn             478.77
2017-06-10 20:13:00.301206 EDT | StdReturn                 534.998
2017-06-10 20:13:00.301520 EDT | MaxReturn                2309.8
2017-06-10 20:13:00.301865 EDT | MinReturn                 237.63
2017-06-10 20:13:00.302200 EDT | AverageEsReturn           394.121
2017-06-10 20:13:00.302597 EDT | StdEsReturn               210.751
2017-06-10 20:13:00.302922 EDT | MaxEsReturn               634.398
2017-06-10 20:13:00.303359 EDT | MinEsReturn               137.673
2017-06-10 20:13:00.303723 EDT | AverageDiscountedReturn   152.502
2017-06-10 20:13:00.304154 EDT | AverageQLoss                1.51031
2017-06-10 20:13:00.304871 EDT | AveragePolicySurr         -22.5788
2017-06-10 20:13:00.305302 EDT | AverageQ                   21.9152
2017-06-10 20:13:00.305788 EDT | AverageAbsQ                21.9376
2017-06-10 20:13:00.306141 EDT | AverageY                   21.9178
2017-06-10 20:13:00.306529 EDT | AverageAbsY                21.9257
2017-06-10 20:13:00.306876 EDT | AverageAbsQYDiff            0.545565
2017-06-10 20:13:00.307626 EDT | AverageAction               0.74641
2017-06-10 20:13:00.307959 EDT | PolicyRegParamNorm         44.6542
2017-06-10 20:13:00.308286 EDT | QFunRegParamNorm           50.2566
2017-06-10 20:13:00.308614 EDT | -----------------------  -----------
2017-06-10 20:13:00.309047 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #129 | Training started
2017-06-10 20:13:15.299794 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #129 | Training finished
2017-06-10 20:13:15.301493 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #129 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 20:13:15.305644 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #129 | Collecting samples for evaluation
2017-06-10 20:13:27.098483 EDT | -----------------------  ----------
2017-06-10 20:13:27.103275 EDT | Epoch                    129
2017-06-10 20:13:27.103576 EDT | Iteration                129
2017-06-10 20:13:27.103837 EDT | AverageReturn            174.883
2017-06-10 20:13:27.104031 EDT | StdReturn                 36.3141
2017-06-10 20:13:27.104354 EDT | MaxReturn                293.102
2017-06-10 20:13:27.104545 EDT | MinReturn                 79.1879
2017-06-10 20:13:27.104730 EDT | AverageEsReturn          513.968
2017-06-10 20:13:27.104911 EDT | StdEsReturn              252.664
2017-06-10 20:13:27.105162 EDT | MaxEsReturn              833.402
2017-06-10 20:13:27.105378 EDT | MinEsReturn              176.696
2017-06-10 20:13:27.105560 EDT | AverageDiscountedReturn  102.192
2017-06-10 20:13:27.105845 EDT | AverageQLoss               1.68489
2017-06-10 20:13:27.106088 EDT | AveragePolicySurr        -22.7107
2017-06-10 20:13:27.106253 EDT | AverageQ                  22.0316
2017-06-10 20:13:27.106417 EDT | AverageAbsQ               22.0528
2017-06-10 20:13:27.106692 EDT | AverageY                  22.0342
2017-06-10 20:13:27.106891 EDT | AverageAbsY               22.0403
2017-06-10 20:13:27.107070 EDT | AverageAbsQYDiff           0.55552
2017-06-10 20:13:27.107303 EDT | AverageAction              0.722796
2017-06-10 20:13:27.107487 EDT | PolicyRegParamNorm        44.8208
2017-06-10 20:13:27.107666 EDT | QFunRegParamNorm          50.4471
2017-06-10 20:13:27.107852 EDT | -----------------------  ----------
2017-06-10 20:13:27.108273 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #130 | Training started
2017-06-10 20:13:41.961835 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #130 | Training finished
2017-06-10 20:13:41.962275 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #130 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 20:13:41.962547 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #130 | Collecting samples for evaluation
2017-06-10 20:13:54.845246 EDT | -----------------------  ----------
2017-06-10 20:13:54.846370 EDT | Epoch                    130
2017-06-10 20:13:54.846618 EDT | Iteration                130
2017-06-10 20:13:54.846878 EDT | AverageReturn            262.12
2017-06-10 20:13:54.847091 EDT | StdReturn                109.397
2017-06-10 20:13:54.847287 EDT | MaxReturn                815.976
2017-06-10 20:13:54.847714 EDT | MinReturn                188.857
2017-06-10 20:13:54.847890 EDT | AverageEsReturn          128.61
2017-06-10 20:13:54.848320 EDT | StdEsReturn              141.333
2017-06-10 20:13:54.848635 EDT | MaxEsReturn              514.251
2017-06-10 20:13:54.849450 EDT | MinEsReturn                7.30291
2017-06-10 20:13:54.849980 EDT | AverageDiscountedReturn  138.518
2017-06-10 20:13:54.850406 EDT | AverageQLoss               1.57372
2017-06-10 20:13:54.851034 EDT | AveragePolicySurr        -22.9482
2017-06-10 20:13:54.851406 EDT | AverageQ                  22.2912
2017-06-10 20:13:54.851774 EDT | AverageAbsQ               22.3104
2017-06-10 20:13:54.852135 EDT | AverageY                  22.2942
2017-06-10 20:13:54.852509 EDT | AverageAbsY               22.2969
2017-06-10 20:13:54.852936 EDT | AverageAbsQYDiff           0.553501
2017-06-10 20:13:54.853320 EDT | AverageAction              0.860639
2017-06-10 20:13:54.853775 EDT | PolicyRegParamNorm        45.0204
2017-06-10 20:13:54.854138 EDT | QFunRegParamNorm          50.6611
2017-06-10 20:13:54.854465 EDT | -----------------------  ----------
2017-06-10 20:13:54.855003 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #131 | Training started
2017-06-10 20:14:08.605079 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #131 | Training finished
2017-06-10 20:14:08.605950 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #131 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 20:14:08.606279 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #131 | Collecting samples for evaluation
2017-06-10 20:14:20.000482 EDT | -----------------------  -----------
2017-06-10 20:14:20.001286 EDT | Epoch                     131
2017-06-10 20:14:20.001626 EDT | Iteration                 131
2017-06-10 20:14:20.001882 EDT | AverageReturn             753.488
2017-06-10 20:14:20.002193 EDT | StdReturn                 431.741
2017-06-10 20:14:20.002544 EDT | MaxReturn                2388.36
2017-06-10 20:14:20.002945 EDT | MinReturn                 263.589
2017-06-10 20:14:20.003237 EDT | AverageEsReturn           267.119
2017-06-10 20:14:20.003421 EDT | StdEsReturn               307.71
2017-06-10 20:14:20.003691 EDT | MaxEsReturn               984.068
2017-06-10 20:14:20.003998 EDT | MinEsReturn                11.3859
2017-06-10 20:14:20.004336 EDT | AverageDiscountedReturn   202.565
2017-06-10 20:14:20.004713 EDT | AverageQLoss                1.58723
2017-06-10 20:14:20.005060 EDT | AveragePolicySurr         -23.2262
2017-06-10 20:14:20.005388 EDT | AverageQ                   22.582
2017-06-10 20:14:20.005714 EDT | AverageAbsQ                22.599
2017-06-10 20:14:20.006022 EDT | AverageY                   22.5859
2017-06-10 20:14:20.006316 EDT | AverageAbsY                22.5899
2017-06-10 20:14:20.006611 EDT | AverageAbsQYDiff            0.555696
2017-06-10 20:14:20.006868 EDT | AverageAction               0.7989
2017-06-10 20:14:20.007189 EDT | PolicyRegParamNorm         45.1062
2017-06-10 20:14:20.007499 EDT | QFunRegParamNorm           50.8948
2017-06-10 20:14:20.007758 EDT | -----------------------  -----------
2017-06-10 20:14:20.008162 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #132 | Training started
2017-06-10 20:14:35.511157 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #132 | Training finished
2017-06-10 20:14:35.511963 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #132 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 20:14:35.512164 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #132 | Collecting samples for evaluation
2017-06-10 20:14:47.106578 EDT | -----------------------  ----------
2017-06-10 20:14:47.107529 EDT | Epoch                    132
2017-06-10 20:14:47.107909 EDT | Iteration                132
2017-06-10 20:14:47.108302 EDT | AverageReturn            269.418
2017-06-10 20:14:47.108788 EDT | StdReturn                 47.8231
2017-06-10 20:14:47.109156 EDT | MaxReturn                463.131
2017-06-10 20:14:47.109508 EDT | MinReturn                195.137
2017-06-10 20:14:47.109872 EDT | AverageEsReturn          199.173
2017-06-10 20:14:47.110247 EDT | StdEsReturn              159.847
2017-06-10 20:14:47.110695 EDT | MaxEsReturn              607.001
2017-06-10 20:14:47.111133 EDT | MinEsReturn                7.67199
2017-06-10 20:14:47.111540 EDT | AverageDiscountedReturn  139.124
2017-06-10 20:14:47.112005 EDT | AverageQLoss               1.37371
2017-06-10 20:14:47.112450 EDT | AveragePolicySurr        -23.3264
2017-06-10 20:14:47.112842 EDT | AverageQ                  22.6792
2017-06-10 20:14:47.113249 EDT | AverageAbsQ               22.6988
2017-06-10 20:14:47.113771 EDT | AverageY                  22.6817
2017-06-10 20:14:47.114212 EDT | AverageAbsY               22.686
2017-06-10 20:14:47.114645 EDT | AverageAbsQYDiff           0.544712
2017-06-10 20:14:47.115121 EDT | AverageAction              0.855343
2017-06-10 20:14:47.115576 EDT | PolicyRegParamNorm        45.2384
2017-06-10 20:14:47.115999 EDT | QFunRegParamNorm          51.0513
2017-06-10 20:14:47.116442 EDT | -----------------------  ----------
2017-06-10 20:14:47.116951 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #133 | Training started
2017-06-10 20:15:01.764158 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #133 | Training finished
2017-06-10 20:15:01.764868 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #133 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 20:15:01.765052 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #133 | Collecting samples for evaluation
2017-06-10 20:15:13.905183 EDT | -----------------------  -----------
2017-06-10 20:15:13.906026 EDT | Epoch                     133
2017-06-10 20:15:13.906340 EDT | Iteration                 133
2017-06-10 20:15:13.906533 EDT | AverageReturn             260.506
2017-06-10 20:15:13.906800 EDT | StdReturn                 215.864
2017-06-10 20:15:13.906958 EDT | MaxReturn                1503.12
2017-06-10 20:15:13.907161 EDT | MinReturn                 148.742
2017-06-10 20:15:13.907421 EDT | AverageEsReturn           281.493
2017-06-10 20:15:13.907683 EDT | StdEsReturn               226.55
2017-06-10 20:15:13.907943 EDT | MaxEsReturn               579.458
2017-06-10 20:15:13.908186 EDT | MinEsReturn                 5.80887
2017-06-10 20:15:13.908436 EDT | AverageDiscountedReturn   120.027
2017-06-10 20:15:13.908692 EDT | AverageQLoss                1.73826
2017-06-10 20:15:13.908966 EDT | AveragePolicySurr         -23.4785
2017-06-10 20:15:13.909231 EDT | AverageQ                   22.8416
2017-06-10 20:15:13.909499 EDT | AverageAbsQ                22.8612
2017-06-10 20:15:13.909774 EDT | AverageY                   22.8454
2017-06-10 20:15:13.910016 EDT | AverageAbsY                22.8507
2017-06-10 20:15:13.910280 EDT | AverageAbsQYDiff            0.587506
2017-06-10 20:15:13.910539 EDT | AverageAction               0.804214
2017-06-10 20:15:13.910743 EDT | PolicyRegParamNorm         45.4428
2017-06-10 20:15:13.910920 EDT | QFunRegParamNorm           51.251
2017-06-10 20:15:13.911070 EDT | -----------------------  -----------
2017-06-10 20:15:13.911332 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #134 | Training started
2017-06-10 20:15:29.073313 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #134 | Training finished
2017-06-10 20:15:29.074270 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #134 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 20:15:29.074660 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #134 | Collecting samples for evaluation
2017-06-10 20:15:40.751546 EDT | -----------------------  ----------
2017-06-10 20:15:40.752671 EDT | Epoch                    134
2017-06-10 20:15:40.753278 EDT | Iteration                134
2017-06-10 20:15:40.753628 EDT | AverageReturn            517.811
2017-06-10 20:15:40.754711 EDT | StdReturn                 56.9952
2017-06-10 20:15:40.755119 EDT | MaxReturn                589.579
2017-06-10 20:15:40.755593 EDT | MinReturn                226.761
2017-06-10 20:15:40.755946 EDT | AverageEsReturn          215.792
2017-06-10 20:15:40.756285 EDT | StdEsReturn              158.614
2017-06-10 20:15:40.756722 EDT | MaxEsReturn              517.904
2017-06-10 20:15:40.757065 EDT | MinEsReturn               11.8194
2017-06-10 20:15:40.759067 EDT | AverageDiscountedReturn  205.431
2017-06-10 20:15:40.759476 EDT | AverageQLoss               1.92871
2017-06-10 20:15:40.759826 EDT | AveragePolicySurr        -23.7022
2017-06-10 20:15:40.760165 EDT | AverageQ                  23.0351
2017-06-10 20:15:40.760510 EDT | AverageAbsQ               23.0566
2017-06-10 20:15:40.760959 EDT | AverageY                  23.0388
2017-06-10 20:15:40.761324 EDT | AverageAbsY               23.045
2017-06-10 20:15:40.761681 EDT | AverageAbsQYDiff           0.605894
2017-06-10 20:15:40.762046 EDT | AverageAction              0.876688
2017-06-10 20:15:40.762406 EDT | PolicyRegParamNorm        45.6115
2017-06-10 20:15:40.762762 EDT | QFunRegParamNorm          51.4286
2017-06-10 20:15:40.763197 EDT | -----------------------  ----------
2017-06-10 20:15:40.763808 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #135 | Training started
2017-06-10 20:15:55.046586 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #135 | Training finished
2017-06-10 20:15:55.069356 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #135 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 20:15:55.069946 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #135 | Collecting samples for evaluation
2017-06-10 20:16:08.016850 EDT | -----------------------  ----------
2017-06-10 20:16:08.017831 EDT | Epoch                    135
2017-06-10 20:16:08.018231 EDT | Iteration                135
2017-06-10 20:16:08.018575 EDT | AverageReturn            391.268
2017-06-10 20:16:08.018967 EDT | StdReturn                 91.3724
2017-06-10 20:16:08.019332 EDT | MaxReturn                593.445
2017-06-10 20:16:08.019745 EDT | MinReturn                282.921
2017-06-10 20:16:08.020075 EDT | AverageEsReturn          175.86
2017-06-10 20:16:08.020390 EDT | StdEsReturn              188.498
2017-06-10 20:16:08.020676 EDT | MaxEsReturn              719.878
2017-06-10 20:16:08.020970 EDT | MinEsReturn                7.06729
2017-06-10 20:16:08.021284 EDT | AverageDiscountedReturn  181.285
2017-06-10 20:16:08.021742 EDT | AverageQLoss               1.39267
2017-06-10 20:16:08.023378 EDT | AveragePolicySurr        -23.8831
2017-06-10 20:16:08.023720 EDT | AverageQ                  23.1934
2017-06-10 20:16:08.024092 EDT | AverageAbsQ               23.211
2017-06-10 20:16:08.024417 EDT | AverageY                  23.1949
2017-06-10 20:16:08.024785 EDT | AverageAbsY               23.199
2017-06-10 20:16:08.025092 EDT | AverageAbsQYDiff           0.552689
2017-06-10 20:16:08.025423 EDT | AverageAction              0.91395
2017-06-10 20:16:08.025748 EDT | PolicyRegParamNorm        45.746
2017-06-10 20:16:08.026068 EDT | QFunRegParamNorm          51.6028
2017-06-10 20:16:08.026379 EDT | -----------------------  ----------
2017-06-10 20:16:08.026910 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #136 | Training started
2017-06-10 20:16:22.491745 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #136 | Training finished
2017-06-10 20:16:22.492194 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #136 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 20:16:22.492570 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #136 | Collecting samples for evaluation
2017-06-10 20:16:33.894174 EDT | -----------------------  ----------
2017-06-10 20:16:33.895147 EDT | Epoch                    136
2017-06-10 20:16:33.895913 EDT | Iteration                136
2017-06-10 20:16:33.896818 EDT | AverageReturn            297.494
2017-06-10 20:16:33.897189 EDT | StdReturn                127.949
2017-06-10 20:16:33.897528 EDT | MaxReturn                851.439
2017-06-10 20:16:33.897891 EDT | MinReturn                221.736
2017-06-10 20:16:33.898225 EDT | AverageEsReturn          262.279
2017-06-10 20:16:33.898445 EDT | StdEsReturn              193.481
2017-06-10 20:16:33.898632 EDT | MaxEsReturn              627.057
2017-06-10 20:16:33.898898 EDT | MinEsReturn                8.17409
2017-06-10 20:16:33.899075 EDT | AverageDiscountedReturn  143.326
2017-06-10 20:16:33.899257 EDT | AverageQLoss               1.77718
2017-06-10 20:16:33.899438 EDT | AveragePolicySurr        -24.0741
2017-06-10 20:16:33.899618 EDT | AverageQ                  23.3926
2017-06-10 20:16:33.899829 EDT | AverageAbsQ               23.4181
2017-06-10 20:16:33.899998 EDT | AverageY                  23.3964
2017-06-10 20:16:33.900165 EDT | AverageAbsY               23.4043
2017-06-10 20:16:33.900571 EDT | AverageAbsQYDiff           0.589986
2017-06-10 20:16:33.901619 EDT | AverageAction              0.7805
2017-06-10 20:16:33.901828 EDT | PolicyRegParamNorm        45.8548
2017-06-10 20:16:33.902023 EDT | QFunRegParamNorm          51.8108
2017-06-10 20:16:33.904393 EDT | -----------------------  ----------
2017-06-10 20:16:33.905436 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #137 | Training started
2017-06-10 20:16:49.584585 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #137 | Training finished
2017-06-10 20:16:49.589811 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #137 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 20:16:49.590378 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #137 | Collecting samples for evaluation
2017-06-10 20:17:01.063155 EDT | -----------------------  ----------
2017-06-10 20:17:01.063961 EDT | Epoch                    137
2017-06-10 20:17:01.064255 EDT | Iteration                137
2017-06-10 20:17:01.064420 EDT | AverageReturn            382.008
2017-06-10 20:17:01.064621 EDT | StdReturn                 31.2924
2017-06-10 20:17:01.064912 EDT | MaxReturn                488.738
2017-06-10 20:17:01.065142 EDT | MinReturn                317.46
2017-06-10 20:17:01.065327 EDT | AverageEsReturn          142.097
2017-06-10 20:17:01.065511 EDT | StdEsReturn              142.68
2017-06-10 20:17:01.065709 EDT | MaxEsReturn              554.75
2017-06-10 20:17:01.065956 EDT | MinEsReturn                7.29496
2017-06-10 20:17:01.066140 EDT | AverageDiscountedReturn  181.565
2017-06-10 20:17:01.066603 EDT | AverageQLoss               1.81072
2017-06-10 20:17:01.066796 EDT | AveragePolicySurr        -24.35
2017-06-10 20:17:01.067220 EDT | AverageQ                  23.6849
2017-06-10 20:17:01.067404 EDT | AverageAbsQ               23.7046
2017-06-10 20:17:01.067588 EDT | AverageY                  23.6881
2017-06-10 20:17:01.067768 EDT | AverageAbsY               23.6944
2017-06-10 20:17:01.068021 EDT | AverageAbsQYDiff           0.589932
2017-06-10 20:17:01.068204 EDT | AverageAction              0.908509
2017-06-10 20:17:01.068385 EDT | PolicyRegParamNorm        45.9979
2017-06-10 20:17:01.068791 EDT | QFunRegParamNorm          52.0018
2017-06-10 20:17:01.069760 EDT | -----------------------  ----------
2017-06-10 20:17:01.070090 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #138 | Training started
2017-06-10 20:17:16.391000 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #138 | Training finished
2017-06-10 20:17:16.413662 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #138 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 20:17:16.414344 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #138 | Collecting samples for evaluation
2017-06-10 20:17:28.758775 EDT | -----------------------  ----------
2017-06-10 20:17:28.759489 EDT | Epoch                    138
2017-06-10 20:17:28.759678 EDT | Iteration                138
2017-06-10 20:17:28.759853 EDT | AverageReturn            420.367
2017-06-10 20:17:28.760179 EDT | StdReturn                 32.4146
2017-06-10 20:17:28.760609 EDT | MaxReturn                517.231
2017-06-10 20:17:28.760937 EDT | MinReturn                324.008
2017-06-10 20:17:28.761258 EDT | AverageEsReturn          134.988
2017-06-10 20:17:28.761508 EDT | StdEsReturn              111.757
2017-06-10 20:17:28.761918 EDT | MaxEsReturn              425.93
2017-06-10 20:17:28.762390 EDT | MinEsReturn               11.7956
2017-06-10 20:17:28.763418 EDT | AverageDiscountedReturn  193.456
2017-06-10 20:17:28.763634 EDT | AverageQLoss               1.8943
2017-06-10 20:17:28.763873 EDT | AveragePolicySurr        -24.5691
2017-06-10 20:17:28.764051 EDT | AverageQ                  23.8637
2017-06-10 20:17:28.764210 EDT | AverageAbsQ               23.8842
2017-06-10 20:17:28.764419 EDT | AverageY                  23.8665
2017-06-10 20:17:28.764597 EDT | AverageAbsY               23.8722
2017-06-10 20:17:28.764749 EDT | AverageAbsQYDiff           0.595577
2017-06-10 20:17:28.764901 EDT | AverageAction              0.898334
2017-06-10 20:17:28.765160 EDT | PolicyRegParamNorm        46.2074
2017-06-10 20:17:28.765318 EDT | QFunRegParamNorm          52.2039
2017-06-10 20:17:28.765473 EDT | -----------------------  ----------
2017-06-10 20:17:28.765949 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #139 | Training started
2017-06-10 20:17:42.468905 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #139 | Training finished
2017-06-10 20:17:42.470042 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #139 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 20:17:42.470553 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #139 | Collecting samples for evaluation
2017-06-10 20:17:55.457115 EDT | -----------------------  ----------
2017-06-10 20:17:55.457978 EDT | Epoch                    139
2017-06-10 20:17:55.458921 EDT | Iteration                139
2017-06-10 20:17:55.459232 EDT | AverageReturn            470.069
2017-06-10 20:17:55.459563 EDT | StdReturn                141.639
2017-06-10 20:17:55.459774 EDT | MaxReturn                977.316
2017-06-10 20:17:55.460481 EDT | MinReturn                311.741
2017-06-10 20:17:55.460795 EDT | AverageEsReturn          277.09
2017-06-10 20:17:55.461082 EDT | StdEsReturn              230.761
2017-06-10 20:17:55.461294 EDT | MaxEsReturn              889.752
2017-06-10 20:17:55.461678 EDT | MinEsReturn               81.7809
2017-06-10 20:17:55.461897 EDT | AverageDiscountedReturn  182.502
2017-06-10 20:17:55.462094 EDT | AverageQLoss               1.7678
2017-06-10 20:17:55.462293 EDT | AveragePolicySurr        -24.6791
2017-06-10 20:17:55.462591 EDT | AverageQ                  23.9615
2017-06-10 20:17:55.462930 EDT | AverageAbsQ               23.9861
2017-06-10 20:17:55.463418 EDT | AverageY                  23.9642
2017-06-10 20:17:55.463692 EDT | AverageAbsY               23.969
2017-06-10 20:17:55.463890 EDT | AverageAbsQYDiff           0.594605
2017-06-10 20:17:55.464091 EDT | AverageAction              0.867782
2017-06-10 20:17:55.465142 EDT | PolicyRegParamNorm        46.3469
2017-06-10 20:17:55.465422 EDT | QFunRegParamNorm          52.4291
2017-06-10 20:17:55.465963 EDT | -----------------------  ----------
2017-06-10 20:17:55.466287 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #140 | Training started
2017-06-10 20:18:10.304708 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #140 | Training finished
2017-06-10 20:18:10.306526 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #140 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 20:18:10.306865 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #140 | Collecting samples for evaluation
2017-06-10 20:18:22.742149 EDT | -----------------------  ----------
2017-06-10 20:18:22.742475 EDT | Epoch                    140
2017-06-10 20:18:22.742653 EDT | Iteration                140
2017-06-10 20:18:22.742821 EDT | AverageReturn            362.271
2017-06-10 20:18:22.742986 EDT | StdReturn                 15.7271
2017-06-10 20:18:22.743149 EDT | MaxReturn                417.936
2017-06-10 20:18:22.743311 EDT | MinReturn                342.809
2017-06-10 20:18:22.743473 EDT | AverageEsReturn          126.814
2017-06-10 20:18:22.743655 EDT | StdEsReturn               86.8443
2017-06-10 20:18:22.743966 EDT | MaxEsReturn              328.793
2017-06-10 20:18:22.744137 EDT | MinEsReturn               46.7052
2017-06-10 20:18:22.744299 EDT | AverageDiscountedReturn  175.178
2017-06-10 20:18:22.744460 EDT | AverageQLoss               1.59569
2017-06-10 20:18:22.744664 EDT | AveragePolicySurr        -24.9215
2017-06-10 20:18:22.744959 EDT | AverageQ                  24.2315
2017-06-10 20:18:22.745123 EDT | AverageAbsQ               24.2507
2017-06-10 20:18:22.745281 EDT | AverageY                  24.2332
2017-06-10 20:18:22.745439 EDT | AverageAbsY               24.2391
2017-06-10 20:18:22.745596 EDT | AverageAbsQYDiff           0.573143
2017-06-10 20:18:22.745783 EDT | AverageAction              0.856808
2017-06-10 20:18:22.746035 EDT | PolicyRegParamNorm        46.4211
2017-06-10 20:18:22.746285 EDT | QFunRegParamNorm          52.6282
2017-06-10 20:18:22.746562 EDT | -----------------------  ----------
2017-06-10 20:18:22.747019 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #141 | Training started
2017-06-10 20:18:37.347740 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #141 | Training finished
2017-06-10 20:18:37.353964 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #141 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 20:18:37.354374 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #141 | Collecting samples for evaluation
2017-06-10 20:18:49.840014 EDT | -----------------------  ----------
2017-06-10 20:18:49.841174 EDT | Epoch                    141
2017-06-10 20:18:49.841534 EDT | Iteration                141
2017-06-10 20:18:49.841932 EDT | AverageReturn            494.611
2017-06-10 20:18:49.842494 EDT | StdReturn                 97.0387
2017-06-10 20:18:49.842867 EDT | MaxReturn                682.52
2017-06-10 20:18:49.843335 EDT | MinReturn                359.164
2017-06-10 20:18:49.843702 EDT | AverageEsReturn          144.793
2017-06-10 20:18:49.844074 EDT | StdEsReturn              135.702
2017-06-10 20:18:49.844606 EDT | MaxEsReturn              507.47
2017-06-10 20:18:49.844980 EDT | MinEsReturn               43.9826
2017-06-10 20:18:49.845400 EDT | AverageDiscountedReturn  186.132
2017-06-10 20:18:49.845778 EDT | AverageQLoss               2.06477
2017-06-10 20:18:49.846151 EDT | AveragePolicySurr        -25.1283
2017-06-10 20:18:49.846681 EDT | AverageQ                  24.4206
2017-06-10 20:18:49.847054 EDT | AverageAbsQ               24.4448
2017-06-10 20:18:49.847574 EDT | AverageY                  24.4251
2017-06-10 20:18:49.848049 EDT | AverageAbsY               24.4304
2017-06-10 20:18:49.848584 EDT | AverageAbsQYDiff           0.626839
2017-06-10 20:18:49.849048 EDT | AverageAction              0.863209
2017-06-10 20:18:49.849668 EDT | PolicyRegParamNorm        46.5327
2017-06-10 20:18:49.850155 EDT | QFunRegParamNorm          52.8421
2017-06-10 20:18:49.850670 EDT | -----------------------  ----------
2017-06-10 20:18:49.851267 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #142 | Training started
2017-06-10 20:19:05.206213 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #142 | Training finished
2017-06-10 20:19:05.207331 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #142 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 20:19:05.207859 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #142 | Collecting samples for evaluation
2017-06-10 20:19:16.967294 EDT | -----------------------  -----------
2017-06-10 20:19:16.968049 EDT | Epoch                     142
2017-06-10 20:19:16.968299 EDT | Iteration                 142
2017-06-10 20:19:16.968459 EDT | AverageReturn             543.917
2017-06-10 20:19:16.968613 EDT | StdReturn                 160.169
2017-06-10 20:19:16.968776 EDT | MaxReturn                1288.96
2017-06-10 20:19:16.968934 EDT | MinReturn                 377.048
2017-06-10 20:19:16.969115 EDT | AverageEsReturn           241.676
2017-06-10 20:19:16.969273 EDT | StdEsReturn               208.966
2017-06-10 20:19:16.969429 EDT | MaxEsReturn               570.628
2017-06-10 20:19:16.969648 EDT | MinEsReturn                32.0249
2017-06-10 20:19:16.969864 EDT | AverageDiscountedReturn   191.821
2017-06-10 20:19:16.970042 EDT | AverageQLoss                1.92752
2017-06-10 20:19:16.970208 EDT | AveragePolicySurr         -25.1582
2017-06-10 20:19:16.970421 EDT | AverageQ                   24.4718
2017-06-10 20:19:16.970602 EDT | AverageAbsQ                24.4927
2017-06-10 20:19:16.970881 EDT | AverageY                   24.4733
2017-06-10 20:19:16.971090 EDT | AverageAbsY                24.4787
2017-06-10 20:19:16.971271 EDT | AverageAbsQYDiff            0.619597
2017-06-10 20:19:16.971501 EDT | AverageAction               0.879861
2017-06-10 20:19:16.971744 EDT | PolicyRegParamNorm         46.6978
2017-06-10 20:19:16.971998 EDT | QFunRegParamNorm           53.0907
2017-06-10 20:19:16.972178 EDT | -----------------------  -----------
2017-06-10 20:19:16.972479 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #143 | Training started
2017-06-10 20:19:31.924144 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #143 | Training finished
2017-06-10 20:19:31.925114 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #143 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 20:19:31.925453 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #143 | Collecting samples for evaluation
2017-06-10 20:19:45.197088 EDT | -----------------------  -----------
2017-06-10 20:19:45.198068 EDT | Epoch                     143
2017-06-10 20:19:45.198595 EDT | Iteration                 143
2017-06-10 20:19:45.198977 EDT | AverageReturn             443.989
2017-06-10 20:19:45.199354 EDT | StdReturn                 291.331
2017-06-10 20:19:45.199731 EDT | MaxReturn                1426.17
2017-06-10 20:19:45.202073 EDT | MinReturn                 164.165
2017-06-10 20:19:45.202493 EDT | AverageEsReturn           164.828
2017-06-10 20:19:45.203385 EDT | StdEsReturn                90.2045
2017-06-10 20:19:45.203784 EDT | MaxEsReturn               380.807
2017-06-10 20:19:45.206316 EDT | MinEsReturn                39.5303
2017-06-10 20:19:45.207539 EDT | AverageDiscountedReturn   147.75
2017-06-10 20:19:45.207951 EDT | AverageQLoss                2.21439
2017-06-10 20:19:45.208334 EDT | AveragePolicySurr         -25.43
2017-06-10 20:19:45.210175 EDT | AverageQ                   24.696
2017-06-10 20:19:45.210580 EDT | AverageAbsQ                24.7206
2017-06-10 20:19:45.210958 EDT | AverageY                   24.7016
2017-06-10 20:19:45.211332 EDT | AverageAbsY                24.7065
2017-06-10 20:19:45.211810 EDT | AverageAbsQYDiff            0.645376
2017-06-10 20:19:45.212288 EDT | AverageAction               0.803026
2017-06-10 20:19:45.212770 EDT | PolicyRegParamNorm         46.8742
2017-06-10 20:19:45.213241 EDT | QFunRegParamNorm           53.3148
2017-06-10 20:19:45.213723 EDT | -----------------------  -----------
2017-06-10 20:19:45.214315 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #144 | Training started
2017-06-10 20:19:59.119089 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #144 | Training finished
2017-06-10 20:19:59.120096 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #144 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 20:19:59.120490 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #144 | Collecting samples for evaluation
2017-06-10 20:20:12.901100 EDT | -----------------------  ----------
2017-06-10 20:20:12.902030 EDT | Epoch                    144
2017-06-10 20:20:12.902378 EDT | Iteration                144
2017-06-10 20:20:12.902719 EDT | AverageReturn            514.676
2017-06-10 20:20:12.903042 EDT | StdReturn                 30.3289
2017-06-10 20:20:12.903375 EDT | MaxReturn                583.445
2017-06-10 20:20:12.903724 EDT | MinReturn                469.194
2017-06-10 20:20:12.904022 EDT | AverageEsReturn          206.261
2017-06-10 20:20:12.904291 EDT | StdEsReturn              108.129
2017-06-10 20:20:12.904629 EDT | MaxEsReturn              368.328
2017-06-10 20:20:12.904974 EDT | MinEsReturn               48.0545
2017-06-10 20:20:12.905292 EDT | AverageDiscountedReturn  207.836
2017-06-10 20:20:12.905559 EDT | AverageQLoss               1.90117
2017-06-10 20:20:12.905904 EDT | AveragePolicySurr        -25.6412
2017-06-10 20:20:12.906339 EDT | AverageQ                  24.9048
2017-06-10 20:20:12.906719 EDT | AverageAbsQ               24.9252
2017-06-10 20:20:12.907112 EDT | AverageY                  24.9084
2017-06-10 20:20:12.907526 EDT | AverageAbsY               24.9138
2017-06-10 20:20:12.909845 EDT | AverageAbsQYDiff           0.60111
2017-06-10 20:20:12.911153 EDT | AverageAction              0.900862
2017-06-10 20:20:12.916404 EDT | PolicyRegParamNorm        47.0049
2017-06-10 20:20:12.916855 EDT | QFunRegParamNorm          53.4689
2017-06-10 20:20:12.917280 EDT | -----------------------  ----------
2017-06-10 20:20:12.918235 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #145 | Training started
2017-06-10 20:20:28.616036 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #145 | Training finished
2017-06-10 20:20:28.617079 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #145 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 20:20:28.617291 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #145 | Collecting samples for evaluation
2017-06-10 20:20:40.233381 EDT | -----------------------  -----------
2017-06-10 20:20:40.234391 EDT | Epoch                     145
2017-06-10 20:20:40.234775 EDT | Iteration                 145
2017-06-10 20:20:40.235057 EDT | AverageReturn             452.6
2017-06-10 20:20:40.235229 EDT | StdReturn                  63.4303
2017-06-10 20:20:40.235394 EDT | MaxReturn                 486.949
2017-06-10 20:20:40.235554 EDT | MinReturn                 156.362
2017-06-10 20:20:40.235705 EDT | AverageEsReturn           271.641
2017-06-10 20:20:40.235865 EDT | StdEsReturn               304.64
2017-06-10 20:20:40.236241 EDT | MaxEsReturn              1040.39
2017-06-10 20:20:40.236495 EDT | MinEsReturn                54.1784
2017-06-10 20:20:40.236770 EDT | AverageDiscountedReturn   195.623
2017-06-10 20:20:40.236956 EDT | AverageQLoss                1.95026
2017-06-10 20:20:40.237180 EDT | AveragePolicySurr         -25.7865
2017-06-10 20:20:40.237370 EDT | AverageQ                   25.0455
2017-06-10 20:20:40.237577 EDT | AverageAbsQ                25.0674
2017-06-10 20:20:40.237782 EDT | AverageY                   25.0478
2017-06-10 20:20:40.238110 EDT | AverageAbsY                25.052
2017-06-10 20:20:40.238454 EDT | AverageAbsQYDiff            0.629466
2017-06-10 20:20:40.238871 EDT | AverageAction               0.898028
2017-06-10 20:20:40.239687 EDT | PolicyRegParamNorm         47.129
2017-06-10 20:20:40.240049 EDT | QFunRegParamNorm           53.7051
2017-06-10 20:20:40.240800 EDT | -----------------------  -----------
2017-06-10 20:20:40.241402 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #146 | Training started
2017-06-10 20:20:56.285465 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #146 | Training finished
2017-06-10 20:20:56.286942 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #146 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 20:20:56.287279 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #146 | Collecting samples for evaluation
2017-06-10 20:21:08.744813 EDT | -----------------------  -----------
2017-06-10 20:21:08.745729 EDT | Epoch                     146
2017-06-10 20:21:08.746094 EDT | Iteration                 146
2017-06-10 20:21:08.746410 EDT | AverageReturn             704.583
2017-06-10 20:21:08.746683 EDT | StdReturn                 307.548
2017-06-10 20:21:08.747009 EDT | MaxReturn                1340.05
2017-06-10 20:21:08.757953 EDT | MinReturn                 242.249
2017-06-10 20:21:08.758439 EDT | AverageEsReturn           177.186
2017-06-10 20:21:08.759128 EDT | StdEsReturn               126.205
2017-06-10 20:21:08.759478 EDT | MaxEsReturn               503.063
2017-06-10 20:21:08.759894 EDT | MinEsReturn                48.5968
2017-06-10 20:21:08.760318 EDT | AverageDiscountedReturn   181.348
2017-06-10 20:21:08.760901 EDT | AverageQLoss                2.11802
2017-06-10 20:21:08.761337 EDT | AveragePolicySurr         -26.069
2017-06-10 20:21:08.762139 EDT | AverageQ                   25.3365
2017-06-10 20:21:08.762695 EDT | AverageAbsQ                25.3578
2017-06-10 20:21:08.763186 EDT | AverageY                   25.3386
2017-06-10 20:21:08.763623 EDT | AverageAbsY                25.3439
2017-06-10 20:21:08.764334 EDT | AverageAbsQYDiff            0.645507
2017-06-10 20:21:08.764704 EDT | AverageAction               0.795786
2017-06-10 20:21:08.765266 EDT | PolicyRegParamNorm         47.3885
2017-06-10 20:21:08.765718 EDT | QFunRegParamNorm           53.98
2017-06-10 20:21:08.766228 EDT | -----------------------  -----------
2017-06-10 20:21:08.766856 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #147 | Training started
2017-06-10 20:21:22.880079 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #147 | Training finished
2017-06-10 20:21:22.880331 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #147 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 20:21:22.880589 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #147 | Collecting samples for evaluation
2017-06-10 20:21:35.041828 EDT | -----------------------  -----------
2017-06-10 20:21:35.042618 EDT | Epoch                     147
2017-06-10 20:21:35.042874 EDT | Iteration                 147
2017-06-10 20:21:35.043092 EDT | AverageReturn             558.948
2017-06-10 20:21:35.043288 EDT | StdReturn                 204.002
2017-06-10 20:21:35.043537 EDT | MaxReturn                1223.82
2017-06-10 20:21:35.043766 EDT | MinReturn                 275.466
2017-06-10 20:21:35.043988 EDT | AverageEsReturn           267.245
2017-06-10 20:21:35.044162 EDT | StdEsReturn               187.259
2017-06-10 20:21:35.044362 EDT | MaxEsReturn               603.502
2017-06-10 20:21:35.044730 EDT | MinEsReturn                35.5126
2017-06-10 20:21:35.045117 EDT | AverageDiscountedReturn   186.051
2017-06-10 20:21:35.045507 EDT | AverageQLoss                2.16302
2017-06-10 20:21:35.045929 EDT | AveragePolicySurr         -26.3189
2017-06-10 20:21:35.046397 EDT | AverageQ                   25.5648
2017-06-10 20:21:35.046711 EDT | AverageAbsQ                25.5826
2017-06-10 20:21:35.047014 EDT | AverageY                   25.5694
2017-06-10 20:21:35.047321 EDT | AverageAbsY                25.5734
2017-06-10 20:21:35.047629 EDT | AverageAbsQYDiff            0.63584
2017-06-10 20:21:35.047828 EDT | AverageAction               0.802616
2017-06-10 20:21:35.048022 EDT | PolicyRegParamNorm         47.5263
2017-06-10 20:21:35.048433 EDT | QFunRegParamNorm           54.2259
2017-06-10 20:21:35.048838 EDT | -----------------------  -----------
2017-06-10 20:21:35.049448 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #148 | Training started
2017-06-10 20:21:49.392638 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #148 | Training finished
2017-06-10 20:21:49.393565 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #148 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 20:21:49.393917 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #148 | Collecting samples for evaluation
2017-06-10 20:22:01.303456 EDT | -----------------------  -----------
2017-06-10 20:22:01.304506 EDT | Epoch                     148
2017-06-10 20:22:01.304697 EDT | Iteration                 148
2017-06-10 20:22:01.304931 EDT | AverageReturn             482.315
2017-06-10 20:22:01.305291 EDT | StdReturn                 221.857
2017-06-10 20:22:01.305652 EDT | MaxReturn                1209.19
2017-06-10 20:22:01.305945 EDT | MinReturn                 219.401
2017-06-10 20:22:01.308057 EDT | AverageEsReturn           311.54
2017-06-10 20:22:01.309015 EDT | StdEsReturn               163.764
2017-06-10 20:22:01.309250 EDT | MaxEsReturn               579.638
2017-06-10 20:22:01.309409 EDT | MinEsReturn                34.4852
2017-06-10 20:22:01.309628 EDT | AverageDiscountedReturn   173.578
2017-06-10 20:22:01.309807 EDT | AverageQLoss                1.87803
2017-06-10 20:22:01.309986 EDT | AveragePolicySurr         -26.5314
2017-06-10 20:22:01.310239 EDT | AverageQ                   25.7747
2017-06-10 20:22:01.310499 EDT | AverageAbsQ                25.7969
2017-06-10 20:22:01.310766 EDT | AverageY                   25.7774
2017-06-10 20:22:01.310976 EDT | AverageAbsY                25.7832
2017-06-10 20:22:01.311129 EDT | AverageAbsQYDiff            0.621711
2017-06-10 20:22:01.311300 EDT | AverageAction               0.807584
2017-06-10 20:22:01.311458 EDT | PolicyRegParamNorm         47.6772
2017-06-10 20:22:01.311613 EDT | QFunRegParamNorm           54.412
2017-06-10 20:22:01.311767 EDT | -----------------------  -----------
2017-06-10 20:22:01.312054 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #149 | Training started
2017-06-10 20:22:16.569763 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #149 | Training finished
2017-06-10 20:22:16.570790 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #149 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 20:22:16.571291 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #149 | Collecting samples for evaluation
2017-06-10 20:22:28.532804 EDT | -----------------------  ----------
2017-06-10 20:22:28.534097 EDT | Epoch                    149
2017-06-10 20:22:28.534777 EDT | Iteration                149
2017-06-10 20:22:28.535236 EDT | AverageReturn            407.425
2017-06-10 20:22:28.535694 EDT | StdReturn                139.589
2017-06-10 20:22:28.536051 EDT | MaxReturn                947.552
2017-06-10 20:22:28.536254 EDT | MinReturn                191.636
2017-06-10 20:22:28.536455 EDT | AverageEsReturn          157.472
2017-06-10 20:22:28.536651 EDT | StdEsReturn              119.801
2017-06-10 20:22:28.536844 EDT | MaxEsReturn              384.562
2017-06-10 20:22:28.537037 EDT | MinEsReturn                9.41214
2017-06-10 20:22:28.537228 EDT | AverageDiscountedReturn  166.986
2017-06-10 20:22:28.537420 EDT | AverageQLoss               2.02092
2017-06-10 20:22:28.537611 EDT | AveragePolicySurr        -26.6875
2017-06-10 20:22:28.537812 EDT | AverageQ                  25.91
2017-06-10 20:22:28.538004 EDT | AverageAbsQ               25.9311
2017-06-10 20:22:28.538196 EDT | AverageY                  25.9121
2017-06-10 20:22:28.538387 EDT | AverageAbsY               25.919
2017-06-10 20:22:28.538579 EDT | AverageAbsQYDiff           0.643364
2017-06-10 20:22:28.538769 EDT | AverageAction              0.820255
2017-06-10 20:22:28.538958 EDT | PolicyRegParamNorm        47.7361
2017-06-10 20:22:28.539155 EDT | QFunRegParamNorm          54.636
2017-06-10 20:22:28.539345 EDT | -----------------------  ----------
2017-06-10 20:22:28.539662 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #150 | Training started
2017-06-10 20:22:43.214950 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #150 | Training finished
2017-06-10 20:22:43.215839 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #150 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 20:22:43.216114 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #150 | Collecting samples for evaluation
2017-06-10 20:22:54.502343 EDT | -----------------------  ----------
2017-06-10 20:22:54.503585 EDT | Epoch                    150
2017-06-10 20:22:54.503849 EDT | Iteration                150
2017-06-10 20:22:54.504052 EDT | AverageReturn            317.695
2017-06-10 20:22:54.504251 EDT | StdReturn                147.176
2017-06-10 20:22:54.504548 EDT | MaxReturn                557.873
2017-06-10 20:22:54.504773 EDT | MinReturn                162.208
2017-06-10 20:22:54.505002 EDT | AverageEsReturn          294.148
2017-06-10 20:22:54.505194 EDT | StdEsReturn              165.462
2017-06-10 20:22:54.505403 EDT | MaxEsReturn              615.772
2017-06-10 20:22:54.505596 EDT | MinEsReturn               38.7192
2017-06-10 20:22:54.505823 EDT | AverageDiscountedReturn  154.702
2017-06-10 20:22:54.506015 EDT | AverageQLoss               2.33993
2017-06-10 20:22:54.506206 EDT | AveragePolicySurr        -26.7594
2017-06-10 20:22:54.506399 EDT | AverageQ                  26.0184
2017-06-10 20:22:54.506596 EDT | AverageAbsQ               26.0463
2017-06-10 20:22:54.506791 EDT | AverageY                  26.0216
2017-06-10 20:22:54.506981 EDT | AverageAbsY               26.0306
2017-06-10 20:22:54.507287 EDT | AverageAbsQYDiff           0.671908
2017-06-10 20:22:54.507485 EDT | AverageAction              0.884516
2017-06-10 20:22:54.507677 EDT | PolicyRegParamNorm        47.8756
2017-06-10 20:22:54.510855 EDT | QFunRegParamNorm          54.8778
2017-06-10 20:22:54.511773 EDT | -----------------------  ----------
2017-06-10 20:22:54.513776 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #151 | Training started
2017-06-10 20:23:09.984473 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #151 | Training finished
2017-06-10 20:23:09.985396 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #151 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 20:23:09.985756 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #151 | Collecting samples for evaluation
2017-06-10 20:23:21.763467 EDT | -----------------------  ----------
2017-06-10 20:23:21.763805 EDT | Epoch                    151
2017-06-10 20:23:21.763975 EDT | Iteration                151
2017-06-10 20:23:21.764134 EDT | AverageReturn            372.304
2017-06-10 20:23:21.764289 EDT | StdReturn                 79.8916
2017-06-10 20:23:21.764440 EDT | MaxReturn                516.801
2017-06-10 20:23:21.764589 EDT | MinReturn                189.737
2017-06-10 20:23:21.764738 EDT | AverageEsReturn          334.402
2017-06-10 20:23:21.764886 EDT | StdEsReturn              178.333
2017-06-10 20:23:21.765034 EDT | MaxEsReturn              569.24
2017-06-10 20:23:21.765181 EDT | MinEsReturn               52.9896
2017-06-10 20:23:21.765330 EDT | AverageDiscountedReturn  172.159
2017-06-10 20:23:21.765479 EDT | AverageQLoss               2.48027
2017-06-10 20:23:21.765626 EDT | AveragePolicySurr        -27.0072
2017-06-10 20:23:21.765784 EDT | AverageQ                  26.2838
2017-06-10 20:23:21.765932 EDT | AverageAbsQ               26.3089
2017-06-10 20:23:21.766079 EDT | AverageY                  26.2877
2017-06-10 20:23:21.766225 EDT | AverageAbsY               26.2962
2017-06-10 20:23:21.766372 EDT | AverageAbsQYDiff           0.690519
2017-06-10 20:23:21.766600 EDT | AverageAction              0.885728
2017-06-10 20:23:21.766838 EDT | PolicyRegParamNorm        48.0487
2017-06-10 20:23:21.767086 EDT | QFunRegParamNorm          55.0568
2017-06-10 20:23:21.767403 EDT | -----------------------  ----------
2017-06-10 20:23:21.767858 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #152 | Training started
2017-06-10 20:23:36.363473 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #152 | Training finished
2017-06-10 20:23:36.364322 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #152 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 20:23:36.364596 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #152 | Collecting samples for evaluation
2017-06-10 20:23:48.601544 EDT | -----------------------  ----------
2017-06-10 20:23:48.602634 EDT | Epoch                    152
2017-06-10 20:23:48.602988 EDT | Iteration                152
2017-06-10 20:23:48.603332 EDT | AverageReturn            284.323
2017-06-10 20:23:48.603863 EDT | StdReturn                 55.7002
2017-06-10 20:23:48.604126 EDT | MaxReturn                472.797
2017-06-10 20:23:48.604310 EDT | MinReturn                216.55
2017-06-10 20:23:48.604492 EDT | AverageEsReturn          306.191
2017-06-10 20:23:48.604668 EDT | StdEsReturn              124.092
2017-06-10 20:23:48.604942 EDT | MaxEsReturn              481.176
2017-06-10 20:23:48.605124 EDT | MinEsReturn              110.861
2017-06-10 20:23:48.605303 EDT | AverageDiscountedReturn  150.928
2017-06-10 20:23:48.605484 EDT | AverageQLoss               2.02954
2017-06-10 20:23:48.605748 EDT | AveragePolicySurr        -27.1474
2017-06-10 20:23:48.606067 EDT | AverageQ                  26.4254
2017-06-10 20:23:48.606388 EDT | AverageAbsQ               26.4488
2017-06-10 20:23:48.606721 EDT | AverageY                  26.4293
2017-06-10 20:23:48.607036 EDT | AverageAbsY               26.4389
2017-06-10 20:23:48.607326 EDT | AverageAbsQYDiff           0.666447
2017-06-10 20:23:48.607511 EDT | AverageAction              0.890443
2017-06-10 20:23:48.607705 EDT | PolicyRegParamNorm        48.1911
2017-06-10 20:23:48.607987 EDT | QFunRegParamNorm          55.2548
2017-06-10 20:23:48.608265 EDT | -----------------------  ----------
2017-06-10 20:23:48.608690 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #153 | Training started
2017-06-10 20:24:02.008374 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #153 | Training finished
2017-06-10 20:24:02.021808 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #153 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 20:24:02.022285 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #153 | Collecting samples for evaluation
2017-06-10 20:24:14.099651 EDT | -----------------------  ----------
2017-06-10 20:24:14.100399 EDT | Epoch                     153
2017-06-10 20:24:14.100885 EDT | Iteration                 153
2017-06-10 20:24:14.101217 EDT | AverageReturn             300.193
2017-06-10 20:24:14.101761 EDT | StdReturn                  59.9474
2017-06-10 20:24:14.104047 EDT | MaxReturn                 450.033
2017-06-10 20:24:14.104817 EDT | MinReturn                 203.454
2017-06-10 20:24:14.105125 EDT | AverageEsReturn           430.979
2017-06-10 20:24:14.105415 EDT | StdEsReturn               422.458
2017-06-10 20:24:14.105725 EDT | MaxEsReturn              1230.94
2017-06-10 20:24:14.106025 EDT | MinEsReturn                 9.36167
2017-06-10 20:24:14.106396 EDT | AverageDiscountedReturn   157.364
2017-06-10 20:24:14.106768 EDT | AverageQLoss                2.10372
2017-06-10 20:24:14.107139 EDT | AveragePolicySurr         -27.4471
2017-06-10 20:24:14.107506 EDT | AverageQ                   26.7024
2017-06-10 20:24:14.107872 EDT | AverageAbsQ                26.7253
2017-06-10 20:24:14.108240 EDT | AverageY                   26.7044
2017-06-10 20:24:14.108606 EDT | AverageAbsY                26.7135
2017-06-10 20:24:14.108972 EDT | AverageAbsQYDiff            0.65666
2017-06-10 20:24:14.109342 EDT | AverageAction               0.86648
2017-06-10 20:24:14.109717 EDT | PolicyRegParamNorm         48.2975
2017-06-10 20:24:14.110143 EDT | QFunRegParamNorm           55.4565
2017-06-10 20:24:14.110489 EDT | -----------------------  ----------
2017-06-10 20:24:14.111017 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #154 | Training started
2017-06-10 20:24:29.019937 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #154 | Training finished
2017-06-10 20:24:29.020798 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #154 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 20:24:29.021174 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #154 | Collecting samples for evaluation
2017-06-10 20:24:41.538544 EDT | -----------------------  ----------
2017-06-10 20:24:41.538819 EDT | Epoch                    154
2017-06-10 20:24:41.539028 EDT | Iteration                154
2017-06-10 20:24:41.539193 EDT | AverageReturn            251.988
2017-06-10 20:24:41.539362 EDT | StdReturn                 26.0519
2017-06-10 20:24:41.539547 EDT | MaxReturn                332.497
2017-06-10 20:24:41.539729 EDT | MinReturn                192.363
2017-06-10 20:24:41.539910 EDT | AverageEsReturn          205.826
2017-06-10 20:24:41.540091 EDT | StdEsReturn              201.79
2017-06-10 20:24:41.540272 EDT | MaxEsReturn              734.729
2017-06-10 20:24:41.540465 EDT | MinEsReturn               67.6469
2017-06-10 20:24:41.540644 EDT | AverageDiscountedReturn  139.904
2017-06-10 20:24:41.540823 EDT | AverageQLoss               2.56168
2017-06-10 20:24:41.541059 EDT | AveragePolicySurr        -27.5035
2017-06-10 20:24:41.541246 EDT | AverageQ                  26.7764
2017-06-10 20:24:41.541426 EDT | AverageAbsQ               26.8015
2017-06-10 20:24:41.541604 EDT | AverageY                  26.7797
2017-06-10 20:24:41.541878 EDT | AverageAbsY               26.7876
2017-06-10 20:24:41.542275 EDT | AverageAbsQYDiff           0.697386
2017-06-10 20:24:41.542681 EDT | AverageAction              0.851959
2017-06-10 20:24:41.543086 EDT | PolicyRegParamNorm        48.4045
2017-06-10 20:24:41.543372 EDT | QFunRegParamNorm          55.6541
2017-06-10 20:24:41.543950 EDT | -----------------------  ----------
2017-06-10 20:24:41.546279 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #155 | Training started
2017-06-10 20:24:57.067608 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #155 | Training finished
2017-06-10 20:24:57.068587 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #155 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 20:24:57.068966 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #155 | Collecting samples for evaluation
2017-06-10 20:25:09.035927 EDT | -----------------------  ----------
2017-06-10 20:25:09.062571 EDT | Epoch                    155
2017-06-10 20:25:09.062879 EDT | Iteration                155
2017-06-10 20:25:09.063102 EDT | AverageReturn            360.166
2017-06-10 20:25:09.063399 EDT | StdReturn                 98.623
2017-06-10 20:25:09.063890 EDT | MaxReturn                547.736
2017-06-10 20:25:09.064424 EDT | MinReturn                196.475
2017-06-10 20:25:09.066365 EDT | AverageEsReturn          205.979
2017-06-10 20:25:09.067519 EDT | StdEsReturn              125.748
2017-06-10 20:25:09.068203 EDT | MaxEsReturn              464.307
2017-06-10 20:25:09.068396 EDT | MinEsReturn               46.2178
2017-06-10 20:25:09.069618 EDT | AverageDiscountedReturn  171.396
2017-06-10 20:25:09.070125 EDT | AverageQLoss               2.16991
2017-06-10 20:25:09.070503 EDT | AveragePolicySurr        -27.6455
2017-06-10 20:25:09.070855 EDT | AverageQ                  26.887
2017-06-10 20:25:09.071209 EDT | AverageAbsQ               26.9154
2017-06-10 20:25:09.071582 EDT | AverageY                  26.89
2017-06-10 20:25:09.071931 EDT | AverageAbsY               26.8997
2017-06-10 20:25:09.072295 EDT | AverageAbsQYDiff           0.681402
2017-06-10 20:25:09.072644 EDT | AverageAction              0.901753
2017-06-10 20:25:09.072942 EDT | PolicyRegParamNorm        48.5176
2017-06-10 20:25:09.073210 EDT | QFunRegParamNorm          55.888
2017-06-10 20:25:09.073499 EDT | -----------------------  ----------
2017-06-10 20:25:09.073825 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #156 | Training started
2017-06-10 20:25:23.355379 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #156 | Training finished
2017-06-10 20:25:23.356299 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #156 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 20:25:23.356630 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #156 | Collecting samples for evaluation
2017-06-10 20:25:35.418998 EDT | -----------------------  ----------
2017-06-10 20:25:35.421298 EDT | Epoch                    156
2017-06-10 20:25:35.421682 EDT | Iteration                156
2017-06-10 20:25:35.422030 EDT | AverageReturn            464.043
2017-06-10 20:25:35.422362 EDT | StdReturn                 40.0918
2017-06-10 20:25:35.422692 EDT | MaxReturn                508.973
2017-06-10 20:25:35.423019 EDT | MinReturn                296.174
2017-06-10 20:25:35.423350 EDT | AverageEsReturn          244.93
2017-06-10 20:25:35.426891 EDT | StdEsReturn              185.02
2017-06-10 20:25:35.427219 EDT | MaxEsReturn              654.258
2017-06-10 20:25:35.427550 EDT | MinEsReturn               43.3515
2017-06-10 20:25:35.427904 EDT | AverageDiscountedReturn  199.954
2017-06-10 20:25:35.428194 EDT | AverageQLoss               2.17429
2017-06-10 20:25:35.428355 EDT | AveragePolicySurr        -27.9059
2017-06-10 20:25:35.428510 EDT | AverageQ                  27.1874
2017-06-10 20:25:35.428670 EDT | AverageAbsQ               27.2143
2017-06-10 20:25:35.428879 EDT | AverageY                  27.1904
2017-06-10 20:25:35.429034 EDT | AverageAbsY               27.1976
2017-06-10 20:25:35.429187 EDT | AverageAbsQYDiff           0.683214
2017-06-10 20:25:35.429336 EDT | AverageAction              0.889301
2017-06-10 20:25:35.429518 EDT | PolicyRegParamNorm        48.6165
2017-06-10 20:25:35.429672 EDT | QFunRegParamNorm          56.0406
2017-06-10 20:25:35.429939 EDT | -----------------------  ----------
2017-06-10 20:25:35.430425 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #157 | Training started
2017-06-10 20:25:48.957082 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #157 | Training finished
2017-06-10 20:25:48.957824 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #157 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 20:25:48.958020 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #157 | Collecting samples for evaluation
2017-06-10 20:26:01.226693 EDT | -----------------------  ----------
2017-06-10 20:26:01.227546 EDT | Epoch                    157
2017-06-10 20:26:01.227737 EDT | Iteration                157
2017-06-10 20:26:01.227906 EDT | AverageReturn            489.098
2017-06-10 20:26:01.228143 EDT | StdReturn                 67.6188
2017-06-10 20:26:01.228307 EDT | MaxReturn                594.387
2017-06-10 20:26:01.228468 EDT | MinReturn                235.04
2017-06-10 20:26:01.228772 EDT | AverageEsReturn          228.486
2017-06-10 20:26:01.229107 EDT | StdEsReturn              140.865
2017-06-10 20:26:01.229423 EDT | MaxEsReturn              474.172
2017-06-10 20:26:01.229589 EDT | MinEsReturn               53.6467
2017-06-10 20:26:01.229773 EDT | AverageDiscountedReturn  203.653
2017-06-10 20:26:01.229955 EDT | AverageQLoss               2.18265
2017-06-10 20:26:01.230166 EDT | AveragePolicySurr        -27.9695
2017-06-10 20:26:01.230576 EDT | AverageQ                  27.278
2017-06-10 20:26:01.230765 EDT | AverageAbsQ               27.3036
2017-06-10 20:26:01.230927 EDT | AverageY                  27.2808
2017-06-10 20:26:01.231199 EDT | AverageAbsY               27.2885
2017-06-10 20:26:01.231379 EDT | AverageAbsQYDiff           0.674653
2017-06-10 20:26:01.231665 EDT | AverageAction              0.914156
2017-06-10 20:26:01.231845 EDT | PolicyRegParamNorm        48.724
2017-06-10 20:26:01.232030 EDT | QFunRegParamNorm          56.1725
2017-06-10 20:26:01.232191 EDT | -----------------------  ----------
2017-06-10 20:26:01.232720 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #158 | Training started
2017-06-10 20:26:15.811655 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #158 | Training finished
2017-06-10 20:26:15.812434 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #158 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 20:26:15.812665 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #158 | Collecting samples for evaluation
2017-06-10 20:26:27.114401 EDT | -----------------------  ----------
2017-06-10 20:26:27.115189 EDT | Epoch                    158
2017-06-10 20:26:27.115385 EDT | Iteration                158
2017-06-10 20:26:27.115558 EDT | AverageReturn            518.273
2017-06-10 20:26:27.117753 EDT | StdReturn                 93.7748
2017-06-10 20:26:27.117941 EDT | MaxReturn                609.122
2017-06-10 20:26:27.118225 EDT | MinReturn                391.813
2017-06-10 20:26:27.118823 EDT | AverageEsReturn          199.312
2017-06-10 20:26:27.119348 EDT | StdEsReturn              140.219
2017-06-10 20:26:27.119532 EDT | MaxEsReturn              428.542
2017-06-10 20:26:27.119726 EDT | MinEsReturn               18.3536
2017-06-10 20:26:27.119997 EDT | AverageDiscountedReturn  206.807
2017-06-10 20:26:27.120220 EDT | AverageQLoss               2.08525
2017-06-10 20:26:27.120460 EDT | AveragePolicySurr        -28.1132
2017-06-10 20:26:27.120638 EDT | AverageQ                  27.4102
2017-06-10 20:26:27.120818 EDT | AverageAbsQ               27.4355
2017-06-10 20:26:27.120998 EDT | AverageY                  27.4129
2017-06-10 20:26:27.121175 EDT | AverageAbsY               27.4225
2017-06-10 20:26:27.121334 EDT | AverageAbsQYDiff           0.670445
2017-06-10 20:26:27.121511 EDT | AverageAction              0.880565
2017-06-10 20:26:27.121769 EDT | PolicyRegParamNorm        48.8846
2017-06-10 20:26:27.121951 EDT | QFunRegParamNorm          56.3204
2017-06-10 20:26:27.122142 EDT | -----------------------  ----------
2017-06-10 20:26:27.122454 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #159 | Training started
2017-06-10 20:26:42.142094 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #159 | Training finished
2017-06-10 20:26:42.147389 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #159 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 20:26:42.147647 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #159 | Collecting samples for evaluation
2017-06-10 20:26:53.737101 EDT | -----------------------  ----------
2017-06-10 20:26:53.738065 EDT | Epoch                    159
2017-06-10 20:26:53.738464 EDT | Iteration                159
2017-06-10 20:26:53.738843 EDT | AverageReturn            457.384
2017-06-10 20:26:53.739235 EDT | StdReturn                 44.9896
2017-06-10 20:26:53.739628 EDT | MaxReturn                560.556
2017-06-10 20:26:53.740010 EDT | MinReturn                365.859
2017-06-10 20:26:53.740483 EDT | AverageEsReturn          317.815
2017-06-10 20:26:53.740955 EDT | StdEsReturn              201.172
2017-06-10 20:26:53.741426 EDT | MaxEsReturn              582.582
2017-06-10 20:26:53.741912 EDT | MinEsReturn                6.45488
2017-06-10 20:26:53.742388 EDT | AverageDiscountedReturn  197.312
2017-06-10 20:26:53.742979 EDT | AverageQLoss               2.215
2017-06-10 20:26:53.743492 EDT | AveragePolicySurr        -28.2574
2017-06-10 20:26:53.743878 EDT | AverageQ                  27.545
2017-06-10 20:26:53.744256 EDT | AverageAbsQ               27.5706
2017-06-10 20:26:53.744625 EDT | AverageY                  27.5499
2017-06-10 20:26:53.745009 EDT | AverageAbsY               27.5567
2017-06-10 20:26:53.745581 EDT | AverageAbsQYDiff           0.683752
2017-06-10 20:26:53.746124 EDT | AverageAction              0.88989
2017-06-10 20:26:53.746522 EDT | PolicyRegParamNorm        48.9362
2017-06-10 20:26:53.746902 EDT | QFunRegParamNorm          56.4653
2017-06-10 20:26:53.747278 EDT | -----------------------  ----------
2017-06-10 20:26:53.747820 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #160 | Training started
2017-06-10 20:27:08.424795 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #160 | Training finished
2017-06-10 20:27:08.425804 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #160 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 20:27:08.426113 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #160 | Collecting samples for evaluation
2017-06-10 20:27:21.500310 EDT | -----------------------  ----------
2017-06-10 20:27:21.501906 EDT | Epoch                    160
2017-06-10 20:27:21.502396 EDT | Iteration                160
2017-06-10 20:27:21.502823 EDT | AverageReturn            461.505
2017-06-10 20:27:21.503252 EDT | StdReturn                 39.2101
2017-06-10 20:27:21.503695 EDT | MaxReturn                500.678
2017-06-10 20:27:21.504194 EDT | MinReturn                336.608
2017-06-10 20:27:21.504622 EDT | AverageEsReturn          280.17
2017-06-10 20:27:21.505140 EDT | StdEsReturn              119.82
2017-06-10 20:27:21.505576 EDT | MaxEsReturn              429.315
2017-06-10 20:27:21.506008 EDT | MinEsReturn               55.1799
2017-06-10 20:27:21.506762 EDT | AverageDiscountedReturn  198.198
2017-06-10 20:27:21.507226 EDT | AverageQLoss               2.44365
2017-06-10 20:27:21.507624 EDT | AveragePolicySurr        -28.2907
2017-06-10 20:27:21.508886 EDT | AverageQ                  27.5683
2017-06-10 20:27:21.509255 EDT | AverageAbsQ               27.5982
2017-06-10 20:27:21.509667 EDT | AverageY                  27.5704
2017-06-10 20:27:21.510069 EDT | AverageAbsY               27.5789
2017-06-10 20:27:21.510493 EDT | AverageAbsQYDiff           0.704665
2017-06-10 20:27:21.510877 EDT | AverageAction              0.896585
2017-06-10 20:27:21.511314 EDT | PolicyRegParamNorm        49.0358
2017-06-10 20:27:21.511732 EDT | QFunRegParamNorm          56.6557
2017-06-10 20:27:21.512477 EDT | -----------------------  ----------
2017-06-10 20:27:21.514100 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #161 | Training started
2017-06-10 20:27:35.394463 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #161 | Training finished
2017-06-10 20:27:35.394709 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #161 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 20:27:35.394899 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #161 | Collecting samples for evaluation
2017-06-10 20:27:47.310805 EDT | -----------------------  ----------
2017-06-10 20:27:47.311930 EDT | Epoch                    161
2017-06-10 20:27:47.312486 EDT | Iteration                161
2017-06-10 20:27:47.312871 EDT | AverageReturn            349.754
2017-06-10 20:27:47.313294 EDT | StdReturn                 81.5896
2017-06-10 20:27:47.325912 EDT | MaxReturn                482.093
2017-06-10 20:27:47.326453 EDT | MinReturn                270.948
2017-06-10 20:27:47.326908 EDT | AverageEsReturn          267.981
2017-06-10 20:27:47.327264 EDT | StdEsReturn               97.8628
2017-06-10 20:27:47.327610 EDT | MaxEsReturn              412.338
2017-06-10 20:27:47.327950 EDT | MinEsReturn               72.1206
2017-06-10 20:27:47.328289 EDT | AverageDiscountedReturn  169.542
2017-06-10 20:27:47.328633 EDT | AverageQLoss               2.48939
2017-06-10 20:27:47.328981 EDT | AveragePolicySurr        -28.4043
2017-06-10 20:27:47.329422 EDT | AverageQ                  27.6935
2017-06-10 20:27:47.329869 EDT | AverageAbsQ               27.7191
2017-06-10 20:27:47.330279 EDT | AverageY                  27.6989
2017-06-10 20:27:47.330658 EDT | AverageAbsY               27.7105
2017-06-10 20:27:47.331018 EDT | AverageAbsQYDiff           0.701672
2017-06-10 20:27:47.331444 EDT | AverageAction              0.865256
2017-06-10 20:27:47.331846 EDT | PolicyRegParamNorm        49.1573
2017-06-10 20:27:47.332183 EDT | QFunRegParamNorm          56.8565
2017-06-10 20:27:47.332564 EDT | -----------------------  ----------
2017-06-10 20:27:47.333161 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #162 | Training started
2017-06-10 20:28:01.973173 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #162 | Training finished
2017-06-10 20:28:01.974141 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #162 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 20:28:01.977429 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #162 | Collecting samples for evaluation
2017-06-10 20:28:13.983469 EDT | -----------------------  ----------
2017-06-10 20:28:13.984643 EDT | Epoch                    162
2017-06-10 20:28:13.984924 EDT | Iteration                162
2017-06-10 20:28:13.985233 EDT | AverageReturn            467.142
2017-06-10 20:28:13.985418 EDT | StdReturn                 44.4023
2017-06-10 20:28:13.985618 EDT | MaxReturn                549.321
2017-06-10 20:28:13.985861 EDT | MinReturn                323.296
2017-06-10 20:28:13.986065 EDT | AverageEsReturn          343.498
2017-06-10 20:28:13.986235 EDT | StdEsReturn              166.858
2017-06-10 20:28:13.986421 EDT | MaxEsReturn              534.472
2017-06-10 20:28:13.986601 EDT | MinEsReturn               79.3795
2017-06-10 20:28:13.986783 EDT | AverageDiscountedReturn  199.327
2017-06-10 20:28:13.986961 EDT | AverageQLoss               2.23379
2017-06-10 20:28:13.987154 EDT | AveragePolicySurr        -28.5302
2017-06-10 20:28:13.987364 EDT | AverageQ                  27.8374
2017-06-10 20:28:13.987546 EDT | AverageAbsQ               27.8602
2017-06-10 20:28:13.988459 EDT | AverageY                  27.8409
2017-06-10 20:28:13.988666 EDT | AverageAbsY               27.8464
2017-06-10 20:28:13.988889 EDT | AverageAbsQYDiff           0.689742
2017-06-10 20:28:13.990185 EDT | AverageAction              0.893993
2017-06-10 20:28:13.990393 EDT | PolicyRegParamNorm        49.2905
2017-06-10 20:28:13.991157 EDT | QFunRegParamNorm          57.0107
2017-06-10 20:28:13.991597 EDT | -----------------------  ----------
2017-06-10 20:28:13.992158 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #163 | Training started
2017-06-10 20:28:28.184663 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #163 | Training finished
2017-06-10 20:28:28.185685 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #163 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 20:28:28.186255 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #163 | Collecting samples for evaluation
2017-06-10 20:28:39.797817 EDT | -----------------------  ----------
2017-06-10 20:28:39.799340 EDT | Epoch                    163
2017-06-10 20:28:39.799825 EDT | Iteration                163
2017-06-10 20:28:39.800273 EDT | AverageReturn            469.362
2017-06-10 20:28:39.800718 EDT | StdReturn                 56.1594
2017-06-10 20:28:39.801166 EDT | MaxReturn                572.75
2017-06-10 20:28:39.801517 EDT | MinReturn                330.54
2017-06-10 20:28:39.801877 EDT | AverageEsReturn          213.574
2017-06-10 20:28:39.802223 EDT | StdEsReturn               80.8338
2017-06-10 20:28:39.802569 EDT | MaxEsReturn              303.469
2017-06-10 20:28:39.802915 EDT | MinEsReturn               40.5309
2017-06-10 20:28:39.803260 EDT | AverageDiscountedReturn  199.492
2017-06-10 20:28:39.803604 EDT | AverageQLoss               2.23284
2017-06-10 20:28:39.803948 EDT | AveragePolicySurr        -28.6117
2017-06-10 20:28:39.804292 EDT | AverageQ                  27.89
2017-06-10 20:28:39.804637 EDT | AverageAbsQ               27.9149
2017-06-10 20:28:39.804980 EDT | AverageY                  27.8919
2017-06-10 20:28:39.805323 EDT | AverageAbsY               27.8987
2017-06-10 20:28:39.805667 EDT | AverageAbsQYDiff           0.689122
2017-06-10 20:28:39.806021 EDT | AverageAction              0.893095
2017-06-10 20:28:39.806363 EDT | PolicyRegParamNorm        49.4011
2017-06-10 20:28:39.806704 EDT | QFunRegParamNorm          57.1487
2017-06-10 20:28:39.807049 EDT | -----------------------  ----------
2017-06-10 20:28:39.807566 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #164 | Training started
2017-06-10 20:28:54.609438 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #164 | Training finished
2017-06-10 20:28:54.610296 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #164 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 20:28:54.610620 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #164 | Collecting samples for evaluation
2017-06-10 20:29:05.812385 EDT | -----------------------  ----------
2017-06-10 20:29:05.812993 EDT | Epoch                    164
2017-06-10 20:29:05.813397 EDT | Iteration                164
2017-06-10 20:29:05.813782 EDT | AverageReturn            505.819
2017-06-10 20:29:05.814156 EDT | StdReturn                 44.6892
2017-06-10 20:29:05.814568 EDT | MaxReturn                565.71
2017-06-10 20:29:05.814943 EDT | MinReturn                414.114
2017-06-10 20:29:05.815310 EDT | AverageEsReturn          264.842
2017-06-10 20:29:05.815691 EDT | StdEsReturn              183.634
2017-06-10 20:29:05.816057 EDT | MaxEsReturn              571.86
2017-06-10 20:29:05.816430 EDT | MinEsReturn               44.5232
2017-06-10 20:29:05.816796 EDT | AverageDiscountedReturn  207.619
2017-06-10 20:29:05.817304 EDT | AverageQLoss               2.58609
2017-06-10 20:29:05.817919 EDT | AveragePolicySurr        -28.8119
2017-06-10 20:29:05.818289 EDT | AverageQ                  28.0971
2017-06-10 20:29:05.818682 EDT | AverageAbsQ               28.1206
2017-06-10 20:29:05.819048 EDT | AverageY                  28.102
2017-06-10 20:29:05.819734 EDT | AverageAbsY               28.1084
2017-06-10 20:29:05.820136 EDT | AverageAbsQYDiff           0.713489
2017-06-10 20:29:05.820622 EDT | AverageAction              0.88733
2017-06-10 20:29:05.822157 EDT | PolicyRegParamNorm        49.5147
2017-06-10 20:29:05.822573 EDT | QFunRegParamNorm          57.3156
2017-06-10 20:29:05.822966 EDT | -----------------------  ----------
2017-06-10 20:29:05.823554 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #165 | Training started
2017-06-10 20:29:19.935586 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #165 | Training finished
2017-06-10 20:29:19.936527 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #165 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 20:29:19.936897 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #165 | Collecting samples for evaluation
2017-06-10 20:29:32.695139 EDT | -----------------------  ----------
2017-06-10 20:29:32.698011 EDT | Epoch                    165
2017-06-10 20:29:32.698351 EDT | Iteration                165
2017-06-10 20:29:32.698690 EDT | AverageReturn            511.827
2017-06-10 20:29:32.699055 EDT | StdReturn                 21.516
2017-06-10 20:29:32.699366 EDT | MaxReturn                564.576
2017-06-10 20:29:32.699724 EDT | MinReturn                418.669
2017-06-10 20:29:32.700070 EDT | AverageEsReturn          256.023
2017-06-10 20:29:32.700398 EDT | StdEsReturn              162.993
2017-06-10 20:29:32.700729 EDT | MaxEsReturn              524.328
2017-06-10 20:29:32.701066 EDT | MinEsReturn               59.6595
2017-06-10 20:29:32.701789 EDT | AverageDiscountedReturn  209.63
2017-06-10 20:29:32.701980 EDT | AverageQLoss               2.66057
2017-06-10 20:29:32.702139 EDT | AveragePolicySurr        -28.6769
2017-06-10 20:29:32.702292 EDT | AverageQ                  27.9679
2017-06-10 20:29:32.702443 EDT | AverageAbsQ               27.996
2017-06-10 20:29:32.702593 EDT | AverageY                  27.9701
2017-06-10 20:29:32.702741 EDT | AverageAbsY               27.9789
2017-06-10 20:29:32.702890 EDT | AverageAbsQYDiff           0.729651
2017-06-10 20:29:32.703041 EDT | AverageAction              0.86249
2017-06-10 20:29:32.703189 EDT | PolicyRegParamNorm        49.6468
2017-06-10 20:29:32.703340 EDT | QFunRegParamNorm          57.5351
2017-06-10 20:29:32.703490 EDT | -----------------------  ----------
2017-06-10 20:29:32.703732 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #166 | Training started
2017-06-10 20:29:45.891684 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #166 | Training finished
2017-06-10 20:29:45.892543 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #166 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 20:29:45.892748 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #166 | Collecting samples for evaluation
2017-06-10 20:29:58.286034 EDT | -----------------------  ----------
2017-06-10 20:29:58.286819 EDT | Epoch                    166
2017-06-10 20:29:58.287013 EDT | Iteration                166
2017-06-10 20:29:58.287189 EDT | AverageReturn            472.481
2017-06-10 20:29:58.287358 EDT | StdReturn                 93.1972
2017-06-10 20:29:58.287562 EDT | MaxReturn                591.957
2017-06-10 20:29:58.287782 EDT | MinReturn                321.511
2017-06-10 20:29:58.287934 EDT | AverageEsReturn          290.295
2017-06-10 20:29:58.288115 EDT | StdEsReturn              135.228
2017-06-10 20:29:58.288266 EDT | MaxEsReturn              522.253
2017-06-10 20:29:58.288467 EDT | MinEsReturn               66.3914
2017-06-10 20:29:58.288754 EDT | AverageDiscountedReturn  198.273
2017-06-10 20:29:58.289023 EDT | AverageQLoss               2.55089
2017-06-10 20:29:58.289268 EDT | AveragePolicySurr        -28.8335
2017-06-10 20:29:58.289506 EDT | AverageQ                  28.1238
2017-06-10 20:29:58.289763 EDT | AverageAbsQ               28.1438
2017-06-10 20:29:58.290014 EDT | AverageY                  28.1268
2017-06-10 20:29:58.290273 EDT | AverageAbsY               28.1337
2017-06-10 20:29:58.290558 EDT | AverageAbsQYDiff           0.719356
2017-06-10 20:29:58.290844 EDT | AverageAction              0.860268
2017-06-10 20:29:58.291111 EDT | PolicyRegParamNorm        49.7626
2017-06-10 20:29:58.291358 EDT | QFunRegParamNorm          57.7262
2017-06-10 20:29:58.291586 EDT | -----------------------  ----------
2017-06-10 20:29:58.292064 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #167 | Training started
2017-06-10 20:30:12.469287 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #167 | Training finished
2017-06-10 20:30:12.470310 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #167 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 20:30:12.470567 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #167 | Collecting samples for evaluation
2017-06-10 20:30:23.821612 EDT | -----------------------  ----------
2017-06-10 20:30:23.822608 EDT | Epoch                    167
2017-06-10 20:30:23.822975 EDT | Iteration                167
2017-06-10 20:30:23.823348 EDT | AverageReturn            418.454
2017-06-10 20:30:23.823717 EDT | StdReturn                 67.6597
2017-06-10 20:30:23.824053 EDT | MaxReturn                557.004
2017-06-10 20:30:23.824381 EDT | MinReturn                375.461
2017-06-10 20:30:23.824784 EDT | AverageEsReturn          229.647
2017-06-10 20:30:23.825114 EDT | StdEsReturn              167.961
2017-06-10 20:30:23.825442 EDT | MaxEsReturn              603.858
2017-06-10 20:30:23.825752 EDT | MinEsReturn               52.0355
2017-06-10 20:30:23.826170 EDT | AverageDiscountedReturn  187.254
2017-06-10 20:30:23.826494 EDT | AverageQLoss               1.98977
2017-06-10 20:30:23.826816 EDT | AveragePolicySurr        -28.9583
2017-06-10 20:30:23.827150 EDT | AverageQ                  28.2465
2017-06-10 20:30:23.827480 EDT | AverageAbsQ               28.2725
2017-06-10 20:30:23.827768 EDT | AverageY                  28.2505
2017-06-10 20:30:23.828094 EDT | AverageAbsY               28.2592
2017-06-10 20:30:23.828427 EDT | AverageAbsQYDiff           0.674311
2017-06-10 20:30:23.828822 EDT | AverageAction              0.853411
2017-06-10 20:30:23.829151 EDT | PolicyRegParamNorm        49.8856
2017-06-10 20:30:23.829495 EDT | QFunRegParamNorm          57.9273
2017-06-10 20:30:23.829830 EDT | -----------------------  ----------
2017-06-10 20:30:23.830328 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #168 | Training started
2017-06-10 20:30:38.383675 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #168 | Training finished
2017-06-10 20:30:38.384518 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #168 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 20:30:38.384796 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #168 | Collecting samples for evaluation
2017-06-10 20:30:49.834741 EDT | -----------------------  -----------
2017-06-10 20:30:49.835040 EDT | Epoch                     168
2017-06-10 20:30:49.835256 EDT | Iteration                 168
2017-06-10 20:30:49.835413 EDT | AverageReturn             541.386
2017-06-10 20:30:49.835566 EDT | StdReturn                 232.834
2017-06-10 20:30:49.835717 EDT | MaxReturn                1256.26
2017-06-10 20:30:49.835997 EDT | MinReturn                 375.862
2017-06-10 20:30:49.836153 EDT | AverageEsReturn           249.183
2017-06-10 20:30:49.837113 EDT | StdEsReturn               157.501
2017-06-10 20:30:49.837272 EDT | MaxEsReturn               510.493
2017-06-10 20:30:49.837572 EDT | MinEsReturn                13.4817
2017-06-10 20:30:49.837907 EDT | AverageDiscountedReturn   195.893
2017-06-10 20:30:49.838251 EDT | AverageQLoss                2.47341
2017-06-10 20:30:49.838411 EDT | AveragePolicySurr         -29.051
2017-06-10 20:30:49.838564 EDT | AverageQ                   28.3266
2017-06-10 20:30:49.838715 EDT | AverageAbsQ                28.3527
2017-06-10 20:30:49.838865 EDT | AverageY                   28.329
2017-06-10 20:30:49.839015 EDT | AverageAbsY                28.3372
2017-06-10 20:30:49.839162 EDT | AverageAbsQYDiff            0.707572
2017-06-10 20:30:49.839310 EDT | AverageAction               0.730235
2017-06-10 20:30:49.839459 EDT | PolicyRegParamNorm         49.9655
2017-06-10 20:30:49.839611 EDT | QFunRegParamNorm           58.113
2017-06-10 20:30:49.839760 EDT | -----------------------  -----------
2017-06-10 20:30:49.839999 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #169 | Training started
2017-06-10 20:31:04.574435 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #169 | Training finished
2017-06-10 20:31:04.576185 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #169 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 20:31:04.576616 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #169 | Collecting samples for evaluation
2017-06-10 20:31:16.382573 EDT | -----------------------  ----------
2017-06-10 20:31:16.383615 EDT | Epoch                    169
2017-06-10 20:31:16.383991 EDT | Iteration                169
2017-06-10 20:31:16.384422 EDT | AverageReturn            556.3
2017-06-10 20:31:16.384844 EDT | StdReturn                126.042
2017-06-10 20:31:16.385256 EDT | MaxReturn                703.073
2017-06-10 20:31:16.385625 EDT | MinReturn                388.924
2017-06-10 20:31:16.386047 EDT | AverageEsReturn          212.306
2017-06-10 20:31:16.386467 EDT | StdEsReturn              122.424
2017-06-10 20:31:16.386889 EDT | MaxEsReturn              431.23
2017-06-10 20:31:16.387306 EDT | MinEsReturn               21.8853
2017-06-10 20:31:16.387701 EDT | AverageDiscountedReturn  214.97
2017-06-10 20:31:16.388065 EDT | AverageQLoss               2.41987
2017-06-10 20:31:16.388475 EDT | AveragePolicySurr        -29.0562
2017-06-10 20:31:16.388841 EDT | AverageQ                  28.3338
2017-06-10 20:31:16.389245 EDT | AverageAbsQ               28.357
2017-06-10 20:31:16.389651 EDT | AverageY                  28.3371
2017-06-10 20:31:16.390071 EDT | AverageAbsY               28.3429
2017-06-10 20:31:16.390433 EDT | AverageAbsQYDiff           0.705015
2017-06-10 20:31:16.390845 EDT | AverageAction              0.787625
2017-06-10 20:31:16.391217 EDT | PolicyRegParamNorm        50.0859
2017-06-10 20:31:16.391637 EDT | QFunRegParamNorm          58.3091
2017-06-10 20:31:16.392031 EDT | -----------------------  ----------
2017-06-10 20:31:16.392494 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #170 | Training started
2017-06-10 20:31:30.606055 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #170 | Training finished
2017-06-10 20:31:30.614905 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #170 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 20:31:30.615353 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #170 | Collecting samples for evaluation
2017-06-10 20:31:43.912664 EDT | -----------------------  -----------
2017-06-10 20:31:43.913512 EDT | Epoch                     170
2017-06-10 20:31:43.913801 EDT | Iteration                 170
2017-06-10 20:31:43.914053 EDT | AverageReturn             827.583
2017-06-10 20:31:43.914301 EDT | StdReturn                 204.587
2017-06-10 20:31:43.914545 EDT | MaxReturn                1181.06
2017-06-10 20:31:43.914787 EDT | MinReturn                 408.254
2017-06-10 20:31:43.915029 EDT | AverageEsReturn           415.107
2017-06-10 20:31:43.915269 EDT | StdEsReturn               246.155
2017-06-10 20:31:43.915509 EDT | MaxEsReturn               655.486
2017-06-10 20:31:43.915748 EDT | MinEsReturn                61.0997
2017-06-10 20:31:43.915987 EDT | AverageDiscountedReturn   231.808
2017-06-10 20:31:43.916225 EDT | AverageQLoss                2.58218
2017-06-10 20:31:43.916464 EDT | AveragePolicySurr         -29.0933
2017-06-10 20:31:43.916703 EDT | AverageQ                   28.3884
2017-06-10 20:31:43.916941 EDT | AverageAbsQ                28.4133
2017-06-10 20:31:43.917180 EDT | AverageY                   28.3929
2017-06-10 20:31:43.917418 EDT | AverageAbsY                28.3982
2017-06-10 20:31:43.917656 EDT | AverageAbsQYDiff            0.729957
2017-06-10 20:31:43.917946 EDT | AverageAction               0.72679
2017-06-10 20:31:43.918224 EDT | PolicyRegParamNorm         50.1843
2017-06-10 20:31:43.918489 EDT | QFunRegParamNorm           58.4717
2017-06-10 20:31:43.918733 EDT | -----------------------  -----------
2017-06-10 20:31:43.919112 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #171 | Training started
2017-06-10 20:31:58.795508 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #171 | Training finished
2017-06-10 20:31:58.827010 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #171 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 20:31:58.827666 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #171 | Collecting samples for evaluation
2017-06-10 20:32:11.077074 EDT | -----------------------  ----------
2017-06-10 20:32:11.077889 EDT | Epoch                    171
2017-06-10 20:32:11.078081 EDT | Iteration                171
2017-06-10 20:32:11.078403 EDT | AverageReturn            465.896
2017-06-10 20:32:11.078575 EDT | StdReturn                 28.4834
2017-06-10 20:32:11.078728 EDT | MaxReturn                497.802
2017-06-10 20:32:11.078920 EDT | MinReturn                368.19
2017-06-10 20:32:11.079085 EDT | AverageEsReturn          308.22
2017-06-10 20:32:11.079266 EDT | StdEsReturn              252.018
2017-06-10 20:32:11.079426 EDT | MaxEsReturn              758.288
2017-06-10 20:32:11.079584 EDT | MinEsReturn                8.75486
2017-06-10 20:32:11.079741 EDT | AverageDiscountedReturn  201.039
2017-06-10 20:32:11.079902 EDT | AverageQLoss               2.03597
2017-06-10 20:32:11.080121 EDT | AveragePolicySurr        -29.2759
2017-06-10 20:32:11.080307 EDT | AverageQ                  28.581
2017-06-10 20:32:11.080556 EDT | AverageAbsQ               28.6008
2017-06-10 20:32:11.082011 EDT | AverageY                  28.5826
2017-06-10 20:32:11.083365 EDT | AverageAbsY               28.5895
2017-06-10 20:32:11.083735 EDT | AverageAbsQYDiff           0.66791
2017-06-10 20:32:11.084006 EDT | AverageAction              0.781382
2017-06-10 20:32:11.084195 EDT | PolicyRegParamNorm        50.264
2017-06-10 20:32:11.084380 EDT | QFunRegParamNorm          58.6349
2017-06-10 20:32:11.084563 EDT | -----------------------  ----------
2017-06-10 20:32:11.084906 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #172 | Training started
2017-06-10 20:32:26.622209 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #172 | Training finished
2017-06-10 20:32:26.623074 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #172 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 20:32:26.623305 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #172 | Collecting samples for evaluation
2017-06-10 20:32:38.280102 EDT | -----------------------  ----------
2017-06-10 20:32:38.280956 EDT | Epoch                    172
2017-06-10 20:32:38.281278 EDT | Iteration                172
2017-06-10 20:32:38.281570 EDT | AverageReturn            392.605
2017-06-10 20:32:38.281930 EDT | StdReturn                 55.8364
2017-06-10 20:32:38.282253 EDT | MaxReturn                463.243
2017-06-10 20:32:38.282577 EDT | MinReturn                337.865
2017-06-10 20:32:38.282889 EDT | AverageEsReturn          369.883
2017-06-10 20:32:38.283171 EDT | StdEsReturn              173.421
2017-06-10 20:32:38.283476 EDT | MaxEsReturn              568.925
2017-06-10 20:32:38.283791 EDT | MinEsReturn                7.81536
2017-06-10 20:32:38.284058 EDT | AverageDiscountedReturn  183.582
2017-06-10 20:32:38.284355 EDT | AverageQLoss               2.01027
2017-06-10 20:32:38.284687 EDT | AveragePolicySurr        -29.4328
2017-06-10 20:32:38.285173 EDT | AverageQ                  28.7209
2017-06-10 20:32:38.285789 EDT | AverageAbsQ               28.7469
2017-06-10 20:32:38.286076 EDT | AverageY                  28.7251
2017-06-10 20:32:38.286402 EDT | AverageAbsY               28.7334
2017-06-10 20:32:38.286671 EDT | AverageAbsQYDiff           0.682177
2017-06-10 20:32:38.286967 EDT | AverageAction              0.735562
2017-06-10 20:32:38.287279 EDT | PolicyRegParamNorm        50.3842
2017-06-10 20:32:38.287601 EDT | QFunRegParamNorm          58.7534
2017-06-10 20:32:38.287920 EDT | -----------------------  ----------
2017-06-10 20:32:38.288338 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #173 | Training started
2017-06-10 20:32:53.404122 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #173 | Training finished
2017-06-10 20:32:53.404895 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #173 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 20:32:53.405114 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #173 | Collecting samples for evaluation
2017-06-10 20:33:06.339032 EDT | -----------------------  ----------
2017-06-10 20:33:06.340040 EDT | Epoch                    173
2017-06-10 20:33:06.340439 EDT | Iteration                173
2017-06-10 20:33:06.340929 EDT | AverageReturn            402.288
2017-06-10 20:33:06.341317 EDT | StdReturn                 36.4163
2017-06-10 20:33:06.341687 EDT | MaxReturn                616.389
2017-06-10 20:33:06.342194 EDT | MinReturn                326.07
2017-06-10 20:33:06.342571 EDT | AverageEsReturn          151.966
2017-06-10 20:33:06.342950 EDT | StdEsReturn              134.09
2017-06-10 20:33:06.343453 EDT | MaxEsReturn              376.88
2017-06-10 20:33:06.343837 EDT | MinEsReturn               13.1606
2017-06-10 20:33:06.344332 EDT | AverageDiscountedReturn  184.876
2017-06-10 20:33:06.344715 EDT | AverageQLoss               2.66825
2017-06-10 20:33:06.345089 EDT | AveragePolicySurr        -29.5177
2017-06-10 20:33:06.345599 EDT | AverageQ                  28.7859
2017-06-10 20:33:06.345994 EDT | AverageAbsQ               28.8094
2017-06-10 20:33:06.346472 EDT | AverageY                  28.7879
2017-06-10 20:33:06.346856 EDT | AverageAbsY               28.7939
2017-06-10 20:33:06.347229 EDT | AverageAbsQYDiff           0.724563
2017-06-10 20:33:06.347717 EDT | AverageAction              0.727989
2017-06-10 20:33:06.348089 EDT | PolicyRegParamNorm        50.4177
2017-06-10 20:33:06.348543 EDT | QFunRegParamNorm          58.9144
2017-06-10 20:33:06.348927 EDT | -----------------------  ----------
2017-06-10 20:33:06.349588 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #174 | Training started
2017-06-10 20:33:20.522583 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #174 | Training finished
2017-06-10 20:33:20.523035 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #174 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 20:33:20.523391 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #174 | Collecting samples for evaluation
2017-06-10 20:33:33.633541 EDT | -----------------------  -----------
2017-06-10 20:33:33.634297 EDT | Epoch                     174
2017-06-10 20:33:33.634501 EDT | Iteration                 174
2017-06-10 20:33:33.634663 EDT | AverageReturn             771.123
2017-06-10 20:33:33.634820 EDT | StdReturn                 460.139
2017-06-10 20:33:33.635057 EDT | MaxReturn                2273.97
2017-06-10 20:33:33.635567 EDT | MinReturn                 349.814
2017-06-10 20:33:33.635765 EDT | AverageEsReturn           147.857
2017-06-10 20:33:33.635983 EDT | StdEsReturn               140.657
2017-06-10 20:33:33.636256 EDT | MaxEsReturn               478.1
2017-06-10 20:33:33.636497 EDT | MinEsReturn                11.4413
2017-06-10 20:33:33.636664 EDT | AverageDiscountedReturn   215.873
2017-06-10 20:33:33.636821 EDT | AverageQLoss                2.74373
2017-06-10 20:33:33.637097 EDT | AveragePolicySurr         -29.6275
2017-06-10 20:33:33.637257 EDT | AverageQ                   28.8977
2017-06-10 20:33:33.637466 EDT | AverageAbsQ                28.9226
2017-06-10 20:33:33.637737 EDT | AverageY                   28.9001
2017-06-10 20:33:33.637988 EDT | AverageAbsY                28.9087
2017-06-10 20:33:33.638235 EDT | AverageAbsQYDiff            0.721691
2017-06-10 20:33:33.638481 EDT | AverageAction               0.723501
2017-06-10 20:33:33.638725 EDT | PolicyRegParamNorm         50.5274
2017-06-10 20:33:33.639023 EDT | QFunRegParamNorm           59.0829
2017-06-10 20:33:33.639313 EDT | -----------------------  -----------
2017-06-10 20:33:33.639750 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #175 | Training started
2017-06-10 20:33:46.942512 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #175 | Training finished
2017-06-10 20:33:46.943648 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #175 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 20:33:46.944116 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #175 | Collecting samples for evaluation
2017-06-10 20:33:59.735568 EDT | -----------------------  ----------
2017-06-10 20:33:59.737445 EDT | Epoch                    175
2017-06-10 20:33:59.737774 EDT | Iteration                175
2017-06-10 20:33:59.737964 EDT | AverageReturn            583.891
2017-06-10 20:33:59.738171 EDT | StdReturn                193.86
2017-06-10 20:33:59.738555 EDT | MaxReturn                987.571
2017-06-10 20:33:59.739030 EDT | MinReturn                408.136
2017-06-10 20:33:59.739380 EDT | AverageEsReturn          290.231
2017-06-10 20:33:59.739783 EDT | StdEsReturn              223.958
2017-06-10 20:33:59.740122 EDT | MaxEsReturn              655.068
2017-06-10 20:33:59.740455 EDT | MinEsReturn               13.0036
2017-06-10 20:33:59.740877 EDT | AverageDiscountedReturn  213.391
2017-06-10 20:33:59.741218 EDT | AverageQLoss               2.6617
2017-06-10 20:33:59.741614 EDT | AveragePolicySurr        -29.7377
2017-06-10 20:33:59.742059 EDT | AverageQ                  28.9872
2017-06-10 20:33:59.744390 EDT | AverageAbsQ               29.01
2017-06-10 20:33:59.744573 EDT | AverageY                  28.9907
2017-06-10 20:33:59.745592 EDT | AverageAbsY               28.9988
2017-06-10 20:33:59.745818 EDT | AverageAbsQYDiff           0.720135
2017-06-10 20:33:59.746120 EDT | AverageAction              0.775786
2017-06-10 20:33:59.746280 EDT | PolicyRegParamNorm        50.5381
2017-06-10 20:33:59.746437 EDT | QFunRegParamNorm          59.2638
2017-06-10 20:33:59.746593 EDT | -----------------------  ----------
2017-06-10 20:33:59.746871 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #176 | Training started
2017-06-10 20:34:14.031399 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #176 | Training finished
2017-06-10 20:34:14.032205 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #176 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 20:34:14.032575 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #176 | Collecting samples for evaluation
2017-06-10 20:34:26.109218 EDT | -----------------------  -----------
2017-06-10 20:34:26.111077 EDT | Epoch                     176
2017-06-10 20:34:26.111959 EDT | Iteration                 176
2017-06-10 20:34:26.112147 EDT | AverageReturn             599.56
2017-06-10 20:34:26.112339 EDT | StdReturn                 169.813
2017-06-10 20:34:26.112525 EDT | MaxReturn                1035.79
2017-06-10 20:34:26.112707 EDT | MinReturn                 337.547
2017-06-10 20:34:26.112889 EDT | AverageEsReturn           276.626
2017-06-10 20:34:26.113072 EDT | StdEsReturn               219.396
2017-06-10 20:34:26.113253 EDT | MaxEsReturn               635.288
2017-06-10 20:34:26.113464 EDT | MinEsReturn                12.6205
2017-06-10 20:34:26.113651 EDT | AverageDiscountedReturn   212.157
2017-06-10 20:34:26.113944 EDT | AverageQLoss                2.59055
2017-06-10 20:34:26.114279 EDT | AveragePolicySurr         -30.022
2017-06-10 20:34:26.114599 EDT | AverageQ                   29.2834
2017-06-10 20:34:26.114919 EDT | AverageAbsQ                29.3056
2017-06-10 20:34:26.115297 EDT | AverageY                   29.288
2017-06-10 20:34:26.115610 EDT | AverageAbsY                29.2936
2017-06-10 20:34:26.115920 EDT | AverageAbsQYDiff            0.710724
2017-06-10 20:34:26.116226 EDT | AverageAction               0.7139
2017-06-10 20:34:26.118615 EDT | PolicyRegParamNorm         50.6348
2017-06-10 20:34:26.119023 EDT | QFunRegParamNorm           59.4726
2017-06-10 20:34:26.119340 EDT | -----------------------  -----------
2017-06-10 20:34:26.119936 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #177 | Training started
2017-06-10 20:34:41.183030 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #177 | Training finished
2017-06-10 20:34:41.183332 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #177 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 20:34:41.183622 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #177 | Collecting samples for evaluation
2017-06-10 20:34:52.757960 EDT | -----------------------  ----------
2017-06-10 20:34:52.758946 EDT | Epoch                    177
2017-06-10 20:34:52.759293 EDT | Iteration                177
2017-06-10 20:34:52.759639 EDT | AverageReturn            419.159
2017-06-10 20:34:52.760073 EDT | StdReturn                 75.385
2017-06-10 20:34:52.760499 EDT | MaxReturn                742.221
2017-06-10 20:34:52.761116 EDT | MinReturn                351.399
2017-06-10 20:34:52.762000 EDT | AverageEsReturn          154.568
2017-06-10 20:34:52.762451 EDT | StdEsReturn              194.778
2017-06-10 20:34:52.763229 EDT | MaxEsReturn              626.173
2017-06-10 20:34:52.763949 EDT | MinEsReturn                8.79165
2017-06-10 20:34:52.766049 EDT | AverageDiscountedReturn  185.741
2017-06-10 20:34:52.766353 EDT | AverageQLoss               2.71686
2017-06-10 20:34:52.766645 EDT | AveragePolicySurr        -30.0868
2017-06-10 20:34:52.766968 EDT | AverageQ                  29.3542
2017-06-10 20:34:52.767297 EDT | AverageAbsQ               29.3764
2017-06-10 20:34:52.767617 EDT | AverageY                  29.3557
2017-06-10 20:34:52.768049 EDT | AverageAbsY               29.3633
2017-06-10 20:34:52.768475 EDT | AverageAbsQYDiff           0.72913
2017-06-10 20:34:52.768805 EDT | AverageAction              0.697655
2017-06-10 20:34:52.769138 EDT | PolicyRegParamNorm        50.7596
2017-06-10 20:34:52.769577 EDT | QFunRegParamNorm          59.6666
2017-06-10 20:34:52.769974 EDT | -----------------------  ----------
2017-06-10 20:34:52.770451 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #178 | Training started
2017-06-10 20:35:07.064353 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #178 | Training finished
2017-06-10 20:35:07.065478 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #178 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 20:35:07.066012 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #178 | Collecting samples for evaluation
2017-06-10 20:35:19.553127 EDT | -----------------------  -----------
2017-06-10 20:35:19.554047 EDT | Epoch                     178
2017-06-10 20:35:19.554250 EDT | Iteration                 178
2017-06-10 20:35:19.554412 EDT | AverageReturn             725.723
2017-06-10 20:35:19.554575 EDT | StdReturn                 149.976
2017-06-10 20:35:19.554746 EDT | MaxReturn                1356.55
2017-06-10 20:35:19.554948 EDT | MinReturn                 317.188
2017-06-10 20:35:19.555199 EDT | AverageEsReturn           218.091
2017-06-10 20:35:19.555392 EDT | StdEsReturn               126.25
2017-06-10 20:35:19.555557 EDT | MaxEsReturn               481.082
2017-06-10 20:35:19.555879 EDT | MinEsReturn                30.3286
2017-06-10 20:35:19.556103 EDT | AverageDiscountedReturn   228.11
2017-06-10 20:35:19.556280 EDT | AverageQLoss                2.87599
2017-06-10 20:35:19.556557 EDT | AveragePolicySurr         -30.0468
2017-06-10 20:35:19.556737 EDT | AverageQ                   29.3141
2017-06-10 20:35:19.557085 EDT | AverageAbsQ                29.3453
2017-06-10 20:35:19.557262 EDT | AverageY                   29.3146
2017-06-10 20:35:19.557504 EDT | AverageAbsY                29.3258
2017-06-10 20:35:19.557666 EDT | AverageAbsQYDiff            0.726889
2017-06-10 20:35:19.558604 EDT | AverageAction               0.695668
2017-06-10 20:35:19.559826 EDT | PolicyRegParamNorm         50.8316
2017-06-10 20:35:19.560114 EDT | QFunRegParamNorm           59.8128
2017-06-10 20:35:19.560402 EDT | -----------------------  -----------
2017-06-10 20:35:19.560818 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #179 | Training started
2017-06-10 20:35:32.773776 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #179 | Training finished
2017-06-10 20:35:32.774760 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #179 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 20:35:32.775097 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #179 | Collecting samples for evaluation
2017-06-10 20:35:45.414927 EDT | -----------------------  -----------
2017-06-10 20:35:45.415739 EDT | Epoch                     179
2017-06-10 20:35:45.416362 EDT | Iteration                 179
2017-06-10 20:35:45.416646 EDT | AverageReturn             739.19
2017-06-10 20:35:45.416990 EDT | StdReturn                 177.69
2017-06-10 20:35:45.417323 EDT | MaxReturn                1023.73
2017-06-10 20:35:45.418421 EDT | MinReturn                 280.673
2017-06-10 20:35:45.418754 EDT | AverageEsReturn           221.807
2017-06-10 20:35:45.420684 EDT | StdEsReturn               195.009
2017-06-10 20:35:45.421004 EDT | MaxEsReturn               570.851
2017-06-10 20:35:45.421303 EDT | MinEsReturn                 8.86664
2017-06-10 20:35:45.421636 EDT | AverageDiscountedReturn   219.245
2017-06-10 20:35:45.421979 EDT | AverageQLoss                2.94304
2017-06-10 20:35:45.422250 EDT | AveragePolicySurr         -30.2499
2017-06-10 20:35:45.422567 EDT | AverageQ                   29.5264
2017-06-10 20:35:45.422898 EDT | AverageAbsQ                29.5543
2017-06-10 20:35:45.423222 EDT | AverageY                   29.5307
2017-06-10 20:35:45.423487 EDT | AverageAbsY                29.5402
2017-06-10 20:35:45.423774 EDT | AverageAbsQYDiff            0.731013
2017-06-10 20:35:45.424098 EDT | AverageAction               0.70125
2017-06-10 20:35:45.424428 EDT | PolicyRegParamNorm         50.8958
2017-06-10 20:35:45.424717 EDT | QFunRegParamNorm           59.9453
2017-06-10 20:35:45.424974 EDT | -----------------------  -----------
2017-06-10 20:35:45.425470 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #180 | Training started
2017-06-10 20:35:59.589384 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #180 | Training finished
2017-06-10 20:35:59.590533 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #180 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 20:35:59.591159 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #180 | Collecting samples for evaluation
2017-06-10 20:36:11.422038 EDT | -----------------------  ----------
2017-06-10 20:36:11.432489 EDT | Epoch                    180
2017-06-10 20:36:11.433191 EDT | Iteration                180
2017-06-10 20:36:11.433572 EDT | AverageReturn            712.635
2017-06-10 20:36:11.434042 EDT | StdReturn                 88.7474
2017-06-10 20:36:11.434282 EDT | MaxReturn                980.928
2017-06-10 20:36:11.434620 EDT | MinReturn                622.648
2017-06-10 20:36:11.434981 EDT | AverageEsReturn          230.331
2017-06-10 20:36:11.435241 EDT | StdEsReturn              180.498
2017-06-10 20:36:11.435611 EDT | MaxEsReturn              507.12
2017-06-10 20:36:11.435964 EDT | MinEsReturn               11.4784
2017-06-10 20:36:11.436340 EDT | AverageDiscountedReturn  220.998
2017-06-10 20:36:11.436704 EDT | AverageQLoss               2.73135
2017-06-10 20:36:11.437158 EDT | AveragePolicySurr        -30.3799
2017-06-10 20:36:11.437620 EDT | AverageQ                  29.65
2017-06-10 20:36:11.439449 EDT | AverageAbsQ               29.6793
2017-06-10 20:36:11.439884 EDT | AverageY                  29.6522
2017-06-10 20:36:11.440310 EDT | AverageAbsY               29.6646
2017-06-10 20:36:11.440748 EDT | AverageAbsQYDiff           0.725153
2017-06-10 20:36:11.441217 EDT | AverageAction              0.656714
2017-06-10 20:36:11.441681 EDT | PolicyRegParamNorm        50.9734
2017-06-10 20:36:11.442544 EDT | QFunRegParamNorm          60.0883
2017-06-10 20:36:11.443088 EDT | -----------------------  ----------
2017-06-10 20:36:11.443729 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #181 | Training started
2017-06-10 20:36:26.756416 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #181 | Training finished
2017-06-10 20:36:26.757413 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #181 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 20:36:26.757847 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #181 | Collecting samples for evaluation
2017-06-10 20:36:38.822482 EDT | -----------------------  -----------
2017-06-10 20:36:38.823360 EDT | Epoch                     181
2017-06-10 20:36:38.823715 EDT | Iteration                 181
2017-06-10 20:36:38.824122 EDT | AverageReturn             950.852
2017-06-10 20:36:38.824580 EDT | StdReturn                 571.584
2017-06-10 20:36:38.824928 EDT | MaxReturn                2984.25
2017-06-10 20:36:38.825125 EDT | MinReturn                 628.663
2017-06-10 20:36:38.825281 EDT | AverageEsReturn           455.408
2017-06-10 20:36:38.825434 EDT | StdEsReturn               241.482
2017-06-10 20:36:38.825584 EDT | MaxEsReturn               700.881
2017-06-10 20:36:38.825752 EDT | MinEsReturn                14.6047
2017-06-10 20:36:38.826307 EDT | AverageDiscountedReturn   215.44
2017-06-10 20:36:38.826482 EDT | AverageQLoss                2.46252
2017-06-10 20:36:38.826896 EDT | AveragePolicySurr         -30.5501
2017-06-10 20:36:38.827342 EDT | AverageQ                   29.8128
2017-06-10 20:36:38.827619 EDT | AverageAbsQ                29.8401
2017-06-10 20:36:38.828159 EDT | AverageY                   29.8165
2017-06-10 20:36:38.829192 EDT | AverageAbsY                29.8287
2017-06-10 20:36:38.830160 EDT | AverageAbsQYDiff            0.699145
2017-06-10 20:36:38.830528 EDT | AverageAction               0.655966
2017-06-10 20:36:38.830852 EDT | PolicyRegParamNorm         51.0257
2017-06-10 20:36:38.831243 EDT | QFunRegParamNorm           60.192
2017-06-10 20:36:38.831579 EDT | -----------------------  -----------
2017-06-10 20:36:38.832758 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #182 | Training started
2017-06-10 20:36:52.531660 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #182 | Training finished
2017-06-10 20:36:52.531903 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #182 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 20:36:52.532078 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #182 | Collecting samples for evaluation
2017-06-10 20:37:05.242464 EDT | -----------------------  -----------
2017-06-10 20:37:05.243403 EDT | Epoch                     182
2017-06-10 20:37:05.244171 EDT | Iteration                 182
2017-06-10 20:37:05.244364 EDT | AverageReturn             765.78
2017-06-10 20:37:05.244588 EDT | StdReturn                 332.011
2017-06-10 20:37:05.244789 EDT | MaxReturn                2294.49
2017-06-10 20:37:05.245055 EDT | MinReturn                 626.17
2017-06-10 20:37:05.245254 EDT | AverageEsReturn           327.623
2017-06-10 20:37:05.245456 EDT | StdEsReturn               102.949
2017-06-10 20:37:05.245676 EDT | MaxEsReturn               493.116
2017-06-10 20:37:05.245873 EDT | MinEsReturn               189.43
2017-06-10 20:37:05.246054 EDT | AverageDiscountedReturn   217.82
2017-06-10 20:37:05.246247 EDT | AverageQLoss                2.63122
2017-06-10 20:37:05.246433 EDT | AveragePolicySurr         -30.5936
2017-06-10 20:37:05.246612 EDT | AverageQ                   29.8768
2017-06-10 20:37:05.246791 EDT | AverageAbsQ                29.9078
2017-06-10 20:37:05.246968 EDT | AverageY                   29.8791
2017-06-10 20:37:05.247853 EDT | AverageAbsY                29.8921
2017-06-10 20:37:05.248046 EDT | AverageAbsQYDiff            0.710503
2017-06-10 20:37:05.248257 EDT | AverageAction               0.630727
2017-06-10 20:37:05.248492 EDT | PolicyRegParamNorm         51.1763
2017-06-10 20:37:05.248674 EDT | QFunRegParamNorm           60.3086
2017-06-10 20:37:05.248866 EDT | -----------------------  -----------
2017-06-10 20:37:05.249264 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #183 | Training started
2017-06-10 20:37:20.022890 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #183 | Training finished
2017-06-10 20:37:20.023655 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #183 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 20:37:20.023862 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #183 | Collecting samples for evaluation
2017-06-10 20:37:32.266325 EDT | -----------------------  -----------
2017-06-10 20:37:32.267119 EDT | Epoch                     183
2017-06-10 20:37:32.267554 EDT | Iteration                 183
2017-06-10 20:37:32.267962 EDT | AverageReturn             916.702
2017-06-10 20:37:32.268293 EDT | StdReturn                 393.028
2017-06-10 20:37:32.268686 EDT | MaxReturn                1853.72
2017-06-10 20:37:32.269029 EDT | MinReturn                 436.683
2017-06-10 20:37:32.270224 EDT | AverageEsReturn           283.721
2017-06-10 20:37:32.270598 EDT | StdEsReturn               223.151
2017-06-10 20:37:32.270949 EDT | MaxEsReturn               638.584
2017-06-10 20:37:32.271293 EDT | MinEsReturn                15.8048
2017-06-10 20:37:32.271650 EDT | AverageDiscountedReturn   221.08
2017-06-10 20:37:32.272085 EDT | AverageQLoss                3.11265
2017-06-10 20:37:32.272443 EDT | AveragePolicySurr         -30.6236
2017-06-10 20:37:32.272802 EDT | AverageQ                   29.9012
2017-06-10 20:37:32.273156 EDT | AverageAbsQ                29.9368
2017-06-10 20:37:32.273574 EDT | AverageY                   29.9053
2017-06-10 20:37:32.274026 EDT | AverageAbsY                29.9229
2017-06-10 20:37:32.274461 EDT | AverageAbsQYDiff            0.754437
2017-06-10 20:37:32.274814 EDT | AverageAction               0.692129
2017-06-10 20:37:32.275158 EDT | PolicyRegParamNorm         51.2038
2017-06-10 20:37:32.275504 EDT | QFunRegParamNorm           60.5117
2017-06-10 20:37:32.275850 EDT | -----------------------  -----------
2017-06-10 20:37:32.276569 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #184 | Training started
2017-06-10 20:37:46.622746 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #184 | Training finished
2017-06-10 20:37:46.623568 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #184 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 20:37:46.623777 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #184 | Collecting samples for evaluation
2017-06-10 20:37:59.155114 EDT | -----------------------  -----------
2017-06-10 20:37:59.156036 EDT | Epoch                     184
2017-06-10 20:37:59.156372 EDT | Iteration                 184
2017-06-10 20:37:59.156705 EDT | AverageReturn             800.899
2017-06-10 20:37:59.156974 EDT | StdReturn                 185.001
2017-06-10 20:37:59.157326 EDT | MaxReturn                1367.99
2017-06-10 20:37:59.157651 EDT | MinReturn                 499.617
2017-06-10 20:37:59.157985 EDT | AverageEsReturn           278.928
2017-06-10 20:37:59.158301 EDT | StdEsReturn               225.096
2017-06-10 20:37:59.166035 EDT | MaxEsReturn               688.693
2017-06-10 20:37:59.166530 EDT | MinEsReturn                 8.28025
2017-06-10 20:37:59.166937 EDT | AverageDiscountedReturn   216.445
2017-06-10 20:37:59.167316 EDT | AverageQLoss                2.49143
2017-06-10 20:37:59.167690 EDT | AveragePolicySurr         -30.6726
2017-06-10 20:37:59.168043 EDT | AverageQ                   29.9737
2017-06-10 20:37:59.168223 EDT | AverageAbsQ                30.0059
2017-06-10 20:37:59.168496 EDT | AverageY                   29.9747
2017-06-10 20:37:59.168905 EDT | AverageAbsY                29.9895
2017-06-10 20:37:59.169240 EDT | AverageAbsQYDiff            0.700339
2017-06-10 20:37:59.169576 EDT | AverageAction               0.736081
2017-06-10 20:37:59.169910 EDT | PolicyRegParamNorm         51.3467
2017-06-10 20:37:59.170232 EDT | QFunRegParamNorm           60.6189
2017-06-10 20:37:59.170542 EDT | -----------------------  -----------
2017-06-10 20:37:59.171013 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #185 | Training started
2017-06-10 20:38:13.480945 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #185 | Training finished
2017-06-10 20:38:13.481441 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #185 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 20:38:13.481829 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #185 | Collecting samples for evaluation
2017-06-10 20:38:24.871141 EDT | -----------------------  -----------
2017-06-10 20:38:24.873119 EDT | Epoch                     185
2017-06-10 20:38:24.873585 EDT | Iteration                 185
2017-06-10 20:38:24.875320 EDT | AverageReturn             979.545
2017-06-10 20:38:24.875730 EDT | StdReturn                 309.836
2017-06-10 20:38:24.876159 EDT | MaxReturn                1787.74
2017-06-10 20:38:24.876591 EDT | MinReturn                 481.561
2017-06-10 20:38:24.877580 EDT | AverageEsReturn           413.426
2017-06-10 20:38:24.880094 EDT | StdEsReturn               204.098
2017-06-10 20:38:24.881254 EDT | MaxEsReturn               620.513
2017-06-10 20:38:24.882536 EDT | MinEsReturn                28.8858
2017-06-10 20:38:24.882981 EDT | AverageDiscountedReturn   223.05
2017-06-10 20:38:24.885260 EDT | AverageQLoss                2.70663
2017-06-10 20:38:24.885716 EDT | AveragePolicySurr         -30.8571
2017-06-10 20:38:24.886158 EDT | AverageQ                   30.1424
2017-06-10 20:38:24.888138 EDT | AverageAbsQ                30.179
2017-06-10 20:38:24.889017 EDT | AverageY                   30.1462
2017-06-10 20:38:24.889393 EDT | AverageAbsY                30.166
2017-06-10 20:38:24.890467 EDT | AverageAbsQYDiff            0.702249
2017-06-10 20:38:24.890855 EDT | AverageAction               0.776714
2017-06-10 20:38:24.893240 EDT | PolicyRegParamNorm         51.4044
2017-06-10 20:38:24.893653 EDT | QFunRegParamNorm           60.7689
2017-06-10 20:38:24.894087 EDT | -----------------------  -----------
2017-06-10 20:38:24.894684 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #186 | Training started
2017-06-10 20:38:40.094215 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #186 | Training finished
2017-06-10 20:38:40.095051 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #186 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 20:38:40.095328 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #186 | Collecting samples for evaluation
2017-06-10 20:38:52.139072 EDT | -----------------------  ----------
2017-06-10 20:38:52.140347 EDT | Epoch                    186
2017-06-10 20:38:52.140700 EDT | Iteration                186
2017-06-10 20:38:52.141039 EDT | AverageReturn            291.495
2017-06-10 20:38:52.141368 EDT | StdReturn                  8.6671
2017-06-10 20:38:52.141705 EDT | MaxReturn                313.594
2017-06-10 20:38:52.142037 EDT | MinReturn                270.538
2017-06-10 20:38:52.142352 EDT | AverageEsReturn          341.765
2017-06-10 20:38:52.142678 EDT | StdEsReturn              295.315
2017-06-10 20:38:52.143078 EDT | MaxEsReturn              813.131
2017-06-10 20:38:52.143396 EDT | MinEsReturn                7.55822
2017-06-10 20:38:52.143728 EDT | AverageDiscountedReturn  150.56
2017-06-10 20:38:52.144059 EDT | AverageQLoss               3.00077
2017-06-10 20:38:52.144401 EDT | AveragePolicySurr        -30.9859
2017-06-10 20:38:52.144733 EDT | AverageQ                  30.2939
2017-06-10 20:38:52.145031 EDT | AverageAbsQ               30.3252
2017-06-10 20:38:52.145372 EDT | AverageY                  30.2969
2017-06-10 20:38:52.145790 EDT | AverageAbsY               30.3109
2017-06-10 20:38:52.146198 EDT | AverageAbsQYDiff           0.741317
2017-06-10 20:38:52.146642 EDT | AverageAction              0.71967
2017-06-10 20:38:52.147030 EDT | PolicyRegParamNorm        51.5433
2017-06-10 20:38:52.147501 EDT | QFunRegParamNorm          60.9075
2017-06-10 20:38:52.147876 EDT | -----------------------  ----------
2017-06-10 20:38:52.148454 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #187 | Training started
2017-06-10 20:39:06.112477 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #187 | Training finished
2017-06-10 20:39:06.121819 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #187 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 20:39:06.122213 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #187 | Collecting samples for evaluation
2017-06-10 20:39:18.657823 EDT | -----------------------  -----------
2017-06-10 20:39:18.658801 EDT | Epoch                     187
2017-06-10 20:39:18.659902 EDT | Iteration                 187
2017-06-10 20:39:18.660260 EDT | AverageReturn             551.109
2017-06-10 20:39:18.660565 EDT | StdReturn                 389.859
2017-06-10 20:39:18.660727 EDT | MaxReturn                2571.53
2017-06-10 20:39:18.660881 EDT | MinReturn                 331.903
2017-06-10 20:39:18.661044 EDT | AverageEsReturn           215.876
2017-06-10 20:39:18.661228 EDT | StdEsReturn               234.041
2017-06-10 20:39:18.661403 EDT | MaxEsReturn               736.922
2017-06-10 20:39:18.661567 EDT | MinEsReturn                14.9906
2017-06-10 20:39:18.661805 EDT | AverageDiscountedReturn   194.518
2017-06-10 20:39:18.662407 EDT | AverageQLoss                2.4382
2017-06-10 20:39:18.662819 EDT | AveragePolicySurr         -31.1277
2017-06-10 20:39:18.663286 EDT | AverageQ                   30.4147
2017-06-10 20:39:18.663612 EDT | AverageAbsQ                30.4504
2017-06-10 20:39:18.663938 EDT | AverageY                   30.4176
2017-06-10 20:39:18.664283 EDT | AverageAbsY                30.4323
2017-06-10 20:39:18.664578 EDT | AverageAbsQYDiff            0.688434
2017-06-10 20:39:18.664847 EDT | AverageAction               0.766802
2017-06-10 20:39:18.665108 EDT | PolicyRegParamNorm         51.6492
2017-06-10 20:39:18.665369 EDT | QFunRegParamNorm           61.0311
2017-06-10 20:39:18.665631 EDT | -----------------------  -----------
2017-06-10 20:39:18.666117 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #188 | Training started
2017-06-10 20:39:32.841351 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #188 | Training finished
2017-06-10 20:39:32.842467 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #188 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 20:39:32.842870 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #188 | Collecting samples for evaluation
2017-06-10 20:39:43.890676 EDT | -----------------------  ----------
2017-06-10 20:39:43.892012 EDT | Epoch                    188
2017-06-10 20:39:43.892254 EDT | Iteration                188
2017-06-10 20:39:43.892447 EDT | AverageReturn            570.919
2017-06-10 20:39:43.892633 EDT | StdReturn                 91.1606
2017-06-10 20:39:43.892819 EDT | MaxReturn                835.93
2017-06-10 20:39:43.893010 EDT | MinReturn                469.469
2017-06-10 20:39:43.893191 EDT | AverageEsReturn          276.212
2017-06-10 20:39:43.893372 EDT | StdEsReturn              274.18
2017-06-10 20:39:43.893562 EDT | MaxEsReturn              835.165
2017-06-10 20:39:43.893757 EDT | MinEsReturn               12.1763
2017-06-10 20:39:43.893938 EDT | AverageDiscountedReturn  196.402
2017-06-10 20:39:43.894125 EDT | AverageQLoss               2.60654
2017-06-10 20:39:43.894305 EDT | AveragePolicySurr        -31.1326
2017-06-10 20:39:43.894636 EDT | AverageQ                  30.3926
2017-06-10 20:39:43.896228 EDT | AverageAbsQ               30.4304
2017-06-10 20:39:43.896526 EDT | AverageY                  30.3972
2017-06-10 20:39:43.897157 EDT | AverageAbsY               30.4139
2017-06-10 20:39:43.899242 EDT | AverageAbsQYDiff           0.713759
2017-06-10 20:39:43.899532 EDT | AverageAction              0.745896
2017-06-10 20:39:43.899800 EDT | PolicyRegParamNorm        51.7005
2017-06-10 20:39:43.900066 EDT | QFunRegParamNorm          61.2239
2017-06-10 20:39:43.900326 EDT | -----------------------  ----------
2017-06-10 20:39:43.900714 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #189 | Training started
2017-06-10 20:39:58.728059 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #189 | Training finished
2017-06-10 20:39:58.729039 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #189 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 20:39:58.729537 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #189 | Collecting samples for evaluation
2017-06-10 20:40:10.698780 EDT | -----------------------  -----------
2017-06-10 20:40:10.699397 EDT | Epoch                     189
2017-06-10 20:40:10.701435 EDT | Iteration                 189
2017-06-10 20:40:10.701932 EDT | AverageReturn            1007.48
2017-06-10 20:40:10.702369 EDT | StdReturn                 399.814
2017-06-10 20:40:10.702742 EDT | MaxReturn                1904.67
2017-06-10 20:40:10.703144 EDT | MinReturn                 382.003
2017-06-10 20:40:10.703579 EDT | AverageEsReturn           259.837
2017-06-10 20:40:10.703998 EDT | StdEsReturn               170.719
2017-06-10 20:40:10.704349 EDT | MaxEsReturn               624.345
2017-06-10 20:40:10.704774 EDT | MinEsReturn                18.4163
2017-06-10 20:40:10.705212 EDT | AverageDiscountedReturn   224.778
2017-06-10 20:40:10.705599 EDT | AverageQLoss                2.85172
2017-06-10 20:40:10.705984 EDT | AveragePolicySurr         -31.2082
2017-06-10 20:40:10.706414 EDT | AverageQ                   30.4613
2017-06-10 20:40:10.706815 EDT | AverageAbsQ                30.4923
2017-06-10 20:40:10.707192 EDT | AverageY                   30.464
2017-06-10 20:40:10.707590 EDT | AverageAbsY                30.4779
2017-06-10 20:40:10.707996 EDT | AverageAbsQYDiff            0.720921
2017-06-10 20:40:10.708430 EDT | AverageAction               0.710335
2017-06-10 20:40:10.708782 EDT | PolicyRegParamNorm         51.7995
2017-06-10 20:40:10.709155 EDT | QFunRegParamNorm           61.4273
2017-06-10 20:40:10.709541 EDT | -----------------------  -----------
2017-06-10 20:40:10.710067 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #190 | Training started
2017-06-10 20:40:25.778217 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #190 | Training finished
2017-06-10 20:40:25.779539 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #190 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 20:40:25.779750 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #190 | Collecting samples for evaluation
2017-06-10 20:40:37.565561 EDT | -----------------------  ----------
2017-06-10 20:40:37.566883 EDT | Epoch                    190
2017-06-10 20:40:37.567176 EDT | Iteration                190
2017-06-10 20:40:37.567428 EDT | AverageReturn            612.514
2017-06-10 20:40:37.567785 EDT | StdReturn                127.42
2017-06-10 20:40:37.568171 EDT | MaxReturn                993.447
2017-06-10 20:40:37.568650 EDT | MinReturn                424.83
2017-06-10 20:40:37.568949 EDT | AverageEsReturn          307.614
2017-06-10 20:40:37.569164 EDT | StdEsReturn              211.984
2017-06-10 20:40:37.569376 EDT | MaxEsReturn              654.672
2017-06-10 20:40:37.569583 EDT | MinEsReturn                8.5004
2017-06-10 20:40:37.569813 EDT | AverageDiscountedReturn  211.997
2017-06-10 20:40:37.570036 EDT | AverageQLoss               2.98019
2017-06-10 20:40:37.570280 EDT | AveragePolicySurr        -31.3188
2017-06-10 20:40:37.570465 EDT | AverageQ                  30.5486
2017-06-10 20:40:37.570826 EDT | AverageAbsQ               30.5811
2017-06-10 20:40:37.571202 EDT | AverageY                  30.5506
2017-06-10 20:40:37.571535 EDT | AverageAbsY               30.5637
2017-06-10 20:40:37.571886 EDT | AverageAbsQYDiff           0.730536
2017-06-10 20:40:37.572225 EDT | AverageAction              0.752439
2017-06-10 20:40:37.572527 EDT | PolicyRegParamNorm        51.9242
2017-06-10 20:40:37.572845 EDT | QFunRegParamNorm          61.5962
2017-06-10 20:40:37.573150 EDT | -----------------------  ----------
2017-06-10 20:40:37.573610 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #191 | Training started
2017-06-10 20:40:52.193362 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #191 | Training finished
2017-06-10 20:40:52.193921 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #191 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 20:40:52.194113 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #191 | Collecting samples for evaluation
2017-06-10 20:41:04.465477 EDT | -----------------------  -----------
2017-06-10 20:41:04.466358 EDT | Epoch                     191
2017-06-10 20:41:04.466542 EDT | Iteration                 191
2017-06-10 20:41:04.466701 EDT | AverageReturn             575.776
2017-06-10 20:41:04.467201 EDT | StdReturn                 361.05
2017-06-10 20:41:04.467441 EDT | MaxReturn                2671.02
2017-06-10 20:41:04.467992 EDT | MinReturn                 388.706
2017-06-10 20:41:04.469857 EDT | AverageEsReturn           269.813
2017-06-10 20:41:04.470035 EDT | StdEsReturn               167.78
2017-06-10 20:41:04.470312 EDT | MaxEsReturn               492.615
2017-06-10 20:41:04.470591 EDT | MinEsReturn                 6.03355
2017-06-10 20:41:04.470941 EDT | AverageDiscountedReturn   191.846
2017-06-10 20:41:04.471097 EDT | AverageQLoss                2.85764
2017-06-10 20:41:04.471249 EDT | AveragePolicySurr         -31.5521
2017-06-10 20:41:04.471476 EDT | AverageQ                   30.803
2017-06-10 20:41:04.471746 EDT | AverageAbsQ                30.8328
2017-06-10 20:41:04.471982 EDT | AverageY                   30.808
2017-06-10 20:41:04.472137 EDT | AverageAbsY                30.8224
2017-06-10 20:41:04.472292 EDT | AverageAbsQYDiff            0.733572
2017-06-10 20:41:04.472508 EDT | AverageAction               0.733918
2017-06-10 20:41:04.472684 EDT | PolicyRegParamNorm         52.0631
2017-06-10 20:41:04.472836 EDT | QFunRegParamNorm           61.7149
2017-06-10 20:41:04.472985 EDT | -----------------------  -----------
2017-06-10 20:41:04.473327 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #192 | Training started
2017-06-10 20:41:17.936170 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #192 | Training finished
2017-06-10 20:41:17.936448 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #192 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 20:41:17.936628 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #192 | Collecting samples for evaluation
2017-06-10 20:41:30.183931 EDT | -----------------------  -----------
2017-06-10 20:41:30.185179 EDT | Epoch                     192
2017-06-10 20:41:30.185647 EDT | Iteration                 192
2017-06-10 20:41:30.186003 EDT | AverageReturn            1036.39
2017-06-10 20:41:30.186435 EDT | StdReturn                 492.482
2017-06-10 20:41:30.186752 EDT | MaxReturn                2121.76
2017-06-10 20:41:30.187076 EDT | MinReturn                 401.509
2017-06-10 20:41:30.187412 EDT | AverageEsReturn           281.925
2017-06-10 20:41:30.187659 EDT | StdEsReturn               233.932
2017-06-10 20:41:30.187985 EDT | MaxEsReturn               641.251
2017-06-10 20:41:30.188309 EDT | MinEsReturn                24.4786
2017-06-10 20:41:30.188641 EDT | AverageDiscountedReturn   213.426
2017-06-10 20:41:30.194135 EDT | AverageQLoss                2.49983
2017-06-10 20:41:30.194423 EDT | AveragePolicySurr         -31.6195
2017-06-10 20:41:30.194727 EDT | AverageQ                   30.8948
2017-06-10 20:41:30.195575 EDT | AverageAbsQ                30.9222
2017-06-10 20:41:30.195863 EDT | AverageY                   30.8953
2017-06-10 20:41:30.196116 EDT | AverageAbsY                30.9066
2017-06-10 20:41:30.196302 EDT | AverageAbsQYDiff            0.703508
2017-06-10 20:41:30.196610 EDT | AverageAction               0.688501
2017-06-10 20:41:30.196928 EDT | PolicyRegParamNorm         52.1831
2017-06-10 20:41:30.197261 EDT | QFunRegParamNorm           61.9284
2017-06-10 20:41:30.197571 EDT | -----------------------  -----------
2017-06-10 20:41:30.198047 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #193 | Training started
2017-06-10 20:41:44.708796 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #193 | Training finished
2017-06-10 20:41:44.709779 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #193 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 20:41:44.710254 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #193 | Collecting samples for evaluation
2017-06-10 20:41:55.847502 EDT | -----------------------  -----------
2017-06-10 20:41:55.848023 EDT | Epoch                     193
2017-06-10 20:41:55.848266 EDT | Iteration                 193
2017-06-10 20:41:55.848451 EDT | AverageReturn             617.578
2017-06-10 20:41:55.848618 EDT | StdReturn                 470.125
2017-06-10 20:41:55.848813 EDT | MaxReturn                2709.88
2017-06-10 20:41:55.848980 EDT | MinReturn                 383.392
2017-06-10 20:41:55.849155 EDT | AverageEsReturn           387.941
2017-06-10 20:41:55.849315 EDT | StdEsReturn               276.731
2017-06-10 20:41:55.849586 EDT | MaxEsReturn               731.464
2017-06-10 20:41:55.849889 EDT | MinEsReturn                12.3164
2017-06-10 20:41:55.850725 EDT | AverageDiscountedReturn   192.46
2017-06-10 20:41:55.850925 EDT | AverageQLoss                2.85146
2017-06-10 20:41:55.851113 EDT | AveragePolicySurr         -31.7303
2017-06-10 20:41:55.851295 EDT | AverageQ                   30.988
2017-06-10 20:41:55.851556 EDT | AverageAbsQ                31.017
2017-06-10 20:41:55.851732 EDT | AverageY                   30.992
2017-06-10 20:41:55.851922 EDT | AverageAbsY                31.0039
2017-06-10 20:41:55.852099 EDT | AverageAbsQYDiff            0.716546
2017-06-10 20:41:55.852256 EDT | AverageAction               0.707188
2017-06-10 20:41:55.852419 EDT | PolicyRegParamNorm         52.2789
2017-06-10 20:41:55.852702 EDT | QFunRegParamNorm           62.0641
2017-06-10 20:41:55.852906 EDT | -----------------------  -----------
2017-06-10 20:41:55.853468 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #194 | Training started
2017-06-10 20:42:10.713385 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #194 | Training finished
2017-06-10 20:42:10.714198 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #194 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 20:42:10.714425 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #194 | Collecting samples for evaluation
2017-06-10 20:42:22.607816 EDT | -----------------------  ----------
2017-06-10 20:42:22.608772 EDT | Epoch                     194
2017-06-10 20:42:22.609819 EDT | Iteration                 194
2017-06-10 20:42:22.610616 EDT | AverageReturn            1017.35
2017-06-10 20:42:22.611088 EDT | StdReturn                 488.454
2017-06-10 20:42:22.611923 EDT | MaxReturn                2665.4
2017-06-10 20:42:22.612297 EDT | MinReturn                 482.782
2017-06-10 20:42:22.612665 EDT | AverageEsReturn           272.514
2017-06-10 20:42:22.613605 EDT | StdEsReturn               282.434
2017-06-10 20:42:22.613965 EDT | MaxEsReturn               695.897
2017-06-10 20:42:22.614194 EDT | MinEsReturn                18.3381
2017-06-10 20:42:22.614374 EDT | AverageDiscountedReturn   221.128
2017-06-10 20:42:22.614731 EDT | AverageQLoss                2.64216
2017-06-10 20:42:22.615054 EDT | AveragePolicySurr         -31.828
2017-06-10 20:42:22.615516 EDT | AverageQ                   31.1071
2017-06-10 20:42:22.615983 EDT | AverageAbsQ                31.1378
2017-06-10 20:42:22.616460 EDT | AverageY                   31.1095
2017-06-10 20:42:22.616907 EDT | AverageAbsY                31.1224
2017-06-10 20:42:22.617389 EDT | AverageAbsQYDiff            0.70994
2017-06-10 20:42:22.617826 EDT | AverageAction               0.66815
2017-06-10 20:42:22.618233 EDT | PolicyRegParamNorm         52.4467
2017-06-10 20:42:22.618678 EDT | QFunRegParamNorm           62.2421
2017-06-10 20:42:22.619112 EDT | -----------------------  ----------
2017-06-10 20:42:22.619723 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #195 | Training started
2017-06-10 20:42:36.439069 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #195 | Training finished
2017-06-10 20:42:36.439964 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #195 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 20:42:36.440170 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #195 | Collecting samples for evaluation
2017-06-10 20:42:49.027334 EDT | -----------------------  -----------
2017-06-10 20:42:49.028277 EDT | Epoch                     195
2017-06-10 20:42:49.028672 EDT | Iteration                 195
2017-06-10 20:42:49.028893 EDT | AverageReturn            1113.85
2017-06-10 20:42:49.029080 EDT | StdReturn                 183.906
2017-06-10 20:42:49.029265 EDT | MaxReturn                1497.38
2017-06-10 20:42:49.029448 EDT | MinReturn                 551.99
2017-06-10 20:42:49.029630 EDT | AverageEsReturn           333.259
2017-06-10 20:42:49.030025 EDT | StdEsReturn               234.087
2017-06-10 20:42:49.030451 EDT | MaxEsReturn               676.573
2017-06-10 20:42:49.030947 EDT | MinEsReturn                85.4739
2017-06-10 20:42:49.031406 EDT | AverageDiscountedReturn   236.152
2017-06-10 20:42:49.031841 EDT | AverageQLoss                3.35493
2017-06-10 20:42:49.032248 EDT | AveragePolicySurr         -31.5859
2017-06-10 20:42:49.032603 EDT | AverageQ                   30.8577
2017-06-10 20:42:49.033002 EDT | AverageAbsQ                30.8949
2017-06-10 20:42:49.033433 EDT | AverageY                   30.864
2017-06-10 20:42:49.033784 EDT | AverageAbsY                30.877
2017-06-10 20:42:49.034069 EDT | AverageAbsQYDiff            0.764349
2017-06-10 20:42:49.034444 EDT | AverageAction               0.721953
2017-06-10 20:42:49.034872 EDT | PolicyRegParamNorm         52.5335
2017-06-10 20:42:49.035300 EDT | QFunRegParamNorm           62.3909
2017-06-10 20:42:49.035654 EDT | -----------------------  -----------
2017-06-10 20:42:49.036198 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #196 | Training started
2017-06-10 20:43:04.088770 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #196 | Training finished
2017-06-10 20:43:04.089787 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #196 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 20:43:04.090017 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #196 | Collecting samples for evaluation
2017-06-10 20:43:16.165778 EDT | -----------------------  -----------
2017-06-10 20:43:16.166040 EDT | Epoch                     196
2017-06-10 20:43:16.166299 EDT | Iteration                 196
2017-06-10 20:43:16.166511 EDT | AverageReturn            1125.46
2017-06-10 20:43:16.166735 EDT | StdReturn                 485.877
2017-06-10 20:43:16.168767 EDT | MaxReturn                2143.55
2017-06-10 20:43:16.168998 EDT | MinReturn                 407.38
2017-06-10 20:43:16.169458 EDT | AverageEsReturn           308.658
2017-06-10 20:43:16.171570 EDT | StdEsReturn               267.523
2017-06-10 20:43:16.171876 EDT | MaxEsReturn               718.539
2017-06-10 20:43:16.172064 EDT | MinEsReturn                36.8491
2017-06-10 20:43:16.172248 EDT | AverageDiscountedReturn   226.151
2017-06-10 20:43:16.172426 EDT | AverageQLoss                3.12424
2017-06-10 20:43:16.172592 EDT | AveragePolicySurr         -31.8107
2017-06-10 20:43:16.172769 EDT | AverageQ                   31.1261
2017-06-10 20:43:16.172943 EDT | AverageAbsQ                31.1659
2017-06-10 20:43:16.173124 EDT | AverageY                   31.1266
2017-06-10 20:43:16.173301 EDT | AverageAbsY                31.1459
2017-06-10 20:43:16.173459 EDT | AverageAbsQYDiff            0.749388
2017-06-10 20:43:16.173616 EDT | AverageAction               0.718521
2017-06-10 20:43:16.173788 EDT | PolicyRegParamNorm         52.5898
2017-06-10 20:43:16.173954 EDT | QFunRegParamNorm           62.5406
2017-06-10 20:43:16.174111 EDT | -----------------------  -----------
2017-06-10 20:43:16.174384 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #197 | Training started
2017-06-10 20:43:31.129719 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #197 | Training finished
2017-06-10 20:43:31.130542 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #197 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 20:43:31.130813 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #197 | Collecting samples for evaluation
2017-06-10 20:43:43.904300 EDT | -----------------------  -----------
2017-06-10 20:43:43.905179 EDT | Epoch                     197
2017-06-10 20:43:43.905371 EDT | Iteration                 197
2017-06-10 20:43:43.905533 EDT | AverageReturn             538.53
2017-06-10 20:43:43.905713 EDT | StdReturn                 369.846
2017-06-10 20:43:43.906044 EDT | MaxReturn                2083.4
2017-06-10 20:43:43.906373 EDT | MinReturn                 267.53
2017-06-10 20:43:43.906696 EDT | AverageEsReturn           268.23
2017-06-10 20:43:43.907007 EDT | StdEsReturn               210.795
2017-06-10 20:43:43.907333 EDT | MaxEsReturn               604.363
2017-06-10 20:43:43.907657 EDT | MinEsReturn                38.0369
2017-06-10 20:43:43.907983 EDT | AverageDiscountedReturn   186.261
2017-06-10 20:43:43.908315 EDT | AverageQLoss                2.94726
2017-06-10 20:43:43.908608 EDT | AveragePolicySurr         -31.8597
2017-06-10 20:43:43.908769 EDT | AverageQ                   31.1603
2017-06-10 20:43:43.908922 EDT | AverageAbsQ                31.1936
2017-06-10 20:43:43.909096 EDT | AverageY                   31.1628
2017-06-10 20:43:43.909252 EDT | AverageAbsY                31.175
2017-06-10 20:43:43.909402 EDT | AverageAbsQYDiff            0.732108
2017-06-10 20:43:43.909567 EDT | AverageAction               0.761595
2017-06-10 20:43:43.909798 EDT | PolicyRegParamNorm         52.692
2017-06-10 20:43:43.910003 EDT | QFunRegParamNorm           62.63
2017-06-10 20:43:43.910156 EDT | -----------------------  -----------
2017-06-10 20:43:43.910415 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #198 | Training started
2017-06-10 20:43:58.912719 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #198 | Training finished
2017-06-10 20:43:58.913742 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #198 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 20:43:58.914018 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #198 | Collecting samples for evaluation
2017-06-10 20:44:11.618536 EDT | -----------------------  ----------
2017-06-10 20:44:11.619292 EDT | Epoch                    198
2017-06-10 20:44:11.619662 EDT | Iteration                198
2017-06-10 20:44:11.619851 EDT | AverageReturn            429.501
2017-06-10 20:44:11.620107 EDT | StdReturn                 81.3421
2017-06-10 20:44:11.620349 EDT | MaxReturn                737.517
2017-06-10 20:44:11.620600 EDT | MinReturn                254.882
2017-06-10 20:44:11.620839 EDT | AverageEsReturn          218.141
2017-06-10 20:44:11.621086 EDT | StdEsReturn              198.429
2017-06-10 20:44:11.621365 EDT | MaxEsReturn              646.314
2017-06-10 20:44:11.622443 EDT | MinEsReturn               26.087
2017-06-10 20:44:11.622743 EDT | AverageDiscountedReturn  185.659
2017-06-10 20:44:11.623002 EDT | AverageQLoss               3.31969
2017-06-10 20:44:11.623190 EDT | AveragePolicySurr        -31.8573
2017-06-10 20:44:11.623383 EDT | AverageQ                  31.147
2017-06-10 20:44:11.623560 EDT | AverageAbsQ               31.1799
2017-06-10 20:44:11.623714 EDT | AverageY                  31.1502
2017-06-10 20:44:11.623864 EDT | AverageAbsY               31.1646
2017-06-10 20:44:11.624014 EDT | AverageAbsQYDiff           0.751286
2017-06-10 20:44:11.624261 EDT | AverageAction              0.71739
2017-06-10 20:44:11.624748 EDT | PolicyRegParamNorm        52.8257
2017-06-10 20:44:11.625254 EDT | QFunRegParamNorm          62.8298
2017-06-10 20:44:11.625439 EDT | -----------------------  ----------
2017-06-10 20:44:11.626417 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #199 | Training started
2017-06-10 20:44:25.527469 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #199 | Training finished
2017-06-10 20:44:25.528301 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #199 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 20:44:25.528515 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #199 | Collecting samples for evaluation
2017-06-10 20:44:38.782015 EDT | -----------------------  -----------
2017-06-10 20:44:38.783407 EDT | Epoch                     199
2017-06-10 20:44:38.783666 EDT | Iteration                 199
2017-06-10 20:44:38.783844 EDT | AverageReturn             711.737
2017-06-10 20:44:38.784046 EDT | StdReturn                 271.524
2017-06-10 20:44:38.784201 EDT | MaxReturn                1310.2
2017-06-10 20:44:38.784352 EDT | MinReturn                 386.586
2017-06-10 20:44:38.784502 EDT | AverageEsReturn           343.09
2017-06-10 20:44:38.784703 EDT | StdEsReturn               195.168
2017-06-10 20:44:38.784867 EDT | MaxEsReturn               607.145
2017-06-10 20:44:38.785019 EDT | MinEsReturn                21.2981
2017-06-10 20:44:38.785167 EDT | AverageDiscountedReturn   216.342
2017-06-10 20:44:38.785372 EDT | AverageQLoss                2.64414
2017-06-10 20:44:38.785523 EDT | AveragePolicySurr         -31.9167
2017-06-10 20:44:38.785672 EDT | AverageQ                   31.1932
2017-06-10 20:44:38.785856 EDT | AverageAbsQ                31.2261
2017-06-10 20:44:38.786056 EDT | AverageY                   31.1954
2017-06-10 20:44:38.786211 EDT | AverageAbsY                31.2083
2017-06-10 20:44:38.786361 EDT | AverageAbsQYDiff            0.724434
2017-06-10 20:44:38.786509 EDT | AverageAction               0.719444
2017-06-10 20:44:38.786657 EDT | PolicyRegParamNorm         52.9182
2017-06-10 20:44:38.786862 EDT | QFunRegParamNorm           62.965
2017-06-10 20:44:38.787181 EDT | -----------------------  -----------
2017-06-10 20:44:38.787587 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #200 | Training started
2017-06-10 20:44:53.245610 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #200 | Training finished
2017-06-10 20:44:53.246623 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #200 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 20:44:53.247000 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #200 | Collecting samples for evaluation
2017-06-10 20:45:06.937743 EDT | -----------------------  ----------
2017-06-10 20:45:06.940510 EDT | Epoch                    200
2017-06-10 20:45:06.940759 EDT | Iteration                200
2017-06-10 20:45:06.940956 EDT | AverageReturn            485.538
2017-06-10 20:45:06.941208 EDT | StdReturn                134.955
2017-06-10 20:45:06.941513 EDT | MaxReturn                995.992
2017-06-10 20:45:06.941782 EDT | MinReturn                308.222
2017-06-10 20:45:06.941984 EDT | AverageEsReturn          334.536
2017-06-10 20:45:06.942152 EDT | StdEsReturn              221.444
2017-06-10 20:45:06.942343 EDT | MaxEsReturn              701.205
2017-06-10 20:45:06.942527 EDT | MinEsReturn               23.4226
2017-06-10 20:45:06.942727 EDT | AverageDiscountedReturn  190.237
2017-06-10 20:45:06.942907 EDT | AverageQLoss               2.79038
2017-06-10 20:45:06.943086 EDT | AveragePolicySurr        -31.9785
2017-06-10 20:45:06.943273 EDT | AverageQ                  31.2647
2017-06-10 20:45:06.943533 EDT | AverageAbsQ               31.2955
2017-06-10 20:45:06.943710 EDT | AverageY                  31.2688
2017-06-10 20:45:06.943892 EDT | AverageAbsY               31.2769
2017-06-10 20:45:06.944070 EDT | AverageAbsQYDiff           0.726106
2017-06-10 20:45:06.944259 EDT | AverageAction              0.78792
2017-06-10 20:45:06.944438 EDT | PolicyRegParamNorm        53.0024
2017-06-10 20:45:06.944616 EDT | QFunRegParamNorm          63.0795
2017-06-10 20:45:06.944793 EDT | -----------------------  ----------
2017-06-10 20:45:06.945225 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #201 | Training started
2017-06-10 20:45:22.129132 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #201 | Training finished
2017-06-10 20:45:22.130256 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #201 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 20:45:22.130452 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #201 | Collecting samples for evaluation
2017-06-10 20:45:33.975737 EDT | -----------------------  ----------
2017-06-10 20:45:33.976728 EDT | Epoch                    201
2017-06-10 20:45:33.978034 EDT | Iteration                201
2017-06-10 20:45:33.978487 EDT | AverageReturn            469.795
2017-06-10 20:45:33.978814 EDT | StdReturn                 97.7632
2017-06-10 20:45:33.979122 EDT | MaxReturn                914.101
2017-06-10 20:45:33.979553 EDT | MinReturn                335.416
2017-06-10 20:45:33.980188 EDT | AverageEsReturn          306.896
2017-06-10 20:45:33.980521 EDT | StdEsReturn              230.115
2017-06-10 20:45:33.980990 EDT | MaxEsReturn              679.15
2017-06-10 20:45:33.981273 EDT | MinEsReturn               30.4768
2017-06-10 20:45:33.981558 EDT | AverageDiscountedReturn  194.632
2017-06-10 20:45:33.981895 EDT | AverageQLoss               3.00517
2017-06-10 20:45:33.982204 EDT | AveragePolicySurr        -32.0599
2017-06-10 20:45:33.982490 EDT | AverageQ                  31.3356
2017-06-10 20:45:33.982783 EDT | AverageAbsQ               31.3615
2017-06-10 20:45:33.985434 EDT | AverageY                  31.3376
2017-06-10 20:45:33.985653 EDT | AverageAbsY               31.3471
2017-06-10 20:45:33.985885 EDT | AverageAbsQYDiff           0.753133
2017-06-10 20:45:33.986049 EDT | AverageAction              0.851253
2017-06-10 20:45:33.986302 EDT | PolicyRegParamNorm        53.0537
2017-06-10 20:45:33.986459 EDT | QFunRegParamNorm          63.2451
2017-06-10 20:45:33.986700 EDT | -----------------------  ----------
2017-06-10 20:45:33.987027 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #202 | Training started
2017-06-10 20:45:49.420349 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #202 | Training finished
2017-06-10 20:45:49.421283 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #202 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 20:45:49.421665 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #202 | Collecting samples for evaluation
2017-06-10 20:46:01.493748 EDT | -----------------------  ----------
2017-06-10 20:46:01.494992 EDT | Epoch                    202
2017-06-10 20:46:01.495185 EDT | Iteration                202
2017-06-10 20:46:01.495345 EDT | AverageReturn            420.753
2017-06-10 20:46:01.495538 EDT | StdReturn                 46.1498
2017-06-10 20:46:01.495858 EDT | MaxReturn                585.528
2017-06-10 20:46:01.496187 EDT | MinReturn                374.321
2017-06-10 20:46:01.496509 EDT | AverageEsReturn          326.715
2017-06-10 20:46:01.496847 EDT | StdEsReturn              182.908
2017-06-10 20:46:01.497176 EDT | MaxEsReturn              554.325
2017-06-10 20:46:01.497500 EDT | MinEsReturn              110.57
2017-06-10 20:46:01.497909 EDT | AverageDiscountedReturn  188.994
2017-06-10 20:46:01.498243 EDT | AverageQLoss               3.10588
2017-06-10 20:46:01.499421 EDT | AveragePolicySurr        -32.0308
2017-06-10 20:46:01.499786 EDT | AverageQ                  31.3374
2017-06-10 20:46:01.500083 EDT | AverageAbsQ               31.3652
2017-06-10 20:46:01.500407 EDT | AverageY                  31.3394
2017-06-10 20:46:01.500863 EDT | AverageAbsY               31.3496
2017-06-10 20:46:01.501197 EDT | AverageAbsQYDiff           0.727761
2017-06-10 20:46:01.501522 EDT | AverageAction              0.869218
2017-06-10 20:46:01.501857 EDT | PolicyRegParamNorm        53.1945
2017-06-10 20:46:01.502324 EDT | QFunRegParamNorm          63.3507
2017-06-10 20:46:01.502686 EDT | -----------------------  ----------
2017-06-10 20:46:01.503258 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #203 | Training started
2017-06-10 20:46:16.053045 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #203 | Training finished
2017-06-10 20:46:16.053847 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #203 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 20:46:16.054226 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #203 | Collecting samples for evaluation
2017-06-10 20:46:28.739596 EDT | -----------------------  -----------
2017-06-10 20:46:28.740509 EDT | Epoch                     203
2017-06-10 20:46:28.740879 EDT | Iteration                 203
2017-06-10 20:46:28.741230 EDT | AverageReturn             661.524
2017-06-10 20:46:28.741688 EDT | StdReturn                 322.471
2017-06-10 20:46:28.742153 EDT | MaxReturn                2366.78
2017-06-10 20:46:28.742502 EDT | MinReturn                 422.489
2017-06-10 20:46:28.742852 EDT | AverageEsReturn           313.527
2017-06-10 20:46:28.743197 EDT | StdEsReturn               179.504
2017-06-10 20:46:28.743536 EDT | MaxEsReturn               616.107
2017-06-10 20:46:28.743876 EDT | MinEsReturn                84.1407
2017-06-10 20:46:28.744326 EDT | AverageDiscountedReturn   205.777
2017-06-10 20:46:28.744738 EDT | AverageQLoss                2.8804
2017-06-10 20:46:28.745088 EDT | AveragePolicySurr         -32.1547
2017-06-10 20:46:28.745526 EDT | AverageQ                   31.4321
2017-06-10 20:46:28.745959 EDT | AverageAbsQ                31.4627
2017-06-10 20:46:28.748380 EDT | AverageY                   31.4373
2017-06-10 20:46:28.748839 EDT | AverageAbsY                31.4453
2017-06-10 20:46:28.749193 EDT | AverageAbsQYDiff            0.745597
2017-06-10 20:46:28.749555 EDT | AverageAction               0.804574
2017-06-10 20:46:28.749914 EDT | PolicyRegParamNorm         53.3105
2017-06-10 20:46:28.750362 EDT | QFunRegParamNorm           63.4854
2017-06-10 20:46:28.750823 EDT | -----------------------  -----------
2017-06-10 20:46:28.754573 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #204 | Training started
2017-06-10 20:46:43.487460 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #204 | Training finished
2017-06-10 20:46:43.488480 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #204 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 20:46:43.488868 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #204 | Collecting samples for evaluation
2017-06-10 20:46:57.339977 EDT | -----------------------  -----------
2017-06-10 20:46:57.340465 EDT | Epoch                     204
2017-06-10 20:46:57.340829 EDT | Iteration                 204
2017-06-10 20:46:57.341193 EDT | AverageReturn            1044.65
2017-06-10 20:46:57.341556 EDT | StdReturn                 447.88
2017-06-10 20:46:57.341922 EDT | MaxReturn                2713.14
2017-06-10 20:46:57.342278 EDT | MinReturn                 392.153
2017-06-10 20:46:57.342637 EDT | AverageEsReturn           373.478
2017-06-10 20:46:57.342993 EDT | StdEsReturn               152.191
2017-06-10 20:46:57.343349 EDT | MaxEsReturn               525.14
2017-06-10 20:46:57.343839 EDT | MinEsReturn                30.6649
2017-06-10 20:46:57.344203 EDT | AverageDiscountedReturn   212.506
2017-06-10 20:46:57.344630 EDT | AverageQLoss                2.81449
2017-06-10 20:46:57.344971 EDT | AveragePolicySurr         -32.2297
2017-06-10 20:46:57.345420 EDT | AverageQ                   31.5126
2017-06-10 20:46:57.345860 EDT | AverageAbsQ                31.5403
2017-06-10 20:46:57.346199 EDT | AverageY                   31.5125
2017-06-10 20:46:57.346530 EDT | AverageAbsY                31.5185
2017-06-10 20:46:57.346869 EDT | AverageAbsQYDiff            0.729941
2017-06-10 20:46:57.347259 EDT | AverageAction               0.718122
2017-06-10 20:46:57.347599 EDT | PolicyRegParamNorm         53.3634
2017-06-10 20:46:57.347912 EDT | QFunRegParamNorm           63.6214
2017-06-10 20:46:57.348164 EDT | -----------------------  -----------
2017-06-10 20:46:57.348843 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #205 | Training started
2017-06-10 20:47:13.297141 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #205 | Training finished
2017-06-10 20:47:13.299613 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #205 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 20:47:13.300033 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #205 | Collecting samples for evaluation
2017-06-10 20:47:25.646359 EDT | -----------------------  -----------
2017-06-10 20:47:25.646757 EDT | Epoch                     205
2017-06-10 20:47:25.646993 EDT | Iteration                 205
2017-06-10 20:47:25.647163 EDT | AverageReturn             877.324
2017-06-10 20:47:25.647389 EDT | StdReturn                 239.157
2017-06-10 20:47:25.647554 EDT | MaxReturn                1282.3
2017-06-10 20:47:25.647719 EDT | MinReturn                 398.193
2017-06-10 20:47:25.647911 EDT | AverageEsReturn           318.953
2017-06-10 20:47:25.648111 EDT | StdEsReturn               215.841
2017-06-10 20:47:25.648334 EDT | MaxEsReturn               598.603
2017-06-10 20:47:25.648487 EDT | MinEsReturn                31.0145
2017-06-10 20:47:25.648645 EDT | AverageDiscountedReturn   224.88
2017-06-10 20:47:25.648868 EDT | AverageQLoss                3.18238
2017-06-10 20:47:25.649123 EDT | AveragePolicySurr         -32.2338
2017-06-10 20:47:25.649504 EDT | AverageQ                   31.524
2017-06-10 20:47:25.649769 EDT | AverageAbsQ                31.5504
2017-06-10 20:47:25.649934 EDT | AverageY                   31.5286
2017-06-10 20:47:25.650101 EDT | AverageAbsY                31.5372
2017-06-10 20:47:25.650437 EDT | AverageAbsQYDiff            0.75511
2017-06-10 20:47:25.650613 EDT | AverageAction               0.770989
2017-06-10 20:47:25.650850 EDT | PolicyRegParamNorm         53.4806
2017-06-10 20:47:25.651160 EDT | QFunRegParamNorm           63.7635
2017-06-10 20:47:25.653841 EDT | -----------------------  -----------
2017-06-10 20:47:25.654700 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #206 | Training started
2017-06-10 20:47:41.516535 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #206 | Training finished
2017-06-10 20:47:41.517595 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #206 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 20:47:41.517921 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #206 | Collecting samples for evaluation
2017-06-10 20:47:54.187183 EDT | -----------------------  -----------
2017-06-10 20:47:54.188084 EDT | Epoch                     206
2017-06-10 20:47:54.188454 EDT | Iteration                 206
2017-06-10 20:47:54.189536 EDT | AverageReturn             989.416
2017-06-10 20:47:54.189982 EDT | StdReturn                 284.693
2017-06-10 20:47:54.190376 EDT | MaxReturn                1546.01
2017-06-10 20:47:54.190772 EDT | MinReturn                 315.752
2017-06-10 20:47:54.191105 EDT | AverageEsReturn           273.79
2017-06-10 20:47:54.191540 EDT | StdEsReturn               121.901
2017-06-10 20:47:54.191962 EDT | MaxEsReturn               523.95
2017-06-10 20:47:54.192429 EDT | MinEsReturn               164.843
2017-06-10 20:47:54.192785 EDT | AverageDiscountedReturn   233.931
2017-06-10 20:47:54.193110 EDT | AverageQLoss                3.56818
2017-06-10 20:47:54.193507 EDT | AveragePolicySurr         -32.2382
2017-06-10 20:47:54.193862 EDT | AverageQ                   31.5246
2017-06-10 20:47:54.194296 EDT | AverageAbsQ                31.5556
2017-06-10 20:47:54.194629 EDT | AverageY                   31.5266
2017-06-10 20:47:54.195038 EDT | AverageAbsY                31.5373
2017-06-10 20:47:54.195420 EDT | AverageAbsQYDiff            0.773638
2017-06-10 20:47:54.195743 EDT | AverageAction               0.713283
2017-06-10 20:47:54.196187 EDT | PolicyRegParamNorm         53.576
2017-06-10 20:47:54.196521 EDT | QFunRegParamNorm           63.9515
2017-06-10 20:47:54.196863 EDT | -----------------------  -----------
2017-06-10 20:47:54.197347 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #207 | Training started
2017-06-10 20:48:08.938513 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #207 | Training finished
2017-06-10 20:48:08.939322 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #207 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 20:48:08.939569 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #207 | Collecting samples for evaluation
2017-06-10 20:48:20.257712 EDT | -----------------------  -----------
2017-06-10 20:48:20.258438 EDT | Epoch                     207
2017-06-10 20:48:20.258765 EDT | Iteration                 207
2017-06-10 20:48:20.259110 EDT | AverageReturn             488.232
2017-06-10 20:48:20.259337 EDT | StdReturn                 392.952
2017-06-10 20:48:20.259583 EDT | MaxReturn                1884.96
2017-06-10 20:48:20.259823 EDT | MinReturn                 179.22
2017-06-10 20:48:20.260008 EDT | AverageEsReturn           365.695
2017-06-10 20:48:20.260307 EDT | StdEsReturn               301.917
2017-06-10 20:48:20.260588 EDT | MaxEsReturn               973.418
2017-06-10 20:48:20.261206 EDT | MinEsReturn                20.7625
2017-06-10 20:48:20.261533 EDT | AverageDiscountedReturn   145.581
2017-06-10 20:48:20.261881 EDT | AverageQLoss                3.47687
2017-06-10 20:48:20.262221 EDT | AveragePolicySurr         -32.2475
2017-06-10 20:48:20.262580 EDT | AverageQ                   31.541
2017-06-10 20:48:20.262780 EDT | AverageAbsQ                31.5675
2017-06-10 20:48:20.263121 EDT | AverageY                   31.5435
2017-06-10 20:48:20.263384 EDT | AverageAbsY                31.5522
2017-06-10 20:48:20.263565 EDT | AverageAbsQYDiff            0.779063
2017-06-10 20:48:20.263912 EDT | AverageAction               0.699117
2017-06-10 20:48:20.264085 EDT | PolicyRegParamNorm         53.6634
2017-06-10 20:48:20.264298 EDT | QFunRegParamNorm           64.1052
2017-06-10 20:48:20.264541 EDT | -----------------------  -----------
2017-06-10 20:48:20.264831 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #208 | Training started
2017-06-10 20:48:34.888058 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #208 | Training finished
2017-06-10 20:48:34.888829 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #208 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 20:48:34.889242 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #208 | Collecting samples for evaluation
2017-06-10 20:48:48.182023 EDT | -----------------------  -----------
2017-06-10 20:48:48.182893 EDT | Epoch                     208
2017-06-10 20:48:48.183254 EDT | Iteration                 208
2017-06-10 20:48:48.183651 EDT | AverageReturn             603.329
2017-06-10 20:48:48.183870 EDT | StdReturn                 274.265
2017-06-10 20:48:48.184068 EDT | MaxReturn                1240.11
2017-06-10 20:48:48.184266 EDT | MinReturn                 265.201
2017-06-10 20:48:48.184882 EDT | AverageEsReturn           261.369
2017-06-10 20:48:48.185081 EDT | StdEsReturn               191.818
2017-06-10 20:48:48.185281 EDT | MaxEsReturn               588.55
2017-06-10 20:48:48.185532 EDT | MinEsReturn                37.4419
2017-06-10 20:48:48.185836 EDT | AverageDiscountedReturn   202.577
2017-06-10 20:48:48.186259 EDT | AverageQLoss                2.89188
2017-06-10 20:48:48.186662 EDT | AveragePolicySurr         -32.3621
2017-06-10 20:48:48.186846 EDT | AverageQ                   31.6571
2017-06-10 20:48:48.187045 EDT | AverageAbsQ                31.6843
2017-06-10 20:48:48.187361 EDT | AverageY                   31.6613
2017-06-10 20:48:48.187663 EDT | AverageAbsY                31.6676
2017-06-10 20:48:48.187961 EDT | AverageAbsQYDiff            0.726676
2017-06-10 20:48:48.188337 EDT | AverageAction               0.773915
2017-06-10 20:48:48.189914 EDT | PolicyRegParamNorm         53.7588
2017-06-10 20:48:48.190248 EDT | QFunRegParamNorm           64.1924
2017-06-10 20:48:48.190446 EDT | -----------------------  -----------
2017-06-10 20:48:48.190786 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #209 | Training started
2017-06-10 20:49:02.564314 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #209 | Training finished
2017-06-10 20:49:02.565093 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #209 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 20:49:02.565292 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #209 | Collecting samples for evaluation
2017-06-10 20:49:14.559133 EDT | -----------------------  -----------
2017-06-10 20:49:14.560124 EDT | Epoch                     209
2017-06-10 20:49:14.560424 EDT | Iteration                 209
2017-06-10 20:49:14.560619 EDT | AverageReturn             515.873
2017-06-10 20:49:14.560807 EDT | StdReturn                 142.291
2017-06-10 20:49:14.560990 EDT | MaxReturn                1119.9
2017-06-10 20:49:14.561172 EDT | MinReturn                 377.52
2017-06-10 20:49:14.561353 EDT | AverageEsReturn           263.813
2017-06-10 20:49:14.561533 EDT | StdEsReturn               205.963
2017-06-10 20:49:14.561730 EDT | MaxEsReturn               673.591
2017-06-10 20:49:14.562000 EDT | MinEsReturn                19.951
2017-06-10 20:49:14.562184 EDT | AverageDiscountedReturn   201.304
2017-06-10 20:49:14.562366 EDT | AverageQLoss                2.80173
2017-06-10 20:49:14.562546 EDT | AveragePolicySurr         -32.3896
2017-06-10 20:49:14.562726 EDT | AverageQ                   31.7037
2017-06-10 20:49:14.562906 EDT | AverageAbsQ                31.7314
2017-06-10 20:49:14.563937 EDT | AverageY                   31.7049
2017-06-10 20:49:14.565622 EDT | AverageAbsY                31.7132
2017-06-10 20:49:14.566481 EDT | AverageAbsQYDiff            0.73926
2017-06-10 20:49:14.566756 EDT | AverageAction               0.761578
2017-06-10 20:49:14.566945 EDT | PolicyRegParamNorm         53.8695
2017-06-10 20:49:14.567157 EDT | QFunRegParamNorm           64.4127
2017-06-10 20:49:14.567386 EDT | -----------------------  -----------
2017-06-10 20:49:14.567695 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #210 | Training started
2017-06-10 20:49:30.260318 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #210 | Training finished
2017-06-10 20:49:30.261065 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #210 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 20:49:30.261292 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #210 | Collecting samples for evaluation
2017-06-10 20:49:41.645022 EDT | -----------------------  -----------
2017-06-10 20:49:41.645508 EDT | Epoch                     210
2017-06-10 20:49:41.645914 EDT | Iteration                 210
2017-06-10 20:49:41.646245 EDT | AverageReturn             642.999
2017-06-10 20:49:41.646580 EDT | StdReturn                 344.909
2017-06-10 20:49:41.646949 EDT | MaxReturn                1818.67
2017-06-10 20:49:41.647321 EDT | MinReturn                 337.334
2017-06-10 20:49:41.647631 EDT | AverageEsReturn           231.507
2017-06-10 20:49:41.647979 EDT | StdEsReturn               187.098
2017-06-10 20:49:41.648515 EDT | MaxEsReturn               561.108
2017-06-10 20:49:41.648854 EDT | MinEsReturn                13.2666
2017-06-10 20:49:41.649251 EDT | AverageDiscountedReturn   205.222
2017-06-10 20:49:41.649627 EDT | AverageQLoss                3.00377
2017-06-10 20:49:41.650005 EDT | AveragePolicySurr         -32.5149
2017-06-10 20:49:41.650312 EDT | AverageQ                   31.814
2017-06-10 20:49:41.650662 EDT | AverageAbsQ                31.8374
2017-06-10 20:49:41.651181 EDT | AverageY                   31.819
2017-06-10 20:49:41.651535 EDT | AverageAbsY                31.828
2017-06-10 20:49:41.651857 EDT | AverageAbsQYDiff            0.742476
2017-06-10 20:49:41.652233 EDT | AverageAction               0.772442
2017-06-10 20:49:41.652612 EDT | PolicyRegParamNorm         53.9601
2017-06-10 20:49:41.653031 EDT | QFunRegParamNorm           64.6056
2017-06-10 20:49:41.654724 EDT | -----------------------  -----------
2017-06-10 20:49:41.655788 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #211 | Training started
2017-06-10 20:49:57.327757 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #211 | Training finished
2017-06-10 20:49:57.328546 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #211 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 20:49:57.328902 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #211 | Collecting samples for evaluation
2017-06-10 20:50:09.324236 EDT | -----------------------  -----------
2017-06-10 20:50:09.325040 EDT | Epoch                     211
2017-06-10 20:50:09.325224 EDT | Iteration                 211
2017-06-10 20:50:09.325383 EDT | AverageReturn             792.047
2017-06-10 20:50:09.325537 EDT | StdReturn                 387.668
2017-06-10 20:50:09.325689 EDT | MaxReturn                1956.28
2017-06-10 20:50:09.325861 EDT | MinReturn                 287.348
2017-06-10 20:50:09.326208 EDT | AverageEsReturn           368.377
2017-06-10 20:50:09.326380 EDT | StdEsReturn               235.513
2017-06-10 20:50:09.326536 EDT | MaxEsReturn               867.747
2017-06-10 20:50:09.326970 EDT | MinEsReturn                19.4791
2017-06-10 20:50:09.327164 EDT | AverageDiscountedReturn   208.183
2017-06-10 20:50:09.327350 EDT | AverageQLoss                3.31761
2017-06-10 20:50:09.327717 EDT | AveragePolicySurr         -32.5104
2017-06-10 20:50:09.328063 EDT | AverageQ                   31.8103
2017-06-10 20:50:09.328481 EDT | AverageAbsQ                31.8404
2017-06-10 20:50:09.328636 EDT | AverageY                   31.8118
2017-06-10 20:50:09.328798 EDT | AverageAbsY                31.8203
2017-06-10 20:50:09.329019 EDT | AverageAbsQYDiff            0.768513
2017-06-10 20:50:09.329172 EDT | AverageAction               0.749915
2017-06-10 20:50:09.329323 EDT | PolicyRegParamNorm         54.0582
2017-06-10 20:50:09.329471 EDT | QFunRegParamNorm           64.7133
2017-06-10 20:50:09.329621 EDT | -----------------------  -----------
2017-06-10 20:50:09.329984 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #212 | Training started
2017-06-10 20:50:22.926170 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #212 | Training finished
2017-06-10 20:50:22.926949 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #212 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 20:50:22.927174 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #212 | Collecting samples for evaluation
2017-06-10 20:50:36.058178 EDT | -----------------------  -----------
2017-06-10 20:50:36.059198 EDT | Epoch                     212
2017-06-10 20:50:36.059642 EDT | Iteration                 212
2017-06-10 20:50:36.059863 EDT | AverageReturn             595.03
2017-06-10 20:50:36.060095 EDT | StdReturn                 215.51
2017-06-10 20:50:36.060280 EDT | MaxReturn                1210.67
2017-06-10 20:50:36.060462 EDT | MinReturn                 236.695
2017-06-10 20:50:36.060651 EDT | AverageEsReturn           238.98
2017-06-10 20:50:36.060876 EDT | StdEsReturn               199.359
2017-06-10 20:50:36.061058 EDT | MaxEsReturn               516.211
2017-06-10 20:50:36.061237 EDT | MinEsReturn                19.2458
2017-06-10 20:50:36.061416 EDT | AverageDiscountedReturn   199.193
2017-06-10 20:50:36.061598 EDT | AverageQLoss                2.97476
2017-06-10 20:50:36.061802 EDT | AveragePolicySurr         -32.5771
2017-06-10 20:50:36.061982 EDT | AverageQ                   31.8616
2017-06-10 20:50:36.062161 EDT | AverageAbsQ                31.8841
2017-06-10 20:50:36.062340 EDT | AverageY                   31.867
2017-06-10 20:50:36.062529 EDT | AverageAbsY                31.8749
2017-06-10 20:50:36.062713 EDT | AverageAbsQYDiff            0.741845
2017-06-10 20:50:36.062892 EDT | AverageAction               0.737688
2017-06-10 20:50:36.063071 EDT | PolicyRegParamNorm         54.139
2017-06-10 20:50:36.063249 EDT | QFunRegParamNorm           64.904
2017-06-10 20:50:36.063427 EDT | -----------------------  -----------
2017-06-10 20:50:36.063801 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #213 | Training started
2017-06-10 20:50:51.031351 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #213 | Training finished
2017-06-10 20:50:51.045808 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #213 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 20:50:51.046210 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #213 | Collecting samples for evaluation
2017-06-10 20:51:03.185147 EDT | -----------------------  -----------
2017-06-10 20:51:03.185791 EDT | Epoch                     213
2017-06-10 20:51:03.186139 EDT | Iteration                 213
2017-06-10 20:51:03.186580 EDT | AverageReturn            1294.5
2017-06-10 20:51:03.186888 EDT | StdReturn                 834.564
2017-06-10 20:51:03.187430 EDT | MaxReturn                2715.13
2017-06-10 20:51:03.187786 EDT | MinReturn                 269.061
2017-06-10 20:51:03.188109 EDT | AverageEsReturn           412.356
2017-06-10 20:51:03.188438 EDT | StdEsReturn               213.705
2017-06-10 20:51:03.188775 EDT | MaxEsReturn               705.152
2017-06-10 20:51:03.189369 EDT | MinEsReturn               137.414
2017-06-10 20:51:03.189784 EDT | AverageDiscountedReturn   192.847
2017-06-10 20:51:03.190122 EDT | AverageQLoss                3.01142
2017-06-10 20:51:03.190442 EDT | AveragePolicySurr         -32.5571
2017-06-10 20:51:03.190767 EDT | AverageQ                   31.8429
2017-06-10 20:51:03.191214 EDT | AverageAbsQ                31.8667
2017-06-10 20:51:03.191555 EDT | AverageY                   31.8436
2017-06-10 20:51:03.191882 EDT | AverageAbsY                31.8509
2017-06-10 20:51:03.192806 EDT | AverageAbsQYDiff            0.741277
2017-06-10 20:51:03.193149 EDT | AverageAction               0.642639
2017-06-10 20:51:03.193491 EDT | PolicyRegParamNorm         54.1812
2017-06-10 20:51:03.194077 EDT | QFunRegParamNorm           64.9952
2017-06-10 20:51:03.194426 EDT | -----------------------  -----------
2017-06-10 20:51:03.194935 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #214 | Training started
2017-06-10 20:51:18.859820 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #214 | Training finished
2017-06-10 20:51:18.860634 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #214 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 20:51:18.860986 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #214 | Collecting samples for evaluation
2017-06-10 20:51:30.960800 EDT | -----------------------  -----------
2017-06-10 20:51:30.962162 EDT | Epoch                     214
2017-06-10 20:51:30.962742 EDT | Iteration                 214
2017-06-10 20:51:30.963198 EDT | AverageReturn             828.31
2017-06-10 20:51:30.963656 EDT | StdReturn                 642.67
2017-06-10 20:51:30.964205 EDT | MaxReturn                2850.63
2017-06-10 20:51:30.964650 EDT | MinReturn                 255.247
2017-06-10 20:51:30.965120 EDT | AverageEsReturn           384.48
2017-06-10 20:51:30.965759 EDT | StdEsReturn               247.994
2017-06-10 20:51:30.966206 EDT | MaxEsReturn               745.036
2017-06-10 20:51:30.966646 EDT | MinEsReturn                13.4851
2017-06-10 20:51:30.967133 EDT | AverageDiscountedReturn   189.408
2017-06-10 20:51:30.967478 EDT | AverageQLoss                3.13839
2017-06-10 20:51:30.967827 EDT | AveragePolicySurr         -32.5577
2017-06-10 20:51:30.968258 EDT | AverageQ                   31.8408
2017-06-10 20:51:30.968604 EDT | AverageAbsQ                31.8663
2017-06-10 20:51:30.968962 EDT | AverageY                   31.8444
2017-06-10 20:51:30.969305 EDT | AverageAbsY                31.8514
2017-06-10 20:51:30.969650 EDT | AverageAbsQYDiff            0.770358
2017-06-10 20:51:30.970035 EDT | AverageAction               0.689741
2017-06-10 20:51:30.970427 EDT | PolicyRegParamNorm         54.2771
2017-06-10 20:51:30.970868 EDT | QFunRegParamNorm           65.1379
2017-06-10 20:51:30.971311 EDT | -----------------------  -----------
2017-06-10 20:51:30.971927 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #215 | Training started
2017-06-10 20:51:45.813767 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #215 | Training finished
2017-06-10 20:51:45.814929 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #215 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 20:51:45.815350 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #215 | Collecting samples for evaluation
2017-06-10 20:51:59.113908 EDT | -----------------------  -----------
2017-06-10 20:51:59.114896 EDT | Epoch                     215
2017-06-10 20:51:59.115236 EDT | Iteration                 215
2017-06-10 20:51:59.115623 EDT | AverageReturn            1072.79
2017-06-10 20:51:59.116066 EDT | StdReturn                 463.373
2017-06-10 20:51:59.116373 EDT | MaxReturn                2283.39
2017-06-10 20:51:59.117002 EDT | MinReturn                 298.873
2017-06-10 20:51:59.117426 EDT | AverageEsReturn           334.406
2017-06-10 20:51:59.117777 EDT | StdEsReturn               184.538
2017-06-10 20:51:59.118188 EDT | MaxEsReturn               601.239
2017-06-10 20:51:59.118472 EDT | MinEsReturn                47.77
2017-06-10 20:51:59.118807 EDT | AverageDiscountedReturn   220.765
2017-06-10 20:51:59.119313 EDT | AverageQLoss                2.51819
2017-06-10 20:51:59.119643 EDT | AveragePolicySurr         -32.778
2017-06-10 20:51:59.119968 EDT | AverageQ                   32.0541
2017-06-10 20:51:59.120310 EDT | AverageAbsQ                32.0798
2017-06-10 20:51:59.120615 EDT | AverageY                   32.0579
2017-06-10 20:51:59.120936 EDT | AverageAbsY                32.0661
2017-06-10 20:51:59.121575 EDT | AverageAbsQYDiff            0.725474
2017-06-10 20:51:59.121933 EDT | AverageAction               0.689133
2017-06-10 20:51:59.126628 EDT | PolicyRegParamNorm         54.3615
2017-06-10 20:51:59.127150 EDT | QFunRegParamNorm           65.2781
2017-06-10 20:51:59.127498 EDT | -----------------------  -----------
2017-06-10 20:51:59.127989 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #216 | Training started
2017-06-10 20:52:13.331618 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #216 | Training finished
2017-06-10 20:52:13.332062 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #216 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 20:52:13.332397 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #216 | Collecting samples for evaluation
2017-06-10 20:52:25.919963 EDT | -----------------------  ----------
2017-06-10 20:52:25.921108 EDT | Epoch                    216
2017-06-10 20:52:25.921526 EDT | Iteration                216
2017-06-10 20:52:25.925615 EDT | AverageReturn            452.722
2017-06-10 20:52:25.926016 EDT | StdReturn                 95.2371
2017-06-10 20:52:25.926436 EDT | MaxReturn                654.794
2017-06-10 20:52:25.926826 EDT | MinReturn                366.756
2017-06-10 20:52:25.927210 EDT | AverageEsReturn          278.328
2017-06-10 20:52:25.927607 EDT | StdEsReturn              262.915
2017-06-10 20:52:25.927992 EDT | MaxEsReturn              669.637
2017-06-10 20:52:25.928374 EDT | MinEsReturn                5.7001
2017-06-10 20:52:25.928757 EDT | AverageDiscountedReturn  194.492
2017-06-10 20:52:25.929136 EDT | AverageQLoss               3.21304
2017-06-10 20:52:25.929517 EDT | AveragePolicySurr        -32.6943
2017-06-10 20:52:25.929909 EDT | AverageQ                  31.9912
2017-06-10 20:52:25.930298 EDT | AverageAbsQ               32.0158
2017-06-10 20:52:25.930694 EDT | AverageY                  31.9948
2017-06-10 20:52:25.931067 EDT | AverageAbsY               32.0009
2017-06-10 20:52:25.931445 EDT | AverageAbsQYDiff           0.762804
2017-06-10 20:52:25.931817 EDT | AverageAction              0.71523
2017-06-10 20:52:25.932175 EDT | PolicyRegParamNorm        54.4454
2017-06-10 20:52:25.932599 EDT | QFunRegParamNorm          65.3973
2017-06-10 20:52:25.932980 EDT | -----------------------  ----------
2017-06-10 20:52:25.933533 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #217 | Training started
2017-06-10 20:52:40.184402 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #217 | Training finished
2017-06-10 20:52:40.186191 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #217 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 20:52:40.186537 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #217 | Collecting samples for evaluation
2017-06-10 20:52:53.626963 EDT | -----------------------  -----------
2017-06-10 20:52:53.628284 EDT | Epoch                     217
2017-06-10 20:52:53.628702 EDT | Iteration                 217
2017-06-10 20:52:53.628873 EDT | AverageReturn             937.865
2017-06-10 20:52:53.629031 EDT | StdReturn                 351.001
2017-06-10 20:52:53.629187 EDT | MaxReturn                1731.99
2017-06-10 20:52:53.629355 EDT | MinReturn                 263.358
2017-06-10 20:52:53.629519 EDT | AverageEsReturn           132.438
2017-06-10 20:52:53.629823 EDT | StdEsReturn               150.224
2017-06-10 20:52:53.630007 EDT | MaxEsReturn               596.613
2017-06-10 20:52:53.630189 EDT | MinEsReturn                 6.56841
2017-06-10 20:52:53.630368 EDT | AverageDiscountedReturn   221.131
2017-06-10 20:52:53.630548 EDT | AverageQLoss                2.96662
2017-06-10 20:52:53.630726 EDT | AveragePolicySurr         -32.8614
2017-06-10 20:52:53.630904 EDT | AverageQ                   32.1386
2017-06-10 20:52:53.631082 EDT | AverageAbsQ                32.1631
2017-06-10 20:52:53.631260 EDT | AverageY                   32.1389
2017-06-10 20:52:53.631436 EDT | AverageAbsY                32.1457
2017-06-10 20:52:53.631612 EDT | AverageAbsQYDiff            0.740996
2017-06-10 20:52:53.631789 EDT | AverageAction               0.685246
2017-06-10 20:52:53.631965 EDT | PolicyRegParamNorm         54.523
2017-06-10 20:52:53.632143 EDT | QFunRegParamNorm           65.5221
2017-06-10 20:52:53.632319 EDT | -----------------------  -----------
2017-06-10 20:52:53.632598 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #218 | Training started
2017-06-10 20:53:08.713049 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #218 | Training finished
2017-06-10 20:53:08.713926 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #218 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 20:53:08.714333 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #218 | Collecting samples for evaluation
2017-06-10 20:53:20.604505 EDT | -----------------------  -----------
2017-06-10 20:53:20.605671 EDT | Epoch                     218
2017-06-10 20:53:20.606149 EDT | Iteration                 218
2017-06-10 20:53:20.606413 EDT | AverageReturn            1042.36
2017-06-10 20:53:20.606698 EDT | StdReturn                 226.166
2017-06-10 20:53:20.606967 EDT | MaxReturn                2017.09
2017-06-10 20:53:20.607283 EDT | MinReturn                 767.836
2017-06-10 20:53:20.616850 EDT | AverageEsReturn           260.494
2017-06-10 20:53:20.617077 EDT | StdEsReturn               195.626
2017-06-10 20:53:20.617239 EDT | MaxEsReturn               577.706
2017-06-10 20:53:20.617555 EDT | MinEsReturn                 8.84152
2017-06-10 20:53:20.617884 EDT | AverageDiscountedReturn   242.303
2017-06-10 20:53:20.618053 EDT | AverageQLoss                2.66586
2017-06-10 20:53:20.618206 EDT | AveragePolicySurr         -32.8855
2017-06-10 20:53:20.618358 EDT | AverageQ                   32.1576
2017-06-10 20:53:20.618510 EDT | AverageAbsQ                32.1855
2017-06-10 20:53:20.618694 EDT | AverageY                   32.161
2017-06-10 20:53:20.618847 EDT | AverageAbsY                32.1685
2017-06-10 20:53:20.618998 EDT | AverageAbsQYDiff            0.724269
2017-06-10 20:53:20.619221 EDT | AverageAction               0.721721
2017-06-10 20:53:20.622502 EDT | PolicyRegParamNorm         54.5587
2017-06-10 20:53:20.623317 EDT | QFunRegParamNorm           65.653
2017-06-10 20:53:20.623765 EDT | -----------------------  -----------
2017-06-10 20:53:20.624090 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #219 | Training started
2017-06-10 20:53:35.479379 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #219 | Training finished
2017-06-10 20:53:35.480622 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #219 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 20:53:35.481025 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #219 | Collecting samples for evaluation
2017-06-10 20:53:47.420995 EDT | -----------------------  -----------
2017-06-10 20:53:47.421779 EDT | Epoch                     219
2017-06-10 20:53:47.422058 EDT | Iteration                 219
2017-06-10 20:53:47.422270 EDT | AverageReturn            1040.72
2017-06-10 20:53:47.422468 EDT | StdReturn                 417.682
2017-06-10 20:53:47.422623 EDT | MaxReturn                2511.15
2017-06-10 20:53:47.422802 EDT | MinReturn                 738.682
2017-06-10 20:53:47.422960 EDT | AverageEsReturn           281.118
2017-06-10 20:53:47.423138 EDT | StdEsReturn               238.606
2017-06-10 20:53:47.423289 EDT | MaxEsReturn               740.503
2017-06-10 20:53:47.423466 EDT | MinEsReturn                29.0928
2017-06-10 20:53:47.423620 EDT | AverageDiscountedReturn   227.162
2017-06-10 20:53:47.423770 EDT | AverageQLoss                2.78571
2017-06-10 20:53:47.423919 EDT | AveragePolicySurr         -32.9024
2017-06-10 20:53:47.424069 EDT | AverageQ                   32.1748
2017-06-10 20:53:47.424219 EDT | AverageAbsQ                32.1984
2017-06-10 20:53:47.424369 EDT | AverageY                   32.1762
2017-06-10 20:53:47.424518 EDT | AverageAbsY                32.1807
2017-06-10 20:53:47.424666 EDT | AverageAbsQYDiff            0.728158
2017-06-10 20:53:47.424814 EDT | AverageAction               0.680838
2017-06-10 20:53:47.424966 EDT | PolicyRegParamNorm         54.6602
2017-06-10 20:53:47.425210 EDT | QFunRegParamNorm           65.751
2017-06-10 20:53:47.425362 EDT | -----------------------  -----------
2017-06-10 20:53:47.425638 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #220 | Training started
2017-06-10 20:54:02.114863 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #220 | Training finished
2017-06-10 20:54:02.115860 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #220 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 20:54:02.116237 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #220 | Collecting samples for evaluation
2017-06-10 20:54:14.674732 EDT | -----------------------  -----------
2017-06-10 20:54:14.675295 EDT | Epoch                     220
2017-06-10 20:54:14.675731 EDT | Iteration                 220
2017-06-10 20:54:14.676151 EDT | AverageReturn            1014.47
2017-06-10 20:54:14.676786 EDT | StdReturn                 469.042
2017-06-10 20:54:14.677465 EDT | MaxReturn                2177.67
2017-06-10 20:54:14.678678 EDT | MinReturn                 401.978
2017-06-10 20:54:14.680484 EDT | AverageEsReturn           243.361
2017-06-10 20:54:14.680913 EDT | StdEsReturn               177.526
2017-06-10 20:54:14.681340 EDT | MaxEsReturn               470.41
2017-06-10 20:54:14.682403 EDT | MinEsReturn                 6.52662
2017-06-10 20:54:14.690485 EDT | AverageDiscountedReturn   218.743
2017-06-10 20:54:14.690962 EDT | AverageQLoss                2.83572
2017-06-10 20:54:14.691367 EDT | AveragePolicySurr         -33.0889
2017-06-10 20:54:14.691642 EDT | AverageQ                   32.3694
2017-06-10 20:54:14.691960 EDT | AverageAbsQ                32.3946
2017-06-10 20:54:14.692260 EDT | AverageY                   32.3702
2017-06-10 20:54:14.692588 EDT | AverageAbsY                32.3759
2017-06-10 20:54:14.693137 EDT | AverageAbsQYDiff            0.733253
2017-06-10 20:54:14.693386 EDT | AverageAction               0.666012
2017-06-10 20:54:14.693654 EDT | PolicyRegParamNorm         54.6967
2017-06-10 20:54:14.694721 EDT | QFunRegParamNorm           65.8918
2017-06-10 20:54:14.695067 EDT | -----------------------  -----------
2017-06-10 20:54:14.695805 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #221 | Training started
2017-06-10 20:54:29.512779 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #221 | Training finished
2017-06-10 20:54:29.513710 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #221 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 20:54:29.514115 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #221 | Collecting samples for evaluation
2017-06-10 20:54:43.100054 EDT | -----------------------  -----------
2017-06-10 20:54:43.100925 EDT | Epoch                     221
2017-06-10 20:54:43.101279 EDT | Iteration                 221
2017-06-10 20:54:43.101628 EDT | AverageReturn            1035.68
2017-06-10 20:54:43.101944 EDT | StdReturn                 322.586
2017-06-10 20:54:43.102213 EDT | MaxReturn                2264.56
2017-06-10 20:54:43.102470 EDT | MinReturn                 732.145
2017-06-10 20:54:43.102724 EDT | AverageEsReturn           260.167
2017-06-10 20:54:43.102988 EDT | StdEsReturn               218.247
2017-06-10 20:54:43.103431 EDT | MaxEsReturn               710.432
2017-06-10 20:54:43.104478 EDT | MinEsReturn                 9.88134
2017-06-10 20:54:43.105355 EDT | AverageDiscountedReturn   229.232
2017-06-10 20:54:43.106454 EDT | AverageQLoss                3.60731
2017-06-10 20:54:43.107334 EDT | AveragePolicySurr         -32.9361
2017-06-10 20:54:43.108403 EDT | AverageQ                   32.1853
2017-06-10 20:54:43.109240 EDT | AverageAbsQ                32.2168
2017-06-10 20:54:43.110318 EDT | AverageY                   32.1893
2017-06-10 20:54:43.111184 EDT | AverageAbsY                32.1998
2017-06-10 20:54:43.112270 EDT | AverageAbsQYDiff            0.798563
2017-06-10 20:54:43.113141 EDT | AverageAction               0.648723
2017-06-10 20:54:43.114240 EDT | PolicyRegParamNorm         54.7533
2017-06-10 20:54:43.115128 EDT | QFunRegParamNorm           66.0815
2017-06-10 20:54:43.116214 EDT | -----------------------  -----------
2017-06-10 20:54:43.117280 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #222 | Training started
2017-06-10 20:54:58.435317 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #222 | Training finished
2017-06-10 20:54:58.436112 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #222 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 20:54:58.436338 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #222 | Collecting samples for evaluation
2017-06-10 20:55:11.434414 EDT | -----------------------  -----------
2017-06-10 20:55:11.784075 EDT | Epoch                     222
2017-06-10 20:55:11.784985 EDT | Iteration                 222
2017-06-10 20:55:11.785456 EDT | AverageReturn             433.625
2017-06-10 20:55:11.785652 EDT | StdReturn                 861.911
2017-06-10 20:55:11.785940 EDT | MaxReturn                2802.6
2017-06-10 20:55:11.786205 EDT | MinReturn                  18.273
2017-06-10 20:55:11.787043 EDT | AverageEsReturn           181.84
2017-06-10 20:55:11.787394 EDT | StdEsReturn               286.826
2017-06-10 20:55:11.787898 EDT | MaxEsReturn               993.348
2017-06-10 20:55:11.788238 EDT | MinEsReturn                 9.89655
2017-06-10 20:55:11.789121 EDT | AverageDiscountedReturn    55.5645
2017-06-10 20:55:11.789478 EDT | AverageQLoss                3.04591
2017-06-10 20:55:11.789853 EDT | AveragePolicySurr         -33.0331
2017-06-10 20:55:11.790184 EDT | AverageQ                   32.2754
2017-06-10 20:55:11.790521 EDT | AverageAbsQ                32.3007
2017-06-10 20:55:11.790973 EDT | AverageY                   32.2787
2017-06-10 20:55:11.791306 EDT | AverageAbsY                32.2855
2017-06-10 20:55:11.791648 EDT | AverageAbsQYDiff            0.76273
2017-06-10 20:55:11.792104 EDT | AverageAction               0.655611
2017-06-10 20:55:11.792970 EDT | PolicyRegParamNorm         54.887
2017-06-10 20:55:11.793309 EDT | QFunRegParamNorm           66.2335
2017-06-10 20:55:11.793754 EDT | -----------------------  -----------
2017-06-10 20:55:11.794701 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #223 | Training started
2017-06-10 20:55:26.859867 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #223 | Training finished
2017-06-10 20:55:26.860900 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #223 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 20:55:26.861304 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #223 | Collecting samples for evaluation
2017-06-10 20:55:39.401259 EDT | -----------------------  -----------
2017-06-10 20:55:39.401975 EDT | Epoch                     223
2017-06-10 20:55:39.402334 EDT | Iteration                 223
2017-06-10 20:55:39.402620 EDT | AverageReturn            1472.97
2017-06-10 20:55:39.402781 EDT | StdReturn                 855.717
2017-06-10 20:55:39.403006 EDT | MaxReturn                2873.65
2017-06-10 20:55:39.403165 EDT | MinReturn                 277.864
2017-06-10 20:55:39.403478 EDT | AverageEsReturn           134.054
2017-06-10 20:55:39.403754 EDT | StdEsReturn               145.639
2017-06-10 20:55:39.404118 EDT | MaxEsReturn               442.823
2017-06-10 20:55:39.404490 EDT | MinEsReturn                 7.00673
2017-06-10 20:55:39.404863 EDT | AverageDiscountedReturn   209.504
2017-06-10 20:55:39.405086 EDT | AverageQLoss                2.84266
2017-06-10 20:55:39.405272 EDT | AveragePolicySurr         -33.2502
2017-06-10 20:55:39.405463 EDT | AverageQ                   32.4949
2017-06-10 20:55:39.405684 EDT | AverageAbsQ                32.522
2017-06-10 20:55:39.405893 EDT | AverageY                   32.498
2017-06-10 20:55:39.406072 EDT | AverageAbsY                32.5069
2017-06-10 20:55:39.406314 EDT | AverageAbsQYDiff            0.747805
2017-06-10 20:55:39.406499 EDT | AverageAction               0.64963
2017-06-10 20:55:39.406849 EDT | PolicyRegParamNorm         54.9382
2017-06-10 20:55:39.407223 EDT | QFunRegParamNorm           66.3639
2017-06-10 20:55:39.407610 EDT | -----------------------  -----------
2017-06-10 20:55:39.408082 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #224 | Training started
2017-06-10 20:55:55.653893 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #224 | Training finished
2017-06-10 20:55:55.654923 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #224 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 20:55:55.655308 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #224 | Collecting samples for evaluation
2017-06-10 20:56:08.862355 EDT | -----------------------  -----------
2017-06-10 20:56:08.863241 EDT | Epoch                     224
2017-06-10 20:56:08.863544 EDT | Iteration                 224
2017-06-10 20:56:08.863779 EDT | AverageReturn            1891.31
2017-06-10 20:56:08.864237 EDT | StdReturn                 748.191
2017-06-10 20:56:08.864493 EDT | MaxReturn                3150.45
2017-06-10 20:56:08.864683 EDT | MinReturn                 964.443
2017-06-10 20:56:08.865068 EDT | AverageEsReturn           193.746
2017-06-10 20:56:08.865244 EDT | StdEsReturn               204.928
2017-06-10 20:56:08.865606 EDT | MaxEsReturn               476.325
2017-06-10 20:56:08.866143 EDT | MinEsReturn                 6.53818
2017-06-10 20:56:08.866511 EDT | AverageDiscountedReturn   225.544
2017-06-10 20:56:08.866880 EDT | AverageQLoss                3.12534
2017-06-10 20:56:08.867584 EDT | AveragePolicySurr         -33.1816
2017-06-10 20:56:08.867841 EDT | AverageQ                   32.4467
2017-06-10 20:56:08.868194 EDT | AverageAbsQ                32.4741
2017-06-10 20:56:08.868529 EDT | AverageY                   32.4508
2017-06-10 20:56:08.868852 EDT | AverageAbsY                32.4568
2017-06-10 20:56:08.869068 EDT | AverageAbsQYDiff            0.760073
2017-06-10 20:56:08.869227 EDT | AverageAction               0.711869
2017-06-10 20:56:08.869383 EDT | PolicyRegParamNorm         54.9666
2017-06-10 20:56:08.869536 EDT | QFunRegParamNorm           66.4799
2017-06-10 20:56:08.869707 EDT | -----------------------  -----------
2017-06-10 20:56:08.870153 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #225 | Training started
2017-06-10 20:56:23.829013 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #225 | Training finished
2017-06-10 20:56:23.829587 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #225 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 20:56:23.829973 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #225 | Collecting samples for evaluation
2017-06-10 20:56:36.203288 EDT | -----------------------  -----------
2017-06-10 20:56:36.204206 EDT | Epoch                     225
2017-06-10 20:56:36.204659 EDT | Iteration                 225
2017-06-10 20:56:36.205004 EDT | AverageReturn            1017.12
2017-06-10 20:56:36.205351 EDT | StdReturn                 136.836
2017-06-10 20:56:36.205805 EDT | MaxReturn                1598.57
2017-06-10 20:56:36.206159 EDT | MinReturn                 860.172
2017-06-10 20:56:36.206501 EDT | AverageEsReturn           259.865
2017-06-10 20:56:36.206833 EDT | StdEsReturn               227.628
2017-06-10 20:56:36.207260 EDT | MaxEsReturn               712.374
2017-06-10 20:56:36.207638 EDT | MinEsReturn                11.4299
2017-06-10 20:56:36.208018 EDT | AverageDiscountedReturn   227.556
2017-06-10 20:56:36.208457 EDT | AverageQLoss                3.11774
2017-06-10 20:56:36.208802 EDT | AveragePolicySurr         -33.2208
2017-06-10 20:56:36.209207 EDT | AverageQ                   32.4742
2017-06-10 20:56:36.209553 EDT | AverageAbsQ                32.5022
2017-06-10 20:56:36.209914 EDT | AverageY                   32.4757
2017-06-10 20:56:36.210273 EDT | AverageAbsY                32.482
2017-06-10 20:56:36.210624 EDT | AverageAbsQYDiff            0.758317
2017-06-10 20:56:36.210964 EDT | AverageAction               0.687353
2017-06-10 20:56:36.211403 EDT | PolicyRegParamNorm         55.0433
2017-06-10 20:56:36.211847 EDT | QFunRegParamNorm           66.6185
2017-06-10 20:56:36.212227 EDT | -----------------------  -----------
2017-06-10 20:56:36.212725 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #226 | Training started
2017-06-10 20:56:51.619189 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #226 | Training finished
2017-06-10 20:56:51.620546 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #226 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 20:56:51.620850 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #226 | Collecting samples for evaluation
2017-06-10 20:57:03.665062 EDT | -----------------------  -----------
2017-06-10 20:57:03.672085 EDT | Epoch                     226
2017-06-10 20:57:03.672312 EDT | Iteration                 226
2017-06-10 20:57:03.672779 EDT | AverageReturn             809.267
2017-06-10 20:57:03.673494 EDT | StdReturn                 892.811
2017-06-10 20:57:03.673738 EDT | MaxReturn                2819.65
2017-06-10 20:57:03.673928 EDT | MinReturn                 259.538
2017-06-10 20:57:03.674147 EDT | AverageEsReturn           167.015
2017-06-10 20:57:03.674428 EDT | StdEsReturn               207.769
2017-06-10 20:57:03.674636 EDT | MaxEsReturn               720.352
2017-06-10 20:57:03.674797 EDT | MinEsReturn                 7.66419
2017-06-10 20:57:03.674963 EDT | AverageDiscountedReturn   160.678
2017-06-10 20:57:03.675186 EDT | AverageQLoss                3.80373
2017-06-10 20:57:03.675465 EDT | AveragePolicySurr         -33.3741
2017-06-10 20:57:03.675738 EDT | AverageQ                   32.565
2017-06-10 20:57:03.676008 EDT | AverageAbsQ                32.594
2017-06-10 20:57:03.676291 EDT | AverageY                   32.5682
2017-06-10 20:57:03.676587 EDT | AverageAbsY                32.5785
2017-06-10 20:57:03.676862 EDT | AverageAbsQYDiff            0.811518
2017-06-10 20:57:03.677158 EDT | AverageAction               0.635762
2017-06-10 20:57:03.677459 EDT | PolicyRegParamNorm         55.171
2017-06-10 20:57:03.677620 EDT | QFunRegParamNorm           66.7255
2017-06-10 20:57:03.677796 EDT | -----------------------  -----------
2017-06-10 20:57:03.678039 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #227 | Training started
2017-06-10 20:57:18.323295 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #227 | Training finished
2017-06-10 20:57:18.324589 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #227 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 20:57:18.325097 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #227 | Collecting samples for evaluation
2017-06-10 20:57:30.543211 EDT | -----------------------  -----------
2017-06-10 20:57:30.543969 EDT | Epoch                     227
2017-06-10 20:57:30.544155 EDT | Iteration                 227
2017-06-10 20:57:30.544328 EDT | AverageReturn             697.041
2017-06-10 20:57:30.544485 EDT | StdReturn                 525.665
2017-06-10 20:57:30.544639 EDT | MaxReturn                2683.66
2017-06-10 20:57:30.544889 EDT | MinReturn                 329.875
2017-06-10 20:57:30.545045 EDT | AverageEsReturn           145.979
2017-06-10 20:57:30.545196 EDT | StdEsReturn               110.295
2017-06-10 20:57:30.545358 EDT | MaxEsReturn               321.649
2017-06-10 20:57:30.545509 EDT | MinEsReturn                10.3687
2017-06-10 20:57:30.545660 EDT | AverageDiscountedReturn   190.458
2017-06-10 20:57:30.546194 EDT | AverageQLoss                3.62221
2017-06-10 20:57:30.546673 EDT | AveragePolicySurr         -33.5596
2017-06-10 20:57:30.547017 EDT | AverageQ                   32.7173
2017-06-10 20:57:30.547345 EDT | AverageAbsQ                32.7465
2017-06-10 20:57:30.547629 EDT | AverageY                   32.7215
2017-06-10 20:57:30.547937 EDT | AverageAbsY                32.7309
2017-06-10 20:57:30.548282 EDT | AverageAbsQYDiff            0.793167
2017-06-10 20:57:30.548792 EDT | AverageAction               0.657022
2017-06-10 20:57:30.549125 EDT | PolicyRegParamNorm         55.198
2017-06-10 20:57:30.549452 EDT | QFunRegParamNorm           66.8775
2017-06-10 20:57:30.550168 EDT | -----------------------  -----------
2017-06-10 20:57:30.550898 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #228 | Training started
2017-06-10 20:57:45.979686 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #228 | Training finished
2017-06-10 20:57:45.980636 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #228 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 20:57:45.981000 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #228 | Collecting samples for evaluation
2017-06-10 20:57:57.548425 EDT | -----------------------  -----------
2017-06-10 20:57:57.549770 EDT | Epoch                     228
2017-06-10 20:57:57.550188 EDT | Iteration                 228
2017-06-10 20:57:57.550769 EDT | AverageReturn             606.099
2017-06-10 20:57:57.551627 EDT | StdReturn                 312.47
2017-06-10 20:57:57.551922 EDT | MaxReturn                1440.55
2017-06-10 20:57:57.552211 EDT | MinReturn                 219.04
2017-06-10 20:57:57.552678 EDT | AverageEsReturn           201.956
2017-06-10 20:57:57.553058 EDT | StdEsReturn               332.296
2017-06-10 20:57:57.553358 EDT | MaxEsReturn              1034.67
2017-06-10 20:57:57.553808 EDT | MinEsReturn                 6.63454
2017-06-10 20:57:57.554303 EDT | AverageDiscountedReturn   177.84
2017-06-10 20:57:57.554682 EDT | AverageQLoss                3.42147
2017-06-10 20:57:57.556901 EDT | AveragePolicySurr         -33.6008
2017-06-10 20:57:57.557931 EDT | AverageQ                   32.809
2017-06-10 20:57:57.559390 EDT | AverageAbsQ                32.8367
2017-06-10 20:57:57.559610 EDT | AverageY                   32.8098
2017-06-10 20:57:57.559813 EDT | AverageAbsY                32.8169
2017-06-10 20:57:57.560012 EDT | AverageAbsQYDiff            0.785083
2017-06-10 20:57:57.560208 EDT | AverageAction               0.640117
2017-06-10 20:57:57.560402 EDT | PolicyRegParamNorm         55.2828
2017-06-10 20:57:57.560596 EDT | QFunRegParamNorm           67.0123
2017-06-10 20:57:57.560790 EDT | -----------------------  -----------
2017-06-10 20:57:57.561109 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #229 | Training started
2017-06-10 20:58:12.304624 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #229 | Training finished
2017-06-10 20:58:12.313817 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #229 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 20:58:12.314292 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #229 | Collecting samples for evaluation
2017-06-10 20:58:25.261423 EDT | -----------------------  ----------
2017-06-10 20:58:25.262130 EDT | Epoch                    229
2017-06-10 20:58:25.262500 EDT | Iteration                229
2017-06-10 20:58:25.262887 EDT | AverageReturn            187.304
2017-06-10 20:58:25.263289 EDT | StdReturn                 40.2322
2017-06-10 20:58:25.263571 EDT | MaxReturn                230.325
2017-06-10 20:58:25.263842 EDT | MinReturn                132.553
2017-06-10 20:58:25.263998 EDT | AverageEsReturn          196.142
2017-06-10 20:58:25.264149 EDT | StdEsReturn              146.522
2017-06-10 20:58:25.264338 EDT | MaxEsReturn              415.186
2017-06-10 20:58:25.264491 EDT | MinEsReturn               12.4222
2017-06-10 20:58:25.264711 EDT | AverageDiscountedReturn  110.044
2017-06-10 20:58:25.265210 EDT | AverageQLoss               3.06483
2017-06-10 20:58:25.265430 EDT | AveragePolicySurr        -33.6705
2017-06-10 20:58:25.265620 EDT | AverageQ                  32.8775
2017-06-10 20:58:25.265831 EDT | AverageAbsQ               32.9054
2017-06-10 20:58:25.265983 EDT | AverageY                  32.8788
2017-06-10 20:58:25.266133 EDT | AverageAbsY               32.8893
2017-06-10 20:58:25.266281 EDT | AverageAbsQYDiff           0.756911
2017-06-10 20:58:25.266708 EDT | AverageAction              0.548745
2017-06-10 20:58:25.266916 EDT | PolicyRegParamNorm        55.398
2017-06-10 20:58:25.267191 EDT | QFunRegParamNorm          67.1881
2017-06-10 20:58:25.267451 EDT | -----------------------  ----------
2017-06-10 20:58:25.268189 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #230 | Training started
2017-06-10 20:58:38.776262 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #230 | Training finished
2017-06-10 20:58:38.777566 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #230 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 20:58:38.777926 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #230 | Collecting samples for evaluation
2017-06-10 20:58:51.687301 EDT | -----------------------  -----------
2017-06-10 20:58:51.688532 EDT | Epoch                     230
2017-06-10 20:58:51.688860 EDT | Iteration                 230
2017-06-10 20:58:51.689128 EDT | AverageReturn            1577.49
2017-06-10 20:58:51.689406 EDT | StdReturn                 612.048
2017-06-10 20:58:51.689690 EDT | MaxReturn                2969.37
2017-06-10 20:58:51.689981 EDT | MinReturn                 600.438
2017-06-10 20:58:51.691000 EDT | AverageEsReturn           130.913
2017-06-10 20:58:51.691457 EDT | StdEsReturn               152.455
2017-06-10 20:58:51.691958 EDT | MaxEsReturn               412.765
2017-06-10 20:58:51.692247 EDT | MinEsReturn                 7.73186
2017-06-10 20:58:51.692579 EDT | AverageDiscountedReturn   216.082
2017-06-10 20:58:51.692925 EDT | AverageQLoss                3.55301
2017-06-10 20:58:51.693349 EDT | AveragePolicySurr         -33.7106
2017-06-10 20:58:51.693790 EDT | AverageQ                   32.8966
2017-06-10 20:58:51.694759 EDT | AverageAbsQ                32.9295
2017-06-10 20:58:51.694969 EDT | AverageY                   32.8996
2017-06-10 20:58:51.695159 EDT | AverageAbsY                32.9087
2017-06-10 20:58:51.695434 EDT | AverageAbsQYDiff            0.797504
2017-06-10 20:58:51.695693 EDT | AverageAction               0.694793
2017-06-10 20:58:51.695962 EDT | PolicyRegParamNorm         55.5149
2017-06-10 20:58:51.696337 EDT | QFunRegParamNorm           67.3437
2017-06-10 20:58:51.696719 EDT | -----------------------  -----------
2017-06-10 20:58:51.697262 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #231 | Training started
2017-06-10 20:59:06.625471 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #231 | Training finished
2017-06-10 20:59:06.626448 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #231 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 20:59:06.626816 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #231 | Collecting samples for evaluation
2017-06-10 20:59:17.741260 EDT | -----------------------  ----------
2017-06-10 20:59:17.742219 EDT | Epoch                    231
2017-06-10 20:59:17.742421 EDT | Iteration                231
2017-06-10 20:59:17.742703 EDT | AverageReturn            517.072
2017-06-10 20:59:17.742893 EDT | StdReturn                 91.3707
2017-06-10 20:59:17.743079 EDT | MaxReturn                750.329
2017-06-10 20:59:17.743373 EDT | MinReturn                251.991
2017-06-10 20:59:17.743716 EDT | AverageEsReturn          195.967
2017-06-10 20:59:17.744122 EDT | StdEsReturn              249.908
2017-06-10 20:59:17.744432 EDT | MaxEsReturn              866.485
2017-06-10 20:59:17.744760 EDT | MinEsReturn                7.51379
2017-06-10 20:59:17.744939 EDT | AverageDiscountedReturn  189.793
2017-06-10 20:59:17.745123 EDT | AverageQLoss               3.21512
2017-06-10 20:59:17.745304 EDT | AveragePolicySurr        -33.8877
2017-06-10 20:59:17.745483 EDT | AverageQ                  33.1089
2017-06-10 20:59:17.745664 EDT | AverageAbsQ               33.1377
2017-06-10 20:59:17.745862 EDT | AverageY                  33.1126
2017-06-10 20:59:17.746137 EDT | AverageAbsY               33.1233
2017-06-10 20:59:17.746431 EDT | AverageAbsQYDiff           0.760912
2017-06-10 20:59:17.746689 EDT | AverageAction              0.679371
2017-06-10 20:59:17.746962 EDT | PolicyRegParamNorm        55.5627
2017-06-10 20:59:17.747217 EDT | QFunRegParamNorm          67.4615
2017-06-10 20:59:17.747489 EDT | -----------------------  ----------
2017-06-10 20:59:17.748124 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #232 | Training started
2017-06-10 20:59:32.364877 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #232 | Training finished
2017-06-10 20:59:32.365982 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #232 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 20:59:32.366315 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #232 | Collecting samples for evaluation
2017-06-10 20:59:44.651026 EDT | -----------------------  -----------
2017-06-10 20:59:44.652125 EDT | Epoch                     232
2017-06-10 20:59:44.652490 EDT | Iteration                 232
2017-06-10 20:59:44.652841 EDT | AverageReturn             484.192
2017-06-10 20:59:44.654906 EDT | StdReturn                 429.366
2017-06-10 20:59:44.655273 EDT | MaxReturn                1895.13
2017-06-10 20:59:44.655629 EDT | MinReturn                 263.567
2017-06-10 20:59:44.656101 EDT | AverageEsReturn           290.917
2017-06-10 20:59:44.656474 EDT | StdEsReturn               235.193
2017-06-10 20:59:44.656820 EDT | MaxEsReturn               616.617
2017-06-10 20:59:44.657485 EDT | MinEsReturn                 9.41603
2017-06-10 20:59:44.658170 EDT | AverageDiscountedReturn   161.195
2017-06-10 20:59:44.658561 EDT | AverageQLoss                3.00077
2017-06-10 20:59:44.659020 EDT | AveragePolicySurr         -33.8581
2017-06-10 20:59:44.659369 EDT | AverageQ                   33.1093
2017-06-10 20:59:44.659739 EDT | AverageAbsQ                33.1449
2017-06-10 20:59:44.660196 EDT | AverageY                   33.111
2017-06-10 20:59:44.660557 EDT | AverageAbsY                33.1239
2017-06-10 20:59:44.660905 EDT | AverageAbsQYDiff            0.76458
2017-06-10 20:59:44.661359 EDT | AverageAction               0.688961
2017-06-10 20:59:44.661741 EDT | PolicyRegParamNorm         55.6927
2017-06-10 20:59:44.662085 EDT | QFunRegParamNorm           67.6119
2017-06-10 20:59:44.662537 EDT | -----------------------  -----------
2017-06-10 20:59:44.663037 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #233 | Training started
2017-06-10 20:59:58.821561 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #233 | Training finished
2017-06-10 20:59:58.822824 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #233 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 20:59:58.823313 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #233 | Collecting samples for evaluation
2017-06-10 21:00:12.120275 EDT | -----------------------  -----------
2017-06-10 21:00:12.121254 EDT | Epoch                     233
2017-06-10 21:00:12.121618 EDT | Iteration                 233
2017-06-10 21:00:12.123735 EDT | AverageReturn            1019.85
2017-06-10 21:00:12.124923 EDT | StdReturn                 846.491
2017-06-10 21:00:12.125486 EDT | MaxReturn                3045.75
2017-06-10 21:00:12.125804 EDT | MinReturn                 211.033
2017-06-10 21:00:12.126127 EDT | AverageEsReturn           180.914
2017-06-10 21:00:12.126461 EDT | StdEsReturn               270.108
2017-06-10 21:00:12.127206 EDT | MaxEsReturn               999.079
2017-06-10 21:00:12.127551 EDT | MinEsReturn                 7.63406
2017-06-10 21:00:12.128002 EDT | AverageDiscountedReturn   182.151
2017-06-10 21:00:12.128331 EDT | AverageQLoss                3.05462
2017-06-10 21:00:12.128665 EDT | AveragePolicySurr         -33.8689
2017-06-10 21:00:12.129255 EDT | AverageQ                   33.1271
2017-06-10 21:00:12.129591 EDT | AverageAbsQ                33.161
2017-06-10 21:00:12.130005 EDT | AverageY                   33.1294
2017-06-10 21:00:12.130346 EDT | AverageAbsY                33.1466
2017-06-10 21:00:12.130676 EDT | AverageAbsQYDiff            0.759747
2017-06-10 21:00:12.131054 EDT | AverageAction               0.710695
2017-06-10 21:00:12.131700 EDT | PolicyRegParamNorm         55.7387
2017-06-10 21:00:12.132116 EDT | QFunRegParamNorm           67.7419
2017-06-10 21:00:12.132403 EDT | -----------------------  -----------
2017-06-10 21:00:12.133203 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #234 | Training started
2017-06-10 21:00:26.328382 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #234 | Training finished
2017-06-10 21:00:26.329400 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #234 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 21:00:26.329817 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #234 | Collecting samples for evaluation
2017-06-10 21:00:38.827860 EDT | -----------------------  -----------
2017-06-10 21:00:38.831021 EDT | Epoch                     234
2017-06-10 21:00:38.831693 EDT | Iteration                 234
2017-06-10 21:00:38.831991 EDT | AverageReturn             740.638
2017-06-10 21:00:38.832323 EDT | StdReturn                 511.311
2017-06-10 21:00:38.832658 EDT | MaxReturn                2290.71
2017-06-10 21:00:38.832934 EDT | MinReturn                 202.648
2017-06-10 21:00:38.833200 EDT | AverageEsReturn           209.178
2017-06-10 21:00:38.833529 EDT | StdEsReturn               199.689
2017-06-10 21:00:38.835828 EDT | MaxEsReturn               665.383
2017-06-10 21:00:38.837177 EDT | MinEsReturn                18.8231
2017-06-10 21:00:38.843162 EDT | AverageDiscountedReturn   130.392
2017-06-10 21:00:38.843592 EDT | AverageQLoss                3.15087
2017-06-10 21:00:38.843953 EDT | AveragePolicySurr         -33.8939
2017-06-10 21:00:38.844384 EDT | AverageQ                   33.136
2017-06-10 21:00:38.844808 EDT | AverageAbsQ                33.1675
2017-06-10 21:00:38.845163 EDT | AverageY                   33.1383
2017-06-10 21:00:38.845585 EDT | AverageAbsY                33.1508
2017-06-10 21:00:38.846071 EDT | AverageAbsQYDiff            0.766839
2017-06-10 21:00:38.846435 EDT | AverageAction               0.769884
2017-06-10 21:00:38.846848 EDT | PolicyRegParamNorm         55.8293
2017-06-10 21:00:38.847277 EDT | QFunRegParamNorm           67.8561
2017-06-10 21:00:38.847667 EDT | -----------------------  -----------
2017-06-10 21:00:38.848226 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #235 | Training started
2017-06-10 21:00:53.381564 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #235 | Training finished
2017-06-10 21:00:53.382356 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #235 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 21:00:53.382554 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #235 | Collecting samples for evaluation
2017-06-10 21:01:05.553113 EDT | -----------------------  ----------
2017-06-10 21:01:05.554545 EDT | Epoch                    235
2017-06-10 21:01:05.554756 EDT | Iteration                235
2017-06-10 21:01:05.554961 EDT | AverageReturn            307.132
2017-06-10 21:01:05.555321 EDT | StdReturn                 33.3413
2017-06-10 21:01:05.555620 EDT | MaxReturn                571.207
2017-06-10 21:01:05.555843 EDT | MinReturn                277.673
2017-06-10 21:01:05.556040 EDT | AverageEsReturn          190.913
2017-06-10 21:01:05.556239 EDT | StdEsReturn              166.853
2017-06-10 21:01:05.560537 EDT | MaxEsReturn              517.104
2017-06-10 21:01:05.561058 EDT | MinEsReturn               31.7816
2017-06-10 21:01:05.561434 EDT | AverageDiscountedReturn  152.689
2017-06-10 21:01:05.561815 EDT | AverageQLoss               3.32395
2017-06-10 21:01:05.562174 EDT | AveragePolicySurr        -33.9794
2017-06-10 21:01:05.562526 EDT | AverageQ                  33.2448
2017-06-10 21:01:05.562951 EDT | AverageAbsQ               33.2768
2017-06-10 21:01:05.563705 EDT | AverageY                  33.2482
2017-06-10 21:01:05.565898 EDT | AverageAbsY               33.2598
2017-06-10 21:01:05.566204 EDT | AverageAbsQYDiff           0.764828
2017-06-10 21:01:05.566516 EDT | AverageAction              0.734322
2017-06-10 21:01:05.566838 EDT | PolicyRegParamNorm        55.8577
2017-06-10 21:01:05.567154 EDT | QFunRegParamNorm          67.9763
2017-06-10 21:01:05.567471 EDT | -----------------------  ----------
2017-06-10 21:01:05.567965 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #236 | Training started
2017-06-10 21:01:20.627166 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #236 | Training finished
2017-06-10 21:01:20.627600 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #236 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 21:01:20.627946 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #236 | Collecting samples for evaluation
2017-06-10 21:01:32.572329 EDT | -----------------------  -----------
2017-06-10 21:01:32.573777 EDT | Epoch                     236
2017-06-10 21:01:32.574378 EDT | Iteration                 236
2017-06-10 21:01:32.574551 EDT | AverageReturn             560.184
2017-06-10 21:01:32.574739 EDT | StdReturn                 356.165
2017-06-10 21:01:32.574906 EDT | MaxReturn                2040.18
2017-06-10 21:01:32.575064 EDT | MinReturn                 220.205
2017-06-10 21:01:32.575227 EDT | AverageEsReturn           230.992
2017-06-10 21:01:32.575416 EDT | StdEsReturn               138.842
2017-06-10 21:01:32.575638 EDT | MaxEsReturn               428.36
2017-06-10 21:01:32.575819 EDT | MinEsReturn                70.6487
2017-06-10 21:01:32.575999 EDT | AverageDiscountedReturn   165.408
2017-06-10 21:01:32.576177 EDT | AverageQLoss                3.0729
2017-06-10 21:01:32.576355 EDT | AveragePolicySurr         -34.0174
2017-06-10 21:01:32.576532 EDT | AverageQ                   33.2596
2017-06-10 21:01:32.576716 EDT | AverageAbsQ                33.2936
2017-06-10 21:01:32.576893 EDT | AverageY                   33.2622
2017-06-10 21:01:32.577071 EDT | AverageAbsY                33.2757
2017-06-10 21:01:32.577250 EDT | AverageAbsQYDiff            0.759719
2017-06-10 21:01:32.577475 EDT | AverageAction               0.685511
2017-06-10 21:01:32.577662 EDT | PolicyRegParamNorm         55.9664
2017-06-10 21:01:32.577857 EDT | QFunRegParamNorm           68.1442
2017-06-10 21:01:32.578055 EDT | -----------------------  -----------
2017-06-10 21:01:32.578370 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #237 | Training started
2017-06-10 21:01:47.327097 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #237 | Training finished
2017-06-10 21:01:47.327904 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #237 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 21:01:47.328096 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #237 | Collecting samples for evaluation
2017-06-10 21:02:00.088513 EDT | -----------------------  -----------
2017-06-10 21:02:00.089458 EDT | Epoch                     237
2017-06-10 21:02:00.089844 EDT | Iteration                 237
2017-06-10 21:02:00.090192 EDT | AverageReturn             301.035
2017-06-10 21:02:00.090540 EDT | StdReturn                 242.893
2017-06-10 21:02:00.090884 EDT | MaxReturn                1850.25
2017-06-10 21:02:00.091223 EDT | MinReturn                 186.24
2017-06-10 21:02:00.091570 EDT | AverageEsReturn           362.14
2017-06-10 21:02:00.091914 EDT | StdEsReturn               230.105
2017-06-10 21:02:00.092256 EDT | MaxEsReturn               645.153
2017-06-10 21:02:00.092593 EDT | MinEsReturn                67.3304
2017-06-10 21:02:00.092935 EDT | AverageDiscountedReturn   128.998
2017-06-10 21:02:00.093276 EDT | AverageQLoss                3.32625
2017-06-10 21:02:00.093616 EDT | AveragePolicySurr         -34.0526
2017-06-10 21:02:00.093970 EDT | AverageQ                   33.3062
2017-06-10 21:02:00.094312 EDT | AverageAbsQ                33.3371
2017-06-10 21:02:00.094650 EDT | AverageY                   33.3068
2017-06-10 21:02:00.094988 EDT | AverageAbsY                33.3202
2017-06-10 21:02:00.095317 EDT | AverageAbsQYDiff            0.774832
2017-06-10 21:02:00.095653 EDT | AverageAction               0.794203
2017-06-10 21:02:00.095994 EDT | PolicyRegParamNorm         56.0866
2017-06-10 21:02:00.096333 EDT | QFunRegParamNorm           68.2586
2017-06-10 21:02:00.096670 EDT | -----------------------  -----------
2017-06-10 21:02:00.097179 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #238 | Training started
2017-06-10 21:02:14.702109 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #238 | Training finished
2017-06-10 21:02:14.703861 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #238 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 21:02:14.704202 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #238 | Collecting samples for evaluation
2017-06-10 21:02:27.682558 EDT | -----------------------  -----------
2017-06-10 21:02:27.683738 EDT | Epoch                     238
2017-06-10 21:02:27.684383 EDT | Iteration                 238
2017-06-10 21:02:27.685126 EDT | AverageReturn             827.355
2017-06-10 21:02:27.688214 EDT | StdReturn                 654.784
2017-06-10 21:02:27.688685 EDT | MaxReturn                2555.82
2017-06-10 21:02:27.689085 EDT | MinReturn                 228.09
2017-06-10 21:02:27.689473 EDT | AverageEsReturn           282.245
2017-06-10 21:02:27.689866 EDT | StdEsReturn               294.886
2017-06-10 21:02:27.690238 EDT | MaxEsReturn               868.008
2017-06-10 21:02:27.690692 EDT | MinEsReturn                18.4917
2017-06-10 21:02:27.691072 EDT | AverageDiscountedReturn   176.332
2017-06-10 21:02:27.691457 EDT | AverageQLoss                3.17666
2017-06-10 21:02:27.691846 EDT | AveragePolicySurr         -34.0305
2017-06-10 21:02:27.695081 EDT | AverageQ                   33.3373
2017-06-10 21:02:27.695473 EDT | AverageAbsQ                33.3735
2017-06-10 21:02:27.695857 EDT | AverageY                   33.3398
2017-06-10 21:02:27.696235 EDT | AverageAbsY                33.3556
2017-06-10 21:02:27.696605 EDT | AverageAbsQYDiff            0.763309
2017-06-10 21:02:27.696984 EDT | AverageAction               0.741784
2017-06-10 21:02:27.697368 EDT | PolicyRegParamNorm         56.1979
2017-06-10 21:02:27.697754 EDT | QFunRegParamNorm           68.4123
2017-06-10 21:02:27.698127 EDT | -----------------------  -----------
2017-06-10 21:02:27.698683 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #239 | Training started
2017-06-10 21:02:41.774216 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #239 | Training finished
2017-06-10 21:02:41.774979 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #239 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 21:02:41.775202 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #239 | Collecting samples for evaluation
2017-06-10 21:02:54.089879 EDT | -----------------------  -----------
2017-06-10 21:02:54.090653 EDT | Epoch                     239
2017-06-10 21:02:54.090979 EDT | Iteration                 239
2017-06-10 21:02:54.091268 EDT | AverageReturn             682.658
2017-06-10 21:02:54.091484 EDT | StdReturn                 624.793
2017-06-10 21:02:54.091648 EDT | MaxReturn                2853.17
2017-06-10 21:02:54.091808 EDT | MinReturn                 241.759
2017-06-10 21:02:54.092005 EDT | AverageEsReturn           511.85
2017-06-10 21:02:54.092232 EDT | StdEsReturn               244.678
2017-06-10 21:02:54.092495 EDT | MaxEsReturn               910.591
2017-06-10 21:02:54.092741 EDT | MinEsReturn               145.888
2017-06-10 21:02:54.092925 EDT | AverageDiscountedReturn   169.762
2017-06-10 21:02:54.093099 EDT | AverageQLoss                3.5362
2017-06-10 21:02:54.093259 EDT | AveragePolicySurr         -34.0656
2017-06-10 21:02:54.093485 EDT | AverageQ                   33.3526
2017-06-10 21:02:54.093645 EDT | AverageAbsQ                33.3848
2017-06-10 21:02:54.093926 EDT | AverageY                   33.3555
2017-06-10 21:02:54.094087 EDT | AverageAbsY                33.365
2017-06-10 21:02:54.094245 EDT | AverageAbsQYDiff            0.787074
2017-06-10 21:02:54.094470 EDT | AverageAction               0.787985
2017-06-10 21:02:54.094634 EDT | PolicyRegParamNorm         56.2261
2017-06-10 21:02:54.094820 EDT | QFunRegParamNorm           68.6003
2017-06-10 21:02:54.095043 EDT | -----------------------  -----------
2017-06-10 21:02:54.095357 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #240 | Training started
2017-06-10 21:03:10.522524 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #240 | Training finished
2017-06-10 21:03:10.523306 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #240 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 21:03:10.523507 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #240 | Collecting samples for evaluation
2017-06-10 21:03:22.128841 EDT | -----------------------  -----------
2017-06-10 21:03:22.129893 EDT | Epoch                     240
2017-06-10 21:03:22.130765 EDT | Iteration                 240
2017-06-10 21:03:22.131618 EDT | AverageReturn             341.364
2017-06-10 21:03:22.133737 EDT | StdReturn                 216.749
2017-06-10 21:03:22.134600 EDT | MaxReturn                1369.15
2017-06-10 21:03:22.136966 EDT | MinReturn                 257.471
2017-06-10 21:03:22.137832 EDT | AverageEsReturn           400.811
2017-06-10 21:03:22.138488 EDT | StdEsReturn               333.592
2017-06-10 21:03:22.140443 EDT | MaxEsReturn               943.153
2017-06-10 21:03:22.141108 EDT | MinEsReturn                20.9657
2017-06-10 21:03:22.141729 EDT | AverageDiscountedReturn   152.179
2017-06-10 21:03:22.161849 EDT | AverageQLoss                3.32335
2017-06-10 21:03:22.162253 EDT | AveragePolicySurr         -33.9277
2017-06-10 21:03:22.162599 EDT | AverageQ                   33.212
2017-06-10 21:03:22.162948 EDT | AverageAbsQ                33.242
2017-06-10 21:03:22.163284 EDT | AverageY                   33.2123
2017-06-10 21:03:22.164038 EDT | AverageAbsY                33.2222
2017-06-10 21:03:22.164908 EDT | AverageAbsQYDiff            0.775392
2017-06-10 21:03:22.165791 EDT | AverageAction               0.823284
2017-06-10 21:03:22.166685 EDT | PolicyRegParamNorm         56.3558
2017-06-10 21:03:22.167554 EDT | QFunRegParamNorm           68.6931
2017-06-10 21:03:22.168430 EDT | -----------------------  -----------
2017-06-10 21:03:22.169479 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #241 | Training started
2017-06-10 21:03:37.352071 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #241 | Training finished
2017-06-10 21:03:37.353011 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #241 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 21:03:37.353382 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #241 | Collecting samples for evaluation
2017-06-10 21:03:49.988875 EDT | -----------------------  ----------
2017-06-10 21:03:49.989160 EDT | Epoch                    241
2017-06-10 21:03:49.989361 EDT | Iteration                241
2017-06-10 21:03:49.989561 EDT | AverageReturn            226.617
2017-06-10 21:03:49.989775 EDT | StdReturn                 15.4153
2017-06-10 21:03:49.990106 EDT | MaxReturn                251.296
2017-06-10 21:03:49.990444 EDT | MinReturn                196.972
2017-06-10 21:03:49.990762 EDT | AverageEsReturn          385.942
2017-06-10 21:03:49.991181 EDT | StdEsReturn              149.245
2017-06-10 21:03:49.991616 EDT | MaxEsReturn              691.163
2017-06-10 21:03:49.991960 EDT | MinEsReturn              242.497
2017-06-10 21:03:49.992357 EDT | AverageDiscountedReturn  127.798
2017-06-10 21:03:49.992694 EDT | AverageQLoss               3.33288
2017-06-10 21:03:49.993001 EDT | AveragePolicySurr        -33.9918
2017-06-10 21:03:49.993317 EDT | AverageQ                  33.2382
2017-06-10 21:03:49.993671 EDT | AverageAbsQ               33.2644
2017-06-10 21:03:49.994005 EDT | AverageY                  33.2418
2017-06-10 21:03:49.994332 EDT | AverageAbsY               33.2505
2017-06-10 21:03:49.994762 EDT | AverageAbsQYDiff           0.778488
2017-06-10 21:03:49.995073 EDT | AverageAction              0.783202
2017-06-10 21:03:49.995383 EDT | PolicyRegParamNorm        56.3921
2017-06-10 21:03:49.995796 EDT | QFunRegParamNorm          68.7992
2017-06-10 21:03:49.996213 EDT | -----------------------  ----------
2017-06-10 21:03:49.996773 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #242 | Training started
2017-06-10 21:04:03.844028 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #242 | Training finished
2017-06-10 21:04:03.845002 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #242 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 21:04:03.845296 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #242 | Collecting samples for evaluation
2017-06-10 21:04:17.306892 EDT | -----------------------  ----------
2017-06-10 21:04:17.307679 EDT | Epoch                    242
2017-06-10 21:04:17.307923 EDT | Iteration                242
2017-06-10 21:04:17.308106 EDT | AverageReturn            238.618
2017-06-10 21:04:17.308270 EDT | StdReturn                  5.69042
2017-06-10 21:04:17.308436 EDT | MaxReturn                252.926
2017-06-10 21:04:17.308663 EDT | MinReturn                224.895
2017-06-10 21:04:17.308839 EDT | AverageEsReturn          239.635
2017-06-10 21:04:17.309040 EDT | StdEsReturn              155.716
2017-06-10 21:04:17.309206 EDT | MaxEsReturn              496.214
2017-06-10 21:04:17.309392 EDT | MinEsReturn               18.7365
2017-06-10 21:04:17.309677 EDT | AverageDiscountedReturn  131.718
2017-06-10 21:04:17.309891 EDT | AverageQLoss               3.52397
2017-06-10 21:04:17.310139 EDT | AveragePolicySurr        -33.9493
2017-06-10 21:04:17.310304 EDT | AverageQ                  33.2232
2017-06-10 21:04:17.310531 EDT | AverageAbsQ               33.2498
2017-06-10 21:04:17.310690 EDT | AverageY                  33.2242
2017-06-10 21:04:17.310853 EDT | AverageAbsY               33.233
2017-06-10 21:04:17.311040 EDT | AverageAbsQYDiff           0.777989
2017-06-10 21:04:17.311281 EDT | AverageAction              0.706003
2017-06-10 21:04:17.311445 EDT | PolicyRegParamNorm        56.4445
2017-06-10 21:04:17.311597 EDT | QFunRegParamNorm          68.9241
2017-06-10 21:04:17.311748 EDT | -----------------------  ----------
2017-06-10 21:04:17.312010 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #243 | Training started
2017-06-10 21:04:31.415121 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #243 | Training finished
2017-06-10 21:04:31.416045 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #243 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 21:04:31.416356 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #243 | Collecting samples for evaluation
2017-06-10 21:04:44.018486 EDT | -----------------------  -----------
2017-06-10 21:04:44.020128 EDT | Epoch                     243
2017-06-10 21:04:44.020326 EDT | Iteration                 243
2017-06-10 21:04:44.020497 EDT | AverageReturn             516.498
2017-06-10 21:04:44.020718 EDT | StdReturn                 698.546
2017-06-10 21:04:44.020912 EDT | MaxReturn                3056.55
2017-06-10 21:04:44.021097 EDT | MinReturn                 245.619
2017-06-10 21:04:44.021296 EDT | AverageEsReturn           485.772
2017-06-10 21:04:44.021568 EDT | StdEsReturn               229.528
2017-06-10 21:04:44.021770 EDT | MaxEsReturn               806.637
2017-06-10 21:04:44.021954 EDT | MinEsReturn               219.773
2017-06-10 21:04:44.022136 EDT | AverageDiscountedReturn   157.539
2017-06-10 21:04:44.022401 EDT | AverageQLoss                2.74793
2017-06-10 21:04:44.022602 EDT | AveragePolicySurr         -34.1499
2017-06-10 21:04:44.022785 EDT | AverageQ                   33.4207
2017-06-10 21:04:44.022968 EDT | AverageAbsQ                33.4519
2017-06-10 21:04:44.023148 EDT | AverageY                   33.4237
2017-06-10 21:04:44.023327 EDT | AverageAbsY                33.4344
2017-06-10 21:04:44.023531 EDT | AverageAbsQYDiff            0.748847
2017-06-10 21:04:44.023806 EDT | AverageAction               0.829217
2017-06-10 21:04:44.024022 EDT | PolicyRegParamNorm         56.5935
2017-06-10 21:04:44.024248 EDT | QFunRegParamNorm           69.0355
2017-06-10 21:04:44.024427 EDT | -----------------------  -----------
2017-06-10 21:04:44.024720 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #244 | Training started
2017-06-10 21:04:59.223188 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #244 | Training finished
2017-06-10 21:04:59.224661 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #244 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 21:04:59.224960 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #244 | Collecting samples for evaluation
2017-06-10 21:05:11.895689 EDT | -----------------------  ----------
2017-06-10 21:05:11.896394 EDT | Epoch                    244
2017-06-10 21:05:11.896574 EDT | Iteration                244
2017-06-10 21:05:11.896732 EDT | AverageReturn            259.65
2017-06-10 21:05:11.896886 EDT | StdReturn                  8.61352
2017-06-10 21:05:11.897148 EDT | MaxReturn                276.64
2017-06-10 21:05:11.897530 EDT | MinReturn                242.483
2017-06-10 21:05:11.897872 EDT | AverageEsReturn          302.595
2017-06-10 21:05:11.898191 EDT | StdEsReturn              201.352
2017-06-10 21:05:11.898518 EDT | MaxEsReturn              645.973
2017-06-10 21:05:11.898905 EDT | MinEsReturn                8.6923
2017-06-10 21:05:11.899246 EDT | AverageDiscountedReturn  139.522
2017-06-10 21:05:11.899440 EDT | AverageQLoss               3.54755
2017-06-10 21:05:11.899764 EDT | AveragePolicySurr        -34.0786
2017-06-10 21:05:11.900019 EDT | AverageQ                  33.3955
2017-06-10 21:05:11.900254 EDT | AverageAbsQ               33.4312
2017-06-10 21:05:11.900575 EDT | AverageY                  33.3966
2017-06-10 21:05:11.901712 EDT | AverageAbsY               33.4118
2017-06-10 21:05:11.902130 EDT | AverageAbsQYDiff           0.772438
2017-06-10 21:05:11.902451 EDT | AverageAction              0.883354
2017-06-10 21:05:11.902956 EDT | PolicyRegParamNorm        56.7322
2017-06-10 21:05:11.903280 EDT | QFunRegParamNorm          69.1469
2017-06-10 21:05:11.903595 EDT | -----------------------  ----------
2017-06-10 21:05:11.904125 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #245 | Training started
2017-06-10 21:05:27.737103 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #245 | Training finished
2017-06-10 21:05:27.738218 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #245 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 21:05:27.738428 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #245 | Collecting samples for evaluation
2017-06-10 21:05:40.431954 EDT | -----------------------  ----------
2017-06-10 21:05:40.432951 EDT | Epoch                    245
2017-06-10 21:05:40.433410 EDT | Iteration                245
2017-06-10 21:05:40.433777 EDT | AverageReturn            278.813
2017-06-10 21:05:40.434110 EDT | StdReturn                  6.66917
2017-06-10 21:05:40.434529 EDT | MaxReturn                296.119
2017-06-10 21:05:40.434864 EDT | MinReturn                265.85
2017-06-10 21:05:40.435198 EDT | AverageEsReturn          324.64
2017-06-10 21:05:40.435595 EDT | StdEsReturn              276.628
2017-06-10 21:05:40.435928 EDT | MaxEsReturn              835.716
2017-06-10 21:05:40.436262 EDT | MinEsReturn               43.1164
2017-06-10 21:05:40.436772 EDT | AverageDiscountedReturn  144.876
2017-06-10 21:05:40.437425 EDT | AverageQLoss               3.6848
2017-06-10 21:05:40.437713 EDT | AveragePolicySurr        -34.047
2017-06-10 21:05:40.437984 EDT | AverageQ                  33.3609
2017-06-10 21:05:40.438714 EDT | AverageAbsQ               33.4017
2017-06-10 21:05:40.438981 EDT | AverageY                  33.364
2017-06-10 21:05:40.439243 EDT | AverageAbsY               33.3867
2017-06-10 21:05:40.439505 EDT | AverageAbsQYDiff           0.782776
2017-06-10 21:05:40.439767 EDT | AverageAction              0.886584
2017-06-10 21:05:40.440027 EDT | PolicyRegParamNorm        56.8089
2017-06-10 21:05:40.440287 EDT | QFunRegParamNorm          69.2888
2017-06-10 21:05:40.440546 EDT | -----------------------  ----------
2017-06-10 21:05:40.442173 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #246 | Training started
2017-06-10 21:05:54.682596 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #246 | Training finished
2017-06-10 21:05:54.683398 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #246 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 21:05:54.683872 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #246 | Collecting samples for evaluation
2017-06-10 21:06:07.480154 EDT | -----------------------  -----------
2017-06-10 21:06:07.480973 EDT | Epoch                     246
2017-06-10 21:06:07.481230 EDT | Iteration                 246
2017-06-10 21:06:07.481479 EDT | AverageReturn             373.427
2017-06-10 21:06:07.481639 EDT | StdReturn                 305.234
2017-06-10 21:06:07.481814 EDT | MaxReturn                1751.22
2017-06-10 21:06:07.481967 EDT | MinReturn                 198.303
2017-06-10 21:06:07.483088 EDT | AverageEsReturn           340.663
2017-06-10 21:06:07.483251 EDT | StdEsReturn               375.979
2017-06-10 21:06:07.483531 EDT | MaxEsReturn              1225.54
2017-06-10 21:06:07.483847 EDT | MinEsReturn                15.731
2017-06-10 21:06:07.484159 EDT | AverageDiscountedReturn   144.652
2017-06-10 21:06:07.484488 EDT | AverageQLoss                3.14537
2017-06-10 21:06:07.484964 EDT | AveragePolicySurr         -34.0276
2017-06-10 21:06:07.485586 EDT | AverageQ                   33.319
2017-06-10 21:06:07.485933 EDT | AverageAbsQ                33.3515
2017-06-10 21:06:07.486222 EDT | AverageY                   33.3236
2017-06-10 21:06:07.486765 EDT | AverageAbsY                33.3368
2017-06-10 21:06:07.487096 EDT | AverageAbsQYDiff            0.747741
2017-06-10 21:06:07.487594 EDT | AverageAction               0.852126
2017-06-10 21:06:07.489511 EDT | PolicyRegParamNorm         56.8963
2017-06-10 21:06:07.489736 EDT | QFunRegParamNorm           69.4298
2017-06-10 21:06:07.490501 EDT | -----------------------  -----------
2017-06-10 21:06:07.491069 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #247 | Training started
2017-06-10 21:06:22.324987 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #247 | Training finished
2017-06-10 21:06:22.325992 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #247 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 21:06:22.326330 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #247 | Collecting samples for evaluation
2017-06-10 21:06:35.343948 EDT | -----------------------  -----------
2017-06-10 21:06:35.344738 EDT | Epoch                     247
2017-06-10 21:06:35.344946 EDT | Iteration                 247
2017-06-10 21:06:35.345114 EDT | AverageReturn             405.029
2017-06-10 21:06:35.345277 EDT | StdReturn                 332.239
2017-06-10 21:06:35.345436 EDT | MaxReturn                1684.93
2017-06-10 21:06:35.345757 EDT | MinReturn                 207.401
2017-06-10 21:06:35.345921 EDT | AverageEsReturn           360.375
2017-06-10 21:06:35.346103 EDT | StdEsReturn               182.472
2017-06-10 21:06:35.346396 EDT | MaxEsReturn               648.389
2017-06-10 21:06:35.346557 EDT | MinEsReturn                 9.46296
2017-06-10 21:06:35.346741 EDT | AverageDiscountedReturn   155.634
2017-06-10 21:06:35.346898 EDT | AverageQLoss                3.40374
2017-06-10 21:06:35.347054 EDT | AveragePolicySurr         -34.0287
2017-06-10 21:06:35.347209 EDT | AverageQ                   33.333
2017-06-10 21:06:35.347381 EDT | AverageAbsQ                33.3643
2017-06-10 21:06:35.347538 EDT | AverageY                   33.3365
2017-06-10 21:06:35.347904 EDT | AverageAbsY                33.3492
2017-06-10 21:06:35.348104 EDT | AverageAbsQYDiff            0.784655
2017-06-10 21:06:35.348347 EDT | AverageAction               0.846708
2017-06-10 21:06:35.348588 EDT | PolicyRegParamNorm         56.9868
2017-06-10 21:06:35.348824 EDT | QFunRegParamNorm           69.5733
2017-06-10 21:06:35.349040 EDT | -----------------------  -----------
2017-06-10 21:06:35.349331 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #248 | Training started
2017-06-10 21:06:50.906850 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #248 | Training finished
2017-06-10 21:06:50.907680 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #248 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 21:06:50.908065 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #248 | Collecting samples for evaluation
2017-06-10 21:07:03.352211 EDT | -----------------------  ----------
2017-06-10 21:07:03.353173 EDT | Epoch                    248
2017-06-10 21:07:03.353401 EDT | Iteration                248
2017-06-10 21:07:03.353757 EDT | AverageReturn            233.411
2017-06-10 21:07:03.354058 EDT | StdReturn                  9.21229
2017-06-10 21:07:03.354412 EDT | MaxReturn                259.493
2017-06-10 21:07:03.354594 EDT | MinReturn                221.901
2017-06-10 21:07:03.354775 EDT | AverageEsReturn          218.755
2017-06-10 21:07:03.354955 EDT | StdEsReturn               89.5242
2017-06-10 21:07:03.355138 EDT | MaxEsReturn              398.332
2017-06-10 21:07:03.355357 EDT | MinEsReturn              122.925
2017-06-10 21:07:03.355571 EDT | AverageDiscountedReturn  128.283
2017-06-10 21:07:03.355797 EDT | AverageQLoss               3.53724
2017-06-10 21:07:03.356033 EDT | AveragePolicySurr        -34.11
2017-06-10 21:07:03.356552 EDT | AverageQ                  33.3812
2017-06-10 21:07:03.357880 EDT | AverageAbsQ               33.4174
2017-06-10 21:07:03.358584 EDT | AverageY                  33.3829
2017-06-10 21:07:03.359327 EDT | AverageAbsY               33.3961
2017-06-10 21:07:03.359700 EDT | AverageAbsQYDiff           0.775642
2017-06-10 21:07:03.360067 EDT | AverageAction              0.863136
2017-06-10 21:07:03.360481 EDT | PolicyRegParamNorm        57.0718
2017-06-10 21:07:03.360638 EDT | QFunRegParamNorm          69.6755
2017-06-10 21:07:03.360801 EDT | -----------------------  ----------
2017-06-10 21:07:03.361114 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #249 | Training started
2017-06-10 21:07:18.485913 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #249 | Training finished
2017-06-10 21:07:18.486386 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #249 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 21:07:18.486765 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #249 | Collecting samples for evaluation
2017-06-10 21:07:31.141498 EDT | -----------------------  -----------
2017-06-10 21:07:31.142437 EDT | Epoch                     249
2017-06-10 21:07:31.142713 EDT | Iteration                 249
2017-06-10 21:07:31.142976 EDT | AverageReturn             254.687
2017-06-10 21:07:31.143226 EDT | StdReturn                 212.246
2017-06-10 21:07:31.143475 EDT | MaxReturn                2095.99
2017-06-10 21:07:31.143721 EDT | MinReturn                 173.62
2017-06-10 21:07:31.143966 EDT | AverageEsReturn           812.18
2017-06-10 21:07:31.144211 EDT | StdEsReturn               688.918
2017-06-10 21:07:31.144455 EDT | MaxEsReturn              1894.19
2017-06-10 21:07:31.144700 EDT | MinEsReturn               191.767
2017-06-10 21:07:31.144945 EDT | AverageDiscountedReturn   128.256
2017-06-10 21:07:31.145188 EDT | AverageQLoss                3.25171
2017-06-10 21:07:31.145432 EDT | AveragePolicySurr         -34.1251
2017-06-10 21:07:31.145675 EDT | AverageQ                   33.4252
2017-06-10 21:07:31.145940 EDT | AverageAbsQ                33.4602
2017-06-10 21:07:31.146185 EDT | AverageY                   33.426
2017-06-10 21:07:31.146428 EDT | AverageAbsY                33.4392
2017-06-10 21:07:31.146671 EDT | AverageAbsQYDiff            0.765288
2017-06-10 21:07:31.146915 EDT | AverageAction               0.828412
2017-06-10 21:07:31.147163 EDT | PolicyRegParamNorm         57.1471
2017-06-10 21:07:31.147406 EDT | QFunRegParamNorm           69.7802
2017-06-10 21:07:31.147648 EDT | -----------------------  -----------
2017-06-10 21:07:31.148035 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #250 | Training started
2017-06-10 21:07:46.182620 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #250 | Training finished
2017-06-10 21:07:46.183019 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #250 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 21:07:46.183335 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #250 | Collecting samples for evaluation
2017-06-10 21:07:58.381016 EDT | -----------------------  -----------
2017-06-10 21:07:58.381779 EDT | Epoch                     250
2017-06-10 21:07:58.382336 EDT | Iteration                 250
2017-06-10 21:07:58.382598 EDT | AverageReturn             715.245
2017-06-10 21:07:58.382847 EDT | StdReturn                 166.351
2017-06-10 21:07:58.383022 EDT | MaxReturn                1566.89
2017-06-10 21:07:58.383184 EDT | MinReturn                 233.015
2017-06-10 21:07:58.383378 EDT | AverageEsReturn           529.121
2017-06-10 21:07:58.383538 EDT | StdEsReturn               325.554
2017-06-10 21:07:58.383695 EDT | MaxEsReturn               880.397
2017-06-10 21:07:58.383932 EDT | MinEsReturn                37.446
2017-06-10 21:07:58.384170 EDT | AverageDiscountedReturn   221.771
2017-06-10 21:07:58.384340 EDT | AverageQLoss                3.32546
2017-06-10 21:07:58.384533 EDT | AveragePolicySurr         -34.0622
2017-06-10 21:07:58.385102 EDT | AverageQ                   33.3611
2017-06-10 21:07:58.385264 EDT | AverageAbsQ                33.3994
2017-06-10 21:07:58.385484 EDT | AverageY                   33.3648
2017-06-10 21:07:58.385917 EDT | AverageAbsY                33.3801
2017-06-10 21:07:58.386121 EDT | AverageAbsQYDiff            0.786738
2017-06-10 21:07:58.386376 EDT | AverageAction               0.808943
2017-06-10 21:07:58.386631 EDT | PolicyRegParamNorm         57.2552
2017-06-10 21:07:58.388454 EDT | QFunRegParamNorm           69.9124
2017-06-10 21:07:58.389387 EDT | -----------------------  -----------
2017-06-10 21:07:58.389715 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #251 | Training started
2017-06-10 21:08:12.274376 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #251 | Training finished
2017-06-10 21:08:12.275596 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #251 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 21:08:12.276141 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #251 | Collecting samples for evaluation
2017-06-10 21:08:24.984537 EDT | -----------------------  -----------
2017-06-10 21:08:24.985351 EDT | Epoch                     251
2017-06-10 21:08:24.985551 EDT | Iteration                 251
2017-06-10 21:08:24.985733 EDT | AverageReturn             424.741
2017-06-10 21:08:24.985904 EDT | StdReturn                 605.424
2017-06-10 21:08:24.986097 EDT | MaxReturn                2926.66
2017-06-10 21:08:24.986280 EDT | MinReturn                 216.814
2017-06-10 21:08:24.986462 EDT | AverageEsReturn           353.739
2017-06-10 21:08:24.986765 EDT | StdEsReturn               231.798
2017-06-10 21:08:24.986944 EDT | MaxEsReturn               728.034
2017-06-10 21:08:24.987769 EDT | MinEsReturn                45.8044
2017-06-10 21:08:24.991751 EDT | AverageDiscountedReturn   143.309
2017-06-10 21:08:24.991969 EDT | AverageQLoss                3.30241
2017-06-10 21:08:24.992144 EDT | AveragePolicySurr         -34.147
2017-06-10 21:08:24.992300 EDT | AverageQ                   33.4538
2017-06-10 21:08:24.992454 EDT | AverageAbsQ                33.4858
2017-06-10 21:08:24.992605 EDT | AverageY                   33.4537
2017-06-10 21:08:24.992755 EDT | AverageAbsY                33.4666
2017-06-10 21:08:24.992905 EDT | AverageAbsQYDiff            0.773094
2017-06-10 21:08:24.993055 EDT | AverageAction               0.865758
2017-06-10 21:08:24.993204 EDT | PolicyRegParamNorm         57.3814
2017-06-10 21:08:24.993356 EDT | QFunRegParamNorm           70.0143
2017-06-10 21:08:24.993514 EDT | -----------------------  -----------
2017-06-10 21:08:24.993788 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #252 | Training started
2017-06-10 21:08:40.655960 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #252 | Training finished
2017-06-10 21:08:40.657072 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #252 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 21:08:40.657290 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #252 | Collecting samples for evaluation
2017-06-10 21:08:51.877572 EDT | -----------------------  -----------
2017-06-10 21:08:51.878391 EDT | Epoch                     252
2017-06-10 21:08:51.878659 EDT | Iteration                 252
2017-06-10 21:08:51.878936 EDT | AverageReturn             851.475
2017-06-10 21:08:51.879106 EDT | StdReturn                 148.234
2017-06-10 21:08:51.879271 EDT | MaxReturn                1031.87
2017-06-10 21:08:51.879433 EDT | MinReturn                 277.625
2017-06-10 21:08:51.879594 EDT | AverageEsReturn           555.85
2017-06-10 21:08:51.879756 EDT | StdEsReturn               330.121
2017-06-10 21:08:51.880028 EDT | MaxEsReturn              1058.58
2017-06-10 21:08:51.880203 EDT | MinEsReturn               124.03
2017-06-10 21:08:51.880571 EDT | AverageDiscountedReturn   223.504
2017-06-10 21:08:51.880751 EDT | AverageQLoss                3.23846
2017-06-10 21:08:51.880964 EDT | AveragePolicySurr         -34.0729
2017-06-10 21:08:51.881205 EDT | AverageQ                   33.3608
2017-06-10 21:08:51.881367 EDT | AverageAbsQ                33.3897
2017-06-10 21:08:51.881528 EDT | AverageY                   33.3654
2017-06-10 21:08:51.881685 EDT | AverageAbsY                33.376
2017-06-10 21:08:51.881982 EDT | AverageAbsQYDiff            0.758736
2017-06-10 21:08:51.882205 EDT | AverageAction               0.888676
2017-06-10 21:08:51.882473 EDT | PolicyRegParamNorm         57.444
2017-06-10 21:08:51.883016 EDT | QFunRegParamNorm           70.0943
2017-06-10 21:08:51.883266 EDT | -----------------------  -----------
2017-06-10 21:08:51.883719 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #253 | Training started
2017-06-10 21:09:08.236451 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #253 | Training finished
2017-06-10 21:09:08.237459 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #253 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 21:09:08.237671 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #253 | Collecting samples for evaluation
2017-06-10 21:09:21.000641 EDT | -----------------------  -----------
2017-06-10 21:09:21.001499 EDT | Epoch                     253
2017-06-10 21:09:21.001955 EDT | Iteration                 253
2017-06-10 21:09:21.002375 EDT | AverageReturn             829.012
2017-06-10 21:09:21.002774 EDT | StdReturn                 683.108
2017-06-10 21:09:21.003193 EDT | MaxReturn                2132.64
2017-06-10 21:09:21.003604 EDT | MinReturn                 200.644
2017-06-10 21:09:21.004029 EDT | AverageEsReturn           499.192
2017-06-10 21:09:21.004463 EDT | StdEsReturn               265.98
2017-06-10 21:09:21.004862 EDT | MaxEsReturn               888.778
2017-06-10 21:09:21.005209 EDT | MinEsReturn               148.922
2017-06-10 21:09:21.005626 EDT | AverageDiscountedReturn   168.508
2017-06-10 21:09:21.006012 EDT | AverageQLoss                3.32885
2017-06-10 21:09:21.006391 EDT | AveragePolicySurr         -34.179
2017-06-10 21:09:21.006804 EDT | AverageQ                   33.4832
2017-06-10 21:09:21.007229 EDT | AverageAbsQ                33.5201
2017-06-10 21:09:21.007650 EDT | AverageY                   33.4859
2017-06-10 21:09:21.008036 EDT | AverageAbsY                33.5019
2017-06-10 21:09:21.008397 EDT | AverageAbsQYDiff            0.780263
2017-06-10 21:09:21.008820 EDT | AverageAction               0.861775
2017-06-10 21:09:21.009182 EDT | PolicyRegParamNorm         57.4384
2017-06-10 21:09:21.009866 EDT | QFunRegParamNorm           70.1721
2017-06-10 21:09:21.010571 EDT | -----------------------  -----------
2017-06-10 21:09:21.011535 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #254 | Training started
2017-06-10 21:09:36.878107 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #254 | Training finished
2017-06-10 21:09:36.879641 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #254 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 21:09:36.880189 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #254 | Collecting samples for evaluation
2017-06-10 21:09:49.556032 EDT | -----------------------  -----------
2017-06-10 21:09:49.557162 EDT | Epoch                     254
2017-06-10 21:09:49.558023 EDT | Iteration                 254
2017-06-10 21:09:49.558387 EDT | AverageReturn             810.522
2017-06-10 21:09:49.559001 EDT | StdReturn                 575.605
2017-06-10 21:09:49.559363 EDT | MaxReturn                2215.95
2017-06-10 21:09:49.559706 EDT | MinReturn                 219.338
2017-06-10 21:09:49.560051 EDT | AverageEsReturn           284.593
2017-06-10 21:09:49.560393 EDT | StdEsReturn               211.451
2017-06-10 21:09:49.560730 EDT | MaxEsReturn               626.599
2017-06-10 21:09:49.561073 EDT | MinEsReturn                11.2097
2017-06-10 21:09:49.561414 EDT | AverageDiscountedReturn   186.821
2017-06-10 21:09:49.561760 EDT | AverageQLoss                3.16758
2017-06-10 21:09:49.562104 EDT | AveragePolicySurr         -34.1245
2017-06-10 21:09:49.562443 EDT | AverageQ                   33.4333
2017-06-10 21:09:49.563037 EDT | AverageAbsQ                33.4661
2017-06-10 21:09:49.563488 EDT | AverageY                   33.4361
2017-06-10 21:09:49.563835 EDT | AverageAbsY                33.4499
2017-06-10 21:09:49.564174 EDT | AverageAbsQYDiff            0.766506
2017-06-10 21:09:49.564515 EDT | AverageAction               0.845789
2017-06-10 21:09:49.564971 EDT | PolicyRegParamNorm         57.5183
2017-06-10 21:09:49.565316 EDT | QFunRegParamNorm           70.2738
2017-06-10 21:09:49.565766 EDT | -----------------------  -----------
2017-06-10 21:09:49.566274 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #255 | Training started
2017-06-10 21:10:02.900893 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #255 | Training finished
2017-06-10 21:10:02.926044 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #255 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 21:10:02.926414 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #255 | Collecting samples for evaluation
2017-06-10 21:10:15.534755 EDT | -----------------------  ----------
2017-06-10 21:10:15.535743 EDT | Epoch                    255
2017-06-10 21:10:15.536117 EDT | Iteration                255
2017-06-10 21:10:15.536539 EDT | AverageReturn            348.681
2017-06-10 21:10:15.536953 EDT | StdReturn                122.624
2017-06-10 21:10:15.537379 EDT | MaxReturn                653.357
2017-06-10 21:10:15.537840 EDT | MinReturn                276.871
2017-06-10 21:10:15.538691 EDT | AverageEsReturn          328.007
2017-06-10 21:10:15.539434 EDT | StdEsReturn              169.193
2017-06-10 21:10:15.539882 EDT | MaxEsReturn              560.953
2017-06-10 21:10:15.542387 EDT | MinEsReturn               39.3647
2017-06-10 21:10:15.542725 EDT | AverageDiscountedReturn  158.695
2017-06-10 21:10:15.543148 EDT | AverageQLoss               3.43995
2017-06-10 21:10:15.543500 EDT | AveragePolicySurr        -34.1181
2017-06-10 21:10:15.543825 EDT | AverageQ                  33.4033
2017-06-10 21:10:15.544215 EDT | AverageAbsQ               33.4342
2017-06-10 21:10:15.544630 EDT | AverageY                  33.4049
2017-06-10 21:10:15.547727 EDT | AverageAbsY               33.4147
2017-06-10 21:10:15.548070 EDT | AverageAbsQYDiff           0.771097
2017-06-10 21:10:15.548392 EDT | AverageAction              0.876267
2017-06-10 21:10:15.548723 EDT | PolicyRegParamNorm        57.5629
2017-06-10 21:10:15.549061 EDT | QFunRegParamNorm          70.3783
2017-06-10 21:10:15.549370 EDT | -----------------------  ----------
2017-06-10 21:10:15.549886 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #256 | Training started
2017-06-10 21:10:31.165228 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #256 | Training finished
2017-06-10 21:10:31.165950 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #256 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 21:10:31.166327 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #256 | Collecting samples for evaluation
2017-06-10 21:10:43.702523 EDT | -----------------------  -----------
2017-06-10 21:10:43.706413 EDT | Epoch                     256
2017-06-10 21:10:43.706869 EDT | Iteration                 256
2017-06-10 21:10:43.707346 EDT | AverageReturn             400.858
2017-06-10 21:10:43.707684 EDT | StdReturn                 344.471
2017-06-10 21:10:43.708085 EDT | MaxReturn                1471.16
2017-06-10 21:10:43.708412 EDT | MinReturn                 203.518
2017-06-10 21:10:43.708745 EDT | AverageEsReturn           367.828
2017-06-10 21:10:43.709138 EDT | StdEsReturn               303.885
2017-06-10 21:10:43.709464 EDT | MaxEsReturn               784.211
2017-06-10 21:10:43.709812 EDT | MinEsReturn                40.6511
2017-06-10 21:10:43.710369 EDT | AverageDiscountedReturn   156.336
2017-06-10 21:10:43.710805 EDT | AverageQLoss                3.76582
2017-06-10 21:10:43.711144 EDT | AveragePolicySurr         -34.1627
2017-06-10 21:10:43.711478 EDT | AverageQ                   33.4346
2017-06-10 21:10:43.713247 EDT | AverageAbsQ                33.4772
2017-06-10 21:10:43.713671 EDT | AverageY                   33.4371
2017-06-10 21:10:43.715770 EDT | AverageAbsY                33.4547
2017-06-10 21:10:43.716086 EDT | AverageAbsQYDiff            0.789475
2017-06-10 21:10:43.716804 EDT | AverageAction               0.866029
2017-06-10 21:10:43.717516 EDT | PolicyRegParamNorm         57.6576
2017-06-10 21:10:43.717851 EDT | QFunRegParamNorm           70.5102
2017-06-10 21:10:43.718185 EDT | -----------------------  -----------
2017-06-10 21:10:43.718729 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #257 | Training started
2017-06-10 21:10:59.577471 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #257 | Training finished
2017-06-10 21:10:59.578875 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #257 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 21:10:59.579101 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #257 | Collecting samples for evaluation
2017-06-10 21:11:11.778937 EDT | -----------------------  -----------
2017-06-10 21:11:11.789997 EDT | Epoch                     257
2017-06-10 21:11:11.790252 EDT | Iteration                 257
2017-06-10 21:11:11.790469 EDT | AverageReturn             307.956
2017-06-10 21:11:11.790867 EDT | StdReturn                 268.018
2017-06-10 21:11:11.791229 EDT | MaxReturn                1546.73
2017-06-10 21:11:11.791415 EDT | MinReturn                 142.989
2017-06-10 21:11:11.791599 EDT | AverageEsReturn           304.8
2017-06-10 21:11:11.791865 EDT | StdEsReturn               152.435
2017-06-10 21:11:11.792227 EDT | MaxEsReturn               592.052
2017-06-10 21:11:11.792553 EDT | MinEsReturn               148.13
2017-06-10 21:11:11.792875 EDT | AverageDiscountedReturn   126.931
2017-06-10 21:11:11.793196 EDT | AverageQLoss                3.50703
2017-06-10 21:11:11.793551 EDT | AveragePolicySurr         -34.1139
2017-06-10 21:11:11.793924 EDT | AverageQ                   33.4405
2017-06-10 21:11:11.794308 EDT | AverageAbsQ                33.4779
2017-06-10 21:11:11.794682 EDT | AverageY                   33.4413
2017-06-10 21:11:11.795057 EDT | AverageAbsY                33.461
2017-06-10 21:11:11.795375 EDT | AverageAbsQYDiff            0.754669
2017-06-10 21:11:11.795554 EDT | AverageAction               0.827323
2017-06-10 21:11:11.795736 EDT | PolicyRegParamNorm         57.7364
2017-06-10 21:11:11.796075 EDT | QFunRegParamNorm           70.6377
2017-06-10 21:11:11.796252 EDT | -----------------------  -----------
2017-06-10 21:11:11.796585 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #258 | Training started
2017-06-10 21:11:26.488833 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #258 | Training finished
2017-06-10 21:11:26.489641 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #258 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 21:11:26.489901 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #258 | Collecting samples for evaluation
2017-06-10 21:11:38.951730 EDT | -----------------------  -----------
2017-06-10 21:11:38.953293 EDT | Epoch                     258
2017-06-10 21:11:38.953656 EDT | Iteration                 258
2017-06-10 21:11:38.954018 EDT | AverageReturn             950.861
2017-06-10 21:11:38.954309 EDT | StdReturn                 622.71
2017-06-10 21:11:38.954576 EDT | MaxReturn                2438.12
2017-06-10 21:11:38.954910 EDT | MinReturn                 254.094
2017-06-10 21:11:38.955244 EDT | AverageEsReturn           252.691
2017-06-10 21:11:38.955546 EDT | StdEsReturn               165.952
2017-06-10 21:11:38.955933 EDT | MaxEsReturn               502.968
2017-06-10 21:11:38.956288 EDT | MinEsReturn                30.0468
2017-06-10 21:11:38.956633 EDT | AverageDiscountedReturn   188.371
2017-06-10 21:11:38.956931 EDT | AverageQLoss                2.98889
2017-06-10 21:11:38.957206 EDT | AveragePolicySurr         -34.1028
2017-06-10 21:11:38.957537 EDT | AverageQ                   33.4143
2017-06-10 21:11:38.957899 EDT | AverageAbsQ                33.4471
2017-06-10 21:11:38.959149 EDT | AverageY                   33.4167
2017-06-10 21:11:38.959512 EDT | AverageAbsY                33.4327
2017-06-10 21:11:38.959842 EDT | AverageAbsQYDiff            0.734442
2017-06-10 21:11:38.960187 EDT | AverageAction               0.879492
2017-06-10 21:11:38.960532 EDT | PolicyRegParamNorm         57.8226
2017-06-10 21:11:38.960941 EDT | QFunRegParamNorm           70.7156
2017-06-10 21:11:38.961361 EDT | -----------------------  -----------
2017-06-10 21:11:38.961885 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #259 | Training started
2017-06-10 21:11:53.696308 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #259 | Training finished
2017-06-10 21:11:53.696730 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #259 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 21:11:53.697023 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #259 | Collecting samples for evaluation
2017-06-10 21:12:07.923246 EDT | -----------------------  -----------
2017-06-10 21:12:07.924188 EDT | Epoch                     259
2017-06-10 21:12:07.924555 EDT | Iteration                 259
2017-06-10 21:12:07.925028 EDT | AverageReturn            1421.96
2017-06-10 21:12:07.925378 EDT | StdReturn                 541.982
2017-06-10 21:12:07.925730 EDT | MaxReturn                2810.11
2017-06-10 21:12:07.926076 EDT | MinReturn                 692.244
2017-06-10 21:12:07.926413 EDT | AverageEsReturn           281.163
2017-06-10 21:12:07.926878 EDT | StdEsReturn               187.601
2017-06-10 21:12:07.927183 EDT | MaxEsReturn               540.005
2017-06-10 21:12:07.927438 EDT | MinEsReturn                33.4865
2017-06-10 21:12:07.927734 EDT | AverageDiscountedReturn   235.558
2017-06-10 21:12:07.928027 EDT | AverageQLoss                2.83565
2017-06-10 21:12:07.928306 EDT | AveragePolicySurr         -34.1196
2017-06-10 21:12:07.928783 EDT | AverageQ                   33.4487
2017-06-10 21:12:07.929260 EDT | AverageAbsQ                33.4846
2017-06-10 21:12:07.930957 EDT | AverageY                   33.4501
2017-06-10 21:12:07.932155 EDT | AverageAbsY                33.4652
2017-06-10 21:12:07.932691 EDT | AverageAbsQYDiff            0.738022
2017-06-10 21:12:07.933022 EDT | AverageAction               0.856212
2017-06-10 21:12:07.933362 EDT | PolicyRegParamNorm         57.8888
2017-06-10 21:12:07.933708 EDT | QFunRegParamNorm           70.7964
2017-06-10 21:12:07.934132 EDT | -----------------------  -----------
2017-06-10 21:12:07.934577 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #260 | Training started
2017-06-10 21:12:22.992260 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #260 | Training finished
2017-06-10 21:12:22.992830 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #260 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 21:12:22.993205 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #260 | Collecting samples for evaluation
2017-06-10 21:12:35.901304 EDT | -----------------------  ----------
2017-06-10 21:12:35.902780 EDT | Epoch                    260
2017-06-10 21:12:35.903082 EDT | Iteration                260
2017-06-10 21:12:35.903418 EDT | AverageReturn            240.934
2017-06-10 21:12:35.903840 EDT | StdReturn                  8.2719
2017-06-10 21:12:35.904185 EDT | MaxReturn                261.032
2017-06-10 21:12:35.904486 EDT | MinReturn                220.04
2017-06-10 21:12:35.904706 EDT | AverageEsReturn          415.086
2017-06-10 21:12:35.904933 EDT | StdEsReturn              182.597
2017-06-10 21:12:35.905250 EDT | MaxEsReturn              591.141
2017-06-10 21:12:35.905531 EDT | MinEsReturn              112.367
2017-06-10 21:12:35.905872 EDT | AverageDiscountedReturn  132.603
2017-06-10 21:12:35.906207 EDT | AverageQLoss               3.1864
2017-06-10 21:12:35.906694 EDT | AveragePolicySurr        -34.0378
2017-06-10 21:12:35.907100 EDT | AverageQ                  33.3734
2017-06-10 21:12:35.907427 EDT | AverageAbsQ               33.4036
2017-06-10 21:12:35.907839 EDT | AverageY                  33.377
2017-06-10 21:12:35.908203 EDT | AverageAbsY               33.3874
2017-06-10 21:12:35.908634 EDT | AverageAbsQYDiff           0.745128
2017-06-10 21:12:35.908951 EDT | AverageAction              0.752379
2017-06-10 21:12:35.910117 EDT | PolicyRegParamNorm        58.0157
2017-06-10 21:12:35.910644 EDT | QFunRegParamNorm          70.8633
2017-06-10 21:12:35.910978 EDT | -----------------------  ----------
2017-06-10 21:12:35.911578 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #261 | Training started
2017-06-10 21:12:51.402468 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #261 | Training finished
2017-06-10 21:12:51.410671 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #261 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 21:12:51.411246 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #261 | Collecting samples for evaluation
2017-06-10 21:13:03.267555 EDT | -----------------------  -----------
2017-06-10 21:13:03.268453 EDT | Epoch                     261
2017-06-10 21:13:03.268805 EDT | Iteration                 261
2017-06-10 21:13:03.269133 EDT | AverageReturn             828.709
2017-06-10 21:13:03.269461 EDT | StdReturn                 657.055
2017-06-10 21:13:03.270144 EDT | MaxReturn                3038.11
2017-06-10 21:13:03.272209 EDT | MinReturn                 218.816
2017-06-10 21:13:03.272612 EDT | AverageEsReturn           417.106
2017-06-10 21:13:03.272978 EDT | StdEsReturn               286.384
2017-06-10 21:13:03.273305 EDT | MaxEsReturn               924.559
2017-06-10 21:13:03.273628 EDT | MinEsReturn               108.922
2017-06-10 21:13:03.274461 EDT | AverageDiscountedReturn   190.387
2017-06-10 21:13:03.275146 EDT | AverageQLoss                3.22398
2017-06-10 21:13:03.275472 EDT | AveragePolicySurr         -34.0463
2017-06-10 21:13:03.275793 EDT | AverageQ                   33.362
2017-06-10 21:13:03.277214 EDT | AverageAbsQ                33.3963
2017-06-10 21:13:03.277542 EDT | AverageY                   33.3622
2017-06-10 21:13:03.278132 EDT | AverageAbsY                33.3743
2017-06-10 21:13:03.278689 EDT | AverageAbsQYDiff            0.757968
2017-06-10 21:13:03.279033 EDT | AverageAction               0.807451
2017-06-10 21:13:03.280250 EDT | PolicyRegParamNorm         58.1417
2017-06-10 21:13:03.280679 EDT | QFunRegParamNorm           70.9293
2017-06-10 21:13:03.281012 EDT | -----------------------  -----------
2017-06-10 21:13:03.281633 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #262 | Training started
2017-06-10 21:13:19.027919 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #262 | Training finished
2017-06-10 21:13:19.028776 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #262 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 21:13:19.029003 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #262 | Collecting samples for evaluation
2017-06-10 21:13:31.165049 EDT | -----------------------  -----------
2017-06-10 21:13:31.166015 EDT | Epoch                     262
2017-06-10 21:13:31.166371 EDT | Iteration                 262
2017-06-10 21:13:31.166713 EDT | AverageReturn             898.097
2017-06-10 21:13:31.167048 EDT | StdReturn                 589.748
2017-06-10 21:13:31.167383 EDT | MaxReturn                2486.66
2017-06-10 21:13:31.167712 EDT | MinReturn                 276.608
2017-06-10 21:13:31.168038 EDT | AverageEsReturn           395.893
2017-06-10 21:13:31.168366 EDT | StdEsReturn               220.866
2017-06-10 21:13:31.168693 EDT | MaxEsReturn               720.114
2017-06-10 21:13:31.169019 EDT | MinEsReturn               110.099
2017-06-10 21:13:31.169344 EDT | AverageDiscountedReturn   203.093
2017-06-10 21:13:31.169670 EDT | AverageQLoss                3.30252
2017-06-10 21:13:31.170007 EDT | AveragePolicySurr         -34.0865
2017-06-10 21:13:31.170333 EDT | AverageQ                   33.4086
2017-06-10 21:13:31.170658 EDT | AverageAbsQ                33.4407
2017-06-10 21:13:31.170982 EDT | AverageY                   33.4121
2017-06-10 21:13:31.171305 EDT | AverageAbsY                33.4254
2017-06-10 21:13:31.171628 EDT | AverageAbsQYDiff            0.736676
2017-06-10 21:13:31.171951 EDT | AverageAction               0.819452
2017-06-10 21:13:31.172278 EDT | PolicyRegParamNorm         58.2096
2017-06-10 21:13:31.172603 EDT | QFunRegParamNorm           71.0426
2017-06-10 21:13:31.172925 EDT | -----------------------  -----------
2017-06-10 21:13:31.173394 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #263 | Training started
2017-06-10 21:13:46.719264 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #263 | Training finished
2017-06-10 21:13:46.720014 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #263 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 21:13:46.720518 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #263 | Collecting samples for evaluation
2017-06-10 21:13:59.668544 EDT | -----------------------  -----------
2017-06-10 21:13:59.669746 EDT | Epoch                     263
2017-06-10 21:13:59.670242 EDT | Iteration                 263
2017-06-10 21:13:59.670715 EDT | AverageReturn             865.089
2017-06-10 21:13:59.671129 EDT | StdReturn                 254.543
2017-06-10 21:13:59.671741 EDT | MaxReturn                1783.66
2017-06-10 21:13:59.672270 EDT | MinReturn                 688.539
2017-06-10 21:13:59.672690 EDT | AverageEsReturn           411.579
2017-06-10 21:13:59.673214 EDT | StdEsReturn               177.467
2017-06-10 21:13:59.673784 EDT | MaxEsReturn               661.155
2017-06-10 21:13:59.674208 EDT | MinEsReturn               131.752
2017-06-10 21:13:59.674794 EDT | AverageDiscountedReturn   226.43
2017-06-10 21:13:59.675265 EDT | AverageQLoss                3.38093
2017-06-10 21:13:59.675815 EDT | AveragePolicySurr         -34.097
2017-06-10 21:13:59.676274 EDT | AverageQ                   33.3811
2017-06-10 21:13:59.676850 EDT | AverageAbsQ                33.4124
2017-06-10 21:13:59.677267 EDT | AverageY                   33.3859
2017-06-10 21:13:59.677824 EDT | AverageAbsY                33.3978
2017-06-10 21:13:59.678292 EDT | AverageAbsQYDiff            0.760399
2017-06-10 21:13:59.678837 EDT | AverageAction               0.807033
2017-06-10 21:13:59.679297 EDT | PolicyRegParamNorm         58.2771
2017-06-10 21:13:59.679860 EDT | QFunRegParamNorm           71.1761
2017-06-10 21:13:59.680291 EDT | -----------------------  -----------
2017-06-10 21:13:59.680911 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #264 | Training started
2017-06-10 21:14:13.619998 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #264 | Training finished
2017-06-10 21:14:13.620763 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #264 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 21:14:13.620991 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #264 | Collecting samples for evaluation
2017-06-10 21:14:26.904059 EDT | -----------------------  -----------
2017-06-10 21:14:26.905679 EDT | Epoch                     264
2017-06-10 21:14:26.905961 EDT | Iteration                 264
2017-06-10 21:14:26.906305 EDT | AverageReturn             930.771
2017-06-10 21:14:26.906506 EDT | StdReturn                 192.866
2017-06-10 21:14:26.906720 EDT | MaxReturn                1490.65
2017-06-10 21:14:26.906958 EDT | MinReturn                 672.015
2017-06-10 21:14:26.907153 EDT | AverageEsReturn           224.118
2017-06-10 21:14:26.907346 EDT | StdEsReturn               224.744
2017-06-10 21:14:26.907538 EDT | MaxEsReturn               647.257
2017-06-10 21:14:26.907731 EDT | MinEsReturn                26.1161
2017-06-10 21:14:26.908080 EDT | AverageDiscountedReturn   230.939
2017-06-10 21:14:26.908278 EDT | AverageQLoss                3.41585
2017-06-10 21:14:26.908497 EDT | AveragePolicySurr         -34.0861
2017-06-10 21:14:26.908793 EDT | AverageQ                   33.3987
2017-06-10 21:14:26.908983 EDT | AverageAbsQ                33.4304
2017-06-10 21:14:26.909810 EDT | AverageY                   33.3998
2017-06-10 21:14:26.910077 EDT | AverageAbsY                33.4102
2017-06-10 21:14:26.910361 EDT | AverageAbsQYDiff            0.757478
2017-06-10 21:14:26.910560 EDT | AverageAction               0.768439
2017-06-10 21:14:26.910756 EDT | PolicyRegParamNorm         58.326
2017-06-10 21:14:26.910950 EDT | QFunRegParamNorm           71.3018
2017-06-10 21:14:26.911258 EDT | -----------------------  -----------
2017-06-10 21:14:26.911671 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #265 | Training started
2017-06-10 21:14:41.934914 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #265 | Training finished
2017-06-10 21:14:41.935403 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #265 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 21:14:41.935895 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #265 | Collecting samples for evaluation
2017-06-10 21:14:53.694195 EDT | -----------------------  -----------
2017-06-10 21:14:53.696878 EDT | Epoch                     265
2017-06-10 21:14:53.697348 EDT | Iteration                 265
2017-06-10 21:14:53.697952 EDT | AverageReturn             966.771
2017-06-10 21:14:53.698227 EDT | StdReturn                 188.218
2017-06-10 21:14:53.698559 EDT | MaxReturn                1534.02
2017-06-10 21:14:53.698896 EDT | MinReturn                 785.307
2017-06-10 21:14:53.699233 EDT | AverageEsReturn           285.098
2017-06-10 21:14:53.699644 EDT | StdEsReturn               242.07
2017-06-10 21:14:53.700050 EDT | MaxEsReturn               669.483
2017-06-10 21:14:53.700355 EDT | MinEsReturn                33.6945
2017-06-10 21:14:53.700687 EDT | AverageDiscountedReturn   235.755
2017-06-10 21:14:53.701019 EDT | AverageQLoss                3.5912
2017-06-10 21:14:53.701353 EDT | AveragePolicySurr         -34.1055
2017-06-10 21:14:53.701790 EDT | AverageQ                   33.4262
2017-06-10 21:14:53.702407 EDT | AverageAbsQ                33.4577
2017-06-10 21:14:53.702679 EDT | AverageY                   33.4264
2017-06-10 21:14:53.702947 EDT | AverageAbsY                33.4367
2017-06-10 21:14:53.703206 EDT | AverageAbsQYDiff            0.762941
2017-06-10 21:14:53.703476 EDT | AverageAction               0.785828
2017-06-10 21:14:53.703722 EDT | PolicyRegParamNorm         58.433
2017-06-10 21:14:53.704430 EDT | QFunRegParamNorm           71.4368
2017-06-10 21:14:53.704785 EDT | -----------------------  -----------
2017-06-10 21:14:53.707528 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #266 | Training started
2017-06-10 21:15:08.782683 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #266 | Training finished
2017-06-10 21:15:08.783450 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #266 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 21:15:08.783649 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #266 | Collecting samples for evaluation
2017-06-10 21:15:20.969424 EDT | -----------------------  -----------
2017-06-10 21:15:20.970330 EDT | Epoch                     266
2017-06-10 21:15:20.970521 EDT | Iteration                 266
2017-06-10 21:15:20.970854 EDT | AverageReturn             324.24
2017-06-10 21:15:20.971087 EDT | StdReturn                 234.431
2017-06-10 21:15:20.971274 EDT | MaxReturn                1861.36
2017-06-10 21:15:20.971459 EDT | MinReturn                 267.128
2017-06-10 21:15:20.971739 EDT | AverageEsReturn           419.38
2017-06-10 21:15:20.971990 EDT | StdEsReturn               448.842
2017-06-10 21:15:20.972200 EDT | MaxEsReturn              1272.62
2017-06-10 21:15:20.972383 EDT | MinEsReturn                12.1973
2017-06-10 21:15:20.972600 EDT | AverageDiscountedReturn   148.842
2017-06-10 21:15:20.972837 EDT | AverageQLoss                2.99779
2017-06-10 21:15:20.973012 EDT | AveragePolicySurr         -34.0903
2017-06-10 21:15:20.973217 EDT | AverageQ                   33.4433
2017-06-10 21:15:20.973398 EDT | AverageAbsQ                33.4763
2017-06-10 21:15:20.973583 EDT | AverageY                   33.447
2017-06-10 21:15:20.974463 EDT | AverageAbsY                33.4613
2017-06-10 21:15:20.974731 EDT | AverageAbsQYDiff            0.711826
2017-06-10 21:15:20.975005 EDT | AverageAction               0.701217
2017-06-10 21:15:20.975274 EDT | PolicyRegParamNorm         58.468
2017-06-10 21:15:20.975504 EDT | QFunRegParamNorm           71.5464
2017-06-10 21:15:20.975772 EDT | -----------------------  -----------
2017-06-10 21:15:20.976209 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #267 | Training started
2017-06-10 21:15:35.403583 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #267 | Training finished
2017-06-10 21:15:35.404346 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #267 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 21:15:35.404539 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #267 | Collecting samples for evaluation
2017-06-10 21:15:47.423735 EDT | -----------------------  -----------
2017-06-10 21:15:47.425413 EDT | Epoch                     267
2017-06-10 21:15:47.425894 EDT | Iteration                 267
2017-06-10 21:15:47.426330 EDT | AverageReturn             820.267
2017-06-10 21:15:47.426691 EDT | StdReturn                 119.579
2017-06-10 21:15:47.427065 EDT | MaxReturn                1210.75
2017-06-10 21:15:47.427376 EDT | MinReturn                 716.873
2017-06-10 21:15:47.427998 EDT | AverageEsReturn           185.588
2017-06-10 21:15:47.428326 EDT | StdEsReturn               187.827
2017-06-10 21:15:47.428720 EDT | MaxEsReturn               610.161
2017-06-10 21:15:47.429081 EDT | MinEsReturn                 8.05199
2017-06-10 21:15:47.429418 EDT | AverageDiscountedReturn   232.141
2017-06-10 21:15:47.430786 EDT | AverageQLoss                3.64028
2017-06-10 21:15:47.431167 EDT | AveragePolicySurr         -33.9773
2017-06-10 21:15:47.431394 EDT | AverageQ                   33.3239
2017-06-10 21:15:47.431573 EDT | AverageAbsQ                33.3559
2017-06-10 21:15:47.431753 EDT | AverageY                   33.3266
2017-06-10 21:15:47.431987 EDT | AverageAbsY                33.3417
2017-06-10 21:15:47.432164 EDT | AverageAbsQYDiff            0.761038
2017-06-10 21:15:47.432364 EDT | AverageAction               0.772151
2017-06-10 21:15:47.432741 EDT | PolicyRegParamNorm         58.512
2017-06-10 21:15:47.433221 EDT | QFunRegParamNorm           71.6554
2017-06-10 21:15:47.433615 EDT | -----------------------  -----------
2017-06-10 21:15:47.435566 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #268 | Training started
2017-06-10 21:16:02.269061 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #268 | Training finished
2017-06-10 21:16:02.270194 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #268 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 21:16:02.270622 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #268 | Collecting samples for evaluation
2017-06-10 21:16:14.751920 EDT | -----------------------  -----------
2017-06-10 21:16:14.752413 EDT | Epoch                     268
2017-06-10 21:16:14.752794 EDT | Iteration                 268
2017-06-10 21:16:14.753060 EDT | AverageReturn             909.955
2017-06-10 21:16:14.753355 EDT | StdReturn                 955.248
2017-06-10 21:16:14.753671 EDT | MaxReturn                2969.71
2017-06-10 21:16:14.753965 EDT | MinReturn                 233.925
2017-06-10 21:16:14.754249 EDT | AverageEsReturn           207.903
2017-06-10 21:16:14.754739 EDT | StdEsReturn               166.322
2017-06-10 21:16:14.755066 EDT | MaxEsReturn               495.681
2017-06-10 21:16:14.757217 EDT | MinEsReturn                 8.18983
2017-06-10 21:16:14.758017 EDT | AverageDiscountedReturn   162.027
2017-06-10 21:16:14.759518 EDT | AverageQLoss                3.25526
2017-06-10 21:16:14.759874 EDT | AveragePolicySurr         -34.0982
2017-06-10 21:16:14.760232 EDT | AverageQ                   33.4059
2017-06-10 21:16:14.760581 EDT | AverageAbsQ                33.4345
2017-06-10 21:16:14.760925 EDT | AverageY                   33.4078
2017-06-10 21:16:14.761266 EDT | AverageAbsY                33.4185
2017-06-10 21:16:14.761607 EDT | AverageAbsQYDiff            0.748977
2017-06-10 21:16:14.761961 EDT | AverageAction               0.751458
2017-06-10 21:16:14.762302 EDT | PolicyRegParamNorm         58.6412
2017-06-10 21:16:14.762644 EDT | QFunRegParamNorm           71.7476
2017-06-10 21:16:14.762985 EDT | -----------------------  -----------
2017-06-10 21:16:14.763511 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #269 | Training started
2017-06-10 21:16:29.674195 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #269 | Training finished
2017-06-10 21:16:29.675736 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #269 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 21:16:29.676276 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #269 | Collecting samples for evaluation
2017-06-10 21:16:42.091147 EDT | -----------------------  -----------
2017-06-10 21:16:42.093571 EDT | Epoch                     269
2017-06-10 21:16:42.094557 EDT | Iteration                 269
2017-06-10 21:16:42.095660 EDT | AverageReturn            1044.19
2017-06-10 21:16:42.096006 EDT | StdReturn                 415.794
2017-06-10 21:16:42.096334 EDT | MaxReturn                1842.62
2017-06-10 21:16:42.096662 EDT | MinReturn                 289.324
2017-06-10 21:16:42.096977 EDT | AverageEsReturn           296.023
2017-06-10 21:16:42.097273 EDT | StdEsReturn               222.529
2017-06-10 21:16:42.097591 EDT | MaxEsReturn               679.156
2017-06-10 21:16:42.097951 EDT | MinEsReturn                 8.31629
2017-06-10 21:16:42.098301 EDT | AverageDiscountedReturn   217.531
2017-06-10 21:16:42.098625 EDT | AverageQLoss                2.96812
2017-06-10 21:16:42.098963 EDT | AveragePolicySurr         -34.1481
2017-06-10 21:16:42.099366 EDT | AverageQ                   33.4563
2017-06-10 21:16:42.099730 EDT | AverageAbsQ                33.4868
2017-06-10 21:16:42.100050 EDT | AverageY                   33.4572
2017-06-10 21:16:42.100348 EDT | AverageAbsY                33.4701
2017-06-10 21:16:42.100662 EDT | AverageAbsQYDiff            0.710485
2017-06-10 21:16:42.100983 EDT | AverageAction               0.759933
2017-06-10 21:16:42.101302 EDT | PolicyRegParamNorm         58.7096
2017-06-10 21:16:42.101614 EDT | QFunRegParamNorm           71.8129
2017-06-10 21:16:42.101918 EDT | -----------------------  -----------
2017-06-10 21:16:42.102416 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #270 | Training started
2017-06-10 21:16:57.071756 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #270 | Training finished
2017-06-10 21:16:57.072398 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #270 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 21:16:57.072725 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #270 | Collecting samples for evaluation
2017-06-10 21:17:08.894771 EDT | -----------------------  -----------
2017-06-10 21:17:08.895708 EDT | Epoch                     270
2017-06-10 21:17:08.896064 EDT | Iteration                 270
2017-06-10 21:17:08.896583 EDT | AverageReturn             706.681
2017-06-10 21:17:08.896969 EDT | StdReturn                 738.166
2017-06-10 21:17:08.897398 EDT | MaxReturn                3121.91
2017-06-10 21:17:08.898069 EDT | MinReturn                 274.089
2017-06-10 21:17:08.898590 EDT | AverageEsReturn           235.599
2017-06-10 21:17:08.899075 EDT | StdEsReturn               256.905
2017-06-10 21:17:08.899506 EDT | MaxEsReturn               933.781
2017-06-10 21:17:08.899979 EDT | MinEsReturn                 9.05715
2017-06-10 21:17:08.900317 EDT | AverageDiscountedReturn   176.776
2017-06-10 21:17:08.901043 EDT | AverageQLoss                2.83793
2017-06-10 21:17:08.901587 EDT | AveragePolicySurr         -34.1106
2017-06-10 21:17:08.902028 EDT | AverageQ                   33.4272
2017-06-10 21:17:08.902535 EDT | AverageAbsQ                33.457
2017-06-10 21:17:08.902960 EDT | AverageY                   33.4293
2017-06-10 21:17:08.903374 EDT | AverageAbsY                33.4386
2017-06-10 21:17:08.903852 EDT | AverageAbsQYDiff            0.719041
2017-06-10 21:17:08.904281 EDT | AverageAction               0.751566
2017-06-10 21:17:08.904696 EDT | PolicyRegParamNorm         58.8004
2017-06-10 21:17:08.905024 EDT | QFunRegParamNorm           71.9441
2017-06-10 21:17:08.905355 EDT | -----------------------  -----------
2017-06-10 21:17:08.905944 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #271 | Training started
2017-06-10 21:17:23.853889 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #271 | Training finished
2017-06-10 21:17:23.854801 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #271 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 21:17:23.855043 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #271 | Collecting samples for evaluation
2017-06-10 21:17:36.272807 EDT | -----------------------  -----------
2017-06-10 21:17:36.274194 EDT | Epoch                     271
2017-06-10 21:17:36.274622 EDT | Iteration                 271
2017-06-10 21:17:36.275038 EDT | AverageReturn            1361.25
2017-06-10 21:17:36.275413 EDT | StdReturn                 221.135
2017-06-10 21:17:36.275849 EDT | MaxReturn                1944.97
2017-06-10 21:17:36.276268 EDT | MinReturn                 938.244
2017-06-10 21:17:36.276586 EDT | AverageEsReturn           244.043
2017-06-10 21:17:36.276967 EDT | StdEsReturn               203.75
2017-06-10 21:17:36.277271 EDT | MaxEsReturn               576.074
2017-06-10 21:17:36.277611 EDT | MinEsReturn                 9.0345
2017-06-10 21:17:36.280167 EDT | AverageDiscountedReturn   230.042
2017-06-10 21:17:36.280541 EDT | AverageQLoss                3.28874
2017-06-10 21:17:36.280886 EDT | AveragePolicySurr         -34.1497
2017-06-10 21:17:36.281236 EDT | AverageQ                   33.4799
2017-06-10 21:17:36.281607 EDT | AverageAbsQ                33.5081
2017-06-10 21:17:36.281950 EDT | AverageY                   33.4826
2017-06-10 21:17:36.282363 EDT | AverageAbsY                33.494
2017-06-10 21:17:36.283223 EDT | AverageAbsQYDiff            0.736314
2017-06-10 21:17:36.283640 EDT | AverageAction               0.795795
2017-06-10 21:17:36.284061 EDT | PolicyRegParamNorm         58.927
2017-06-10 21:17:36.284801 EDT | QFunRegParamNorm           72.0786
2017-06-10 21:17:36.285237 EDT | -----------------------  -----------
2017-06-10 21:17:36.285740 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #272 | Training started
2017-06-10 21:17:51.524807 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #272 | Training finished
2017-06-10 21:17:51.526154 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #272 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 21:17:51.526545 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #272 | Collecting samples for evaluation
2017-06-10 21:18:04.570828 EDT | -----------------------  -----------
2017-06-10 21:18:04.573499 EDT | Epoch                     272
2017-06-10 21:18:04.574243 EDT | Iteration                 272
2017-06-10 21:18:04.575069 EDT | AverageReturn             324.742
2017-06-10 21:18:04.575874 EDT | StdReturn                 459.028
2017-06-10 21:18:04.576615 EDT | MaxReturn                2986.96
2017-06-10 21:18:04.577346 EDT | MinReturn                 230.337
2017-06-10 21:18:04.578259 EDT | AverageEsReturn           186.338
2017-06-10 21:18:04.578620 EDT | StdEsReturn               208.447
2017-06-10 21:18:04.579043 EDT | MaxEsReturn               602.372
2017-06-10 21:18:04.580991 EDT | MinEsReturn                10.3322
2017-06-10 21:18:04.581443 EDT | AverageDiscountedReturn   136.379
2017-06-10 21:18:04.581724 EDT | AverageQLoss                3.49188
2017-06-10 21:18:04.582023 EDT | AveragePolicySurr         -34.2176
2017-06-10 21:18:04.582422 EDT | AverageQ                   33.5362
2017-06-10 21:18:04.582811 EDT | AverageAbsQ                33.58
2017-06-10 21:18:04.583170 EDT | AverageY                   33.5368
2017-06-10 21:18:04.583353 EDT | AverageAbsY                33.5523
2017-06-10 21:18:04.583538 EDT | AverageAbsQYDiff            0.761987
2017-06-10 21:18:04.583784 EDT | AverageAction               0.73847
2017-06-10 21:18:04.583968 EDT | PolicyRegParamNorm         58.9783
2017-06-10 21:18:04.584253 EDT | QFunRegParamNorm           72.208
2017-06-10 21:18:04.584546 EDT | -----------------------  -----------
2017-06-10 21:18:04.584927 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #273 | Training started
2017-06-10 21:18:19.310725 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #273 | Training finished
2017-06-10 21:18:19.311786 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #273 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 21:18:19.312150 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #273 | Collecting samples for evaluation
2017-06-10 21:18:30.957245 EDT | -----------------------  -----------
2017-06-10 21:18:30.960085 EDT | Epoch                     273
2017-06-10 21:18:30.960589 EDT | Iteration                 273
2017-06-10 21:18:30.960953 EDT | AverageReturn             631.91
2017-06-10 21:18:30.961300 EDT | StdReturn                 675.132
2017-06-10 21:18:30.961648 EDT | MaxReturn                2543.03
2017-06-10 21:18:30.962006 EDT | MinReturn                 251.001
2017-06-10 21:18:30.962349 EDT | AverageEsReturn           315.141
2017-06-10 21:18:30.962691 EDT | StdEsReturn               240.855
2017-06-10 21:18:30.963033 EDT | MaxEsReturn               792.186
2017-06-10 21:18:30.963372 EDT | MinEsReturn                13.353
2017-06-10 21:18:30.963713 EDT | AverageDiscountedReturn   161.585
2017-06-10 21:18:30.964055 EDT | AverageQLoss                3.38269
2017-06-10 21:18:30.964398 EDT | AveragePolicySurr         -34.2089
2017-06-10 21:18:30.964739 EDT | AverageQ                   33.5324
2017-06-10 21:18:30.965079 EDT | AverageAbsQ                33.5632
2017-06-10 21:18:30.965424 EDT | AverageY                   33.5366
2017-06-10 21:18:30.965777 EDT | AverageAbsY                33.5485
2017-06-10 21:18:30.966118 EDT | AverageAbsQYDiff            0.735183
2017-06-10 21:18:30.966460 EDT | AverageAction               0.758845
2017-06-10 21:18:30.966805 EDT | PolicyRegParamNorm         59.0387
2017-06-10 21:18:30.967147 EDT | QFunRegParamNorm           72.3003
2017-06-10 21:18:30.967488 EDT | -----------------------  -----------
2017-06-10 21:18:30.968006 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #274 | Training started
2017-06-10 21:18:46.624083 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #274 | Training finished
2017-06-10 21:18:46.624892 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #274 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 21:18:46.625090 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #274 | Collecting samples for evaluation
2017-06-10 21:18:59.199645 EDT | -----------------------  -----------
2017-06-10 21:18:59.201362 EDT | Epoch                     274
2017-06-10 21:18:59.201566 EDT | Iteration                 274
2017-06-10 21:18:59.201925 EDT | AverageReturn             649.057
2017-06-10 21:18:59.202281 EDT | StdReturn                 649.144
2017-06-10 21:18:59.202559 EDT | MaxReturn                2913.84
2017-06-10 21:18:59.202747 EDT | MinReturn                 189.531
2017-06-10 21:18:59.202932 EDT | AverageEsReturn           216.805
2017-06-10 21:18:59.203187 EDT | StdEsReturn               213.419
2017-06-10 21:18:59.203365 EDT | MaxEsReturn               743.165
2017-06-10 21:18:59.203558 EDT | MinEsReturn                14.8619
2017-06-10 21:18:59.203800 EDT | AverageDiscountedReturn   168.343
2017-06-10 21:18:59.203976 EDT | AverageQLoss                3.00118
2017-06-10 21:18:59.204260 EDT | AveragePolicySurr         -34.2041
2017-06-10 21:18:59.204444 EDT | AverageQ                   33.5037
2017-06-10 21:18:59.204635 EDT | AverageAbsQ                33.5412
2017-06-10 21:18:59.204817 EDT | AverageY                   33.506
2017-06-10 21:18:59.204998 EDT | AverageAbsY                33.5221
2017-06-10 21:18:59.205178 EDT | AverageAbsQYDiff            0.721625
2017-06-10 21:18:59.205460 EDT | AverageAction               0.784806
2017-06-10 21:18:59.205652 EDT | PolicyRegParamNorm         59.214
2017-06-10 21:18:59.205844 EDT | QFunRegParamNorm           72.3838
2017-06-10 21:18:59.206117 EDT | -----------------------  -----------
2017-06-10 21:18:59.206413 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #275 | Training started
2017-06-10 21:19:13.914056 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #275 | Training finished
2017-06-10 21:19:13.914577 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #275 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 21:19:13.915008 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #275 | Collecting samples for evaluation
2017-06-10 21:19:27.892083 EDT | -----------------------  -----------
2017-06-10 21:19:27.895002 EDT | Epoch                     275
2017-06-10 21:19:27.895237 EDT | Iteration                 275
2017-06-10 21:19:27.895401 EDT | AverageReturn             957.96
2017-06-10 21:19:27.895557 EDT | StdReturn                 756.613
2017-06-10 21:19:27.895815 EDT | MaxReturn                3268.47
2017-06-10 21:19:27.896070 EDT | MinReturn                 304.52
2017-06-10 21:19:27.896289 EDT | AverageEsReturn           184.314
2017-06-10 21:19:27.896508 EDT | StdEsReturn               127.02
2017-06-10 21:19:27.896690 EDT | MaxEsReturn               394.537
2017-06-10 21:19:27.896881 EDT | MinEsReturn                 8.28415
2017-06-10 21:19:27.897061 EDT | AverageDiscountedReturn   197.664
2017-06-10 21:19:27.897240 EDT | AverageQLoss                3.09554
2017-06-10 21:19:27.897468 EDT | AveragePolicySurr         -34.2571
2017-06-10 21:19:27.897918 EDT | AverageQ                   33.5592
2017-06-10 21:19:27.898555 EDT | AverageAbsQ                33.6049
2017-06-10 21:19:27.899002 EDT | AverageY                   33.562
2017-06-10 21:19:27.899272 EDT | AverageAbsY                33.582
2017-06-10 21:19:27.899478 EDT | AverageAbsQYDiff            0.732301
2017-06-10 21:19:27.899698 EDT | AverageAction               0.807612
2017-06-10 21:19:27.899892 EDT | PolicyRegParamNorm         59.2882
2017-06-10 21:19:27.900073 EDT | QFunRegParamNorm           72.4848
2017-06-10 21:19:27.900252 EDT | -----------------------  -----------
2017-06-10 21:19:27.900677 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #276 | Training started
2017-06-10 21:19:41.434809 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #276 | Training finished
2017-06-10 21:19:41.435090 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #276 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 21:19:41.435272 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #276 | Collecting samples for evaluation
2017-06-10 21:19:54.567884 EDT | -----------------------  ----------
2017-06-10 21:19:54.569048 EDT | Epoch                    276
2017-06-10 21:19:54.569404 EDT | Iteration                276
2017-06-10 21:19:54.569765 EDT | AverageReturn            225.056
2017-06-10 21:19:54.570053 EDT | StdReturn                 25.3373
2017-06-10 21:19:54.570510 EDT | MaxReturn                271.295
2017-06-10 21:19:54.570844 EDT | MinReturn                160.563
2017-06-10 21:19:54.571175 EDT | AverageEsReturn          176.776
2017-06-10 21:19:54.571489 EDT | StdEsReturn              208.254
2017-06-10 21:19:54.572277 EDT | MaxEsReturn              802.757
2017-06-10 21:19:54.572594 EDT | MinEsReturn                7.80262
2017-06-10 21:19:54.573011 EDT | AverageDiscountedReturn  126.203
2017-06-10 21:19:54.573356 EDT | AverageQLoss               3.61734
2017-06-10 21:19:54.573644 EDT | AveragePolicySurr        -34.417
2017-06-10 21:19:54.573985 EDT | AverageQ                  33.7246
2017-06-10 21:19:54.574320 EDT | AverageAbsQ               33.7579
2017-06-10 21:19:54.574555 EDT | AverageY                  33.7245
2017-06-10 21:19:54.574718 EDT | AverageAbsY               33.7412
2017-06-10 21:19:54.574877 EDT | AverageAbsQYDiff           0.746755
2017-06-10 21:19:54.575063 EDT | AverageAction              0.783448
2017-06-10 21:19:54.575315 EDT | PolicyRegParamNorm        59.3947
2017-06-10 21:19:54.575477 EDT | QFunRegParamNorm          72.5928
2017-06-10 21:19:54.575763 EDT | -----------------------  ----------
2017-06-10 21:19:54.577812 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #277 | Training started
2017-06-10 21:20:09.035433 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #277 | Training finished
2017-06-10 21:20:09.036450 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #277 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 21:20:09.036838 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #277 | Collecting samples for evaluation
2017-06-10 21:20:21.226286 EDT | -----------------------  -----------
2017-06-10 21:20:21.227179 EDT | Epoch                     277
2017-06-10 21:20:21.227513 EDT | Iteration                 277
2017-06-10 21:20:21.227796 EDT | AverageReturn             525.372
2017-06-10 21:20:21.227957 EDT | StdReturn                 552.528
2017-06-10 21:20:21.228233 EDT | MaxReturn                2444.63
2017-06-10 21:20:21.228496 EDT | MinReturn                 255.474
2017-06-10 21:20:21.228652 EDT | AverageEsReturn           299.998
2017-06-10 21:20:21.228818 EDT | StdEsReturn               224.783
2017-06-10 21:20:21.229140 EDT | MaxEsReturn               627.532
2017-06-10 21:20:21.229620 EDT | MinEsReturn                 3.98521
2017-06-10 21:20:21.229979 EDT | AverageDiscountedReturn   160.28
2017-06-10 21:20:21.230256 EDT | AverageQLoss                3.40144
2017-06-10 21:20:21.230425 EDT | AveragePolicySurr         -34.2183
2017-06-10 21:20:21.230577 EDT | AverageQ                   33.5442
2017-06-10 21:20:21.230775 EDT | AverageAbsQ                33.5878
2017-06-10 21:20:21.231120 EDT | AverageY                   33.5482
2017-06-10 21:20:21.231292 EDT | AverageAbsY                33.5644
2017-06-10 21:20:21.231458 EDT | AverageAbsQYDiff            0.753277
2017-06-10 21:20:21.231637 EDT | AverageAction               0.726205
2017-06-10 21:20:21.231961 EDT | PolicyRegParamNorm         59.4857
2017-06-10 21:20:21.232131 EDT | QFunRegParamNorm           72.717
2017-06-10 21:20:21.232291 EDT | -----------------------  -----------
2017-06-10 21:20:21.232623 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #278 | Training started
2017-06-10 21:20:35.794128 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #278 | Training finished
2017-06-10 21:20:35.809808 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #278 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 21:20:35.810453 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #278 | Collecting samples for evaluation
2017-06-10 21:20:48.059665 EDT | -----------------------  -----------
2017-06-10 21:20:48.060388 EDT | Epoch                     278
2017-06-10 21:20:48.060608 EDT | Iteration                 278
2017-06-10 21:20:48.060794 EDT | AverageReturn            1065.21
2017-06-10 21:20:48.060955 EDT | StdReturn                 796.938
2017-06-10 21:20:48.061112 EDT | MaxReturn                2830.96
2017-06-10 21:20:48.061268 EDT | MinReturn                 285.1
2017-06-10 21:20:48.061424 EDT | AverageEsReturn           287.29
2017-06-10 21:20:48.061579 EDT | StdEsReturn               228.052
2017-06-10 21:20:48.061760 EDT | MaxEsReturn               769.423
2017-06-10 21:20:48.061917 EDT | MinEsReturn                16.9741
2017-06-10 21:20:48.062192 EDT | AverageDiscountedReturn   198.948
2017-06-10 21:20:48.062732 EDT | AverageQLoss                3.1977
2017-06-10 21:20:48.063076 EDT | AveragePolicySurr         -34.3784
2017-06-10 21:20:48.063402 EDT | AverageQ                   33.7191
2017-06-10 21:20:48.063723 EDT | AverageAbsQ                33.7576
2017-06-10 21:20:48.064077 EDT | AverageY                   33.7227
2017-06-10 21:20:48.064446 EDT | AverageAbsY                33.7425
2017-06-10 21:20:48.064750 EDT | AverageAbsQYDiff            0.72323
2017-06-10 21:20:48.065620 EDT | AverageAction               0.816339
2017-06-10 21:20:48.065922 EDT | PolicyRegParamNorm         59.5149
2017-06-10 21:20:48.066165 EDT | QFunRegParamNorm           72.8019
2017-06-10 21:20:48.066348 EDT | -----------------------  -----------
2017-06-10 21:20:48.066699 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #279 | Training started
2017-06-10 21:21:03.709586 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #279 | Training finished
2017-06-10 21:21:03.710557 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #279 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 21:21:03.710974 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #279 | Collecting samples for evaluation
2017-06-10 21:21:16.516736 EDT | -----------------------  -----------
2017-06-10 21:21:16.517724 EDT | Epoch                     279
2017-06-10 21:21:16.518610 EDT | Iteration                 279
2017-06-10 21:21:16.518948 EDT | AverageReturn             664.33
2017-06-10 21:21:16.519282 EDT | StdReturn                 265.483
2017-06-10 21:21:16.519497 EDT | MaxReturn                1789.81
2017-06-10 21:21:16.519685 EDT | MinReturn                 361.806
2017-06-10 21:21:16.519980 EDT | AverageEsReturn           245.465
2017-06-10 21:21:16.520246 EDT | StdEsReturn               177.774
2017-06-10 21:21:16.520533 EDT | MaxEsReturn               489.851
2017-06-10 21:21:16.520799 EDT | MinEsReturn                10.7263
2017-06-10 21:21:16.521081 EDT | AverageDiscountedReturn   207.991
2017-06-10 21:21:16.521339 EDT | AverageQLoss                2.94901
2017-06-10 21:21:16.521550 EDT | AveragePolicySurr         -34.293
2017-06-10 21:21:16.521716 EDT | AverageQ                   33.6371
2017-06-10 21:21:16.521881 EDT | AverageAbsQ                33.6861
2017-06-10 21:21:16.522066 EDT | AverageY                   33.6382
2017-06-10 21:21:16.522246 EDT | AverageAbsY                33.6645
2017-06-10 21:21:16.522425 EDT | AverageAbsQYDiff            0.720926
2017-06-10 21:21:16.522613 EDT | AverageAction               0.833008
2017-06-10 21:21:16.522791 EDT | PolicyRegParamNorm         59.6562
2017-06-10 21:21:16.522970 EDT | QFunRegParamNorm           72.8725
2017-06-10 21:21:16.523149 EDT | -----------------------  -----------
2017-06-10 21:21:16.523452 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #280 | Training started
2017-06-10 21:21:30.637002 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #280 | Training finished
2017-06-10 21:21:30.638021 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #280 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 21:21:30.638499 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #280 | Collecting samples for evaluation
2017-06-10 21:21:43.506304 EDT | -----------------------  -----------
2017-06-10 21:21:43.506775 EDT | Epoch                     280
2017-06-10 21:21:43.507125 EDT | Iteration                 280
2017-06-10 21:21:43.507469 EDT | AverageReturn            1029
2017-06-10 21:21:43.507809 EDT | StdReturn                 270.25
2017-06-10 21:21:43.508153 EDT | MaxReturn                1485.51
2017-06-10 21:21:43.508493 EDT | MinReturn                 412.855
2017-06-10 21:21:43.508831 EDT | AverageEsReturn           335.918
2017-06-10 21:21:43.509170 EDT | StdEsReturn               303.363
2017-06-10 21:21:43.509508 EDT | MaxEsReturn               777.077
2017-06-10 21:21:43.509862 EDT | MinEsReturn                12.069
2017-06-10 21:21:43.510203 EDT | AverageDiscountedReturn   234.227
2017-06-10 21:21:43.510592 EDT | AverageQLoss                3.31157
2017-06-10 21:21:43.511013 EDT | AveragePolicySurr         -34.2812
2017-06-10 21:21:43.511361 EDT | AverageQ                   33.6109
2017-06-10 21:21:43.511704 EDT | AverageAbsQ                33.6531
2017-06-10 21:21:43.512042 EDT | AverageY                   33.6133
2017-06-10 21:21:43.512505 EDT | AverageAbsY                33.6406
2017-06-10 21:21:43.512850 EDT | AverageAbsQYDiff            0.752095
2017-06-10 21:21:43.513284 EDT | AverageAction               0.843576
2017-06-10 21:21:43.513625 EDT | PolicyRegParamNorm         59.6878
2017-06-10 21:21:43.513975 EDT | QFunRegParamNorm           73.0035
2017-06-10 21:21:43.514317 EDT | -----------------------  -----------
2017-06-10 21:21:43.514991 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #281 | Training started
2017-06-10 21:21:59.014381 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #281 | Training finished
2017-06-10 21:21:59.015211 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #281 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 21:21:59.015435 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #281 | Collecting samples for evaluation
2017-06-10 21:22:11.660293 EDT | -----------------------  -----------
2017-06-10 21:22:11.661491 EDT | Epoch                     281
2017-06-10 21:22:11.661969 EDT | Iteration                 281
2017-06-10 21:22:11.662452 EDT | AverageReturn            1097.41
2017-06-10 21:22:11.662799 EDT | StdReturn                 204.032
2017-06-10 21:22:11.663137 EDT | MaxReturn                1566.71
2017-06-10 21:22:11.663554 EDT | MinReturn                 863.407
2017-06-10 21:22:11.663853 EDT | AverageEsReturn           290.364
2017-06-10 21:22:11.664190 EDT | StdEsReturn               330.274
2017-06-10 21:22:11.664624 EDT | MaxEsReturn               829.179
2017-06-10 21:22:11.665088 EDT | MinEsReturn                 7.33308
2017-06-10 21:22:11.665515 EDT | AverageDiscountedReturn   239.101
2017-06-10 21:22:11.665959 EDT | AverageQLoss                3.38614
2017-06-10 21:22:11.666413 EDT | AveragePolicySurr         -34.3351
2017-06-10 21:22:11.666840 EDT | AverageQ                   33.6724
2017-06-10 21:22:11.667277 EDT | AverageAbsQ                33.7185
2017-06-10 21:22:11.667758 EDT | AverageY                   33.675
2017-06-10 21:22:11.668160 EDT | AverageAbsY                33.7005
2017-06-10 21:22:11.668504 EDT | AverageAbsQYDiff            0.74478
2017-06-10 21:22:11.668906 EDT | AverageAction               0.853816
2017-06-10 21:22:11.669190 EDT | PolicyRegParamNorm         59.7189
2017-06-10 21:22:11.669526 EDT | QFunRegParamNorm           73.1073
2017-06-10 21:22:11.669875 EDT | -----------------------  -----------
2017-06-10 21:22:11.670490 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #282 | Training started
2017-06-10 21:22:26.053408 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #282 | Training finished
2017-06-10 21:22:26.054426 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #282 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 21:22:26.054892 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #282 | Collecting samples for evaluation
2017-06-10 21:22:37.944275 EDT | -----------------------  -----------
2017-06-10 21:22:37.944991 EDT | Epoch                     282
2017-06-10 21:22:37.945323 EDT | Iteration                 282
2017-06-10 21:22:37.945578 EDT | AverageReturn            1089.94
2017-06-10 21:22:37.945838 EDT | StdReturn                  49.3835
2017-06-10 21:22:37.946189 EDT | MaxReturn                1186.22
2017-06-10 21:22:37.946470 EDT | MinReturn                1000.48
2017-06-10 21:22:37.946741 EDT | AverageEsReturn           351.419
2017-06-10 21:22:37.946981 EDT | StdEsReturn               267.641
2017-06-10 21:22:37.947270 EDT | MaxEsReturn               688.639
2017-06-10 21:22:37.947583 EDT | MinEsReturn                 9.52304
2017-06-10 21:22:37.947910 EDT | AverageDiscountedReturn   255.856
2017-06-10 21:22:37.948293 EDT | AverageQLoss                2.92104
2017-06-10 21:22:37.948629 EDT | AveragePolicySurr         -34.3461
2017-06-10 21:22:37.949109 EDT | AverageQ                   33.6591
2017-06-10 21:22:37.949427 EDT | AverageAbsQ                33.7055
2017-06-10 21:22:37.949734 EDT | AverageY                   33.6618
2017-06-10 21:22:37.950050 EDT | AverageAbsY                33.6867
2017-06-10 21:22:37.951407 EDT | AverageAbsQYDiff            0.714326
2017-06-10 21:22:37.951723 EDT | AverageAction               0.852478
2017-06-10 21:22:37.952230 EDT | PolicyRegParamNorm         59.7901
2017-06-10 21:22:37.952389 EDT | QFunRegParamNorm           73.2351
2017-06-10 21:22:37.952543 EDT | -----------------------  -----------
2017-06-10 21:22:37.952859 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #283 | Training started
2017-06-10 21:22:53.076992 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #283 | Training finished
2017-06-10 21:22:53.077844 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #283 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 21:22:53.078038 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #283 | Collecting samples for evaluation
2017-06-10 21:23:05.059325 EDT | -----------------------  -----------
2017-06-10 21:23:05.060675 EDT | Epoch                     283
2017-06-10 21:23:05.060889 EDT | Iteration                 283
2017-06-10 21:23:05.061135 EDT | AverageReturn            1211.39
2017-06-10 21:23:05.061355 EDT | StdReturn                 229.281
2017-06-10 21:23:05.061596 EDT | MaxReturn                1818.48
2017-06-10 21:23:05.061987 EDT | MinReturn                 945.627
2017-06-10 21:23:05.062347 EDT | AverageEsReturn           244.08
2017-06-10 21:23:05.062681 EDT | StdEsReturn               188.33
2017-06-10 21:23:05.063043 EDT | MaxEsReturn               691.198
2017-06-10 21:23:05.063286 EDT | MinEsReturn                72.2558
2017-06-10 21:23:05.063527 EDT | AverageDiscountedReturn   245.211
2017-06-10 21:23:05.063818 EDT | AverageQLoss                3.46793
2017-06-10 21:23:05.064015 EDT | AveragePolicySurr         -34.441
2017-06-10 21:23:05.064220 EDT | AverageQ                   33.7834
2017-06-10 21:23:05.064412 EDT | AverageAbsQ                33.8248
2017-06-10 21:23:05.064646 EDT | AverageY                   33.7838
2017-06-10 21:23:05.064886 EDT | AverageAbsY                33.8122
2017-06-10 21:23:05.065079 EDT | AverageAbsQYDiff            0.741408
2017-06-10 21:23:05.065325 EDT | AverageAction               0.847209
2017-06-10 21:23:05.065604 EDT | PolicyRegParamNorm         59.862
2017-06-10 21:23:05.065855 EDT | QFunRegParamNorm           73.3193
2017-06-10 21:23:05.066097 EDT | -----------------------  -----------
2017-06-10 21:23:05.066665 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #284 | Training started
2017-06-10 21:23:19.462047 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #284 | Training finished
2017-06-10 21:23:19.477815 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #284 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 21:23:19.478473 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #284 | Collecting samples for evaluation
2017-06-10 21:23:32.382836 EDT | -----------------------  -----------
2017-06-10 21:23:32.384332 EDT | Epoch                     284
2017-06-10 21:23:32.384716 EDT | Iteration                 284
2017-06-10 21:23:32.385078 EDT | AverageReturn            1050.37
2017-06-10 21:23:32.385448 EDT | StdReturn                 114.453
2017-06-10 21:23:32.385624 EDT | MaxReturn                1285.24
2017-06-10 21:23:32.385953 EDT | MinReturn                 783.902
2017-06-10 21:23:32.386279 EDT | AverageEsReturn           308.875
2017-06-10 21:23:32.386600 EDT | StdEsReturn               188.344
2017-06-10 21:23:32.386925 EDT | MaxEsReturn               683.001
2017-06-10 21:23:32.387180 EDT | MinEsReturn                31.3174
2017-06-10 21:23:32.387363 EDT | AverageDiscountedReturn   251.381
2017-06-10 21:23:32.387544 EDT | AverageQLoss                3.25824
2017-06-10 21:23:32.387894 EDT | AveragePolicySurr         -34.2921
2017-06-10 21:23:32.388095 EDT | AverageQ                   33.6027
2017-06-10 21:23:32.388276 EDT | AverageAbsQ                33.6467
2017-06-10 21:23:32.388605 EDT | AverageY                   33.6038
2017-06-10 21:23:32.388944 EDT | AverageAbsY                33.6289
2017-06-10 21:23:32.389257 EDT | AverageAbsQYDiff            0.736472
2017-06-10 21:23:32.389728 EDT | AverageAction               0.853376
2017-06-10 21:23:32.390106 EDT | PolicyRegParamNorm         59.9609
2017-06-10 21:23:32.390418 EDT | QFunRegParamNorm           73.4278
2017-06-10 21:23:32.390696 EDT | -----------------------  -----------
2017-06-10 21:23:32.391173 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #285 | Training started
2017-06-10 21:23:46.467580 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #285 | Training finished
2017-06-10 21:23:46.468515 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #285 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 21:23:46.468875 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #285 | Collecting samples for evaluation
2017-06-10 21:23:59.066489 EDT | -----------------------  -----------
2017-06-10 21:23:59.067236 EDT | Epoch                     285
2017-06-10 21:23:59.067414 EDT | Iteration                 285
2017-06-10 21:23:59.067573 EDT | AverageReturn            1421.83
2017-06-10 21:23:59.067729 EDT | StdReturn                 676.149
2017-06-10 21:23:59.067936 EDT | MaxReturn                3187.66
2017-06-10 21:23:59.068137 EDT | MinReturn                 676.435
2017-06-10 21:23:59.068303 EDT | AverageEsReturn           345.735
2017-06-10 21:23:59.068457 EDT | StdEsReturn               299.493
2017-06-10 21:23:59.068608 EDT | MaxEsReturn               726.897
2017-06-10 21:23:59.068790 EDT | MinEsReturn                10.7115
2017-06-10 21:23:59.069043 EDT | AverageDiscountedReturn   229.975
2017-06-10 21:23:59.069315 EDT | AverageQLoss                3.26299
2017-06-10 21:23:59.069571 EDT | AveragePolicySurr         -34.3676
2017-06-10 21:23:59.069832 EDT | AverageQ                   33.7005
2017-06-10 21:23:59.070060 EDT | AverageAbsQ                33.7341
2017-06-10 21:23:59.070334 EDT | AverageY                   33.702
2017-06-10 21:23:59.070617 EDT | AverageAbsY                33.7197
2017-06-10 21:23:59.071049 EDT | AverageAbsQYDiff            0.725861
2017-06-10 21:23:59.071373 EDT | AverageAction               0.856835
2017-06-10 21:23:59.071687 EDT | PolicyRegParamNorm         60.0837
2017-06-10 21:23:59.072000 EDT | QFunRegParamNorm           73.4818
2017-06-10 21:23:59.072318 EDT | -----------------------  -----------
2017-06-10 21:23:59.072774 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #286 | Training started
2017-06-10 21:24:14.592466 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #286 | Training finished
2017-06-10 21:24:14.592986 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #286 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 21:24:14.593322 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #286 | Collecting samples for evaluation
2017-06-10 21:24:25.938979 EDT | -----------------------  -----------
2017-06-10 21:24:25.940277 EDT | Epoch                     286
2017-06-10 21:24:25.940644 EDT | Iteration                 286
2017-06-10 21:24:25.940843 EDT | AverageReturn             860.96
2017-06-10 21:24:25.941038 EDT | StdReturn                 230.319
2017-06-10 21:24:25.941255 EDT | MaxReturn                1350.67
2017-06-10 21:24:25.941783 EDT | MinReturn                 416.129
2017-06-10 21:24:25.942320 EDT | AverageEsReturn           327.741
2017-06-10 21:24:25.942797 EDT | StdEsReturn               305.77
2017-06-10 21:24:25.943203 EDT | MaxEsReturn               973.29
2017-06-10 21:24:25.943627 EDT | MinEsReturn                11.7918
2017-06-10 21:24:25.944166 EDT | AverageDiscountedReturn   237.917
2017-06-10 21:24:25.944484 EDT | AverageQLoss                3.45457
2017-06-10 21:24:25.944816 EDT | AveragePolicySurr         -34.4024
2017-06-10 21:24:25.945158 EDT | AverageQ                   33.7548
2017-06-10 21:24:25.945487 EDT | AverageAbsQ                33.7892
2017-06-10 21:24:25.945825 EDT | AverageY                   33.7587
2017-06-10 21:24:25.946388 EDT | AverageAbsY                33.7731
2017-06-10 21:24:25.946852 EDT | AverageAbsQYDiff            0.74518
2017-06-10 21:24:25.947043 EDT | AverageAction               0.883824
2017-06-10 21:24:25.947215 EDT | PolicyRegParamNorm         60.1487
2017-06-10 21:24:25.947403 EDT | QFunRegParamNorm           73.5313
2017-06-10 21:24:25.947579 EDT | -----------------------  -----------
2017-06-10 21:24:25.947853 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #287 | Training started
2017-06-10 21:24:41.142161 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #287 | Training finished
2017-06-10 21:24:41.142691 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #287 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 21:24:41.143077 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #287 | Collecting samples for evaluation
2017-06-10 21:24:53.289812 EDT | -----------------------  -----------
2017-06-10 21:24:53.290748 EDT | Epoch                     287
2017-06-10 21:24:53.291116 EDT | Iteration                 287
2017-06-10 21:24:53.291370 EDT | AverageReturn             996.516
2017-06-10 21:24:53.291703 EDT | StdReturn                 209.757
2017-06-10 21:24:53.292044 EDT | MaxReturn                1590.63
2017-06-10 21:24:53.292269 EDT | MinReturn                 637.73
2017-06-10 21:24:53.292601 EDT | AverageEsReturn           360.877
2017-06-10 21:24:53.292942 EDT | StdEsReturn               178.564
2017-06-10 21:24:53.293204 EDT | MaxEsReturn               607.411
2017-06-10 21:24:53.293533 EDT | MinEsReturn                26.2095
2017-06-10 21:24:53.293883 EDT | AverageDiscountedReturn   247.21
2017-06-10 21:24:53.294131 EDT | AverageQLoss                3.36473
2017-06-10 21:24:53.294462 EDT | AveragePolicySurr         -34.2962
2017-06-10 21:24:53.294798 EDT | AverageQ                   33.6354
2017-06-10 21:24:53.295122 EDT | AverageAbsQ                33.6686
2017-06-10 21:24:53.295454 EDT | AverageY                   33.6372
2017-06-10 21:24:53.295782 EDT | AverageAbsY                33.6523
2017-06-10 21:24:53.296108 EDT | AverageAbsQYDiff            0.726605
2017-06-10 21:24:53.296444 EDT | AverageAction               0.829461
2017-06-10 21:24:53.296787 EDT | PolicyRegParamNorm         60.3151
2017-06-10 21:24:53.297093 EDT | QFunRegParamNorm           73.6711
2017-06-10 21:24:53.297949 EDT | -----------------------  -----------
2017-06-10 21:24:53.298421 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #288 | Training started
2017-06-10 21:25:07.670834 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #288 | Training finished
2017-06-10 21:25:07.671957 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #288 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 21:25:07.672286 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #288 | Collecting samples for evaluation
2017-06-10 21:25:20.518758 EDT | -----------------------  -----------
2017-06-10 21:25:20.519692 EDT | Epoch                     288
2017-06-10 21:25:20.519905 EDT | Iteration                 288
2017-06-10 21:25:20.520079 EDT | AverageReturn            1162.59
2017-06-10 21:25:20.520373 EDT | StdReturn                 360.186
2017-06-10 21:25:20.520542 EDT | MaxReturn                2637.14
2017-06-10 21:25:20.520764 EDT | MinReturn                 826.751
2017-06-10 21:25:20.520928 EDT | AverageEsReturn           468.233
2017-06-10 21:25:20.521090 EDT | StdEsReturn               295.615
2017-06-10 21:25:20.521250 EDT | MaxEsReturn               984.654
2017-06-10 21:25:20.521424 EDT | MinEsReturn                 8.41455
2017-06-10 21:25:20.521627 EDT | AverageDiscountedReturn   251.898
2017-06-10 21:25:20.521998 EDT | AverageQLoss                3.11587
2017-06-10 21:25:20.522459 EDT | AveragePolicySurr         -34.3908
2017-06-10 21:25:20.523122 EDT | AverageQ                   33.7565
2017-06-10 21:25:20.523592 EDT | AverageAbsQ                33.792
2017-06-10 21:25:20.524021 EDT | AverageY                   33.7562
2017-06-10 21:25:20.524390 EDT | AverageAbsY                33.7716
2017-06-10 21:25:20.524619 EDT | AverageAbsQYDiff            0.714507
2017-06-10 21:25:20.524816 EDT | AverageAction               0.88818
2017-06-10 21:25:20.525098 EDT | PolicyRegParamNorm         60.381
2017-06-10 21:25:20.525384 EDT | QFunRegParamNorm           73.7756
2017-06-10 21:25:20.525579 EDT | -----------------------  -----------
2017-06-10 21:25:20.526081 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #289 | Training started
2017-06-10 21:25:35.984391 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #289 | Training finished
2017-06-10 21:25:35.985261 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #289 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 21:25:35.985586 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #289 | Collecting samples for evaluation
2017-06-10 21:25:48.176067 EDT | -----------------------  -----------
2017-06-10 21:25:48.178311 EDT | Epoch                     289
2017-06-10 21:25:48.178700 EDT | Iteration                 289
2017-06-10 21:25:48.179069 EDT | AverageReturn            1076.05
2017-06-10 21:25:48.179415 EDT | StdReturn                 490.766
2017-06-10 21:25:48.179893 EDT | MaxReturn                1974.84
2017-06-10 21:25:48.180361 EDT | MinReturn                 296.55
2017-06-10 21:25:48.180791 EDT | AverageEsReturn           288.323
2017-06-10 21:25:48.181131 EDT | StdEsReturn               241.601
2017-06-10 21:25:48.181418 EDT | MaxEsReturn               612.791
2017-06-10 21:25:48.181906 EDT | MinEsReturn                26.983
2017-06-10 21:25:48.182321 EDT | AverageDiscountedReturn   227.521
2017-06-10 21:25:48.183399 EDT | AverageQLoss                3.31816
2017-06-10 21:25:48.183630 EDT | AveragePolicySurr         -34.3731
2017-06-10 21:25:48.183829 EDT | AverageQ                   33.7529
2017-06-10 21:25:48.184076 EDT | AverageAbsQ                33.7852
2017-06-10 21:25:48.184240 EDT | AverageY                   33.7581
2017-06-10 21:25:48.184467 EDT | AverageAbsY                33.7669
2017-06-10 21:25:48.184867 EDT | AverageAbsQYDiff            0.723879
2017-06-10 21:25:48.185184 EDT | AverageAction               0.849349
2017-06-10 21:25:48.185357 EDT | PolicyRegParamNorm         60.4549
2017-06-10 21:25:48.185559 EDT | QFunRegParamNorm           73.8231
2017-06-10 21:25:48.185750 EDT | -----------------------  -----------
2017-06-10 21:25:48.186467 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #290 | Training started
2017-06-10 21:26:02.333839 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #290 | Training finished
2017-06-10 21:26:02.334894 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #290 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 21:26:02.335381 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #290 | Collecting samples for evaluation
2017-06-10 21:26:14.949180 EDT | -----------------------  -----------
2017-06-10 21:26:14.951311 EDT | Epoch                     290
2017-06-10 21:26:14.951571 EDT | Iteration                 290
2017-06-10 21:26:14.951843 EDT | AverageReturn             984.886
2017-06-10 21:26:14.952125 EDT | StdReturn                 391.607
2017-06-10 21:26:14.952389 EDT | MaxReturn                1855.66
2017-06-10 21:26:14.952670 EDT | MinReturn                 406.349
2017-06-10 21:26:14.952944 EDT | AverageEsReturn           472.463
2017-06-10 21:26:14.953253 EDT | StdEsReturn               337.167
2017-06-10 21:26:14.953537 EDT | MaxEsReturn               958.781
2017-06-10 21:26:14.953832 EDT | MinEsReturn               115.291
2017-06-10 21:26:14.954142 EDT | AverageDiscountedReturn   242.099
2017-06-10 21:26:14.954413 EDT | AverageQLoss                3.14711
2017-06-10 21:26:14.954713 EDT | AveragePolicySurr         -34.2811
2017-06-10 21:26:14.955023 EDT | AverageQ                   33.6388
2017-06-10 21:26:14.955373 EDT | AverageAbsQ                33.6635
2017-06-10 21:26:14.955736 EDT | AverageY                   33.6399
2017-06-10 21:26:14.956051 EDT | AverageAbsY                33.6493
2017-06-10 21:26:14.956377 EDT | AverageAbsQYDiff            0.710572
2017-06-10 21:26:14.956749 EDT | AverageAction               0.837752
2017-06-10 21:26:14.957090 EDT | PolicyRegParamNorm         60.5344
2017-06-10 21:26:14.957407 EDT | QFunRegParamNorm           73.9087
2017-06-10 21:26:14.957736 EDT | -----------------------  -----------
2017-06-10 21:26:14.958894 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #291 | Training started
2017-06-10 21:26:29.470729 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #291 | Training finished
2017-06-10 21:26:29.471636 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #291 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 21:26:29.471965 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #291 | Collecting samples for evaluation
2017-06-10 21:26:41.676823 EDT | -----------------------  -----------
2017-06-10 21:26:41.677370 EDT | Epoch                     291
2017-06-10 21:26:41.677755 EDT | Iteration                 291
2017-06-10 21:26:41.678195 EDT | AverageReturn            1074.43
2017-06-10 21:26:41.678555 EDT | StdReturn                 686.567
2017-06-10 21:26:41.678905 EDT | MaxReturn                2776.03
2017-06-10 21:26:41.679275 EDT | MinReturn                 301.442
2017-06-10 21:26:41.679617 EDT | AverageEsReturn           265.478
2017-06-10 21:26:41.680086 EDT | StdEsReturn               195.662
2017-06-10 21:26:41.680271 EDT | MaxEsReturn               542.776
2017-06-10 21:26:41.680750 EDT | MinEsReturn                31.0209
2017-06-10 21:26:41.681049 EDT | AverageDiscountedReturn   218.628
2017-06-10 21:26:41.681232 EDT | AverageQLoss                3.40504
2017-06-10 21:26:41.681447 EDT | AveragePolicySurr         -34.3145
2017-06-10 21:26:41.681633 EDT | AverageQ                   33.6862
2017-06-10 21:26:41.681908 EDT | AverageAbsQ                33.7163
2017-06-10 21:26:41.682177 EDT | AverageY                   33.6883
2017-06-10 21:26:41.682358 EDT | AverageAbsY                33.7009
2017-06-10 21:26:41.682541 EDT | AverageAbsQYDiff            0.722483
2017-06-10 21:26:41.682723 EDT | AverageAction               0.883633
2017-06-10 21:26:41.682904 EDT | PolicyRegParamNorm         60.5704
2017-06-10 21:26:41.683148 EDT | QFunRegParamNorm           74.0243
2017-06-10 21:26:41.683331 EDT | -----------------------  -----------
2017-06-10 21:26:41.683859 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #292 | Training started
2017-06-10 21:26:56.129756 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #292 | Training finished
2017-06-10 21:26:56.130659 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #292 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 21:26:56.130854 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #292 | Collecting samples for evaluation
2017-06-10 21:27:08.790632 EDT | -----------------------  -----------
2017-06-10 21:27:08.791450 EDT | Epoch                     292
2017-06-10 21:27:08.791647 EDT | Iteration                 292
2017-06-10 21:27:08.791859 EDT | AverageReturn            1046.93
2017-06-10 21:27:08.792074 EDT | StdReturn                 415.809
2017-06-10 21:27:08.792302 EDT | MaxReturn                1674.72
2017-06-10 21:27:08.792485 EDT | MinReturn                 315.253
2017-06-10 21:27:08.792666 EDT | AverageEsReturn           354.143
2017-06-10 21:27:08.792931 EDT | StdEsReturn               171.6
2017-06-10 21:27:08.793161 EDT | MaxEsReturn               669.653
2017-06-10 21:27:08.793345 EDT | MinEsReturn               154.687
2017-06-10 21:27:08.793557 EDT | AverageDiscountedReturn   227.977
2017-06-10 21:27:08.793755 EDT | AverageQLoss                3.30474
2017-06-10 21:27:08.793937 EDT | AveragePolicySurr         -34.2709
2017-06-10 21:27:08.794121 EDT | AverageQ                   33.6277
2017-06-10 21:27:08.794370 EDT | AverageAbsQ                33.6583
2017-06-10 21:27:08.794645 EDT | AverageY                   33.6277
2017-06-10 21:27:08.794928 EDT | AverageAbsY                33.6389
2017-06-10 21:27:08.795687 EDT | AverageAbsQYDiff            0.717004
2017-06-10 21:27:08.796052 EDT | AverageAction               0.862707
2017-06-10 21:27:08.796325 EDT | PolicyRegParamNorm         60.6444
2017-06-10 21:27:08.796599 EDT | QFunRegParamNorm           74.136
2017-06-10 21:27:08.796808 EDT | -----------------------  -----------
2017-06-10 21:27:08.797262 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #293 | Training started
2017-06-10 21:27:23.631021 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #293 | Training finished
2017-06-10 21:27:23.632025 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #293 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 21:27:23.632417 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #293 | Collecting samples for evaluation
2017-06-10 21:27:36.387250 EDT | -----------------------  -----------
2017-06-10 21:27:36.388156 EDT | Epoch                     293
2017-06-10 21:27:36.388440 EDT | Iteration                 293
2017-06-10 21:27:36.388697 EDT | AverageReturn             618.35
2017-06-10 21:27:36.388952 EDT | StdReturn                 220.165
2017-06-10 21:27:36.389202 EDT | MaxReturn                1778.7
2017-06-10 21:27:36.389450 EDT | MinReturn                 480.57
2017-06-10 21:27:36.389732 EDT | AverageEsReturn           255.405
2017-06-10 21:27:36.390000 EDT | StdEsReturn               171.355
2017-06-10 21:27:36.390257 EDT | MaxEsReturn               574.498
2017-06-10 21:27:36.390512 EDT | MinEsReturn                11.7157
2017-06-10 21:27:36.390768 EDT | AverageDiscountedReturn   211.755
2017-06-10 21:27:36.391024 EDT | AverageQLoss                3.17146
2017-06-10 21:27:36.391278 EDT | AveragePolicySurr         -34.2438
2017-06-10 21:27:36.391534 EDT | AverageQ                   33.6257
2017-06-10 21:27:36.391878 EDT | AverageAbsQ                33.6553
2017-06-10 21:27:36.392215 EDT | AverageY                   33.6273
2017-06-10 21:27:36.392530 EDT | AverageAbsY                33.6405
2017-06-10 21:27:36.392786 EDT | AverageAbsQYDiff            0.701641
2017-06-10 21:27:36.392999 EDT | AverageAction               0.871178
2017-06-10 21:27:36.393151 EDT | PolicyRegParamNorm         60.718
2017-06-10 21:27:36.393311 EDT | QFunRegParamNorm           74.2568
2017-06-10 21:27:36.393498 EDT | -----------------------  -----------
2017-06-10 21:27:36.393815 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #294 | Training started
2017-06-10 21:27:50.966619 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #294 | Training finished
2017-06-10 21:27:50.967318 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #294 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 21:27:50.967560 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #294 | Collecting samples for evaluation
2017-06-10 21:28:05.193170 EDT | -----------------------  -----------
2017-06-10 21:28:05.194697 EDT | Epoch                     294
2017-06-10 21:28:05.194898 EDT | Iteration                 294
2017-06-10 21:28:05.195059 EDT | AverageReturn            2392.51
2017-06-10 21:28:05.195215 EDT | StdReturn                 978.637
2017-06-10 21:28:05.195372 EDT | MaxReturn                3543.33
2017-06-10 21:28:05.195523 EDT | MinReturn                 274.068
2017-06-10 21:28:05.195672 EDT | AverageEsReturn           333.054
2017-06-10 21:28:05.195822 EDT | StdEsReturn               212.646
2017-06-10 21:28:05.195970 EDT | MaxEsReturn               596.315
2017-06-10 21:28:05.196240 EDT | MinEsReturn                41.5593
2017-06-10 21:28:05.196507 EDT | AverageDiscountedReturn   227.243
2017-06-10 21:28:05.196829 EDT | AverageQLoss                3.23372
2017-06-10 21:28:05.197145 EDT | AveragePolicySurr         -34.2983
2017-06-10 21:28:05.197425 EDT | AverageQ                   33.6614
2017-06-10 21:28:05.197714 EDT | AverageAbsQ                33.6993
2017-06-10 21:28:05.197977 EDT | AverageY                   33.6624
2017-06-10 21:28:05.198134 EDT | AverageAbsY                33.6798
2017-06-10 21:28:05.198295 EDT | AverageAbsQYDiff            0.732164
2017-06-10 21:28:05.198606 EDT | AverageAction               0.867616
2017-06-10 21:28:05.198797 EDT | PolicyRegParamNorm         60.7942
2017-06-10 21:28:05.198981 EDT | QFunRegParamNorm           74.3564
2017-06-10 21:28:05.199162 EDT | -----------------------  -----------
2017-06-10 21:28:05.199532 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #295 | Training started
2017-06-10 21:28:21.075718 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #295 | Training finished
2017-06-10 21:28:21.076463 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #295 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 21:28:21.076662 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #295 | Collecting samples for evaluation
2017-06-10 21:28:32.899036 EDT | -----------------------  -----------
2017-06-10 21:28:32.900951 EDT | Epoch                     295
2017-06-10 21:28:32.902370 EDT | Iteration                 295
2017-06-10 21:28:32.902552 EDT | AverageReturn            1497.17
2017-06-10 21:28:32.902930 EDT | StdReturn                 706.479
2017-06-10 21:28:32.903395 EDT | MaxReturn                3263.03
2017-06-10 21:28:32.903743 EDT | MinReturn                 672.605
2017-06-10 21:28:32.906564 EDT | AverageEsReturn           419.197
2017-06-10 21:28:32.906989 EDT | StdEsReturn               248.118
2017-06-10 21:28:32.907404 EDT | MaxEsReturn               739.161
2017-06-10 21:28:32.907668 EDT | MinEsReturn                30.95
2017-06-10 21:28:32.907836 EDT | AverageDiscountedReturn   233.498
2017-06-10 21:28:32.908119 EDT | AverageQLoss                2.9243
2017-06-10 21:28:32.908295 EDT | AveragePolicySurr         -34.1947
2017-06-10 21:28:32.908457 EDT | AverageQ                   33.5345
2017-06-10 21:28:32.908699 EDT | AverageAbsQ                33.5649
2017-06-10 21:28:32.908907 EDT | AverageY                   33.5378
2017-06-10 21:28:32.909160 EDT | AverageAbsY                33.5503
2017-06-10 21:28:32.909327 EDT | AverageAbsQYDiff            0.704378
2017-06-10 21:28:32.909504 EDT | AverageAction               0.856293
2017-06-10 21:28:32.909779 EDT | PolicyRegParamNorm         60.8729
2017-06-10 21:28:32.909978 EDT | QFunRegParamNorm           74.478
2017-06-10 21:28:32.910289 EDT | -----------------------  -----------
2017-06-10 21:28:32.910759 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #296 | Training started
2017-06-10 21:28:49.042710 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #296 | Training finished
2017-06-10 21:28:49.045495 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #296 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 21:28:49.047454 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #296 | Collecting samples for evaluation
2017-06-10 21:29:01.922673 EDT | -----------------------  -----------
2017-06-10 21:29:01.923601 EDT | Epoch                     296
2017-06-10 21:29:01.923831 EDT | Iteration                 296
2017-06-10 21:29:01.924061 EDT | AverageReturn            1317.11
2017-06-10 21:29:01.924247 EDT | StdReturn                 675.906
2017-06-10 21:29:01.924429 EDT | MaxReturn                3227.4
2017-06-10 21:29:01.924808 EDT | MinReturn                 391.923
2017-06-10 21:29:01.927442 EDT | AverageEsReturn           582.892
2017-06-10 21:29:01.927895 EDT | StdEsReturn               174.01
2017-06-10 21:29:01.929216 EDT | MaxEsReturn               878.974
2017-06-10 21:29:01.929643 EDT | MinEsReturn               431.923
2017-06-10 21:29:01.929988 EDT | AverageDiscountedReturn   235.838
2017-06-10 21:29:01.930369 EDT | AverageQLoss                2.79821
2017-06-10 21:29:01.930723 EDT | AveragePolicySurr         -34.2657
2017-06-10 21:29:01.931044 EDT | AverageQ                   33.6469
2017-06-10 21:29:01.931461 EDT | AverageAbsQ                33.6781
2017-06-10 21:29:01.932296 EDT | AverageY                   33.646
2017-06-10 21:29:01.932723 EDT | AverageAbsY                33.659
2017-06-10 21:29:01.933143 EDT | AverageAbsQYDiff            0.688103
2017-06-10 21:29:01.933471 EDT | AverageAction               0.864661
2017-06-10 21:29:01.933915 EDT | PolicyRegParamNorm         60.9071
2017-06-10 21:29:01.934076 EDT | QFunRegParamNorm           74.5947
2017-06-10 21:29:01.934231 EDT | -----------------------  -----------
2017-06-10 21:29:01.934503 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #297 | Training started
2017-06-10 21:29:17.992798 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #297 | Training finished
2017-06-10 21:29:17.993561 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #297 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 21:29:17.993815 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #297 | Collecting samples for evaluation
2017-06-10 21:29:31.876960 EDT | -----------------------  -----------
2017-06-10 21:29:31.877924 EDT | Epoch                     297
2017-06-10 21:29:31.878474 EDT | Iteration                 297
2017-06-10 21:29:31.878904 EDT | AverageReturn            1096.87
2017-06-10 21:29:31.879248 EDT | StdReturn                 938.206
2017-06-10 21:29:31.879516 EDT | MaxReturn                3384.91
2017-06-10 21:29:31.879911 EDT | MinReturn                 265.254
2017-06-10 21:29:31.880343 EDT | AverageEsReturn           589.985
2017-06-10 21:29:31.880766 EDT | StdEsReturn               360.32
2017-06-10 21:29:31.881119 EDT | MaxEsReturn              1130.95
2017-06-10 21:29:31.882155 EDT | MinEsReturn               166.962
2017-06-10 21:29:31.882507 EDT | AverageDiscountedReturn   202.057
2017-06-10 21:29:31.882934 EDT | AverageQLoss                3.43849
2017-06-10 21:29:31.883370 EDT | AveragePolicySurr         -34.2527
2017-06-10 21:29:31.883778 EDT | AverageQ                   33.5868
2017-06-10 21:29:31.884273 EDT | AverageAbsQ                33.616
2017-06-10 21:29:31.885145 EDT | AverageY                   33.5908
2017-06-10 21:29:31.885511 EDT | AverageAbsY                33.6009
2017-06-10 21:29:31.885947 EDT | AverageAbsQYDiff            0.750165
2017-06-10 21:29:31.886386 EDT | AverageAction               0.869816
2017-06-10 21:29:31.886804 EDT | PolicyRegParamNorm         60.9955
2017-06-10 21:29:31.887222 EDT | QFunRegParamNorm           74.7552
2017-06-10 21:29:31.887655 EDT | -----------------------  -----------
2017-06-10 21:29:31.888233 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #298 | Training started
2017-06-10 21:29:46.628119 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #298 | Training finished
2017-06-10 21:29:46.636974 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #298 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 21:29:46.637899 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #298 | Collecting samples for evaluation
2017-06-10 21:29:58.770161 EDT | -----------------------  -----------
2017-06-10 21:29:58.771196 EDT | Epoch                     298
2017-06-10 21:29:58.771400 EDT | Iteration                 298
2017-06-10 21:29:58.771617 EDT | AverageReturn             912.025
2017-06-10 21:29:58.771816 EDT | StdReturn                 439.938
2017-06-10 21:29:58.772011 EDT | MaxReturn                2441.64
2017-06-10 21:29:58.772205 EDT | MinReturn                 336.143
2017-06-10 21:29:58.772671 EDT | AverageEsReturn           247.315
2017-06-10 21:29:58.773247 EDT | StdEsReturn               150.635
2017-06-10 21:29:58.778170 EDT | MaxEsReturn               581.053
2017-06-10 21:29:58.778466 EDT | MinEsReturn                39.6702
2017-06-10 21:29:58.778671 EDT | AverageDiscountedReturn   206.395
2017-06-10 21:29:58.778869 EDT | AverageQLoss                3.07884
2017-06-10 21:29:58.779064 EDT | AveragePolicySurr         -34.2062
2017-06-10 21:29:58.779259 EDT | AverageQ                   33.5494
2017-06-10 21:29:58.779451 EDT | AverageAbsQ                33.5809
2017-06-10 21:29:58.779644 EDT | AverageY                   33.55
2017-06-10 21:29:58.779836 EDT | AverageAbsY                33.5605
2017-06-10 21:29:58.780027 EDT | AverageAbsQYDiff            0.698889
2017-06-10 21:29:58.780217 EDT | AverageAction               0.855593
2017-06-10 21:29:58.780407 EDT | PolicyRegParamNorm         61.131
2017-06-10 21:29:58.780597 EDT | QFunRegParamNorm           74.8591
2017-06-10 21:29:58.780779 EDT | -----------------------  -----------
2017-06-10 21:29:58.781217 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #299 | Training started
2017-06-10 21:30:12.952425 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #299 | Training finished
2017-06-10 21:30:12.953767 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #299 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 21:30:12.954452 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #299 | Collecting samples for evaluation
2017-06-10 21:30:25.692887 EDT | -----------------------  -----------
2017-06-10 21:30:25.694019 EDT | Epoch                     299
2017-06-10 21:30:25.694469 EDT | Iteration                 299
2017-06-10 21:30:25.694892 EDT | AverageReturn             496.333
2017-06-10 21:30:25.695310 EDT | StdReturn                 638.652
2017-06-10 21:30:25.696105 EDT | MaxReturn                3285.33
2017-06-10 21:30:25.696531 EDT | MinReturn                 240.62
2017-06-10 21:30:25.696959 EDT | AverageEsReturn           243.943
2017-06-10 21:30:25.697375 EDT | StdEsReturn               227.014
2017-06-10 21:30:25.697986 EDT | MaxEsReturn               710.636
2017-06-10 21:30:25.698507 EDT | MinEsReturn                19.812
2017-06-10 21:30:25.698894 EDT | AverageDiscountedReturn   157.157
2017-06-10 21:30:25.699319 EDT | AverageQLoss                3.16537
2017-06-10 21:30:25.700912 EDT | AveragePolicySurr         -34.3069
2017-06-10 21:30:25.701452 EDT | AverageQ                   33.6909
2017-06-10 21:30:25.702070 EDT | AverageAbsQ                33.7175
2017-06-10 21:30:25.702497 EDT | AverageY                   33.6927
2017-06-10 21:30:25.702987 EDT | AverageAbsY                33.6993
2017-06-10 21:30:25.703404 EDT | AverageAbsQYDiff            0.696803
2017-06-10 21:30:25.704752 EDT | AverageAction               0.817022
2017-06-10 21:30:25.705415 EDT | PolicyRegParamNorm         61.2124
2017-06-10 21:30:25.706128 EDT | QFunRegParamNorm           74.9963
2017-06-10 21:30:25.706907 EDT | -----------------------  -----------
2017-06-10 21:30:25.707886 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #300 | Training started
2017-06-10 21:30:41.615879 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #300 | Training finished
2017-06-10 21:30:41.616836 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #300 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 21:30:41.617204 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #300 | Collecting samples for evaluation
2017-06-10 21:30:53.962367 EDT | -----------------------  -----------
2017-06-10 21:30:53.963600 EDT | Epoch                     300
2017-06-10 21:30:53.963962 EDT | Iteration                 300
2017-06-10 21:30:53.964772 EDT | AverageReturn             982.364
2017-06-10 21:30:53.966021 EDT | StdReturn                 741.761
2017-06-10 21:30:53.966355 EDT | MaxReturn                3008.77
2017-06-10 21:30:53.967314 EDT | MinReturn                 294.316
2017-06-10 21:30:53.967593 EDT | AverageEsReturn           500.586
2017-06-10 21:30:53.968189 EDT | StdEsReturn               400.085
2017-06-10 21:30:53.968484 EDT | MaxEsReturn              1026.22
2017-06-10 21:30:53.968774 EDT | MinEsReturn                16.6101
2017-06-10 21:30:53.969054 EDT | AverageDiscountedReturn   199.926
2017-06-10 21:30:53.969366 EDT | AverageQLoss                3.22035
2017-06-10 21:30:53.969668 EDT | AveragePolicySurr         -34.1817
2017-06-10 21:30:53.970020 EDT | AverageQ                   33.5534
2017-06-10 21:30:53.970372 EDT | AverageAbsQ                33.582
2017-06-10 21:30:53.970730 EDT | AverageY                   33.5564
2017-06-10 21:30:53.971091 EDT | AverageAbsY                33.5649
2017-06-10 21:30:53.971446 EDT | AverageAbsQYDiff            0.716863
2017-06-10 21:30:53.971807 EDT | AverageAction               0.861234
2017-06-10 21:30:53.972165 EDT | PolicyRegParamNorm         61.3095
2017-06-10 21:30:53.972521 EDT | QFunRegParamNorm           75.1068
2017-06-10 21:30:53.972878 EDT | -----------------------  -----------
2017-06-10 21:30:53.973416 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #301 | Training started
2017-06-10 21:31:09.930125 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #301 | Training finished
2017-06-10 21:31:09.931101 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #301 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 21:31:09.931462 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #301 | Collecting samples for evaluation
2017-06-10 21:31:21.505142 EDT | -----------------------  -----------
2017-06-10 21:31:21.506341 EDT | Epoch                     301
2017-06-10 21:31:21.506880 EDT | Iteration                 301
2017-06-10 21:31:21.507285 EDT | AverageReturn            1263.76
2017-06-10 21:31:21.508052 EDT | StdReturn                 427.349
2017-06-10 21:31:21.508495 EDT | MaxReturn                2248.16
2017-06-10 21:31:21.508915 EDT | MinReturn                 297.121
2017-06-10 21:31:21.509600 EDT | AverageEsReturn           320.541
2017-06-10 21:31:21.510711 EDT | StdEsReturn               250.531
2017-06-10 21:31:21.511194 EDT | MaxEsReturn               687.873
2017-06-10 21:31:21.511602 EDT | MinEsReturn                28.0349
2017-06-10 21:31:21.512024 EDT | AverageDiscountedReturn   226.71
2017-06-10 21:31:21.513171 EDT | AverageQLoss                3.14478
2017-06-10 21:31:21.513724 EDT | AveragePolicySurr         -34.369
2017-06-10 21:31:21.514166 EDT | AverageQ                   33.715
2017-06-10 21:31:21.514577 EDT | AverageAbsQ                33.7394
2017-06-10 21:31:21.515077 EDT | AverageY                   33.7155
2017-06-10 21:31:21.515484 EDT | AverageAbsY                33.7211
2017-06-10 21:31:21.515873 EDT | AverageAbsQYDiff            0.715273
2017-06-10 21:31:21.516326 EDT | AverageAction               0.865723
2017-06-10 21:31:21.516724 EDT | PolicyRegParamNorm         61.363
2017-06-10 21:31:21.516996 EDT | QFunRegParamNorm           75.2252
2017-06-10 21:31:21.517315 EDT | -----------------------  -----------
2017-06-10 21:31:21.517818 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #302 | Training started
2017-06-10 21:31:35.763228 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #302 | Training finished
2017-06-10 21:31:35.764103 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #302 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 21:31:35.764502 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #302 | Collecting samples for evaluation
2017-06-10 21:31:49.052594 EDT | -----------------------  -----------
2017-06-10 21:31:49.053359 EDT | Epoch                     302
2017-06-10 21:31:49.053698 EDT | Iteration                 302
2017-06-10 21:31:49.054769 EDT | AverageReturn             936.945
2017-06-10 21:31:49.055062 EDT | StdReturn                 446.036
2017-06-10 21:31:49.055721 EDT | MaxReturn                2962.58
2017-06-10 21:31:49.056014 EDT | MinReturn                 520.09
2017-06-10 21:31:49.057185 EDT | AverageEsReturn           328.445
2017-06-10 21:31:49.057868 EDT | StdEsReturn               203.52
2017-06-10 21:31:49.058921 EDT | MaxEsReturn               754.935
2017-06-10 21:31:49.059426 EDT | MinEsReturn                25.4458
2017-06-10 21:31:49.061030 EDT | AverageDiscountedReturn   231.303
2017-06-10 21:31:49.061615 EDT | AverageQLoss                2.75055
2017-06-10 21:31:49.063156 EDT | AveragePolicySurr         -34.388
2017-06-10 21:31:49.063518 EDT | AverageQ                   33.7505
2017-06-10 21:31:49.063871 EDT | AverageAbsQ                33.7793
2017-06-10 21:31:49.064375 EDT | AverageY                   33.7538
2017-06-10 21:31:49.066544 EDT | AverageAbsY                33.7628
2017-06-10 21:31:49.067229 EDT | AverageAbsQYDiff            0.689264
2017-06-10 21:31:49.067886 EDT | AverageAction               0.857199
2017-06-10 21:31:49.068573 EDT | PolicyRegParamNorm         61.4421
2017-06-10 21:31:49.069784 EDT | QFunRegParamNorm           75.359
2017-06-10 21:31:49.070785 EDT | -----------------------  -----------
2017-06-10 21:31:49.071974 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #303 | Training started
2017-06-10 21:32:03.214705 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #303 | Training finished
2017-06-10 21:32:03.216485 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #303 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 21:32:03.216914 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #303 | Collecting samples for evaluation
2017-06-10 21:32:15.720979 EDT | -----------------------  ----------
2017-06-10 21:32:15.723403 EDT | Epoch                     303
2017-06-10 21:32:15.723924 EDT | Iteration                 303
2017-06-10 21:32:15.724377 EDT | AverageReturn             656.58
2017-06-10 21:32:15.724966 EDT | StdReturn                 591.38
2017-06-10 21:32:15.725424 EDT | MaxReturn                2815.88
2017-06-10 21:32:15.725903 EDT | MinReturn                 213.788
2017-06-10 21:32:15.726349 EDT | AverageEsReturn           368.222
2017-06-10 21:32:15.726801 EDT | StdEsReturn               166.446
2017-06-10 21:32:15.727245 EDT | MaxEsReturn               630.32
2017-06-10 21:32:15.727792 EDT | MinEsReturn               160.026
2017-06-10 21:32:15.728242 EDT | AverageDiscountedReturn   172.689
2017-06-10 21:32:15.728685 EDT | AverageQLoss                3.06721
2017-06-10 21:32:15.729129 EDT | AveragePolicySurr         -34.2887
2017-06-10 21:32:15.729573 EDT | AverageQ                   33.6203
2017-06-10 21:32:15.730021 EDT | AverageAbsQ                33.6465
2017-06-10 21:32:15.730463 EDT | AverageY                   33.6214
2017-06-10 21:32:15.730906 EDT | AverageAbsY                33.6333
2017-06-10 21:32:15.731346 EDT | AverageAbsQYDiff            0.70351
2017-06-10 21:32:15.731785 EDT | AverageAction               0.81752
2017-06-10 21:32:15.732230 EDT | PolicyRegParamNorm         61.5132
2017-06-10 21:32:15.732674 EDT | QFunRegParamNorm           75.43
2017-06-10 21:32:15.733213 EDT | -----------------------  ----------
2017-06-10 21:32:15.733844 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #304 | Training started
2017-06-10 21:32:30.700944 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #304 | Training finished
2017-06-10 21:32:30.702264 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #304 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 21:32:30.702667 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #304 | Collecting samples for evaluation
2017-06-10 21:32:42.310269 EDT | -----------------------  -----------
2017-06-10 21:32:42.311023 EDT | Epoch                     304
2017-06-10 21:32:42.311501 EDT | Iteration                 304
2017-06-10 21:32:42.311955 EDT | AverageReturn             932.051
2017-06-10 21:32:42.312398 EDT | StdReturn                 429.993
2017-06-10 21:32:42.312854 EDT | MaxReturn                2845.39
2017-06-10 21:32:42.313301 EDT | MinReturn                 352.468
2017-06-10 21:32:42.313774 EDT | AverageEsReturn           368.208
2017-06-10 21:32:42.315699 EDT | StdEsReturn               285.205
2017-06-10 21:32:42.316525 EDT | MaxEsReturn               940.457
2017-06-10 21:32:42.316973 EDT | MinEsReturn                35.4902
2017-06-10 21:32:42.317418 EDT | AverageDiscountedReturn   208.26
2017-06-10 21:32:42.317881 EDT | AverageQLoss                2.99043
2017-06-10 21:32:42.318328 EDT | AveragePolicySurr         -34.4096
2017-06-10 21:32:42.318776 EDT | AverageQ                   33.7611
2017-06-10 21:32:42.319223 EDT | AverageAbsQ                33.7928
2017-06-10 21:32:42.319672 EDT | AverageY                   33.7645
2017-06-10 21:32:42.320118 EDT | AverageAbsY                33.7717
2017-06-10 21:32:42.320560 EDT | AverageAbsQYDiff            0.710583
2017-06-10 21:32:42.321004 EDT | AverageAction               0.864046
2017-06-10 21:32:42.321448 EDT | PolicyRegParamNorm         61.6454
2017-06-10 21:32:42.321917 EDT | QFunRegParamNorm           75.5462
2017-06-10 21:32:42.322367 EDT | -----------------------  -----------
2017-06-10 21:32:42.322994 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #305 | Training started
2017-06-10 21:32:57.869814 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #305 | Training finished
2017-06-10 21:32:57.870380 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #305 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 21:32:57.870582 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #305 | Collecting samples for evaluation
2017-06-10 21:33:10.093067 EDT | -----------------------  -----------
2017-06-10 21:33:10.093924 EDT | Epoch                     305
2017-06-10 21:33:10.094107 EDT | Iteration                 305
2017-06-10 21:33:10.094267 EDT | AverageReturn            1506.74
2017-06-10 21:33:10.094424 EDT | StdReturn                 984.089
2017-06-10 21:33:10.094682 EDT | MaxReturn                3408.71
2017-06-10 21:33:10.094925 EDT | MinReturn                 297.973
2017-06-10 21:33:10.095081 EDT | AverageEsReturn           337.504
2017-06-10 21:33:10.095234 EDT | StdEsReturn               193.833
2017-06-10 21:33:10.095384 EDT | MaxEsReturn               632.282
2017-06-10 21:33:10.095664 EDT | MinEsReturn                25.2656
2017-06-10 21:33:10.095845 EDT | AverageDiscountedReturn   228.803
2017-06-10 21:33:10.096056 EDT | AverageQLoss                3.01038
2017-06-10 21:33:10.096211 EDT | AveragePolicySurr         -34.2487
2017-06-10 21:33:10.096362 EDT | AverageQ                   33.6063
2017-06-10 21:33:10.096512 EDT | AverageAbsQ                33.6306
2017-06-10 21:33:10.096700 EDT | AverageY                   33.6068
2017-06-10 21:33:10.096853 EDT | AverageAbsY                33.6144
2017-06-10 21:33:10.097022 EDT | AverageAbsQYDiff            0.692973
2017-06-10 21:33:10.097224 EDT | AverageAction               0.840823
2017-06-10 21:33:10.097392 EDT | PolicyRegParamNorm         61.7678
2017-06-10 21:33:10.097550 EDT | QFunRegParamNorm           75.611
2017-06-10 21:33:10.097715 EDT | -----------------------  -----------
2017-06-10 21:33:10.097974 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #306 | Training started
2017-06-10 21:33:24.334525 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #306 | Training finished
2017-06-10 21:33:24.335373 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #306 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 21:33:24.335646 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #306 | Collecting samples for evaluation
2017-06-10 21:33:37.107211 EDT | -----------------------  -----------
2017-06-10 21:33:37.113508 EDT | Epoch                     306
2017-06-10 21:33:37.113800 EDT | Iteration                 306
2017-06-10 21:33:37.114074 EDT | AverageReturn             990.176
2017-06-10 21:33:37.114364 EDT | StdReturn                 756.54
2017-06-10 21:33:37.114536 EDT | MaxReturn                2676.12
2017-06-10 21:33:37.114705 EDT | MinReturn                 260.741
2017-06-10 21:33:37.114902 EDT | AverageEsReturn           244.415
2017-06-10 21:33:37.115081 EDT | StdEsReturn               199.618
2017-06-10 21:33:37.115240 EDT | MaxEsReturn               587.74
2017-06-10 21:33:37.115399 EDT | MinEsReturn                 7.22502
2017-06-10 21:33:37.115555 EDT | AverageDiscountedReturn   184.986
2017-06-10 21:33:37.115718 EDT | AverageQLoss                3.15671
2017-06-10 21:33:37.115894 EDT | AveragePolicySurr         -34.2425
2017-06-10 21:33:37.116051 EDT | AverageQ                   33.5885
2017-06-10 21:33:37.116207 EDT | AverageAbsQ                33.614
2017-06-10 21:33:37.116363 EDT | AverageY                   33.5894
2017-06-10 21:33:37.116524 EDT | AverageAbsY                33.5969
2017-06-10 21:33:37.116701 EDT | AverageAbsQYDiff            0.712513
2017-06-10 21:33:37.116858 EDT | AverageAction               0.748444
2017-06-10 21:33:37.117014 EDT | PolicyRegParamNorm         61.8486
2017-06-10 21:33:37.117171 EDT | QFunRegParamNorm           75.7377
2017-06-10 21:33:37.117334 EDT | -----------------------  -----------
2017-06-10 21:33:37.117596 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #307 | Training started
2017-06-10 21:33:51.496120 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #307 | Training finished
2017-06-10 21:33:51.496923 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #307 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 21:33:51.497114 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #307 | Collecting samples for evaluation
2017-06-10 21:34:03.551426 EDT | -----------------------  -----------
2017-06-10 21:34:03.552320 EDT | Epoch                     307
2017-06-10 21:34:03.552663 EDT | Iteration                 307
2017-06-10 21:34:03.552987 EDT | AverageReturn            1724.62
2017-06-10 21:34:03.553340 EDT | StdReturn                 898.668
2017-06-10 21:34:03.553683 EDT | MaxReturn                2883.82
2017-06-10 21:34:03.554048 EDT | MinReturn                 303.101
2017-06-10 21:34:03.554377 EDT | AverageEsReturn           284.452
2017-06-10 21:34:03.554693 EDT | StdEsReturn               315.356
2017-06-10 21:34:03.554951 EDT | MaxEsReturn              1100.51
2017-06-10 21:34:03.555265 EDT | MinEsReturn                36.6534
2017-06-10 21:34:03.555594 EDT | AverageDiscountedReturn   215.813
2017-06-10 21:34:03.555867 EDT | AverageQLoss                3.47361
2017-06-10 21:34:03.556163 EDT | AveragePolicySurr         -34.4125
2017-06-10 21:34:03.556476 EDT | AverageQ                   33.7369
2017-06-10 21:34:03.556808 EDT | AverageAbsQ                33.7622
2017-06-10 21:34:03.557122 EDT | AverageY                   33.7404
2017-06-10 21:34:03.557460 EDT | AverageAbsY                33.7484
2017-06-10 21:34:03.559984 EDT | AverageAbsQYDiff            0.757227
2017-06-10 21:34:03.560311 EDT | AverageAction               0.79189
2017-06-10 21:34:03.560795 EDT | PolicyRegParamNorm         61.9166
2017-06-10 21:34:03.561019 EDT | QFunRegParamNorm           75.8405
2017-06-10 21:34:03.561178 EDT | -----------------------  -----------
2017-06-10 21:34:03.561445 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #308 | Training started
2017-06-10 21:34:19.244950 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #308 | Training finished
2017-06-10 21:34:19.245254 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #308 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 21:34:19.245529 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #308 | Collecting samples for evaluation
2017-06-10 21:34:32.462339 EDT | -----------------------  -----------
2017-06-10 21:34:32.463312 EDT | Epoch                     308
2017-06-10 21:34:32.463644 EDT | Iteration                 308
2017-06-10 21:34:32.463878 EDT | AverageReturn            1632.89
2017-06-10 21:34:32.464118 EDT | StdReturn                1199.31
2017-06-10 21:34:32.464281 EDT | MaxReturn                3363.86
2017-06-10 21:34:32.464484 EDT | MinReturn                 269.237
2017-06-10 21:34:32.464740 EDT | AverageEsReturn           339.854
2017-06-10 21:34:32.464927 EDT | StdEsReturn               356.604
2017-06-10 21:34:32.465088 EDT | MaxEsReturn              1036.86
2017-06-10 21:34:32.465244 EDT | MinEsReturn                35.6372
2017-06-10 21:34:32.465408 EDT | AverageDiscountedReturn   227.395
2017-06-10 21:34:32.465757 EDT | AverageQLoss                2.76345
2017-06-10 21:34:32.466301 EDT | AveragePolicySurr         -34.3214
2017-06-10 21:34:32.466706 EDT | AverageQ                   33.6817
2017-06-10 21:34:32.467109 EDT | AverageAbsQ                33.7109
2017-06-10 21:34:32.467474 EDT | AverageY                   33.6841
2017-06-10 21:34:32.467879 EDT | AverageAbsY                33.691
2017-06-10 21:34:32.468259 EDT | AverageAbsQYDiff            0.684434
2017-06-10 21:34:32.468677 EDT | AverageAction               0.789859
2017-06-10 21:34:32.468986 EDT | PolicyRegParamNorm         62.0248
2017-06-10 21:34:32.469315 EDT | QFunRegParamNorm           75.9119
2017-06-10 21:34:32.469513 EDT | -----------------------  -----------
2017-06-10 21:34:32.470014 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #309 | Training started
2017-06-10 21:34:47.714901 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #309 | Training finished
2017-06-10 21:34:47.715702 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #309 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 21:34:47.715884 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #309 | Collecting samples for evaluation
2017-06-10 21:34:59.876993 EDT | -----------------------  -----------
2017-06-10 21:34:59.877787 EDT | Epoch                     309
2017-06-10 21:34:59.877984 EDT | Iteration                 309
2017-06-10 21:34:59.878145 EDT | AverageReturn            2072.6
2017-06-10 21:34:59.878311 EDT | StdReturn                 725.385
2017-06-10 21:34:59.878504 EDT | MaxReturn                2935.03
2017-06-10 21:34:59.878688 EDT | MinReturn                1014.69
2017-06-10 21:34:59.878869 EDT | AverageEsReturn           204.259
2017-06-10 21:34:59.879048 EDT | StdEsReturn               167.462
2017-06-10 21:34:59.879227 EDT | MaxEsReturn               638.74
2017-06-10 21:34:59.879406 EDT | MinEsReturn                35.202
2017-06-10 21:34:59.879584 EDT | AverageDiscountedReturn   217.473
2017-06-10 21:34:59.879772 EDT | AverageQLoss                2.80078
2017-06-10 21:34:59.879948 EDT | AveragePolicySurr         -34.4123
2017-06-10 21:34:59.880128 EDT | AverageQ                   33.7774
2017-06-10 21:34:59.880307 EDT | AverageAbsQ                33.7984
2017-06-10 21:34:59.880486 EDT | AverageY                   33.7766
2017-06-10 21:34:59.880663 EDT | AverageAbsY                33.7827
2017-06-10 21:34:59.880842 EDT | AverageAbsQYDiff            0.695187
2017-06-10 21:34:59.881019 EDT | AverageAction               0.734828
2017-06-10 21:34:59.881198 EDT | PolicyRegParamNorm         62.0794
2017-06-10 21:34:59.881375 EDT | QFunRegParamNorm           76.0134
2017-06-10 21:34:59.881553 EDT | -----------------------  -----------
2017-06-10 21:34:59.881993 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #310 | Training started
2017-06-10 21:35:14.987786 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #310 | Training finished
2017-06-10 21:35:14.988519 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #310 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 21:35:14.988721 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #310 | Collecting samples for evaluation
2017-06-10 21:35:28.548944 EDT | -----------------------  -----------
2017-06-10 21:35:28.553348 EDT | Epoch                     310
2017-06-10 21:35:28.553872 EDT | Iteration                 310
2017-06-10 21:35:28.554309 EDT | AverageReturn            1189.63
2017-06-10 21:35:28.554813 EDT | StdReturn                1211.54
2017-06-10 21:35:28.555307 EDT | MaxReturn                3282.3
2017-06-10 21:35:28.555742 EDT | MinReturn                 251.297
2017-06-10 21:35:28.556162 EDT | AverageEsReturn           255.045
2017-06-10 21:35:28.556563 EDT | StdEsReturn               302.076
2017-06-10 21:35:28.556996 EDT | MaxEsReturn              1007.67
2017-06-10 21:35:28.557418 EDT | MinEsReturn                24.2587
2017-06-10 21:35:28.557784 EDT | AverageDiscountedReturn   187.316
2017-06-10 21:35:28.558214 EDT | AverageQLoss                3.07627
2017-06-10 21:35:28.558652 EDT | AveragePolicySurr         -34.3418
2017-06-10 21:35:28.559038 EDT | AverageQ                   33.7218
2017-06-10 21:35:28.559415 EDT | AverageAbsQ                33.7496
2017-06-10 21:35:28.559840 EDT | AverageY                   33.7252
2017-06-10 21:35:28.560267 EDT | AverageAbsY                33.7351
2017-06-10 21:35:28.560619 EDT | AverageAbsQYDiff            0.700554
2017-06-10 21:35:28.561039 EDT | AverageAction               0.76954
2017-06-10 21:35:28.561474 EDT | PolicyRegParamNorm         62.1557
2017-06-10 21:35:28.561886 EDT | QFunRegParamNorm           76.1563
2017-06-10 21:35:28.568216 EDT | -----------------------  -----------
2017-06-10 21:35:28.568836 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #311 | Training started
2017-06-10 21:35:42.322583 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #311 | Training finished
2017-06-10 21:35:42.323573 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #311 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 21:35:42.323941 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #311 | Collecting samples for evaluation
2017-06-10 21:35:55.379932 EDT | -----------------------  -----------
2017-06-10 21:35:55.380787 EDT | Epoch                     311
2017-06-10 21:35:55.381157 EDT | Iteration                 311
2017-06-10 21:35:55.381486 EDT | AverageReturn            1840.66
2017-06-10 21:35:55.381916 EDT | StdReturn                 686.01
2017-06-10 21:35:55.382221 EDT | MaxReturn                3096.12
2017-06-10 21:35:55.383380 EDT | MinReturn                 960.105
2017-06-10 21:35:55.383942 EDT | AverageEsReturn           365.349
2017-06-10 21:35:55.384351 EDT | StdEsReturn               265.281
2017-06-10 21:35:55.384687 EDT | MaxEsReturn               757.306
2017-06-10 21:35:55.385159 EDT | MinEsReturn                26.6506
2017-06-10 21:35:55.385322 EDT | AverageDiscountedReturn   217.797
2017-06-10 21:35:55.385478 EDT | AverageQLoss                3.49291
2017-06-10 21:35:55.385631 EDT | AveragePolicySurr         -34.4496
2017-06-10 21:35:55.385805 EDT | AverageQ                   33.8011
2017-06-10 21:35:55.385956 EDT | AverageAbsQ                33.8318
2017-06-10 21:35:55.386106 EDT | AverageY                   33.8026
2017-06-10 21:35:55.386255 EDT | AverageAbsY                33.8121
2017-06-10 21:35:55.386405 EDT | AverageAbsQYDiff            0.738298
2017-06-10 21:35:55.386554 EDT | AverageAction               0.825499
2017-06-10 21:35:55.386703 EDT | PolicyRegParamNorm         62.264
2017-06-10 21:35:55.386852 EDT | QFunRegParamNorm           76.2739
2017-06-10 21:35:55.387002 EDT | -----------------------  -----------
2017-06-10 21:35:55.387264 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #312 | Training started
2017-06-10 21:36:09.537244 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #312 | Training finished
2017-06-10 21:36:09.538036 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #312 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 21:36:09.538498 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #312 | Collecting samples for evaluation
2017-06-10 21:36:22.236375 EDT | -----------------------  ----------
2017-06-10 21:36:22.237472 EDT | Epoch                    312
2017-06-10 21:36:22.237859 EDT | Iteration                312
2017-06-10 21:36:22.238175 EDT | AverageReturn            407.242
2017-06-10 21:36:22.238349 EDT | StdReturn                203.976
2017-06-10 21:36:22.238511 EDT | MaxReturn                967.253
2017-06-10 21:36:22.238675 EDT | MinReturn                268.408
2017-06-10 21:36:22.239007 EDT | AverageEsReturn          179.641
2017-06-10 21:36:22.240035 EDT | StdEsReturn              176.515
2017-06-10 21:36:22.240405 EDT | MaxEsReturn              513.515
2017-06-10 21:36:22.240740 EDT | MinEsReturn               20.3789
2017-06-10 21:36:22.241099 EDT | AverageDiscountedReturn  162.584
2017-06-10 21:36:22.241474 EDT | AverageQLoss               3.23943
2017-06-10 21:36:22.241850 EDT | AveragePolicySurr        -34.2761
2017-06-10 21:36:22.242768 EDT | AverageQ                  33.6463
2017-06-10 21:36:22.242958 EDT | AverageAbsQ               33.6789
2017-06-10 21:36:22.243229 EDT | AverageY                  33.6465
2017-06-10 21:36:22.243661 EDT | AverageAbsY               33.6585
2017-06-10 21:36:22.244098 EDT | AverageAbsQYDiff           0.716368
2017-06-10 21:36:22.244536 EDT | AverageAction              0.827345
2017-06-10 21:36:22.244836 EDT | PolicyRegParamNorm        62.3031
2017-06-10 21:36:22.245022 EDT | QFunRegParamNorm          76.4175
2017-06-10 21:36:22.245192 EDT | -----------------------  ----------
2017-06-10 21:36:22.245500 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #313 | Training started
2017-06-10 21:36:37.827174 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #313 | Training finished
2017-06-10 21:36:37.828466 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #313 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 21:36:37.828828 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #313 | Collecting samples for evaluation
2017-06-10 21:36:50.016829 EDT | -----------------------  -----------
2017-06-10 21:36:50.017605 EDT | Epoch                     313
2017-06-10 21:36:50.017943 EDT | Iteration                 313
2017-06-10 21:36:50.018288 EDT | AverageReturn            2569.39
2017-06-10 21:36:50.018692 EDT | StdReturn                 836.285
2017-06-10 21:36:50.019032 EDT | MaxReturn                3330.79
2017-06-10 21:36:50.019362 EDT | MinReturn                 551.578
2017-06-10 21:36:50.019689 EDT | AverageEsReturn           207.406
2017-06-10 21:36:50.020137 EDT | StdEsReturn               240.802
2017-06-10 21:36:50.020493 EDT | MaxEsReturn               656.613
2017-06-10 21:36:50.020846 EDT | MinEsReturn                17.4537
2017-06-10 21:36:50.021174 EDT | AverageDiscountedReturn   211.268
2017-06-10 21:36:50.021498 EDT | AverageQLoss                3.20003
2017-06-10 21:36:50.021837 EDT | AveragePolicySurr         -34.4174
2017-06-10 21:36:50.022165 EDT | AverageQ                   33.7905
2017-06-10 21:36:50.022489 EDT | AverageAbsQ                33.8208
2017-06-10 21:36:50.022814 EDT | AverageY                   33.7928
2017-06-10 21:36:50.023155 EDT | AverageAbsY                33.8065
2017-06-10 21:36:50.023489 EDT | AverageAbsQYDiff            0.723549
2017-06-10 21:36:50.023815 EDT | AverageAction               0.792813
2017-06-10 21:36:50.024143 EDT | PolicyRegParamNorm         62.4021
2017-06-10 21:36:50.024468 EDT | QFunRegParamNorm           76.5361
2017-06-10 21:36:50.024796 EDT | -----------------------  -----------
2017-06-10 21:36:50.025256 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #314 | Training started
2017-06-10 21:37:05.534909 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #314 | Training finished
2017-06-10 21:37:05.535961 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #314 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 21:37:05.536192 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #314 | Collecting samples for evaluation
2017-06-10 21:37:18.088637 EDT | -----------------------  -----------
2017-06-10 21:37:18.089457 EDT | Epoch                     314
2017-06-10 21:37:18.089860 EDT | Iteration                 314
2017-06-10 21:37:18.090232 EDT | AverageReturn             750.717
2017-06-10 21:37:18.090511 EDT | StdReturn                 825.211
2017-06-10 21:37:18.091404 EDT | MaxReturn                3227.84
2017-06-10 21:37:18.091718 EDT | MinReturn                 119.346
2017-06-10 21:37:18.092066 EDT | AverageEsReturn           231.039
2017-06-10 21:37:18.092382 EDT | StdEsReturn               165.511
2017-06-10 21:37:18.092808 EDT | MaxEsReturn               574.812
2017-06-10 21:37:18.093567 EDT | MinEsReturn                20.9595
2017-06-10 21:37:18.093925 EDT | AverageDiscountedReturn   168.722
2017-06-10 21:37:18.094196 EDT | AverageQLoss                3.39247
2017-06-10 21:37:18.094520 EDT | AveragePolicySurr         -34.3432
2017-06-10 21:37:18.094856 EDT | AverageQ                   33.7348
2017-06-10 21:37:18.095190 EDT | AverageAbsQ                33.7716
2017-06-10 21:37:18.095521 EDT | AverageY                   33.7368
2017-06-10 21:37:18.095929 EDT | AverageAbsY                33.7589
2017-06-10 21:37:18.096270 EDT | AverageAbsQYDiff            0.714677
2017-06-10 21:37:18.096631 EDT | AverageAction               0.781088
2017-06-10 21:37:18.096865 EDT | PolicyRegParamNorm         62.5115
2017-06-10 21:37:18.097025 EDT | QFunRegParamNorm           76.6266
2017-06-10 21:37:18.097178 EDT | -----------------------  -----------
2017-06-10 21:37:18.097457 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #315 | Training started
2017-06-10 21:37:32.237356 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #315 | Training finished
2017-06-10 21:37:32.238405 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #315 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 21:37:32.238794 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #315 | Collecting samples for evaluation
2017-06-10 21:37:45.474363 EDT | -----------------------  -----------
2017-06-10 21:37:45.475826 EDT | Epoch                     315
2017-06-10 21:37:45.476673 EDT | Iteration                 315
2017-06-10 21:37:45.477131 EDT | AverageReturn             742.001
2017-06-10 21:37:45.477582 EDT | StdReturn                 291.52
2017-06-10 21:37:45.477956 EDT | MaxReturn                1367.64
2017-06-10 21:37:45.478301 EDT | MinReturn                 395.522
2017-06-10 21:37:45.478650 EDT | AverageEsReturn           332.329
2017-06-10 21:37:45.478994 EDT | StdEsReturn               237.233
2017-06-10 21:37:45.479338 EDT | MaxEsReturn               673.163
2017-06-10 21:37:45.479684 EDT | MinEsReturn                16.4902
2017-06-10 21:37:45.480128 EDT | AverageDiscountedReturn   227.204
2017-06-10 21:37:45.480574 EDT | AverageQLoss                2.58248
2017-06-10 21:37:45.481031 EDT | AveragePolicySurr         -34.2708
2017-06-10 21:37:45.481486 EDT | AverageQ                   33.6532
2017-06-10 21:37:45.481947 EDT | AverageAbsQ                33.6959
2017-06-10 21:37:45.482393 EDT | AverageY                   33.6552
2017-06-10 21:37:45.482839 EDT | AverageAbsY                33.6813
2017-06-10 21:37:45.483286 EDT | AverageAbsQYDiff            0.689932
2017-06-10 21:37:45.483732 EDT | AverageAction               0.847604
2017-06-10 21:37:45.484179 EDT | PolicyRegParamNorm         62.5257
2017-06-10 21:37:45.484625 EDT | QFunRegParamNorm           76.7193
2017-06-10 21:37:45.485073 EDT | -----------------------  -----------
2017-06-10 21:37:45.485680 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #316 | Training started
2017-06-10 21:38:00.456994 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #316 | Training finished
2017-06-10 21:38:00.457958 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #316 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 21:38:00.458314 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #316 | Collecting samples for evaluation
2017-06-10 21:38:12.378075 EDT | -----------------------  -----------
2017-06-10 21:38:12.379707 EDT | Epoch                     316
2017-06-10 21:38:12.380027 EDT | Iteration                 316
2017-06-10 21:38:12.380329 EDT | AverageReturn            1469.68
2017-06-10 21:38:12.380650 EDT | StdReturn                 576.191
2017-06-10 21:38:12.380923 EDT | MaxReturn                3242.66
2017-06-10 21:38:12.381251 EDT | MinReturn                 321.783
2017-06-10 21:38:12.381565 EDT | AverageEsReturn           223.567
2017-06-10 21:38:12.381931 EDT | StdEsReturn               248.81
2017-06-10 21:38:12.382260 EDT | MaxEsReturn               906.011
2017-06-10 21:38:12.382587 EDT | MinEsReturn                21.0451
2017-06-10 21:38:12.382916 EDT | AverageDiscountedReturn   227.779
2017-06-10 21:38:12.383193 EDT | AverageQLoss                3.3337
2017-06-10 21:38:12.383502 EDT | AveragePolicySurr         -34.3465
2017-06-10 21:38:12.383836 EDT | AverageQ                   33.7155
2017-06-10 21:38:12.384116 EDT | AverageAbsQ                33.7609
2017-06-10 21:38:12.386191 EDT | AverageY                   33.7149
2017-06-10 21:38:12.386580 EDT | AverageAbsY                33.7395
2017-06-10 21:38:12.386921 EDT | AverageAbsQYDiff            0.729242
2017-06-10 21:38:12.387247 EDT | AverageAction               0.836596
2017-06-10 21:38:12.388206 EDT | PolicyRegParamNorm         62.5816
2017-06-10 21:38:12.388575 EDT | QFunRegParamNorm           76.8464
2017-06-10 21:38:12.388905 EDT | -----------------------  -----------
2017-06-10 21:38:12.389393 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #317 | Training started
2017-06-10 21:38:28.583985 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #317 | Training finished
2017-06-10 21:38:28.584936 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #317 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 21:38:28.585319 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #317 | Collecting samples for evaluation
2017-06-10 21:38:42.168579 EDT | -----------------------  -----------
2017-06-10 21:38:42.169766 EDT | Epoch                     317
2017-06-10 21:38:42.170001 EDT | Iteration                 317
2017-06-10 21:38:42.170204 EDT | AverageReturn            1345.98
2017-06-10 21:38:42.170389 EDT | StdReturn                 430.488
2017-06-10 21:38:42.170639 EDT | MaxReturn                2414.75
2017-06-10 21:38:42.170822 EDT | MinReturn                 813.404
2017-06-10 21:38:42.171003 EDT | AverageEsReturn           239.147
2017-06-10 21:38:42.171193 EDT | StdEsReturn               292.252
2017-06-10 21:38:42.171372 EDT | MaxEsReturn               953.494
2017-06-10 21:38:42.171556 EDT | MinEsReturn                12.9965
2017-06-10 21:38:42.171733 EDT | AverageDiscountedReturn   234.333
2017-06-10 21:38:42.171912 EDT | AverageQLoss                3.05894
2017-06-10 21:38:42.172133 EDT | AveragePolicySurr         -34.3644
2017-06-10 21:38:42.172326 EDT | AverageQ                   33.744
2017-06-10 21:38:42.172572 EDT | AverageAbsQ                33.7893
2017-06-10 21:38:42.172753 EDT | AverageY                   33.7478
2017-06-10 21:38:42.172931 EDT | AverageAbsY                33.775
2017-06-10 21:38:42.173107 EDT | AverageAbsQYDiff            0.713913
2017-06-10 21:38:42.173292 EDT | AverageAction               0.781852
2017-06-10 21:38:42.173470 EDT | PolicyRegParamNorm         62.6869
2017-06-10 21:38:42.173823 EDT | QFunRegParamNorm           76.9694
2017-06-10 21:38:42.174002 EDT | -----------------------  -----------
2017-06-10 21:38:42.174332 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #318 | Training started
2017-06-10 21:38:58.056217 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #318 | Training finished
2017-06-10 21:38:58.057112 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #318 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 21:38:58.057490 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #318 | Collecting samples for evaluation
2017-06-10 21:39:10.656188 EDT | -----------------------  -----------
2017-06-10 21:39:10.657225 EDT | Epoch                     318
2017-06-10 21:39:10.657760 EDT | Iteration                 318
2017-06-10 21:39:10.658428 EDT | AverageReturn            1646.23
2017-06-10 21:39:10.658779 EDT | StdReturn                 624.779
2017-06-10 21:39:10.659130 EDT | MaxReturn                3264.43
2017-06-10 21:39:10.660491 EDT | MinReturn                 316.229
2017-06-10 21:39:10.660860 EDT | AverageEsReturn           363.601
2017-06-10 21:39:10.661204 EDT | StdEsReturn               231.387
2017-06-10 21:39:10.661551 EDT | MaxEsReturn               703.612
2017-06-10 21:39:10.662259 EDT | MinEsReturn                14.7631
2017-06-10 21:39:10.662667 EDT | AverageDiscountedReturn   234.211
2017-06-10 21:39:10.663114 EDT | AverageQLoss                2.49642
2017-06-10 21:39:10.664616 EDT | AveragePolicySurr         -34.4007
2017-06-10 21:39:10.665268 EDT | AverageQ                   33.743
2017-06-10 21:39:10.665737 EDT | AverageAbsQ                33.7873
2017-06-10 21:39:10.666648 EDT | AverageY                   33.7441
2017-06-10 21:39:10.667432 EDT | AverageAbsY                33.7701
2017-06-10 21:39:10.668388 EDT | AverageAbsQYDiff            0.68648
2017-06-10 21:39:10.669431 EDT | AverageAction               0.823085
2017-06-10 21:39:10.669910 EDT | PolicyRegParamNorm         62.7028
2017-06-10 21:39:10.672012 EDT | QFunRegParamNorm           77.0402
2017-06-10 21:39:10.672493 EDT | -----------------------  -----------
2017-06-10 21:39:10.673084 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #319 | Training started
2017-06-10 21:39:26.014694 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #319 | Training finished
2017-06-10 21:39:26.015977 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #319 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 21:39:26.016529 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #319 | Collecting samples for evaluation
2017-06-10 21:39:38.094174 EDT | -----------------------  -----------
2017-06-10 21:39:38.094891 EDT | Epoch                     319
2017-06-10 21:39:38.095078 EDT | Iteration                 319
2017-06-10 21:39:38.095240 EDT | AverageReturn             832.334
2017-06-10 21:39:38.095398 EDT | StdReturn                 840.082
2017-06-10 21:39:38.095552 EDT | MaxReturn                2717.22
2017-06-10 21:39:38.095705 EDT | MinReturn                 230.503
2017-06-10 21:39:38.095858 EDT | AverageEsReturn           286.157
2017-06-10 21:39:38.096164 EDT | StdEsReturn               211.705
2017-06-10 21:39:38.096468 EDT | MaxEsReturn               680.878
2017-06-10 21:39:38.096765 EDT | MinEsReturn                11.5117
2017-06-10 21:39:38.097022 EDT | AverageDiscountedReturn   176.266
2017-06-10 21:39:38.097263 EDT | AverageQLoss                3.14897
2017-06-10 21:39:38.097501 EDT | AveragePolicySurr         -34.3438
2017-06-10 21:39:38.097763 EDT | AverageQ                   33.7263
2017-06-10 21:39:38.098066 EDT | AverageAbsQ                33.7661
2017-06-10 21:39:38.098370 EDT | AverageY                   33.7267
2017-06-10 21:39:38.098679 EDT | AverageAbsY                33.7477
2017-06-10 21:39:38.098950 EDT | AverageAbsQYDiff            0.717559
2017-06-10 21:39:38.099263 EDT | AverageAction               0.825626
2017-06-10 21:39:38.099536 EDT | PolicyRegParamNorm         62.7097
2017-06-10 21:39:38.099807 EDT | QFunRegParamNorm           77.1787
2017-06-10 21:39:38.100095 EDT | -----------------------  -----------
2017-06-10 21:39:38.100567 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #320 | Training started
2017-06-10 21:39:53.386782 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #320 | Training finished
2017-06-10 21:39:53.387750 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #320 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 21:39:53.388114 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #320 | Collecting samples for evaluation
2017-06-10 21:40:07.103985 EDT | -----------------------  -----------
2017-06-10 21:40:07.105255 EDT | Epoch                     320
2017-06-10 21:40:07.105880 EDT | Iteration                 320
2017-06-10 21:40:07.106203 EDT | AverageReturn             817.897
2017-06-10 21:40:07.107574 EDT | StdReturn                 119.824
2017-06-10 21:40:07.107939 EDT | MaxReturn                1120.13
2017-06-10 21:40:07.108303 EDT | MinReturn                 649.169
2017-06-10 21:40:07.108661 EDT | AverageEsReturn           437.293
2017-06-10 21:40:07.109029 EDT | StdEsReturn               348.383
2017-06-10 21:40:07.109395 EDT | MaxEsReturn              1041.08
2017-06-10 21:40:07.109846 EDT | MinEsReturn                37.1536
2017-06-10 21:40:07.110652 EDT | AverageDiscountedReturn   216.403
2017-06-10 21:40:07.111101 EDT | AverageQLoss                3.4218
2017-06-10 21:40:07.111553 EDT | AveragePolicySurr         -34.583
2017-06-10 21:40:07.112001 EDT | AverageQ                   33.9698
2017-06-10 21:40:07.112455 EDT | AverageAbsQ                34.003
2017-06-10 21:40:07.112900 EDT | AverageY                   33.9731
2017-06-10 21:40:07.114945 EDT | AverageAbsY                33.9879
2017-06-10 21:40:07.115903 EDT | AverageAbsQYDiff            0.716079
2017-06-10 21:40:07.116398 EDT | AverageAction               0.854308
2017-06-10 21:40:07.116830 EDT | PolicyRegParamNorm         62.8128
2017-06-10 21:40:07.117252 EDT | QFunRegParamNorm           77.2297
2017-06-10 21:40:07.117710 EDT | -----------------------  -----------
2017-06-10 21:40:07.118340 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #321 | Training started
2017-06-10 21:40:22.777762 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #321 | Training finished
2017-06-10 21:40:22.778678 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #321 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 21:40:22.778963 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #321 | Collecting samples for evaluation
2017-06-10 21:40:35.380112 EDT | -----------------------  -----------
2017-06-10 21:40:35.380926 EDT | Epoch                     321
2017-06-10 21:40:35.381205 EDT | Iteration                 321
2017-06-10 21:40:35.381458 EDT | AverageReturn            1144.99
2017-06-10 21:40:35.381712 EDT | StdReturn                 439.681
2017-06-10 21:40:35.381964 EDT | MaxReturn                2868.83
2017-06-10 21:40:35.382208 EDT | MinReturn                 544.954
2017-06-10 21:40:35.382450 EDT | AverageEsReturn           351.564
2017-06-10 21:40:35.382693 EDT | StdEsReturn               235.451
2017-06-10 21:40:35.382935 EDT | MaxEsReturn               652.668
2017-06-10 21:40:35.383176 EDT | MinEsReturn                18.0322
2017-06-10 21:40:35.383417 EDT | AverageDiscountedReturn   232.677
2017-06-10 21:40:35.383658 EDT | AverageQLoss                2.93533
2017-06-10 21:40:35.383899 EDT | AveragePolicySurr         -34.4655
2017-06-10 21:40:35.384140 EDT | AverageQ                   33.8386
2017-06-10 21:40:35.384379 EDT | AverageAbsQ                33.8691
2017-06-10 21:40:35.384619 EDT | AverageY                   33.8412
2017-06-10 21:40:35.384858 EDT | AverageAbsY                33.8563
2017-06-10 21:40:35.385099 EDT | AverageAbsQYDiff            0.691835
2017-06-10 21:40:35.385339 EDT | AverageAction               0.833109
2017-06-10 21:40:35.385579 EDT | PolicyRegParamNorm         62.9412
2017-06-10 21:40:35.385833 EDT | QFunRegParamNorm           77.2826
2017-06-10 21:40:35.386075 EDT | -----------------------  -----------
2017-06-10 21:40:35.386460 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #322 | Training started
2017-06-10 21:40:51.752228 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #322 | Training finished
2017-06-10 21:40:51.753079 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #322 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 21:40:51.753475 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #322 | Collecting samples for evaluation
2017-06-10 21:41:04.021922 EDT | -----------------------  -----------
2017-06-10 21:41:04.023469 EDT | Epoch                     322
2017-06-10 21:41:04.023674 EDT | Iteration                 322
2017-06-10 21:41:04.024091 EDT | AverageReturn            1180.96
2017-06-10 21:41:04.024386 EDT | StdReturn                 220.347
2017-06-10 21:41:04.024583 EDT | MaxReturn                1574.53
2017-06-10 21:41:04.024820 EDT | MinReturn                 820.69
2017-06-10 21:41:04.024996 EDT | AverageEsReturn           191.925
2017-06-10 21:41:04.025205 EDT | StdEsReturn               148.153
2017-06-10 21:41:04.025391 EDT | MaxEsReturn               543.508
2017-06-10 21:41:04.025571 EDT | MinEsReturn                49.4133
2017-06-10 21:41:04.025764 EDT | AverageDiscountedReturn   221.011
2017-06-10 21:41:04.026017 EDT | AverageQLoss                3.21874
2017-06-10 21:41:04.026213 EDT | AveragePolicySurr         -34.4808
2017-06-10 21:41:04.026544 EDT | AverageQ                   33.8496
2017-06-10 21:41:04.026887 EDT | AverageAbsQ                33.8798
2017-06-10 21:41:04.027228 EDT | AverageY                   33.8502
2017-06-10 21:41:04.027407 EDT | AverageAbsY                33.8662
2017-06-10 21:41:04.027681 EDT | AverageAbsQYDiff            0.727474
2017-06-10 21:41:04.028418 EDT | AverageAction               0.867906
2017-06-10 21:41:04.028617 EDT | PolicyRegParamNorm         62.9772
2017-06-10 21:41:04.028850 EDT | QFunRegParamNorm           77.4556
2017-06-10 21:41:04.029034 EDT | -----------------------  -----------
2017-06-10 21:41:04.029341 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #323 | Training started
2017-06-10 21:41:18.780685 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #323 | Training finished
2017-06-10 21:41:18.781550 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #323 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 21:41:18.781791 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #323 | Collecting samples for evaluation
2017-06-10 21:41:32.335092 EDT | -----------------------  -----------
2017-06-10 21:41:32.336043 EDT | Epoch                     323
2017-06-10 21:41:32.336422 EDT | Iteration                 323
2017-06-10 21:41:32.336782 EDT | AverageReturn            2523.29
2017-06-10 21:41:32.337127 EDT | StdReturn                 437.308
2017-06-10 21:41:32.337472 EDT | MaxReturn                3037.23
2017-06-10 21:41:32.337825 EDT | MinReturn                1643.65
2017-06-10 21:41:32.338269 EDT | AverageEsReturn           460.391
2017-06-10 21:41:32.338621 EDT | StdEsReturn               286.327
2017-06-10 21:41:32.338962 EDT | MaxEsReturn              1011.81
2017-06-10 21:41:32.339301 EDT | MinEsReturn               220.78
2017-06-10 21:41:32.339641 EDT | AverageDiscountedReturn   211.93
2017-06-10 21:41:32.339983 EDT | AverageQLoss                3.28224
2017-06-10 21:41:32.340319 EDT | AveragePolicySurr         -34.3658
2017-06-10 21:41:32.340658 EDT | AverageQ                   33.7531
2017-06-10 21:41:32.341001 EDT | AverageAbsQ                33.7865
2017-06-10 21:41:32.341344 EDT | AverageY                   33.7558
2017-06-10 21:41:32.341686 EDT | AverageAbsY                33.7707
2017-06-10 21:41:32.342036 EDT | AverageAbsQYDiff            0.725238
2017-06-10 21:41:32.342377 EDT | AverageAction               0.842564
2017-06-10 21:41:32.342723 EDT | PolicyRegParamNorm         63.0237
2017-06-10 21:41:32.343061 EDT | QFunRegParamNorm           77.5568
2017-06-10 21:41:32.343401 EDT | -----------------------  -----------
2017-06-10 21:41:32.343912 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #324 | Training started
2017-06-10 21:41:46.455943 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #324 | Training finished
2017-06-10 21:41:46.458250 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #324 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 21:41:46.458599 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #324 | Collecting samples for evaluation
2017-06-10 21:41:59.294739 EDT | -----------------------  -----------
2017-06-10 21:41:59.295623 EDT | Epoch                     324
2017-06-10 21:41:59.295822 EDT | Iteration                 324
2017-06-10 21:41:59.296031 EDT | AverageReturn            2691.94
2017-06-10 21:41:59.296242 EDT | StdReturn                 503.321
2017-06-10 21:41:59.296428 EDT | MaxReturn                3063.88
2017-06-10 21:41:59.296611 EDT | MinReturn                1257.67
2017-06-10 21:41:59.296846 EDT | AverageEsReturn           232.026
2017-06-10 21:41:59.297028 EDT | StdEsReturn               142.081
2017-06-10 21:41:59.297262 EDT | MaxEsReturn               463.787
2017-06-10 21:41:59.297482 EDT | MinEsReturn                12.6064
2017-06-10 21:41:59.297661 EDT | AverageDiscountedReturn   216.213
2017-06-10 21:41:59.297931 EDT | AverageQLoss                2.84504
2017-06-10 21:41:59.298258 EDT | AveragePolicySurr         -34.2693
2017-06-10 21:41:59.298692 EDT | AverageQ                   33.6833
2017-06-10 21:41:59.299096 EDT | AverageAbsQ                33.7234
2017-06-10 21:41:59.299818 EDT | AverageY                   33.6827
2017-06-10 21:41:59.300600 EDT | AverageAbsY                33.7037
2017-06-10 21:41:59.301009 EDT | AverageAbsQYDiff            0.67773
2017-06-10 21:41:59.301667 EDT | AverageAction               0.846905
2017-06-10 21:41:59.303773 EDT | PolicyRegParamNorm         63.1216
2017-06-10 21:41:59.304179 EDT | QFunRegParamNorm           77.6352
2017-06-10 21:41:59.304549 EDT | -----------------------  -----------
2017-06-10 21:41:59.305111 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #325 | Training started
2017-06-10 21:42:13.838698 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #325 | Training finished
2017-06-10 21:42:13.839506 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #325 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 21:42:13.839797 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #325 | Collecting samples for evaluation
2017-06-10 21:42:27.065328 EDT | -----------------------  -----------
2017-06-10 21:42:27.065960 EDT | Epoch                     325
2017-06-10 21:42:27.066416 EDT | Iteration                 325
2017-06-10 21:42:27.066769 EDT | AverageReturn            1436.44
2017-06-10 21:42:27.067215 EDT | StdReturn                 686.368
2017-06-10 21:42:27.067662 EDT | MaxReturn                2936.98
2017-06-10 21:42:27.068104 EDT | MinReturn                 372.021
2017-06-10 21:42:27.068546 EDT | AverageEsReturn           261.812
2017-06-10 21:42:27.068988 EDT | StdEsReturn               432.416
2017-06-10 21:42:27.069432 EDT | MaxEsReturn              1309.83
2017-06-10 21:42:27.069886 EDT | MinEsReturn                 9.53389
2017-06-10 21:42:27.070334 EDT | AverageDiscountedReturn   197.05
2017-06-10 21:42:27.070774 EDT | AverageQLoss                3.00935
2017-06-10 21:42:27.071197 EDT | AveragePolicySurr         -34.436
2017-06-10 21:42:27.071558 EDT | AverageQ                   33.8417
2017-06-10 21:42:27.072001 EDT | AverageAbsQ                33.8808
2017-06-10 21:42:27.072446 EDT | AverageY                   33.8433
2017-06-10 21:42:27.072797 EDT | AverageAbsY                33.8617
2017-06-10 21:42:27.073240 EDT | AverageAbsQYDiff            0.697522
2017-06-10 21:42:27.073684 EDT | AverageAction               0.862052
2017-06-10 21:42:27.074138 EDT | PolicyRegParamNorm         63.1974
2017-06-10 21:42:27.074492 EDT | QFunRegParamNorm           77.7284
2017-06-10 21:42:27.074849 EDT | -----------------------  -----------
2017-06-10 21:42:27.075357 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #326 | Training started
2017-06-10 21:42:42.277907 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #326 | Training finished
2017-06-10 21:42:42.278813 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #326 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 21:42:42.279139 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #326 | Collecting samples for evaluation
2017-06-10 21:42:54.051659 EDT | -----------------------  -----------
2017-06-10 21:42:54.052395 EDT | Epoch                     326
2017-06-10 21:42:54.052572 EDT | Iteration                 326
2017-06-10 21:42:54.052730 EDT | AverageReturn            1164.08
2017-06-10 21:42:54.052952 EDT | StdReturn                 579.544
2017-06-10 21:42:54.053123 EDT | MaxReturn                3080.39
2017-06-10 21:42:54.053286 EDT | MinReturn                 594.776
2017-06-10 21:42:54.053600 EDT | AverageEsReturn           428.526
2017-06-10 21:42:54.054544 EDT | StdEsReturn               219.804
2017-06-10 21:42:54.054881 EDT | MaxEsReturn               688.657
2017-06-10 21:42:54.055209 EDT | MinEsReturn               138.474
2017-06-10 21:42:54.055470 EDT | AverageDiscountedReturn   222.028
2017-06-10 21:42:54.055730 EDT | AverageQLoss                3.51757
2017-06-10 21:42:54.056574 EDT | AveragePolicySurr         -34.3198
2017-06-10 21:42:54.056848 EDT | AverageQ                   33.7061
2017-06-10 21:42:54.057138 EDT | AverageAbsQ                33.7478
2017-06-10 21:42:54.057399 EDT | AverageY                   33.7081
2017-06-10 21:42:54.057778 EDT | AverageAbsY                33.733
2017-06-10 21:42:54.058035 EDT | AverageAbsQYDiff            0.740163
2017-06-10 21:42:54.058283 EDT | AverageAction               0.83096
2017-06-10 21:42:54.058639 EDT | PolicyRegParamNorm         63.2953
2017-06-10 21:42:54.058899 EDT | QFunRegParamNorm           77.8229
2017-06-10 21:42:54.059148 EDT | -----------------------  -----------
2017-06-10 21:42:54.059560 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #327 | Training started
2017-06-10 21:43:09.791444 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #327 | Training finished
2017-06-10 21:43:09.792816 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #327 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 21:43:09.793031 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #327 | Collecting samples for evaluation
2017-06-10 21:43:22.354995 EDT | -----------------------  -----------
2017-06-10 21:43:22.355305 EDT | Epoch                     327
2017-06-10 21:43:22.355485 EDT | Iteration                 327
2017-06-10 21:43:22.355645 EDT | AverageReturn             987.986
2017-06-10 21:43:22.355798 EDT | StdReturn                 375.73
2017-06-10 21:43:22.355950 EDT | MaxReturn                2274.82
2017-06-10 21:43:22.356148 EDT | MinReturn                 579.621
2017-06-10 21:43:22.356301 EDT | AverageEsReturn           270.477
2017-06-10 21:43:22.356452 EDT | StdEsReturn               208.339
2017-06-10 21:43:22.356602 EDT | MaxEsReturn               630.95
2017-06-10 21:43:22.356752 EDT | MinEsReturn                22.4613
2017-06-10 21:43:22.356900 EDT | AverageDiscountedReturn   217.364
2017-06-10 21:43:22.357049 EDT | AverageQLoss                3.47806
2017-06-10 21:43:22.357286 EDT | AveragePolicySurr         -34.3105
2017-06-10 21:43:22.357450 EDT | AverageQ                   33.6828
2017-06-10 21:43:22.357630 EDT | AverageAbsQ                33.7284
2017-06-10 21:43:22.357811 EDT | AverageY                   33.6835
2017-06-10 21:43:22.357960 EDT | AverageAbsY                33.7116
2017-06-10 21:43:22.358111 EDT | AverageAbsQYDiff            0.725935
2017-06-10 21:43:22.358264 EDT | AverageAction               0.926115
2017-06-10 21:43:22.358465 EDT | PolicyRegParamNorm         63.3468
2017-06-10 21:43:22.358616 EDT | QFunRegParamNorm           77.9276
2017-06-10 21:43:22.358765 EDT | -----------------------  -----------
2017-06-10 21:43:22.359002 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #328 | Training started
2017-06-10 21:43:37.019519 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #328 | Training finished
2017-06-10 21:43:37.020458 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #328 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 21:43:37.020778 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #328 | Collecting samples for evaluation
2017-06-10 21:43:49.265065 EDT | -----------------------  ----------
2017-06-10 21:43:49.267399 EDT | Epoch                    328
2017-06-10 21:43:49.267780 EDT | Iteration                328
2017-06-10 21:43:49.268223 EDT | AverageReturn            645.665
2017-06-10 21:43:49.268607 EDT | StdReturn                124.726
2017-06-10 21:43:49.268971 EDT | MaxReturn                986.587
2017-06-10 21:43:49.269323 EDT | MinReturn                437.806
2017-06-10 21:43:49.269894 EDT | AverageEsReturn          444.563
2017-06-10 21:43:49.270704 EDT | StdEsReturn              317.181
2017-06-10 21:43:49.274100 EDT | MaxEsReturn              900.449
2017-06-10 21:43:49.274326 EDT | MinEsReturn               57.8967
2017-06-10 21:43:49.274587 EDT | AverageDiscountedReturn  191.49
2017-06-10 21:43:49.274853 EDT | AverageQLoss               3.31565
2017-06-10 21:43:49.275115 EDT | AveragePolicySurr        -34.3049
2017-06-10 21:43:49.275464 EDT | AverageQ                  33.7078
2017-06-10 21:43:49.275854 EDT | AverageAbsQ               33.7563
2017-06-10 21:43:49.276262 EDT | AverageY                  33.709
2017-06-10 21:43:49.276618 EDT | AverageAbsY               33.7421
2017-06-10 21:43:49.276967 EDT | AverageAbsQYDiff           0.702223
2017-06-10 21:43:49.277390 EDT | AverageAction              0.87757
2017-06-10 21:43:49.277756 EDT | PolicyRegParamNorm        63.4097
2017-06-10 21:43:49.278126 EDT | QFunRegParamNorm          78.0163
2017-06-10 21:43:49.278488 EDT | -----------------------  ----------
2017-06-10 21:43:49.279124 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #329 | Training started
2017-06-10 21:44:03.829130 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #329 | Training finished
2017-06-10 21:44:03.829865 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #329 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 21:44:03.830060 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #329 | Collecting samples for evaluation
2017-06-10 21:44:17.128782 EDT | -----------------------  -----------
2017-06-10 21:44:17.129615 EDT | Epoch                     329
2017-06-10 21:44:17.130140 EDT | Iteration                 329
2017-06-10 21:44:17.130421 EDT | AverageReturn             946.917
2017-06-10 21:44:17.130666 EDT | StdReturn                 448.639
2017-06-10 21:44:17.130942 EDT | MaxReturn                2401.5
2017-06-10 21:44:17.131209 EDT | MinReturn                 369.965
2017-06-10 21:44:17.131477 EDT | AverageEsReturn           477.7
2017-06-10 21:44:17.131732 EDT | StdEsReturn               272.753
2017-06-10 21:44:17.131979 EDT | MaxEsReturn               824.745
2017-06-10 21:44:17.132224 EDT | MinEsReturn                80.7684
2017-06-10 21:44:17.132583 EDT | AverageDiscountedReturn   203.563
2017-06-10 21:44:17.132917 EDT | AverageQLoss                3.36993
2017-06-10 21:44:17.133181 EDT | AveragePolicySurr         -34.1342
2017-06-10 21:44:17.133439 EDT | AverageQ                   33.5213
2017-06-10 21:44:17.133700 EDT | AverageAbsQ                33.576
2017-06-10 21:44:17.133958 EDT | AverageY                   33.5272
2017-06-10 21:44:17.134211 EDT | AverageAbsY                33.5646
2017-06-10 21:44:17.134468 EDT | AverageAbsQYDiff            0.70582
2017-06-10 21:44:17.134722 EDT | AverageAction               0.852869
2017-06-10 21:44:17.134976 EDT | PolicyRegParamNorm         63.487
2017-06-10 21:44:17.135287 EDT | QFunRegParamNorm           78.1708
2017-06-10 21:44:17.136184 EDT | -----------------------  -----------
2017-06-10 21:44:17.136649 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #330 | Training started
2017-06-10 21:44:31.856158 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #330 | Training finished
2017-06-10 21:44:31.856903 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #330 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 21:44:31.857182 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #330 | Collecting samples for evaluation
2017-06-10 21:44:44.613102 EDT | -----------------------  -----------
2017-06-10 21:44:44.614180 EDT | Epoch                     330
2017-06-10 21:44:44.614515 EDT | Iteration                 330
2017-06-10 21:44:44.614809 EDT | AverageReturn            1219.96
2017-06-10 21:44:44.615129 EDT | StdReturn                 365.566
2017-06-10 21:44:44.615420 EDT | MaxReturn                2019.25
2017-06-10 21:44:44.615757 EDT | MinReturn                 630.409
2017-06-10 21:44:44.616077 EDT | AverageEsReturn           359.704
2017-06-10 21:44:44.616396 EDT | StdEsReturn               282.988
2017-06-10 21:44:44.616706 EDT | MaxEsReturn               727.563
2017-06-10 21:44:44.616996 EDT | MinEsReturn                12.096
2017-06-10 21:44:44.617186 EDT | AverageDiscountedReturn   197.957
2017-06-10 21:44:44.617363 EDT | AverageQLoss                2.77266
2017-06-10 21:44:44.617516 EDT | AveragePolicySurr         -34.0766
2017-06-10 21:44:44.617666 EDT | AverageQ                   33.491
2017-06-10 21:44:44.617833 EDT | AverageAbsQ                33.5388
2017-06-10 21:44:44.617989 EDT | AverageY                   33.4896
2017-06-10 21:44:44.618144 EDT | AverageAbsY                33.5238
2017-06-10 21:44:44.618305 EDT | AverageAbsQYDiff            0.674958
2017-06-10 21:44:44.618496 EDT | AverageAction               0.851258
2017-06-10 21:44:44.618694 EDT | PolicyRegParamNorm         63.5471
2017-06-10 21:44:44.618956 EDT | QFunRegParamNorm           78.2594
2017-06-10 21:44:44.619237 EDT | -----------------------  -----------
2017-06-10 21:44:44.619529 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #331 | Training started
2017-06-10 21:45:00.390068 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #331 | Training finished
2017-06-10 21:45:00.390884 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #331 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 21:45:00.391107 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #331 | Collecting samples for evaluation
2017-06-10 21:45:12.329885 EDT | -----------------------  -----------
2017-06-10 21:45:12.330342 EDT | Epoch                     331
2017-06-10 21:45:12.330638 EDT | Iteration                 331
2017-06-10 21:45:12.330973 EDT | AverageReturn             867.508
2017-06-10 21:45:12.331269 EDT | StdReturn                 203.909
2017-06-10 21:45:12.331570 EDT | MaxReturn                1461.38
2017-06-10 21:45:12.331990 EDT | MinReturn                 502.078
2017-06-10 21:45:12.332654 EDT | AverageEsReturn           348.887
2017-06-10 21:45:12.333055 EDT | StdEsReturn               252.101
2017-06-10 21:45:12.333475 EDT | MaxEsReturn               816.724
2017-06-10 21:45:12.333899 EDT | MinEsReturn                32.7196
2017-06-10 21:45:12.334267 EDT | AverageDiscountedReturn   215.606
2017-06-10 21:45:12.334683 EDT | AverageQLoss                2.8319
2017-06-10 21:45:12.335105 EDT | AveragePolicySurr         -34.0538
2017-06-10 21:45:12.335520 EDT | AverageQ                   33.4918
2017-06-10 21:45:12.336282 EDT | AverageAbsQ                33.5411
2017-06-10 21:45:12.336670 EDT | AverageY                   33.4937
2017-06-10 21:45:12.337587 EDT | AverageAbsY                33.5288
2017-06-10 21:45:12.338043 EDT | AverageAbsQYDiff            0.68652
2017-06-10 21:45:12.338457 EDT | AverageAction               0.837406
2017-06-10 21:45:12.338898 EDT | PolicyRegParamNorm         63.6188
2017-06-10 21:45:12.339239 EDT | QFunRegParamNorm           78.3421
2017-06-10 21:45:12.339560 EDT | -----------------------  -----------
2017-06-10 21:45:12.340077 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #332 | Training started
2017-06-10 21:45:27.278617 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #332 | Training finished
2017-06-10 21:45:27.279575 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #332 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 21:45:27.279951 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #332 | Collecting samples for evaluation
2017-06-10 21:45:39.797956 EDT | -----------------------  -----------
2017-06-10 21:45:39.798736 EDT | Epoch                     332
2017-06-10 21:45:39.798930 EDT | Iteration                 332
2017-06-10 21:45:39.799143 EDT | AverageReturn             936.594
2017-06-10 21:45:39.799493 EDT | StdReturn                 458.003
2017-06-10 21:45:39.799719 EDT | MaxReturn                2648.41
2017-06-10 21:45:39.800434 EDT | MinReturn                 458.359
2017-06-10 21:45:39.800833 EDT | AverageEsReturn           348.236
2017-06-10 21:45:39.801427 EDT | StdEsReturn               276.785
2017-06-10 21:45:39.801796 EDT | MaxEsReturn               884.062
2017-06-10 21:45:39.802097 EDT | MinEsReturn                27.4831
2017-06-10 21:45:39.802376 EDT | AverageDiscountedReturn   220.699
2017-06-10 21:45:39.802559 EDT | AverageQLoss                3.10751
2017-06-10 21:45:39.802742 EDT | AveragePolicySurr         -34.0677
2017-06-10 21:45:39.802923 EDT | AverageQ                   33.4936
2017-06-10 21:45:39.803848 EDT | AverageAbsQ                33.5475
2017-06-10 21:45:39.804145 EDT | AverageY                   33.4957
2017-06-10 21:45:39.804333 EDT | AverageAbsY                33.5319
2017-06-10 21:45:39.804622 EDT | AverageAbsQYDiff            0.711776
2017-06-10 21:45:39.804806 EDT | AverageAction               0.831376
2017-06-10 21:45:39.804987 EDT | PolicyRegParamNorm         63.7024
2017-06-10 21:45:39.805354 EDT | QFunRegParamNorm           78.4838
2017-06-10 21:45:39.805951 EDT | -----------------------  -----------
2017-06-10 21:45:39.806528 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #333 | Training started
2017-06-10 21:45:54.019047 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #333 | Training finished
2017-06-10 21:45:54.020012 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #333 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 21:45:54.020381 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #333 | Collecting samples for evaluation
2017-06-10 21:46:06.731294 EDT | -----------------------  -----------
2017-06-10 21:46:06.732143 EDT | Epoch                     333
2017-06-10 21:46:06.732324 EDT | Iteration                 333
2017-06-10 21:46:06.732484 EDT | AverageReturn             771.64
2017-06-10 21:46:06.732639 EDT | StdReturn                 201.462
2017-06-10 21:46:06.733021 EDT | MaxReturn                1260.71
2017-06-10 21:46:06.733270 EDT | MinReturn                 578.057
2017-06-10 21:46:06.733425 EDT | AverageEsReturn           670.584
2017-06-10 21:46:06.733641 EDT | StdEsReturn               202.564
2017-06-10 21:46:06.733921 EDT | MaxEsReturn               835.544
2017-06-10 21:46:06.735682 EDT | MinEsReturn               272.419
2017-06-10 21:46:06.736046 EDT | AverageDiscountedReturn   220.764
2017-06-10 21:46:06.736422 EDT | AverageQLoss                2.69696
2017-06-10 21:46:06.736761 EDT | AveragePolicySurr         -33.9718
2017-06-10 21:46:06.737090 EDT | AverageQ                   33.367
2017-06-10 21:46:06.737422 EDT | AverageAbsQ                33.4104
2017-06-10 21:46:06.737753 EDT | AverageY                   33.3683
2017-06-10 21:46:06.738171 EDT | AverageAbsY                33.3963
2017-06-10 21:46:06.738331 EDT | AverageAbsQYDiff            0.678945
2017-06-10 21:46:06.738495 EDT | AverageAction               0.862465
2017-06-10 21:46:06.738650 EDT | PolicyRegParamNorm         63.7451
2017-06-10 21:46:06.738800 EDT | QFunRegParamNorm           78.6083
2017-06-10 21:46:06.738952 EDT | -----------------------  -----------
2017-06-10 21:46:06.739199 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #334 | Training started
2017-06-10 21:46:21.000116 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #334 | Training finished
2017-06-10 21:46:21.000787 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #334 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 21:46:21.001171 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #334 | Collecting samples for evaluation
2017-06-10 21:46:33.811195 EDT | -----------------------  -----------
2017-06-10 21:46:33.814280 EDT | Epoch                     334
2017-06-10 21:46:33.814525 EDT | Iteration                 334
2017-06-10 21:46:33.814735 EDT | AverageReturn             776.849
2017-06-10 21:46:33.814936 EDT | StdReturn                 170.063
2017-06-10 21:46:33.815144 EDT | MaxReturn                1308.85
2017-06-10 21:46:33.815340 EDT | MinReturn                 626.97
2017-06-10 21:46:33.815580 EDT | AverageEsReturn           351.945
2017-06-10 21:46:33.815899 EDT | StdEsReturn               256.448
2017-06-10 21:46:33.816104 EDT | MaxEsReturn               680.542
2017-06-10 21:46:33.816510 EDT | MinEsReturn                44.8252
2017-06-10 21:46:33.816828 EDT | AverageDiscountedReturn   216.919
2017-06-10 21:46:33.817204 EDT | AverageQLoss                3.19688
2017-06-10 21:46:33.817586 EDT | AveragePolicySurr         -34.0612
2017-06-10 21:46:33.817987 EDT | AverageQ                   33.4682
2017-06-10 21:46:33.818392 EDT | AverageAbsQ                33.514
2017-06-10 21:46:33.818750 EDT | AverageY                   33.4706
2017-06-10 21:46:33.819151 EDT | AverageAbsY                33.4952
2017-06-10 21:46:33.819387 EDT | AverageAbsQYDiff            0.718341
2017-06-10 21:46:33.819802 EDT | AverageAction               0.856468
2017-06-10 21:46:33.820033 EDT | PolicyRegParamNorm         63.8745
2017-06-10 21:46:33.820228 EDT | QFunRegParamNorm           78.6966
2017-06-10 21:46:33.820426 EDT | -----------------------  -----------
2017-06-10 21:46:33.820791 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #335 | Training started
2017-06-10 21:46:48.500083 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #335 | Training finished
2017-06-10 21:46:48.500836 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #335 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 21:46:48.501292 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #335 | Collecting samples for evaluation
2017-06-10 21:47:00.754943 EDT | -----------------------  -----------
2017-06-10 21:47:00.755656 EDT | Epoch                     335
2017-06-10 21:47:00.755929 EDT | Iteration                 335
2017-06-10 21:47:00.756425 EDT | AverageReturn             707.463
2017-06-10 21:47:00.756666 EDT | StdReturn                 254.257
2017-06-10 21:47:00.756855 EDT | MaxReturn                1737.32
2017-06-10 21:47:00.757038 EDT | MinReturn                 288.555
2017-06-10 21:47:00.757227 EDT | AverageEsReturn           482.46
2017-06-10 21:47:00.757416 EDT | StdEsReturn               362.536
2017-06-10 21:47:00.757681 EDT | MaxEsReturn              1185.61
2017-06-10 21:47:00.757881 EDT | MinEsReturn                22.0053
2017-06-10 21:47:00.758067 EDT | AverageDiscountedReturn   205.651
2017-06-10 21:47:00.758592 EDT | AverageQLoss                3.24177
2017-06-10 21:47:00.758831 EDT | AveragePolicySurr         -34.028
2017-06-10 21:47:00.759088 EDT | AverageQ                   33.4508
2017-06-10 21:47:00.759330 EDT | AverageAbsQ                33.4942
2017-06-10 21:47:00.759507 EDT | AverageY                   33.4506
2017-06-10 21:47:00.759731 EDT | AverageAbsY                33.4768
2017-06-10 21:47:00.760436 EDT | AverageAbsQYDiff            0.697758
2017-06-10 21:47:00.760738 EDT | AverageAction               0.872261
2017-06-10 21:47:00.760997 EDT | PolicyRegParamNorm         63.9651
2017-06-10 21:47:00.761202 EDT | QFunRegParamNorm           78.8001
2017-06-10 21:47:00.761422 EDT | -----------------------  -----------
2017-06-10 21:47:00.761758 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #336 | Training started
2017-06-10 21:47:16.232126 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #336 | Training finished
2017-06-10 21:47:16.232999 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #336 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 21:47:16.233943 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #336 | Collecting samples for evaluation
2017-06-10 21:47:28.571803 EDT | -----------------------  -----------
2017-06-10 21:47:28.575110 EDT | Epoch                     336
2017-06-10 21:47:28.575498 EDT | Iteration                 336
2017-06-10 21:47:28.575842 EDT | AverageReturn             610.968
2017-06-10 21:47:28.576182 EDT | StdReturn                 396.408
2017-06-10 21:47:28.576524 EDT | MaxReturn                2078.12
2017-06-10 21:47:28.576863 EDT | MinReturn                 255.256
2017-06-10 21:47:28.577204 EDT | AverageEsReturn           325.959
2017-06-10 21:47:28.577539 EDT | StdEsReturn               245.546
2017-06-10 21:47:28.577891 EDT | MaxEsReturn               761.542
2017-06-10 21:47:28.578195 EDT | MinEsReturn                34.6941
2017-06-10 21:47:28.578531 EDT | AverageDiscountedReturn   174.459
2017-06-10 21:47:28.578869 EDT | AverageQLoss                3.78817
2017-06-10 21:47:28.579210 EDT | AveragePolicySurr         -33.9702
2017-06-10 21:47:28.579548 EDT | AverageQ                   33.3976
2017-06-10 21:47:28.579883 EDT | AverageAbsQ                33.4406
2017-06-10 21:47:28.580219 EDT | AverageY                   33.3997
2017-06-10 21:47:28.580555 EDT | AverageAbsY                33.4256
2017-06-10 21:47:28.580892 EDT | AverageAbsQYDiff            0.722406
2017-06-10 21:47:28.581230 EDT | AverageAction               0.903697
2017-06-10 21:47:28.581568 EDT | PolicyRegParamNorm         64.0576
2017-06-10 21:47:28.581916 EDT | QFunRegParamNorm           78.927
2017-06-10 21:47:28.582252 EDT | -----------------------  -----------
2017-06-10 21:47:28.582754 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #337 | Training started
2017-06-10 21:47:43.298662 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #337 | Training finished
2017-06-10 21:47:43.299587 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #337 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 21:47:43.299945 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #337 | Collecting samples for evaluation
2017-06-10 21:47:56.226289 EDT | -----------------------  -----------
2017-06-10 21:47:56.227346 EDT | Epoch                     337
2017-06-10 21:47:56.227715 EDT | Iteration                 337
2017-06-10 21:47:56.228068 EDT | AverageReturn             830.583
2017-06-10 21:47:56.228402 EDT | StdReturn                 390.799
2017-06-10 21:47:56.228690 EDT | MaxReturn                1787.72
2017-06-10 21:47:56.228998 EDT | MinReturn                 293.237
2017-06-10 21:47:56.229353 EDT | AverageEsReturn           456.454
2017-06-10 21:47:56.229633 EDT | StdEsReturn               185.976
2017-06-10 21:47:56.229983 EDT | MaxEsReturn               649.985
2017-06-10 21:47:56.230391 EDT | MinEsReturn               180.04
2017-06-10 21:47:56.230722 EDT | AverageDiscountedReturn   201.55
2017-06-10 21:47:56.231038 EDT | AverageQLoss                2.89969
2017-06-10 21:47:56.231344 EDT | AveragePolicySurr         -33.9005
2017-06-10 21:47:56.231838 EDT | AverageQ                   33.3426
2017-06-10 21:47:56.232170 EDT | AverageAbsQ                33.387
2017-06-10 21:47:56.232382 EDT | AverageY                   33.3442
2017-06-10 21:47:56.232538 EDT | AverageAbsY                33.3694
2017-06-10 21:47:56.232716 EDT | AverageAbsQYDiff            0.673829
2017-06-10 21:47:56.232983 EDT | AverageAction               0.895085
2017-06-10 21:47:56.233276 EDT | PolicyRegParamNorm         64.082
2017-06-10 21:47:56.233598 EDT | QFunRegParamNorm           79.0217
2017-06-10 21:47:56.236496 EDT | -----------------------  -----------
2017-06-10 21:47:56.237247 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #338 | Training started
2017-06-10 21:48:11.014237 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #338 | Training finished
2017-06-10 21:48:11.015495 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #338 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 21:48:11.015815 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #338 | Collecting samples for evaluation
2017-06-10 21:48:23.360887 EDT | -----------------------  -----------
2017-06-10 21:48:23.361635 EDT | Epoch                     338
2017-06-10 21:48:23.361997 EDT | Iteration                 338
2017-06-10 21:48:23.362334 EDT | AverageReturn             405.25
2017-06-10 21:48:23.362657 EDT | StdReturn                 221.545
2017-06-10 21:48:23.362977 EDT | MaxReturn                1267.48
2017-06-10 21:48:23.363290 EDT | MinReturn                 269.548
2017-06-10 21:48:23.363474 EDT | AverageEsReturn           726.703
2017-06-10 21:48:23.363680 EDT | StdEsReturn               435.471
2017-06-10 21:48:23.363864 EDT | MaxEsReturn              1464.2
2017-06-10 21:48:23.364043 EDT | MinEsReturn               340.786
2017-06-10 21:48:23.364222 EDT | AverageDiscountedReturn   162.429
2017-06-10 21:48:23.364400 EDT | AverageQLoss                2.5792
2017-06-10 21:48:23.364575 EDT | AveragePolicySurr         -33.8239
2017-06-10 21:48:23.364754 EDT | AverageQ                   33.2942
2017-06-10 21:48:23.364931 EDT | AverageAbsQ                33.3362
2017-06-10 21:48:23.365286 EDT | AverageY                   33.2956
2017-06-10 21:48:23.365607 EDT | AverageAbsY                33.3194
2017-06-10 21:48:23.365930 EDT | AverageAbsQYDiff            0.657951
2017-06-10 21:48:23.366201 EDT | AverageAction               0.909822
2017-06-10 21:48:23.366525 EDT | PolicyRegParamNorm         64.1125
2017-06-10 21:48:23.366858 EDT | QFunRegParamNorm           79.1069
2017-06-10 21:48:23.367187 EDT | -----------------------  -----------
2017-06-10 21:48:23.368041 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #339 | Training started
2017-06-10 21:48:37.781067 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #339 | Training finished
2017-06-10 21:48:37.782185 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #339 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 21:48:37.782702 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #339 | Collecting samples for evaluation
2017-06-10 21:48:50.447386 EDT | -----------------------  -----------
2017-06-10 21:48:50.447659 EDT | Epoch                     339
2017-06-10 21:48:50.447892 EDT | Iteration                 339
2017-06-10 21:48:50.448082 EDT | AverageReturn             386.66
2017-06-10 21:48:50.448249 EDT | StdReturn                 287.86
2017-06-10 21:48:50.448456 EDT | MaxReturn                1891.27
2017-06-10 21:48:50.448639 EDT | MinReturn                 264.084
2017-06-10 21:48:50.448935 EDT | AverageEsReturn           508.858
2017-06-10 21:48:50.449162 EDT | StdEsReturn               317.264
2017-06-10 21:48:50.449345 EDT | MaxEsReturn              1012.03
2017-06-10 21:48:50.449525 EDT | MinEsReturn               133.247
2017-06-10 21:48:50.449787 EDT | AverageDiscountedReturn   160.055
2017-06-10 21:48:50.449974 EDT | AverageQLoss                2.72488
2017-06-10 21:48:50.450204 EDT | AveragePolicySurr         -33.7581
2017-06-10 21:48:50.450386 EDT | AverageQ                   33.1925
2017-06-10 21:48:50.453195 EDT | AverageAbsQ                33.2386
2017-06-10 21:48:50.454037 EDT | AverageY                   33.1954
2017-06-10 21:48:50.457958 EDT | AverageAbsY                33.2224
2017-06-10 21:48:50.458132 EDT | AverageAbsQYDiff            0.663329
2017-06-10 21:48:50.458324 EDT | AverageAction               0.922973
2017-06-10 21:48:50.458508 EDT | PolicyRegParamNorm         64.2596
2017-06-10 21:48:50.458683 EDT | QFunRegParamNorm           79.1664
2017-06-10 21:48:50.458850 EDT | -----------------------  -----------
2017-06-10 21:48:50.459119 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #340 | Training started
2017-06-10 21:49:05.425782 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #340 | Training finished
2017-06-10 21:49:05.427019 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #340 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 21:49:05.427538 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #340 | Collecting samples for evaluation
2017-06-10 21:49:18.288075 EDT | -----------------------  ----------
2017-06-10 21:49:18.289404 EDT | Epoch                    340
2017-06-10 21:49:18.289964 EDT | Iteration                340
2017-06-10 21:49:18.290237 EDT | AverageReturn            283.027
2017-06-10 21:49:18.290455 EDT | StdReturn                 15.4794
2017-06-10 21:49:18.290643 EDT | MaxReturn                322.618
2017-06-10 21:49:18.290815 EDT | MinReturn                241.367
2017-06-10 21:49:18.290985 EDT | AverageEsReturn          394.414
2017-06-10 21:49:18.291153 EDT | StdEsReturn              174.088
2017-06-10 21:49:18.291330 EDT | MaxEsReturn              584.047
2017-06-10 21:49:18.291534 EDT | MinEsReturn               80.0329
2017-06-10 21:49:18.291727 EDT | AverageDiscountedReturn  147.138
2017-06-10 21:49:18.291919 EDT | AverageQLoss               3.35356
2017-06-10 21:49:18.292111 EDT | AveragePolicySurr        -33.7109
2017-06-10 21:49:18.292455 EDT | AverageQ                  33.1364
2017-06-10 21:49:18.292748 EDT | AverageAbsQ               33.1805
2017-06-10 21:49:18.293035 EDT | AverageY                  33.1369
2017-06-10 21:49:18.293366 EDT | AverageAbsY               33.1626
2017-06-10 21:49:18.293678 EDT | AverageAbsQYDiff           0.713228
2017-06-10 21:49:18.294064 EDT | AverageAction              0.912792
2017-06-10 21:49:18.294401 EDT | PolicyRegParamNorm        64.3821
2017-06-10 21:49:18.294809 EDT | QFunRegParamNorm          79.2967
2017-06-10 21:49:18.295120 EDT | -----------------------  ----------
2017-06-10 21:49:18.295581 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #341 | Training started
2017-06-10 21:49:33.255371 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #341 | Training finished
2017-06-10 21:49:33.256137 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #341 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 21:49:33.256411 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #341 | Collecting samples for evaluation
2017-06-10 21:49:45.769683 EDT | -----------------------  ----------
2017-06-10 21:49:45.770689 EDT | Epoch                    341
2017-06-10 21:49:45.770983 EDT | Iteration                341
2017-06-10 21:49:45.771307 EDT | AverageReturn            298.739
2017-06-10 21:49:45.771628 EDT | StdReturn                 90.1847
2017-06-10 21:49:45.771904 EDT | MaxReturn                947.288
2017-06-10 21:49:45.772241 EDT | MinReturn                267.547
2017-06-10 21:49:45.772564 EDT | AverageEsReturn          282.069
2017-06-10 21:49:45.772888 EDT | StdEsReturn              185.926
2017-06-10 21:49:45.773199 EDT | MaxEsReturn              614.474
2017-06-10 21:49:45.774167 EDT | MinEsReturn               22.305
2017-06-10 21:49:45.774498 EDT | AverageDiscountedReturn  148.999
2017-06-10 21:49:45.774814 EDT | AverageQLoss               2.92692
2017-06-10 21:49:45.775330 EDT | AveragePolicySurr        -33.8133
2017-06-10 21:49:45.775673 EDT | AverageQ                  33.2446
2017-06-10 21:49:45.776215 EDT | AverageAbsQ               33.2926
2017-06-10 21:49:45.777391 EDT | AverageY                  33.2471
2017-06-10 21:49:45.777734 EDT | AverageAbsY               33.274
2017-06-10 21:49:45.777987 EDT | AverageAbsQYDiff           0.685798
2017-06-10 21:49:45.778146 EDT | AverageAction              0.895474
2017-06-10 21:49:45.778300 EDT | PolicyRegParamNorm        64.4311
2017-06-10 21:49:45.778450 EDT | QFunRegParamNorm          79.4406
2017-06-10 21:49:45.778601 EDT | -----------------------  ----------
2017-06-10 21:49:45.778855 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #342 | Training started
2017-06-10 21:49:59.930613 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #342 | Training finished
2017-06-10 21:49:59.931424 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #342 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 21:49:59.931619 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #342 | Collecting samples for evaluation
2017-06-10 21:50:12.782289 EDT | -----------------------  -----------
2017-06-10 21:50:12.783103 EDT | Epoch                     342
2017-06-10 21:50:12.783505 EDT | Iteration                 342
2017-06-10 21:50:12.783848 EDT | AverageReturn             627.734
2017-06-10 21:50:12.784176 EDT | StdReturn                 417.281
2017-06-10 21:50:12.784501 EDT | MaxReturn                1702.98
2017-06-10 21:50:12.784826 EDT | MinReturn                 280.892
2017-06-10 21:50:12.785228 EDT | AverageEsReturn           500.078
2017-06-10 21:50:12.785591 EDT | StdEsReturn               124.425
2017-06-10 21:50:12.785962 EDT | MaxEsReturn               647.203
2017-06-10 21:50:12.786277 EDT | MinEsReturn               335.447
2017-06-10 21:50:12.786454 EDT | AverageDiscountedReturn   178.574
2017-06-10 21:50:12.786631 EDT | AverageQLoss                2.58661
2017-06-10 21:50:12.786800 EDT | AveragePolicySurr         -33.7442
2017-06-10 21:50:12.786970 EDT | AverageQ                   33.1319
2017-06-10 21:50:12.787155 EDT | AverageAbsQ                33.177
2017-06-10 21:50:12.787334 EDT | AverageY                   33.134
2017-06-10 21:50:12.787515 EDT | AverageAbsY                33.1613
2017-06-10 21:50:12.787688 EDT | AverageAbsQYDiff            0.664919
2017-06-10 21:50:12.787845 EDT | AverageAction               0.894897
2017-06-10 21:50:12.788000 EDT | PolicyRegParamNorm         64.488
2017-06-10 21:50:12.788154 EDT | QFunRegParamNorm           79.531
2017-06-10 21:50:12.788701 EDT | -----------------------  -----------
2017-06-10 21:50:12.789280 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #343 | Training started
2017-06-10 21:50:27.296712 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #343 | Training finished
2017-06-10 21:50:27.297497 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #343 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 21:50:27.297707 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #343 | Collecting samples for evaluation
2017-06-10 21:50:39.337877 EDT | -----------------------  -----------
2017-06-10 21:50:39.339067 EDT | Epoch                     343
2017-06-10 21:50:39.339260 EDT | Iteration                 343
2017-06-10 21:50:39.339421 EDT | AverageReturn             283.096
2017-06-10 21:50:39.339583 EDT | StdReturn                 125.121
2017-06-10 21:50:39.339894 EDT | MaxReturn                1355.2
2017-06-10 21:50:39.340085 EDT | MinReturn                 246.856
2017-06-10 21:50:39.340269 EDT | AverageEsReturn           585.448
2017-06-10 21:50:39.340450 EDT | StdEsReturn               285.674
2017-06-10 21:50:39.340701 EDT | MaxEsReturn               863.15
2017-06-10 21:50:39.340884 EDT | MinEsReturn               124.706
2017-06-10 21:50:39.341066 EDT | AverageDiscountedReturn   143.379
2017-06-10 21:50:39.341244 EDT | AverageQLoss                3.35276
2017-06-10 21:50:39.341423 EDT | AveragePolicySurr         -33.6973
2017-06-10 21:50:39.342962 EDT | AverageQ                   33.1313
2017-06-10 21:50:39.343166 EDT | AverageAbsQ                33.178
2017-06-10 21:50:39.343907 EDT | AverageY                   33.1331
2017-06-10 21:50:39.344301 EDT | AverageAbsY                33.1593
2017-06-10 21:50:39.344613 EDT | AverageAbsQYDiff            0.710757
2017-06-10 21:50:39.344772 EDT | AverageAction               0.875723
2017-06-10 21:50:39.344924 EDT | PolicyRegParamNorm         64.5436
2017-06-10 21:50:39.345073 EDT | QFunRegParamNorm           79.5892
2017-06-10 21:50:39.345222 EDT | -----------------------  -----------
2017-06-10 21:50:39.345467 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #344 | Training started
2017-06-10 21:50:54.525382 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #344 | Training finished
2017-06-10 21:50:54.526387 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #344 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 21:50:54.526685 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #344 | Collecting samples for evaluation
2017-06-10 21:51:06.355244 EDT | -----------------------  -----------
2017-06-10 21:51:06.356388 EDT | Epoch                     344
2017-06-10 21:51:06.356906 EDT | Iteration                 344
2017-06-10 21:51:06.357359 EDT | AverageReturn            1063.51
2017-06-10 21:51:06.357785 EDT | StdReturn                 525.072
2017-06-10 21:51:06.358023 EDT | MaxReturn                2565.92
2017-06-10 21:51:06.358211 EDT | MinReturn                 632.521
2017-06-10 21:51:06.358423 EDT | AverageEsReturn           438.439
2017-06-10 21:51:06.358670 EDT | StdEsReturn               366.379
2017-06-10 21:51:06.358910 EDT | MaxEsReturn              1129.54
2017-06-10 21:51:06.359126 EDT | MinEsReturn                18.9497
2017-06-10 21:51:06.359326 EDT | AverageDiscountedReturn   222.254
2017-06-10 21:51:06.359524 EDT | AverageQLoss                3.03868
2017-06-10 21:51:06.359704 EDT | AveragePolicySurr         -33.5806
2017-06-10 21:51:06.359883 EDT | AverageQ                   32.9908
2017-06-10 21:51:06.360062 EDT | AverageAbsQ                33.0394
2017-06-10 21:51:06.360240 EDT | AverageY                   32.9896
2017-06-10 21:51:06.360423 EDT | AverageAbsY                33.0132
2017-06-10 21:51:06.360601 EDT | AverageAbsQYDiff            0.690256
2017-06-10 21:51:06.360836 EDT | AverageAction               0.867331
2017-06-10 21:51:06.361060 EDT | PolicyRegParamNorm         64.5742
2017-06-10 21:51:06.361240 EDT | QFunRegParamNorm           79.6813
2017-06-10 21:51:06.361438 EDT | -----------------------  -----------
2017-06-10 21:51:06.361766 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #345 | Training started
2017-06-10 21:51:21.426957 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #345 | Training finished
2017-06-10 21:51:21.427195 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #345 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 21:51:21.427368 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #345 | Collecting samples for evaluation
2017-06-10 21:51:34.970246 EDT | -----------------------  ----------
2017-06-10 21:51:34.971615 EDT | Epoch                    345
2017-06-10 21:51:34.972101 EDT | Iteration                345
2017-06-10 21:51:34.972527 EDT | AverageReturn            260.519
2017-06-10 21:51:34.972961 EDT | StdReturn                 55.4769
2017-06-10 21:51:34.974380 EDT | MaxReturn                607.062
2017-06-10 21:51:34.974757 EDT | MinReturn                234.065
2017-06-10 21:51:34.975178 EDT | AverageEsReturn          195.955
2017-06-10 21:51:34.975610 EDT | StdEsReturn              116.802
2017-06-10 21:51:34.976249 EDT | MaxEsReturn              398.787
2017-06-10 21:51:34.976738 EDT | MinEsReturn               55.1891
2017-06-10 21:51:34.977615 EDT | AverageDiscountedReturn  139.223
2017-06-10 21:51:34.978084 EDT | AverageQLoss               3.35713
2017-06-10 21:51:34.978483 EDT | AveragePolicySurr        -33.6799
2017-06-10 21:51:34.978868 EDT | AverageQ                  33.135
2017-06-10 21:51:34.979375 EDT | AverageAbsQ               33.169
2017-06-10 21:51:34.979796 EDT | AverageY                  33.1376
2017-06-10 21:51:34.980153 EDT | AverageAbsY               33.1517
2017-06-10 21:51:34.980657 EDT | AverageAbsQYDiff           0.702568
2017-06-10 21:51:34.981353 EDT | AverageAction              0.887975
2017-06-10 21:51:34.981754 EDT | PolicyRegParamNorm        64.6363
2017-06-10 21:51:34.982084 EDT | QFunRegParamNorm          79.7938
2017-06-10 21:51:34.982418 EDT | -----------------------  ----------
2017-06-10 21:51:34.982899 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #346 | Training started
2017-06-10 21:51:49.577968 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #346 | Training finished
2017-06-10 21:51:49.578856 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #346 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 21:51:49.579056 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #346 | Collecting samples for evaluation
2017-06-10 21:52:02.173322 EDT | -----------------------  -----------
2017-06-10 21:52:02.174254 EDT | Epoch                     346
2017-06-10 21:52:02.174631 EDT | Iteration                 346
2017-06-10 21:52:02.175081 EDT | AverageReturn             234.615
2017-06-10 21:52:02.175543 EDT | StdReturn                 402.251
2017-06-10 21:52:02.175948 EDT | MaxReturn                2914.22
2017-06-10 21:52:02.176391 EDT | MinReturn                  93.1565
2017-06-10 21:52:02.176835 EDT | AverageEsReturn           282.004
2017-06-10 21:52:02.177220 EDT | StdEsReturn               183.426
2017-06-10 21:52:02.177520 EDT | MaxEsReturn               579.315
2017-06-10 21:52:02.177896 EDT | MinEsReturn                76.616
2017-06-10 21:52:02.178239 EDT | AverageDiscountedReturn   107.287
2017-06-10 21:52:02.178576 EDT | AverageQLoss                2.80851
2017-06-10 21:52:02.178919 EDT | AveragePolicySurr         -33.6823
2017-06-10 21:52:02.179258 EDT | AverageQ                   33.1424
2017-06-10 21:52:02.179597 EDT | AverageAbsQ                33.1789
2017-06-10 21:52:02.180125 EDT | AverageY                   33.1439
2017-06-10 21:52:02.180541 EDT | AverageAbsY                33.1631
2017-06-10 21:52:02.180923 EDT | AverageAbsQYDiff            0.660125
2017-06-10 21:52:02.181361 EDT | AverageAction               0.885936
2017-06-10 21:52:02.181804 EDT | PolicyRegParamNorm         64.7857
2017-06-10 21:52:02.182256 EDT | QFunRegParamNorm           79.9376
2017-06-10 21:52:02.182697 EDT | -----------------------  -----------
2017-06-10 21:52:02.183276 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #347 | Training started
2017-06-10 21:52:16.700821 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #347 | Training finished
2017-06-10 21:52:16.701721 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #347 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 21:52:16.702028 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #347 | Collecting samples for evaluation
2017-06-10 21:52:28.809172 EDT | -----------------------  -----------
2017-06-10 21:52:28.812264 EDT | Epoch                     347
2017-06-10 21:52:28.812494 EDT | Iteration                 347
2017-06-10 21:52:28.812657 EDT | AverageReturn            1311.06
2017-06-10 21:52:28.812812 EDT | StdReturn                 724.309
2017-06-10 21:52:28.812993 EDT | MaxReturn                2903.58
2017-06-10 21:52:28.813144 EDT | MinReturn                 289.279
2017-06-10 21:52:28.813294 EDT | AverageEsReturn           461.246
2017-06-10 21:52:28.813442 EDT | StdEsReturn               310.626
2017-06-10 21:52:28.813588 EDT | MaxEsReturn               999.113
2017-06-10 21:52:28.813776 EDT | MinEsReturn               136.895
2017-06-10 21:52:28.814015 EDT | AverageDiscountedReturn   213.985
2017-06-10 21:52:28.814262 EDT | AverageQLoss                2.98855
2017-06-10 21:52:28.814416 EDT | AveragePolicySurr         -33.5194
2017-06-10 21:52:28.814564 EDT | AverageQ                   33.0128
2017-06-10 21:52:28.814811 EDT | AverageAbsQ                33.0516
2017-06-10 21:52:28.814986 EDT | AverageY                   33.0132
2017-06-10 21:52:28.815165 EDT | AverageAbsY                33.0333
2017-06-10 21:52:28.815322 EDT | AverageAbsQYDiff            0.674006
2017-06-10 21:52:28.815477 EDT | AverageAction               0.867952
2017-06-10 21:52:28.815633 EDT | PolicyRegParamNorm         64.8213
2017-06-10 21:52:28.815787 EDT | QFunRegParamNorm           80.0356
2017-06-10 21:52:28.815942 EDT | -----------------------  -----------
2017-06-10 21:52:28.816266 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #348 | Training started
2017-06-10 21:52:44.189616 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #348 | Training finished
2017-06-10 21:52:44.190503 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #348 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 21:52:44.190821 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #348 | Collecting samples for evaluation
2017-06-10 21:52:56.658666 EDT | -----------------------  ----------
2017-06-10 21:52:56.659564 EDT | Epoch                    348
2017-06-10 21:52:56.659933 EDT | Iteration                348
2017-06-10 21:52:56.660277 EDT | AverageReturn            253.113
2017-06-10 21:52:56.660756 EDT | StdReturn                 24.7488
2017-06-10 21:52:56.661098 EDT | MaxReturn                286.327
2017-06-10 21:52:56.661546 EDT | MinReturn                186.515
2017-06-10 21:52:56.661915 EDT | AverageEsReturn          209.634
2017-06-10 21:52:56.662256 EDT | StdEsReturn              257.418
2017-06-10 21:52:56.662596 EDT | MaxEsReturn              798.721
2017-06-10 21:52:56.663057 EDT | MinEsReturn               19.0367
2017-06-10 21:52:56.663403 EDT | AverageDiscountedReturn  136.889
2017-06-10 21:52:56.663742 EDT | AverageQLoss               2.9001
2017-06-10 21:52:56.664223 EDT | AveragePolicySurr        -33.3632
2017-06-10 21:52:56.664563 EDT | AverageQ                  32.8282
2017-06-10 21:52:56.664903 EDT | AverageAbsQ               32.8584
2017-06-10 21:52:56.665370 EDT | AverageY                  32.8338
2017-06-10 21:52:56.665718 EDT | AverageAbsY               32.8458
2017-06-10 21:52:56.666060 EDT | AverageAbsQYDiff           0.683787
2017-06-10 21:52:56.666526 EDT | AverageAction              0.920255
2017-06-10 21:52:56.666867 EDT | PolicyRegParamNorm        64.9181
2017-06-10 21:52:56.667204 EDT | QFunRegParamNorm          80.1651
2017-06-10 21:52:56.667690 EDT | -----------------------  ----------
2017-06-10 21:52:56.668201 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #349 | Training started
2017-06-10 21:53:11.250780 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #349 | Training finished
2017-06-10 21:53:11.252158 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #349 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 21:53:11.252660 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #349 | Collecting samples for evaluation
2017-06-10 21:53:24.208867 EDT | -----------------------  -----------
2017-06-10 21:53:24.209811 EDT | Epoch                     349
2017-06-10 21:53:24.210158 EDT | Iteration                 349
2017-06-10 21:53:24.210495 EDT | AverageReturn             314.481
2017-06-10 21:53:24.210765 EDT | StdReturn                 128.194
2017-06-10 21:53:24.211057 EDT | MaxReturn                1153.01
2017-06-10 21:53:24.211385 EDT | MinReturn                 251.032
2017-06-10 21:53:24.212199 EDT | AverageEsReturn           420.604
2017-06-10 21:53:24.212646 EDT | StdEsReturn               362.907
2017-06-10 21:53:24.212961 EDT | MaxEsReturn              1163.84
2017-06-10 21:53:24.213298 EDT | MinEsReturn                31.9046
2017-06-10 21:53:24.213647 EDT | AverageDiscountedReturn   151.406
2017-06-10 21:53:24.213872 EDT | AverageQLoss                2.56982
2017-06-10 21:53:24.214132 EDT | AveragePolicySurr         -33.3942
2017-06-10 21:53:24.214548 EDT | AverageQ                   32.8353
2017-06-10 21:53:24.214976 EDT | AverageAbsQ                32.8707
2017-06-10 21:53:24.215362 EDT | AverageY                   32.8349
2017-06-10 21:53:24.215726 EDT | AverageAbsY                32.8513
2017-06-10 21:53:24.216281 EDT | AverageAbsQYDiff            0.66708
2017-06-10 21:53:24.216804 EDT | AverageAction               0.910556
2017-06-10 21:53:24.217158 EDT | PolicyRegParamNorm         64.9354
2017-06-10 21:53:24.217681 EDT | QFunRegParamNorm           80.271
2017-06-10 21:53:24.218128 EDT | -----------------------  -----------
2017-06-10 21:53:24.218741 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #350 | Training started
2017-06-10 21:53:38.735674 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #350 | Training finished
2017-06-10 21:53:38.736417 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #350 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 21:53:38.736788 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #350 | Collecting samples for evaluation
2017-06-10 21:53:51.002142 EDT | -----------------------  -----------
2017-06-10 21:53:51.002581 EDT | Epoch                     350
2017-06-10 21:53:51.002945 EDT | Iteration                 350
2017-06-10 21:53:51.003270 EDT | AverageReturn             822.617
2017-06-10 21:53:51.003596 EDT | StdReturn                 301.527
2017-06-10 21:53:51.003934 EDT | MaxReturn                1669.75
2017-06-10 21:53:51.004239 EDT | MinReturn                 312.428
2017-06-10 21:53:51.004497 EDT | AverageEsReturn           440.804
2017-06-10 21:53:51.007447 EDT | StdEsReturn               374.405
2017-06-10 21:53:51.009344 EDT | MaxEsReturn              1133.67
2017-06-10 21:53:51.009839 EDT | MinEsReturn                51.0284
2017-06-10 21:53:51.010105 EDT | AverageDiscountedReturn   192.782
2017-06-10 21:53:51.010445 EDT | AverageQLoss                3.0267
2017-06-10 21:53:51.010783 EDT | AveragePolicySurr         -33.3539
2017-06-10 21:53:51.011123 EDT | AverageQ                   32.8106
2017-06-10 21:53:51.011388 EDT | AverageAbsQ                32.8395
2017-06-10 21:53:51.011703 EDT | AverageY                   32.8117
2017-06-10 21:53:51.012043 EDT | AverageAbsY                32.8218
2017-06-10 21:53:51.012403 EDT | AverageAbsQYDiff            0.685282
2017-06-10 21:53:51.012706 EDT | AverageAction               0.848493
2017-06-10 21:53:51.013030 EDT | PolicyRegParamNorm         64.9833
2017-06-10 21:53:51.013366 EDT | QFunRegParamNorm           80.372
2017-06-10 21:53:51.013686 EDT | -----------------------  -----------
2017-06-10 21:53:51.014177 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #351 | Training started
2017-06-10 21:54:06.101612 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #351 | Training finished
2017-06-10 21:54:06.102482 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #351 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 21:54:06.102709 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #351 | Collecting samples for evaluation
2017-06-10 21:54:19.043844 EDT | -----------------------  -----------
2017-06-10 21:54:19.044659 EDT | Epoch                     351
2017-06-10 21:54:19.045616 EDT | Iteration                 351
2017-06-10 21:54:19.046155 EDT | AverageReturn             370.09
2017-06-10 21:54:19.046581 EDT | StdReturn                 245.536
2017-06-10 21:54:19.047050 EDT | MaxReturn                1514.85
2017-06-10 21:54:19.047425 EDT | MinReturn                 258.89
2017-06-10 21:54:19.047790 EDT | AverageEsReturn           358.248
2017-06-10 21:54:19.048160 EDT | StdEsReturn               276.386
2017-06-10 21:54:19.048528 EDT | MaxEsReturn               801.242
2017-06-10 21:54:19.048907 EDT | MinEsReturn                43.6991
2017-06-10 21:54:19.049316 EDT | AverageDiscountedReturn   153.978
2017-06-10 21:54:19.049835 EDT | AverageQLoss                3.05508
2017-06-10 21:54:19.050152 EDT | AveragePolicySurr         -33.2604
2017-06-10 21:54:19.050594 EDT | AverageQ                   32.7347
2017-06-10 21:54:19.051172 EDT | AverageAbsQ                32.7715
2017-06-10 21:54:19.051677 EDT | AverageY                   32.7368
2017-06-10 21:54:19.052076 EDT | AverageAbsY                32.752
2017-06-10 21:54:19.052472 EDT | AverageAbsQYDiff            0.684172
2017-06-10 21:54:19.052840 EDT | AverageAction               0.883448
2017-06-10 21:54:19.053209 EDT | PolicyRegParamNorm         65.0676
2017-06-10 21:54:19.053632 EDT | QFunRegParamNorm           80.4643
2017-06-10 21:54:19.053997 EDT | -----------------------  -----------
2017-06-10 21:54:19.055163 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #352 | Training started
2017-06-10 21:54:34.001538 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #352 | Training finished
2017-06-10 21:54:34.002340 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #352 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 21:54:34.002619 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #352 | Collecting samples for evaluation
2017-06-10 21:54:45.971296 EDT | -----------------------  -----------
2017-06-10 21:54:45.972301 EDT | Epoch                     352
2017-06-10 21:54:45.972681 EDT | Iteration                 352
2017-06-10 21:54:45.973029 EDT | AverageReturn             991.414
2017-06-10 21:54:45.973376 EDT | StdReturn                 517.445
2017-06-10 21:54:45.973729 EDT | MaxReturn                2652.31
2017-06-10 21:54:45.974071 EDT | MinReturn                 327.252
2017-06-10 21:54:45.974423 EDT | AverageEsReturn           357.563
2017-06-10 21:54:45.974731 EDT | StdEsReturn               178.447
2017-06-10 21:54:45.974990 EDT | MaxEsReturn               656.486
2017-06-10 21:54:45.975241 EDT | MinEsReturn                31.5113
2017-06-10 21:54:45.975499 EDT | AverageDiscountedReturn   202.566
2017-06-10 21:54:45.975770 EDT | AverageQLoss                2.88972
2017-06-10 21:54:45.976055 EDT | AveragePolicySurr         -33.252
2017-06-10 21:54:45.976326 EDT | AverageQ                   32.7148
2017-06-10 21:54:45.976663 EDT | AverageAbsQ                32.744
2017-06-10 21:54:45.977001 EDT | AverageY                   32.7153
2017-06-10 21:54:45.977339 EDT | AverageAbsY                32.73
2017-06-10 21:54:45.977592 EDT | AverageAbsQYDiff            0.661328
2017-06-10 21:54:45.977860 EDT | AverageAction               0.825475
2017-06-10 21:54:45.978104 EDT | PolicyRegParamNorm         65.1094
2017-06-10 21:54:45.978342 EDT | QFunRegParamNorm           80.5552
2017-06-10 21:54:45.978610 EDT | -----------------------  -----------
2017-06-10 21:54:45.979106 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #353 | Training started
2017-06-10 21:55:01.309438 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #353 | Training finished
2017-06-10 21:55:01.310465 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #353 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 21:55:01.310847 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #353 | Collecting samples for evaluation
2017-06-10 21:55:13.598596 EDT | -----------------------  -----------
2017-06-10 21:55:13.599336 EDT | Epoch                     353
2017-06-10 21:55:13.599578 EDT | Iteration                 353
2017-06-10 21:55:13.599773 EDT | AverageReturn             429.938
2017-06-10 21:55:13.600335 EDT | StdReturn                 368.223
2017-06-10 21:55:13.600618 EDT | MaxReturn                1619.83
2017-06-10 21:55:13.601006 EDT | MinReturn                 211.997
2017-06-10 21:55:13.601186 EDT | AverageEsReturn           688.774
2017-06-10 21:55:13.601446 EDT | StdEsReturn               393.081
2017-06-10 21:55:13.601751 EDT | MaxEsReturn              1240.71
2017-06-10 21:55:13.602196 EDT | MinEsReturn               149.441
2017-06-10 21:55:13.602562 EDT | AverageDiscountedReturn   149.153
2017-06-10 21:55:13.602861 EDT | AverageQLoss                2.97592
2017-06-10 21:55:13.603134 EDT | AveragePolicySurr         -33.2048
2017-06-10 21:55:13.603320 EDT | AverageQ                   32.6416
2017-06-10 21:55:13.603503 EDT | AverageAbsQ                32.6773
2017-06-10 21:55:13.603777 EDT | AverageY                   32.6437
2017-06-10 21:55:13.603956 EDT | AverageAbsY                32.6627
2017-06-10 21:55:13.604137 EDT | AverageAbsQYDiff            0.674949
2017-06-10 21:55:13.604318 EDT | AverageAction               0.901125
2017-06-10 21:55:13.604655 EDT | PolicyRegParamNorm         65.2082
2017-06-10 21:55:13.604837 EDT | QFunRegParamNorm           80.6628
2017-06-10 21:55:13.605075 EDT | -----------------------  -----------
2017-06-10 21:55:13.605458 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #354 | Training started
2017-06-10 21:55:28.415751 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #354 | Training finished
2017-06-10 21:55:28.416674 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #354 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 21:55:28.417048 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #354 | Collecting samples for evaluation
2017-06-10 21:55:41.268047 EDT | -----------------------  -----------
2017-06-10 21:55:41.268767 EDT | Epoch                     354
2017-06-10 21:55:41.268982 EDT | Iteration                 354
2017-06-10 21:55:41.269267 EDT | AverageReturn            1586.41
2017-06-10 21:55:41.269439 EDT | StdReturn                 473.077
2017-06-10 21:55:41.269629 EDT | MaxReturn                2427.63
2017-06-10 21:55:41.269835 EDT | MinReturn                 908.989
2017-06-10 21:55:41.270026 EDT | AverageEsReturn           522.21
2017-06-10 21:55:41.270404 EDT | StdEsReturn               314.657
2017-06-10 21:55:41.270676 EDT | MaxEsReturn               876.18
2017-06-10 21:55:41.270866 EDT | MinEsReturn                31.5717
2017-06-10 21:55:41.271055 EDT | AverageDiscountedReturn   225.51
2017-06-10 21:55:41.271236 EDT | AverageQLoss                3.0793
2017-06-10 21:55:41.271414 EDT | AveragePolicySurr         -33.1762
2017-06-10 21:55:41.271673 EDT | AverageQ                   32.6111
2017-06-10 21:55:41.272003 EDT | AverageAbsQ                32.6512
2017-06-10 21:55:41.272368 EDT | AverageY                   32.612
2017-06-10 21:55:41.272564 EDT | AverageAbsY                32.632
2017-06-10 21:55:41.272726 EDT | AverageAbsQYDiff            0.693886
2017-06-10 21:55:41.272885 EDT | AverageAction               0.847868
2017-06-10 21:55:41.273041 EDT | PolicyRegParamNorm         65.3164
2017-06-10 21:55:41.273197 EDT | QFunRegParamNorm           80.7606
2017-06-10 21:55:41.273351 EDT | -----------------------  -----------
2017-06-10 21:55:41.274034 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #355 | Training started
2017-06-10 21:55:54.963613 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #355 | Training finished
2017-06-10 21:55:54.964023 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #355 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 21:55:54.964328 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #355 | Collecting samples for evaluation
2017-06-10 21:56:08.336237 EDT | -----------------------  -----------
2017-06-10 21:56:08.337051 EDT | Epoch                     355
2017-06-10 21:56:08.337232 EDT | Iteration                 355
2017-06-10 21:56:08.337396 EDT | AverageReturn            1431.13
2017-06-10 21:56:08.337563 EDT | StdReturn                1007.49
2017-06-10 21:56:08.337927 EDT | MaxReturn                3057.76
2017-06-10 21:56:08.338095 EDT | MinReturn                 272.291
2017-06-10 21:56:08.339025 EDT | AverageEsReturn           416.4
2017-06-10 21:56:08.341088 EDT | StdEsReturn               167.076
2017-06-10 21:56:08.341272 EDT | MaxEsReturn               580.296
2017-06-10 21:56:08.341467 EDT | MinEsReturn               186.483
2017-06-10 21:56:08.342211 EDT | AverageDiscountedReturn   200.699
2017-06-10 21:56:08.343145 EDT | AverageQLoss                2.97302
2017-06-10 21:56:08.343338 EDT | AveragePolicySurr         -33.1634
2017-06-10 21:56:08.343521 EDT | AverageQ                   32.6322
2017-06-10 21:56:08.343703 EDT | AverageAbsQ                32.6635
2017-06-10 21:56:08.343885 EDT | AverageY                   32.6333
2017-06-10 21:56:08.344065 EDT | AverageAbsY                32.6504
2017-06-10 21:56:08.344246 EDT | AverageAbsQYDiff            0.687266
2017-06-10 21:56:08.344426 EDT | AverageAction               0.893964
2017-06-10 21:56:08.344605 EDT | PolicyRegParamNorm         65.3917
2017-06-10 21:56:08.344784 EDT | QFunRegParamNorm           80.8921
2017-06-10 21:56:08.344963 EDT | -----------------------  -----------
2017-06-10 21:56:08.345269 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #356 | Training started
2017-06-10 21:56:23.335099 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #356 | Training finished
2017-06-10 21:56:23.336170 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #356 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 21:56:23.336440 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #356 | Collecting samples for evaluation
2017-06-10 21:56:34.739994 EDT | -----------------------  -----------
2017-06-10 21:56:34.742389 EDT | Epoch                     356
2017-06-10 21:56:34.742721 EDT | Iteration                 356
2017-06-10 21:56:34.743228 EDT | AverageReturn             348.899
2017-06-10 21:56:34.743444 EDT | StdReturn                 414.377
2017-06-10 21:56:34.743681 EDT | MaxReturn                2775.77
2017-06-10 21:56:34.743896 EDT | MinReturn                 180.085
2017-06-10 21:56:34.744085 EDT | AverageEsReturn           396.758
2017-06-10 21:56:34.744268 EDT | StdEsReturn               268.814
2017-06-10 21:56:34.744453 EDT | MaxEsReturn               835.465
2017-06-10 21:56:34.745199 EDT | MinEsReturn                49.195
2017-06-10 21:56:34.745628 EDT | AverageDiscountedReturn   136.209
2017-06-10 21:56:34.746061 EDT | AverageQLoss                2.97324
2017-06-10 21:56:34.748742 EDT | AveragePolicySurr         -33.1678
2017-06-10 21:56:34.749020 EDT | AverageQ                   32.6244
2017-06-10 21:56:34.749308 EDT | AverageAbsQ                32.6555
2017-06-10 21:56:34.749602 EDT | AverageY                   32.6284
2017-06-10 21:56:34.749901 EDT | AverageAbsY                32.6412
2017-06-10 21:56:34.750087 EDT | AverageAbsQYDiff            0.672963
2017-06-10 21:56:34.750395 EDT | AverageAction               0.923825
2017-06-10 21:56:34.750601 EDT | PolicyRegParamNorm         65.481
2017-06-10 21:56:34.751091 EDT | QFunRegParamNorm           81.0267
2017-06-10 21:56:34.751313 EDT | -----------------------  -----------
2017-06-10 21:56:34.751723 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #357 | Training started
2017-06-10 21:56:50.515224 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #357 | Training finished
2017-06-10 21:56:50.515997 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #357 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 21:56:50.516236 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #357 | Collecting samples for evaluation
2017-06-10 21:57:03.239470 EDT | -----------------------  -----------
2017-06-10 21:57:03.240388 EDT | Epoch                     357
2017-06-10 21:57:03.240735 EDT | Iteration                 357
2017-06-10 21:57:03.241071 EDT | AverageReturn            1854.26
2017-06-10 21:57:03.241405 EDT | StdReturn                 866.5
2017-06-10 21:57:03.241735 EDT | MaxReturn                3064.57
2017-06-10 21:57:03.242067 EDT | MinReturn                 534.54
2017-06-10 21:57:03.242403 EDT | AverageEsReturn           672.054
2017-06-10 21:57:03.242729 EDT | StdEsReturn               614.4
2017-06-10 21:57:03.243057 EDT | MaxEsReturn              1645.8
2017-06-10 21:57:03.243391 EDT | MinEsReturn                40.035
2017-06-10 21:57:03.243702 EDT | AverageDiscountedReturn   218.707
2017-06-10 21:57:03.244029 EDT | AverageQLoss                2.77312
2017-06-10 21:57:03.244424 EDT | AveragePolicySurr         -33.2026
2017-06-10 21:57:03.244758 EDT | AverageQ                   32.6288
2017-06-10 21:57:03.245161 EDT | AverageAbsQ                32.6648
2017-06-10 21:57:03.245691 EDT | AverageY                   32.6266
2017-06-10 21:57:03.246030 EDT | AverageAbsY                32.6413
2017-06-10 21:57:03.246358 EDT | AverageAbsQYDiff            0.670085
2017-06-10 21:57:03.246689 EDT | AverageAction               0.878067
2017-06-10 21:57:03.247088 EDT | PolicyRegParamNorm         65.517
2017-06-10 21:57:03.247413 EDT | QFunRegParamNorm           81.1451
2017-06-10 21:57:03.247745 EDT | -----------------------  -----------
2017-06-10 21:57:03.248210 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #358 | Training started
2017-06-10 21:57:18.237786 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #358 | Training finished
2017-06-10 21:57:18.238991 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #358 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 21:57:18.239561 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #358 | Collecting samples for evaluation
2017-06-10 21:57:30.918324 EDT | -----------------------  -----------
2017-06-10 21:57:30.919625 EDT | Epoch                     358
2017-06-10 21:57:30.920111 EDT | Iteration                 358
2017-06-10 21:57:30.920580 EDT | AverageReturn            1133.88
2017-06-10 21:57:30.921155 EDT | StdReturn                 488.723
2017-06-10 21:57:30.921618 EDT | MaxReturn                2502.17
2017-06-10 21:57:30.922214 EDT | MinReturn                 578.42
2017-06-10 21:57:30.922682 EDT | AverageEsReturn           528.321
2017-06-10 21:57:30.923149 EDT | StdEsReturn               259.794
2017-06-10 21:57:30.923718 EDT | MaxEsReturn              1000.43
2017-06-10 21:57:30.924181 EDT | MinEsReturn               264.787
2017-06-10 21:57:30.924741 EDT | AverageDiscountedReturn   203.54
2017-06-10 21:57:30.925205 EDT | AverageQLoss                2.79449
2017-06-10 21:57:30.925788 EDT | AveragePolicySurr         -33.1473
2017-06-10 21:57:30.926258 EDT | AverageQ                   32.6139
2017-06-10 21:57:30.926720 EDT | AverageAbsQ                32.6451
2017-06-10 21:57:30.927284 EDT | AverageY                   32.6177
2017-06-10 21:57:30.927746 EDT | AverageAbsY                32.6316
2017-06-10 21:57:30.928284 EDT | AverageAbsQYDiff            0.672532
2017-06-10 21:57:30.928752 EDT | AverageAction               0.864574
2017-06-10 21:57:30.929218 EDT | PolicyRegParamNorm         65.5798
2017-06-10 21:57:30.929785 EDT | QFunRegParamNorm           81.2892
2017-06-10 21:57:30.930249 EDT | -----------------------  -----------
2017-06-10 21:57:30.930981 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #359 | Training started
2017-06-10 21:57:45.494516 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #359 | Training finished
2017-06-10 21:57:45.495407 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #359 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 21:57:45.495702 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #359 | Collecting samples for evaluation
2017-06-10 21:57:58.595417 EDT | -----------------------  -----------
2017-06-10 21:57:58.597985 EDT | Epoch                     359
2017-06-10 21:57:58.598358 EDT | Iteration                 359
2017-06-10 21:57:58.598685 EDT | AverageReturn            1987.44
2017-06-10 21:57:58.599003 EDT | StdReturn                 725.002
2017-06-10 21:57:58.599301 EDT | MaxReturn                2642.07
2017-06-10 21:57:58.599622 EDT | MinReturn                 608.178
2017-06-10 21:57:58.599925 EDT | AverageEsReturn           645.405
2017-06-10 21:57:58.600208 EDT | StdEsReturn               459.591
2017-06-10 21:57:58.600488 EDT | MaxEsReturn              1266.43
2017-06-10 21:57:58.600773 EDT | MinEsReturn               155.832
2017-06-10 21:57:58.601133 EDT | AverageDiscountedReturn   213.294
2017-06-10 21:57:58.601291 EDT | AverageQLoss                3.15008
2017-06-10 21:57:58.601443 EDT | AveragePolicySurr         -33.0826
2017-06-10 21:57:58.601727 EDT | AverageQ                   32.5422
2017-06-10 21:57:58.601920 EDT | AverageAbsQ                32.5756
2017-06-10 21:57:58.602073 EDT | AverageY                   32.5441
2017-06-10 21:57:58.602412 EDT | AverageAbsY                32.5609
2017-06-10 21:57:58.602749 EDT | AverageAbsQYDiff            0.692967
2017-06-10 21:57:58.603074 EDT | AverageAction               0.837666
2017-06-10 21:57:58.603393 EDT | PolicyRegParamNorm         65.6793
2017-06-10 21:57:58.603825 EDT | QFunRegParamNorm           81.3807
2017-06-10 21:57:58.604165 EDT | -----------------------  -----------
2017-06-10 21:57:58.604611 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #360 | Training started
2017-06-10 21:58:13.697102 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #360 | Training finished
2017-06-10 21:58:13.698003 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #360 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 21:58:13.698529 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #360 | Collecting samples for evaluation
2017-06-10 21:58:26.523377 EDT | -----------------------  -----------
2017-06-10 21:58:26.523965 EDT | Epoch                     360
2017-06-10 21:58:26.524430 EDT | Iteration                 360
2017-06-10 21:58:26.524895 EDT | AverageReturn            2183.53
2017-06-10 21:58:26.526173 EDT | StdReturn                 735.187
2017-06-10 21:58:26.526557 EDT | MaxReturn                3274.13
2017-06-10 21:58:26.527995 EDT | MinReturn                1303.55
2017-06-10 21:58:26.528377 EDT | AverageEsReturn           326.64
2017-06-10 21:58:26.528740 EDT | StdEsReturn               166.109
2017-06-10 21:58:26.530005 EDT | MaxEsReturn               595.004
2017-06-10 21:58:26.530388 EDT | MinEsReturn                75.1634
2017-06-10 21:58:26.530739 EDT | AverageDiscountedReturn   239.553
2017-06-10 21:58:26.531081 EDT | AverageQLoss                2.60587
2017-06-10 21:58:26.533271 EDT | AveragePolicySurr         -33.076
2017-06-10 21:58:26.533648 EDT | AverageQ                   32.5477
2017-06-10 21:58:26.535073 EDT | AverageAbsQ                32.5788
2017-06-10 21:58:26.535542 EDT | AverageY                   32.5496
2017-06-10 21:58:26.536821 EDT | AverageAbsY                32.5627
2017-06-10 21:58:26.537282 EDT | AverageAbsQYDiff            0.643032
2017-06-10 21:58:26.537636 EDT | AverageAction               0.782723
2017-06-10 21:58:26.539208 EDT | PolicyRegParamNorm         65.7468
2017-06-10 21:58:26.539577 EDT | QFunRegParamNorm           81.4367
2017-06-10 21:58:26.541186 EDT | -----------------------  -----------
2017-06-10 21:58:26.542577 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #361 | Training started
2017-06-10 21:58:41.183190 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #361 | Training finished
2017-06-10 21:58:41.183966 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #361 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 21:58:41.184300 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #361 | Collecting samples for evaluation
2017-06-10 21:58:53.293951 EDT | -----------------------  -----------
2017-06-10 21:58:53.311777 EDT | Epoch                     361
2017-06-10 21:58:53.312207 EDT | Iteration                 361
2017-06-10 21:58:53.312511 EDT | AverageReturn            1395.77
2017-06-10 21:58:53.312865 EDT | StdReturn                 413.974
2017-06-10 21:58:53.313223 EDT | MaxReturn                2519.59
2017-06-10 21:58:53.313559 EDT | MinReturn                 930.269
2017-06-10 21:58:53.313913 EDT | AverageEsReturn           394.405
2017-06-10 21:58:53.314251 EDT | StdEsReturn               228.958
2017-06-10 21:58:53.314562 EDT | MaxEsReturn               645.843
2017-06-10 21:58:53.314880 EDT | MinEsReturn                49.2994
2017-06-10 21:58:53.315119 EDT | AverageDiscountedReturn   241.921
2017-06-10 21:58:53.315281 EDT | AverageQLoss                2.65884
2017-06-10 21:58:53.315446 EDT | AveragePolicySurr         -33.0503
2017-06-10 21:58:53.315634 EDT | AverageQ                   32.5244
2017-06-10 21:58:53.315814 EDT | AverageAbsQ                32.5592
2017-06-10 21:58:53.315994 EDT | AverageY                   32.5269
2017-06-10 21:58:53.316165 EDT | AverageAbsY                32.5459
2017-06-10 21:58:53.316329 EDT | AverageAbsQYDiff            0.667858
2017-06-10 21:58:53.316487 EDT | AverageAction               0.848477
2017-06-10 21:58:53.316649 EDT | PolicyRegParamNorm         65.8181
2017-06-10 21:58:53.316830 EDT | QFunRegParamNorm           81.5289
2017-06-10 21:58:53.317003 EDT | -----------------------  -----------
2017-06-10 21:58:53.317244 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #362 | Training started
2017-06-10 21:59:09.123545 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #362 | Training finished
2017-06-10 21:59:09.126172 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #362 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 21:59:09.126898 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #362 | Collecting samples for evaluation
2017-06-10 21:59:20.873162 EDT | -----------------------  -----------
2017-06-10 21:59:20.874219 EDT | Epoch                     362
2017-06-10 21:59:20.874532 EDT | Iteration                 362
2017-06-10 21:59:20.874969 EDT | AverageReturn            2271
2017-06-10 21:59:20.875399 EDT | StdReturn                 670.848
2017-06-10 21:59:20.875827 EDT | MaxReturn                2994.61
2017-06-10 21:59:20.877017 EDT | MinReturn                 924.417
2017-06-10 21:59:20.877454 EDT | AverageEsReturn           288.715
2017-06-10 21:59:20.877855 EDT | StdEsReturn               220.895
2017-06-10 21:59:20.878113 EDT | MaxEsReturn               681.589
2017-06-10 21:59:20.878452 EDT | MinEsReturn                32.2233
2017-06-10 21:59:20.878795 EDT | AverageDiscountedReturn   224.733
2017-06-10 21:59:20.879103 EDT | AverageQLoss                2.67034
2017-06-10 21:59:20.879424 EDT | AveragePolicySurr         -33.1881
2017-06-10 21:59:20.879751 EDT | AverageQ                   32.6367
2017-06-10 21:59:20.880087 EDT | AverageAbsQ                32.6722
2017-06-10 21:59:20.880296 EDT | AverageY                   32.6333
2017-06-10 21:59:20.880623 EDT | AverageAbsY                32.6505
2017-06-10 21:59:20.880953 EDT | AverageAbsQYDiff            0.656949
2017-06-10 21:59:20.881283 EDT | AverageAction               0.832624
2017-06-10 21:59:20.881615 EDT | PolicyRegParamNorm         65.829
2017-06-10 21:59:20.881959 EDT | QFunRegParamNorm           81.6655
2017-06-10 21:59:20.882276 EDT | -----------------------  -----------
2017-06-10 21:59:20.882759 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #363 | Training started
2017-06-10 21:59:36.162718 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #363 | Training finished
2017-06-10 21:59:36.163662 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #363 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 21:59:36.164307 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #363 | Collecting samples for evaluation
2017-06-10 21:59:49.731234 EDT | -----------------------  -----------
2017-06-10 21:59:49.732493 EDT | Epoch                     363
2017-06-10 21:59:49.732705 EDT | Iteration                 363
2017-06-10 21:59:49.733334 EDT | AverageReturn            2308.83
2017-06-10 21:59:49.734122 EDT | StdReturn                 636.225
2017-06-10 21:59:49.734407 EDT | MaxReturn                2736.16
2017-06-10 21:59:49.734709 EDT | MinReturn                 528.058
2017-06-10 21:59:49.735014 EDT | AverageEsReturn           280.202
2017-06-10 21:59:49.735316 EDT | StdEsReturn               245.284
2017-06-10 21:59:49.735568 EDT | MaxEsReturn               634.06
2017-06-10 21:59:49.735848 EDT | MinEsReturn                11.8694
2017-06-10 21:59:49.736169 EDT | AverageDiscountedReturn   220.104
2017-06-10 21:59:49.736379 EDT | AverageQLoss                2.38929
2017-06-10 21:59:49.736682 EDT | AveragePolicySurr         -33.0572
2017-06-10 21:59:49.736879 EDT | AverageQ                   32.5144
2017-06-10 21:59:49.737116 EDT | AverageAbsQ                32.5478
2017-06-10 21:59:49.737582 EDT | AverageY                   32.5187
2017-06-10 21:59:49.737849 EDT | AverageAbsY                32.5348
2017-06-10 21:59:49.738041 EDT | AverageAbsQYDiff            0.650032
2017-06-10 21:59:49.738215 EDT | AverageAction               0.906147
2017-06-10 21:59:49.738448 EDT | PolicyRegParamNorm         65.919
2017-06-10 21:59:49.738656 EDT | QFunRegParamNorm           81.7707
2017-06-10 21:59:49.739262 EDT | -----------------------  -----------
2017-06-10 21:59:49.739728 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #364 | Training started
2017-06-10 22:00:03.842724 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #364 | Training finished
2017-06-10 22:00:03.843499 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #364 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 22:00:03.843753 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #364 | Collecting samples for evaluation
2017-06-10 22:00:16.683976 EDT | -----------------------  -----------
2017-06-10 22:00:16.686942 EDT | Epoch                     364
2017-06-10 22:00:16.687392 EDT | Iteration                 364
2017-06-10 22:00:16.687777 EDT | AverageReturn            2485.89
2017-06-10 22:00:16.688218 EDT | StdReturn                 638.653
2017-06-10 22:00:16.688634 EDT | MaxReturn                3101.46
2017-06-10 22:00:16.689047 EDT | MinReturn                 964.301
2017-06-10 22:00:16.689537 EDT | AverageEsReturn           476.49
2017-06-10 22:00:16.689971 EDT | StdEsReturn               320.626
2017-06-10 22:00:16.690402 EDT | MaxEsReturn               930.667
2017-06-10 22:00:16.690825 EDT | MinEsReturn               118.43
2017-06-10 22:00:16.691239 EDT | AverageDiscountedReturn   233.728
2017-06-10 22:00:16.691648 EDT | AverageQLoss                3.18066
2017-06-10 22:00:16.692154 EDT | AveragePolicySurr         -33.1219
2017-06-10 22:00:16.692733 EDT | AverageQ                   32.5821
2017-06-10 22:00:16.693132 EDT | AverageAbsQ                32.6169
2017-06-10 22:00:16.693479 EDT | AverageY                   32.5847
2017-06-10 22:00:16.693821 EDT | AverageAbsY                32.6018
2017-06-10 22:00:16.694142 EDT | AverageAbsQYDiff            0.68938
2017-06-10 22:00:16.694928 EDT | AverageAction               0.897904
2017-06-10 22:00:16.695584 EDT | PolicyRegParamNorm         66.0049
2017-06-10 22:00:16.696819 EDT | QFunRegParamNorm           81.8846
2017-06-10 22:00:16.697144 EDT | -----------------------  -----------
2017-06-10 22:00:16.697600 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #365 | Training started
2017-06-10 22:00:31.250180 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #365 | Training finished
2017-06-10 22:00:31.251471 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #365 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 22:00:31.251776 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #365 | Collecting samples for evaluation
2017-06-10 22:00:42.060303 EDT | -----------------------  -----------
2017-06-10 22:00:42.061050 EDT | Epoch                     365
2017-06-10 22:00:42.061243 EDT | Iteration                 365
2017-06-10 22:00:42.061433 EDT | AverageReturn            1165.49
2017-06-10 22:00:42.061616 EDT | StdReturn                1069.79
2017-06-10 22:00:42.061827 EDT | MaxReturn                2974.7
2017-06-10 22:00:42.062037 EDT | MinReturn                 260.802
2017-06-10 22:00:42.062253 EDT | AverageEsReturn           245.717
2017-06-10 22:00:42.062437 EDT | StdEsReturn               183.06
2017-06-10 22:00:42.062711 EDT | MaxEsReturn               590.262
2017-06-10 22:00:42.062939 EDT | MinEsReturn                63.2697
2017-06-10 22:00:42.063510 EDT | AverageDiscountedReturn   190.933
2017-06-10 22:00:42.063688 EDT | AverageQLoss                2.42389
2017-06-10 22:00:42.063882 EDT | AveragePolicySurr         -33.0976
2017-06-10 22:00:42.064367 EDT | AverageQ                   32.5753
2017-06-10 22:00:42.064545 EDT | AverageAbsQ                32.6066
2017-06-10 22:00:42.064727 EDT | AverageY                   32.5771
2017-06-10 22:00:42.064916 EDT | AverageAbsY                32.5899
2017-06-10 22:00:42.065097 EDT | AverageAbsQYDiff            0.647352
2017-06-10 22:00:42.065276 EDT | AverageAction               0.910881
2017-06-10 22:00:42.065716 EDT | PolicyRegParamNorm         66.0571
2017-06-10 22:00:42.068548 EDT | QFunRegParamNorm           82.0114
2017-06-10 22:00:42.069094 EDT | -----------------------  -----------
2017-06-10 22:00:42.069667 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #366 | Training started
2017-06-10 22:00:57.913580 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #366 | Training finished
2017-06-10 22:00:57.929829 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #366 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 22:00:57.930256 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #366 | Collecting samples for evaluation
2017-06-10 22:01:10.943944 EDT | -----------------------  -----------
2017-06-10 22:01:10.944723 EDT | Epoch                     366
2017-06-10 22:01:10.944910 EDT | Iteration                 366
2017-06-10 22:01:10.945095 EDT | AverageReturn            1825.08
2017-06-10 22:01:10.945349 EDT | StdReturn                 909.386
2017-06-10 22:01:10.945637 EDT | MaxReturn                2939.07
2017-06-10 22:01:10.945817 EDT | MinReturn                 768.907
2017-06-10 22:01:10.945982 EDT | AverageEsReturn           453.864
2017-06-10 22:01:10.946158 EDT | StdEsReturn               399.907
2017-06-10 22:01:10.946321 EDT | MaxEsReturn              1226.48
2017-06-10 22:01:10.946483 EDT | MinEsReturn                63.4689
2017-06-10 22:01:10.946801 EDT | AverageDiscountedReturn   227.05
2017-06-10 22:01:10.947035 EDT | AverageQLoss                2.89908
2017-06-10 22:01:10.947314 EDT | AveragePolicySurr         -33.0233
2017-06-10 22:01:10.947515 EDT | AverageQ                   32.476
2017-06-10 22:01:10.947711 EDT | AverageAbsQ                32.5093
2017-06-10 22:01:10.948087 EDT | AverageY                   32.4782
2017-06-10 22:01:10.948428 EDT | AverageAbsY                32.4953
2017-06-10 22:01:10.948744 EDT | AverageAbsQYDiff            0.666889
2017-06-10 22:01:10.949161 EDT | AverageAction               0.863733
2017-06-10 22:01:10.949582 EDT | PolicyRegParamNorm         66.0858
2017-06-10 22:01:10.949947 EDT | QFunRegParamNorm           82.1649
2017-06-10 22:01:10.950370 EDT | -----------------------  -----------
2017-06-10 22:01:10.950874 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #367 | Training started
2017-06-10 22:01:25.616117 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #367 | Training finished
2017-06-10 22:01:25.616849 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #367 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 22:01:25.617031 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #367 | Collecting samples for evaluation
2017-06-10 22:01:38.516164 EDT | -----------------------  -----------
2017-06-10 22:01:38.516877 EDT | Epoch                     367
2017-06-10 22:01:38.517163 EDT | Iteration                 367
2017-06-10 22:01:38.517378 EDT | AverageReturn             531.204
2017-06-10 22:01:38.517934 EDT | StdReturn                 271.897
2017-06-10 22:01:38.518241 EDT | MaxReturn                2086.32
2017-06-10 22:01:38.518558 EDT | MinReturn                 263.56
2017-06-10 22:01:38.519002 EDT | AverageEsReturn           451.814
2017-06-10 22:01:38.519437 EDT | StdEsReturn               221.527
2017-06-10 22:01:38.519880 EDT | MaxEsReturn               675.643
2017-06-10 22:01:38.520362 EDT | MinEsReturn                55.8613
2017-06-10 22:01:38.520741 EDT | AverageDiscountedReturn   189.321
2017-06-10 22:01:38.522031 EDT | AverageQLoss                2.90832
2017-06-10 22:01:38.522420 EDT | AveragePolicySurr         -33.0005
2017-06-10 22:01:38.522854 EDT | AverageQ                   32.4503
2017-06-10 22:01:38.523545 EDT | AverageAbsQ                32.4866
2017-06-10 22:01:38.523943 EDT | AverageY                   32.4523
2017-06-10 22:01:38.524298 EDT | AverageAbsY                32.4676
2017-06-10 22:01:38.524728 EDT | AverageAbsQYDiff            0.676503
2017-06-10 22:01:38.525052 EDT | AverageAction               0.897913
2017-06-10 22:01:38.525338 EDT | PolicyRegParamNorm         66.126
2017-06-10 22:01:38.525687 EDT | QFunRegParamNorm           82.2846
2017-06-10 22:01:38.525987 EDT | -----------------------  -----------
2017-06-10 22:01:38.526443 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #368 | Training started
2017-06-10 22:01:53.307532 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #368 | Training finished
2017-06-10 22:01:53.307970 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #368 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 22:01:53.308301 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #368 | Collecting samples for evaluation
2017-06-10 22:02:06.572005 EDT | -----------------------  -----------
2017-06-10 22:02:06.572776 EDT | Epoch                     368
2017-06-10 22:02:06.573293 EDT | Iteration                 368
2017-06-10 22:02:06.573644 EDT | AverageReturn            2248.03
2017-06-10 22:02:06.574036 EDT | StdReturn                 583.843
2017-06-10 22:02:06.574389 EDT | MaxReturn                2748.75
2017-06-10 22:02:06.574719 EDT | MinReturn                1225.63
2017-06-10 22:02:06.575039 EDT | AverageEsReturn           287.112
2017-06-10 22:02:06.575475 EDT | StdEsReturn               194.495
2017-06-10 22:02:06.575813 EDT | MaxEsReturn               644.012
2017-06-10 22:02:06.577655 EDT | MinEsReturn                 9.35077
2017-06-10 22:02:06.578243 EDT | AverageDiscountedReturn   223.092
2017-06-10 22:02:06.578453 EDT | AverageQLoss                3.02876
2017-06-10 22:02:06.579833 EDT | AveragePolicySurr         -33.0617
2017-06-10 22:02:06.580145 EDT | AverageQ                   32.528
2017-06-10 22:02:06.580338 EDT | AverageAbsQ                32.5649
2017-06-10 22:02:06.580493 EDT | AverageY                   32.5283
2017-06-10 22:02:06.580645 EDT | AverageAbsY                32.5516
2017-06-10 22:02:06.580794 EDT | AverageAbsQYDiff            0.689389
2017-06-10 22:02:06.580942 EDT | AverageAction               0.883932
2017-06-10 22:02:06.581089 EDT | PolicyRegParamNorm         66.2188
2017-06-10 22:02:06.581236 EDT | QFunRegParamNorm           82.4028
2017-06-10 22:02:06.581405 EDT | -----------------------  -----------
2017-06-10 22:02:06.581680 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #369 | Training started
2017-06-10 22:02:21.571359 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #369 | Training finished
2017-06-10 22:02:21.571729 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #369 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 22:02:21.572063 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #369 | Collecting samples for evaluation
2017-06-10 22:02:34.515499 EDT | -----------------------  -----------
2017-06-10 22:02:34.516433 EDT | Epoch                     369
2017-06-10 22:02:34.516805 EDT | Iteration                 369
2017-06-10 22:02:34.517144 EDT | AverageReturn            1473.43
2017-06-10 22:02:34.517380 EDT | StdReturn                 530.584
2017-06-10 22:02:34.517540 EDT | MaxReturn                2727.3
2017-06-10 22:02:34.517711 EDT | MinReturn                 676.576
2017-06-10 22:02:34.517915 EDT | AverageEsReturn           261.072
2017-06-10 22:02:34.518284 EDT | StdEsReturn               180.92
2017-06-10 22:02:34.518534 EDT | MaxEsReturn               576.181
2017-06-10 22:02:34.518689 EDT | MinEsReturn                62.602
2017-06-10 22:02:34.518840 EDT | AverageDiscountedReturn   217.835
2017-06-10 22:02:34.519065 EDT | AverageQLoss                2.86606
2017-06-10 22:02:34.519335 EDT | AveragePolicySurr         -32.91
2017-06-10 22:02:34.519595 EDT | AverageQ                   32.3767
2017-06-10 22:02:34.519854 EDT | AverageAbsQ                32.4134
2017-06-10 22:02:34.520133 EDT | AverageY                   32.3787
2017-06-10 22:02:34.520382 EDT | AverageAbsY                32.3993
2017-06-10 22:02:34.520626 EDT | AverageAbsQYDiff            0.674158
2017-06-10 22:02:34.520869 EDT | AverageAction               0.818967
2017-06-10 22:02:34.522157 EDT | PolicyRegParamNorm         66.2471
2017-06-10 22:02:34.522465 EDT | QFunRegParamNorm           82.5134
2017-06-10 22:02:34.522640 EDT | -----------------------  -----------
2017-06-10 22:02:34.522913 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #370 | Training started
2017-06-10 22:02:49.618480 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #370 | Training finished
2017-06-10 22:02:49.619315 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #370 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 22:02:49.619516 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #370 | Collecting samples for evaluation
2017-06-10 22:03:02.929019 EDT | -----------------------  -----------
2017-06-10 22:03:02.930086 EDT | Epoch                     370
2017-06-10 22:03:02.930345 EDT | Iteration                 370
2017-06-10 22:03:02.930696 EDT | AverageReturn             725.046
2017-06-10 22:03:02.931008 EDT | StdReturn                 240.253
2017-06-10 22:03:02.931299 EDT | MaxReturn                1171.94
2017-06-10 22:03:02.931582 EDT | MinReturn                 391.083
2017-06-10 22:03:02.931888 EDT | AverageEsReturn           354.805
2017-06-10 22:03:02.932207 EDT | StdEsReturn               226.609
2017-06-10 22:03:02.932472 EDT | MaxEsReturn               730.381
2017-06-10 22:03:02.932809 EDT | MinEsReturn               148.681
2017-06-10 22:03:02.933084 EDT | AverageDiscountedReturn   185.226
2017-06-10 22:03:02.933420 EDT | AverageQLoss                2.86267
2017-06-10 22:03:02.933757 EDT | AveragePolicySurr         -32.983
2017-06-10 22:03:02.934100 EDT | AverageQ                   32.469
2017-06-10 22:03:02.934380 EDT | AverageAbsQ                32.5048
2017-06-10 22:03:02.934665 EDT | AverageY                   32.4704
2017-06-10 22:03:02.935012 EDT | AverageAbsY                32.4892
2017-06-10 22:03:02.935295 EDT | AverageAbsQYDiff            0.669348
2017-06-10 22:03:02.935552 EDT | AverageAction               0.854581
2017-06-10 22:03:02.935831 EDT | PolicyRegParamNorm         66.2848
2017-06-10 22:03:02.936130 EDT | QFunRegParamNorm           82.6209
2017-06-10 22:03:02.936413 EDT | -----------------------  -----------
2017-06-10 22:03:02.936825 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #371 | Training started
2017-06-10 22:03:18.932013 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #371 | Training finished
2017-06-10 22:03:18.933018 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #371 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 22:03:18.933401 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #371 | Collecting samples for evaluation
2017-06-10 22:03:31.192855 EDT | -----------------------  -----------
2017-06-10 22:03:31.193816 EDT | Epoch                     371
2017-06-10 22:03:31.194174 EDT | Iteration                 371
2017-06-10 22:03:31.194492 EDT | AverageReturn             925.856
2017-06-10 22:03:31.194819 EDT | StdReturn                 244.561
2017-06-10 22:03:31.195150 EDT | MaxReturn                1583.47
2017-06-10 22:03:31.195454 EDT | MinReturn                 542.837
2017-06-10 22:03:31.195768 EDT | AverageEsReturn           386.054
2017-06-10 22:03:31.196091 EDT | StdEsReturn               335.113
2017-06-10 22:03:31.196397 EDT | MaxEsReturn              1058.55
2017-06-10 22:03:31.196702 EDT | MinEsReturn                41.1096
2017-06-10 22:03:31.197016 EDT | AverageDiscountedReturn   220.676
2017-06-10 22:03:31.197307 EDT | AverageQLoss                2.78669
2017-06-10 22:03:31.197617 EDT | AveragePolicySurr         -32.9839
2017-06-10 22:03:31.198031 EDT | AverageQ                   32.4491
2017-06-10 22:03:31.198311 EDT | AverageAbsQ                32.4831
2017-06-10 22:03:31.198573 EDT | AverageY                   32.449
2017-06-10 22:03:31.198867 EDT | AverageAbsY                32.4666
2017-06-10 22:03:31.199127 EDT | AverageAbsQYDiff            0.665121
2017-06-10 22:03:31.223591 EDT | AverageAction               0.795965
2017-06-10 22:03:31.223863 EDT | PolicyRegParamNorm         66.3104
2017-06-10 22:03:31.224119 EDT | QFunRegParamNorm           82.7506
2017-06-10 22:03:31.224371 EDT | -----------------------  -----------
2017-06-10 22:03:31.224744 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #372 | Training started
2017-06-10 22:03:46.919687 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #372 | Training finished
2017-06-10 22:03:46.920608 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #372 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 22:03:46.920957 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #372 | Collecting samples for evaluation
2017-06-10 22:03:59.578767 EDT | -----------------------  ----------
2017-06-10 22:03:59.579775 EDT | Epoch                    372
2017-06-10 22:03:59.580228 EDT | Iteration                372
2017-06-10 22:03:59.580532 EDT | AverageReturn            466.646
2017-06-10 22:03:59.580702 EDT | StdReturn                144.922
2017-06-10 22:03:59.580881 EDT | MaxReturn                859.526
2017-06-10 22:03:59.581164 EDT | MinReturn                193.77
2017-06-10 22:03:59.581356 EDT | AverageEsReturn          285.001
2017-06-10 22:03:59.581529 EDT | StdEsReturn              234.768
2017-06-10 22:03:59.581719 EDT | MaxEsReturn              761.939
2017-06-10 22:03:59.581971 EDT | MinEsReturn               26.6953
2017-06-10 22:03:59.582160 EDT | AverageDiscountedReturn  173.651
2017-06-10 22:03:59.582361 EDT | AverageQLoss               2.87105
2017-06-10 22:03:59.582523 EDT | AveragePolicySurr        -32.9573
2017-06-10 22:03:59.582730 EDT | AverageQ                  32.4597
2017-06-10 22:03:59.583190 EDT | AverageAbsQ               32.494
2017-06-10 22:03:59.583529 EDT | AverageY                  32.4619
2017-06-10 22:03:59.583812 EDT | AverageAbsY               32.4802
2017-06-10 22:03:59.584091 EDT | AverageAbsQYDiff           0.646805
2017-06-10 22:03:59.584384 EDT | AverageAction              0.913755
2017-06-10 22:03:59.584707 EDT | PolicyRegParamNorm        66.3885
2017-06-10 22:03:59.585045 EDT | QFunRegParamNorm          82.8376
2017-06-10 22:03:59.585360 EDT | -----------------------  ----------
2017-06-10 22:03:59.585822 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #373 | Training started
2017-06-10 22:04:13.827167 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #373 | Training finished
2017-06-10 22:04:13.828316 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #373 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 22:04:13.828702 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #373 | Collecting samples for evaluation
2017-06-10 22:04:27.014015 EDT | -----------------------  ----------
2017-06-10 22:04:27.014946 EDT | Epoch                    373
2017-06-10 22:04:27.015394 EDT | Iteration                373
2017-06-10 22:04:27.015669 EDT | AverageReturn            407.045
2017-06-10 22:04:27.015943 EDT | StdReturn                 89.8066
2017-06-10 22:04:27.016262 EDT | MaxReturn                718.122
2017-06-10 22:04:27.016504 EDT | MinReturn                279.004
2017-06-10 22:04:27.016791 EDT | AverageEsReturn          325.821
2017-06-10 22:04:27.017123 EDT | StdEsReturn              213.741
2017-06-10 22:04:27.017446 EDT | MaxEsReturn              670.541
2017-06-10 22:04:27.017775 EDT | MinEsReturn              117.161
2017-06-10 22:04:27.018079 EDT | AverageDiscountedReturn  157.313
2017-06-10 22:04:27.018385 EDT | AverageQLoss               3.20006
2017-06-10 22:04:27.018698 EDT | AveragePolicySurr        -32.6283
2017-06-10 22:04:27.018972 EDT | AverageQ                  32.1511
2017-06-10 22:04:27.019279 EDT | AverageAbsQ               32.1852
2017-06-10 22:04:27.019596 EDT | AverageY                  32.1528
2017-06-10 22:04:27.019915 EDT | AverageAbsY               32.1736
2017-06-10 22:04:27.020221 EDT | AverageAbsQYDiff           0.677411
2017-06-10 22:04:27.020526 EDT | AverageAction              0.903736
2017-06-10 22:04:27.020833 EDT | PolicyRegParamNorm        66.4498
2017-06-10 22:04:27.021103 EDT | QFunRegParamNorm          82.9202
2017-06-10 22:04:27.021426 EDT | -----------------------  ----------
2017-06-10 22:04:27.021811 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #374 | Training started
2017-06-10 22:04:42.994022 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #374 | Training finished
2017-06-10 22:04:42.995567 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #374 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 22:04:42.995856 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #374 | Collecting samples for evaluation
2017-06-10 22:04:55.718159 EDT | -----------------------  -----------
2017-06-10 22:04:55.718868 EDT | Epoch                     374
2017-06-10 22:04:55.719046 EDT | Iteration                 374
2017-06-10 22:04:55.719204 EDT | AverageReturn            1009.05
2017-06-10 22:04:55.719358 EDT | StdReturn                 447.123
2017-06-10 22:04:55.719590 EDT | MaxReturn                2845.13
2017-06-10 22:04:55.719821 EDT | MinReturn                 644.253
2017-06-10 22:04:55.719974 EDT | AverageEsReturn           458.41
2017-06-10 22:04:55.720125 EDT | StdEsReturn               210.791
2017-06-10 22:04:55.720313 EDT | MaxEsReturn               830.842
2017-06-10 22:04:55.720572 EDT | MinEsReturn               134.754
2017-06-10 22:04:55.720779 EDT | AverageDiscountedReturn   234.035
2017-06-10 22:04:55.721038 EDT | AverageQLoss                2.9204
2017-06-10 22:04:55.721297 EDT | AveragePolicySurr         -32.7995
2017-06-10 22:04:55.721545 EDT | AverageQ                   32.3026
2017-06-10 22:04:55.721825 EDT | AverageAbsQ                32.3398
2017-06-10 22:04:55.722120 EDT | AverageY                   32.3031
2017-06-10 22:04:55.722890 EDT | AverageAbsY                32.3246
2017-06-10 22:04:55.723183 EDT | AverageAbsQYDiff            0.668507
2017-06-10 22:04:55.723443 EDT | AverageAction               0.843032
2017-06-10 22:04:55.723689 EDT | PolicyRegParamNorm         66.5199
2017-06-10 22:04:55.723931 EDT | QFunRegParamNorm           82.9743
2017-06-10 22:04:55.724110 EDT | -----------------------  -----------
2017-06-10 22:04:55.724412 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #375 | Training started
2017-06-10 22:05:11.879952 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #375 | Training finished
2017-06-10 22:05:11.880756 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #375 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 22:05:11.881147 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #375 | Collecting samples for evaluation
2017-06-10 22:05:23.696311 EDT | -----------------------  -----------
2017-06-10 22:05:23.697623 EDT | Epoch                     375
2017-06-10 22:05:23.697995 EDT | Iteration                 375
2017-06-10 22:05:23.699035 EDT | AverageReturn            1398.83
2017-06-10 22:05:23.699365 EDT | StdReturn                 569.073
2017-06-10 22:05:23.699739 EDT | MaxReturn                2700.27
2017-06-10 22:05:23.700071 EDT | MinReturn                 763.603
2017-06-10 22:05:23.700415 EDT | AverageEsReturn           377.114
2017-06-10 22:05:23.700749 EDT | StdEsReturn               282.785
2017-06-10 22:05:23.701081 EDT | MaxEsReturn               904.64
2017-06-10 22:05:23.701401 EDT | MinEsReturn                33.1888
2017-06-10 22:05:23.701741 EDT | AverageDiscountedReturn   243.073
2017-06-10 22:05:23.702136 EDT | AverageQLoss                2.56807
2017-06-10 22:05:23.702472 EDT | AveragePolicySurr         -32.6814
2017-06-10 22:05:23.703579 EDT | AverageQ                   32.1724
2017-06-10 22:05:23.703860 EDT | AverageAbsQ                32.2133
2017-06-10 22:05:23.704132 EDT | AverageY                   32.1743
2017-06-10 22:05:23.704412 EDT | AverageAbsY                32.2005
2017-06-10 22:05:23.704685 EDT | AverageAbsQYDiff            0.63391
2017-06-10 22:05:23.704958 EDT | AverageAction               0.817565
2017-06-10 22:05:23.705263 EDT | PolicyRegParamNorm         66.5749
2017-06-10 22:05:23.705576 EDT | QFunRegParamNorm           83.0634
2017-06-10 22:05:23.705890 EDT | -----------------------  -----------
2017-06-10 22:05:23.706347 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #376 | Training started
2017-06-10 22:05:38.773018 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #376 | Training finished
2017-06-10 22:05:38.774299 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #376 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 22:05:38.774694 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #376 | Collecting samples for evaluation
2017-06-10 22:05:51.769400 EDT | -----------------------  -----------
2017-06-10 22:05:51.770236 EDT | Epoch                     376
2017-06-10 22:05:51.770575 EDT | Iteration                 376
2017-06-10 22:05:51.770938 EDT | AverageReturn            1248
2017-06-10 22:05:51.771286 EDT | StdReturn                 520.406
2017-06-10 22:05:51.771626 EDT | MaxReturn                2226.67
2017-06-10 22:05:51.771990 EDT | MinReturn                 496.092
2017-06-10 22:05:51.772326 EDT | AverageEsReturn           308.834
2017-06-10 22:05:51.772678 EDT | StdEsReturn               243.393
2017-06-10 22:05:51.773054 EDT | MaxEsReturn               703.117
2017-06-10 22:05:51.773413 EDT | MinEsReturn                80.9438
2017-06-10 22:05:51.773792 EDT | AverageDiscountedReturn   206.909
2017-06-10 22:05:51.774204 EDT | AverageQLoss                2.7348
2017-06-10 22:05:51.774527 EDT | AveragePolicySurr         -32.6646
2017-06-10 22:05:51.774886 EDT | AverageQ                   32.1836
2017-06-10 22:05:51.775235 EDT | AverageAbsQ                32.225
2017-06-10 22:05:51.775566 EDT | AverageY                   32.1855
2017-06-10 22:05:51.775934 EDT | AverageAbsY                32.2118
2017-06-10 22:05:51.776291 EDT | AverageAbsQYDiff            0.649604
2017-06-10 22:05:51.776645 EDT | AverageAction               0.808808
2017-06-10 22:05:51.776986 EDT | PolicyRegParamNorm         66.671
2017-06-10 22:05:51.777663 EDT | QFunRegParamNorm           83.1629
2017-06-10 22:05:51.778047 EDT | -----------------------  -----------
2017-06-10 22:05:51.778622 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #377 | Training started
2017-06-10 22:06:06.773471 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #377 | Training finished
2017-06-10 22:06:06.774549 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #377 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 22:06:06.774757 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #377 | Collecting samples for evaluation
2017-06-10 22:06:19.223100 EDT | -----------------------  -----------
2017-06-10 22:06:19.223750 EDT | Epoch                     377
2017-06-10 22:06:19.224031 EDT | Iteration                 377
2017-06-10 22:06:19.225426 EDT | AverageReturn            1514.54
2017-06-10 22:06:19.226808 EDT | StdReturn                 786.707
2017-06-10 22:06:19.226981 EDT | MaxReturn                3051.41
2017-06-10 22:06:19.227145 EDT | MinReturn                 478.332
2017-06-10 22:06:19.227447 EDT | AverageEsReturn           875.618
2017-06-10 22:06:19.227634 EDT | StdEsReturn               275.225
2017-06-10 22:06:19.227827 EDT | MaxEsReturn              1162.39
2017-06-10 22:06:19.228010 EDT | MinEsReturn               574.306
2017-06-10 22:06:19.228221 EDT | AverageDiscountedReturn   213.573
2017-06-10 22:06:19.228405 EDT | AverageQLoss                2.73523
2017-06-10 22:06:19.228587 EDT | AveragePolicySurr         -32.6776
2017-06-10 22:06:19.228777 EDT | AverageQ                   32.1891
2017-06-10 22:06:19.228958 EDT | AverageAbsQ                32.235
2017-06-10 22:06:19.229139 EDT | AverageY                   32.1912
2017-06-10 22:06:19.229382 EDT | AverageAbsY                32.2159
2017-06-10 22:06:19.229566 EDT | AverageAbsQYDiff            0.653701
2017-06-10 22:06:19.229759 EDT | AverageAction               0.845152
2017-06-10 22:06:19.229961 EDT | PolicyRegParamNorm         66.7494
2017-06-10 22:06:19.230142 EDT | QFunRegParamNorm           83.2549
2017-06-10 22:06:19.230491 EDT | -----------------------  -----------
2017-06-10 22:06:19.231026 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #378 | Training started
2017-06-10 22:06:34.512063 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #378 | Training finished
2017-06-10 22:06:34.514228 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #378 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 22:06:34.514640 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #378 | Collecting samples for evaluation
2017-06-10 22:06:47.582209 EDT | -----------------------  -----------
2017-06-10 22:06:47.586048 EDT | Epoch                     378
2017-06-10 22:06:47.586434 EDT | Iteration                 378
2017-06-10 22:06:47.586752 EDT | AverageReturn             872.022
2017-06-10 22:06:47.587048 EDT | StdReturn                 284.622
2017-06-10 22:06:47.587355 EDT | MaxReturn                1526.42
2017-06-10 22:06:47.587669 EDT | MinReturn                 403.19
2017-06-10 22:06:47.587978 EDT | AverageEsReturn           348.532
2017-06-10 22:06:47.588307 EDT | StdEsReturn               227.266
2017-06-10 22:06:47.588626 EDT | MaxEsReturn               653.869
2017-06-10 22:06:47.588964 EDT | MinEsReturn                 9.6674
2017-06-10 22:06:47.589296 EDT | AverageDiscountedReturn   212.443
2017-06-10 22:06:47.591861 EDT | AverageQLoss                2.86384
2017-06-10 22:06:47.592180 EDT | AveragePolicySurr         -32.6156
2017-06-10 22:06:47.592459 EDT | AverageQ                   32.1168
2017-06-10 22:06:47.592925 EDT | AverageAbsQ                32.163
2017-06-10 22:06:47.593242 EDT | AverageY                   32.1179
2017-06-10 22:06:47.593434 EDT | AverageAbsY                32.147
2017-06-10 22:06:47.593671 EDT | AverageAbsQYDiff            0.673125
2017-06-10 22:06:47.593971 EDT | AverageAction               0.801706
2017-06-10 22:06:47.594267 EDT | PolicyRegParamNorm         66.7864
2017-06-10 22:06:47.594580 EDT | QFunRegParamNorm           83.3344
2017-06-10 22:06:47.594883 EDT | -----------------------  -----------
2017-06-10 22:06:47.595339 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #379 | Training started
2017-06-10 22:07:03.226241 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #379 | Training finished
2017-06-10 22:07:03.228290 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #379 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 22:07:03.228720 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #379 | Collecting samples for evaluation
2017-06-10 22:07:16.123841 EDT | -----------------------  -----------
2017-06-10 22:07:16.124099 EDT | Epoch                     379
2017-06-10 22:07:16.124306 EDT | Iteration                 379
2017-06-10 22:07:16.124462 EDT | AverageReturn            2493.13
2017-06-10 22:07:16.124627 EDT | StdReturn                 553.966
2017-06-10 22:07:16.124780 EDT | MaxReturn                3212.98
2017-06-10 22:07:16.124997 EDT | MinReturn                1550.36
2017-06-10 22:07:16.125151 EDT | AverageEsReturn           561.657
2017-06-10 22:07:16.125302 EDT | StdEsReturn               265.148
2017-06-10 22:07:16.125452 EDT | MaxEsReturn              1085.11
2017-06-10 22:07:16.125627 EDT | MinEsReturn               267.615
2017-06-10 22:07:16.125889 EDT | AverageDiscountedReturn   237.905
2017-06-10 22:07:16.126107 EDT | AverageQLoss                2.95534
2017-06-10 22:07:16.126261 EDT | AveragePolicySurr         -32.5121
2017-06-10 22:07:16.126412 EDT | AverageQ                   32.0254
2017-06-10 22:07:16.126642 EDT | AverageAbsQ                32.0738
2017-06-10 22:07:16.126861 EDT | AverageY                   32.0273
2017-06-10 22:07:16.127016 EDT | AverageAbsY                32.0629
2017-06-10 22:07:16.127167 EDT | AverageAbsQYDiff            0.656008
2017-06-10 22:07:16.127317 EDT | AverageAction               0.781065
2017-06-10 22:07:16.127530 EDT | PolicyRegParamNorm         66.8743
2017-06-10 22:07:16.127699 EDT | QFunRegParamNorm           83.4743
2017-06-10 22:07:16.127865 EDT | -----------------------  -----------
2017-06-10 22:07:16.128128 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #380 | Training started
2017-06-10 22:07:31.015496 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #380 | Training finished
2017-06-10 22:07:31.016415 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #380 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 22:07:31.016775 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #380 | Collecting samples for evaluation
2017-06-10 22:07:43.485356 EDT | -----------------------  -----------
2017-06-10 22:07:43.486662 EDT | Epoch                     380
2017-06-10 22:07:43.486863 EDT | Iteration                 380
2017-06-10 22:07:43.487077 EDT | AverageReturn             915.224
2017-06-10 22:07:43.487234 EDT | StdReturn                 563.262
2017-06-10 22:07:43.487387 EDT | MaxReturn                3345.8
2017-06-10 22:07:43.487582 EDT | MinReturn                 571.074
2017-06-10 22:07:43.487740 EDT | AverageEsReturn           553.754
2017-06-10 22:07:43.487893 EDT | StdEsReturn               436.951
2017-06-10 22:07:43.488044 EDT | MaxEsReturn              1347.35
2017-06-10 22:07:43.488224 EDT | MinEsReturn                32.456
2017-06-10 22:07:43.488378 EDT | AverageDiscountedReturn   226.508
2017-06-10 22:07:43.488528 EDT | AverageQLoss                2.68183
2017-06-10 22:07:43.488676 EDT | AveragePolicySurr         -32.5648
2017-06-10 22:07:43.488864 EDT | AverageQ                   32.1028
2017-06-10 22:07:43.489192 EDT | AverageAbsQ                32.1502
2017-06-10 22:07:43.489525 EDT | AverageY                   32.1022
2017-06-10 22:07:43.489833 EDT | AverageAbsY                32.1331
2017-06-10 22:07:43.490156 EDT | AverageAbsQYDiff            0.651003
2017-06-10 22:07:43.490490 EDT | AverageAction               0.823254
2017-06-10 22:07:43.490805 EDT | PolicyRegParamNorm         66.9417
2017-06-10 22:07:43.491137 EDT | QFunRegParamNorm           83.5612
2017-06-10 22:07:43.491450 EDT | -----------------------  -----------
2017-06-10 22:07:43.493439 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #381 | Training started
2017-06-10 22:07:58.998974 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #381 | Training finished
2017-06-10 22:07:58.999724 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #381 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 22:07:58.999928 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #381 | Collecting samples for evaluation
2017-06-10 22:08:11.589394 EDT | -----------------------  -----------
2017-06-10 22:08:11.590108 EDT | Epoch                     381
2017-06-10 22:08:11.590291 EDT | Iteration                 381
2017-06-10 22:08:11.590451 EDT | AverageReturn            2384.33
2017-06-10 22:08:11.590607 EDT | StdReturn                 771.762
2017-06-10 22:08:11.590760 EDT | MaxReturn                3108.36
2017-06-10 22:08:11.590912 EDT | MinReturn                 804.884
2017-06-10 22:08:11.591071 EDT | AverageEsReturn           445.475
2017-06-10 22:08:11.591225 EDT | StdEsReturn               261.991
2017-06-10 22:08:11.591376 EDT | MaxEsReturn               718.212
2017-06-10 22:08:11.591527 EDT | MinEsReturn                20.2454
2017-06-10 22:08:11.591677 EDT | AverageDiscountedReturn   220.434
2017-06-10 22:08:11.591827 EDT | AverageQLoss                3.12378
2017-06-10 22:08:11.591976 EDT | AveragePolicySurr         -32.6107
2017-06-10 22:08:11.592132 EDT | AverageQ                   32.1372
2017-06-10 22:08:11.592284 EDT | AverageAbsQ                32.1816
2017-06-10 22:08:11.592440 EDT | AverageY                   32.1376
2017-06-10 22:08:11.592664 EDT | AverageAbsY                32.1628
2017-06-10 22:08:11.592917 EDT | AverageAbsQYDiff            0.674269
2017-06-10 22:08:11.593070 EDT | AverageAction               0.790067
2017-06-10 22:08:11.593247 EDT | PolicyRegParamNorm         67.0188
2017-06-10 22:08:11.593560 EDT | QFunRegParamNorm           83.621
2017-06-10 22:08:11.593838 EDT | -----------------------  -----------
2017-06-10 22:08:11.594216 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #382 | Training started
2017-06-10 22:08:25.827431 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #382 | Training finished
2017-06-10 22:08:25.828257 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #382 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 22:08:25.828531 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #382 | Collecting samples for evaluation
2017-06-10 22:08:38.601576 EDT | -----------------------  -----------
2017-06-10 22:08:38.602625 EDT | Epoch                     382
2017-06-10 22:08:38.603048 EDT | Iteration                 382
2017-06-10 22:08:38.603446 EDT | AverageReturn            1100.36
2017-06-10 22:08:38.603838 EDT | StdReturn                 331.579
2017-06-10 22:08:38.604223 EDT | MaxReturn                2014.12
2017-06-10 22:08:38.604598 EDT | MinReturn                  73.9812
2017-06-10 22:08:38.604980 EDT | AverageEsReturn           505.92
2017-06-10 22:08:38.605360 EDT | StdEsReturn               206.54
2017-06-10 22:08:38.605743 EDT | MaxEsReturn               715.197
2017-06-10 22:08:38.606129 EDT | MinEsReturn               177.891
2017-06-10 22:08:38.606513 EDT | AverageDiscountedReturn   225.779
2017-06-10 22:08:38.606888 EDT | AverageQLoss                2.39136
2017-06-10 22:08:38.607265 EDT | AveragePolicySurr         -32.4793
2017-06-10 22:08:38.607645 EDT | AverageQ                   31.9888
2017-06-10 22:08:38.608020 EDT | AverageAbsQ                32.034
2017-06-10 22:08:38.608397 EDT | AverageY                   31.9915
2017-06-10 22:08:38.608765 EDT | AverageAbsY                32.0172
2017-06-10 22:08:38.609140 EDT | AverageAbsQYDiff            0.636037
2017-06-10 22:08:38.609519 EDT | AverageAction               0.832789
2017-06-10 22:08:38.609907 EDT | PolicyRegParamNorm         67.013
2017-06-10 22:08:38.610281 EDT | QFunRegParamNorm           83.7086
2017-06-10 22:08:38.610648 EDT | -----------------------  -----------
2017-06-10 22:08:38.611333 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #383 | Training started
2017-06-10 22:08:53.350819 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #383 | Training finished
2017-06-10 22:08:53.365806 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #383 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 22:08:53.366448 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #383 | Collecting samples for evaluation
2017-06-10 22:09:04.730454 EDT | -----------------------  -----------
2017-06-10 22:09:04.731176 EDT | Epoch                     383
2017-06-10 22:09:04.731434 EDT | Iteration                 383
2017-06-10 22:09:04.731607 EDT | AverageReturn            1065.78
2017-06-10 22:09:04.731791 EDT | StdReturn                 477.8
2017-06-10 22:09:04.731944 EDT | MaxReturn                2908.8
2017-06-10 22:09:04.732094 EDT | MinReturn                 667.768
2017-06-10 22:09:04.732271 EDT | AverageEsReturn           491.97
2017-06-10 22:09:04.732539 EDT | StdEsReturn               208.322
2017-06-10 22:09:04.732698 EDT | MaxEsReturn               799.626
2017-06-10 22:09:04.732930 EDT | MinEsReturn               263.03
2017-06-10 22:09:04.733180 EDT | AverageDiscountedReturn   199.452
2017-06-10 22:09:04.733334 EDT | AverageQLoss                2.69784
2017-06-10 22:09:04.733485 EDT | AveragePolicySurr         -32.4544
2017-06-10 22:09:04.733635 EDT | AverageQ                   31.9665
2017-06-10 22:09:04.733809 EDT | AverageAbsQ                32.0061
2017-06-10 22:09:04.733959 EDT | AverageY                   31.9684
2017-06-10 22:09:04.734109 EDT | AverageAbsY                31.9906
2017-06-10 22:09:04.734258 EDT | AverageAbsQYDiff            0.655519
2017-06-10 22:09:04.734451 EDT | AverageAction               0.838747
2017-06-10 22:09:04.734613 EDT | PolicyRegParamNorm         67.1377
2017-06-10 22:09:04.734839 EDT | QFunRegParamNorm           83.806
2017-06-10 22:09:04.734989 EDT | -----------------------  -----------
2017-06-10 22:09:04.735247 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #384 | Training started
2017-06-10 22:09:20.158174 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #384 | Training finished
2017-06-10 22:09:20.159477 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #384 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 22:09:20.159863 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #384 | Collecting samples for evaluation
2017-06-10 22:09:31.199119 EDT | -----------------------  -----------
2017-06-10 22:09:31.200140 EDT | Epoch                     384
2017-06-10 22:09:31.200385 EDT | Iteration                 384
2017-06-10 22:09:31.200649 EDT | AverageReturn            1336.77
2017-06-10 22:09:31.200846 EDT | StdReturn                 752.817
2017-06-10 22:09:31.201219 EDT | MaxReturn                2667.81
2017-06-10 22:09:31.201464 EDT | MinReturn                 423.873
2017-06-10 22:09:31.201648 EDT | AverageEsReturn           238.665
2017-06-10 22:09:31.201848 EDT | StdEsReturn               196.902
2017-06-10 22:09:31.202201 EDT | MaxEsReturn               648.748
2017-06-10 22:09:31.202419 EDT | MinEsReturn                50.8421
2017-06-10 22:09:31.202603 EDT | AverageDiscountedReturn   200.811
2017-06-10 22:09:31.202783 EDT | AverageQLoss                2.65813
2017-06-10 22:09:31.203059 EDT | AveragePolicySurr         -32.4586
2017-06-10 22:09:31.203255 EDT | AverageQ                   31.9682
2017-06-10 22:09:31.203514 EDT | AverageAbsQ                32.008
2017-06-10 22:09:31.203696 EDT | AverageY                   31.9705
2017-06-10 22:09:31.203898 EDT | AverageAbsY                31.9931
2017-06-10 22:09:31.204118 EDT | AverageAbsQYDiff            0.656356
2017-06-10 22:09:31.204298 EDT | AverageAction               0.805472
2017-06-10 22:09:31.204477 EDT | PolicyRegParamNorm         67.2307
2017-06-10 22:09:31.204766 EDT | QFunRegParamNorm           83.8861
2017-06-10 22:09:31.204994 EDT | -----------------------  -----------
2017-06-10 22:09:31.205284 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #385 | Training started
2017-06-10 22:09:46.086016 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #385 | Training finished
2017-06-10 22:09:46.086933 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #385 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 22:09:46.087327 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #385 | Collecting samples for evaluation
2017-06-10 22:09:59.172943 EDT | -----------------------  -----------
2017-06-10 22:09:59.174874 EDT | Epoch                     385
2017-06-10 22:09:59.175070 EDT | Iteration                 385
2017-06-10 22:09:59.175259 EDT | AverageReturn            1050.81
2017-06-10 22:09:59.176206 EDT | StdReturn                 523.168
2017-06-10 22:09:59.176445 EDT | MaxReturn                2667.22
2017-06-10 22:09:59.176602 EDT | MinReturn                 402.021
2017-06-10 22:09:59.176756 EDT | AverageEsReturn           227.162
2017-06-10 22:09:59.176917 EDT | StdEsReturn               153.703
2017-06-10 22:09:59.177094 EDT | MaxEsReturn               518.244
2017-06-10 22:09:59.177246 EDT | MinEsReturn                36.7002
2017-06-10 22:09:59.177396 EDT | AverageDiscountedReturn   192.228
2017-06-10 22:09:59.177545 EDT | AverageQLoss                2.48483
2017-06-10 22:09:59.177703 EDT | AveragePolicySurr         -32.3507
2017-06-10 22:09:59.177865 EDT | AverageQ                   31.8747
2017-06-10 22:09:59.178019 EDT | AverageAbsQ                31.9056
2017-06-10 22:09:59.178169 EDT | AverageY                   31.8739
2017-06-10 22:09:59.178318 EDT | AverageAbsY                31.8899
2017-06-10 22:09:59.178466 EDT | AverageAbsQYDiff            0.631613
2017-06-10 22:09:59.178644 EDT | AverageAction               0.84836
2017-06-10 22:09:59.178798 EDT | PolicyRegParamNorm         67.2903
2017-06-10 22:09:59.178960 EDT | QFunRegParamNorm           84.0003
2017-06-10 22:09:59.179109 EDT | -----------------------  -----------
2017-06-10 22:09:59.179343 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #386 | Training started
2017-06-10 22:10:12.946203 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #386 | Training finished
2017-06-10 22:10:12.946980 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #386 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 22:10:12.947193 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #386 | Collecting samples for evaluation
2017-06-10 22:10:25.498230 EDT | -----------------------  -----------
2017-06-10 22:10:25.498999 EDT | Epoch                     386
2017-06-10 22:10:25.499194 EDT | Iteration                 386
2017-06-10 22:10:25.499432 EDT | AverageReturn             991.556
2017-06-10 22:10:25.499618 EDT | StdReturn                 677.622
2017-06-10 22:10:25.499911 EDT | MaxReturn                2650.83
2017-06-10 22:10:25.500266 EDT | MinReturn                 216.415
2017-06-10 22:10:25.500445 EDT | AverageEsReturn           248.125
2017-06-10 22:10:25.500628 EDT | StdEsReturn               145.19
2017-06-10 22:10:25.500843 EDT | MaxEsReturn               557.596
2017-06-10 22:10:25.501025 EDT | MinEsReturn                44.6828
2017-06-10 22:10:25.501203 EDT | AverageDiscountedReturn   186.718
2017-06-10 22:10:25.501383 EDT | AverageQLoss                2.67416
2017-06-10 22:10:25.501569 EDT | AveragePolicySurr         -32.2785
2017-06-10 22:10:25.501767 EDT | AverageQ                   31.8117
2017-06-10 22:10:25.501947 EDT | AverageAbsQ                31.8435
2017-06-10 22:10:25.502126 EDT | AverageY                   31.8139
2017-06-10 22:10:25.502303 EDT | AverageAbsY                31.8288
2017-06-10 22:10:25.502481 EDT | AverageAbsQYDiff            0.643628
2017-06-10 22:10:25.502659 EDT | AverageAction               0.870099
2017-06-10 22:10:25.502837 EDT | PolicyRegParamNorm         67.3432
2017-06-10 22:10:25.503016 EDT | QFunRegParamNorm           84.0936
2017-06-10 22:10:25.503242 EDT | -----------------------  -----------
2017-06-10 22:10:25.503500 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #387 | Training started
2017-06-10 22:10:40.451405 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #387 | Training finished
2017-06-10 22:10:40.452512 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #387 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 22:10:40.453033 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #387 | Collecting samples for evaluation
2017-06-10 22:10:53.546398 EDT | -----------------------  -----------
2017-06-10 22:10:53.546767 EDT | Epoch                     387
2017-06-10 22:10:53.547644 EDT | Iteration                 387
2017-06-10 22:10:53.548762 EDT | AverageReturn            1432.53
2017-06-10 22:10:53.550319 EDT | StdReturn                 766.638
2017-06-10 22:10:53.551439 EDT | MaxReturn                3194.59
2017-06-10 22:10:53.552230 EDT | MinReturn                 564.521
2017-06-10 22:10:53.553099 EDT | AverageEsReturn           358.954
2017-06-10 22:10:53.553444 EDT | StdEsReturn               299.313
2017-06-10 22:10:53.553782 EDT | MaxEsReturn               836.974
2017-06-10 22:10:53.554033 EDT | MinEsReturn                28.5556
2017-06-10 22:10:53.554286 EDT | AverageDiscountedReturn   221.027
2017-06-10 22:10:53.554538 EDT | AverageQLoss                3.01114
2017-06-10 22:10:53.555265 EDT | AveragePolicySurr         -32.3348
2017-06-10 22:10:53.556127 EDT | AverageQ                   31.8517
2017-06-10 22:10:53.557763 EDT | AverageAbsQ                31.888
2017-06-10 22:10:53.558438 EDT | AverageY                   31.8541
2017-06-10 22:10:53.559429 EDT | AverageAbsY                31.8721
2017-06-10 22:10:53.559776 EDT | AverageAbsQYDiff            0.659479
2017-06-10 22:10:53.561337 EDT | AverageAction               0.766922
2017-06-10 22:10:53.561740 EDT | PolicyRegParamNorm         67.4757
2017-06-10 22:10:53.562020 EDT | QFunRegParamNorm           84.2036
2017-06-10 22:10:53.562287 EDT | -----------------------  -----------
2017-06-10 22:10:53.563535 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #388 | Training started
2017-06-10 22:11:09.729913 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #388 | Training finished
2017-06-10 22:11:09.730871 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #388 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 22:11:09.731177 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #388 | Collecting samples for evaluation
2017-06-10 22:11:22.222336 EDT | -----------------------  -----------
2017-06-10 22:11:22.222757 EDT | Epoch                     388
2017-06-10 22:11:22.223062 EDT | Iteration                 388
2017-06-10 22:11:22.223569 EDT | AverageReturn            1540.55
2017-06-10 22:11:22.224670 EDT | StdReturn                 495.323
2017-06-10 22:11:22.225205 EDT | MaxReturn                2387.5
2017-06-10 22:11:22.225679 EDT | MinReturn                 591.443
2017-06-10 22:11:22.226035 EDT | AverageEsReturn           542.244
2017-06-10 22:11:22.226510 EDT | StdEsReturn               200.365
2017-06-10 22:11:22.226858 EDT | MaxEsReturn               872.146
2017-06-10 22:11:22.227266 EDT | MinEsReturn               262.996
2017-06-10 22:11:22.227614 EDT | AverageDiscountedReturn   227.792
2017-06-10 22:11:22.227977 EDT | AverageQLoss                2.81698
2017-06-10 22:11:22.228364 EDT | AveragePolicySurr         -32.2132
2017-06-10 22:11:22.228730 EDT | AverageQ                   31.7299
2017-06-10 22:11:22.229066 EDT | AverageAbsQ                31.7593
2017-06-10 22:11:22.229406 EDT | AverageY                   31.7327
2017-06-10 22:11:22.229739 EDT | AverageAbsY                31.7482
2017-06-10 22:11:22.230087 EDT | AverageAbsQYDiff            0.648941
2017-06-10 22:11:22.230431 EDT | AverageAction               0.814277
2017-06-10 22:11:22.230773 EDT | PolicyRegParamNorm         67.5337
2017-06-10 22:11:22.231108 EDT | QFunRegParamNorm           84.3332
2017-06-10 22:11:22.231461 EDT | -----------------------  -----------
2017-06-10 22:11:22.231953 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #389 | Training started
2017-06-10 22:11:36.850050 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #389 | Training finished
2017-06-10 22:11:36.850847 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #389 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 22:11:36.851041 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #389 | Collecting samples for evaluation
2017-06-10 22:11:49.871417 EDT | -----------------------  -----------
2017-06-10 22:11:49.872217 EDT | Epoch                     389
2017-06-10 22:11:49.872411 EDT | Iteration                 389
2017-06-10 22:11:49.872716 EDT | AverageReturn            1856.26
2017-06-10 22:11:49.872986 EDT | StdReturn                 800.344
2017-06-10 22:11:49.873185 EDT | MaxReturn                2793.79
2017-06-10 22:11:49.873369 EDT | MinReturn                 721.06
2017-06-10 22:11:49.873551 EDT | AverageEsReturn           338.779
2017-06-10 22:11:49.873751 EDT | StdEsReturn               222.381
2017-06-10 22:11:49.873932 EDT | MaxEsReturn               752.57
2017-06-10 22:11:49.874111 EDT | MinEsReturn               110.136
2017-06-10 22:11:49.874298 EDT | AverageDiscountedReturn   231.456
2017-06-10 22:11:49.874519 EDT | AverageQLoss                2.98265
2017-06-10 22:11:49.874836 EDT | AveragePolicySurr         -32.1751
2017-06-10 22:11:49.875020 EDT | AverageQ                   31.6987
2017-06-10 22:11:49.875205 EDT | AverageAbsQ                31.7327
2017-06-10 22:11:49.875397 EDT | AverageY                   31.6992
2017-06-10 22:11:49.875648 EDT | AverageAbsY                31.7173
2017-06-10 22:11:49.875827 EDT | AverageAbsQYDiff            0.669838
2017-06-10 22:11:49.876006 EDT | AverageAction               0.837416
2017-06-10 22:11:49.876185 EDT | PolicyRegParamNorm         67.5782
2017-06-10 22:11:49.876459 EDT | QFunRegParamNorm           84.4569
2017-06-10 22:11:49.876636 EDT | -----------------------  -----------
2017-06-10 22:11:49.877042 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #390 | Training started
2017-06-10 22:12:05.114947 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #390 | Training finished
2017-06-10 22:12:05.115922 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #390 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 22:12:05.116328 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #390 | Collecting samples for evaluation
2017-06-10 22:12:18.677655 EDT | -----------------------  -----------
2017-06-10 22:12:18.678564 EDT | Epoch                     390
2017-06-10 22:12:18.678819 EDT | Iteration                 390
2017-06-10 22:12:18.678981 EDT | AverageReturn            1903.51
2017-06-10 22:12:18.679137 EDT | StdReturn                 830.188
2017-06-10 22:12:18.679342 EDT | MaxReturn                2978.32
2017-06-10 22:12:18.679540 EDT | MinReturn                 770.883
2017-06-10 22:12:18.679738 EDT | AverageEsReturn           434.641
2017-06-10 22:12:18.679893 EDT | StdEsReturn               258.588
2017-06-10 22:12:18.680104 EDT | MaxEsReturn               840.795
2017-06-10 22:12:18.680257 EDT | MinEsReturn                88.5107
2017-06-10 22:12:18.680408 EDT | AverageDiscountedReturn   220.005
2017-06-10 22:12:18.680572 EDT | AverageQLoss                2.53706
2017-06-10 22:12:18.680724 EDT | AveragePolicySurr         -32.1576
2017-06-10 22:12:18.680873 EDT | AverageQ                   31.681
2017-06-10 22:12:18.681062 EDT | AverageAbsQ                31.7087
2017-06-10 22:12:18.681214 EDT | AverageY                   31.68
2017-06-10 22:12:18.681363 EDT | AverageAbsY                31.6934
2017-06-10 22:12:18.681610 EDT | AverageAbsQYDiff            0.634137
2017-06-10 22:12:18.681783 EDT | AverageAction               0.814324
2017-06-10 22:12:18.681936 EDT | PolicyRegParamNorm         67.6545
2017-06-10 22:12:18.682090 EDT | QFunRegParamNorm           84.5623
2017-06-10 22:12:18.682336 EDT | -----------------------  -----------
2017-06-10 22:12:18.682585 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #391 | Training started
2017-06-10 22:12:33.010679 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #391 | Training finished
2017-06-10 22:12:33.017831 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #391 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 22:12:33.018512 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #391 | Collecting samples for evaluation
2017-06-10 22:12:46.234359 EDT | -----------------------  -----------
2017-06-10 22:12:46.235490 EDT | Epoch                     391
2017-06-10 22:12:46.235740 EDT | Iteration                 391
2017-06-10 22:12:46.235904 EDT | AverageReturn            1142.09
2017-06-10 22:12:46.236077 EDT | StdReturn                 563.892
2017-06-10 22:12:46.236242 EDT | MaxReturn                2632.92
2017-06-10 22:12:46.236396 EDT | MinReturn                 588.709
2017-06-10 22:12:46.236579 EDT | AverageEsReturn           421.129
2017-06-10 22:12:46.236732 EDT | StdEsReturn               313.658
2017-06-10 22:12:46.236895 EDT | MaxEsReturn              1005.56
2017-06-10 22:12:46.237052 EDT | MinEsReturn               127.183
2017-06-10 22:12:46.237268 EDT | AverageDiscountedReturn   219.024
2017-06-10 22:12:46.237433 EDT | AverageQLoss                2.95505
2017-06-10 22:12:46.237617 EDT | AveragePolicySurr         -32.2206
2017-06-10 22:12:46.237804 EDT | AverageQ                   31.7795
2017-06-10 22:12:46.238143 EDT | AverageAbsQ                31.8067
2017-06-10 22:12:46.238430 EDT | AverageY                   31.782
2017-06-10 22:12:46.238600 EDT | AverageAbsY                31.7943
2017-06-10 22:12:46.238757 EDT | AverageAbsQYDiff            0.665226
2017-06-10 22:12:46.238920 EDT | AverageAction               0.853048
2017-06-10 22:12:46.239135 EDT | PolicyRegParamNorm         67.7224
2017-06-10 22:12:46.239412 EDT | QFunRegParamNorm           84.6297
2017-06-10 22:12:46.239573 EDT | -----------------------  -----------
2017-06-10 22:12:46.239817 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #392 | Training started
2017-06-10 22:13:01.757824 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #392 | Training finished
2017-06-10 22:13:01.758614 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #392 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 22:13:01.758835 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #392 | Collecting samples for evaluation
2017-06-10 22:13:14.695830 EDT | -----------------------  -----------
2017-06-10 22:13:14.697072 EDT | Epoch                     392
2017-06-10 22:13:14.697542 EDT | Iteration                 392
2017-06-10 22:13:14.697977 EDT | AverageReturn            1124.79
2017-06-10 22:13:14.698427 EDT | StdReturn                 255.52
2017-06-10 22:13:14.698845 EDT | MaxReturn                2034.3
2017-06-10 22:13:14.699269 EDT | MinReturn                 575.246
2017-06-10 22:13:14.699715 EDT | AverageEsReturn           562.686
2017-06-10 22:13:14.700135 EDT | StdEsReturn               296.597
2017-06-10 22:13:14.700484 EDT | MaxEsReturn               964.934
2017-06-10 22:13:14.700926 EDT | MinEsReturn               137.677
2017-06-10 22:13:14.701345 EDT | AverageDiscountedReturn   248.474
2017-06-10 22:13:14.701711 EDT | AverageQLoss                2.40936
2017-06-10 22:13:14.702057 EDT | AveragePolicySurr         -32.1559
2017-06-10 22:13:14.702397 EDT | AverageQ                   31.6863
2017-06-10 22:13:14.702737 EDT | AverageAbsQ                31.7207
2017-06-10 22:13:14.717830 EDT | AverageY                   31.6884
2017-06-10 22:13:14.718380 EDT | AverageAbsY                31.7023
2017-06-10 22:13:14.718833 EDT | AverageAbsQYDiff            0.622507
2017-06-10 22:13:14.719281 EDT | AverageAction               0.808029
2017-06-10 22:13:14.719731 EDT | PolicyRegParamNorm         67.7821
2017-06-10 22:13:14.720175 EDT | QFunRegParamNorm           84.6918
2017-06-10 22:13:14.720614 EDT | -----------------------  -----------
2017-06-10 22:13:14.721248 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #393 | Training started
2017-06-10 22:13:29.413594 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #393 | Training finished
2017-06-10 22:13:29.414518 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #393 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 22:13:29.414858 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #393 | Collecting samples for evaluation
2017-06-10 22:13:41.431604 EDT | -----------------------  -----------
2017-06-10 22:13:41.436278 EDT | Epoch                     393
2017-06-10 22:13:41.436721 EDT | Iteration                 393
2017-06-10 22:13:41.436963 EDT | AverageReturn            1510.16
2017-06-10 22:13:41.438536 EDT | StdReturn                 523.104
2017-06-10 22:13:41.438795 EDT | MaxReturn                2601.44
2017-06-10 22:13:41.439064 EDT | MinReturn                 816.453
2017-06-10 22:13:41.439427 EDT | AverageEsReturn           346.03
2017-06-10 22:13:41.439721 EDT | StdEsReturn               200.567
2017-06-10 22:13:41.440002 EDT | MaxEsReturn               629.736
2017-06-10 22:13:41.440292 EDT | MinEsReturn                85.3948
2017-06-10 22:13:41.440666 EDT | AverageDiscountedReturn   214.958
2017-06-10 22:13:41.440940 EDT | AverageQLoss                2.77391
2017-06-10 22:13:41.441122 EDT | AveragePolicySurr         -32.0033
2017-06-10 22:13:41.441308 EDT | AverageQ                   31.5186
2017-06-10 22:13:41.441507 EDT | AverageAbsQ                31.5538
2017-06-10 22:13:41.441850 EDT | AverageY                   31.5196
2017-06-10 22:13:41.442026 EDT | AverageAbsY                31.5379
2017-06-10 22:13:41.442259 EDT | AverageAbsQYDiff            0.656709
2017-06-10 22:13:41.442439 EDT | AverageAction               0.843513
2017-06-10 22:13:41.442617 EDT | PolicyRegParamNorm         67.9263
2017-06-10 22:13:41.442887 EDT | QFunRegParamNorm           84.7859
2017-06-10 22:13:41.443067 EDT | -----------------------  -----------
2017-06-10 22:13:41.443339 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #394 | Training started
2017-06-10 22:13:56.243940 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #394 | Training finished
2017-06-10 22:13:56.244745 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #394 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 22:13:56.245062 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #394 | Collecting samples for evaluation
2017-06-10 22:14:09.097829 EDT | -----------------------  -----------
2017-06-10 22:14:09.098727 EDT | Epoch                     394
2017-06-10 22:14:09.099100 EDT | Iteration                 394
2017-06-10 22:14:09.099550 EDT | AverageReturn            1839.48
2017-06-10 22:14:09.099928 EDT | StdReturn                 915.014
2017-06-10 22:14:09.100189 EDT | MaxReturn                3182.62
2017-06-10 22:14:09.100439 EDT | MinReturn                 473.627
2017-06-10 22:14:09.100724 EDT | AverageEsReturn           376.311
2017-06-10 22:14:09.101039 EDT | StdEsReturn               249.758
2017-06-10 22:14:09.101372 EDT | MaxEsReturn               826.813
2017-06-10 22:14:09.101939 EDT | MinEsReturn                50.3617
2017-06-10 22:14:09.102355 EDT | AverageDiscountedReturn   216.17
2017-06-10 22:14:09.102791 EDT | AverageQLoss                2.36839
2017-06-10 22:14:09.103338 EDT | AveragePolicySurr         -32.128
2017-06-10 22:14:09.103934 EDT | AverageQ                   31.6374
2017-06-10 22:14:09.104720 EDT | AverageAbsQ                31.6827
2017-06-10 22:14:09.105162 EDT | AverageY                   31.6377
2017-06-10 22:14:09.105812 EDT | AverageAbsY                31.6698
2017-06-10 22:14:09.106147 EDT | AverageAbsQYDiff            0.619808
2017-06-10 22:14:09.106479 EDT | AverageAction               0.844127
2017-06-10 22:14:09.106950 EDT | PolicyRegParamNorm         67.9617
2017-06-10 22:14:09.107371 EDT | QFunRegParamNorm           84.8475
2017-06-10 22:14:09.108139 EDT | -----------------------  -----------
2017-06-10 22:14:09.108745 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #395 | Training started
2017-06-10 22:14:24.461150 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #395 | Training finished
2017-06-10 22:14:24.461560 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #395 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 22:14:24.461883 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #395 | Collecting samples for evaluation
2017-06-10 22:14:37.251916 EDT | -----------------------  -----------
2017-06-10 22:14:37.253061 EDT | Epoch                     395
2017-06-10 22:14:37.253763 EDT | Iteration                 395
2017-06-10 22:14:37.254739 EDT | AverageReturn            1539.41
2017-06-10 22:14:37.255798 EDT | StdReturn                 818.121
2017-06-10 22:14:37.256784 EDT | MaxReturn                2871.45
2017-06-10 22:14:37.257775 EDT | MinReturn                 382.495
2017-06-10 22:14:37.258703 EDT | AverageEsReturn           622.538
2017-06-10 22:14:37.259638 EDT | StdEsReturn               453.291
2017-06-10 22:14:37.260569 EDT | MaxEsReturn              1231.67
2017-06-10 22:14:37.261487 EDT | MinEsReturn               145.376
2017-06-10 22:14:37.262257 EDT | AverageDiscountedReturn   200.805
2017-06-10 22:14:37.262506 EDT | AverageQLoss                2.61335
2017-06-10 22:14:37.263441 EDT | AveragePolicySurr         -32.1482
2017-06-10 22:14:37.263728 EDT | AverageQ                   31.6547
2017-06-10 22:14:37.263979 EDT | AverageAbsQ                31.6949
2017-06-10 22:14:37.264176 EDT | AverageY                   31.6574
2017-06-10 22:14:37.264403 EDT | AverageAbsY                31.6791
2017-06-10 22:14:37.264622 EDT | AverageAbsQYDiff            0.645928
2017-06-10 22:14:37.264813 EDT | AverageAction               0.875431
2017-06-10 22:14:37.266592 EDT | PolicyRegParamNorm         68.0341
2017-06-10 22:14:37.266982 EDT | QFunRegParamNorm           84.9512
2017-06-10 22:14:37.267364 EDT | -----------------------  -----------
2017-06-10 22:14:37.267906 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #396 | Training started
2017-06-10 22:14:51.917249 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #396 | Training finished
2017-06-10 22:14:51.987639 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #396 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 22:14:51.988087 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #396 | Collecting samples for evaluation
2017-06-10 22:15:05.169661 EDT | -----------------------  -----------
2017-06-10 22:15:05.170661 EDT | Epoch                     396
2017-06-10 22:15:05.170996 EDT | Iteration                 396
2017-06-10 22:15:05.171616 EDT | AverageReturn            1884.74
2017-06-10 22:15:05.172067 EDT | StdReturn                 820.844
2017-06-10 22:15:05.172512 EDT | MaxReturn                3208.16
2017-06-10 22:15:05.172952 EDT | MinReturn                 784.477
2017-06-10 22:15:05.173394 EDT | AverageEsReturn           423.19
2017-06-10 22:15:05.173853 EDT | StdEsReturn               244.065
2017-06-10 22:15:05.174297 EDT | MaxEsReturn               785.817
2017-06-10 22:15:05.174733 EDT | MinEsReturn                36.1517
2017-06-10 22:15:05.175177 EDT | AverageDiscountedReturn   226.44
2017-06-10 22:15:05.175613 EDT | AverageQLoss                2.96809
2017-06-10 22:15:05.176051 EDT | AveragePolicySurr         -32.2344
2017-06-10 22:15:05.176489 EDT | AverageQ                   31.724
2017-06-10 22:15:05.176925 EDT | AverageAbsQ                31.7536
2017-06-10 22:15:05.177363 EDT | AverageY                   31.7258
2017-06-10 22:15:05.177811 EDT | AverageAbsY                31.7424
2017-06-10 22:15:05.178172 EDT | AverageAbsQYDiff            0.669318
2017-06-10 22:15:05.178612 EDT | AverageAction               0.844214
2017-06-10 22:15:05.178958 EDT | PolicyRegParamNorm         68.1123
2017-06-10 22:15:05.179310 EDT | QFunRegParamNorm           85.0843
2017-06-10 22:15:05.179652 EDT | -----------------------  -----------
2017-06-10 22:15:05.180169 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #397 | Training started
2017-06-10 22:15:20.291764 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #397 | Training finished
2017-06-10 22:15:20.292746 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #397 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 22:15:20.293178 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #397 | Collecting samples for evaluation
2017-06-10 22:15:32.582796 EDT | -----------------------  -----------
2017-06-10 22:15:32.583611 EDT | Epoch                     397
2017-06-10 22:15:32.583806 EDT | Iteration                 397
2017-06-10 22:15:32.583996 EDT | AverageReturn            1938.89
2017-06-10 22:15:32.584159 EDT | StdReturn                 871.368
2017-06-10 22:15:32.584393 EDT | MaxReturn                2904.2
2017-06-10 22:15:32.584548 EDT | MinReturn                 425.658
2017-06-10 22:15:32.584750 EDT | AverageEsReturn           252.812
2017-06-10 22:15:32.584956 EDT | StdEsReturn               252.304
2017-06-10 22:15:32.585114 EDT | MaxEsReturn               761.334
2017-06-10 22:15:32.585804 EDT | MinEsReturn                14.6439
2017-06-10 22:15:32.585987 EDT | AverageDiscountedReturn   222.031
2017-06-10 22:15:32.586285 EDT | AverageQLoss                3.05581
2017-06-10 22:15:32.586634 EDT | AveragePolicySurr         -32.1929
2017-06-10 22:15:32.587211 EDT | AverageQ                   31.7041
2017-06-10 22:15:32.587438 EDT | AverageAbsQ                31.7312
2017-06-10 22:15:32.587695 EDT | AverageY                   31.7024
2017-06-10 22:15:32.587972 EDT | AverageAbsY                31.7132
2017-06-10 22:15:32.588360 EDT | AverageAbsQYDiff            0.66429
2017-06-10 22:15:32.588872 EDT | AverageAction               0.831999
2017-06-10 22:15:32.589249 EDT | PolicyRegParamNorm         68.179
2017-06-10 22:15:32.589598 EDT | QFunRegParamNorm           85.1736
2017-06-10 22:15:32.589980 EDT | -----------------------  -----------
2017-06-10 22:15:32.590335 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #398 | Training started
2017-06-10 22:15:47.845574 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #398 | Training finished
2017-06-10 22:15:47.846333 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #398 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 22:15:47.846587 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #398 | Collecting samples for evaluation
2017-06-10 22:16:00.237864 EDT | -----------------------  -----------
2017-06-10 22:16:00.238931 EDT | Epoch                     398
2017-06-10 22:16:00.239392 EDT | Iteration                 398
2017-06-10 22:16:00.239811 EDT | AverageReturn            1002.26
2017-06-10 22:16:00.240214 EDT | StdReturn                 687.577
2017-06-10 22:16:00.241797 EDT | MaxReturn                2437.03
2017-06-10 22:16:00.242348 EDT | MinReturn                 238.085
2017-06-10 22:16:00.242758 EDT | AverageEsReturn           467.892
2017-06-10 22:16:00.243190 EDT | StdEsReturn               322.986
2017-06-10 22:16:00.243707 EDT | MaxEsReturn              1027.73
2017-06-10 22:16:00.244133 EDT | MinEsReturn                78.5534
2017-06-10 22:16:00.245971 EDT | AverageDiscountedReturn   210.194
2017-06-10 22:16:00.246505 EDT | AverageQLoss                2.87018
2017-06-10 22:16:00.247004 EDT | AveragePolicySurr         -32.0948
2017-06-10 22:16:00.247463 EDT | AverageQ                   31.6038
2017-06-10 22:16:00.247858 EDT | AverageAbsQ                31.6324
2017-06-10 22:16:00.248412 EDT | AverageY                   31.6062
2017-06-10 22:16:00.248844 EDT | AverageAbsY                31.6169
2017-06-10 22:16:00.249260 EDT | AverageAbsQYDiff            0.641981
2017-06-10 22:16:00.249625 EDT | AverageAction               0.853477
2017-06-10 22:16:00.250054 EDT | PolicyRegParamNorm         68.2616
2017-06-10 22:16:00.251000 EDT | QFunRegParamNorm           85.2891
2017-06-10 22:16:00.254033 EDT | -----------------------  -----------
2017-06-10 22:16:00.254562 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #399 | Training started
2017-06-10 22:16:15.155558 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #399 | Training finished
2017-06-10 22:16:15.156550 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #399 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 22:16:15.157014 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #399 | Collecting samples for evaluation
2017-06-10 22:16:28.202725 EDT | -----------------------  -----------
2017-06-10 22:16:28.203770 EDT | Epoch                     399
2017-06-10 22:16:28.204138 EDT | Iteration                 399
2017-06-10 22:16:28.204500 EDT | AverageReturn             746.455
2017-06-10 22:16:28.204855 EDT | StdReturn                 425.151
2017-06-10 22:16:28.205211 EDT | MaxReturn                1468.55
2017-06-10 22:16:28.205554 EDT | MinReturn                 245.379
2017-06-10 22:16:28.205926 EDT | AverageEsReturn           272.626
2017-06-10 22:16:28.206285 EDT | StdEsReturn               315.618
2017-06-10 22:16:28.206643 EDT | MaxEsReturn               812.349
2017-06-10 22:16:28.206996 EDT | MinEsReturn                26.2164
2017-06-10 22:16:28.207351 EDT | AverageDiscountedReturn   179.227
2017-06-10 22:16:28.207693 EDT | AverageQLoss                2.67657
2017-06-10 22:16:28.208035 EDT | AveragePolicySurr         -32.1236
2017-06-10 22:16:28.208375 EDT | AverageQ                   31.6722
2017-06-10 22:16:28.208788 EDT | AverageAbsQ                31.7032
2017-06-10 22:16:28.209140 EDT | AverageY                   31.6736
2017-06-10 22:16:28.209495 EDT | AverageAbsY                31.6869
2017-06-10 22:16:28.209861 EDT | AverageAbsQYDiff            0.630456
2017-06-10 22:16:28.210205 EDT | AverageAction               0.87885
2017-06-10 22:16:28.210549 EDT | PolicyRegParamNorm         68.3361
2017-06-10 22:16:28.210902 EDT | QFunRegParamNorm           85.4478
2017-06-10 22:16:28.211253 EDT | -----------------------  -----------
2017-06-10 22:16:28.211839 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #400 | Training started
2017-06-10 22:16:43.076039 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #400 | Training finished
2017-06-10 22:16:43.076924 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #400 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 22:16:43.077138 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #400 | Collecting samples for evaluation
2017-06-10 22:16:55.185905 EDT | -----------------------  ----------
2017-06-10 22:16:55.186740 EDT | Epoch                    400
2017-06-10 22:16:55.187235 EDT | Iteration                400
2017-06-10 22:16:55.188150 EDT | AverageReturn            384.748
2017-06-10 22:16:55.188785 EDT | StdReturn                204.826
2017-06-10 22:16:55.189133 EDT | MaxReturn                932.03
2017-06-10 22:16:55.189477 EDT | MinReturn                184.33
2017-06-10 22:16:55.189838 EDT | AverageEsReturn          333.342
2017-06-10 22:16:55.190182 EDT | StdEsReturn              168.048
2017-06-10 22:16:55.193303 EDT | MaxEsReturn              555.528
2017-06-10 22:16:55.195213 EDT | MinEsReturn               29.3266
2017-06-10 22:16:55.195593 EDT | AverageDiscountedReturn  161.961
2017-06-10 22:16:55.195942 EDT | AverageQLoss               2.33407
2017-06-10 22:16:55.196289 EDT | AveragePolicySurr        -32.1174
2017-06-10 22:16:55.196634 EDT | AverageQ                  31.6183
2017-06-10 22:16:55.196988 EDT | AverageAbsQ               31.6459
2017-06-10 22:16:55.197434 EDT | AverageY                  31.6206
2017-06-10 22:16:55.197799 EDT | AverageAbsY               31.6328
2017-06-10 22:16:55.198147 EDT | AverageAbsQYDiff           0.636269
2017-06-10 22:16:55.198489 EDT | AverageAction              0.910297
2017-06-10 22:16:55.198831 EDT | PolicyRegParamNorm        68.4227
2017-06-10 22:16:55.199195 EDT | QFunRegParamNorm          85.5391
2017-06-10 22:16:55.199638 EDT | -----------------------  ----------
2017-06-10 22:16:55.200261 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #401 | Training started
2017-06-10 22:17:09.483386 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #401 | Training finished
2017-06-10 22:17:09.484216 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #401 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 22:17:09.484506 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #401 | Collecting samples for evaluation
2017-06-10 22:17:22.328023 EDT | -----------------------  -----------
2017-06-10 22:17:22.333354 EDT | Epoch                     401
2017-06-10 22:17:22.333734 EDT | Iteration                 401
2017-06-10 22:17:22.334060 EDT | AverageReturn             551.771
2017-06-10 22:17:22.334502 EDT | StdReturn                 326.97
2017-06-10 22:17:22.334852 EDT | MaxReturn                1330.6
2017-06-10 22:17:22.335203 EDT | MinReturn                 246.162
2017-06-10 22:17:22.335579 EDT | AverageEsReturn           394.789
2017-06-10 22:17:22.335912 EDT | StdEsReturn               231.445
2017-06-10 22:17:22.336235 EDT | MaxEsReturn               765.397
2017-06-10 22:17:22.336597 EDT | MinEsReturn                61.8468
2017-06-10 22:17:22.336872 EDT | AverageDiscountedReturn   169.062
2017-06-10 22:17:22.337191 EDT | AverageQLoss                2.76419
2017-06-10 22:17:22.337707 EDT | AveragePolicySurr         -32.0028
2017-06-10 22:17:22.339198 EDT | AverageQ                   31.5136
2017-06-10 22:17:22.339409 EDT | AverageAbsQ                31.5372
2017-06-10 22:17:22.339566 EDT | AverageY                   31.5156
2017-06-10 22:17:22.339720 EDT | AverageAbsY                31.5263
2017-06-10 22:17:22.339905 EDT | AverageAbsQYDiff            0.641886
2017-06-10 22:17:22.340057 EDT | AverageAction               0.893237
2017-06-10 22:17:22.340206 EDT | PolicyRegParamNorm         68.4472
2017-06-10 22:17:22.340355 EDT | QFunRegParamNorm           85.6384
2017-06-10 22:17:22.340503 EDT | -----------------------  -----------
2017-06-10 22:17:22.340834 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #402 | Training started
2017-06-10 22:17:36.954476 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #402 | Training finished
2017-06-10 22:17:36.955343 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #402 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 22:17:36.955656 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #402 | Collecting samples for evaluation
2017-06-10 22:17:49.812191 EDT | -----------------------  -----------
2017-06-10 22:17:49.813113 EDT | Epoch                     402
2017-06-10 22:17:49.813474 EDT | Iteration                 402
2017-06-10 22:17:49.813827 EDT | AverageReturn             372.631
2017-06-10 22:17:49.814161 EDT | StdReturn                 314.184
2017-06-10 22:17:49.814501 EDT | MaxReturn                1137.99
2017-06-10 22:17:49.814825 EDT | MinReturn                  63.1087
2017-06-10 22:17:49.815157 EDT | AverageEsReturn           263.076
2017-06-10 22:17:49.815492 EDT | StdEsReturn               175.486
2017-06-10 22:17:49.815813 EDT | MaxEsReturn               546.741
2017-06-10 22:17:49.816146 EDT | MinEsReturn                23.2074
2017-06-10 22:17:49.816479 EDT | AverageDiscountedReturn   131.92
2017-06-10 22:17:49.816805 EDT | AverageQLoss                2.92075
2017-06-10 22:17:49.816988 EDT | AveragePolicySurr         -32.1119
2017-06-10 22:17:49.817315 EDT | AverageQ                   31.6342
2017-06-10 22:17:49.817654 EDT | AverageAbsQ                31.6622
2017-06-10 22:17:49.817992 EDT | AverageY                   31.6373
2017-06-10 22:17:49.818265 EDT | AverageAbsY                31.6472
2017-06-10 22:17:49.818552 EDT | AverageAbsQYDiff            0.675442
2017-06-10 22:17:49.818874 EDT | AverageAction               0.935446
2017-06-10 22:17:49.819208 EDT | PolicyRegParamNorm         68.4521
2017-06-10 22:17:49.819519 EDT | QFunRegParamNorm           85.6952
2017-06-10 22:17:49.819777 EDT | -----------------------  -----------
2017-06-10 22:17:49.820210 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #403 | Training started
2017-06-10 22:18:05.842712 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #403 | Training finished
2017-06-10 22:18:05.843548 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #403 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 22:18:05.843825 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #403 | Collecting samples for evaluation
2017-06-10 22:18:18.216446 EDT | -----------------------  -----------
2017-06-10 22:18:18.219768 EDT | Epoch                     403
2017-06-10 22:18:18.220114 EDT | Iteration                 403
2017-06-10 22:18:18.220400 EDT | AverageReturn            1214.04
2017-06-10 22:18:18.220727 EDT | StdReturn                 326.972
2017-06-10 22:18:18.221009 EDT | MaxReturn                2146.17
2017-06-10 22:18:18.221275 EDT | MinReturn                 492.116
2017-06-10 22:18:18.221537 EDT | AverageEsReturn           291.285
2017-06-10 22:18:18.221815 EDT | StdEsReturn               289.642
2017-06-10 22:18:18.222112 EDT | MaxEsReturn               861.567
2017-06-10 22:18:18.223489 EDT | MinEsReturn                16.6012
2017-06-10 22:18:18.223884 EDT | AverageDiscountedReturn   217.191
2017-06-10 22:18:18.225359 EDT | AverageQLoss                2.58977
2017-06-10 22:18:18.225715 EDT | AveragePolicySurr         -32.0294
2017-06-10 22:18:18.227439 EDT | AverageQ                   31.5551
2017-06-10 22:18:18.227784 EDT | AverageAbsQ                31.583
2017-06-10 22:18:18.228907 EDT | AverageY                   31.5544
2017-06-10 22:18:18.230016 EDT | AverageAbsY                31.5657
2017-06-10 22:18:18.230387 EDT | AverageAbsQYDiff            0.638735
2017-06-10 22:18:18.231603 EDT | AverageAction               0.889713
2017-06-10 22:18:18.231960 EDT | PolicyRegParamNorm         68.5456
2017-06-10 22:18:18.232274 EDT | QFunRegParamNorm           85.7827
2017-06-10 22:18:18.232594 EDT | -----------------------  -----------
2017-06-10 22:18:18.233073 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #404 | Training started
2017-06-10 22:18:32.384653 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #404 | Training finished
2017-06-10 22:18:32.385767 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #404 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 22:18:32.386122 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #404 | Collecting samples for evaluation
2017-06-10 22:18:46.112500 EDT | -----------------------  -----------
2017-06-10 22:18:46.113779 EDT | Epoch                     404
2017-06-10 22:18:46.114113 EDT | Iteration                 404
2017-06-10 22:18:46.114288 EDT | AverageReturn            1047.25
2017-06-10 22:18:46.114447 EDT | StdReturn                 457.639
2017-06-10 22:18:46.114604 EDT | MaxReturn                1948.7
2017-06-10 22:18:46.114917 EDT | MinReturn                 297.962
2017-06-10 22:18:46.115247 EDT | AverageEsReturn           587.506
2017-06-10 22:18:46.115679 EDT | StdEsReturn               347.906
2017-06-10 22:18:46.116083 EDT | MaxEsReturn              1259.83
2017-06-10 22:18:46.116526 EDT | MinEsReturn               309.843
2017-06-10 22:18:46.116949 EDT | AverageDiscountedReturn   201.916
2017-06-10 22:18:46.117799 EDT | AverageQLoss                2.8649
2017-06-10 22:18:46.118051 EDT | AveragePolicySurr         -32.0058
2017-06-10 22:18:46.118554 EDT | AverageQ                   31.516
2017-06-10 22:18:46.118749 EDT | AverageAbsQ                31.5486
2017-06-10 22:18:46.118932 EDT | AverageY                   31.5161
2017-06-10 22:18:46.119112 EDT | AverageAbsY                31.5303
2017-06-10 22:18:46.119292 EDT | AverageAbsQYDiff            0.659297
2017-06-10 22:18:46.120898 EDT | AverageAction               0.900437
2017-06-10 22:18:46.121081 EDT | PolicyRegParamNorm         68.6051
2017-06-10 22:18:46.121732 EDT | QFunRegParamNorm           85.8667
2017-06-10 22:18:46.121922 EDT | -----------------------  -----------
2017-06-10 22:18:46.128193 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #405 | Training started
2017-06-10 22:18:59.483317 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #405 | Training finished
2017-06-10 22:18:59.484108 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #405 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 22:18:59.484336 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #405 | Collecting samples for evaluation
2017-06-10 22:19:13.148006 EDT | -----------------------  -----------
2017-06-10 22:19:13.151761 EDT | Epoch                     405
2017-06-10 22:19:13.152171 EDT | Iteration                 405
2017-06-10 22:19:13.152549 EDT | AverageReturn             450.435
2017-06-10 22:19:13.152930 EDT | StdReturn                 201.24
2017-06-10 22:19:13.153301 EDT | MaxReturn                 982.959
2017-06-10 22:19:13.153674 EDT | MinReturn                 240.007
2017-06-10 22:19:13.154049 EDT | AverageEsReturn           216.11
2017-06-10 22:19:13.154413 EDT | StdEsReturn               342.185
2017-06-10 22:19:13.154778 EDT | MaxEsReturn              1274.3
2017-06-10 22:19:13.155141 EDT | MinEsReturn                51.4301
2017-06-10 22:19:13.155503 EDT | AverageDiscountedReturn   168.064
2017-06-10 22:19:13.155866 EDT | AverageQLoss                2.84134
2017-06-10 22:19:13.156227 EDT | AveragePolicySurr         -32.0655
2017-06-10 22:19:13.156588 EDT | AverageQ                   31.5591
2017-06-10 22:19:13.157766 EDT | AverageAbsQ                31.5921
2017-06-10 22:19:13.158140 EDT | AverageY                   31.5616
2017-06-10 22:19:13.158512 EDT | AverageAbsY                31.5738
2017-06-10 22:19:13.158877 EDT | AverageAbsQYDiff            0.645946
2017-06-10 22:19:13.159241 EDT | AverageAction               0.898002
2017-06-10 22:19:13.159605 EDT | PolicyRegParamNorm         68.6431
2017-06-10 22:19:13.159966 EDT | QFunRegParamNorm           85.9943
2017-06-10 22:19:13.160328 EDT | -----------------------  -----------
2017-06-10 22:19:13.160853 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #406 | Training started
2017-06-10 22:19:27.758962 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #406 | Training finished
2017-06-10 22:19:27.759214 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #406 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 22:19:27.759444 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #406 | Collecting samples for evaluation
2017-06-10 22:19:40.574683 EDT | -----------------------  -----------
2017-06-10 22:19:40.575271 EDT | Epoch                     406
2017-06-10 22:19:40.575473 EDT | Iteration                 406
2017-06-10 22:19:40.575740 EDT | AverageReturn             455.186
2017-06-10 22:19:40.575963 EDT | StdReturn                 223.72
2017-06-10 22:19:40.577893 EDT | MaxReturn                1166.42
2017-06-10 22:19:40.579007 EDT | MinReturn                 255.055
2017-06-10 22:19:40.579717 EDT | AverageEsReturn           283.732
2017-06-10 22:19:40.579925 EDT | StdEsReturn               216.768
2017-06-10 22:19:40.580251 EDT | MaxEsReturn               608.739
2017-06-10 22:19:40.580627 EDT | MinEsReturn                24.9145
2017-06-10 22:19:40.580931 EDT | AverageDiscountedReturn   172.65
2017-06-10 22:19:40.581179 EDT | AverageQLoss                2.68922
2017-06-10 22:19:40.581368 EDT | AveragePolicySurr         -31.9949
2017-06-10 22:19:40.581611 EDT | AverageQ                   31.533
2017-06-10 22:19:40.581895 EDT | AverageAbsQ                31.5648
2017-06-10 22:19:40.582096 EDT | AverageY                   31.5333
2017-06-10 22:19:40.582289 EDT | AverageAbsY                31.5514
2017-06-10 22:19:40.582483 EDT | AverageAbsQYDiff            0.648953
2017-06-10 22:19:40.582682 EDT | AverageAction               0.9257
2017-06-10 22:19:40.582946 EDT | PolicyRegParamNorm         68.7108
2017-06-10 22:19:40.583140 EDT | QFunRegParamNorm           86.1535
2017-06-10 22:19:40.583555 EDT | -----------------------  -----------
2017-06-10 22:19:40.583888 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #407 | Training started
2017-06-10 22:19:56.351623 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #407 | Training finished
2017-06-10 22:19:56.352478 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #407 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 22:19:56.352757 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #407 | Collecting samples for evaluation
2017-06-10 22:20:08.258062 EDT | -----------------------  ----------
2017-06-10 22:20:08.258941 EDT | Epoch                    407
2017-06-10 22:20:08.259306 EDT | Iteration                407
2017-06-10 22:20:08.259653 EDT | AverageReturn            394.593
2017-06-10 22:20:08.259996 EDT | StdReturn                 87.2079
2017-06-10 22:20:08.260340 EDT | MaxReturn                575.039
2017-06-10 22:20:08.260684 EDT | MinReturn                295.04
2017-06-10 22:20:08.260993 EDT | AverageEsReturn          336.579
2017-06-10 22:20:08.261245 EDT | StdEsReturn              146.291
2017-06-10 22:20:08.261491 EDT | MaxEsReturn              495.267
2017-06-10 22:20:08.261743 EDT | MinEsReturn              116.901
2017-06-10 22:20:08.261997 EDT | AverageDiscountedReturn  174.456
2017-06-10 22:20:08.262241 EDT | AverageQLoss               2.6336
2017-06-10 22:20:08.262483 EDT | AveragePolicySurr        -31.9283
2017-06-10 22:20:08.262724 EDT | AverageQ                  31.4502
2017-06-10 22:20:08.262966 EDT | AverageAbsQ               31.4838
2017-06-10 22:20:08.263207 EDT | AverageY                  31.452
2017-06-10 22:20:08.263447 EDT | AverageAbsY               31.4709
2017-06-10 22:20:08.263688 EDT | AverageAbsQYDiff           0.632787
2017-06-10 22:20:08.263929 EDT | AverageAction              0.884266
2017-06-10 22:20:08.264171 EDT | PolicyRegParamNorm        68.8225
2017-06-10 22:20:08.264411 EDT | QFunRegParamNorm          86.2625
2017-06-10 22:20:08.264651 EDT | -----------------------  ----------
2017-06-10 22:20:08.265008 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #408 | Training started
2017-06-10 22:20:24.661148 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #408 | Training finished
2017-06-10 22:20:24.669562 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #408 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 22:20:24.670677 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #408 | Collecting samples for evaluation
2017-06-10 22:20:37.820750 EDT | -----------------------  ----------
2017-06-10 22:20:37.821573 EDT | Epoch                    408
2017-06-10 22:20:37.821984 EDT | Iteration                408
2017-06-10 22:20:37.822242 EDT | AverageReturn            488.891
2017-06-10 22:20:37.822436 EDT | StdReturn                138.57
2017-06-10 22:20:37.822617 EDT | MaxReturn                972.142
2017-06-10 22:20:37.823468 EDT | MinReturn                298.443
2017-06-10 22:20:37.823805 EDT | AverageEsReturn          473.86
2017-06-10 22:20:37.823992 EDT | StdEsReturn              276.568
2017-06-10 22:20:37.824440 EDT | MaxEsReturn              969.641
2017-06-10 22:20:37.824708 EDT | MinEsReturn               43.0747
2017-06-10 22:20:37.824985 EDT | AverageDiscountedReturn  172.305
2017-06-10 22:20:37.825218 EDT | AverageQLoss               2.77599
2017-06-10 22:20:37.825436 EDT | AveragePolicySurr        -32.0041
2017-06-10 22:20:37.825755 EDT | AverageQ                  31.5112
2017-06-10 22:20:37.825940 EDT | AverageAbsQ               31.5551
2017-06-10 22:20:37.826153 EDT | AverageY                  31.5147
2017-06-10 22:20:37.826332 EDT | AverageAbsY               31.5427
2017-06-10 22:20:37.826565 EDT | AverageAbsQYDiff           0.641641
2017-06-10 22:20:37.826744 EDT | AverageAction              0.902236
2017-06-10 22:20:37.827109 EDT | PolicyRegParamNorm        68.8815
2017-06-10 22:20:37.827348 EDT | QFunRegParamNorm          86.3338
2017-06-10 22:20:37.827846 EDT | -----------------------  ----------
2017-06-10 22:20:37.828510 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #409 | Training started
2017-06-10 22:20:51.347517 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #409 | Training finished
2017-06-10 22:20:51.348362 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #409 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 22:20:51.348685 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #409 | Collecting samples for evaluation
2017-06-10 22:21:03.927506 EDT | -----------------------  ----------
2017-06-10 22:21:03.928231 EDT | Epoch                    409
2017-06-10 22:21:03.928501 EDT | Iteration                409
2017-06-10 22:21:03.928704 EDT | AverageReturn            479.905
2017-06-10 22:21:03.928976 EDT | StdReturn                 99.7327
2017-06-10 22:21:03.929461 EDT | MaxReturn                870.728
2017-06-10 22:21:03.929656 EDT | MinReturn                392.529
2017-06-10 22:21:03.929981 EDT | AverageEsReturn          306.51
2017-06-10 22:21:03.930487 EDT | StdEsReturn              152.317
2017-06-10 22:21:03.930824 EDT | MaxEsReturn              487.63
2017-06-10 22:21:03.932176 EDT | MinEsReturn              105.728
2017-06-10 22:21:03.932357 EDT | AverageDiscountedReturn  168.053
2017-06-10 22:21:03.932669 EDT | AverageQLoss               3.1818
2017-06-10 22:21:03.932947 EDT | AveragePolicySurr        -31.9632
2017-06-10 22:21:03.933184 EDT | AverageQ                  31.4553
2017-06-10 22:21:03.933470 EDT | AverageAbsQ               31.4972
2017-06-10 22:21:03.933650 EDT | AverageY                  31.4549
2017-06-10 22:21:03.933858 EDT | AverageAbsY               31.484
2017-06-10 22:21:03.934052 EDT | AverageAbsQYDiff           0.664763
2017-06-10 22:21:03.934231 EDT | AverageAction              0.859863
2017-06-10 22:21:03.934538 EDT | PolicyRegParamNorm        69.0117
2017-06-10 22:21:03.934875 EDT | QFunRegParamNorm          86.5308
2017-06-10 22:21:03.935232 EDT | -----------------------  ----------
2017-06-10 22:21:03.935604 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #410 | Training started
2017-06-10 22:21:19.238589 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #410 | Training finished
2017-06-10 22:21:19.239389 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #410 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 22:21:19.239597 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #410 | Collecting samples for evaluation
2017-06-10 22:21:31.485627 EDT | -----------------------  ----------
2017-06-10 22:21:31.486568 EDT | Epoch                    410
2017-06-10 22:21:31.486781 EDT | Iteration                410
2017-06-10 22:21:31.486973 EDT | AverageReturn            641.762
2017-06-10 22:21:31.487158 EDT | StdReturn                100.679
2017-06-10 22:21:31.487340 EDT | MaxReturn                897.849
2017-06-10 22:21:31.487536 EDT | MinReturn                483.918
2017-06-10 22:21:31.487808 EDT | AverageEsReturn          254.69
2017-06-10 22:21:31.488069 EDT | StdEsReturn              185.719
2017-06-10 22:21:31.488223 EDT | MaxEsReturn              587.813
2017-06-10 22:21:31.488373 EDT | MinEsReturn               18.0023
2017-06-10 22:21:31.488597 EDT | AverageDiscountedReturn  204.192
2017-06-10 22:21:31.488793 EDT | AverageQLoss               2.59768
2017-06-10 22:21:31.488945 EDT | AveragePolicySurr        -32.1005
2017-06-10 22:21:31.489096 EDT | AverageQ                  31.6117
2017-06-10 22:21:31.489246 EDT | AverageAbsQ               31.6552
2017-06-10 22:21:31.489395 EDT | AverageY                  31.6122
2017-06-10 22:21:31.489555 EDT | AverageAbsY               31.6402
2017-06-10 22:21:31.489833 EDT | AverageAbsQYDiff           0.63349
2017-06-10 22:21:31.489987 EDT | AverageAction              0.893252
2017-06-10 22:21:31.490137 EDT | PolicyRegParamNorm        69.0761
2017-06-10 22:21:31.490372 EDT | QFunRegParamNorm          86.5948
2017-06-10 22:21:31.490524 EDT | -----------------------  ----------
2017-06-10 22:21:31.490850 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #411 | Training started
2017-06-10 22:21:47.503359 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #411 | Training finished
2017-06-10 22:21:47.504236 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #411 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 22:21:47.504584 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #411 | Collecting samples for evaluation
2017-06-10 22:21:59.942319 EDT | -----------------------  ----------
2017-06-10 22:21:59.945093 EDT | Epoch                    411
2017-06-10 22:21:59.945309 EDT | Iteration                411
2017-06-10 22:21:59.945574 EDT | AverageReturn            468.549
2017-06-10 22:21:59.945957 EDT | StdReturn                 86.2905
2017-06-10 22:21:59.946253 EDT | MaxReturn                708.517
2017-06-10 22:21:59.946432 EDT | MinReturn                295.901
2017-06-10 22:21:59.947987 EDT | AverageEsReturn          313.765
2017-06-10 22:21:59.948235 EDT | StdEsReturn              183.118
2017-06-10 22:21:59.948442 EDT | MaxEsReturn              563.272
2017-06-10 22:21:59.948604 EDT | MinEsReturn               91.4669
2017-06-10 22:21:59.948812 EDT | AverageDiscountedReturn  181.153
2017-06-10 22:21:59.948972 EDT | AverageQLoss               2.92455
2017-06-10 22:21:59.949360 EDT | AveragePolicySurr        -31.9532
2017-06-10 22:21:59.949650 EDT | AverageQ                  31.4722
2017-06-10 22:21:59.949907 EDT | AverageAbsQ               31.5119
2017-06-10 22:21:59.950116 EDT | AverageY                  31.474
2017-06-10 22:21:59.950292 EDT | AverageAbsY               31.4941
2017-06-10 22:21:59.950451 EDT | AverageAbsQYDiff           0.659284
2017-06-10 22:21:59.950608 EDT | AverageAction              0.907205
2017-06-10 22:21:59.950770 EDT | PolicyRegParamNorm        69.1748
2017-06-10 22:21:59.951006 EDT | QFunRegParamNorm          86.6963
2017-06-10 22:21:59.951216 EDT | -----------------------  ----------
2017-06-10 22:21:59.951504 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #412 | Training started
2017-06-10 22:22:15.113425 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #412 | Training finished
2017-06-10 22:22:15.114878 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #412 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 22:22:15.115281 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #412 | Collecting samples for evaluation
2017-06-10 22:22:28.372632 EDT | -----------------------  -----------
2017-06-10 22:22:28.373532 EDT | Epoch                     412
2017-06-10 22:22:28.373965 EDT | Iteration                 412
2017-06-10 22:22:28.374160 EDT | AverageReturn             901.541
2017-06-10 22:22:28.374419 EDT | StdReturn                 198.541
2017-06-10 22:22:28.375074 EDT | MaxReturn                1385.42
2017-06-10 22:22:28.375325 EDT | MinReturn                 518.939
2017-06-10 22:22:28.375513 EDT | AverageEsReturn           257.023
2017-06-10 22:22:28.375696 EDT | StdEsReturn               149.768
2017-06-10 22:22:28.376486 EDT | MaxEsReturn               461.486
2017-06-10 22:22:28.376749 EDT | MinEsReturn                48.4947
2017-06-10 22:22:28.377020 EDT | AverageDiscountedReturn   227.596
2017-06-10 22:22:28.377268 EDT | AverageQLoss                2.85391
2017-06-10 22:22:28.377513 EDT | AveragePolicySurr         -32.0208
2017-06-10 22:22:28.377782 EDT | AverageQ                   31.5296
2017-06-10 22:22:28.378039 EDT | AverageAbsQ                31.5653
2017-06-10 22:22:28.379458 EDT | AverageY                   31.5293
2017-06-10 22:22:28.379752 EDT | AverageAbsY                31.5493
2017-06-10 22:22:28.380029 EDT | AverageAbsQYDiff            0.654948
2017-06-10 22:22:28.380221 EDT | AverageAction               0.858855
2017-06-10 22:22:28.380403 EDT | PolicyRegParamNorm         69.1884
2017-06-10 22:22:28.380583 EDT | QFunRegParamNorm           86.8208
2017-06-10 22:22:28.380763 EDT | -----------------------  -----------
2017-06-10 22:22:28.381137 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #413 | Training started
2017-06-10 22:22:43.146341 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #413 | Training finished
2017-06-10 22:22:43.146946 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #413 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 22:22:43.147482 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #413 | Collecting samples for evaluation
2017-06-10 22:22:56.113051 EDT | -----------------------  -----------
2017-06-10 22:22:56.114258 EDT | Epoch                     413
2017-06-10 22:22:56.114620 EDT | Iteration                 413
2017-06-10 22:22:56.115012 EDT | AverageReturn             508.188
2017-06-10 22:22:56.115205 EDT | StdReturn                 260.87
2017-06-10 22:22:56.115473 EDT | MaxReturn                1236.5
2017-06-10 22:22:56.115651 EDT | MinReturn                 269.126
2017-06-10 22:22:56.115866 EDT | AverageEsReturn           237.212
2017-06-10 22:22:56.116029 EDT | StdEsReturn               224.099
2017-06-10 22:22:56.116559 EDT | MaxEsReturn               644.275
2017-06-10 22:22:56.116873 EDT | MinEsReturn                29.4672
2017-06-10 22:22:56.117189 EDT | AverageDiscountedReturn   179.875
2017-06-10 22:22:56.117435 EDT | AverageQLoss                3.46951
2017-06-10 22:22:56.117597 EDT | AveragePolicySurr         -31.8798
2017-06-10 22:22:56.117873 EDT | AverageQ                   31.4036
2017-06-10 22:22:56.118100 EDT | AverageAbsQ                31.4414
2017-06-10 22:22:56.118260 EDT | AverageY                   31.4062
2017-06-10 22:22:56.118434 EDT | AverageAbsY                31.428
2017-06-10 22:22:56.121700 EDT | AverageAbsQYDiff            0.690404
2017-06-10 22:22:56.122724 EDT | AverageAction               0.890219
2017-06-10 22:22:56.123040 EDT | PolicyRegParamNorm         69.2347
2017-06-10 22:22:56.123324 EDT | QFunRegParamNorm           86.9169
2017-06-10 22:22:56.123867 EDT | -----------------------  -----------
2017-06-10 22:22:56.124206 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #414 | Training started
2017-06-10 22:23:11.027736 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #414 | Training finished
2017-06-10 22:23:11.028211 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #414 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 22:23:11.028718 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #414 | Collecting samples for evaluation
2017-06-10 22:23:24.092076 EDT | -----------------------  -----------
2017-06-10 22:23:24.093385 EDT | Epoch                     414
2017-06-10 22:23:24.093804 EDT | Iteration                 414
2017-06-10 22:23:24.094181 EDT | AverageReturn             793.147
2017-06-10 22:23:24.094500 EDT | StdReturn                 193.834
2017-06-10 22:23:24.094868 EDT | MaxReturn                1171.87
2017-06-10 22:23:24.095238 EDT | MinReturn                 297.689
2017-06-10 22:23:24.095556 EDT | AverageEsReturn           357.439
2017-06-10 22:23:24.095915 EDT | StdEsReturn               215.535
2017-06-10 22:23:24.096282 EDT | MaxEsReturn               742.74
2017-06-10 22:23:24.096640 EDT | MinEsReturn                42.0243
2017-06-10 22:23:24.096945 EDT | AverageDiscountedReturn   215.105
2017-06-10 22:23:24.097311 EDT | AverageQLoss                2.7099
2017-06-10 22:23:24.097682 EDT | AveragePolicySurr         -31.9122
2017-06-10 22:23:24.098033 EDT | AverageQ                   31.4625
2017-06-10 22:23:24.098360 EDT | AverageAbsQ                31.5031
2017-06-10 22:23:24.098828 EDT | AverageY                   31.4638
2017-06-10 22:23:24.099871 EDT | AverageAbsY                31.4889
2017-06-10 22:23:24.100369 EDT | AverageAbsQYDiff            0.633693
2017-06-10 22:23:24.100745 EDT | AverageAction               0.866802
2017-06-10 22:23:24.101112 EDT | PolicyRegParamNorm         69.2737
2017-06-10 22:23:24.101553 EDT | QFunRegParamNorm           87.0493
2017-06-10 22:23:24.102214 EDT | -----------------------  -----------
2017-06-10 22:23:24.103193 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #415 | Training started
2017-06-10 22:23:39.204628 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #415 | Training finished
2017-06-10 22:23:39.205636 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #415 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 22:23:39.206032 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #415 | Collecting samples for evaluation
2017-06-10 22:23:51.583820 EDT | -----------------------  -----------
2017-06-10 22:23:51.584802 EDT | Epoch                     415
2017-06-10 22:23:51.585165 EDT | Iteration                 415
2017-06-10 22:23:51.585500 EDT | AverageReturn             968.439
2017-06-10 22:23:51.585855 EDT | StdReturn                 112.686
2017-06-10 22:23:51.586184 EDT | MaxReturn                1215.04
2017-06-10 22:23:51.586511 EDT | MinReturn                 800.941
2017-06-10 22:23:51.586838 EDT | AverageEsReturn           225.263
2017-06-10 22:23:51.587162 EDT | StdEsReturn               206.997
2017-06-10 22:23:51.587486 EDT | MaxEsReturn               631.091
2017-06-10 22:23:51.587809 EDT | MinEsReturn                15.1091
2017-06-10 22:23:51.588132 EDT | AverageDiscountedReturn   231.02
2017-06-10 22:23:51.588463 EDT | AverageQLoss                2.55687
2017-06-10 22:23:51.588783 EDT | AveragePolicySurr         -31.9155
2017-06-10 22:23:51.589110 EDT | AverageQ                   31.4281
2017-06-10 22:23:51.589429 EDT | AverageAbsQ                31.4682
2017-06-10 22:23:51.589757 EDT | AverageY                   31.428
2017-06-10 22:23:51.590079 EDT | AverageAbsY                31.4509
2017-06-10 22:23:51.590398 EDT | AverageAbsQYDiff            0.638903
2017-06-10 22:23:51.590724 EDT | AverageAction               0.846813
2017-06-10 22:23:51.591044 EDT | PolicyRegParamNorm         69.3782
2017-06-10 22:23:51.591365 EDT | QFunRegParamNorm           87.2001
2017-06-10 22:23:51.591690 EDT | -----------------------  -----------
2017-06-10 22:23:51.592163 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #416 | Training started
2017-06-10 22:24:07.100564 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #416 | Training finished
2017-06-10 22:24:07.101486 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #416 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 22:24:07.101829 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #416 | Collecting samples for evaluation
2017-06-10 22:24:19.669348 EDT | -----------------------  -----------
2017-06-10 22:24:19.670873 EDT | Epoch                     416
2017-06-10 22:24:19.671228 EDT | Iteration                 416
2017-06-10 22:24:19.671501 EDT | AverageReturn            1089.05
2017-06-10 22:24:19.671846 EDT | StdReturn                 223.808
2017-06-10 22:24:19.672197 EDT | MaxReturn                1778.76
2017-06-10 22:24:19.672517 EDT | MinReturn                 767.088
2017-06-10 22:24:19.672785 EDT | AverageEsReturn           544.186
2017-06-10 22:24:19.673124 EDT | StdEsReturn               297.976
2017-06-10 22:24:19.673475 EDT | MaxEsReturn              1112.83
2017-06-10 22:24:19.673886 EDT | MinEsReturn               127.612
2017-06-10 22:24:19.674169 EDT | AverageDiscountedReturn   242.932
2017-06-10 22:24:19.675337 EDT | AverageQLoss                2.55796
2017-06-10 22:24:19.677072 EDT | AveragePolicySurr         -31.8726
2017-06-10 22:24:19.677523 EDT | AverageQ                   31.3745
2017-06-10 22:24:19.677905 EDT | AverageAbsQ                31.4117
2017-06-10 22:24:19.678844 EDT | AverageY                   31.3774
2017-06-10 22:24:19.681036 EDT | AverageAbsY                31.3989
2017-06-10 22:24:19.681477 EDT | AverageAbsQYDiff            0.634069
2017-06-10 22:24:19.681844 EDT | AverageAction               0.841423
2017-06-10 22:24:19.682283 EDT | PolicyRegParamNorm         69.4509
2017-06-10 22:24:19.686568 EDT | QFunRegParamNorm           87.3188
2017-06-10 22:24:19.686954 EDT | -----------------------  -----------
2017-06-10 22:24:19.687756 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #417 | Training started
2017-06-10 22:24:34.444335 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #417 | Training finished
2017-06-10 22:24:34.445200 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #417 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 22:24:34.445450 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #417 | Collecting samples for evaluation
2017-06-10 22:24:47.035198 EDT | -----------------------  ----------
2017-06-10 22:24:47.036004 EDT | Epoch                    417
2017-06-10 22:24:47.036287 EDT | Iteration                417
2017-06-10 22:24:47.036476 EDT | AverageReturn            488.264
2017-06-10 22:24:47.036660 EDT | StdReturn                 75.4302
2017-06-10 22:24:47.036843 EDT | MaxReturn                660.529
2017-06-10 22:24:47.037085 EDT | MinReturn                348.041
2017-06-10 22:24:47.037269 EDT | AverageEsReturn          223.007
2017-06-10 22:24:47.037451 EDT | StdEsReturn              214.081
2017-06-10 22:24:47.037662 EDT | MaxEsReturn              688.906
2017-06-10 22:24:47.037907 EDT | MinEsReturn               19.6948
2017-06-10 22:24:47.038091 EDT | AverageDiscountedReturn  193.636
2017-06-10 22:24:47.038274 EDT | AverageQLoss               2.32208
2017-06-10 22:24:47.038456 EDT | AveragePolicySurr        -31.9112
2017-06-10 22:24:47.038756 EDT | AverageQ                  31.4296
2017-06-10 22:24:47.038981 EDT | AverageAbsQ               31.4668
2017-06-10 22:24:47.039259 EDT | AverageY                  31.4295
2017-06-10 22:24:47.039534 EDT | AverageAbsY               31.4502
2017-06-10 22:24:47.039788 EDT | AverageAbsQYDiff           0.62863
2017-06-10 22:24:47.040022 EDT | AverageAction              0.881187
2017-06-10 22:24:47.040207 EDT | PolicyRegParamNorm        69.4547
2017-06-10 22:24:47.040423 EDT | QFunRegParamNorm          87.3948
2017-06-10 22:24:47.040604 EDT | -----------------------  ----------
2017-06-10 22:24:47.040910 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #418 | Training started
2017-06-10 22:25:01.192929 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #418 | Training finished
2017-06-10 22:25:01.194832 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #418 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 22:25:01.195222 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #418 | Collecting samples for evaluation
2017-06-10 22:25:13.938007 EDT | -----------------------  -----------
2017-06-10 22:25:13.938919 EDT | Epoch                     418
2017-06-10 22:25:13.939267 EDT | Iteration                 418
2017-06-10 22:25:13.939620 EDT | AverageReturn             975.127
2017-06-10 22:25:13.939935 EDT | StdReturn                 181.204
2017-06-10 22:25:13.940271 EDT | MaxReturn                1335.34
2017-06-10 22:25:13.940593 EDT | MinReturn                 565.993
2017-06-10 22:25:13.940911 EDT | AverageEsReturn           301.95
2017-06-10 22:25:13.943608 EDT | StdEsReturn               226.737
2017-06-10 22:25:13.944577 EDT | MaxEsReturn               581.887
2017-06-10 22:25:13.944865 EDT | MinEsReturn                10.72
2017-06-10 22:25:13.945184 EDT | AverageDiscountedReturn   238.35
2017-06-10 22:25:13.945489 EDT | AverageQLoss                2.95087
2017-06-10 22:25:13.945649 EDT | AveragePolicySurr         -31.8928
2017-06-10 22:25:13.945825 EDT | AverageQ                   31.4026
2017-06-10 22:25:13.945984 EDT | AverageAbsQ                31.4381
2017-06-10 22:25:13.946135 EDT | AverageY                   31.4048
2017-06-10 22:25:13.946285 EDT | AverageAbsY                31.425
2017-06-10 22:25:13.946434 EDT | AverageAbsQYDiff            0.656307
2017-06-10 22:25:13.946581 EDT | AverageAction               0.863839
2017-06-10 22:25:13.946729 EDT | PolicyRegParamNorm         69.5534
2017-06-10 22:25:13.946877 EDT | QFunRegParamNorm           87.5105
2017-06-10 22:25:13.947024 EDT | -----------------------  -----------
2017-06-10 22:25:13.947368 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #419 | Training started
2017-06-10 22:25:29.932719 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #419 | Training finished
2017-06-10 22:25:30.057649 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #419 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 22:25:30.057926 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #419 | Collecting samples for evaluation
2017-06-10 22:25:43.126217 EDT | -----------------------  -----------
2017-06-10 22:25:43.127126 EDT | Epoch                     419
2017-06-10 22:25:43.127471 EDT | Iteration                 419
2017-06-10 22:25:43.127814 EDT | AverageReturn            1247.53
2017-06-10 22:25:43.128152 EDT | StdReturn                 577.127
2017-06-10 22:25:43.128500 EDT | MaxReturn                2817.29
2017-06-10 22:25:43.128842 EDT | MinReturn                 757.658
2017-06-10 22:25:43.129185 EDT | AverageEsReturn           459.83
2017-06-10 22:25:43.129489 EDT | StdEsReturn               242.586
2017-06-10 22:25:43.129842 EDT | MaxEsReturn               815.257
2017-06-10 22:25:43.130167 EDT | MinEsReturn                65.6364
2017-06-10 22:25:43.130509 EDT | AverageDiscountedReturn   219.989
2017-06-10 22:25:43.130847 EDT | AverageQLoss                2.6489
2017-06-10 22:25:43.131227 EDT | AveragePolicySurr         -31.9106
2017-06-10 22:25:43.131545 EDT | AverageQ                   31.406
2017-06-10 22:25:43.131849 EDT | AverageAbsQ                31.4389
2017-06-10 22:25:43.132122 EDT | AverageY                   31.4067
2017-06-10 22:25:43.132393 EDT | AverageAbsY                31.4227
2017-06-10 22:25:43.132694 EDT | AverageAbsQYDiff            0.64958
2017-06-10 22:25:43.133022 EDT | AverageAction               0.925602
2017-06-10 22:25:43.133308 EDT | PolicyRegParamNorm         69.613
2017-06-10 22:25:43.133632 EDT | QFunRegParamNorm           87.6156
2017-06-10 22:25:43.133898 EDT | -----------------------  -----------
2017-06-10 22:25:43.134283 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #420 | Training started
2017-06-10 22:25:59.585506 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #420 | Training finished
2017-06-10 22:25:59.586457 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #420 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 22:25:59.586943 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #420 | Collecting samples for evaluation
2017-06-10 22:26:12.186140 EDT | -----------------------  -----------
2017-06-10 22:26:12.186996 EDT | Epoch                     420
2017-06-10 22:26:12.187381 EDT | Iteration                 420
2017-06-10 22:26:12.187742 EDT | AverageReturn            1160.84
2017-06-10 22:26:12.188096 EDT | StdReturn                 314.705
2017-06-10 22:26:12.188460 EDT | MaxReturn                2124.83
2017-06-10 22:26:12.188827 EDT | MinReturn                 555.516
2017-06-10 22:26:12.189138 EDT | AverageEsReturn           415.873
2017-06-10 22:26:12.189454 EDT | StdEsReturn               387.362
2017-06-10 22:26:12.189799 EDT | MaxEsReturn              1108.32
2017-06-10 22:26:12.190096 EDT | MinEsReturn                76.7628
2017-06-10 22:26:12.190426 EDT | AverageDiscountedReturn   223.234
2017-06-10 22:26:12.190746 EDT | AverageQLoss                2.36962
2017-06-10 22:26:12.191097 EDT | AveragePolicySurr         -31.8623
2017-06-10 22:26:12.191393 EDT | AverageQ                   31.3913
2017-06-10 22:26:12.191758 EDT | AverageAbsQ                31.4286
2017-06-10 22:26:12.192116 EDT | AverageY                   31.3922
2017-06-10 22:26:12.192469 EDT | AverageAbsY                31.4138
2017-06-10 22:26:12.192808 EDT | AverageAbsQYDiff            0.625007
2017-06-10 22:26:12.193174 EDT | AverageAction               0.90632
2017-06-10 22:26:12.193528 EDT | PolicyRegParamNorm         69.6324
2017-06-10 22:26:12.193888 EDT | QFunRegParamNorm           87.7214
2017-06-10 22:26:12.194246 EDT | -----------------------  -----------
2017-06-10 22:26:12.194764 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #421 | Training started
2017-06-10 22:26:27.820592 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #421 | Training finished
2017-06-10 22:26:27.821957 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #421 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 22:26:27.823421 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #421 | Collecting samples for evaluation
2017-06-10 22:26:40.502827 EDT | -----------------------  -----------
2017-06-10 22:26:40.503757 EDT | Epoch                     421
2017-06-10 22:26:40.504125 EDT | Iteration                 421
2017-06-10 22:26:40.504380 EDT | AverageReturn             976.199
2017-06-10 22:26:40.504721 EDT | StdReturn                 496.902
2017-06-10 22:26:40.505075 EDT | MaxReturn                2428.67
2017-06-10 22:26:40.505412 EDT | MinReturn                  45.9692
2017-06-10 22:26:40.505759 EDT | AverageEsReturn           301.078
2017-06-10 22:26:40.506200 EDT | StdEsReturn               166.16
2017-06-10 22:26:40.506629 EDT | MaxEsReturn               578.815
2017-06-10 22:26:40.506977 EDT | MinEsReturn                93.3179
2017-06-10 22:26:40.507312 EDT | AverageDiscountedReturn   215.218
2017-06-10 22:26:40.507699 EDT | AverageQLoss                2.64474
2017-06-10 22:26:40.508021 EDT | AveragePolicySurr         -32.0068
2017-06-10 22:26:40.508398 EDT | AverageQ                   31.5025
2017-06-10 22:26:40.508619 EDT | AverageAbsQ                31.5439
2017-06-10 22:26:40.508949 EDT | AverageY                   31.5045
2017-06-10 22:26:40.509445 EDT | AverageAbsY                31.5307
2017-06-10 22:26:40.509613 EDT | AverageAbsQYDiff            0.657137
2017-06-10 22:26:40.510425 EDT | AverageAction               0.918071
2017-06-10 22:26:40.510757 EDT | PolicyRegParamNorm         69.6751
2017-06-10 22:26:40.511134 EDT | QFunRegParamNorm           87.7908
2017-06-10 22:26:40.511485 EDT | -----------------------  -----------
2017-06-10 22:26:40.512126 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #422 | Training started
2017-06-10 22:26:55.208856 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #422 | Training finished
2017-06-10 22:26:55.209855 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #422 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 22:26:55.210261 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #422 | Collecting samples for evaluation
2017-06-10 22:27:08.496756 EDT | -----------------------  -----------
2017-06-10 22:27:08.497774 EDT | Epoch                     422
2017-06-10 22:27:08.498401 EDT | Iteration                 422
2017-06-10 22:27:08.502154 EDT | AverageReturn            1336.02
2017-06-10 22:27:08.502637 EDT | StdReturn                 553.619
2017-06-10 22:27:08.503132 EDT | MaxReturn                3070.92
2017-06-10 22:27:08.503583 EDT | MinReturn                 531.915
2017-06-10 22:27:08.504029 EDT | AverageEsReturn           376.444
2017-06-10 22:27:08.504438 EDT | StdEsReturn               293.317
2017-06-10 22:27:08.508162 EDT | MaxEsReturn               952.603
2017-06-10 22:27:08.508785 EDT | MinEsReturn                74.7376
2017-06-10 22:27:08.509189 EDT | AverageDiscountedReturn   229.162
2017-06-10 22:27:08.509535 EDT | AverageQLoss                2.42804
2017-06-10 22:27:08.510053 EDT | AveragePolicySurr         -32.0163
2017-06-10 22:27:08.510462 EDT | AverageQ                   31.5521
2017-06-10 22:27:08.510809 EDT | AverageAbsQ                31.5903
2017-06-10 22:27:08.511150 EDT | AverageY                   31.5527
2017-06-10 22:27:08.511633 EDT | AverageAbsY                31.574
2017-06-10 22:27:08.512111 EDT | AverageAbsQYDiff            0.629717
2017-06-10 22:27:08.512552 EDT | AverageAction               0.918595
2017-06-10 22:27:08.513035 EDT | PolicyRegParamNorm         69.7776
2017-06-10 22:27:08.514196 EDT | QFunRegParamNorm           87.8711
2017-06-10 22:27:08.514564 EDT | -----------------------  -----------
2017-06-10 22:27:08.517814 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #423 | Training started
2017-06-10 22:27:23.937938 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #423 | Training finished
2017-06-10 22:27:23.938831 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #423 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 22:27:23.939023 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #423 | Collecting samples for evaluation
2017-06-10 22:27:36.118147 EDT | -----------------------  -----------
2017-06-10 22:27:36.143154 EDT | Epoch                     423
2017-06-10 22:27:36.143883 EDT | Iteration                 423
2017-06-10 22:27:36.144191 EDT | AverageReturn             869.204
2017-06-10 22:27:36.144493 EDT | StdReturn                 280.491
2017-06-10 22:27:36.148857 EDT | MaxReturn                1297.39
2017-06-10 22:27:36.151288 EDT | MinReturn                 340.449
2017-06-10 22:27:36.151597 EDT | AverageEsReturn           328.148
2017-06-10 22:27:36.154290 EDT | StdEsReturn               191.009
2017-06-10 22:27:36.154600 EDT | MaxEsReturn               568.926
2017-06-10 22:27:36.154897 EDT | MinEsReturn                95.3366
2017-06-10 22:27:36.155195 EDT | AverageDiscountedReturn   223.167
2017-06-10 22:27:36.157999 EDT | AverageQLoss                3.01264
2017-06-10 22:27:36.158298 EDT | AveragePolicySurr         -31.8779
2017-06-10 22:27:36.158593 EDT | AverageQ                   31.4103
2017-06-10 22:27:36.158887 EDT | AverageAbsQ                31.4467
2017-06-10 22:27:36.159180 EDT | AverageY                   31.4093
2017-06-10 22:27:36.159473 EDT | AverageAbsY                31.429
2017-06-10 22:27:36.159766 EDT | AverageAbsQYDiff            0.673236
2017-06-10 22:27:36.164221 EDT | AverageAction               0.914825
2017-06-10 22:27:36.164534 EDT | PolicyRegParamNorm         69.7766
2017-06-10 22:27:36.164817 EDT | QFunRegParamNorm           87.951
2017-06-10 22:27:36.165102 EDT | -----------------------  -----------
2017-06-10 22:27:36.165566 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #424 | Training started
2017-06-10 22:27:51.913565 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #424 | Training finished
2017-06-10 22:27:51.914047 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #424 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 22:27:51.914806 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #424 | Collecting samples for evaluation
2017-06-10 22:28:04.936135 EDT | -----------------------  -----------
2017-06-10 22:28:04.937336 EDT | Epoch                     424
2017-06-10 22:28:04.937639 EDT | Iteration                 424
2017-06-10 22:28:04.943395 EDT | AverageReturn             984.22
2017-06-10 22:28:04.943741 EDT | StdReturn                 214.104
2017-06-10 22:28:04.944073 EDT | MaxReturn                1760.15
2017-06-10 22:28:04.945821 EDT | MinReturn                 660.396
2017-06-10 22:28:04.946431 EDT | AverageEsReturn           226.958
2017-06-10 22:28:04.948084 EDT | StdEsReturn               109.329
2017-06-10 22:28:04.949975 EDT | MaxEsReturn               437.888
2017-06-10 22:28:04.950283 EDT | MinEsReturn                70.0839
2017-06-10 22:28:04.951949 EDT | AverageDiscountedReturn   223.328
2017-06-10 22:28:04.952271 EDT | AverageQLoss                3.05685
2017-06-10 22:28:04.952683 EDT | AveragePolicySurr         -32.0004
2017-06-10 22:28:04.953252 EDT | AverageQ                   31.5209
2017-06-10 22:28:04.953805 EDT | AverageAbsQ                31.5509
2017-06-10 22:28:04.954875 EDT | AverageY                   31.5232
2017-06-10 22:28:04.956188 EDT | AverageAbsY                31.5356
2017-06-10 22:28:04.956826 EDT | AverageAbsQYDiff            0.673083
2017-06-10 22:28:04.958446 EDT | AverageAction               0.900014
2017-06-10 22:28:04.959132 EDT | PolicyRegParamNorm         69.8393
2017-06-10 22:28:04.960612 EDT | QFunRegParamNorm           88.0149
2017-06-10 22:28:04.961270 EDT | -----------------------  -----------
2017-06-10 22:28:04.963590 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #425 | Training started
2017-06-10 22:28:20.751928 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #425 | Training finished
2017-06-10 22:28:20.752683 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #425 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 22:28:20.752888 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #425 | Collecting samples for evaluation
2017-06-10 22:28:34.285457 EDT | -----------------------  -----------
2017-06-10 22:28:34.286395 EDT | Epoch                     425
2017-06-10 22:28:34.286750 EDT | Iteration                 425
2017-06-10 22:28:34.287069 EDT | AverageReturn             905.294
2017-06-10 22:28:34.287377 EDT | StdReturn                 366.064
2017-06-10 22:28:34.287798 EDT | MaxReturn                1917.08
2017-06-10 22:28:34.287959 EDT | MinReturn                 427.039
2017-06-10 22:28:34.288113 EDT | AverageEsReturn           259.067
2017-06-10 22:28:34.288264 EDT | StdEsReturn               176.867
2017-06-10 22:28:34.288415 EDT | MaxEsReturn               616.417
2017-06-10 22:28:34.288565 EDT | MinEsReturn                58.8348
2017-06-10 22:28:34.289299 EDT | AverageDiscountedReturn   225.618
2017-06-10 22:28:34.289568 EDT | AverageQLoss                2.82151
2017-06-10 22:28:34.289773 EDT | AveragePolicySurr         -31.9399
2017-06-10 22:28:34.290095 EDT | AverageQ                   31.473
2017-06-10 22:28:34.290408 EDT | AverageAbsQ                31.5033
2017-06-10 22:28:34.290720 EDT | AverageY                   31.4746
2017-06-10 22:28:34.291033 EDT | AverageAbsY                31.4894
2017-06-10 22:28:34.291505 EDT | AverageAbsQYDiff            0.644519
2017-06-10 22:28:34.291801 EDT | AverageAction               0.890961
2017-06-10 22:28:34.292183 EDT | PolicyRegParamNorm         69.8573
2017-06-10 22:28:34.292483 EDT | QFunRegParamNorm           88.092
2017-06-10 22:28:34.292781 EDT | -----------------------  -----------
2017-06-10 22:28:34.293232 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #426 | Training started
2017-06-10 22:28:49.119078 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #426 | Training finished
2017-06-10 22:28:49.120009 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #426 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 22:28:49.120220 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #426 | Collecting samples for evaluation
2017-06-10 22:29:02.351542 EDT | -----------------------  -----------
2017-06-10 22:29:02.352655 EDT | Epoch                     426
2017-06-10 22:29:02.353000 EDT | Iteration                 426
2017-06-10 22:29:02.353166 EDT | AverageReturn            1234.34
2017-06-10 22:29:02.353411 EDT | StdReturn                 294.22
2017-06-10 22:29:02.353745 EDT | MaxReturn                2025.66
2017-06-10 22:29:02.354096 EDT | MinReturn                 845.368
2017-06-10 22:29:02.354418 EDT | AverageEsReturn           592.786
2017-06-10 22:29:02.354747 EDT | StdEsReturn               222.886
2017-06-10 22:29:02.355021 EDT | MaxEsReturn               800.058
2017-06-10 22:29:02.355217 EDT | MinEsReturn               195.37
2017-06-10 22:29:02.355399 EDT | AverageDiscountedReturn   224.883
2017-06-10 22:29:02.355698 EDT | AverageQLoss                2.87316
2017-06-10 22:29:02.356014 EDT | AveragePolicySurr         -31.9069
2017-06-10 22:29:02.356196 EDT | AverageQ                   31.4213
2017-06-10 22:29:02.356382 EDT | AverageAbsQ                31.4522
2017-06-10 22:29:02.356561 EDT | AverageY                   31.4232
2017-06-10 22:29:02.356862 EDT | AverageAbsY                31.4387
2017-06-10 22:29:02.357183 EDT | AverageAbsQYDiff            0.668283
2017-06-10 22:29:02.357475 EDT | AverageAction               0.909386
2017-06-10 22:29:02.357749 EDT | PolicyRegParamNorm         69.8948
2017-06-10 22:29:02.357921 EDT | QFunRegParamNorm           88.1682
2017-06-10 22:29:02.358199 EDT | -----------------------  -----------
2017-06-10 22:29:02.359933 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #427 | Training started
2017-06-10 22:29:16.770594 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #427 | Training finished
2017-06-10 22:29:16.771596 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #427 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 22:29:16.771975 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #427 | Collecting samples for evaluation
2017-06-10 22:29:29.268790 EDT | -----------------------  -----------
2017-06-10 22:29:29.269872 EDT | Epoch                     427
2017-06-10 22:29:29.270300 EDT | Iteration                 427
2017-06-10 22:29:29.270690 EDT | AverageReturn            1312.78
2017-06-10 22:29:29.271121 EDT | StdReturn                 463.966
2017-06-10 22:29:29.271551 EDT | MaxReturn                2550.14
2017-06-10 22:29:29.271959 EDT | MinReturn                 387.842
2017-06-10 22:29:29.272329 EDT | AverageEsReturn           229.239
2017-06-10 22:29:29.272741 EDT | StdEsReturn               139.534
2017-06-10 22:29:29.273103 EDT | MaxEsReturn               524.38
2017-06-10 22:29:29.273419 EDT | MinEsReturn                63.6094
2017-06-10 22:29:29.273838 EDT | AverageDiscountedReturn   238.354
2017-06-10 22:29:29.274227 EDT | AverageQLoss                2.56175
2017-06-10 22:29:29.274528 EDT | AveragePolicySurr         -32.0479
2017-06-10 22:29:29.274825 EDT | AverageQ                   31.5582
2017-06-10 22:29:29.275144 EDT | AverageAbsQ                31.5868
2017-06-10 22:29:29.275521 EDT | AverageY                   31.5591
2017-06-10 22:29:29.275946 EDT | AverageAbsY                31.572
2017-06-10 22:29:29.276190 EDT | AverageAbsQYDiff            0.638784
2017-06-10 22:29:29.276377 EDT | AverageAction               0.905818
2017-06-10 22:29:29.276558 EDT | PolicyRegParamNorm         69.9277
2017-06-10 22:29:29.276801 EDT | QFunRegParamNorm           88.2489
2017-06-10 22:29:29.277041 EDT | -----------------------  -----------
2017-06-10 22:29:29.277533 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #428 | Training started
2017-06-10 22:29:44.315719 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #428 | Training finished
2017-06-10 22:29:44.316879 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #428 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 22:29:44.317288 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #428 | Collecting samples for evaluation
2017-06-10 22:29:56.500715 EDT | -----------------------  -----------
2017-06-10 22:29:56.501863 EDT | Epoch                     428
2017-06-10 22:29:56.502441 EDT | Iteration                 428
2017-06-10 22:29:56.503000 EDT | AverageReturn            1165.87
2017-06-10 22:29:56.503559 EDT | StdReturn                 206.635
2017-06-10 22:29:56.504386 EDT | MaxReturn                1696.98
2017-06-10 22:29:56.505184 EDT | MinReturn                 745.254
2017-06-10 22:29:56.505771 EDT | AverageEsReturn           251.505
2017-06-10 22:29:56.506609 EDT | StdEsReturn               240.497
2017-06-10 22:29:56.506998 EDT | MaxEsReturn               646.223
2017-06-10 22:29:56.507369 EDT | MinEsReturn                57.2673
2017-06-10 22:29:56.507739 EDT | AverageDiscountedReturn   227.808
2017-06-10 22:29:56.508106 EDT | AverageQLoss                2.39635
2017-06-10 22:29:56.508472 EDT | AveragePolicySurr         -31.8602
2017-06-10 22:29:56.508838 EDT | AverageQ                   31.4022
2017-06-10 22:29:56.509203 EDT | AverageAbsQ                31.4347
2017-06-10 22:29:56.509570 EDT | AverageY                   31.4028
2017-06-10 22:29:56.509948 EDT | AverageAbsY                31.4214
2017-06-10 22:29:56.510314 EDT | AverageAbsQYDiff            0.63934
2017-06-10 22:29:56.510679 EDT | AverageAction               0.906985
2017-06-10 22:29:56.511055 EDT | PolicyRegParamNorm         69.9865
2017-06-10 22:29:56.511418 EDT | QFunRegParamNorm           88.3277
2017-06-10 22:29:56.511782 EDT | -----------------------  -----------
2017-06-10 22:29:56.512309 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #429 | Training started
2017-06-10 22:30:12.296784 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #429 | Training finished
2017-06-10 22:30:12.298259 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #429 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 22:30:12.298472 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #429 | Collecting samples for evaluation
2017-06-10 22:30:25.647498 EDT | -----------------------  -----------
2017-06-10 22:30:25.648480 EDT | Epoch                     429
2017-06-10 22:30:25.648862 EDT | Iteration                 429
2017-06-10 22:30:25.649213 EDT | AverageReturn            1715.01
2017-06-10 22:30:25.649575 EDT | StdReturn                 922.994
2017-06-10 22:30:25.649965 EDT | MaxReturn                3144.56
2017-06-10 22:30:25.650392 EDT | MinReturn                 298.589
2017-06-10 22:30:25.650811 EDT | AverageEsReturn           377.755
2017-06-10 22:30:25.651152 EDT | StdEsReturn               216.238
2017-06-10 22:30:25.651487 EDT | MaxEsReturn               818.4
2017-06-10 22:30:25.651827 EDT | MinEsReturn               186.244
2017-06-10 22:30:25.652153 EDT | AverageDiscountedReturn   230.16
2017-06-10 22:30:25.652478 EDT | AverageQLoss                3.18777
2017-06-10 22:30:25.652845 EDT | AveragePolicySurr         -31.8973
2017-06-10 22:30:25.653229 EDT | AverageQ                   31.4461
2017-06-10 22:30:25.657798 EDT | AverageAbsQ                31.4842
2017-06-10 22:30:25.658166 EDT | AverageY                   31.4491
2017-06-10 22:30:25.658511 EDT | AverageAbsY                31.468
2017-06-10 22:30:25.658877 EDT | AverageAbsQYDiff            0.687069
2017-06-10 22:30:25.659322 EDT | AverageAction               0.8908
2017-06-10 22:30:25.659764 EDT | PolicyRegParamNorm         70.026
2017-06-10 22:30:25.660206 EDT | QFunRegParamNorm           88.3982
2017-06-10 22:30:25.660649 EDT | -----------------------  -----------
2017-06-10 22:30:25.661221 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #430 | Training started
2017-06-10 22:30:41.973564 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #430 | Training finished
2017-06-10 22:30:41.974324 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #430 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 22:30:41.974620 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #430 | Collecting samples for evaluation
2017-06-10 22:30:54.334052 EDT | -----------------------  -----------
2017-06-10 22:30:54.334772 EDT | Epoch                     430
2017-06-10 22:30:54.334949 EDT | Iteration                 430
2017-06-10 22:30:54.335107 EDT | AverageReturn            1592.42
2017-06-10 22:30:54.335263 EDT | StdReturn                 635.049
2017-06-10 22:30:54.335415 EDT | MaxReturn                2967.82
2017-06-10 22:30:54.335565 EDT | MinReturn                 866.056
2017-06-10 22:30:54.335714 EDT | AverageEsReturn           342.454
2017-06-10 22:30:54.335876 EDT | StdEsReturn               341.131
2017-06-10 22:30:54.336026 EDT | MaxEsReturn               897.923
2017-06-10 22:30:54.336176 EDT | MinEsReturn                50.7925
2017-06-10 22:30:54.336324 EDT | AverageDiscountedReturn   232.923
2017-06-10 22:30:54.336474 EDT | AverageQLoss                2.41115
2017-06-10 22:30:54.336622 EDT | AveragePolicySurr         -31.9984
2017-06-10 22:30:54.336949 EDT | AverageQ                   31.514
2017-06-10 22:30:54.337150 EDT | AverageAbsQ                31.5506
2017-06-10 22:30:54.337318 EDT | AverageY                   31.5165
2017-06-10 22:30:54.337576 EDT | AverageAbsY                31.5398
2017-06-10 22:30:54.337763 EDT | AverageAbsQYDiff            0.635653
2017-06-10 22:30:54.337922 EDT | AverageAction               0.859239
2017-06-10 22:30:54.338076 EDT | PolicyRegParamNorm         70.1267
2017-06-10 22:30:54.338270 EDT | QFunRegParamNorm           88.4672
2017-06-10 22:30:54.338420 EDT | -----------------------  -----------
2017-06-10 22:30:54.338656 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #431 | Training started
2017-06-10 22:31:10.374511 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #431 | Training finished
2017-06-10 22:31:10.375514 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #431 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 22:31:10.375912 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #431 | Collecting samples for evaluation
2017-06-10 22:31:23.608908 EDT | -----------------------  -----------
2017-06-10 22:31:23.609665 EDT | Epoch                     431
2017-06-10 22:31:23.609897 EDT | Iteration                 431
2017-06-10 22:31:23.610104 EDT | AverageReturn            1878.82
2017-06-10 22:31:23.610428 EDT | StdReturn                 702.817
2017-06-10 22:31:23.610768 EDT | MaxReturn                2846.15
2017-06-10 22:31:23.611115 EDT | MinReturn                 798.472
2017-06-10 22:31:23.611399 EDT | AverageEsReturn           336.409
2017-06-10 22:31:23.611566 EDT | StdEsReturn               370.978
2017-06-10 22:31:23.611728 EDT | MaxEsReturn              1048.91
2017-06-10 22:31:23.611937 EDT | MinEsReturn                12.5697
2017-06-10 22:31:23.612156 EDT | AverageDiscountedReturn   235.973
2017-06-10 22:31:23.612329 EDT | AverageQLoss                2.86148
2017-06-10 22:31:23.612499 EDT | AveragePolicySurr         -31.9077
2017-06-10 22:31:23.612746 EDT | AverageQ                   31.4369
2017-06-10 22:31:23.612933 EDT | AverageAbsQ                31.4685
2017-06-10 22:31:23.613435 EDT | AverageY                   31.4378
2017-06-10 22:31:23.613627 EDT | AverageAbsY                31.4543
2017-06-10 22:31:23.613844 EDT | AverageAbsQYDiff            0.65524
2017-06-10 22:31:23.614274 EDT | AverageAction               0.874598
2017-06-10 22:31:23.614561 EDT | PolicyRegParamNorm         70.2162
2017-06-10 22:31:23.614956 EDT | QFunRegParamNorm           88.5299
2017-06-10 22:31:23.617108 EDT | -----------------------  -----------
2017-06-10 22:31:23.617479 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #432 | Training started
2017-06-10 22:31:38.809679 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #432 | Training finished
2017-06-10 22:31:38.810520 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #432 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 22:31:38.810726 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #432 | Collecting samples for evaluation
2017-06-10 22:31:51.444911 EDT | -----------------------  -----------
2017-06-10 22:31:51.445923 EDT | Epoch                     432
2017-06-10 22:31:51.446384 EDT | Iteration                 432
2017-06-10 22:31:51.446768 EDT | AverageReturn            1176.73
2017-06-10 22:31:51.447153 EDT | StdReturn                 376.896
2017-06-10 22:31:51.447610 EDT | MaxReturn                2371.48
2017-06-10 22:31:51.448252 EDT | MinReturn                 654.65
2017-06-10 22:31:51.448636 EDT | AverageEsReturn           494.149
2017-06-10 22:31:51.449013 EDT | StdEsReturn               364.283
2017-06-10 22:31:51.449381 EDT | MaxEsReturn               961.624
2017-06-10 22:31:51.449778 EDT | MinEsReturn                72.6758
2017-06-10 22:31:51.450248 EDT | AverageDiscountedReturn   224.448
2017-06-10 22:31:51.450887 EDT | AverageQLoss                2.83114
2017-06-10 22:31:51.451589 EDT | AveragePolicySurr         -31.9451
2017-06-10 22:31:51.452390 EDT | AverageQ                   31.4648
2017-06-10 22:31:51.453158 EDT | AverageAbsQ                31.5009
2017-06-10 22:31:51.453901 EDT | AverageY                   31.4643
2017-06-10 22:31:51.454621 EDT | AverageAbsY                31.4824
2017-06-10 22:31:51.455440 EDT | AverageAbsQYDiff            0.664651
2017-06-10 22:31:51.456308 EDT | AverageAction               0.882415
2017-06-10 22:31:51.457206 EDT | PolicyRegParamNorm         70.2549
2017-06-10 22:31:51.458510 EDT | QFunRegParamNorm           88.6193
2017-06-10 22:31:51.459436 EDT | -----------------------  -----------
2017-06-10 22:31:51.460496 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #433 | Training started
2017-06-10 22:32:07.576303 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #433 | Training finished
2017-06-10 22:32:07.580469 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #433 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 22:32:07.580794 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #433 | Collecting samples for evaluation
2017-06-10 22:32:19.675668 EDT | -----------------------  -----------
2017-06-10 22:32:19.676175 EDT | Epoch                     433
2017-06-10 22:32:19.676534 EDT | Iteration                 433
2017-06-10 22:32:19.676881 EDT | AverageReturn            1673.06
2017-06-10 22:32:19.677280 EDT | StdReturn                 775.065
2017-06-10 22:32:19.677625 EDT | MaxReturn                2677.14
2017-06-10 22:32:19.677986 EDT | MinReturn                  83.1062
2017-06-10 22:32:19.678318 EDT | AverageEsReturn           454.793
2017-06-10 22:32:19.678651 EDT | StdEsReturn               463.019
2017-06-10 22:32:19.678978 EDT | MaxEsReturn              1324.79
2017-06-10 22:32:19.679305 EDT | MinEsReturn                 7.081
2017-06-10 22:32:19.679633 EDT | AverageDiscountedReturn   208.75
2017-06-10 22:32:19.679960 EDT | AverageQLoss                2.73625
2017-06-10 22:32:19.680286 EDT | AveragePolicySurr         -32.0297
2017-06-10 22:32:19.680613 EDT | AverageQ                   31.5584
2017-06-10 22:32:19.680939 EDT | AverageAbsQ                31.5908
2017-06-10 22:32:19.681265 EDT | AverageY                   31.5596
2017-06-10 22:32:19.681590 EDT | AverageAbsY                31.5738
2017-06-10 22:32:19.681930 EDT | AverageAbsQYDiff            0.659092
2017-06-10 22:32:19.682259 EDT | AverageAction               0.858527
2017-06-10 22:32:19.682587 EDT | PolicyRegParamNorm         70.2571
2017-06-10 22:32:19.682913 EDT | QFunRegParamNorm           88.7217
2017-06-10 22:32:19.683240 EDT | -----------------------  -----------
2017-06-10 22:32:19.683711 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #434 | Training started
2017-06-10 22:32:36.134171 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #434 | Training finished
2017-06-10 22:32:36.135847 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #434 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 22:32:36.136163 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #434 | Collecting samples for evaluation
2017-06-10 22:32:48.492401 EDT | -----------------------  -----------
2017-06-10 22:32:48.492820 EDT | Epoch                     434
2017-06-10 22:32:48.493173 EDT | Iteration                 434
2017-06-10 22:32:48.493520 EDT | AverageReturn            1017.56
2017-06-10 22:32:48.493878 EDT | StdReturn                 251.252
2017-06-10 22:32:48.494224 EDT | MaxReturn                1729.16
2017-06-10 22:32:48.494570 EDT | MinReturn                 705.232
2017-06-10 22:32:48.494913 EDT | AverageEsReturn           633.636
2017-06-10 22:32:48.495256 EDT | StdEsReturn               552.389
2017-06-10 22:32:48.495598 EDT | MaxEsReturn              1524.05
2017-06-10 22:32:48.495935 EDT | MinEsReturn                27.3663
2017-06-10 22:32:48.496275 EDT | AverageDiscountedReturn   242.017
2017-06-10 22:32:48.496617 EDT | AverageQLoss                2.77933
2017-06-10 22:32:48.496956 EDT | AveragePolicySurr         -31.9969
2017-06-10 22:32:48.497296 EDT | AverageQ                   31.5252
2017-06-10 22:32:48.497642 EDT | AverageAbsQ                31.5625
2017-06-10 22:32:48.532208 EDT | AverageY                   31.5272
2017-06-10 22:32:48.532560 EDT | AverageAbsY                31.5446
2017-06-10 22:32:48.532904 EDT | AverageAbsQYDiff            0.659537
2017-06-10 22:32:48.533245 EDT | AverageAction               0.887016
2017-06-10 22:32:48.533591 EDT | PolicyRegParamNorm         70.3637
2017-06-10 22:32:48.533944 EDT | QFunRegParamNorm           88.7953
2017-06-10 22:32:48.534285 EDT | -----------------------  -----------
2017-06-10 22:32:48.534803 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #435 | Training started
2017-06-10 22:33:03.423576 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #435 | Training finished
2017-06-10 22:33:03.425710 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #435 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 22:33:03.426133 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #435 | Collecting samples for evaluation
2017-06-10 22:33:16.816416 EDT | -----------------------  -----------
2017-06-10 22:33:16.817787 EDT | Epoch                     435
2017-06-10 22:33:16.818139 EDT | Iteration                 435
2017-06-10 22:33:16.818446 EDT | AverageReturn            1212.1
2017-06-10 22:33:16.818712 EDT | StdReturn                 422.908
2017-06-10 22:33:16.819038 EDT | MaxReturn                2646.52
2017-06-10 22:33:16.821260 EDT | MinReturn                 695.85
2017-06-10 22:33:16.821612 EDT | AverageEsReturn           388.116
2017-06-10 22:33:16.821946 EDT | StdEsReturn               243.059
2017-06-10 22:33:16.822265 EDT | MaxEsReturn               803.382
2017-06-10 22:33:16.822596 EDT | MinEsReturn               205.891
2017-06-10 22:33:16.822920 EDT | AverageDiscountedReturn   238.695
2017-06-10 22:33:16.824475 EDT | AverageQLoss                2.6127
2017-06-10 22:33:16.825030 EDT | AveragePolicySurr         -32.1023
2017-06-10 22:33:16.825290 EDT | AverageQ                   31.6315
2017-06-10 22:33:16.825613 EDT | AverageAbsQ                31.6652
2017-06-10 22:33:16.825908 EDT | AverageY                   31.6337
2017-06-10 22:33:16.826225 EDT | AverageAbsY                31.654
2017-06-10 22:33:16.826553 EDT | AverageAbsQYDiff            0.642471
2017-06-10 22:33:16.826876 EDT | AverageAction               0.912638
2017-06-10 22:33:16.827195 EDT | PolicyRegParamNorm         70.4423
2017-06-10 22:33:16.827601 EDT | QFunRegParamNorm           88.8978
2017-06-10 22:33:16.827924 EDT | -----------------------  -----------
2017-06-10 22:33:16.828391 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #436 | Training started
2017-06-10 22:33:32.538907 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #436 | Training finished
2017-06-10 22:33:32.539636 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #436 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 22:33:32.539821 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #436 | Collecting samples for evaluation
2017-06-10 22:33:45.318417 EDT | -----------------------  -----------
2017-06-10 22:33:45.320247 EDT | Epoch                     436
2017-06-10 22:33:45.320738 EDT | Iteration                 436
2017-06-10 22:33:45.321133 EDT | AverageReturn            1028.34
2017-06-10 22:33:45.321604 EDT | StdReturn                 151.995
2017-06-10 22:33:45.321969 EDT | MaxReturn                1587.26
2017-06-10 22:33:45.322326 EDT | MinReturn                 806.952
2017-06-10 22:33:45.322663 EDT | AverageEsReturn           673.574
2017-06-10 22:33:45.324223 EDT | StdEsReturn               502.685
2017-06-10 22:33:45.324427 EDT | MaxEsReturn              1342.95
2017-06-10 22:33:45.324682 EDT | MinEsReturn                79.9942
2017-06-10 22:33:45.324872 EDT | AverageDiscountedReturn   230.488
2017-06-10 22:33:45.325117 EDT | AverageQLoss                2.79234
2017-06-10 22:33:45.325301 EDT | AveragePolicySurr         -32.034
2017-06-10 22:33:45.325484 EDT | AverageQ                   31.5499
2017-06-10 22:33:45.325664 EDT | AverageAbsQ                31.5866
2017-06-10 22:33:45.325863 EDT | AverageY                   31.5498
2017-06-10 22:33:45.326195 EDT | AverageAbsY                31.5705
2017-06-10 22:33:45.326465 EDT | AverageAbsQYDiff            0.645267
2017-06-10 22:33:45.326649 EDT | AverageAction               0.887078
2017-06-10 22:33:45.326829 EDT | PolicyRegParamNorm         70.5206
2017-06-10 22:33:45.327008 EDT | QFunRegParamNorm           88.9468
2017-06-10 22:33:45.327380 EDT | -----------------------  -----------
2017-06-10 22:33:45.327686 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #437 | Training started
2017-06-10 22:34:01.232849 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #437 | Training finished
2017-06-10 22:34:01.233967 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #437 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 22:34:01.234500 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #437 | Collecting samples for evaluation
2017-06-10 22:34:13.260360 EDT | -----------------------  -----------
2017-06-10 22:34:13.263010 EDT | Epoch                     437
2017-06-10 22:34:13.263308 EDT | Iteration                 437
2017-06-10 22:34:13.263591 EDT | AverageReturn            2129.87
2017-06-10 22:34:13.263852 EDT | StdReturn                 698.611
2017-06-10 22:34:13.264135 EDT | MaxReturn                2784.49
2017-06-10 22:34:13.264400 EDT | MinReturn                 825.93
2017-06-10 22:34:13.264655 EDT | AverageEsReturn           470.311
2017-06-10 22:34:13.264908 EDT | StdEsReturn               290.579
2017-06-10 22:34:13.265186 EDT | MaxEsReturn               906.795
2017-06-10 22:34:13.265448 EDT | MinEsReturn                49.1197
2017-06-10 22:34:13.265714 EDT | AverageDiscountedReturn   230.454
2017-06-10 22:34:13.265998 EDT | AverageQLoss                2.33861
2017-06-10 22:34:13.266253 EDT | AveragePolicySurr         -32.0043
2017-06-10 22:34:13.266514 EDT | AverageQ                   31.5253
2017-06-10 22:34:13.266768 EDT | AverageAbsQ                31.5532
2017-06-10 22:34:13.267026 EDT | AverageY                   31.5278
2017-06-10 22:34:13.267304 EDT | AverageAbsY                31.5418
2017-06-10 22:34:13.267562 EDT | AverageAbsQYDiff            0.624663
2017-06-10 22:34:13.267808 EDT | AverageAction               0.930183
2017-06-10 22:34:13.268068 EDT | PolicyRegParamNorm         70.6225
2017-06-10 22:34:13.268324 EDT | QFunRegParamNorm           89.0624
2017-06-10 22:34:13.268581 EDT | -----------------------  -----------
2017-06-10 22:34:13.268948 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #438 | Training started
2017-06-10 22:34:29.146534 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #438 | Training finished
2017-06-10 22:34:29.147433 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #438 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 22:34:29.147654 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #438 | Collecting samples for evaluation
2017-06-10 22:34:42.174795 EDT | -----------------------  -----------
2017-06-10 22:34:42.175330 EDT | Epoch                     438
2017-06-10 22:34:42.175669 EDT | Iteration                 438
2017-06-10 22:34:42.176104 EDT | AverageReturn            1391.09
2017-06-10 22:34:42.176452 EDT | StdReturn                 506.98
2017-06-10 22:34:42.176874 EDT | MaxReturn                2841.43
2017-06-10 22:34:42.177656 EDT | MinReturn                 909.196
2017-06-10 22:34:42.178108 EDT | AverageEsReturn           461.567
2017-06-10 22:34:42.178448 EDT | StdEsReturn               313.461
2017-06-10 22:34:42.178774 EDT | MaxEsReturn              1052.13
2017-06-10 22:34:42.179105 EDT | MinEsReturn               127.96
2017-06-10 22:34:42.179428 EDT | AverageDiscountedReturn   223.979
2017-06-10 22:34:42.179725 EDT | AverageQLoss                2.79932
2017-06-10 22:34:42.180056 EDT | AveragePolicySurr         -32.1143
2017-06-10 22:34:42.180388 EDT | AverageQ                   31.6626
2017-06-10 22:34:42.180645 EDT | AverageAbsQ                31.6906
2017-06-10 22:34:42.180827 EDT | AverageY                   31.6642
2017-06-10 22:34:42.180987 EDT | AverageAbsY                31.6779
2017-06-10 22:34:42.181143 EDT | AverageAbsQYDiff            0.646371
2017-06-10 22:34:42.181298 EDT | AverageAction               0.899787
2017-06-10 22:34:42.181460 EDT | PolicyRegParamNorm         70.6847
2017-06-10 22:34:42.181681 EDT | QFunRegParamNorm           89.1487
2017-06-10 22:34:42.182090 EDT | -----------------------  -----------
2017-06-10 22:34:42.182473 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #439 | Training started
2017-06-10 22:34:55.974673 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #439 | Training finished
2017-06-10 22:34:55.975780 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #439 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 22:34:55.976203 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #439 | Collecting samples for evaluation
2017-06-10 22:35:08.549228 EDT | -----------------------  -----------
2017-06-10 22:35:08.550180 EDT | Epoch                     439
2017-06-10 22:35:08.550533 EDT | Iteration                 439
2017-06-10 22:35:08.550871 EDT | AverageReturn             552.482
2017-06-10 22:35:08.551206 EDT | StdReturn                 290.984
2017-06-10 22:35:08.551540 EDT | MaxReturn                1452.26
2017-06-10 22:35:08.551873 EDT | MinReturn                 218.853
2017-06-10 22:35:08.552203 EDT | AverageEsReturn           429.537
2017-06-10 22:35:08.552532 EDT | StdEsReturn               243.688
2017-06-10 22:35:08.552862 EDT | MaxEsReturn               719.931
2017-06-10 22:35:08.553190 EDT | MinEsReturn               167.91
2017-06-10 22:35:08.553636 EDT | AverageDiscountedReturn   190.682
2017-06-10 22:35:08.554250 EDT | AverageQLoss                2.90374
2017-06-10 22:35:08.554847 EDT | AveragePolicySurr         -32.0164
2017-06-10 22:35:08.555441 EDT | AverageQ                   31.5107
2017-06-10 22:35:08.556035 EDT | AverageAbsQ                31.548
2017-06-10 22:35:08.556624 EDT | AverageY                   31.5146
2017-06-10 22:35:08.557216 EDT | AverageAbsY                31.5313
2017-06-10 22:35:08.557814 EDT | AverageAbsQYDiff            0.669738
2017-06-10 22:35:08.558411 EDT | AverageAction               0.914569
2017-06-10 22:35:08.559006 EDT | PolicyRegParamNorm         70.7288
2017-06-10 22:35:08.559597 EDT | QFunRegParamNorm           89.2873
2017-06-10 22:35:08.560186 EDT | -----------------------  -----------
2017-06-10 22:35:08.560923 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #440 | Training started
2017-06-10 22:35:23.413445 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #440 | Training finished
2017-06-10 22:35:23.414242 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #440 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 22:35:23.414485 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #440 | Collecting samples for evaluation
2017-06-10 22:35:36.490364 EDT | -----------------------  -----------
2017-06-10 22:35:36.492277 EDT | Epoch                     440
2017-06-10 22:35:36.492591 EDT | Iteration                 440
2017-06-10 22:35:36.492919 EDT | AverageReturn            2170.66
2017-06-10 22:35:36.493191 EDT | StdReturn                 877.451
2017-06-10 22:35:36.493508 EDT | MaxReturn                3129.71
2017-06-10 22:35:36.494684 EDT | MinReturn                 725.989
2017-06-10 22:35:36.494983 EDT | AverageEsReturn           461.249
2017-06-10 22:35:36.495302 EDT | StdEsReturn               333.549
2017-06-10 22:35:36.495625 EDT | MaxEsReturn              1096.69
2017-06-10 22:35:36.496139 EDT | MinEsReturn               120.384
2017-06-10 22:35:36.496478 EDT | AverageDiscountedReturn   235.943
2017-06-10 22:35:36.496795 EDT | AverageQLoss                2.56392
2017-06-10 22:35:36.497114 EDT | AveragePolicySurr         -32.0113
2017-06-10 22:35:36.497453 EDT | AverageQ                   31.5184
2017-06-10 22:35:36.497621 EDT | AverageAbsQ                31.549
2017-06-10 22:35:36.497876 EDT | AverageY                   31.5191
2017-06-10 22:35:36.498711 EDT | AverageAbsY                31.5347
2017-06-10 22:35:36.499020 EDT | AverageAbsQYDiff            0.630346
2017-06-10 22:35:36.499350 EDT | AverageAction               0.9409
2017-06-10 22:35:36.499666 EDT | PolicyRegParamNorm         70.7784
2017-06-10 22:35:36.499984 EDT | QFunRegParamNorm           89.3672
2017-06-10 22:35:36.500292 EDT | -----------------------  -----------
2017-06-10 22:35:36.500730 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #441 | Training started
2017-06-10 22:35:52.240016 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #441 | Training finished
2017-06-10 22:35:52.241083 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #441 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 22:35:52.241651 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #441 | Collecting samples for evaluation
2017-06-10 22:36:03.497635 EDT | -----------------------  -----------
2017-06-10 22:36:03.498644 EDT | Epoch                     441
2017-06-10 22:36:03.498940 EDT | Iteration                 441
2017-06-10 22:36:03.499124 EDT | AverageReturn             227.953
2017-06-10 22:36:03.499328 EDT | StdReturn                  58.6288
2017-06-10 22:36:03.499493 EDT | MaxReturn                 455.413
2017-06-10 22:36:03.499710 EDT | MinReturn                 184.806
2017-06-10 22:36:03.499885 EDT | AverageEsReturn           436.204
2017-06-10 22:36:03.500076 EDT | StdEsReturn               343.817
2017-06-10 22:36:03.500238 EDT | MaxEsReturn              1002.58
2017-06-10 22:36:03.500400 EDT | MinEsReturn                16.6547
2017-06-10 22:36:03.500559 EDT | AverageDiscountedReturn   129.637
2017-06-10 22:36:03.502084 EDT | AverageQLoss                3.1717
2017-06-10 22:36:03.502457 EDT | AveragePolicySurr         -32.0488
2017-06-10 22:36:03.502759 EDT | AverageQ                   31.5644
2017-06-10 22:36:03.503069 EDT | AverageAbsQ                31.5921
2017-06-10 22:36:03.503386 EDT | AverageY                   31.5643
2017-06-10 22:36:03.503694 EDT | AverageAbsY                31.5817
2017-06-10 22:36:03.504014 EDT | AverageAbsQYDiff            0.672255
2017-06-10 22:36:03.504334 EDT | AverageAction               0.95591
2017-06-10 22:36:03.504645 EDT | PolicyRegParamNorm         70.8324
2017-06-10 22:36:03.504978 EDT | QFunRegParamNorm           89.5101
2017-06-10 22:36:03.505326 EDT | -----------------------  -----------
2017-06-10 22:36:03.505871 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #442 | Training started
2017-06-10 22:36:18.998322 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #442 | Training finished
2017-06-10 22:36:18.999100 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #442 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 22:36:18.999398 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #442 | Collecting samples for evaluation
2017-06-10 22:36:31.977379 EDT | -----------------------  -----------
2017-06-10 22:36:31.978103 EDT | Epoch                     442
2017-06-10 22:36:31.978286 EDT | Iteration                 442
2017-06-10 22:36:31.978514 EDT | AverageReturn            2297.43
2017-06-10 22:36:31.978831 EDT | StdReturn                 657.868
2017-06-10 22:36:31.979142 EDT | MaxReturn                2878.47
2017-06-10 22:36:31.979325 EDT | MinReturn                1057.39
2017-06-10 22:36:31.979550 EDT | AverageEsReturn           436.527
2017-06-10 22:36:31.979845 EDT | StdEsReturn               307.239
2017-06-10 22:36:31.980134 EDT | MaxEsReturn               727.249
2017-06-10 22:36:31.980441 EDT | MinEsReturn                 8.02733
2017-06-10 22:36:31.980630 EDT | AverageDiscountedReturn   240.734
2017-06-10 22:36:31.980891 EDT | AverageQLoss                2.46235
2017-06-10 22:36:31.981073 EDT | AveragePolicySurr         -32.0806
2017-06-10 22:36:31.981232 EDT | AverageQ                   31.6066
2017-06-10 22:36:31.981430 EDT | AverageAbsQ                31.6388
2017-06-10 22:36:31.981685 EDT | AverageY                   31.6081
2017-06-10 22:36:31.981917 EDT | AverageAbsY                31.624
2017-06-10 22:36:31.982071 EDT | AverageAbsQYDiff            0.631662
2017-06-10 22:36:31.982221 EDT | AverageAction               0.930127
2017-06-10 22:36:31.982370 EDT | PolicyRegParamNorm         70.9253
2017-06-10 22:36:31.982517 EDT | QFunRegParamNorm           89.5709
2017-06-10 22:36:31.982734 EDT | -----------------------  -----------
2017-06-10 22:36:31.983007 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #443 | Training started
2017-06-10 22:36:47.456752 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #443 | Training finished
2017-06-10 22:36:47.457019 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #443 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 22:36:47.457194 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #443 | Collecting samples for evaluation
2017-06-10 22:37:00.272554 EDT | -----------------------  -----------
2017-06-10 22:37:00.275889 EDT | Epoch                     443
2017-06-10 22:37:00.276664 EDT | Iteration                 443
2017-06-10 22:37:00.276952 EDT | AverageReturn            1945.46
2017-06-10 22:37:00.277204 EDT | StdReturn                 884.393
2017-06-10 22:37:00.277497 EDT | MaxReturn                2981.42
2017-06-10 22:37:00.277715 EDT | MinReturn                 890.084
2017-06-10 22:37:00.278207 EDT | AverageEsReturn           300.148
2017-06-10 22:37:00.278499 EDT | StdEsReturn               175.738
2017-06-10 22:37:00.278818 EDT | MaxEsReturn               714.831
2017-06-10 22:37:00.279106 EDT | MinEsReturn               124.702
2017-06-10 22:37:00.279433 EDT | AverageDiscountedReturn   234.618
2017-06-10 22:37:00.279707 EDT | AverageQLoss                2.36613
2017-06-10 22:37:00.280681 EDT | AveragePolicySurr         -32.01
2017-06-10 22:37:00.281024 EDT | AverageQ                   31.5133
2017-06-10 22:37:00.282456 EDT | AverageAbsQ                31.5515
2017-06-10 22:37:00.282710 EDT | AverageY                   31.5151
2017-06-10 22:37:00.282965 EDT | AverageAbsY                31.5357
2017-06-10 22:37:00.283772 EDT | AverageAbsQYDiff            0.628339
2017-06-10 22:37:00.284125 EDT | AverageAction               0.934677
2017-06-10 22:37:00.285213 EDT | PolicyRegParamNorm         70.965
2017-06-10 22:37:00.286601 EDT | QFunRegParamNorm           89.6539
2017-06-10 22:37:00.286864 EDT | -----------------------  -----------
2017-06-10 22:37:00.287286 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #444 | Training started
2017-06-10 22:37:14.770305 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #444 | Training finished
2017-06-10 22:37:14.927140 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #444 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 22:37:14.927594 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #444 | Collecting samples for evaluation
2017-06-10 22:37:27.174177 EDT | -----------------------  -----------
2017-06-10 22:37:27.175179 EDT | Epoch                     444
2017-06-10 22:37:27.175568 EDT | Iteration                 444
2017-06-10 22:37:27.175926 EDT | AverageReturn            1796.16
2017-06-10 22:37:27.176319 EDT | StdReturn                 598.05
2017-06-10 22:37:27.176684 EDT | MaxReturn                2524.38
2017-06-10 22:37:27.177046 EDT | MinReturn                 943.718
2017-06-10 22:37:27.177377 EDT | AverageEsReturn           331.532
2017-06-10 22:37:27.177730 EDT | StdEsReturn               215.836
2017-06-10 22:37:27.178063 EDT | MaxEsReturn               761.44
2017-06-10 22:37:27.178391 EDT | MinEsReturn                30.8758
2017-06-10 22:37:27.178716 EDT | AverageDiscountedReturn   221.445
2017-06-10 22:37:27.179039 EDT | AverageQLoss                2.43212
2017-06-10 22:37:27.179362 EDT | AveragePolicySurr         -32.1394
2017-06-10 22:37:27.179686 EDT | AverageQ                   31.636
2017-06-10 22:37:27.179956 EDT | AverageAbsQ                31.6641
2017-06-10 22:37:27.180201 EDT | AverageY                   31.6373
2017-06-10 22:37:27.180472 EDT | AverageAbsY                31.6536
2017-06-10 22:37:27.180758 EDT | AverageAbsQYDiff            0.631923
2017-06-10 22:37:27.181040 EDT | AverageAction               0.946505
2017-06-10 22:37:27.181323 EDT | PolicyRegParamNorm         71.0204
2017-06-10 22:37:27.181604 EDT | QFunRegParamNorm           89.6954
2017-06-10 22:37:27.181899 EDT | -----------------------  -----------
2017-06-10 22:37:27.182349 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #445 | Training started
2017-06-10 22:37:43.464973 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #445 | Training finished
2017-06-10 22:37:43.466832 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #445 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 22:37:43.467260 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #445 | Collecting samples for evaluation
2017-06-10 22:37:56.155250 EDT | -----------------------  -----------
2017-06-10 22:37:56.156070 EDT | Epoch                     445
2017-06-10 22:37:56.156450 EDT | Iteration                 445
2017-06-10 22:37:56.156786 EDT | AverageReturn            2056.89
2017-06-10 22:37:56.157138 EDT | StdReturn                 646.993
2017-06-10 22:37:56.157481 EDT | MaxReturn                2747.34
2017-06-10 22:37:56.157837 EDT | MinReturn                1040.92
2017-06-10 22:37:56.158220 EDT | AverageEsReturn           468.197
2017-06-10 22:37:56.159505 EDT | StdEsReturn               147.796
2017-06-10 22:37:56.159833 EDT | MaxEsReturn               682.363
2017-06-10 22:37:56.160204 EDT | MinEsReturn               250.551
2017-06-10 22:37:56.160501 EDT | AverageDiscountedReturn   233.005
2017-06-10 22:37:56.160811 EDT | AverageQLoss                2.85284
2017-06-10 22:37:56.161099 EDT | AveragePolicySurr         -32.0916
2017-06-10 22:37:56.163840 EDT | AverageQ                   31.5879
2017-06-10 22:37:56.164158 EDT | AverageAbsQ                31.6126
2017-06-10 22:37:56.167357 EDT | AverageY                   31.589
2017-06-10 22:37:56.167835 EDT | AverageAbsY                31.599
2017-06-10 22:37:56.168668 EDT | AverageAbsQYDiff            0.657344
2017-06-10 22:37:56.168990 EDT | AverageAction               0.948563
2017-06-10 22:37:56.169294 EDT | PolicyRegParamNorm         71.0991
2017-06-10 22:37:56.169601 EDT | QFunRegParamNorm           89.7674
2017-06-10 22:37:56.169925 EDT | -----------------------  -----------
2017-06-10 22:37:56.170391 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #446 | Training started
2017-06-10 22:38:11.562970 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #446 | Training finished
2017-06-10 22:38:11.563745 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #446 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 22:38:11.563962 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #446 | Collecting samples for evaluation
2017-06-10 22:38:23.636897 EDT | -----------------------  -----------
2017-06-10 22:38:23.637679 EDT | Epoch                     446
2017-06-10 22:38:23.637889 EDT | Iteration                 446
2017-06-10 22:38:23.638049 EDT | AverageReturn            2233.92
2017-06-10 22:38:23.638204 EDT | StdReturn                 799.705
2017-06-10 22:38:23.638372 EDT | MaxReturn                3100.47
2017-06-10 22:38:23.638641 EDT | MinReturn                 849.414
2017-06-10 22:38:23.638812 EDT | AverageEsReturn           331.526
2017-06-10 22:38:23.639061 EDT | StdEsReturn               209.515
2017-06-10 22:38:23.639217 EDT | MaxEsReturn               650.431
2017-06-10 22:38:23.639479 EDT | MinEsReturn                14.253
2017-06-10 22:38:23.639633 EDT | AverageDiscountedReturn   237.926
2017-06-10 22:38:23.639783 EDT | AverageQLoss                2.48876
2017-06-10 22:38:23.639931 EDT | AveragePolicySurr         -32.33
2017-06-10 22:38:23.640079 EDT | AverageQ                   31.8249
2017-06-10 22:38:23.640286 EDT | AverageAbsQ                31.8499
2017-06-10 22:38:23.640527 EDT | AverageY                   31.8261
2017-06-10 22:38:23.640845 EDT | AverageAbsY                31.8355
2017-06-10 22:38:23.641106 EDT | AverageAbsQYDiff            0.63148
2017-06-10 22:38:23.641387 EDT | AverageAction               0.905613
2017-06-10 22:38:23.641718 EDT | PolicyRegParamNorm         71.1055
2017-06-10 22:38:23.642553 EDT | QFunRegParamNorm           89.8571
2017-06-10 22:38:23.642846 EDT | -----------------------  -----------
2017-06-10 22:38:23.643324 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #447 | Training started
2017-06-10 22:38:38.965725 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #447 | Training finished
2017-06-10 22:38:38.966710 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #447 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 22:38:38.967209 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #447 | Collecting samples for evaluation
2017-06-10 22:38:51.290205 EDT | -----------------------  -----------
2017-06-10 22:38:51.291174 EDT | Epoch                     447
2017-06-10 22:38:51.291556 EDT | Iteration                 447
2017-06-10 22:38:51.291917 EDT | AverageReturn            1592.76
2017-06-10 22:38:51.292272 EDT | StdReturn                 528.644
2017-06-10 22:38:51.292629 EDT | MaxReturn                2440.76
2017-06-10 22:38:51.292988 EDT | MinReturn                 841.279
2017-06-10 22:38:51.293343 EDT | AverageEsReturn           621.301
2017-06-10 22:38:51.293715 EDT | StdEsReturn               441.105
2017-06-10 22:38:51.294073 EDT | MaxEsReturn              1060.88
2017-06-10 22:38:51.294430 EDT | MinEsReturn                17.4962
2017-06-10 22:38:51.294782 EDT | AverageDiscountedReturn   218.024
2017-06-10 22:38:51.295137 EDT | AverageQLoss                2.7709
2017-06-10 22:38:51.295491 EDT | AveragePolicySurr         -32.1409
2017-06-10 22:38:51.295848 EDT | AverageQ                   31.634
2017-06-10 22:38:51.296202 EDT | AverageAbsQ                31.6641
2017-06-10 22:38:51.296558 EDT | AverageY                   31.6363
2017-06-10 22:38:51.296913 EDT | AverageAbsY                31.6493
2017-06-10 22:38:51.297265 EDT | AverageAbsQYDiff            0.658097
2017-06-10 22:38:51.297619 EDT | AverageAction               0.935289
2017-06-10 22:38:51.297985 EDT | PolicyRegParamNorm         71.1836
2017-06-10 22:38:51.298341 EDT | QFunRegParamNorm           89.9223
2017-06-10 22:38:51.298694 EDT | -----------------------  -----------
2017-06-10 22:38:51.299210 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #448 | Training started
2017-06-10 22:39:06.448768 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #448 | Training finished
2017-06-10 22:39:06.449609 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #448 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 22:39:06.449924 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #448 | Collecting samples for evaluation
2017-06-10 22:39:19.479041 EDT | -----------------------  -----------
2017-06-10 22:39:19.480044 EDT | Epoch                     448
2017-06-10 22:39:19.480398 EDT | Iteration                 448
2017-06-10 22:39:19.480735 EDT | AverageReturn             938.417
2017-06-10 22:39:19.481069 EDT | StdReturn                 236.487
2017-06-10 22:39:19.481400 EDT | MaxReturn                1595.27
2017-06-10 22:39:19.481737 EDT | MinReturn                 605.929
2017-06-10 22:39:19.482070 EDT | AverageEsReturn           358.585
2017-06-10 22:39:19.482399 EDT | StdEsReturn               268.33
2017-06-10 22:39:19.482766 EDT | MaxEsReturn               995.204
2017-06-10 22:39:19.483122 EDT | MinEsReturn               150.714
2017-06-10 22:39:19.483453 EDT | AverageDiscountedReturn   248.498
2017-06-10 22:39:19.483779 EDT | AverageQLoss                2.93881
2017-06-10 22:39:19.484107 EDT | AveragePolicySurr         -32.0801
2017-06-10 22:39:19.484432 EDT | AverageQ                   31.5938
2017-06-10 22:39:19.484757 EDT | AverageAbsQ                31.6274
2017-06-10 22:39:19.485107 EDT | AverageY                   31.5956
2017-06-10 22:39:19.485444 EDT | AverageAbsY                31.6148
2017-06-10 22:39:19.485781 EDT | AverageAbsQYDiff            0.642189
2017-06-10 22:39:19.486112 EDT | AverageAction               0.884215
2017-06-10 22:39:19.486444 EDT | PolicyRegParamNorm         71.2101
2017-06-10 22:39:19.486818 EDT | QFunRegParamNorm           90.0418
2017-06-10 22:39:19.487184 EDT | -----------------------  -----------
2017-06-10 22:39:19.487650 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #449 | Training started
2017-06-10 22:39:34.492889 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #449 | Training finished
2017-06-10 22:39:34.493730 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #449 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 22:39:34.493974 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #449 | Collecting samples for evaluation
2017-06-10 22:39:47.512719 EDT | -----------------------  -----------
2017-06-10 22:39:47.513554 EDT | Epoch                     449
2017-06-10 22:39:47.513861 EDT | Iteration                 449
2017-06-10 22:39:47.522674 EDT | AverageReturn             714.628
2017-06-10 22:39:47.523084 EDT | StdReturn                 639.226
2017-06-10 22:39:47.523753 EDT | MaxReturn                2645.1
2017-06-10 22:39:47.524108 EDT | MinReturn                  55.5872
2017-06-10 22:39:47.527073 EDT | AverageEsReturn           524.698
2017-06-10 22:39:47.527480 EDT | StdEsReturn               388.902
2017-06-10 22:39:47.527826 EDT | MaxEsReturn              1100.82
2017-06-10 22:39:47.528212 EDT | MinEsReturn               185.851
2017-06-10 22:39:47.528556 EDT | AverageDiscountedReturn   158.166
2017-06-10 22:39:47.528896 EDT | AverageQLoss                2.68642
2017-06-10 22:39:47.529234 EDT | AveragePolicySurr         -32.2972
2017-06-10 22:39:47.529572 EDT | AverageQ                   31.8123
2017-06-10 22:39:47.530013 EDT | AverageAbsQ                31.8448
2017-06-10 22:39:47.530355 EDT | AverageY                   31.8133
2017-06-10 22:39:47.531027 EDT | AverageAbsY                31.83
2017-06-10 22:39:47.532390 EDT | AverageAbsQYDiff            0.637313
2017-06-10 22:39:47.532883 EDT | AverageAction               0.92214
2017-06-10 22:39:47.533680 EDT | PolicyRegParamNorm         71.323
2017-06-10 22:39:47.534639 EDT | QFunRegParamNorm           90.0924
2017-06-10 22:39:47.535390 EDT | -----------------------  -----------
2017-06-10 22:39:47.535919 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #450 | Training started
2017-06-10 22:40:02.982063 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #450 | Training finished
2017-06-10 22:40:02.982860 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #450 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 22:40:02.983083 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #450 | Collecting samples for evaluation
2017-06-10 22:40:14.465490 EDT | -----------------------  -----------
2017-06-10 22:40:14.466110 EDT | Epoch                     450
2017-06-10 22:40:14.466506 EDT | Iteration                 450
2017-06-10 22:40:14.466879 EDT | AverageReturn             566.506
2017-06-10 22:40:14.467277 EDT | StdReturn                 288.435
2017-06-10 22:40:14.467715 EDT | MaxReturn                1499.03
2017-06-10 22:40:14.468089 EDT | MinReturn                 258.181
2017-06-10 22:40:14.468476 EDT | AverageEsReturn           372.931
2017-06-10 22:40:14.468898 EDT | StdEsReturn               298.126
2017-06-10 22:40:14.469397 EDT | MaxEsReturn               984.215
2017-06-10 22:40:14.470153 EDT | MinEsReturn                53.08
2017-06-10 22:40:14.470522 EDT | AverageDiscountedReturn   186.795
2017-06-10 22:40:14.470852 EDT | AverageQLoss                3.01
2017-06-10 22:40:14.471557 EDT | AveragePolicySurr         -32.2676
2017-06-10 22:40:14.472127 EDT | AverageQ                   31.7528
2017-06-10 22:40:14.472524 EDT | AverageAbsQ                31.779
2017-06-10 22:40:14.472804 EDT | AverageY                   31.7529
2017-06-10 22:40:14.473131 EDT | AverageAbsY                31.7651
2017-06-10 22:40:14.473462 EDT | AverageAbsQYDiff            0.652166
2017-06-10 22:40:14.473800 EDT | AverageAction               0.913458
2017-06-10 22:40:14.474090 EDT | PolicyRegParamNorm         71.3626
2017-06-10 22:40:14.485819 EDT | QFunRegParamNorm           90.206
2017-06-10 22:40:14.486339 EDT | -----------------------  -----------
2017-06-10 22:40:14.486931 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #451 | Training started
2017-06-10 22:40:30.443398 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #451 | Training finished
2017-06-10 22:40:30.444378 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #451 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 22:40:30.444767 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #451 | Collecting samples for evaluation
2017-06-10 22:40:43.530277 EDT | -----------------------  -----------
2017-06-10 22:40:43.531275 EDT | Epoch                     451
2017-06-10 22:40:43.531672 EDT | Iteration                 451
2017-06-10 22:40:43.532080 EDT | AverageReturn             758.622
2017-06-10 22:40:43.532514 EDT | StdReturn                 710.388
2017-06-10 22:40:43.532895 EDT | MaxReturn                3058.44
2017-06-10 22:40:43.533273 EDT | MinReturn                  68.4273
2017-06-10 22:40:43.533712 EDT | AverageEsReturn           265.085
2017-06-10 22:40:43.534207 EDT | StdEsReturn               226.129
2017-06-10 22:40:43.534599 EDT | MaxEsReturn               720.955
2017-06-10 22:40:43.535026 EDT | MinEsReturn                80.7499
2017-06-10 22:40:43.535421 EDT | AverageDiscountedReturn   161.871
2017-06-10 22:40:43.535782 EDT | AverageQLoss                2.91205
2017-06-10 22:40:43.536201 EDT | AveragePolicySurr         -32.3721
2017-06-10 22:40:43.536613 EDT | AverageQ                   31.8753
2017-06-10 22:40:43.537053 EDT | AverageAbsQ                31.9002
2017-06-10 22:40:43.537388 EDT | AverageY                   31.8782
2017-06-10 22:40:43.537780 EDT | AverageAbsY                31.8889
2017-06-10 22:40:43.538069 EDT | AverageAbsQYDiff            0.645484
2017-06-10 22:40:43.538384 EDT | AverageAction               0.901766
2017-06-10 22:40:43.538712 EDT | PolicyRegParamNorm         71.4079
2017-06-10 22:40:43.539117 EDT | QFunRegParamNorm           90.3157
2017-06-10 22:40:43.539436 EDT | -----------------------  -----------
2017-06-10 22:40:43.540176 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #452 | Training started
2017-06-10 22:40:57.929328 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #452 | Training finished
2017-06-10 22:40:57.930254 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #452 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 22:40:57.930633 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #452 | Collecting samples for evaluation
2017-06-10 22:41:10.873854 EDT | -----------------------  -----------
2017-06-10 22:41:10.874573 EDT | Epoch                     452
2017-06-10 22:41:10.874798 EDT | Iteration                 452
2017-06-10 22:41:10.874958 EDT | AverageReturn             920.063
2017-06-10 22:41:10.875113 EDT | StdReturn                 481.745
2017-06-10 22:41:10.875319 EDT | MaxReturn                1638.23
2017-06-10 22:41:10.875608 EDT | MinReturn                 282.037
2017-06-10 22:41:10.875928 EDT | AverageEsReturn           416.131
2017-06-10 22:41:10.876207 EDT | StdEsReturn               311.68
2017-06-10 22:41:10.876498 EDT | MaxEsReturn               869.552
2017-06-10 22:41:10.876821 EDT | MinEsReturn                56.7733
2017-06-10 22:41:10.877146 EDT | AverageDiscountedReturn   199.426
2017-06-10 22:41:10.877459 EDT | AverageQLoss                2.68699
2017-06-10 22:41:10.877749 EDT | AveragePolicySurr         -32.2664
2017-06-10 22:41:10.878165 EDT | AverageQ                   31.7802
2017-06-10 22:41:10.878324 EDT | AverageAbsQ                31.8124
2017-06-10 22:41:10.878520 EDT | AverageY                   31.7829
2017-06-10 22:41:10.878844 EDT | AverageAbsY                31.8003
2017-06-10 22:41:10.879016 EDT | AverageAbsQYDiff            0.621716
2017-06-10 22:41:10.879564 EDT | AverageAction               0.939652
2017-06-10 22:41:10.879897 EDT | PolicyRegParamNorm         71.4941
2017-06-10 22:41:10.880251 EDT | QFunRegParamNorm           90.3989
2017-06-10 22:41:10.881892 EDT | -----------------------  -----------
2017-06-10 22:41:10.882834 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #453 | Training started
2017-06-10 22:41:25.015373 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #453 | Training finished
2017-06-10 22:41:25.016321 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #453 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 22:41:25.016727 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #453 | Collecting samples for evaluation
2017-06-10 22:41:37.957867 EDT | -----------------------  -----------
2017-06-10 22:41:37.958952 EDT | Epoch                     453
2017-06-10 22:41:37.959394 EDT | Iteration                 453
2017-06-10 22:41:37.959765 EDT | AverageReturn            1622.34
2017-06-10 22:41:37.960160 EDT | StdReturn                1036.42
2017-06-10 22:41:37.961540 EDT | MaxReturn                3097.22
2017-06-10 22:41:37.962053 EDT | MinReturn                  75.0276
2017-06-10 22:41:37.965688 EDT | AverageEsReturn           505.904
2017-06-10 22:41:37.966213 EDT | StdEsReturn               391.394
2017-06-10 22:41:37.967466 EDT | MaxEsReturn              1079.85
2017-06-10 22:41:37.967663 EDT | MinEsReturn                39.483
2017-06-10 22:41:37.967849 EDT | AverageDiscountedReturn   209.238
2017-06-10 22:41:37.968030 EDT | AverageQLoss                2.89861
2017-06-10 22:41:37.968210 EDT | AveragePolicySurr         -32.3548
2017-06-10 22:41:37.968388 EDT | AverageQ                   31.86
2017-06-10 22:41:37.968586 EDT | AverageAbsQ                31.8906
2017-06-10 22:41:37.968768 EDT | AverageY                   31.8602
2017-06-10 22:41:37.968953 EDT | AverageAbsY                31.8788
2017-06-10 22:41:37.969135 EDT | AverageAbsQYDiff            0.630619
2017-06-10 22:41:37.969318 EDT | AverageAction               0.923473
2017-06-10 22:41:37.969496 EDT | PolicyRegParamNorm         71.4844
2017-06-10 22:41:37.969673 EDT | QFunRegParamNorm           90.4419
2017-06-10 22:41:37.970078 EDT | -----------------------  -----------
2017-06-10 22:41:37.971025 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #454 | Training started
2017-06-10 22:41:53.632003 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #454 | Training finished
2017-06-10 22:41:53.632490 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #454 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 22:41:53.632663 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #454 | Collecting samples for evaluation
2017-06-10 22:42:06.727013 EDT | -----------------------  -----------
2017-06-10 22:42:06.727818 EDT | Epoch                     454
2017-06-10 22:42:06.728177 EDT | Iteration                 454
2017-06-10 22:42:06.729651 EDT | AverageReturn            1590.02
2017-06-10 22:42:06.730080 EDT | StdReturn                 906.471
2017-06-10 22:42:06.730563 EDT | MaxReturn                2617.66
2017-06-10 22:42:06.730948 EDT | MinReturn                 208.053
2017-06-10 22:42:06.731239 EDT | AverageEsReturn           420.691
2017-06-10 22:42:06.731423 EDT | StdEsReturn               318.793
2017-06-10 22:42:06.731605 EDT | MaxEsReturn              1031.38
2017-06-10 22:42:06.731825 EDT | MinEsReturn                67.698
2017-06-10 22:42:06.732007 EDT | AverageDiscountedReturn   199.681
2017-06-10 22:42:06.732189 EDT | AverageQLoss                2.74387
2017-06-10 22:42:06.732367 EDT | AveragePolicySurr         -32.3973
2017-06-10 22:42:06.732545 EDT | AverageQ                   31.9135
2017-06-10 22:42:06.732748 EDT | AverageAbsQ                31.941
2017-06-10 22:42:06.732928 EDT | AverageY                   31.9138
2017-06-10 22:42:06.733101 EDT | AverageAbsY                31.9281
2017-06-10 22:42:06.733264 EDT | AverageAbsQYDiff            0.63695
2017-06-10 22:42:06.733446 EDT | AverageAction               0.950595
2017-06-10 22:42:06.734286 EDT | PolicyRegParamNorm         71.5458
2017-06-10 22:42:06.734697 EDT | QFunRegParamNorm           90.5268
2017-06-10 22:42:06.734895 EDT | -----------------------  -----------
2017-06-10 22:42:06.735452 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #455 | Training started
2017-06-10 22:42:21.627256 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #455 | Training finished
2017-06-10 22:42:21.627773 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #455 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 22:42:21.628142 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #455 | Collecting samples for evaluation
2017-06-10 22:42:34.316434 EDT | -----------------------  -----------
2017-06-10 22:42:34.317329 EDT | Epoch                     455
2017-06-10 22:42:34.317746 EDT | Iteration                 455
2017-06-10 22:42:34.317968 EDT | AverageReturn            1983.53
2017-06-10 22:42:34.318135 EDT | StdReturn                 711.457
2017-06-10 22:42:34.318296 EDT | MaxReturn                2694.64
2017-06-10 22:42:34.318505 EDT | MinReturn                 680.606
2017-06-10 22:42:34.318672 EDT | AverageEsReturn           257.963
2017-06-10 22:42:34.318851 EDT | StdEsReturn                92.6639
2017-06-10 22:42:34.319063 EDT | MaxEsReturn               377.99
2017-06-10 22:42:34.319377 EDT | MinEsReturn               118.056
2017-06-10 22:42:34.319626 EDT | AverageDiscountedReturn   218.663
2017-06-10 22:42:34.319892 EDT | AverageQLoss                2.66206
2017-06-10 22:42:34.320150 EDT | AveragePolicySurr         -32.4029
2017-06-10 22:42:34.320330 EDT | AverageQ                   31.932
2017-06-10 22:42:34.320623 EDT | AverageAbsQ                31.9642
2017-06-10 22:42:34.320798 EDT | AverageY                   31.934
2017-06-10 22:42:34.320988 EDT | AverageAbsY                31.9505
2017-06-10 22:42:34.321266 EDT | AverageAbsQYDiff            0.626611
2017-06-10 22:42:34.321477 EDT | AverageAction               0.952497
2017-06-10 22:42:34.321663 EDT | PolicyRegParamNorm         71.6174
2017-06-10 22:42:34.321853 EDT | QFunRegParamNorm           90.5859
2017-06-10 22:42:34.322033 EDT | -----------------------  -----------
2017-06-10 22:42:34.322336 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #456 | Training started
2017-06-10 22:42:49.743533 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #456 | Training finished
2017-06-10 22:42:49.743947 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #456 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 22:42:49.744309 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #456 | Collecting samples for evaluation
2017-06-10 22:43:03.406371 EDT | -----------------------  -----------
2017-06-10 22:43:03.407394 EDT | Epoch                     456
2017-06-10 22:43:03.408109 EDT | Iteration                 456
2017-06-10 22:43:03.408401 EDT | AverageReturn            1601.86
2017-06-10 22:43:03.408734 EDT | StdReturn                 532.952
2017-06-10 22:43:03.409356 EDT | MaxReturn                2381.57
2017-06-10 22:43:03.409677 EDT | MinReturn                 666.199
2017-06-10 22:43:03.410088 EDT | AverageEsReturn           784.001
2017-06-10 22:43:03.410422 EDT | StdEsReturn               180.084
2017-06-10 22:43:03.410757 EDT | MaxEsReturn              1025.3
2017-06-10 22:43:03.411085 EDT | MinEsReturn               527.728
2017-06-10 22:43:03.411769 EDT | AverageDiscountedReturn   204.831
2017-06-10 22:43:03.412106 EDT | AverageQLoss                2.45931
2017-06-10 22:43:03.413044 EDT | AveragePolicySurr         -32.363
2017-06-10 22:43:03.413399 EDT | AverageQ                   31.8857
2017-06-10 22:43:03.413744 EDT | AverageAbsQ                31.9213
2017-06-10 22:43:03.414297 EDT | AverageY                   31.8854
2017-06-10 22:43:03.414637 EDT | AverageAbsY                31.9018
2017-06-10 22:43:03.414974 EDT | AverageAbsQYDiff            0.60927
2017-06-10 22:43:03.415431 EDT | AverageAction               0.941725
2017-06-10 22:43:03.415768 EDT | PolicyRegParamNorm         71.7288
2017-06-10 22:43:03.416365 EDT | QFunRegParamNorm           90.6432
2017-06-10 22:43:03.416695 EDT | -----------------------  -----------
2017-06-10 22:43:03.417258 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #457 | Training started
2017-06-10 22:43:18.004320 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #457 | Training finished
2017-06-10 22:43:18.005280 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #457 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 22:43:18.005903 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #457 | Collecting samples for evaluation
2017-06-10 22:43:31.205215 EDT | -----------------------  -----------
2017-06-10 22:43:31.206133 EDT | Epoch                     457
2017-06-10 22:43:31.206337 EDT | Iteration                 457
2017-06-10 22:43:31.206502 EDT | AverageReturn            2236.79
2017-06-10 22:43:31.206660 EDT | StdReturn                 747.261
2017-06-10 22:43:31.206812 EDT | MaxReturn                2893.72
2017-06-10 22:43:31.206963 EDT | MinReturn                 890.038
2017-06-10 22:43:31.207118 EDT | AverageEsReturn           424.794
2017-06-10 22:43:31.207267 EDT | StdEsReturn               241.561
2017-06-10 22:43:31.207427 EDT | MaxEsReturn               759.518
2017-06-10 22:43:31.207613 EDT | MinEsReturn                13.7151
2017-06-10 22:43:31.207778 EDT | AverageDiscountedReturn   226.824
2017-06-10 22:43:31.207981 EDT | AverageQLoss                2.89164
2017-06-10 22:43:31.208140 EDT | AveragePolicySurr         -32.3253
2017-06-10 22:43:31.208303 EDT | AverageQ                   31.8416
2017-06-10 22:43:31.208488 EDT | AverageAbsQ                31.878
2017-06-10 22:43:31.208663 EDT | AverageY                   31.8443
2017-06-10 22:43:31.208820 EDT | AverageAbsY                31.8624
2017-06-10 22:43:31.208983 EDT | AverageAbsQYDiff            0.640792
2017-06-10 22:43:31.209192 EDT | AverageAction               0.954195
2017-06-10 22:43:31.209376 EDT | PolicyRegParamNorm         71.7276
2017-06-10 22:43:31.209557 EDT | QFunRegParamNorm           90.7195
2017-06-10 22:43:31.209751 EDT | -----------------------  -----------
2017-06-10 22:43:31.210017 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #458 | Training started
2017-06-10 22:43:45.856665 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #458 | Training finished
2017-06-10 22:43:45.857490 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #458 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 22:43:45.857715 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #458 | Collecting samples for evaluation
2017-06-10 22:43:58.459714 EDT | -----------------------  -----------
2017-06-10 22:43:58.460780 EDT | Epoch                     458
2017-06-10 22:43:58.461160 EDT | Iteration                 458
2017-06-10 22:43:58.461592 EDT | AverageReturn            1728.18
2017-06-10 22:43:58.462255 EDT | StdReturn                 795.966
2017-06-10 22:43:58.463427 EDT | MaxReturn                2529.18
2017-06-10 22:43:58.463843 EDT | MinReturn                 679.377
2017-06-10 22:43:58.464298 EDT | AverageEsReturn           351.811
2017-06-10 22:43:58.464712 EDT | StdEsReturn               183.892
2017-06-10 22:43:58.465042 EDT | MaxEsReturn               674.997
2017-06-10 22:43:58.465355 EDT | MinEsReturn               112.189
2017-06-10 22:43:58.465853 EDT | AverageDiscountedReturn   226.605
2017-06-10 22:43:58.466219 EDT | AverageQLoss                2.69528
2017-06-10 22:43:58.466497 EDT | AveragePolicySurr         -32.2625
2017-06-10 22:43:58.466830 EDT | AverageQ                   31.7902
2017-06-10 22:43:58.467158 EDT | AverageAbsQ                31.8212
2017-06-10 22:43:58.467416 EDT | AverageY                   31.7909
2017-06-10 22:43:58.467721 EDT | AverageAbsY                31.809
2017-06-10 22:43:58.468033 EDT | AverageAbsQYDiff            0.628798
2017-06-10 22:43:58.468360 EDT | AverageAction               0.95711
2017-06-10 22:43:58.468633 EDT | PolicyRegParamNorm         71.8221
2017-06-10 22:43:58.468908 EDT | QFunRegParamNorm           90.8542
2017-06-10 22:43:58.469239 EDT | -----------------------  -----------
2017-06-10 22:43:58.469744 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #459 | Training started
2017-06-10 22:44:13.948034 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #459 | Training finished
2017-06-10 22:44:13.949060 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #459 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 22:44:13.949460 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #459 | Collecting samples for evaluation
2017-06-10 22:44:25.937420 EDT | -----------------------  -----------
2017-06-10 22:44:25.938267 EDT | Epoch                     459
2017-06-10 22:44:25.938448 EDT | Iteration                 459
2017-06-10 22:44:25.938609 EDT | AverageReturn            1547.49
2017-06-10 22:44:25.938806 EDT | StdReturn                 631.925
2017-06-10 22:44:25.939111 EDT | MaxReturn                2551.03
2017-06-10 22:44:25.939339 EDT | MinReturn                 825.739
2017-06-10 22:44:25.939499 EDT | AverageEsReturn           468.167
2017-06-10 22:44:25.939710 EDT | StdEsReturn               156.496
2017-06-10 22:44:25.940151 EDT | MaxEsReturn               703.464
2017-06-10 22:44:25.940625 EDT | MinEsReturn               237.432
2017-06-10 22:44:25.941040 EDT | AverageDiscountedReturn   222.713
2017-06-10 22:44:25.941400 EDT | AverageQLoss                2.0397
2017-06-10 22:44:25.941609 EDT | AveragePolicySurr         -32.4397
2017-06-10 22:44:25.941808 EDT | AverageQ                   31.9841
2017-06-10 22:44:25.941997 EDT | AverageAbsQ                32.0166
2017-06-10 22:44:25.942176 EDT | AverageY                   31.985
2017-06-10 22:44:25.942359 EDT | AverageAbsY                32.0024
2017-06-10 22:44:25.942537 EDT | AverageAbsQYDiff            0.582284
2017-06-10 22:44:25.942823 EDT | AverageAction               0.947952
2017-06-10 22:44:25.943202 EDT | PolicyRegParamNorm         71.8458
2017-06-10 22:44:25.943601 EDT | QFunRegParamNorm           90.9302
2017-06-10 22:44:25.944013 EDT | -----------------------  -----------
2017-06-10 22:44:25.944498 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #460 | Training started
2017-06-10 22:44:40.705658 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #460 | Training finished
2017-06-10 22:44:40.706076 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #460 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 22:44:40.706335 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #460 | Collecting samples for evaluation
2017-06-10 22:44:53.127715 EDT | -----------------------  -----------
2017-06-10 22:44:53.128635 EDT | Epoch                     460
2017-06-10 22:44:53.128925 EDT | Iteration                 460
2017-06-10 22:44:53.129177 EDT | AverageReturn            1760.82
2017-06-10 22:44:53.129487 EDT | StdReturn                 693.572
2017-06-10 22:44:53.129792 EDT | MaxReturn                2462.71
2017-06-10 22:44:53.130042 EDT | MinReturn                 687.773
2017-06-10 22:44:53.130285 EDT | AverageEsReturn           274.282
2017-06-10 22:44:53.130526 EDT | StdEsReturn               302.828
2017-06-10 22:44:53.130779 EDT | MaxEsReturn               967.053
2017-06-10 22:44:53.131021 EDT | MinEsReturn                18.7343
2017-06-10 22:44:53.131260 EDT | AverageDiscountedReturn   210.709
2017-06-10 22:44:53.131499 EDT | AverageQLoss                2.53539
2017-06-10 22:44:53.131737 EDT | AveragePolicySurr         -32.3501
2017-06-10 22:44:53.131975 EDT | AverageQ                   31.8814
2017-06-10 22:44:53.132213 EDT | AverageAbsQ                31.9127
2017-06-10 22:44:53.132453 EDT | AverageY                   31.8829
2017-06-10 22:44:53.132690 EDT | AverageAbsY                31.9012
2017-06-10 22:44:53.132961 EDT | AverageAbsQYDiff            0.615569
2017-06-10 22:44:53.133204 EDT | AverageAction               0.938331
2017-06-10 22:44:53.133444 EDT | PolicyRegParamNorm         71.9196
2017-06-10 22:44:53.133684 EDT | QFunRegParamNorm           91.0143
2017-06-10 22:44:53.133933 EDT | -----------------------  -----------
2017-06-10 22:44:53.134319 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #461 | Training started
2017-06-10 22:45:08.383868 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #461 | Training finished
2017-06-10 22:45:08.384709 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #461 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 22:45:08.384993 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #461 | Collecting samples for evaluation
2017-06-10 22:45:21.134773 EDT | -----------------------  -----------
2017-06-10 22:45:21.135740 EDT | Epoch                     461
2017-06-10 22:45:21.136096 EDT | Iteration                 461
2017-06-10 22:45:21.136439 EDT | AverageReturn            2093.29
2017-06-10 22:45:21.136633 EDT | StdReturn                 717.424
2017-06-10 22:45:21.136818 EDT | MaxReturn                2639.6
2017-06-10 22:45:21.136979 EDT | MinReturn                 885.575
2017-06-10 22:45:21.137144 EDT | AverageEsReturn           289.397
2017-06-10 22:45:21.137321 EDT | StdEsReturn               245.672
2017-06-10 22:45:21.137478 EDT | MaxEsReturn               826.808
2017-06-10 22:45:21.137632 EDT | MinEsReturn                62.761
2017-06-10 22:45:21.137875 EDT | AverageDiscountedReturn   227.375
2017-06-10 22:45:21.138124 EDT | AverageQLoss                2.67145
2017-06-10 22:45:21.138308 EDT | AveragePolicySurr         -32.4944
2017-06-10 22:45:21.138490 EDT | AverageQ                   32.0012
2017-06-10 22:45:21.138714 EDT | AverageAbsQ                32.0349
2017-06-10 22:45:21.138896 EDT | AverageY                   32.0031
2017-06-10 22:45:21.139074 EDT | AverageAbsY                32.0216
2017-06-10 22:45:21.139246 EDT | AverageAbsQYDiff            0.633148
2017-06-10 22:45:21.139403 EDT | AverageAction               0.935389
2017-06-10 22:45:21.139559 EDT | PolicyRegParamNorm         72.0095
2017-06-10 22:45:21.139742 EDT | QFunRegParamNorm           91.0973
2017-06-10 22:45:21.140128 EDT | -----------------------  -----------
2017-06-10 22:45:21.140427 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #462 | Training started
2017-06-10 22:45:35.362617 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #462 | Training finished
2017-06-10 22:45:35.363611 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #462 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 22:45:35.363932 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #462 | Collecting samples for evaluation
2017-06-10 22:45:48.821424 EDT | -----------------------  -----------
2017-06-10 22:45:48.826249 EDT | Epoch                     462
2017-06-10 22:45:48.826679 EDT | Iteration                 462
2017-06-10 22:45:48.827035 EDT | AverageReturn            1415.9
2017-06-10 22:45:48.827396 EDT | StdReturn                 405.547
2017-06-10 22:45:48.827742 EDT | MaxReturn                2315.56
2017-06-10 22:45:48.828104 EDT | MinReturn                 859.252
2017-06-10 22:45:48.829633 EDT | AverageEsReturn           471.288
2017-06-10 22:45:48.832028 EDT | StdEsReturn               266.052
2017-06-10 22:45:48.832389 EDT | MaxEsReturn               948.558
2017-06-10 22:45:48.833853 EDT | MinEsReturn               237.287
2017-06-10 22:45:48.835131 EDT | AverageDiscountedReturn   198.92
2017-06-10 22:45:48.835546 EDT | AverageQLoss                2.59439
2017-06-10 22:45:48.837078 EDT | AveragePolicySurr         -32.4646
2017-06-10 22:45:48.837546 EDT | AverageQ                   31.9509
2017-06-10 22:45:48.837914 EDT | AverageAbsQ                31.9892
2017-06-10 22:45:48.839231 EDT | AverageY                   31.9518
2017-06-10 22:45:48.839596 EDT | AverageAbsY                31.975
2017-06-10 22:45:48.841106 EDT | AverageAbsQYDiff            0.624876
2017-06-10 22:45:48.841485 EDT | AverageAction               0.936817
2017-06-10 22:45:48.842833 EDT | PolicyRegParamNorm         72.0893
2017-06-10 22:45:48.843294 EDT | QFunRegParamNorm           91.202
2017-06-10 22:45:48.844571 EDT | -----------------------  -----------
2017-06-10 22:45:48.845148 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #463 | Training started
2017-06-10 22:46:03.786402 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #463 | Training finished
2017-06-10 22:46:03.787212 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #463 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 22:46:03.787517 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #463 | Collecting samples for evaluation
2017-06-10 22:46:16.458751 EDT | -----------------------  -----------
2017-06-10 22:46:16.459503 EDT | Epoch                     463
2017-06-10 22:46:16.459717 EDT | Iteration                 463
2017-06-10 22:46:16.460002 EDT | AverageReturn            2062.72
2017-06-10 22:46:16.460275 EDT | StdReturn                 534.496
2017-06-10 22:46:16.460506 EDT | MaxReturn                2521.54
2017-06-10 22:46:16.460823 EDT | MinReturn                 991.306
2017-06-10 22:46:16.462756 EDT | AverageEsReturn           307.115
2017-06-10 22:46:16.464209 EDT | StdEsReturn               131.004
2017-06-10 22:46:16.464419 EDT | MaxEsReturn               491.744
2017-06-10 22:46:16.464619 EDT | MinEsReturn               126.576
2017-06-10 22:46:16.464810 EDT | AverageDiscountedReturn   224.05
2017-06-10 22:46:16.464982 EDT | AverageQLoss                2.3036
2017-06-10 22:46:16.465157 EDT | AveragePolicySurr         -32.3898
2017-06-10 22:46:16.465352 EDT | AverageQ                   31.9159
2017-06-10 22:46:16.465569 EDT | AverageAbsQ                31.9504
2017-06-10 22:46:16.465757 EDT | AverageY                   31.9148
2017-06-10 22:46:16.465954 EDT | AverageAbsY                31.9327
2017-06-10 22:46:16.466145 EDT | AverageAbsQYDiff            0.599643
2017-06-10 22:46:16.466336 EDT | AverageAction               0.956034
2017-06-10 22:46:16.466522 EDT | PolicyRegParamNorm         72.0857
2017-06-10 22:46:16.466699 EDT | QFunRegParamNorm           91.2765
2017-06-10 22:46:16.466887 EDT | -----------------------  -----------
2017-06-10 22:46:16.467177 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #464 | Training started
2017-06-10 22:46:32.719033 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #464 | Training finished
2017-06-10 22:46:32.719841 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #464 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 22:46:32.720075 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #464 | Collecting samples for evaluation
2017-06-10 22:46:45.091497 EDT | -----------------------  -----------
2017-06-10 22:46:45.092307 EDT | Epoch                     464
2017-06-10 22:46:45.092624 EDT | Iteration                 464
2017-06-10 22:46:45.092930 EDT | AverageReturn            2043.8
2017-06-10 22:46:45.093268 EDT | StdReturn                 848.455
2017-06-10 22:46:45.093606 EDT | MaxReturn                2849.6
2017-06-10 22:46:45.093946 EDT | MinReturn                 689.574
2017-06-10 22:46:45.094234 EDT | AverageEsReturn           356.183
2017-06-10 22:46:45.094511 EDT | StdEsReturn               257.057
2017-06-10 22:46:45.094823 EDT | MaxEsReturn               955.189
2017-06-10 22:46:45.095150 EDT | MinEsReturn                90.7696
2017-06-10 22:46:45.095486 EDT | AverageDiscountedReturn   233.529
2017-06-10 22:46:45.095715 EDT | AverageQLoss                3.02819
2017-06-10 22:46:45.096011 EDT | AveragePolicySurr         -32.4593
2017-06-10 22:46:45.096329 EDT | AverageQ                   32.0279
2017-06-10 22:46:45.096663 EDT | AverageAbsQ                32.0624
2017-06-10 22:46:45.096998 EDT | AverageY                   32.0316
2017-06-10 22:46:45.097326 EDT | AverageAbsY                32.048
2017-06-10 22:46:45.097629 EDT | AverageAbsQYDiff            0.641953
2017-06-10 22:46:45.097973 EDT | AverageAction               0.945301
2017-06-10 22:46:45.098977 EDT | PolicyRegParamNorm         72.1313
2017-06-10 22:46:45.099312 EDT | QFunRegParamNorm           91.371
2017-06-10 22:46:45.099690 EDT | -----------------------  -----------
2017-06-10 22:46:45.101016 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #465 | Training started
2017-06-10 22:47:01.064178 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #465 | Training finished
2017-06-10 22:47:01.065124 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #465 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 22:47:01.065531 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #465 | Collecting samples for evaluation
2017-06-10 22:47:13.602236 EDT | -----------------------  -----------
2017-06-10 22:47:13.602725 EDT | Epoch                     465
2017-06-10 22:47:13.603138 EDT | Iteration                 465
2017-06-10 22:47:13.604099 EDT | AverageReturn            1380.39
2017-06-10 22:47:13.604487 EDT | StdReturn                 478.916
2017-06-10 22:47:13.604918 EDT | MaxReturn                2836.26
2017-06-10 22:47:13.605338 EDT | MinReturn                 676.012
2017-06-10 22:47:13.605770 EDT | AverageEsReturn           560.61
2017-06-10 22:47:13.606140 EDT | StdEsReturn               267.31
2017-06-10 22:47:13.606550 EDT | MaxEsReturn               843.822
2017-06-10 22:47:13.606945 EDT | MinEsReturn                90.5833
2017-06-10 22:47:13.607369 EDT | AverageDiscountedReturn   240.873
2017-06-10 22:47:13.607874 EDT | AverageQLoss                3.33998
2017-06-10 22:47:13.609193 EDT | AveragePolicySurr         -32.4792
2017-06-10 22:47:13.609938 EDT | AverageQ                   31.9878
2017-06-10 22:47:13.610431 EDT | AverageAbsQ                32.0188
2017-06-10 22:47:13.610841 EDT | AverageY                   31.9889
2017-06-10 22:47:13.611028 EDT | AverageAbsY                32.0073
2017-06-10 22:47:13.611214 EDT | AverageAbsQYDiff            0.667707
2017-06-10 22:47:13.611401 EDT | AverageAction               0.901444
2017-06-10 22:47:13.611582 EDT | PolicyRegParamNorm         72.1441
2017-06-10 22:47:13.611768 EDT | QFunRegParamNorm           91.5149
2017-06-10 22:47:13.612157 EDT | -----------------------  -----------
2017-06-10 22:47:13.612462 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #466 | Training started
2017-06-10 22:47:29.064977 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #466 | Training finished
2017-06-10 22:47:29.065794 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #466 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 22:47:29.066736 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #466 | Collecting samples for evaluation
2017-06-10 22:47:42.224457 EDT | -----------------------  -----------
2017-06-10 22:47:42.224899 EDT | Epoch                     466
2017-06-10 22:47:42.225306 EDT | Iteration                 466
2017-06-10 22:47:42.225653 EDT | AverageReturn            1033.1
2017-06-10 22:47:42.225999 EDT | StdReturn                 167.185
2017-06-10 22:47:42.226344 EDT | MaxReturn                1362.6
2017-06-10 22:47:42.226666 EDT | MinReturn                 606.579
2017-06-10 22:47:42.227279 EDT | AverageEsReturn           287.204
2017-06-10 22:47:42.228374 EDT | StdEsReturn               252.432
2017-06-10 22:47:42.228690 EDT | MaxEsReturn               765.599
2017-06-10 22:47:42.229171 EDT | MinEsReturn                79.4039
2017-06-10 22:47:42.229453 EDT | AverageDiscountedReturn   232.657
2017-06-10 22:47:42.229726 EDT | AverageQLoss                2.21308
2017-06-10 22:47:42.229948 EDT | AveragePolicySurr         -32.44
2017-06-10 22:47:42.230113 EDT | AverageQ                   31.9659
2017-06-10 22:47:42.230411 EDT | AverageAbsQ                32.0038
2017-06-10 22:47:42.230578 EDT | AverageY                   31.9671
2017-06-10 22:47:42.230757 EDT | AverageAbsY                31.9902
2017-06-10 22:47:42.230914 EDT | AverageAbsQYDiff            0.606179
2017-06-10 22:47:42.231365 EDT | AverageAction               0.904801
2017-06-10 22:47:42.233341 EDT | PolicyRegParamNorm         72.1936
2017-06-10 22:47:42.233533 EDT | QFunRegParamNorm           91.6012
2017-06-10 22:47:42.233728 EDT | -----------------------  -----------
2017-06-10 22:47:42.234231 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #467 | Training started
2017-06-10 22:47:57.397385 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #467 | Training finished
2017-06-10 22:47:57.398309 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #467 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 22:47:57.398605 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #467 | Collecting samples for evaluation
2017-06-10 22:48:10.850977 EDT | -----------------------  -----------
2017-06-10 22:48:10.851868 EDT | Epoch                     467
2017-06-10 22:48:10.852054 EDT | Iteration                 467
2017-06-10 22:48:10.852813 EDT | AverageReturn            1262.71
2017-06-10 22:48:10.853421 EDT | StdReturn                 451.821
2017-06-10 22:48:10.853807 EDT | MaxReturn                2303.45
2017-06-10 22:48:10.854146 EDT | MinReturn                 716.693
2017-06-10 22:48:10.854522 EDT | AverageEsReturn           287.815
2017-06-10 22:48:10.855392 EDT | StdEsReturn               244.452
2017-06-10 22:48:10.855685 EDT | MaxEsReturn               734.749
2017-06-10 22:48:10.855873 EDT | MinEsReturn                40.6904
2017-06-10 22:48:10.856035 EDT | AverageDiscountedReturn   230.845
2017-06-10 22:48:10.856194 EDT | AverageQLoss                2.86248
2017-06-10 22:48:10.856351 EDT | AveragePolicySurr         -32.4507
2017-06-10 22:48:10.856507 EDT | AverageQ                   31.9158
2017-06-10 22:48:10.856775 EDT | AverageAbsQ                31.9581
2017-06-10 22:48:10.856943 EDT | AverageY                   31.918
2017-06-10 22:48:10.857206 EDT | AverageAbsY                31.9455
2017-06-10 22:48:10.857535 EDT | AverageAbsQYDiff            0.633153
2017-06-10 22:48:10.857725 EDT | AverageAction               0.887072
2017-06-10 22:48:10.857990 EDT | PolicyRegParamNorm         72.2394
2017-06-10 22:48:10.858176 EDT | QFunRegParamNorm           91.6434
2017-06-10 22:48:10.858380 EDT | -----------------------  -----------
2017-06-10 22:48:10.858687 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #468 | Training started
2017-06-10 22:48:26.448254 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #468 | Training finished
2017-06-10 22:48:26.449442 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #468 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 22:48:26.449982 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #468 | Collecting samples for evaluation
2017-06-10 22:48:39.721769 EDT | -----------------------  -----------
2017-06-10 22:48:39.722940 EDT | Epoch                     468
2017-06-10 22:48:39.723824 EDT | Iteration                 468
2017-06-10 22:48:39.724186 EDT | AverageReturn            1738.72
2017-06-10 22:48:39.724538 EDT | StdReturn                 557.249
2017-06-10 22:48:39.724926 EDT | MaxReturn                2719.47
2017-06-10 22:48:39.725306 EDT | MinReturn                 933.714
2017-06-10 22:48:39.725650 EDT | AverageEsReturn           422.381
2017-06-10 22:48:39.726069 EDT | StdEsReturn               526.858
2017-06-10 22:48:39.726443 EDT | MaxEsReturn              1325.53
2017-06-10 22:48:39.726788 EDT | MinEsReturn                19.5029
2017-06-10 22:48:39.727129 EDT | AverageDiscountedReturn   228.707
2017-06-10 22:48:39.731408 EDT | AverageQLoss                3.04189
2017-06-10 22:48:39.732996 EDT | AveragePolicySurr         -32.4881
2017-06-10 22:48:39.738644 EDT | AverageQ                   32.0145
2017-06-10 22:48:39.739714 EDT | AverageAbsQ                32.0444
2017-06-10 22:48:39.740738 EDT | AverageY                   32.0159
2017-06-10 22:48:39.741683 EDT | AverageAbsY                32.0325
2017-06-10 22:48:39.742647 EDT | AverageAbsQYDiff            0.635677
2017-06-10 22:48:39.743576 EDT | AverageAction               0.922677
2017-06-10 22:48:39.744492 EDT | PolicyRegParamNorm         72.3143
2017-06-10 22:48:39.745401 EDT | QFunRegParamNorm           91.6841
2017-06-10 22:48:39.746289 EDT | -----------------------  -----------
2017-06-10 22:48:39.747569 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #469 | Training started
2017-06-10 22:48:56.049470 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #469 | Training finished
2017-06-10 22:48:56.050442 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #469 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 22:48:56.050710 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #469 | Collecting samples for evaluation
2017-06-10 22:49:08.180053 EDT | -----------------------  -----------
2017-06-10 22:49:08.181322 EDT | Epoch                     469
2017-06-10 22:49:08.181806 EDT | Iteration                 469
2017-06-10 22:49:08.184698 EDT | AverageReturn            1273.07
2017-06-10 22:49:08.185167 EDT | StdReturn                 495.069
2017-06-10 22:49:08.185617 EDT | MaxReturn                2483.68
2017-06-10 22:49:08.186075 EDT | MinReturn                 303.435
2017-06-10 22:49:08.186519 EDT | AverageEsReturn           549.877
2017-06-10 22:49:08.186966 EDT | StdEsReturn               590.324
2017-06-10 22:49:08.187409 EDT | MaxEsReturn              1473.62
2017-06-10 22:49:08.187853 EDT | MinEsReturn                11.1281
2017-06-10 22:49:08.188295 EDT | AverageDiscountedReturn   229.605
2017-06-10 22:49:08.188737 EDT | AverageQLoss                2.53098
2017-06-10 22:49:08.189182 EDT | AveragePolicySurr         -32.5327
2017-06-10 22:49:08.189629 EDT | AverageQ                   32.0527
2017-06-10 22:49:08.190088 EDT | AverageAbsQ                32.0896
2017-06-10 22:49:08.190534 EDT | AverageY                   32.0543
2017-06-10 22:49:08.190979 EDT | AverageAbsY                32.0766
2017-06-10 22:49:08.191421 EDT | AverageAbsQYDiff            0.617467
2017-06-10 22:49:08.191870 EDT | AverageAction               0.910326
2017-06-10 22:49:08.192316 EDT | PolicyRegParamNorm         72.3896
2017-06-10 22:49:08.192757 EDT | QFunRegParamNorm           91.8059
2017-06-10 22:49:08.193200 EDT | -----------------------  -----------
2017-06-10 22:49:08.193825 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #470 | Training started
2017-06-10 22:49:23.026363 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #470 | Training finished
2017-06-10 22:49:23.027383 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #470 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 22:49:23.027584 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #470 | Collecting samples for evaluation
2017-06-10 22:49:36.863498 EDT | -----------------------  -----------
2017-06-10 22:49:37.219481 EDT | Epoch                     470
2017-06-10 22:49:37.219761 EDT | Iteration                 470
2017-06-10 22:49:37.220054 EDT | AverageReturn             706.027
2017-06-10 22:49:37.220334 EDT | StdReturn                  74.3789
2017-06-10 22:49:37.220699 EDT | MaxReturn                1051.31
2017-06-10 22:49:37.220948 EDT | MinReturn                 570.132
2017-06-10 22:49:37.221111 EDT | AverageEsReturn           519.084
2017-06-10 22:49:37.221280 EDT | StdEsReturn               241.455
2017-06-10 22:49:37.221465 EDT | MaxEsReturn               853.302
2017-06-10 22:49:37.221626 EDT | MinEsReturn               204.856
2017-06-10 22:49:37.221892 EDT | AverageDiscountedReturn   224.695
2017-06-10 22:49:37.222256 EDT | AverageQLoss                2.85975
2017-06-10 22:49:37.222678 EDT | AveragePolicySurr         -32.5724
2017-06-10 22:49:37.223102 EDT | AverageQ                   32.097
2017-06-10 22:49:37.223527 EDT | AverageAbsQ                32.1326
2017-06-10 22:49:37.223948 EDT | AverageY                   32.098
2017-06-10 22:49:37.224346 EDT | AverageAbsY                32.1221
2017-06-10 22:49:37.224770 EDT | AverageAbsQYDiff            0.628683
2017-06-10 22:49:37.225101 EDT | AverageAction               0.889168
2017-06-10 22:49:37.225503 EDT | PolicyRegParamNorm         72.3947
2017-06-10 22:49:37.225932 EDT | QFunRegParamNorm           91.8922
2017-06-10 22:49:37.226224 EDT | -----------------------  -----------
2017-06-10 22:49:37.226687 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #471 | Training started
2017-06-10 22:49:52.142956 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #471 | Training finished
2017-06-10 22:49:52.144011 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #471 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 22:49:52.144405 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #471 | Collecting samples for evaluation
2017-06-10 22:50:05.563937 EDT | -----------------------  -----------
2017-06-10 22:50:05.578699 EDT | Epoch                     471
2017-06-10 22:50:05.578978 EDT | Iteration                 471
2017-06-10 22:50:05.579213 EDT | AverageReturn             965.817
2017-06-10 22:50:05.579404 EDT | StdReturn                 354.33
2017-06-10 22:50:05.579597 EDT | MaxReturn                2537
2017-06-10 22:50:05.579780 EDT | MinReturn                 565.891
2017-06-10 22:50:05.579961 EDT | AverageEsReturn           325.713
2017-06-10 22:50:05.580141 EDT | StdEsReturn               189.79
2017-06-10 22:50:05.580326 EDT | MaxEsReturn               633.234
2017-06-10 22:50:05.580506 EDT | MinEsReturn                46.4916
2017-06-10 22:50:05.580690 EDT | AverageDiscountedReturn   220.606
2017-06-10 22:50:05.580871 EDT | AverageQLoss                2.50062
2017-06-10 22:50:05.581050 EDT | AveragePolicySurr         -32.5854
2017-06-10 22:50:05.581243 EDT | AverageQ                   32.1318
2017-06-10 22:50:05.581421 EDT | AverageAbsQ                32.1653
2017-06-10 22:50:05.581600 EDT | AverageY                   32.1321
2017-06-10 22:50:05.581906 EDT | AverageAbsY                32.1509
2017-06-10 22:50:05.582229 EDT | AverageAbsQYDiff            0.594849
2017-06-10 22:50:05.582555 EDT | AverageAction               0.902607
2017-06-10 22:50:05.582877 EDT | PolicyRegParamNorm         72.4406
2017-06-10 22:50:05.583199 EDT | QFunRegParamNorm           91.9464
2017-06-10 22:50:05.583521 EDT | -----------------------  -----------
2017-06-10 22:50:05.584049 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #472 | Training started
2017-06-10 22:50:21.051425 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #472 | Training finished
2017-06-10 22:50:21.052490 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #472 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 22:50:21.052907 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #472 | Collecting samples for evaluation
2017-06-10 22:50:34.289418 EDT | -----------------------  -----------
2017-06-10 22:50:34.290151 EDT | Epoch                     472
2017-06-10 22:50:34.290491 EDT | Iteration                 472
2017-06-10 22:50:34.291109 EDT | AverageReturn            1292.97
2017-06-10 22:50:34.291334 EDT | StdReturn                 388.62
2017-06-10 22:50:34.291492 EDT | MaxReturn                2411.54
2017-06-10 22:50:34.291770 EDT | MinReturn                 772.009
2017-06-10 22:50:34.291943 EDT | AverageEsReturn           426.085
2017-06-10 22:50:34.292112 EDT | StdEsReturn               266.792
2017-06-10 22:50:34.292279 EDT | MaxEsReturn               957.17
2017-06-10 22:50:34.292445 EDT | MinEsReturn               205.452
2017-06-10 22:50:34.292610 EDT | AverageDiscountedReturn   243.253
2017-06-10 22:50:34.292776 EDT | AverageQLoss                2.51524
2017-06-10 22:50:34.292941 EDT | AveragePolicySurr         -32.4623
2017-06-10 22:50:34.293105 EDT | AverageQ                   31.9628
2017-06-10 22:50:34.293270 EDT | AverageAbsQ                32.0067
2017-06-10 22:50:34.293446 EDT | AverageY                   31.9662
2017-06-10 22:50:34.293631 EDT | AverageAbsY                31.9935
2017-06-10 22:50:34.293824 EDT | AverageAbsQYDiff            0.625071
2017-06-10 22:50:34.294002 EDT | AverageAction               0.885651
2017-06-10 22:50:34.294161 EDT | PolicyRegParamNorm         72.527
2017-06-10 22:50:34.294317 EDT | QFunRegParamNorm           92.0175
2017-06-10 22:50:34.294473 EDT | -----------------------  -----------
2017-06-10 22:50:34.294740 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #473 | Training started
2017-06-10 22:50:50.135846 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #473 | Training finished
2017-06-10 22:50:50.136888 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #473 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 22:50:50.137292 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #473 | Collecting samples for evaluation
2017-06-10 22:51:03.550419 EDT | -----------------------  -----------
2017-06-10 22:51:03.552337 EDT | Epoch                     473
2017-06-10 22:51:03.552852 EDT | Iteration                 473
2017-06-10 22:51:03.554260 EDT | AverageReturn            1434.14
2017-06-10 22:51:03.555875 EDT | StdReturn                 709.538
2017-06-10 22:51:03.557389 EDT | MaxReturn                2668.11
2017-06-10 22:51:03.558809 EDT | MinReturn                 288.695
2017-06-10 22:51:03.560237 EDT | AverageEsReturn           381.766
2017-06-10 22:51:03.561621 EDT | StdEsReturn               176.574
2017-06-10 22:51:03.563310 EDT | MaxEsReturn               698.397
2017-06-10 22:51:03.565094 EDT | MinEsReturn               186.903
2017-06-10 22:51:03.566825 EDT | AverageDiscountedReturn   221.447
2017-06-10 22:51:03.567191 EDT | AverageQLoss                2.45672
2017-06-10 22:51:03.567515 EDT | AveragePolicySurr         -32.6055
2017-06-10 22:51:03.567924 EDT | AverageQ                   32.1673
2017-06-10 22:51:03.568317 EDT | AverageAbsQ                32.1992
2017-06-10 22:51:03.568748 EDT | AverageY                   32.1657
2017-06-10 22:51:03.569152 EDT | AverageAbsY                32.1896
2017-06-10 22:51:03.569558 EDT | AverageAbsQYDiff            0.605353
2017-06-10 22:51:03.569945 EDT | AverageAction               0.922372
2017-06-10 22:51:03.570611 EDT | PolicyRegParamNorm         72.5468
2017-06-10 22:51:03.570895 EDT | QFunRegParamNorm           92.1177
2017-06-10 22:51:03.571160 EDT | -----------------------  -----------
2017-06-10 22:51:03.571616 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #474 | Training started
2017-06-10 22:51:19.426251 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #474 | Training finished
2017-06-10 22:51:19.428679 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #474 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 22:51:19.430182 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #474 | Collecting samples for evaluation
2017-06-10 22:51:32.402866 EDT | -----------------------  ----------
2017-06-10 22:51:32.403672 EDT | Epoch                    474
2017-06-10 22:51:32.405614 EDT | Iteration                474
2017-06-10 22:51:32.406748 EDT | AverageReturn            314.336
2017-06-10 22:51:32.407389 EDT | StdReturn                227.811
2017-06-10 22:51:32.408674 EDT | MaxReturn                964.05
2017-06-10 22:51:32.409476 EDT | MinReturn                148.739
2017-06-10 22:51:32.410250 EDT | AverageEsReturn          297.537
2017-06-10 22:51:32.410682 EDT | StdEsReturn              289.732
2017-06-10 22:51:32.411167 EDT | MaxEsReturn              950.684
2017-06-10 22:51:32.411545 EDT | MinEsReturn               51.2495
2017-06-10 22:51:32.411869 EDT | AverageDiscountedReturn  142.134
2017-06-10 22:51:32.412339 EDT | AverageQLoss               2.51889
2017-06-10 22:51:32.412765 EDT | AveragePolicySurr        -32.5292
2017-06-10 22:51:32.413083 EDT | AverageQ                  32.0729
2017-06-10 22:51:32.413410 EDT | AverageAbsQ               32.1088
2017-06-10 22:51:32.413640 EDT | AverageY                  32.0751
2017-06-10 22:51:32.414256 EDT | AverageAbsY               32.1027
2017-06-10 22:51:32.414560 EDT | AverageAbsQYDiff           0.610786
2017-06-10 22:51:32.414905 EDT | AverageAction              0.951922
2017-06-10 22:51:32.415227 EDT | PolicyRegParamNorm        72.5976
2017-06-10 22:51:32.415504 EDT | QFunRegParamNorm          92.1798
2017-06-10 22:51:32.415689 EDT | -----------------------  ----------
2017-06-10 22:51:32.416676 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #475 | Training started
2017-06-10 22:51:49.211206 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #475 | Training finished
2017-06-10 22:51:49.212187 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #475 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 22:51:49.212548 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #475 | Collecting samples for evaluation
2017-06-10 22:52:01.993259 EDT | -----------------------  -----------
2017-06-10 22:52:01.994410 EDT | Epoch                     475
2017-06-10 22:52:01.995078 EDT | Iteration                 475
2017-06-10 22:52:01.995456 EDT | AverageReturn             927.286
2017-06-10 22:52:01.995882 EDT | StdReturn                 347.071
2017-06-10 22:52:01.996250 EDT | MaxReturn                1963.62
2017-06-10 22:52:01.996725 EDT | MinReturn                 541.291
2017-06-10 22:52:01.997168 EDT | AverageEsReturn           706.569
2017-06-10 22:52:01.997705 EDT | StdEsReturn               263.301
2017-06-10 22:52:01.998151 EDT | MaxEsReturn               996.172
2017-06-10 22:52:01.998502 EDT | MinEsReturn               359.064
2017-06-10 22:52:01.998859 EDT | AverageDiscountedReturn   203.943
2017-06-10 22:52:01.999217 EDT | AverageQLoss                2.47453
2017-06-10 22:52:01.999561 EDT | AveragePolicySurr         -32.5543
2017-06-10 22:52:01.999905 EDT | AverageQ                   32.1014
2017-06-10 22:52:02.000347 EDT | AverageAbsQ                32.1381
2017-06-10 22:52:02.000698 EDT | AverageY                   32.1023
2017-06-10 22:52:02.001039 EDT | AverageAbsY                32.1224
2017-06-10 22:52:02.001409 EDT | AverageAbsQYDiff            0.60764
2017-06-10 22:52:02.001872 EDT | AverageAction               0.931509
2017-06-10 22:52:02.002350 EDT | PolicyRegParamNorm         72.6612
2017-06-10 22:52:02.002796 EDT | QFunRegParamNorm           92.25
2017-06-10 22:52:02.003235 EDT | -----------------------  -----------
2017-06-10 22:52:02.003851 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #476 | Training started
2017-06-10 22:52:17.482914 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #476 | Training finished
2017-06-10 22:52:17.483835 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #476 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 22:52:17.484216 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #476 | Collecting samples for evaluation
2017-06-10 22:52:30.873049 EDT | -----------------------  ----------
2017-06-10 22:52:30.873922 EDT | Epoch                    476
2017-06-10 22:52:30.874113 EDT | Iteration                476
2017-06-10 22:52:30.874307 EDT | AverageReturn            609.702
2017-06-10 22:52:30.874492 EDT | StdReturn                221.991
2017-06-10 22:52:30.874674 EDT | MaxReturn                901.861
2017-06-10 22:52:30.874856 EDT | MinReturn                 62.757
2017-06-10 22:52:30.875044 EDT | AverageEsReturn          458.907
2017-06-10 22:52:30.875223 EDT | StdEsReturn              220.531
2017-06-10 22:52:30.875401 EDT | MaxEsReturn              786.361
2017-06-10 22:52:30.875579 EDT | MinEsReturn                8.9029
2017-06-10 22:52:30.875756 EDT | AverageDiscountedReturn  195.141
2017-06-10 22:52:30.876008 EDT | AverageQLoss               2.71131
2017-06-10 22:52:30.876272 EDT | AveragePolicySurr        -32.5758
2017-06-10 22:52:30.876522 EDT | AverageQ                  32.1078
2017-06-10 22:52:30.878111 EDT | AverageAbsQ               32.1446
2017-06-10 22:52:30.878417 EDT | AverageY                  32.1118
2017-06-10 22:52:30.878629 EDT | AverageAbsY               32.1368
2017-06-10 22:52:30.878792 EDT | AverageAbsQYDiff           0.619683
2017-06-10 22:52:30.878992 EDT | AverageAction              0.946328
2017-06-10 22:52:30.879160 EDT | PolicyRegParamNorm        72.7322
2017-06-10 22:52:30.879315 EDT | QFunRegParamNorm          92.3656
2017-06-10 22:52:30.879477 EDT | -----------------------  ----------
2017-06-10 22:52:30.879762 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #477 | Training started
2017-06-10 22:52:45.959696 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #477 | Training finished
2017-06-10 22:52:45.960462 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #477 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 22:52:45.960672 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #477 | Collecting samples for evaluation
2017-06-10 22:52:59.156778 EDT | -----------------------  -----------
2017-06-10 22:52:59.157738 EDT | Epoch                     477
2017-06-10 22:52:59.158109 EDT | Iteration                 477
2017-06-10 22:52:59.158454 EDT | AverageReturn             469.387
2017-06-10 22:52:59.158826 EDT | StdReturn                 202.342
2017-06-10 22:52:59.159165 EDT | MaxReturn                1029.81
2017-06-10 22:52:59.159511 EDT | MinReturn                  60.733
2017-06-10 22:52:59.159878 EDT | AverageEsReturn           310.19
2017-06-10 22:52:59.160220 EDT | StdEsReturn               241.51
2017-06-10 22:52:59.160559 EDT | MaxEsReturn               750.204
2017-06-10 22:52:59.160926 EDT | MinEsReturn                 7.17408
2017-06-10 22:52:59.161265 EDT | AverageDiscountedReturn   176.913
2017-06-10 22:52:59.161607 EDT | AverageQLoss                2.71512
2017-06-10 22:52:59.161990 EDT | AveragePolicySurr         -32.5715
2017-06-10 22:52:59.162339 EDT | AverageQ                   32.1073
2017-06-10 22:52:59.162678 EDT | AverageAbsQ                32.1458
2017-06-10 22:52:59.163040 EDT | AverageY                   32.108
2017-06-10 22:52:59.163380 EDT | AverageAbsY                32.129
2017-06-10 22:52:59.163721 EDT | AverageAbsQYDiff            0.627945
2017-06-10 22:52:59.164084 EDT | AverageAction               0.91193
2017-06-10 22:52:59.164425 EDT | PolicyRegParamNorm         72.829
2017-06-10 22:52:59.165344 EDT | QFunRegParamNorm           92.4333
2017-06-10 22:52:59.166016 EDT | -----------------------  -----------
2017-06-10 22:52:59.168652 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #478 | Training started
2017-06-10 22:53:14.508663 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #478 | Training finished
2017-06-10 22:53:14.509634 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #478 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 22:53:14.510056 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #478 | Collecting samples for evaluation
2017-06-10 22:53:26.686422 EDT | -----------------------  -----------
2017-06-10 22:53:26.687503 EDT | Epoch                     478
2017-06-10 22:53:26.687946 EDT | Iteration                 478
2017-06-10 22:53:26.688329 EDT | AverageReturn             876.772
2017-06-10 22:53:26.688770 EDT | StdReturn                 368.224
2017-06-10 22:53:26.689134 EDT | MaxReturn                1767.24
2017-06-10 22:53:26.689635 EDT | MinReturn                 373.908
2017-06-10 22:53:26.690070 EDT | AverageEsReturn           130.217
2017-06-10 22:53:26.690495 EDT | StdEsReturn               147.702
2017-06-10 22:53:26.690775 EDT | MaxEsReturn               567.904
2017-06-10 22:53:26.691202 EDT | MinEsReturn                28.14
2017-06-10 22:53:26.691611 EDT | AverageDiscountedReturn   213.068
2017-06-10 22:53:26.692001 EDT | AverageQLoss                3.30804
2017-06-10 22:53:26.692311 EDT | AveragePolicySurr         -32.5417
2017-06-10 22:53:26.692555 EDT | AverageQ                   32.0742
2017-06-10 22:53:26.692799 EDT | AverageAbsQ                32.1071
2017-06-10 22:53:26.693038 EDT | AverageY                   32.075
2017-06-10 22:53:26.693286 EDT | AverageAbsY                32.0956
2017-06-10 22:53:26.693625 EDT | AverageAbsQYDiff            0.659727
2017-06-10 22:53:26.693902 EDT | AverageAction               0.909482
2017-06-10 22:53:26.694166 EDT | PolicyRegParamNorm         72.8943
2017-06-10 22:53:26.694386 EDT | QFunRegParamNorm           92.516
2017-06-10 22:53:26.694546 EDT | -----------------------  -----------
2017-06-10 22:53:26.694787 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #479 | Training started
2017-06-10 22:53:43.227890 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #479 | Training finished
2017-06-10 22:53:43.230316 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #479 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 22:53:43.230608 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #479 | Collecting samples for evaluation
2017-06-10 22:53:54.902588 EDT | -----------------------  -----------
2017-06-10 22:53:54.903144 EDT | Epoch                     479
2017-06-10 22:53:54.903492 EDT | Iteration                 479
2017-06-10 22:53:54.903841 EDT | AverageReturn            1108.59
2017-06-10 22:53:54.904291 EDT | StdReturn                 485.461
2017-06-10 22:53:54.904637 EDT | MaxReturn                2588.59
2017-06-10 22:53:54.904976 EDT | MinReturn                  57.7341
2017-06-10 22:53:54.905322 EDT | AverageEsReturn           323.699
2017-06-10 22:53:54.905766 EDT | StdEsReturn               194.219
2017-06-10 22:53:54.906102 EDT | MaxEsReturn               712.439
2017-06-10 22:53:54.906449 EDT | MinEsReturn               121.897
2017-06-10 22:53:54.906888 EDT | AverageDiscountedReturn   215.259
2017-06-10 22:53:54.907228 EDT | AverageQLoss                2.42712
2017-06-10 22:53:54.907570 EDT | AveragePolicySurr         -32.6611
2017-06-10 22:53:54.908017 EDT | AverageQ                   32.2009
2017-06-10 22:53:54.908356 EDT | AverageAbsQ                32.2373
2017-06-10 22:53:54.908695 EDT | AverageY                   32.2023
2017-06-10 22:53:54.909040 EDT | AverageAbsY                32.227
2017-06-10 22:53:54.909490 EDT | AverageAbsQYDiff            0.597609
2017-06-10 22:53:54.909835 EDT | AverageAction               0.913595
2017-06-10 22:53:54.910180 EDT | PolicyRegParamNorm         72.9483
2017-06-10 22:53:54.910614 EDT | QFunRegParamNorm           92.5744
2017-06-10 22:53:54.910950 EDT | -----------------------  -----------
2017-06-10 22:53:54.911446 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #480 | Training started
2017-06-10 22:54:10.767495 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #480 | Training finished
2017-06-10 22:54:10.768250 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #480 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 22:54:10.768531 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #480 | Collecting samples for evaluation
2017-06-10 22:54:24.178467 EDT | -----------------------  -----------
2017-06-10 22:54:24.179116 EDT | Epoch                     480
2017-06-10 22:54:24.179571 EDT | Iteration                 480
2017-06-10 22:54:24.180021 EDT | AverageReturn             761.139
2017-06-10 22:54:24.180468 EDT | StdReturn                 182.119
2017-06-10 22:54:24.180916 EDT | MaxReturn                1380.29
2017-06-10 22:54:24.181367 EDT | MinReturn                 556.651
2017-06-10 22:54:24.181811 EDT | AverageEsReturn           658.022
2017-06-10 22:54:24.182160 EDT | StdEsReturn               380.673
2017-06-10 22:54:24.182497 EDT | MaxEsReturn              1080.2
2017-06-10 22:54:24.182838 EDT | MinEsReturn               157.639
2017-06-10 22:54:24.183166 EDT | AverageDiscountedReturn   215.686
2017-06-10 22:54:24.183492 EDT | AverageQLoss                2.67503
2017-06-10 22:54:24.183817 EDT | AveragePolicySurr         -32.5734
2017-06-10 22:54:24.184143 EDT | AverageQ                   32.0849
2017-06-10 22:54:24.184477 EDT | AverageAbsQ                32.115
2017-06-10 22:54:24.184803 EDT | AverageY                   32.0874
2017-06-10 22:54:24.185126 EDT | AverageAbsY                32.1009
2017-06-10 22:54:24.185452 EDT | AverageAbsQYDiff            0.62194
2017-06-10 22:54:24.185789 EDT | AverageAction               0.899764
2017-06-10 22:54:24.186121 EDT | PolicyRegParamNorm         73.0202
2017-06-10 22:54:24.186445 EDT | QFunRegParamNorm           92.6594
2017-06-10 22:54:24.186853 EDT | -----------------------  -----------
2017-06-10 22:54:24.187589 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #481 | Training started
2017-06-10 22:54:38.644944 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #481 | Training finished
2017-06-10 22:54:38.659649 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #481 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 22:54:38.660019 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #481 | Collecting samples for evaluation
2017-06-10 22:54:51.867147 EDT | -----------------------  -----------
2017-06-10 22:54:51.867916 EDT | Epoch                     481
2017-06-10 22:54:51.868120 EDT | Iteration                 481
2017-06-10 22:54:51.868308 EDT | AverageReturn             965.81
2017-06-10 22:54:51.868528 EDT | StdReturn                 508.988
2017-06-10 22:54:51.868712 EDT | MaxReturn                2399.2
2017-06-10 22:54:51.868893 EDT | MinReturn                  90.2759
2017-06-10 22:54:51.869175 EDT | AverageEsReturn           420.792
2017-06-10 22:54:51.869473 EDT | StdEsReturn               253.421
2017-06-10 22:54:51.869833 EDT | MaxEsReturn               844.216
2017-06-10 22:54:51.870154 EDT | MinEsReturn               138.224
2017-06-10 22:54:51.870444 EDT | AverageDiscountedReturn   204.323
2017-06-10 22:54:51.870793 EDT | AverageQLoss                2.77064
2017-06-10 22:54:51.871130 EDT | AveragePolicySurr         -32.6432
2017-06-10 22:54:51.871467 EDT | AverageQ                   32.1559
2017-06-10 22:54:51.871796 EDT | AverageAbsQ                32.1903
2017-06-10 22:54:51.872126 EDT | AverageY                   32.1584
2017-06-10 22:54:51.872468 EDT | AverageAbsY                32.1795
2017-06-10 22:54:51.872794 EDT | AverageAbsQYDiff            0.632569
2017-06-10 22:54:51.873116 EDT | AverageAction               0.919974
2017-06-10 22:54:51.873378 EDT | PolicyRegParamNorm         73.0903
2017-06-10 22:54:51.873561 EDT | QFunRegParamNorm           92.7673
2017-06-10 22:54:51.873777 EDT | -----------------------  -----------
2017-06-10 22:54:51.874072 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #482 | Training started
2017-06-10 22:55:06.985499 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #482 | Training finished
2017-06-10 22:55:06.986385 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #482 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 22:55:06.999549 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #482 | Collecting samples for evaluation
2017-06-10 22:55:18.921609 EDT | -----------------------  -----------
2017-06-10 22:55:18.921971 EDT | Epoch                     482
2017-06-10 22:55:18.922194 EDT | Iteration                 482
2017-06-10 22:55:18.922379 EDT | AverageReturn            1603.47
2017-06-10 22:55:18.922562 EDT | StdReturn                 531.175
2017-06-10 22:55:18.922815 EDT | MaxReturn                2528.3
2017-06-10 22:55:18.922997 EDT | MinReturn                 758.907
2017-06-10 22:55:18.923180 EDT | AverageEsReturn           396.792
2017-06-10 22:55:18.923386 EDT | StdEsReturn               383.815
2017-06-10 22:55:18.923566 EDT | MaxEsReturn               912.56
2017-06-10 22:55:18.923745 EDT | MinEsReturn                16.1089
2017-06-10 22:55:18.923930 EDT | AverageDiscountedReturn   219.016
2017-06-10 22:55:18.924127 EDT | AverageQLoss                2.47235
2017-06-10 22:55:18.924305 EDT | AveragePolicySurr         -32.6984
2017-06-10 22:55:18.924484 EDT | AverageQ                   32.268
2017-06-10 22:55:18.924660 EDT | AverageAbsQ                32.3016
2017-06-10 22:55:18.924974 EDT | AverageY                   32.27
2017-06-10 22:55:18.925157 EDT | AverageAbsY                32.2915
2017-06-10 22:55:18.925341 EDT | AverageAbsQYDiff            0.605574
2017-06-10 22:55:18.925564 EDT | AverageAction               0.932456
2017-06-10 22:55:18.925770 EDT | PolicyRegParamNorm         73.144
2017-06-10 22:55:18.925975 EDT | QFunRegParamNorm           92.8006
2017-06-10 22:55:18.926305 EDT | -----------------------  -----------
2017-06-10 22:55:18.926765 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #483 | Training started
2017-06-10 22:55:35.426596 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #483 | Training finished
2017-06-10 22:55:35.427366 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #483 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 22:55:35.427636 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #483 | Collecting samples for evaluation
2017-06-10 22:55:47.562370 EDT | -----------------------  -----------
2017-06-10 22:55:47.563790 EDT | Epoch                     483
2017-06-10 22:55:47.564127 EDT | Iteration                 483
2017-06-10 22:55:47.564462 EDT | AverageReturn             767.827
2017-06-10 22:55:47.564799 EDT | StdReturn                 129.809
2017-06-10 22:55:47.565078 EDT | MaxReturn                1022.11
2017-06-10 22:55:47.565405 EDT | MinReturn                 475.607
2017-06-10 22:55:47.565848 EDT | AverageEsReturn           240.629
2017-06-10 22:55:47.567043 EDT | StdEsReturn               266.982
2017-06-10 22:55:47.567424 EDT | MaxEsReturn               853.693
2017-06-10 22:55:47.567980 EDT | MinEsReturn                40.7037
2017-06-10 22:55:47.568256 EDT | AverageDiscountedReturn   220.376
2017-06-10 22:55:47.568808 EDT | AverageQLoss                2.64485
2017-06-10 22:55:47.569211 EDT | AveragePolicySurr         -32.7048
2017-06-10 22:55:47.569542 EDT | AverageQ                   32.2566
2017-06-10 22:55:47.569955 EDT | AverageAbsQ                32.298
2017-06-10 22:55:47.570361 EDT | AverageY                   32.2555
2017-06-10 22:55:47.570690 EDT | AverageAbsY                32.2848
2017-06-10 22:55:47.571029 EDT | AverageAbsQYDiff            0.622196
2017-06-10 22:55:47.571724 EDT | AverageAction               0.886414
2017-06-10 22:55:47.572062 EDT | PolicyRegParamNorm         73.1802
2017-06-10 22:55:47.572674 EDT | QFunRegParamNorm           92.8689
2017-06-10 22:55:47.573015 EDT | -----------------------  -----------
2017-06-10 22:55:47.573478 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #484 | Training started
2017-06-10 22:56:03.030486 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #484 | Training finished
2017-06-10 22:56:03.031244 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #484 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 22:56:03.031479 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #484 | Collecting samples for evaluation
2017-06-10 22:56:16.063737 EDT | -----------------------  -----------
2017-06-10 22:56:16.064748 EDT | Epoch                     484
2017-06-10 22:56:16.064995 EDT | Iteration                 484
2017-06-10 22:56:16.065186 EDT | AverageReturn             775.716
2017-06-10 22:56:16.065370 EDT | StdReturn                 276.836
2017-06-10 22:56:16.065552 EDT | MaxReturn                1563.59
2017-06-10 22:56:16.065815 EDT | MinReturn                 480.865
2017-06-10 22:56:16.066000 EDT | AverageEsReturn           452.396
2017-06-10 22:56:16.066214 EDT | StdEsReturn               219.613
2017-06-10 22:56:16.066486 EDT | MaxEsReturn               719.524
2017-06-10 22:56:16.066682 EDT | MinEsReturn               129.102
2017-06-10 22:56:16.066878 EDT | AverageDiscountedReturn   208.788
2017-06-10 22:56:16.067101 EDT | AverageQLoss                2.47693
2017-06-10 22:56:16.067337 EDT | AveragePolicySurr         -32.6667
2017-06-10 22:56:16.068459 EDT | AverageQ                   32.2366
2017-06-10 22:56:16.068819 EDT | AverageAbsQ                32.2762
2017-06-10 22:56:16.069111 EDT | AverageY                   32.2393
2017-06-10 22:56:16.069331 EDT | AverageAbsY                32.268
2017-06-10 22:56:16.069537 EDT | AverageAbsQYDiff            0.602072
2017-06-10 22:56:16.069722 EDT | AverageAction               0.909153
2017-06-10 22:56:16.070079 EDT | PolicyRegParamNorm         73.2463
2017-06-10 22:56:16.070409 EDT | QFunRegParamNorm           92.9672
2017-06-10 22:56:16.070670 EDT | -----------------------  -----------
2017-06-10 22:56:16.071107 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #485 | Training started
2017-06-10 22:56:31.643584 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #485 | Training finished
2017-06-10 22:56:31.657786 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #485 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 22:56:31.658345 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #485 | Collecting samples for evaluation
2017-06-10 22:56:43.959742 EDT | -----------------------  -----------
2017-06-10 22:56:43.960704 EDT | Epoch                     485
2017-06-10 22:56:43.961069 EDT | Iteration                 485
2017-06-10 22:56:43.961404 EDT | AverageReturn             806.923
2017-06-10 22:56:43.961764 EDT | StdReturn                 211.512
2017-06-10 22:56:43.962125 EDT | MaxReturn                1476.25
2017-06-10 22:56:43.962467 EDT | MinReturn                 522.181
2017-06-10 22:56:43.962809 EDT | AverageEsReturn           426.117
2017-06-10 22:56:43.963139 EDT | StdEsReturn               324.658
2017-06-10 22:56:43.963464 EDT | MaxEsReturn               892.218
2017-06-10 22:56:43.963788 EDT | MinEsReturn                51.0076
2017-06-10 22:56:43.964111 EDT | AverageDiscountedReturn   215.263
2017-06-10 22:56:43.964450 EDT | AverageQLoss                2.94784
2017-06-10 22:56:43.964790 EDT | AveragePolicySurr         -32.6076
2017-06-10 22:56:43.965137 EDT | AverageQ                   32.1511
2017-06-10 22:56:43.965478 EDT | AverageAbsQ                32.1927
2017-06-10 22:56:43.965825 EDT | AverageY                   32.1524
2017-06-10 22:56:43.966152 EDT | AverageAbsY                32.1801
2017-06-10 22:56:43.966473 EDT | AverageAbsQYDiff            0.644759
2017-06-10 22:56:43.966806 EDT | AverageAction               0.91595
2017-06-10 22:56:43.967160 EDT | PolicyRegParamNorm         73.3157
2017-06-10 22:56:43.967550 EDT | QFunRegParamNorm           93.0591
2017-06-10 22:56:43.967952 EDT | -----------------------  -----------
2017-06-10 22:56:43.968480 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #486 | Training started
2017-06-10 22:56:59.063627 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #486 | Training finished
2017-06-10 22:56:59.064574 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #486 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 22:56:59.064920 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #486 | Collecting samples for evaluation
2017-06-10 22:57:11.850069 EDT | -----------------------  -----------
2017-06-10 22:57:11.850913 EDT | Epoch                     486
2017-06-10 22:57:11.851106 EDT | Iteration                 486
2017-06-10 22:57:11.851269 EDT | AverageReturn            1056.05
2017-06-10 22:57:11.851426 EDT | StdReturn                 634.878
2017-06-10 22:57:11.851579 EDT | MaxReturn                2449.17
2017-06-10 22:57:11.851730 EDT | MinReturn                 284.121
2017-06-10 22:57:11.851882 EDT | AverageEsReturn           594.691
2017-06-10 22:57:11.852044 EDT | StdEsReturn               452.582
2017-06-10 22:57:11.852739 EDT | MaxEsReturn              1211.07
2017-06-10 22:57:11.852900 EDT | MinEsReturn                50.4588
2017-06-10 22:57:11.853065 EDT | AverageDiscountedReturn   209.457
2017-06-10 22:57:11.853222 EDT | AverageQLoss                2.67279
2017-06-10 22:57:11.853468 EDT | AveragePolicySurr         -32.5164
2017-06-10 22:57:11.853996 EDT | AverageQ                   32.0741
2017-06-10 22:57:11.854263 EDT | AverageAbsQ                32.112
2017-06-10 22:57:11.854518 EDT | AverageY                   32.0742
2017-06-10 22:57:11.856620 EDT | AverageAbsY                32.0959
2017-06-10 22:57:11.856931 EDT | AverageAbsQYDiff            0.622509
2017-06-10 22:57:11.857216 EDT | AverageAction               0.944998
2017-06-10 22:57:11.857559 EDT | PolicyRegParamNorm         73.3945
2017-06-10 22:57:11.857741 EDT | QFunRegParamNorm           93.1472
2017-06-10 22:57:11.857932 EDT | -----------------------  -----------
2017-06-10 22:57:11.858204 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #487 | Training started
2017-06-10 22:57:27.704413 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #487 | Training finished
2017-06-10 22:57:27.705223 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #487 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 22:57:27.705582 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #487 | Collecting samples for evaluation
2017-06-10 22:57:40.382421 EDT | -----------------------  -----------
2017-06-10 22:57:40.395063 EDT | Epoch                     487
2017-06-10 22:57:40.395969 EDT | Iteration                 487
2017-06-10 22:57:40.396362 EDT | AverageReturn            1063.13
2017-06-10 22:57:40.396793 EDT | StdReturn                 346.745
2017-06-10 22:57:40.397195 EDT | MaxReturn                2109.26
2017-06-10 22:57:40.397530 EDT | MinReturn                 635.61
2017-06-10 22:57:40.397841 EDT | AverageEsReturn           344.044
2017-06-10 22:57:40.398150 EDT | StdEsReturn               272.639
2017-06-10 22:57:40.398459 EDT | MaxEsReturn               706.004
2017-06-10 22:57:40.398764 EDT | MinEsReturn                17.1066
2017-06-10 22:57:40.399091 EDT | AverageDiscountedReturn   225.799
2017-06-10 22:57:40.400137 EDT | AverageQLoss                2.42255
2017-06-10 22:57:40.400474 EDT | AveragePolicySurr         -32.5327
2017-06-10 22:57:40.400803 EDT | AverageQ                   32.0939
2017-06-10 22:57:40.401206 EDT | AverageAbsQ                32.126
2017-06-10 22:57:40.401651 EDT | AverageY                   32.0951
2017-06-10 22:57:40.401996 EDT | AverageAbsY                32.1129
2017-06-10 22:57:40.402316 EDT | AverageAbsQYDiff            0.608156
2017-06-10 22:57:40.402608 EDT | AverageAction               0.852822
2017-06-10 22:57:40.402764 EDT | PolicyRegParamNorm         73.4457
2017-06-10 22:57:40.403805 EDT | QFunRegParamNorm           93.218
2017-06-10 22:57:40.403994 EDT | -----------------------  -----------
2017-06-10 22:57:40.404360 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #488 | Training started
2017-06-10 22:57:55.931013 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #488 | Training finished
2017-06-10 22:57:55.932103 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #488 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 22:57:55.932629 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #488 | Collecting samples for evaluation
2017-06-10 22:58:09.466720 EDT | -----------------------  -----------
2017-06-10 22:58:09.469012 EDT | Epoch                     488
2017-06-10 22:58:09.469305 EDT | Iteration                 488
2017-06-10 22:58:09.469586 EDT | AverageReturn            1300.23
2017-06-10 22:58:09.470831 EDT | StdReturn                 584.243
2017-06-10 22:58:09.471091 EDT | MaxReturn                2779.4
2017-06-10 22:58:09.471337 EDT | MinReturn                 635.754
2017-06-10 22:58:09.473229 EDT | AverageEsReturn           427.74
2017-06-10 22:58:09.474156 EDT | StdEsReturn               343.857
2017-06-10 22:58:09.474520 EDT | MaxEsReturn              1045.71
2017-06-10 22:58:09.475222 EDT | MinEsReturn                78.9836
2017-06-10 22:58:09.475770 EDT | AverageDiscountedReturn   229.367
2017-06-10 22:58:09.476007 EDT | AverageQLoss                2.99417
2017-06-10 22:58:09.476200 EDT | AveragePolicySurr         -32.5316
2017-06-10 22:58:09.476384 EDT | AverageQ                   32.072
2017-06-10 22:58:09.476571 EDT | AverageAbsQ                32.1076
2017-06-10 22:58:09.476753 EDT | AverageY                   32.0735
2017-06-10 22:58:09.476932 EDT | AverageAbsY                32.0949
2017-06-10 22:58:09.477179 EDT | AverageAbsQYDiff            0.639408
2017-06-10 22:58:09.477356 EDT | AverageAction               0.893467
2017-06-10 22:58:09.477567 EDT | PolicyRegParamNorm         73.5241
2017-06-10 22:58:09.477764 EDT | QFunRegParamNorm           93.2817
2017-06-10 22:58:09.477946 EDT | -----------------------  -----------
2017-06-10 22:58:09.478226 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #489 | Training started
2017-06-10 22:58:25.330952 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #489 | Training finished
2017-06-10 22:58:25.331240 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #489 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 22:58:25.331460 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #489 | Collecting samples for evaluation
2017-06-10 22:58:39.616352 EDT | -----------------------  -----------
2017-06-10 22:58:39.617513 EDT | Epoch                     489
2017-06-10 22:58:39.617857 EDT | Iteration                 489
2017-06-10 22:58:39.618103 EDT | AverageReturn            1004.29
2017-06-10 22:58:39.618268 EDT | StdReturn                 262.55
2017-06-10 22:58:39.618423 EDT | MaxReturn                1598.48
2017-06-10 22:58:39.618666 EDT | MinReturn                 649.347
2017-06-10 22:58:39.618913 EDT | AverageEsReturn           578.954
2017-06-10 22:58:39.619203 EDT | StdEsReturn               314.895
2017-06-10 22:58:39.619454 EDT | MaxEsReturn              1022.39
2017-06-10 22:58:39.619654 EDT | MinEsReturn               140.037
2017-06-10 22:58:39.619842 EDT | AverageDiscountedReturn   227.502
2017-06-10 22:58:39.620049 EDT | AverageQLoss                2.49358
2017-06-10 22:58:39.620351 EDT | AveragePolicySurr         -32.5572
2017-06-10 22:58:39.622385 EDT | AverageQ                   32.0965
2017-06-10 22:58:39.622701 EDT | AverageAbsQ                32.1362
2017-06-10 22:58:39.623509 EDT | AverageY                   32.0982
2017-06-10 22:58:39.623838 EDT | AverageAbsY                32.1197
2017-06-10 22:58:39.624164 EDT | AverageAbsQYDiff            0.609331
2017-06-10 22:58:39.624455 EDT | AverageAction               0.935538
2017-06-10 22:58:39.624844 EDT | PolicyRegParamNorm         73.6393
2017-06-10 22:58:39.625197 EDT | QFunRegParamNorm           93.3431
2017-06-10 22:58:39.625535 EDT | -----------------------  -----------
2017-06-10 22:58:39.626116 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #490 | Training started
2017-06-10 22:58:55.537033 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #490 | Training finished
2017-06-10 22:58:55.537824 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #490 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 22:58:55.538098 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #490 | Collecting samples for evaluation
2017-06-10 22:59:10.541655 EDT | -----------------------  -----------
2017-06-10 22:59:10.542511 EDT | Epoch                     490
2017-06-10 22:59:10.542711 EDT | Iteration                 490
2017-06-10 22:59:10.542909 EDT | AverageReturn             816.052
2017-06-10 22:59:10.543111 EDT | StdReturn                 131.211
2017-06-10 22:59:10.543277 EDT | MaxReturn                1037.84
2017-06-10 22:59:10.543550 EDT | MinReturn                 531.547
2017-06-10 22:59:10.543732 EDT | AverageEsReturn           513.448
2017-06-10 22:59:10.543920 EDT | StdEsReturn               238.061
2017-06-10 22:59:10.544104 EDT | MaxEsReturn               898.21
2017-06-10 22:59:10.544267 EDT | MinEsReturn               158.284
2017-06-10 22:59:10.544428 EDT | AverageDiscountedReturn   219.688
2017-06-10 22:59:10.544588 EDT | AverageQLoss                2.87906
2017-06-10 22:59:10.544748 EDT | AveragePolicySurr         -32.5545
2017-06-10 22:59:10.544974 EDT | AverageQ                   32.0603
2017-06-10 22:59:10.545154 EDT | AverageAbsQ                32.0975
2017-06-10 22:59:10.545316 EDT | AverageY                   32.0627
2017-06-10 22:59:10.545473 EDT | AverageAbsY                32.0842
2017-06-10 22:59:10.545633 EDT | AverageAbsQYDiff            0.643736
2017-06-10 22:59:10.545856 EDT | AverageAction               0.896003
2017-06-10 22:59:10.546015 EDT | PolicyRegParamNorm         73.6877
2017-06-10 22:59:10.546195 EDT | QFunRegParamNorm           93.405
2017-06-10 22:59:10.546664 EDT | -----------------------  -----------
2017-06-10 22:59:10.547112 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #491 | Training started
2017-06-10 22:59:26.495564 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #491 | Training finished
2017-06-10 22:59:26.497060 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #491 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 22:59:26.497682 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #491 | Collecting samples for evaluation
2017-06-10 22:59:39.592897 EDT | -----------------------  -----------
2017-06-10 22:59:39.593271 EDT | Epoch                     491
2017-06-10 22:59:39.593615 EDT | Iteration                 491
2017-06-10 22:59:39.593895 EDT | AverageReturn             785.315
2017-06-10 22:59:39.594148 EDT | StdReturn                 175.151
2017-06-10 22:59:39.594400 EDT | MaxReturn                1279.81
2017-06-10 22:59:39.594652 EDT | MinReturn                 566.824
2017-06-10 22:59:39.594908 EDT | AverageEsReturn           541.434
2017-06-10 22:59:39.595099 EDT | StdEsReturn               433.845
2017-06-10 22:59:39.595382 EDT | MaxEsReturn              1149.89
2017-06-10 22:59:39.595550 EDT | MinEsReturn                78.5031
2017-06-10 22:59:39.595705 EDT | AverageDiscountedReturn   214.299
2017-06-10 22:59:39.595856 EDT | AverageQLoss                3.01671
2017-06-10 22:59:39.596005 EDT | AveragePolicySurr         -32.5255
2017-06-10 22:59:39.596153 EDT | AverageQ                   32.0725
2017-06-10 22:59:39.596303 EDT | AverageAbsQ                32.1044
2017-06-10 22:59:39.596479 EDT | AverageY                   32.0738
2017-06-10 22:59:39.596719 EDT | AverageAbsY                32.0926
2017-06-10 22:59:39.596956 EDT | AverageAbsQYDiff            0.644395
2017-06-10 22:59:39.597218 EDT | AverageAction               0.94247
2017-06-10 22:59:39.597454 EDT | PolicyRegParamNorm         73.733
2017-06-10 22:59:39.597690 EDT | QFunRegParamNorm           93.4493
2017-06-10 22:59:39.597941 EDT | -----------------------  -----------
2017-06-10 22:59:39.598180 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #492 | Training started
2017-06-10 22:59:55.474114 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #492 | Training finished
2017-06-10 22:59:55.475052 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #492 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 22:59:55.475438 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #492 | Collecting samples for evaluation
2017-06-10 23:00:07.267403 EDT | -----------------------  -----------
2017-06-10 23:00:07.270709 EDT | Epoch                     492
2017-06-10 23:00:07.270958 EDT | Iteration                 492
2017-06-10 23:00:07.271122 EDT | AverageReturn            1013.59
2017-06-10 23:00:07.271280 EDT | StdReturn                 222.06
2017-06-10 23:00:07.271456 EDT | MaxReturn                1935.95
2017-06-10 23:00:07.271662 EDT | MinReturn                 825.133
2017-06-10 23:00:07.271817 EDT | AverageEsReturn           347.685
2017-06-10 23:00:07.272052 EDT | StdEsReturn               293.548
2017-06-10 23:00:07.272299 EDT | MaxEsReturn               927.142
2017-06-10 23:00:07.272536 EDT | MinEsReturn                11.2228
2017-06-10 23:00:07.272808 EDT | AverageDiscountedReturn   226.643
2017-06-10 23:00:07.273085 EDT | AverageQLoss                2.76244
2017-06-10 23:00:07.273307 EDT | AveragePolicySurr         -32.5882
2017-06-10 23:00:07.273461 EDT | AverageQ                   32.1472
2017-06-10 23:00:07.273683 EDT | AverageAbsQ                32.186
2017-06-10 23:00:07.273883 EDT | AverageY                   32.1477
2017-06-10 23:00:07.274053 EDT | AverageAbsY                32.1694
2017-06-10 23:00:07.274290 EDT | AverageAbsQYDiff            0.61609
2017-06-10 23:00:07.274551 EDT | AverageAction               0.893839
2017-06-10 23:00:07.274706 EDT | PolicyRegParamNorm         73.81
2017-06-10 23:00:07.274895 EDT | QFunRegParamNorm           93.4819
2017-06-10 23:00:07.275055 EDT | -----------------------  -----------
2017-06-10 23:00:07.275444 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #493 | Training started
2017-06-10 23:00:23.869441 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #493 | Training finished
2017-06-10 23:00:23.870255 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #493 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 23:00:23.870617 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #493 | Collecting samples for evaluation
2017-06-10 23:00:35.971916 EDT | -----------------------  -----------
2017-06-10 23:00:35.972832 EDT | Epoch                     493
2017-06-10 23:00:35.973079 EDT | Iteration                 493
2017-06-10 23:00:35.973401 EDT | AverageReturn            1194.31
2017-06-10 23:00:35.973739 EDT | StdReturn                 526
2017-06-10 23:00:35.974074 EDT | MaxReturn                2686.76
2017-06-10 23:00:35.974378 EDT | MinReturn                 414.383
2017-06-10 23:00:35.974759 EDT | AverageEsReturn           443.297
2017-06-10 23:00:35.975054 EDT | StdEsReturn               112.581
2017-06-10 23:00:35.976456 EDT | MaxEsReturn               621.908
2017-06-10 23:00:35.976789 EDT | MinEsReturn               291.546
2017-06-10 23:00:35.977188 EDT | AverageDiscountedReturn   214.716
2017-06-10 23:00:35.977442 EDT | AverageQLoss                2.53988
2017-06-10 23:00:35.978050 EDT | AveragePolicySurr         -32.524
2017-06-10 23:00:35.978370 EDT | AverageQ                   32.0639
2017-06-10 23:00:35.978971 EDT | AverageAbsQ                32.096
2017-06-10 23:00:35.979314 EDT | AverageY                   32.0665
2017-06-10 23:00:35.979638 EDT | AverageAbsY                32.0838
2017-06-10 23:00:35.980046 EDT | AverageAbsQYDiff            0.607907
2017-06-10 23:00:35.980303 EDT | AverageAction               0.929111
2017-06-10 23:00:35.980523 EDT | PolicyRegParamNorm         73.8568
2017-06-10 23:00:35.980846 EDT | QFunRegParamNorm           93.6049
2017-06-10 23:00:35.981233 EDT | -----------------------  -----------
2017-06-10 23:00:35.981863 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #494 | Training started
2017-06-10 23:00:50.834107 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #494 | Training finished
2017-06-10 23:00:50.835136 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #494 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 23:00:50.835524 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #494 | Collecting samples for evaluation
2017-06-10 23:01:03.917183 EDT | -----------------------  -----------
2017-06-10 23:01:03.918321 EDT | Epoch                     494
2017-06-10 23:01:03.918691 EDT | Iteration                 494
2017-06-10 23:01:03.919320 EDT | AverageReturn            1027.34
2017-06-10 23:01:03.919764 EDT | StdReturn                 270.258
2017-06-10 23:01:03.920472 EDT | MaxReturn                1677.17
2017-06-10 23:01:03.923721 EDT | MinReturn                 668.621
2017-06-10 23:01:03.924572 EDT | AverageEsReturn           904.739
2017-06-10 23:01:03.925121 EDT | StdEsReturn               341.263
2017-06-10 23:01:03.925576 EDT | MaxEsReturn              1313.01
2017-06-10 23:01:03.926038 EDT | MinEsReturn               367.345
2017-06-10 23:01:03.929154 EDT | AverageDiscountedReturn   219.186
2017-06-10 23:01:03.931190 EDT | AverageQLoss                2.5725
2017-06-10 23:01:03.932530 EDT | AveragePolicySurr         -32.6579
2017-06-10 23:01:03.934009 EDT | AverageQ                   32.2093
2017-06-10 23:01:03.934475 EDT | AverageAbsQ                32.235
2017-06-10 23:01:03.936799 EDT | AverageY                   32.2099
2017-06-10 23:01:03.937176 EDT | AverageAbsY                32.2268
2017-06-10 23:01:03.937523 EDT | AverageAbsQYDiff            0.604922
2017-06-10 23:01:03.937883 EDT | AverageAction               0.929556
2017-06-10 23:01:03.938225 EDT | PolicyRegParamNorm         73.9595
2017-06-10 23:01:03.938565 EDT | QFunRegParamNorm           93.7129
2017-06-10 23:01:03.938902 EDT | -----------------------  -----------
2017-06-10 23:01:03.939426 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #495 | Training started
2017-06-10 23:01:18.236473 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #495 | Training finished
2017-06-10 23:01:18.237376 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #495 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 23:01:18.237748 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #495 | Collecting samples for evaluation
2017-06-10 23:01:31.258601 EDT | -----------------------  -----------
2017-06-10 23:01:31.259487 EDT | Epoch                     495
2017-06-10 23:01:31.260611 EDT | Iteration                 495
2017-06-10 23:01:31.260798 EDT | AverageReturn             962.855
2017-06-10 23:01:31.260958 EDT | StdReturn                 337.222
2017-06-10 23:01:31.261124 EDT | MaxReturn                1917.51
2017-06-10 23:01:31.261317 EDT | MinReturn                 555.263
2017-06-10 23:01:31.261498 EDT | AverageEsReturn           277.233
2017-06-10 23:01:31.263244 EDT | StdEsReturn               401.347
2017-06-10 23:01:31.264569 EDT | MaxEsReturn              1075.84
2017-06-10 23:01:31.264835 EDT | MinEsReturn                11.1632
2017-06-10 23:01:31.265018 EDT | AverageDiscountedReturn   216.484
2017-06-10 23:01:31.265190 EDT | AverageQLoss                2.74048
2017-06-10 23:01:31.265378 EDT | AveragePolicySurr         -32.5551
2017-06-10 23:01:31.265554 EDT | AverageQ                   32.1089
2017-06-10 23:01:31.265731 EDT | AverageAbsQ                32.1396
2017-06-10 23:01:31.265892 EDT | AverageY                   32.1099
2017-06-10 23:01:31.266051 EDT | AverageAbsY                32.1273
2017-06-10 23:01:31.266208 EDT | AverageAbsQYDiff            0.614174
2017-06-10 23:01:31.266363 EDT | AverageAction               0.92868
2017-06-10 23:01:31.266520 EDT | PolicyRegParamNorm         74.01
2017-06-10 23:01:31.266683 EDT | QFunRegParamNorm           93.7932
2017-06-10 23:01:31.266840 EDT | -----------------------  -----------
2017-06-10 23:01:31.267101 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #496 | Training started
2017-06-10 23:01:47.328912 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #496 | Training finished
2017-06-10 23:01:47.329915 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #496 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 23:01:47.330253 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #496 | Collecting samples for evaluation
2017-06-10 23:01:58.895256 EDT | -----------------------  -----------
2017-06-10 23:01:58.896124 EDT | Epoch                     496
2017-06-10 23:01:58.896479 EDT | Iteration                 496
2017-06-10 23:01:58.896650 EDT | AverageReturn            1571.1
2017-06-10 23:01:58.896805 EDT | StdReturn                 679.35
2017-06-10 23:01:58.896963 EDT | MaxReturn                2855.2
2017-06-10 23:01:58.897174 EDT | MinReturn                 668.838
2017-06-10 23:01:58.897332 EDT | AverageEsReturn           410.68
2017-06-10 23:01:58.897489 EDT | StdEsReturn               416.357
2017-06-10 23:01:58.897643 EDT | MaxEsReturn              1326.91
2017-06-10 23:01:58.897828 EDT | MinEsReturn                14.1697
2017-06-10 23:01:58.898177 EDT | AverageDiscountedReturn   229.628
2017-06-10 23:01:58.898534 EDT | AverageQLoss                3.0432
2017-06-10 23:01:58.898866 EDT | AveragePolicySurr         -32.6187
2017-06-10 23:01:58.899191 EDT | AverageQ                   32.1582
2017-06-10 23:01:58.899540 EDT | AverageAbsQ                32.1904
2017-06-10 23:01:58.900153 EDT | AverageY                   32.1582
2017-06-10 23:01:58.901128 EDT | AverageAbsY                32.1799
2017-06-10 23:01:58.901749 EDT | AverageAbsQYDiff            0.630652
2017-06-10 23:01:58.902326 EDT | AverageAction               0.964831
2017-06-10 23:01:58.903071 EDT | PolicyRegParamNorm         74.0314
2017-06-10 23:01:58.903593 EDT | QFunRegParamNorm           93.8861
2017-06-10 23:01:58.903929 EDT | -----------------------  -----------
2017-06-10 23:01:58.904408 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #497 | Training started
2017-06-10 23:02:15.177349 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #497 | Training finished
2017-06-10 23:02:15.178275 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #497 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 23:02:15.178472 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #497 | Collecting samples for evaluation
2017-06-10 23:02:28.044412 EDT | -----------------------  -----------
2017-06-10 23:02:28.045402 EDT | Epoch                     497
2017-06-10 23:02:28.045786 EDT | Iteration                 497
2017-06-10 23:02:28.046139 EDT | AverageReturn            1316.43
2017-06-10 23:02:28.046483 EDT | StdReturn                 315.778
2017-06-10 23:02:28.046828 EDT | MaxReturn                2164.01
2017-06-10 23:02:28.047172 EDT | MinReturn                 759.073
2017-06-10 23:02:28.047513 EDT | AverageEsReturn           389.169
2017-06-10 23:02:28.047855 EDT | StdEsReturn               364.322
2017-06-10 23:02:28.048200 EDT | MaxEsReturn               991.18
2017-06-10 23:02:28.048544 EDT | MinEsReturn                69.3418
2017-06-10 23:02:28.048882 EDT | AverageDiscountedReturn   240.142
2017-06-10 23:02:28.049226 EDT | AverageQLoss                2.79948
2017-06-10 23:02:28.049573 EDT | AveragePolicySurr         -32.5386
2017-06-10 23:02:28.049921 EDT | AverageQ                   32.0831
2017-06-10 23:02:28.050262 EDT | AverageAbsQ                32.1239
2017-06-10 23:02:28.050603 EDT | AverageY                   32.0854
2017-06-10 23:02:28.050957 EDT | AverageAbsY                32.1109
2017-06-10 23:02:28.051298 EDT | AverageAbsQYDiff            0.616595
2017-06-10 23:02:28.051642 EDT | AverageAction               0.920961
2017-06-10 23:02:28.051984 EDT | PolicyRegParamNorm         74.0841
2017-06-10 23:02:28.052325 EDT | QFunRegParamNorm           94.0438
2017-06-10 23:02:28.052660 EDT | -----------------------  -----------
2017-06-10 23:02:28.053175 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #498 | Training started
2017-06-10 23:02:43.214584 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #498 | Training finished
2017-06-10 23:02:43.215596 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #498 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 23:02:43.216134 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #498 | Collecting samples for evaluation
2017-06-10 23:02:56.485946 EDT | -----------------------  -----------
2017-06-10 23:02:56.486671 EDT | Epoch                     498
2017-06-10 23:02:56.486891 EDT | Iteration                 498
2017-06-10 23:02:56.487163 EDT | AverageReturn             809.08
2017-06-10 23:02:56.487358 EDT | StdReturn                 171.06
2017-06-10 23:02:56.487542 EDT | MaxReturn                1323.81
2017-06-10 23:02:56.487730 EDT | MinReturn                 567.534
2017-06-10 23:02:56.487987 EDT | AverageEsReturn           604.705
2017-06-10 23:02:56.488188 EDT | StdEsReturn               324.798
2017-06-10 23:02:56.488369 EDT | MaxEsReturn               895.388
2017-06-10 23:02:56.488547 EDT | MinEsReturn                53.9597
2017-06-10 23:02:56.488754 EDT | AverageDiscountedReturn   212.203
2017-06-10 23:02:56.488961 EDT | AverageQLoss                2.53013
2017-06-10 23:02:56.489253 EDT | AveragePolicySurr         -32.6089
2017-06-10 23:02:56.489552 EDT | AverageQ                   32.146
2017-06-10 23:02:56.489816 EDT | AverageAbsQ                32.18
2017-06-10 23:02:56.490000 EDT | AverageY                   32.1479
2017-06-10 23:02:56.490181 EDT | AverageAbsY                32.1676
2017-06-10 23:02:56.490445 EDT | AverageAbsQYDiff            0.611988
2017-06-10 23:02:56.490629 EDT | AverageAction               0.946095
2017-06-10 23:02:56.490810 EDT | PolicyRegParamNorm         74.1836
2017-06-10 23:02:56.491009 EDT | QFunRegParamNorm           94.095
2017-06-10 23:02:56.491192 EDT | -----------------------  -----------
2017-06-10 23:02:56.491498 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #499 | Training started
2017-06-10 23:03:11.297755 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #499 | Training finished
2017-06-10 23:03:11.298213 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #499 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 23:03:11.298522 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #499 | Collecting samples for evaluation
2017-06-10 23:03:23.287120 EDT | -----------------------  -----------
2017-06-10 23:03:23.288019 EDT | Epoch                     499
2017-06-10 23:03:23.288446 EDT | Iteration                 499
2017-06-10 23:03:23.288792 EDT | AverageReturn             377.08
2017-06-10 23:03:23.289094 EDT | StdReturn                 154.675
2017-06-10 23:03:23.290973 EDT | MaxReturn                 837.259
2017-06-10 23:03:23.293488 EDT | MinReturn                 239.623
2017-06-10 23:03:23.293815 EDT | AverageEsReturn           838.162
2017-06-10 23:03:23.294471 EDT | StdEsReturn               164.568
2017-06-10 23:03:23.294660 EDT | MaxEsReturn              1052.97
2017-06-10 23:03:23.294847 EDT | MinEsReturn               600.767
2017-06-10 23:03:23.295078 EDT | AverageDiscountedReturn   165.723
2017-06-10 23:03:23.295402 EDT | AverageQLoss                2.51718
2017-06-10 23:03:23.295584 EDT | AveragePolicySurr         -32.5955
2017-06-10 23:03:23.296278 EDT | AverageQ                   32.1538
2017-06-10 23:03:23.298950 EDT | AverageAbsQ                32.192
2017-06-10 23:03:23.299341 EDT | AverageY                   32.1542
2017-06-10 23:03:23.299621 EDT | AverageAbsY                32.1787
2017-06-10 23:03:23.299897 EDT | AverageAbsQYDiff            0.601399
2017-06-10 23:03:23.300168 EDT | AverageAction               0.963226
2017-06-10 23:03:23.300450 EDT | PolicyRegParamNorm         74.2299
2017-06-10 23:03:23.300734 EDT | QFunRegParamNorm           94.1272
2017-06-10 23:03:23.300915 EDT | -----------------------  -----------
2017-06-10 23:03:23.301250 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #500 | Training started
2017-06-10 23:03:38.528519 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #500 | Training finished
2017-06-10 23:03:38.529880 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #500 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 23:03:38.530190 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #500 | Collecting samples for evaluation
2017-06-10 23:03:52.174079 EDT | -----------------------  -----------
2017-06-10 23:03:52.175217 EDT | Epoch                     500
2017-06-10 23:03:52.175654 EDT | Iteration                 500
2017-06-10 23:03:52.175867 EDT | AverageReturn            2164.58
2017-06-10 23:03:52.176082 EDT | StdReturn                 429.606
2017-06-10 23:03:52.176265 EDT | MaxReturn                2362.23
2017-06-10 23:03:52.176508 EDT | MinReturn                 812.139
2017-06-10 23:03:52.176732 EDT | AverageEsReturn           373.938
2017-06-10 23:03:52.176962 EDT | StdEsReturn               354.431
2017-06-10 23:03:52.177138 EDT | MaxEsReturn              1033.06
2017-06-10 23:03:52.177309 EDT | MinEsReturn                12.3405
2017-06-10 23:03:52.177566 EDT | AverageDiscountedReturn   202.672
2017-06-10 23:03:52.177839 EDT | AverageQLoss                2.7952
2017-06-10 23:03:52.178182 EDT | AveragePolicySurr         -32.5197
2017-06-10 23:03:52.178456 EDT | AverageQ                   32.0792
2017-06-10 23:03:52.178825 EDT | AverageAbsQ                32.1163
2017-06-10 23:03:52.179108 EDT | AverageY                   32.0815
2017-06-10 23:03:52.179412 EDT | AverageAbsY                32.1029
2017-06-10 23:03:52.179769 EDT | AverageAbsQYDiff            0.628881
2017-06-10 23:03:52.179990 EDT | AverageAction               0.95981
2017-06-10 23:03:52.180202 EDT | PolicyRegParamNorm         74.2869
2017-06-10 23:03:52.180574 EDT | QFunRegParamNorm           94.2251
2017-06-10 23:03:52.181014 EDT | -----------------------  -----------
2017-06-10 23:03:52.181296 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #501 | Training started
2017-06-10 23:04:08.815027 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #501 | Training finished
2017-06-10 23:04:08.816076 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #501 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 23:04:08.816484 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #501 | Collecting samples for evaluation
2017-06-10 23:04:22.179841 EDT | -----------------------  ----------
2017-06-10 23:04:22.180616 EDT | Epoch                     501
2017-06-10 23:04:22.180808 EDT | Iteration                 501
2017-06-10 23:04:22.180996 EDT | AverageReturn            1713.16
2017-06-10 23:04:22.181218 EDT | StdReturn                 735.734
2017-06-10 23:04:22.181402 EDT | MaxReturn                2917.25
2017-06-10 23:04:22.181583 EDT | MinReturn                 856.482
2017-06-10 23:04:22.181860 EDT | AverageEsReturn           216.199
2017-06-10 23:04:22.182046 EDT | StdEsReturn               181.524
2017-06-10 23:04:22.182224 EDT | MaxEsReturn               706.455
2017-06-10 23:04:22.182410 EDT | MinEsReturn                61.9822
2017-06-10 23:04:22.182681 EDT | AverageDiscountedReturn   233.938
2017-06-10 23:04:22.182940 EDT | AverageQLoss                3.01395
2017-06-10 23:04:22.183122 EDT | AveragePolicySurr         -32.5503
2017-06-10 23:04:22.183324 EDT | AverageQ                   32.0987
2017-06-10 23:04:22.183720 EDT | AverageAbsQ                32.1443
2017-06-10 23:04:22.184146 EDT | AverageY                   32.0988
2017-06-10 23:04:22.184475 EDT | AverageAbsY                32.1251
2017-06-10 23:04:22.184791 EDT | AverageAbsQYDiff            0.64167
2017-06-10 23:04:22.185292 EDT | AverageAction               0.93002
2017-06-10 23:04:22.185478 EDT | PolicyRegParamNorm         74.3273
2017-06-10 23:04:22.185815 EDT | QFunRegParamNorm           94.3387
2017-06-10 23:04:22.186137 EDT | -----------------------  ----------
2017-06-10 23:04:22.186998 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #502 | Training started
2017-06-10 23:04:37.752368 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #502 | Training finished
2017-06-10 23:04:37.753267 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #502 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 23:04:37.753754 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #502 | Collecting samples for evaluation
2017-06-10 23:04:51.713275 EDT | -----------------------  -----------
2017-06-10 23:04:51.714880 EDT | Epoch                     502
2017-06-10 23:04:51.715091 EDT | Iteration                 502
2017-06-10 23:04:51.715448 EDT | AverageReturn            1097.86
2017-06-10 23:04:51.715666 EDT | StdReturn                 385.498
2017-06-10 23:04:51.715885 EDT | MaxReturn                2214.24
2017-06-10 23:04:51.716069 EDT | MinReturn                 647.588
2017-06-10 23:04:51.716250 EDT | AverageEsReturn           202.868
2017-06-10 23:04:51.716524 EDT | StdEsReturn               226.687
2017-06-10 23:04:51.716734 EDT | MaxEsReturn               815.157
2017-06-10 23:04:51.716915 EDT | MinEsReturn                12.3939
2017-06-10 23:04:51.717141 EDT | AverageDiscountedReturn   212.518
2017-06-10 23:04:51.717322 EDT | AverageQLoss                3.08186
2017-06-10 23:04:51.717500 EDT | AveragePolicySurr         -32.5535
2017-06-10 23:04:51.717679 EDT | AverageQ                   32.1346
2017-06-10 23:04:51.717880 EDT | AverageAbsQ                32.1691
2017-06-10 23:04:51.718058 EDT | AverageY                   32.1371
2017-06-10 23:04:51.718237 EDT | AverageAbsY                32.157
2017-06-10 23:04:51.718415 EDT | AverageAbsQYDiff            0.619891
2017-06-10 23:04:51.718662 EDT | AverageAction               0.909444
2017-06-10 23:04:51.718924 EDT | PolicyRegParamNorm         74.4091
2017-06-10 23:04:51.719105 EDT | QFunRegParamNorm           94.444
2017-06-10 23:04:51.719283 EDT | -----------------------  -----------
2017-06-10 23:04:51.723486 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #503 | Training started
2017-06-10 23:05:07.577284 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #503 | Training finished
2017-06-10 23:05:07.578399 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #503 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 23:05:07.578995 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #503 | Collecting samples for evaluation
2017-06-10 23:05:20.424855 EDT | -----------------------  -----------
2017-06-10 23:05:20.425782 EDT | Epoch                     503
2017-06-10 23:05:20.426137 EDT | Iteration                 503
2017-06-10 23:05:20.426433 EDT | AverageReturn            1076.34
2017-06-10 23:05:20.426682 EDT | StdReturn                 494.929
2017-06-10 23:05:20.426974 EDT | MaxReturn                2433.61
2017-06-10 23:05:20.427291 EDT | MinReturn                 595.401
2017-06-10 23:05:20.427598 EDT | AverageEsReturn           182.98
2017-06-10 23:05:20.427921 EDT | StdEsReturn               151.274
2017-06-10 23:05:20.428149 EDT | MaxEsReturn               564.493
2017-06-10 23:05:20.428479 EDT | MinEsReturn                21.1582
2017-06-10 23:05:20.428804 EDT | AverageDiscountedReturn   204.472
2017-06-10 23:05:20.429124 EDT | AverageQLoss                2.43567
2017-06-10 23:05:20.429437 EDT | AveragePolicySurr         -32.4963
2017-06-10 23:05:20.429686 EDT | AverageQ                   32.0957
2017-06-10 23:05:20.430024 EDT | AverageAbsQ                32.133
2017-06-10 23:05:20.430249 EDT | AverageY                   32.0952
2017-06-10 23:05:20.430417 EDT | AverageAbsY                32.1203
2017-06-10 23:05:20.430570 EDT | AverageAbsQYDiff            0.576958
2017-06-10 23:05:20.430722 EDT | AverageAction               0.909912
2017-06-10 23:05:20.430872 EDT | PolicyRegParamNorm         74.4714
2017-06-10 23:05:20.431023 EDT | QFunRegParamNorm           94.527
2017-06-10 23:05:20.431251 EDT | -----------------------  -----------
2017-06-10 23:05:20.431694 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #504 | Training started
2017-06-10 23:05:35.678442 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #504 | Training finished
2017-06-10 23:05:35.679411 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #504 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 23:05:35.679810 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #504 | Collecting samples for evaluation
2017-06-10 23:05:47.779752 EDT | -----------------------  -----------
2017-06-10 23:05:47.780726 EDT | Epoch                     504
2017-06-10 23:05:47.781067 EDT | Iteration                 504
2017-06-10 23:05:47.781389 EDT | AverageReturn            1543.42
2017-06-10 23:05:47.781740 EDT | StdReturn                 590.412
2017-06-10 23:05:47.782066 EDT | MaxReturn                2566.51
2017-06-10 23:05:47.782398 EDT | MinReturn                 725.821
2017-06-10 23:05:47.782896 EDT | AverageEsReturn           334.989
2017-06-10 23:05:47.783230 EDT | StdEsReturn               247.202
2017-06-10 23:05:47.783413 EDT | MaxEsReturn               797.497
2017-06-10 23:05:47.783576 EDT | MinEsReturn                19.1209
2017-06-10 23:05:47.783785 EDT | AverageDiscountedReturn   210.746
2017-06-10 23:05:47.783944 EDT | AverageQLoss                2.84134
2017-06-10 23:05:47.784125 EDT | AveragePolicySurr         -32.4337
2017-06-10 23:05:47.784282 EDT | AverageQ                   32.0159
2017-06-10 23:05:47.784451 EDT | AverageAbsQ                32.0629
2017-06-10 23:05:47.784620 EDT | AverageY                   32.0159
2017-06-10 23:05:47.784776 EDT | AverageAbsY                32.0496
2017-06-10 23:05:47.784939 EDT | AverageAbsQYDiff            0.628261
2017-06-10 23:05:47.785124 EDT | AverageAction               0.912722
2017-06-10 23:05:47.785400 EDT | PolicyRegParamNorm         74.5084
2017-06-10 23:05:47.785638 EDT | QFunRegParamNorm           94.5911
2017-06-10 23:05:47.785892 EDT | -----------------------  -----------
2017-06-10 23:05:47.786197 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #505 | Training started
2017-06-10 23:06:03.273554 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #505 | Training finished
2017-06-10 23:06:03.274517 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #505 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 23:06:03.274730 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #505 | Collecting samples for evaluation
2017-06-10 23:06:16.631960 EDT | -----------------------  -----------
2017-06-10 23:06:16.632789 EDT | Epoch                     505
2017-06-10 23:06:16.633117 EDT | Iteration                 505
2017-06-10 23:06:16.633313 EDT | AverageReturn             865.566
2017-06-10 23:06:16.633507 EDT | StdReturn                 380.643
2017-06-10 23:06:16.633716 EDT | MaxReturn                2431.63
2017-06-10 23:06:16.634005 EDT | MinReturn                 544.502
2017-06-10 23:06:16.634235 EDT | AverageEsReturn           392.716
2017-06-10 23:06:16.634423 EDT | StdEsReturn               218.428
2017-06-10 23:06:16.634609 EDT | MaxEsReturn               723.097
2017-06-10 23:06:16.634789 EDT | MinEsReturn                69.7417
2017-06-10 23:06:16.634962 EDT | AverageDiscountedReturn   210.578
2017-06-10 23:06:16.635121 EDT | AverageQLoss                2.56174
2017-06-10 23:06:16.635277 EDT | AveragePolicySurr         -32.4734
2017-06-10 23:06:16.635620 EDT | AverageQ                   32.0539
2017-06-10 23:06:16.635888 EDT | AverageAbsQ                32.1023
2017-06-10 23:06:16.636072 EDT | AverageY                   32.053
2017-06-10 23:06:16.636379 EDT | AverageAbsY                32.0887
2017-06-10 23:06:16.636647 EDT | AverageAbsQYDiff            0.60204
2017-06-10 23:06:16.636990 EDT | AverageAction               0.915136
2017-06-10 23:06:16.637312 EDT | PolicyRegParamNorm         74.5484
2017-06-10 23:06:16.637653 EDT | QFunRegParamNorm           94.703
2017-06-10 23:06:16.638395 EDT | -----------------------  -----------
2017-06-10 23:06:16.639853 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #506 | Training started
2017-06-10 23:06:32.153713 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #506 | Training finished
2017-06-10 23:06:32.154498 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #506 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 23:06:32.154692 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #506 | Collecting samples for evaluation
2017-06-10 23:06:45.305301 EDT | -----------------------  -----------
2017-06-10 23:06:45.306407 EDT | Epoch                     506
2017-06-10 23:06:45.306772 EDT | Iteration                 506
2017-06-10 23:06:45.307132 EDT | AverageReturn             762.539
2017-06-10 23:06:45.307453 EDT | StdReturn                 280.337
2017-06-10 23:06:45.307798 EDT | MaxReturn                2126.39
2017-06-10 23:06:45.308149 EDT | MinReturn                 532.728
2017-06-10 23:06:45.308476 EDT | AverageEsReturn           216.12
2017-06-10 23:06:45.308956 EDT | StdEsReturn               250.046
2017-06-10 23:06:45.309308 EDT | MaxEsReturn               929.832
2017-06-10 23:06:45.311002 EDT | MinEsReturn                12.2074
2017-06-10 23:06:45.311436 EDT | AverageDiscountedReturn   206.746
2017-06-10 23:06:45.311869 EDT | AverageQLoss                2.89791
2017-06-10 23:06:45.312231 EDT | AveragePolicySurr         -32.2648
2017-06-10 23:06:45.312632 EDT | AverageQ                   31.8164
2017-06-10 23:06:45.312988 EDT | AverageAbsQ                31.8704
2017-06-10 23:06:45.313333 EDT | AverageY                   31.8199
2017-06-10 23:06:45.313611 EDT | AverageAbsY                31.8587
2017-06-10 23:06:45.313940 EDT | AverageAbsQYDiff            0.629864
2017-06-10 23:06:45.314352 EDT | AverageAction               0.928831
2017-06-10 23:06:45.314785 EDT | PolicyRegParamNorm         74.5619
2017-06-10 23:06:45.315179 EDT | QFunRegParamNorm           94.7736
2017-06-10 23:06:45.315605 EDT | -----------------------  -----------
2017-06-10 23:06:45.316205 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #507 | Training started
2017-06-10 23:07:01.375123 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #507 | Training finished
2017-06-10 23:07:01.376149 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #507 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 23:07:01.376559 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #507 | Collecting samples for evaluation
2017-06-10 23:07:13.855619 EDT | -----------------------  -----------
2017-06-10 23:07:13.856718 EDT | Epoch                     507
2017-06-10 23:07:13.857186 EDT | Iteration                 507
2017-06-10 23:07:13.857639 EDT | AverageReturn            1137.22
2017-06-10 23:07:13.858090 EDT | StdReturn                 489.397
2017-06-10 23:07:13.858530 EDT | MaxReturn                2419.36
2017-06-10 23:07:13.858974 EDT | MinReturn                 585.757
2017-06-10 23:07:13.859416 EDT | AverageEsReturn           402.536
2017-06-10 23:07:13.859859 EDT | StdEsReturn               394.225
2017-06-10 23:07:13.860303 EDT | MaxEsReturn              1067.75
2017-06-10 23:07:13.860753 EDT | MinEsReturn                15.1571
2017-06-10 23:07:13.861193 EDT | AverageDiscountedReturn   211.208
2017-06-10 23:07:13.861775 EDT | AverageQLoss                2.85354
2017-06-10 23:07:13.862289 EDT | AveragePolicySurr         -32.3617
2017-06-10 23:07:13.862790 EDT | AverageQ                   31.9547
2017-06-10 23:07:13.863248 EDT | AverageAbsQ                32.0017
2017-06-10 23:07:13.863686 EDT | AverageY                   31.9567
2017-06-10 23:07:13.864129 EDT | AverageAbsY                31.9911
2017-06-10 23:07:13.864572 EDT | AverageAbsQYDiff            0.614894
2017-06-10 23:07:13.865017 EDT | AverageAction               0.915131
2017-06-10 23:07:13.865459 EDT | PolicyRegParamNorm         74.6055
2017-06-10 23:07:13.865918 EDT | QFunRegParamNorm           94.8512
2017-06-10 23:07:13.866361 EDT | -----------------------  -----------
2017-06-10 23:07:13.866979 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #508 | Training started
2017-06-10 23:07:28.687380 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #508 | Training finished
2017-06-10 23:07:28.687850 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #508 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 23:07:28.688229 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #508 | Collecting samples for evaluation
2017-06-10 23:07:42.402742 EDT | -----------------------  -----------
2017-06-10 23:07:42.405760 EDT | Epoch                     508
2017-06-10 23:07:42.406126 EDT | Iteration                 508
2017-06-10 23:07:42.406596 EDT | AverageReturn            1124.69
2017-06-10 23:07:42.406973 EDT | StdReturn                 471.782
2017-06-10 23:07:42.407176 EDT | MaxReturn                2284.13
2017-06-10 23:07:42.407343 EDT | MinReturn                 505.193
2017-06-10 23:07:42.407525 EDT | AverageEsReturn           440.307
2017-06-10 23:07:42.407677 EDT | StdEsReturn               137.461
2017-06-10 23:07:42.407836 EDT | MaxEsReturn               714.213
2017-06-10 23:07:42.408033 EDT | MinEsReturn               304.341
2017-06-10 23:07:42.408186 EDT | AverageDiscountedReturn   207.615
2017-06-10 23:07:42.408347 EDT | AverageQLoss                2.35057
2017-06-10 23:07:42.408496 EDT | AveragePolicySurr         -32.3258
2017-06-10 23:07:42.408645 EDT | AverageQ                   31.8943
2017-06-10 23:07:42.408792 EDT | AverageAbsQ                31.9406
2017-06-10 23:07:42.409031 EDT | AverageY                   31.8948
2017-06-10 23:07:42.409288 EDT | AverageAbsY                31.9265
2017-06-10 23:07:42.411898 EDT | AverageAbsQYDiff            0.593272
2017-06-10 23:07:42.412143 EDT | AverageAction               0.929555
2017-06-10 23:07:42.412353 EDT | PolicyRegParamNorm         74.6417
2017-06-10 23:07:42.412509 EDT | QFunRegParamNorm           94.9329
2017-06-10 23:07:42.412697 EDT | -----------------------  -----------
2017-06-10 23:07:42.413000 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #509 | Training started
2017-06-10 23:07:58.438653 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #509 | Training finished
2017-06-10 23:07:58.439185 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #509 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 23:07:58.441227 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #509 | Collecting samples for evaluation
2017-06-10 23:08:11.371073 EDT | -----------------------  -----------
2017-06-10 23:08:11.372020 EDT | Epoch                     509
2017-06-10 23:08:11.372390 EDT | Iteration                 509
2017-06-10 23:08:11.372735 EDT | AverageReturn            1229.26
2017-06-10 23:08:11.373081 EDT | StdReturn                 468.555
2017-06-10 23:08:11.373468 EDT | MaxReturn                2750.09
2017-06-10 23:08:11.373829 EDT | MinReturn                 620.614
2017-06-10 23:08:11.374171 EDT | AverageEsReturn           401.754
2017-06-10 23:08:11.375531 EDT | StdEsReturn               287.052
2017-06-10 23:08:11.375883 EDT | MaxEsReturn               816.903
2017-06-10 23:08:11.376226 EDT | MinEsReturn                55.4894
2017-06-10 23:08:11.376570 EDT | AverageDiscountedReturn   226.251
2017-06-10 23:08:11.376913 EDT | AverageQLoss                2.73009
2017-06-10 23:08:11.377260 EDT | AveragePolicySurr         -32.2425
2017-06-10 23:08:11.377599 EDT | AverageQ                   31.8056
2017-06-10 23:08:11.377959 EDT | AverageAbsQ                31.8564
2017-06-10 23:08:11.378297 EDT | AverageY                   31.8058
2017-06-10 23:08:11.378641 EDT | AverageAbsY                31.8394
2017-06-10 23:08:11.378981 EDT | AverageAbsQYDiff            0.616836
2017-06-10 23:08:11.379322 EDT | AverageAction               0.909725
2017-06-10 23:08:11.379662 EDT | PolicyRegParamNorm         74.6646
2017-06-10 23:08:11.380004 EDT | QFunRegParamNorm           95.0049
2017-06-10 23:08:11.380343 EDT | -----------------------  -----------
2017-06-10 23:08:11.380825 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #510 | Training started
2017-06-10 23:08:26.993048 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #510 | Training finished
2017-06-10 23:08:26.993485 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #510 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 23:08:26.993799 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #510 | Collecting samples for evaluation
2017-06-10 23:08:39.394199 EDT | -----------------------  -----------
2017-06-10 23:08:39.396110 EDT | Epoch                     510
2017-06-10 23:08:39.396320 EDT | Iteration                 510
2017-06-10 23:08:39.396704 EDT | AverageReturn             985.089
2017-06-10 23:08:39.396944 EDT | StdReturn                 374.026
2017-06-10 23:08:39.397186 EDT | MaxReturn                1850.88
2017-06-10 23:08:39.397492 EDT | MinReturn                 510.952
2017-06-10 23:08:39.397838 EDT | AverageEsReturn           308.75
2017-06-10 23:08:39.398120 EDT | StdEsReturn               373.499
2017-06-10 23:08:39.398748 EDT | MaxEsReturn              1205.28
2017-06-10 23:08:39.399505 EDT | MinEsReturn                41.8833
2017-06-10 23:08:39.399924 EDT | AverageDiscountedReturn   224.696
2017-06-10 23:08:39.400300 EDT | AverageQLoss                2.67202
2017-06-10 23:08:39.401074 EDT | AveragePolicySurr         -32.2747
2017-06-10 23:08:39.401795 EDT | AverageQ                   31.8321
2017-06-10 23:08:39.402167 EDT | AverageAbsQ                31.871
2017-06-10 23:08:39.402534 EDT | AverageY                   31.8339
2017-06-10 23:08:39.403092 EDT | AverageAbsY                31.8564
2017-06-10 23:08:39.404058 EDT | AverageAbsQYDiff            0.625505
2017-06-10 23:08:39.405213 EDT | AverageAction               0.923698
2017-06-10 23:08:39.405601 EDT | PolicyRegParamNorm         74.7184
2017-06-10 23:08:39.406144 EDT | QFunRegParamNorm           95.0839
2017-06-10 23:08:39.406504 EDT | -----------------------  -----------
2017-06-10 23:08:39.406816 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #511 | Training started
2017-06-10 23:08:55.253989 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #511 | Training finished
2017-06-10 23:08:55.255279 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #511 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 23:08:55.255829 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #511 | Collecting samples for evaluation
2017-06-10 23:09:07.257469 EDT | -----------------------  -----------
2017-06-10 23:09:07.258872 EDT | Epoch                     511
2017-06-10 23:09:07.259221 EDT | Iteration                 511
2017-06-10 23:09:07.259560 EDT | AverageReturn            1228.19
2017-06-10 23:09:07.259843 EDT | StdReturn                 500.391
2017-06-10 23:09:07.260109 EDT | MaxReturn                2335.29
2017-06-10 23:09:07.260440 EDT | MinReturn                 642.902
2017-06-10 23:09:07.260778 EDT | AverageEsReturn           454.11
2017-06-10 23:09:07.261076 EDT | StdEsReturn               447.159
2017-06-10 23:09:07.261463 EDT | MaxEsReturn              1319.11
2017-06-10 23:09:07.261869 EDT | MinEsReturn                96.0281
2017-06-10 23:09:07.262203 EDT | AverageDiscountedReturn   206.284
2017-06-10 23:09:07.262478 EDT | AverageQLoss                2.86445
2017-06-10 23:09:07.262746 EDT | AveragePolicySurr         -32.3729
2017-06-10 23:09:07.263093 EDT | AverageQ                   31.9338
2017-06-10 23:09:07.263518 EDT | AverageAbsQ                31.9679
2017-06-10 23:09:07.263851 EDT | AverageY                   31.9355
2017-06-10 23:09:07.264213 EDT | AverageAbsY                31.9545
2017-06-10 23:09:07.264506 EDT | AverageAbsQYDiff            0.632491
2017-06-10 23:09:07.264778 EDT | AverageAction               0.939537
2017-06-10 23:09:07.265106 EDT | PolicyRegParamNorm         74.8212
2017-06-10 23:09:07.265444 EDT | QFunRegParamNorm           95.1308
2017-06-10 23:09:07.266043 EDT | -----------------------  -----------
2017-06-10 23:09:07.266548 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #512 | Training started
2017-06-10 23:09:21.789435 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #512 | Training finished
2017-06-10 23:09:21.791471 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #512 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 23:09:21.791809 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #512 | Collecting samples for evaluation
2017-06-10 23:09:35.429566 EDT | -----------------------  -----------
2017-06-10 23:09:35.430418 EDT | Epoch                     512
2017-06-10 23:09:35.430710 EDT | Iteration                 512
2017-06-10 23:09:35.430918 EDT | AverageReturn            1776.62
2017-06-10 23:09:35.431251 EDT | StdReturn                 626.7
2017-06-10 23:09:35.431586 EDT | MaxReturn                2764
2017-06-10 23:09:35.431909 EDT | MinReturn                 913.386
2017-06-10 23:09:35.432265 EDT | AverageEsReturn           435.608
2017-06-10 23:09:35.432589 EDT | StdEsReturn               319.874
2017-06-10 23:09:35.432914 EDT | MaxEsReturn               949.435
2017-06-10 23:09:35.433380 EDT | MinEsReturn                93.0453
2017-06-10 23:09:35.433676 EDT | AverageDiscountedReturn   233.693
2017-06-10 23:09:35.434108 EDT | AverageQLoss                2.39269
2017-06-10 23:09:35.434512 EDT | AveragePolicySurr         -32.4122
2017-06-10 23:09:35.434836 EDT | AverageQ                   31.9606
2017-06-10 23:09:35.435329 EDT | AverageAbsQ                31.9924
2017-06-10 23:09:35.437490 EDT | AverageY                   31.9594
2017-06-10 23:09:35.439832 EDT | AverageAbsY                31.9788
2017-06-10 23:09:35.440159 EDT | AverageAbsQYDiff            0.593114
2017-06-10 23:09:35.440495 EDT | AverageAction               0.901605
2017-06-10 23:09:35.440921 EDT | PolicyRegParamNorm         74.8437
2017-06-10 23:09:35.443050 EDT | QFunRegParamNorm           95.168
2017-06-10 23:09:35.443981 EDT | -----------------------  -----------
2017-06-10 23:09:35.446497 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #513 | Training started
2017-06-10 23:09:50.722101 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #513 | Training finished
2017-06-10 23:09:50.722902 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #513 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 23:09:50.723384 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #513 | Collecting samples for evaluation
2017-06-10 23:10:04.334672 EDT | -----------------------  -----------
2017-06-10 23:10:04.335842 EDT | Epoch                     513
2017-06-10 23:10:04.336312 EDT | Iteration                 513
2017-06-10 23:10:04.336766 EDT | AverageReturn            2144.97
2017-06-10 23:10:04.337281 EDT | StdReturn                 481.941
2017-06-10 23:10:04.337755 EDT | MaxReturn                2735.44
2017-06-10 23:10:04.338203 EDT | MinReturn                1075.2
2017-06-10 23:10:04.338642 EDT | AverageEsReturn           245.874
2017-06-10 23:10:04.339083 EDT | StdEsReturn               232.025
2017-06-10 23:10:04.339529 EDT | MaxEsReturn               722.853
2017-06-10 23:10:04.339970 EDT | MinEsReturn                11.1054
2017-06-10 23:10:04.340470 EDT | AverageDiscountedReturn   220.471
2017-06-10 23:10:04.340913 EDT | AverageQLoss                2.17942
2017-06-10 23:10:04.345030 EDT | AveragePolicySurr         -32.2959
2017-06-10 23:10:04.345479 EDT | AverageQ                   31.8584
2017-06-10 23:10:04.347673 EDT | AverageAbsQ                31.8949
2017-06-10 23:10:04.348674 EDT | AverageY                   31.8609
2017-06-10 23:10:04.349832 EDT | AverageAbsY                31.8831
2017-06-10 23:10:04.351090 EDT | AverageAbsQYDiff            0.574352
2017-06-10 23:10:04.351555 EDT | AverageAction               0.913453
2017-06-10 23:10:04.352004 EDT | PolicyRegParamNorm         74.8919
2017-06-10 23:10:04.352449 EDT | QFunRegParamNorm           95.2818
2017-06-10 23:10:04.352894 EDT | -----------------------  -----------
2017-06-10 23:10:04.353522 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #514 | Training started
2017-06-10 23:10:20.915844 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #514 | Training finished
2017-06-10 23:10:20.916874 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #514 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 23:10:20.917216 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #514 | Collecting samples for evaluation
2017-06-10 23:10:33.118327 EDT | -----------------------  -----------
2017-06-10 23:10:33.119416 EDT | Epoch                     514
2017-06-10 23:10:33.119866 EDT | Iteration                 514
2017-06-10 23:10:33.120362 EDT | AverageReturn            1505.44
2017-06-10 23:10:33.120791 EDT | StdReturn                 459.288
2017-06-10 23:10:33.121305 EDT | MaxReturn                2456.58
2017-06-10 23:10:33.121711 EDT | MinReturn                 745.179
2017-06-10 23:10:33.122139 EDT | AverageEsReturn           417.92
2017-06-10 23:10:33.122792 EDT | StdEsReturn               270.964
2017-06-10 23:10:33.123243 EDT | MaxEsReturn               764.296
2017-06-10 23:10:33.123700 EDT | MinEsReturn                45.3033
2017-06-10 23:10:33.124031 EDT | AverageDiscountedReturn   249.632
2017-06-10 23:10:33.124370 EDT | AverageQLoss                2.67612
2017-06-10 23:10:33.124895 EDT | AveragePolicySurr         -32.3135
2017-06-10 23:10:33.125230 EDT | AverageQ                   31.9061
2017-06-10 23:10:33.125669 EDT | AverageAbsQ                31.9392
2017-06-10 23:10:33.126018 EDT | AverageY                   31.9071
2017-06-10 23:10:33.126351 EDT | AverageAbsY                31.9254
2017-06-10 23:10:33.126760 EDT | AverageAbsQYDiff            0.605374
2017-06-10 23:10:33.127035 EDT | AverageAction               0.942361
2017-06-10 23:10:33.127363 EDT | PolicyRegParamNorm         74.9489
2017-06-10 23:10:33.127698 EDT | QFunRegParamNorm           95.3406
2017-06-10 23:10:33.128101 EDT | -----------------------  -----------
2017-06-10 23:10:33.128551 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #515 | Training started
2017-06-10 23:10:48.838070 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #515 | Training finished
2017-06-10 23:10:48.838998 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #515 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 23:10:48.839384 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #515 | Collecting samples for evaluation
2017-06-10 23:11:00.940699 EDT | -----------------------  -----------
2017-06-10 23:11:00.945039 EDT | Epoch                     515
2017-06-10 23:11:00.945358 EDT | Iteration                 515
2017-06-10 23:11:00.945617 EDT | AverageReturn            1023.43
2017-06-10 23:11:00.945882 EDT | StdReturn                 502.095
2017-06-10 23:11:00.946133 EDT | MaxReturn                2265.19
2017-06-10 23:11:00.946378 EDT | MinReturn                 438.798
2017-06-10 23:11:00.946699 EDT | AverageEsReturn           408.514
2017-06-10 23:11:00.947032 EDT | StdEsReturn               285.851
2017-06-10 23:11:00.947373 EDT | MaxEsReturn               844.277
2017-06-10 23:11:00.947710 EDT | MinEsReturn               105.918
2017-06-10 23:11:00.948049 EDT | AverageDiscountedReturn   221.925
2017-06-10 23:11:00.948392 EDT | AverageQLoss                2.64383
2017-06-10 23:11:00.948730 EDT | AveragePolicySurr         -32.2807
2017-06-10 23:11:00.949073 EDT | AverageQ                   31.8311
2017-06-10 23:11:00.949416 EDT | AverageAbsQ                31.8684
2017-06-10 23:11:00.960711 EDT | AverageY                   31.8312
2017-06-10 23:11:00.961036 EDT | AverageAbsY                31.852
2017-06-10 23:11:00.961297 EDT | AverageAbsQYDiff            0.6088
2017-06-10 23:11:00.961554 EDT | AverageAction               0.946234
2017-06-10 23:11:00.961821 EDT | PolicyRegParamNorm         74.9764
2017-06-10 23:11:00.962072 EDT | QFunRegParamNorm           95.4625
2017-06-10 23:11:00.962322 EDT | -----------------------  -----------
2017-06-10 23:11:00.962743 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #516 | Training started
2017-06-10 23:11:15.260155 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #516 | Training finished
2017-06-10 23:11:15.261103 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #516 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 23:11:15.261508 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #516 | Collecting samples for evaluation
2017-06-10 23:11:29.739952 EDT | -----------------------  -----------
2017-06-10 23:11:29.740941 EDT | Epoch                     516
2017-06-10 23:11:29.741337 EDT | Iteration                 516
2017-06-10 23:11:29.741684 EDT | AverageReturn            1160.89
2017-06-10 23:11:29.742056 EDT | StdReturn                 708.74
2017-06-10 23:11:29.742435 EDT | MaxReturn                2726.44
2017-06-10 23:11:29.742804 EDT | MinReturn                 561.167
2017-06-10 23:11:29.743138 EDT | AverageEsReturn           450.956
2017-06-10 23:11:29.743460 EDT | StdEsReturn               262.132
2017-06-10 23:11:29.743794 EDT | MaxEsReturn              1002.47
2017-06-10 23:11:29.753910 EDT | MinEsReturn               240.599
2017-06-10 23:11:29.765908 EDT | AverageDiscountedReturn   220.332
2017-06-10 23:11:29.766458 EDT | AverageQLoss                2.47506
2017-06-10 23:11:29.766912 EDT | AveragePolicySurr         -32.3284
2017-06-10 23:11:29.767361 EDT | AverageQ                   31.9177
2017-06-10 23:11:29.767811 EDT | AverageAbsQ                31.9508
2017-06-10 23:11:29.768258 EDT | AverageY                   31.9201
2017-06-10 23:11:29.768707 EDT | AverageAbsY                31.944
2017-06-10 23:11:29.769155 EDT | AverageAbsQYDiff            0.584604
2017-06-10 23:11:29.769602 EDT | AverageAction               0.943712
2017-06-10 23:11:29.770064 EDT | PolicyRegParamNorm         75.0406
2017-06-10 23:11:29.770508 EDT | QFunRegParamNorm           95.5377
2017-06-10 23:11:29.770956 EDT | -----------------------  -----------
2017-06-10 23:11:29.771605 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #517 | Training started
2017-06-10 23:11:45.168042 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #517 | Training finished
2017-06-10 23:11:45.169068 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #517 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 23:11:45.169482 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #517 | Collecting samples for evaluation
2017-06-10 23:11:59.677653 EDT | -----------------------  -----------
2017-06-10 23:11:59.678763 EDT | Epoch                     517
2017-06-10 23:11:59.679128 EDT | Iteration                 517
2017-06-10 23:11:59.679480 EDT | AverageReturn            1213.45
2017-06-10 23:11:59.679816 EDT | StdReturn                 487.589
2017-06-10 23:11:59.680851 EDT | MaxReturn                2217.63
2017-06-10 23:11:59.682305 EDT | MinReturn                 560.288
2017-06-10 23:11:59.682672 EDT | AverageEsReturn           589.388
2017-06-10 23:11:59.683005 EDT | StdEsReturn               417.832
2017-06-10 23:11:59.684120 EDT | MaxEsReturn              1217.03
2017-06-10 23:11:59.685436 EDT | MinEsReturn                85.4898
2017-06-10 23:11:59.685825 EDT | AverageDiscountedReturn   224.507
2017-06-10 23:11:59.686176 EDT | AverageQLoss                2.6583
2017-06-10 23:11:59.686510 EDT | AveragePolicySurr         -32.2747
2017-06-10 23:11:59.686892 EDT | AverageQ                   31.8523
2017-06-10 23:11:59.687337 EDT | AverageAbsQ                31.8899
2017-06-10 23:11:59.687666 EDT | AverageY                   31.8519
2017-06-10 23:11:59.688153 EDT | AverageAbsY                31.8777
2017-06-10 23:11:59.688490 EDT | AverageAbsQYDiff            0.599596
2017-06-10 23:11:59.688818 EDT | AverageAction               0.97673
2017-06-10 23:11:59.689161 EDT | PolicyRegParamNorm         75.1069
2017-06-10 23:11:59.689740 EDT | QFunRegParamNorm           95.6121
2017-06-10 23:11:59.690096 EDT | -----------------------  -----------
2017-06-10 23:11:59.690580 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #518 | Training started
2017-06-10 23:12:15.558819 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #518 | Training finished
2017-06-10 23:12:15.559868 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #518 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 23:12:15.560280 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #518 | Collecting samples for evaluation
2017-06-10 23:12:28.881431 EDT | -----------------------  -----------
2017-06-10 23:12:28.882321 EDT | Epoch                     518
2017-06-10 23:12:28.883029 EDT | Iteration                 518
2017-06-10 23:12:28.883370 EDT | AverageReturn            1427.92
2017-06-10 23:12:28.883706 EDT | StdReturn                 726.079
2017-06-10 23:12:28.884045 EDT | MaxReturn                2597.81
2017-06-10 23:12:28.884532 EDT | MinReturn                 618.76
2017-06-10 23:12:28.884712 EDT | AverageEsReturn           772.589
2017-06-10 23:12:28.884983 EDT | StdEsReturn               495.249
2017-06-10 23:12:28.885164 EDT | MaxEsReturn              1329.31
2017-06-10 23:12:28.886108 EDT | MinEsReturn               126.187
2017-06-10 23:12:28.886442 EDT | AverageDiscountedReturn   223.979
2017-06-10 23:12:28.887472 EDT | AverageQLoss                2.77552
2017-06-10 23:12:28.887952 EDT | AveragePolicySurr         -32.3331
2017-06-10 23:12:28.888300 EDT | AverageQ                   31.9037
2017-06-10 23:12:28.888634 EDT | AverageAbsQ                31.9474
2017-06-10 23:12:28.888969 EDT | AverageY                   31.9033
2017-06-10 23:12:28.889317 EDT | AverageAbsY                31.9295
2017-06-10 23:12:28.889647 EDT | AverageAbsQYDiff            0.610327
2017-06-10 23:12:28.890003 EDT | AverageAction               0.978274
2017-06-10 23:12:28.890191 EDT | PolicyRegParamNorm         75.1255
2017-06-10 23:12:28.890381 EDT | QFunRegParamNorm           95.6369
2017-06-10 23:12:28.890733 EDT | -----------------------  -----------
2017-06-10 23:12:28.891071 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #519 | Training started
2017-06-10 23:12:45.625270 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #519 | Training finished
2017-06-10 23:12:45.626855 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #519 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 23:12:45.627386 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #519 | Collecting samples for evaluation
2017-06-10 23:12:59.292641 EDT | -----------------------  -----------
2017-06-10 23:12:59.293725 EDT | Epoch                     519
2017-06-10 23:12:59.294139 EDT | Iteration                 519
2017-06-10 23:12:59.294515 EDT | AverageReturn             470.145
2017-06-10 23:12:59.295610 EDT | StdReturn                 384.474
2017-06-10 23:12:59.296188 EDT | MaxReturn                2463.46
2017-06-10 23:12:59.296558 EDT | MinReturn                 188.892
2017-06-10 23:12:59.296930 EDT | AverageEsReturn           332.745
2017-06-10 23:12:59.297254 EDT | StdEsReturn               182.531
2017-06-10 23:12:59.297537 EDT | MaxEsReturn               608.731
2017-06-10 23:12:59.297982 EDT | MinEsReturn                42.608
2017-06-10 23:12:59.299127 EDT | AverageDiscountedReturn   165.109
2017-06-10 23:12:59.299548 EDT | AverageQLoss                2.62035
2017-06-10 23:12:59.299910 EDT | AveragePolicySurr         -32.305
2017-06-10 23:12:59.300266 EDT | AverageQ                   31.8751
2017-06-10 23:12:59.300799 EDT | AverageAbsQ                31.9143
2017-06-10 23:12:59.301209 EDT | AverageY                   31.8766
2017-06-10 23:12:59.301625 EDT | AverageAbsY                31.9057
2017-06-10 23:12:59.302025 EDT | AverageAbsQYDiff            0.594846
2017-06-10 23:12:59.302334 EDT | AverageAction               0.977528
2017-06-10 23:12:59.302736 EDT | PolicyRegParamNorm         75.1839
2017-06-10 23:12:59.303264 EDT | QFunRegParamNorm           95.7334
2017-06-10 23:12:59.303710 EDT | -----------------------  -----------
2017-06-10 23:12:59.304518 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #520 | Training started
2017-06-10 23:13:14.179427 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #520 | Training finished
2017-06-10 23:13:14.180424 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #520 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 23:13:14.180665 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #520 | Collecting samples for evaluation
2017-06-10 23:13:28.530810 EDT | -----------------------  -----------
2017-06-10 23:13:28.531708 EDT | Epoch                     520
2017-06-10 23:13:28.532181 EDT | Iteration                 520
2017-06-10 23:13:28.532823 EDT | AverageReturn             991.645
2017-06-10 23:13:28.533287 EDT | StdReturn                 529.632
2017-06-10 23:13:28.533846 EDT | MaxReturn                2857.25
2017-06-10 23:13:28.534362 EDT | MinReturn                  81.8231
2017-06-10 23:13:28.534774 EDT | AverageEsReturn           321.577
2017-06-10 23:13:28.535206 EDT | StdEsReturn               141.593
2017-06-10 23:13:28.535693 EDT | MaxEsReturn               617.306
2017-06-10 23:13:28.536122 EDT | MinEsReturn               159.113
2017-06-10 23:13:28.536707 EDT | AverageDiscountedReturn   222.945
2017-06-10 23:13:28.537139 EDT | AverageQLoss                3.00985
2017-06-10 23:13:28.537638 EDT | AveragePolicySurr         -32.2003
2017-06-10 23:13:28.538074 EDT | AverageQ                   31.7637
2017-06-10 23:13:28.538586 EDT | AverageAbsQ                31.8033
2017-06-10 23:13:28.539019 EDT | AverageY                   31.7658
2017-06-10 23:13:28.539527 EDT | AverageAbsY                31.7894
2017-06-10 23:13:28.539951 EDT | AverageAbsQYDiff            0.635182
2017-06-10 23:13:28.540379 EDT | AverageAction               0.966038
2017-06-10 23:13:28.541078 EDT | PolicyRegParamNorm         75.2851
2017-06-10 23:13:28.541934 EDT | QFunRegParamNorm           95.7887
2017-06-10 23:13:28.542427 EDT | -----------------------  -----------
2017-06-10 23:13:28.543010 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #521 | Training started
2017-06-10 23:13:42.991287 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #521 | Training finished
2017-06-10 23:13:43.090609 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #521 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 23:13:43.091327 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #521 | Collecting samples for evaluation
2017-06-10 23:13:56.262165 EDT | -----------------------  -----------
2017-06-10 23:13:56.265380 EDT | Epoch                     521
2017-06-10 23:13:56.265606 EDT | Iteration                 521
2017-06-10 23:13:56.265907 EDT | AverageReturn            1262.4
2017-06-10 23:13:56.271632 EDT | StdReturn                 419.122
2017-06-10 23:13:56.271831 EDT | MaxReturn                2374.29
2017-06-10 23:13:56.272068 EDT | MinReturn                 800.637
2017-06-10 23:13:56.272262 EDT | AverageEsReturn           503.26
2017-06-10 23:13:56.272462 EDT | StdEsReturn               171.159
2017-06-10 23:13:56.272654 EDT | MaxEsReturn               704.941
2017-06-10 23:13:56.272845 EDT | MinEsReturn               296.034
2017-06-10 23:13:56.273071 EDT | AverageDiscountedReturn   246.429
2017-06-10 23:13:56.273264 EDT | AverageQLoss                3.04108
2017-06-10 23:13:56.273463 EDT | AveragePolicySurr         -32.301
2017-06-10 23:13:56.273655 EDT | AverageQ                   31.8482
2017-06-10 23:13:56.273946 EDT | AverageAbsQ                31.887
2017-06-10 23:13:56.274138 EDT | AverageY                   31.8505
2017-06-10 23:13:56.274331 EDT | AverageAbsY                31.8757
2017-06-10 23:13:56.274641 EDT | AverageAbsQYDiff            0.630627
2017-06-10 23:13:56.274964 EDT | AverageAction               0.966981
2017-06-10 23:13:56.275272 EDT | PolicyRegParamNorm         75.3114
2017-06-10 23:13:56.276016 EDT | QFunRegParamNorm           95.9178
2017-06-10 23:13:56.278204 EDT | -----------------------  -----------
2017-06-10 23:13:56.279226 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #522 | Training started
2017-06-10 23:14:12.077556 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #522 | Training finished
2017-06-10 23:14:12.078612 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #522 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 23:14:12.079032 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #522 | Collecting samples for evaluation
2017-06-10 23:14:25.997229 EDT | -----------------------  -----------
2017-06-10 23:14:25.998184 EDT | Epoch                     522
2017-06-10 23:14:25.998566 EDT | Iteration                 522
2017-06-10 23:14:25.998931 EDT | AverageReturn            1140.1
2017-06-10 23:14:25.999290 EDT | StdReturn                 436.828
2017-06-10 23:14:25.999740 EDT | MaxReturn                2277.33
2017-06-10 23:14:26.000185 EDT | MinReturn                 686.18
2017-06-10 23:14:26.000626 EDT | AverageEsReturn           793.601
2017-06-10 23:14:26.001068 EDT | StdEsReturn               291.544
2017-06-10 23:14:26.001557 EDT | MaxEsReturn              1103.72
2017-06-10 23:14:26.002010 EDT | MinEsReturn               387.167
2017-06-10 23:14:26.002451 EDT | AverageDiscountedReturn   230.316
2017-06-10 23:14:26.002892 EDT | AverageQLoss                2.64175
2017-06-10 23:14:26.009878 EDT | AveragePolicySurr         -32.217
2017-06-10 23:14:26.010391 EDT | AverageQ                   31.7928
2017-06-10 23:14:26.010841 EDT | AverageAbsQ                31.8237
2017-06-10 23:14:26.011289 EDT | AverageY                   31.7931
2017-06-10 23:14:26.011740 EDT | AverageAbsY                31.8087
2017-06-10 23:14:26.012454 EDT | AverageAbsQYDiff            0.619654
2017-06-10 23:14:26.013294 EDT | AverageAction               0.965994
2017-06-10 23:14:26.014135 EDT | PolicyRegParamNorm         75.4107
2017-06-10 23:14:26.014972 EDT | QFunRegParamNorm           95.9952
2017-06-10 23:14:26.015808 EDT | -----------------------  -----------
2017-06-10 23:14:26.016844 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #523 | Training started
2017-06-10 23:14:43.473869 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #523 | Training finished
2017-06-10 23:14:43.474863 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #523 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 23:14:43.475232 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #523 | Collecting samples for evaluation
2017-06-10 23:14:54.911256 EDT | -----------------------  ----------
2017-06-10 23:14:54.913915 EDT | Epoch                    523
2017-06-10 23:14:54.914477 EDT | Iteration                523
2017-06-10 23:14:54.916621 EDT | AverageReturn            634.741
2017-06-10 23:14:54.917065 EDT | StdReturn                 39.34
2017-06-10 23:14:54.917594 EDT | MaxReturn                814.217
2017-06-10 23:14:54.918027 EDT | MinReturn                601.581
2017-06-10 23:14:54.918815 EDT | AverageEsReturn          212.127
2017-06-10 23:14:54.919829 EDT | StdEsReturn               91.7804
2017-06-10 23:14:54.923422 EDT | MaxEsReturn              321.868
2017-06-10 23:14:54.923808 EDT | MinEsReturn               57.9304
2017-06-10 23:14:54.924153 EDT | AverageDiscountedReturn  216.322
2017-06-10 23:14:54.924504 EDT | AverageQLoss               2.20934
2017-06-10 23:14:54.924967 EDT | AveragePolicySurr        -32.1714
2017-06-10 23:14:54.925315 EDT | AverageQ                  31.7621
2017-06-10 23:14:54.925658 EDT | AverageAbsQ               31.7955
2017-06-10 23:14:54.926021 EDT | AverageY                  31.7625
2017-06-10 23:14:54.926366 EDT | AverageAbsY               31.7842
2017-06-10 23:14:54.926710 EDT | AverageAbsQYDiff           0.563472
2017-06-10 23:14:54.927059 EDT | AverageAction              0.968298
2017-06-10 23:14:54.927403 EDT | PolicyRegParamNorm        75.4442
2017-06-10 23:14:54.927938 EDT | QFunRegParamNorm          96.0779
2017-06-10 23:14:54.930561 EDT | -----------------------  ----------
2017-06-10 23:14:54.931096 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #524 | Training started
2017-06-10 23:15:10.792011 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #524 | Training finished
2017-06-10 23:15:10.793975 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #524 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 23:15:10.794235 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #524 | Collecting samples for evaluation
2017-06-10 23:15:23.768183 EDT | -----------------------  -----------
2017-06-10 23:15:23.768950 EDT | Epoch                     524
2017-06-10 23:15:23.769306 EDT | Iteration                 524
2017-06-10 23:15:23.769862 EDT | AverageReturn             837.038
2017-06-10 23:15:23.770423 EDT | StdReturn                 677.948
2017-06-10 23:15:23.771112 EDT | MaxReturn                2698.32
2017-06-10 23:15:23.771611 EDT | MinReturn                 253.307
2017-06-10 23:15:23.771990 EDT | AverageEsReturn           616.594
2017-06-10 23:15:23.772365 EDT | StdEsReturn               310.281
2017-06-10 23:15:23.772762 EDT | MaxEsReturn              1044.76
2017-06-10 23:15:23.773169 EDT | MinEsReturn                70.5905
2017-06-10 23:15:23.774140 EDT | AverageDiscountedReturn   191.71
2017-06-10 23:15:23.774559 EDT | AverageQLoss                2.96342
2017-06-10 23:15:23.774989 EDT | AveragePolicySurr         -32.3306
2017-06-10 23:15:23.775410 EDT | AverageQ                   31.9307
2017-06-10 23:15:23.775840 EDT | AverageAbsQ                31.9638
2017-06-10 23:15:23.777041 EDT | AverageY                   31.9326
2017-06-10 23:15:23.777472 EDT | AverageAbsY                31.9484
2017-06-10 23:15:23.777797 EDT | AverageAbsQYDiff            0.604937
2017-06-10 23:15:23.778124 EDT | AverageAction               0.967135
2017-06-10 23:15:23.778461 EDT | PolicyRegParamNorm         75.5115
2017-06-10 23:15:23.778764 EDT | QFunRegParamNorm           96.1426
2017-06-10 23:15:23.779083 EDT | -----------------------  -----------
2017-06-10 23:15:23.779581 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #525 | Training started
2017-06-10 23:15:38.978414 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #525 | Training finished
2017-06-10 23:15:38.979957 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #525 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 23:15:38.980317 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #525 | Collecting samples for evaluation
2017-06-10 23:15:52.143271 EDT | -----------------------  -----------
2017-06-10 23:15:52.147775 EDT | Epoch                     525
2017-06-10 23:15:52.148201 EDT | Iteration                 525
2017-06-10 23:15:52.148558 EDT | AverageReturn             834.705
2017-06-10 23:15:52.148918 EDT | StdReturn                 288.288
2017-06-10 23:15:52.149271 EDT | MaxReturn                1324.64
2017-06-10 23:15:52.149619 EDT | MinReturn                 209.037
2017-06-10 23:15:52.149992 EDT | AverageEsReturn           389.447
2017-06-10 23:15:52.150336 EDT | StdEsReturn               191.478
2017-06-10 23:15:52.150683 EDT | MaxEsReturn               588.382
2017-06-10 23:15:52.151029 EDT | MinEsReturn                38.1763
2017-06-10 23:15:52.151373 EDT | AverageDiscountedReturn   213.798
2017-06-10 23:15:52.151717 EDT | AverageQLoss                2.59205
2017-06-10 23:15:52.152061 EDT | AveragePolicySurr         -32.3226
2017-06-10 23:15:52.152411 EDT | AverageQ                   31.8928
2017-06-10 23:15:52.152769 EDT | AverageAbsQ                31.925
2017-06-10 23:15:52.154037 EDT | AverageY                   31.8952
2017-06-10 23:15:52.154410 EDT | AverageAbsY                31.913
2017-06-10 23:15:52.154760 EDT | AverageAbsQYDiff            0.601759
2017-06-10 23:15:52.156559 EDT | AverageAction               0.971293
2017-06-10 23:15:52.156913 EDT | PolicyRegParamNorm         75.5562
2017-06-10 23:15:52.157265 EDT | QFunRegParamNorm           96.1775
2017-06-10 23:15:52.157613 EDT | -----------------------  -----------
2017-06-10 23:15:52.158111 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #526 | Training started
2017-06-10 23:16:07.246475 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #526 | Training finished
2017-06-10 23:16:07.250891 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #526 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 23:16:07.251297 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #526 | Collecting samples for evaluation
2017-06-10 23:16:19.718490 EDT | -----------------------  -----------
2017-06-10 23:16:19.719295 EDT | Epoch                     526
2017-06-10 23:16:19.719553 EDT | Iteration                 526
2017-06-10 23:16:19.719871 EDT | AverageReturn             929.467
2017-06-10 23:16:19.721071 EDT | StdReturn                 258.051
2017-06-10 23:16:19.721616 EDT | MaxReturn                1634.3
2017-06-10 23:16:19.721948 EDT | MinReturn                 651.835
2017-06-10 23:16:19.722400 EDT | AverageEsReturn           431.241
2017-06-10 23:16:19.722736 EDT | StdEsReturn               386.556
2017-06-10 23:16:19.723059 EDT | MaxEsReturn              1252.91
2017-06-10 23:16:19.723810 EDT | MinEsReturn                90.4437
2017-06-10 23:16:19.724299 EDT | AverageDiscountedReturn   226.62
2017-06-10 23:16:19.724618 EDT | AverageQLoss                2.40114
2017-06-10 23:16:19.724891 EDT | AveragePolicySurr         -32.3628
2017-06-10 23:16:19.725727 EDT | AverageQ                   31.9196
2017-06-10 23:16:19.726074 EDT | AverageAbsQ                31.9463
2017-06-10 23:16:19.726417 EDT | AverageY                   31.9206
2017-06-10 23:16:19.726747 EDT | AverageAbsY                31.9341
2017-06-10 23:16:19.727069 EDT | AverageAbsQYDiff            0.588288
2017-06-10 23:16:19.727364 EDT | AverageAction               0.971956
2017-06-10 23:16:19.727897 EDT | PolicyRegParamNorm         75.6463
2017-06-10 23:16:19.728296 EDT | QFunRegParamNorm           96.2223
2017-06-10 23:16:19.728630 EDT | -----------------------  -----------
2017-06-10 23:16:19.730038 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #527 | Training started
2017-06-10 23:16:35.728261 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #527 | Training finished
2017-06-10 23:16:35.729224 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #527 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 23:16:35.729540 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #527 | Collecting samples for evaluation
2017-06-10 23:16:47.826988 EDT | -----------------------  -----------
2017-06-10 23:16:47.827721 EDT | Epoch                     527
2017-06-10 23:16:47.827911 EDT | Iteration                 527
2017-06-10 23:16:47.828099 EDT | AverageReturn             671.997
2017-06-10 23:16:47.828281 EDT | StdReturn                 187.664
2017-06-10 23:16:47.828460 EDT | MaxReturn                1452.97
2017-06-10 23:16:47.828639 EDT | MinReturn                 524.955
2017-06-10 23:16:47.828818 EDT | AverageEsReturn           531.544
2017-06-10 23:16:47.828998 EDT | StdEsReturn               195.08
2017-06-10 23:16:47.829176 EDT | MaxEsReturn               782.284
2017-06-10 23:16:47.829362 EDT | MinEsReturn               254.183
2017-06-10 23:16:47.829538 EDT | AverageDiscountedReturn   208.595
2017-06-10 23:16:47.829732 EDT | AverageQLoss                2.6057
2017-06-10 23:16:47.829915 EDT | AveragePolicySurr         -32.3624
2017-06-10 23:16:47.830093 EDT | AverageQ                   31.9306
2017-06-10 23:16:47.830270 EDT | AverageAbsQ                31.9615
2017-06-10 23:16:47.830446 EDT | AverageY                   31.9312
2017-06-10 23:16:47.830670 EDT | AverageAbsY                31.9479
2017-06-10 23:16:47.830854 EDT | AverageAbsQYDiff            0.601411
2017-06-10 23:16:47.831032 EDT | AverageAction               0.97879
2017-06-10 23:16:47.831209 EDT | PolicyRegParamNorm         75.709
2017-06-10 23:16:47.831434 EDT | QFunRegParamNorm           96.3077
2017-06-10 23:16:47.831719 EDT | -----------------------  -----------
2017-06-10 23:16:47.832241 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #528 | Training started
2017-06-10 23:17:04.930820 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #528 | Training finished
2017-06-10 23:17:04.931746 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #528 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 23:17:04.932022 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #528 | Collecting samples for evaluation
2017-06-10 23:17:18.319981 EDT | -----------------------  ----------
2017-06-10 23:17:18.320957 EDT | Epoch                    528
2017-06-10 23:17:18.321284 EDT | Iteration                528
2017-06-10 23:17:18.321609 EDT | AverageReturn             64.8996
2017-06-10 23:17:18.322003 EDT | StdReturn                 33.7874
2017-06-10 23:17:18.322341 EDT | MaxReturn                610.065
2017-06-10 23:17:18.322663 EDT | MinReturn                 48.3564
2017-06-10 23:17:18.322985 EDT | AverageEsReturn          317.711
2017-06-10 23:17:18.323306 EDT | StdEsReturn              201.77
2017-06-10 23:17:18.323674 EDT | MaxEsReturn              793.397
2017-06-10 23:17:18.324379 EDT | MinEsReturn               78.5891
2017-06-10 23:17:18.324582 EDT | AverageDiscountedReturn   52.7085
2017-06-10 23:17:18.324769 EDT | AverageQLoss               2.85046
2017-06-10 23:17:18.324953 EDT | AveragePolicySurr        -32.3722
2017-06-10 23:17:18.325133 EDT | AverageQ                  31.9208
2017-06-10 23:17:18.325322 EDT | AverageAbsQ               31.9449
2017-06-10 23:17:18.325502 EDT | AverageY                  31.924
2017-06-10 23:17:18.325727 EDT | AverageAbsY               31.9352
2017-06-10 23:17:18.325913 EDT | AverageAbsQYDiff           0.610393
2017-06-10 23:17:18.326282 EDT | AverageAction              0.99876
2017-06-10 23:17:18.326631 EDT | PolicyRegParamNorm        75.6858
2017-06-10 23:17:18.326836 EDT | QFunRegParamNorm          96.3742
2017-06-10 23:17:18.327159 EDT | -----------------------  ----------
2017-06-10 23:17:18.328558 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #529 | Training started
2017-06-10 23:17:33.984339 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #529 | Training finished
2017-06-10 23:17:33.985136 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #529 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 23:17:33.985362 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #529 | Collecting samples for evaluation
2017-06-10 23:17:47.411875 EDT | -----------------------  -----------
2017-06-10 23:17:47.412809 EDT | Epoch                     529
2017-06-10 23:17:47.413160 EDT | Iteration                 529
2017-06-10 23:17:47.413475 EDT | AverageReturn             991.592
2017-06-10 23:17:47.413747 EDT | StdReturn                 294.569
2017-06-10 23:17:47.414000 EDT | MaxReturn                1608.93
2017-06-10 23:17:47.414256 EDT | MinReturn                 633.185
2017-06-10 23:17:47.414502 EDT | AverageEsReturn           377.166
2017-06-10 23:17:47.414747 EDT | StdEsReturn               305.975
2017-06-10 23:17:47.414991 EDT | MaxEsReturn               938.477
2017-06-10 23:17:47.415236 EDT | MinEsReturn                11.818
2017-06-10 23:17:47.415590 EDT | AverageDiscountedReturn   222.976
2017-06-10 23:17:47.415840 EDT | AverageQLoss                2.01312
2017-06-10 23:17:47.416086 EDT | AveragePolicySurr         -32.373
2017-06-10 23:17:47.416331 EDT | AverageQ                   31.9372
2017-06-10 23:17:47.416574 EDT | AverageAbsQ                31.9627
2017-06-10 23:17:47.416818 EDT | AverageY                   31.9373
2017-06-10 23:17:47.417062 EDT | AverageAbsY                31.9484
2017-06-10 23:17:47.417305 EDT | AverageAbsQYDiff            0.569999
2017-06-10 23:17:47.417559 EDT | AverageAction               0.959699
2017-06-10 23:17:47.417879 EDT | PolicyRegParamNorm         75.7847
2017-06-10 23:17:47.418271 EDT | QFunRegParamNorm           96.444
2017-06-10 23:17:47.418938 EDT | -----------------------  -----------
2017-06-10 23:17:47.419429 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #530 | Training started
2017-06-10 23:18:02.866832 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #530 | Training finished
2017-06-10 23:18:02.867705 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #530 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 23:18:02.868103 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #530 | Collecting samples for evaluation
2017-06-10 23:18:15.855374 EDT | -----------------------  -----------
2017-06-10 23:18:15.855857 EDT | Epoch                     530
2017-06-10 23:18:15.856142 EDT | Iteration                 530
2017-06-10 23:18:15.856421 EDT | AverageReturn             771.773
2017-06-10 23:18:15.856751 EDT | StdReturn                 462.605
2017-06-10 23:18:15.857065 EDT | MaxReturn                2176.29
2017-06-10 23:18:15.857371 EDT | MinReturn                 176.621
2017-06-10 23:18:15.857653 EDT | AverageEsReturn           442.593
2017-06-10 23:18:15.857965 EDT | StdEsReturn               247.851
2017-06-10 23:18:15.858280 EDT | MaxEsReturn               958.134
2017-06-10 23:18:15.858548 EDT | MinEsReturn               210.023
2017-06-10 23:18:15.858833 EDT | AverageDiscountedReturn   195.972
2017-06-10 23:18:15.859158 EDT | AverageQLoss                2.84092
2017-06-10 23:18:15.859355 EDT | AveragePolicySurr         -32.3548
2017-06-10 23:18:15.859525 EDT | AverageQ                   31.9226
2017-06-10 23:18:15.859846 EDT | AverageAbsQ                31.9484
2017-06-10 23:18:15.860164 EDT | AverageY                   31.9247
2017-06-10 23:18:15.860684 EDT | AverageAbsY                31.9366
2017-06-10 23:18:15.860945 EDT | AverageAbsQYDiff            0.615881
2017-06-10 23:18:15.861203 EDT | AverageAction               0.972811
2017-06-10 23:18:15.861603 EDT | PolicyRegParamNorm         75.8327
2017-06-10 23:18:15.862057 EDT | QFunRegParamNorm           96.5637
2017-06-10 23:18:15.862371 EDT | -----------------------  -----------
2017-06-10 23:18:15.862869 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #531 | Training started
2017-06-10 23:18:31.611686 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #531 | Training finished
2017-06-10 23:18:31.612635 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #531 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 23:18:31.613036 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #531 | Collecting samples for evaluation
2017-06-10 23:18:42.641601 EDT | -----------------------  -----------
2017-06-10 23:18:42.643361 EDT | Epoch                     531
2017-06-10 23:18:42.643650 EDT | Iteration                 531
2017-06-10 23:18:42.643905 EDT | AverageReturn             763.767
2017-06-10 23:18:42.645255 EDT | StdReturn                 420.631
2017-06-10 23:18:42.645527 EDT | MaxReturn                2566.01
2017-06-10 23:18:42.645790 EDT | MinReturn                 175.187
2017-06-10 23:18:42.646037 EDT | AverageEsReturn           615.42
2017-06-10 23:18:42.647247 EDT | StdEsReturn               436.932
2017-06-10 23:18:42.648626 EDT | MaxEsReturn              1146.09
2017-06-10 23:18:42.648881 EDT | MinEsReturn                31.5767
2017-06-10 23:18:42.649128 EDT | AverageDiscountedReturn   208.7
2017-06-10 23:18:42.649373 EDT | AverageQLoss                2.365
2017-06-10 23:18:42.650733 EDT | AveragePolicySurr         -32.3468
2017-06-10 23:18:42.650992 EDT | AverageQ                   31.931
2017-06-10 23:18:42.651242 EDT | AverageAbsQ                31.9564
2017-06-10 23:18:42.651484 EDT | AverageY                   31.9323
2017-06-10 23:18:42.654377 EDT | AverageAbsY                31.9436
2017-06-10 23:18:42.654632 EDT | AverageAbsQYDiff            0.599022
2017-06-10 23:18:42.654906 EDT | AverageAction               0.953731
2017-06-10 23:18:42.655152 EDT | PolicyRegParamNorm         75.9342
2017-06-10 23:18:42.655394 EDT | QFunRegParamNorm           96.6274
2017-06-10 23:18:42.655636 EDT | -----------------------  -----------
2017-06-10 23:18:42.656747 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #532 | Training started
2017-06-10 23:18:59.374327 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #532 | Training finished
2017-06-10 23:18:59.375439 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #532 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 23:18:59.375846 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #532 | Collecting samples for evaluation
2017-06-10 23:19:12.155766 EDT | -----------------------  -----------
2017-06-10 23:19:12.156975 EDT | Epoch                     532
2017-06-10 23:19:12.157518 EDT | Iteration                 532
2017-06-10 23:19:12.157896 EDT | AverageReturn             403.79
2017-06-10 23:19:12.158252 EDT | StdReturn                 264.184
2017-06-10 23:19:12.158914 EDT | MaxReturn                1008.59
2017-06-10 23:19:12.159195 EDT | MinReturn                 153.94
2017-06-10 23:19:12.159552 EDT | AverageEsReturn           627.385
2017-06-10 23:19:12.159889 EDT | StdEsReturn               291.826
2017-06-10 23:19:12.160299 EDT | MaxEsReturn               947.783
2017-06-10 23:19:12.160567 EDT | MinEsReturn               159.726
2017-06-10 23:19:12.160817 EDT | AverageDiscountedReturn   160.77
2017-06-10 23:19:12.161060 EDT | AverageQLoss                2.83024
2017-06-10 23:19:12.161381 EDT | AveragePolicySurr         -32.3171
2017-06-10 23:19:12.161870 EDT | AverageQ                   31.8906
2017-06-10 23:19:12.162237 EDT | AverageAbsQ                31.9169
2017-06-10 23:19:12.162495 EDT | AverageY                   31.8893
2017-06-10 23:19:12.162747 EDT | AverageAbsY                31.9052
2017-06-10 23:19:12.163046 EDT | AverageAbsQYDiff            0.612162
2017-06-10 23:19:12.163381 EDT | AverageAction               0.950793
2017-06-10 23:19:12.163806 EDT | PolicyRegParamNorm         75.9671
2017-06-10 23:19:12.164087 EDT | QFunRegParamNorm           96.6954
2017-06-10 23:19:12.164343 EDT | -----------------------  -----------
2017-06-10 23:19:12.164768 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #533 | Training started
2017-06-10 23:19:27.279060 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #533 | Training finished
2017-06-10 23:19:27.279979 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #533 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 23:19:27.280323 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #533 | Collecting samples for evaluation
2017-06-10 23:19:40.265014 EDT | -----------------------  -----------
2017-06-10 23:19:40.265474 EDT | Epoch                     533
2017-06-10 23:19:40.265900 EDT | Iteration                 533
2017-06-10 23:19:40.266254 EDT | AverageReturn             800.284
2017-06-10 23:19:40.266603 EDT | StdReturn                 198.142
2017-06-10 23:19:40.266948 EDT | MaxReturn                1246.28
2017-06-10 23:19:40.267294 EDT | MinReturn                 570.743
2017-06-10 23:19:40.272966 EDT | AverageEsReturn           343.54
2017-06-10 23:19:40.273333 EDT | StdEsReturn               221.341
2017-06-10 23:19:40.276869 EDT | MaxEsReturn               735.089
2017-06-10 23:19:40.277225 EDT | MinEsReturn                 7.91296
2017-06-10 23:19:40.277577 EDT | AverageDiscountedReturn   221.597
2017-06-10 23:19:40.277940 EDT | AverageQLoss                2.56466
2017-06-10 23:19:40.278289 EDT | AveragePolicySurr         -32.3398
2017-06-10 23:19:40.278639 EDT | AverageQ                   31.9225
2017-06-10 23:19:40.279054 EDT | AverageAbsQ                31.947
2017-06-10 23:19:40.279401 EDT | AverageY                   31.9232
2017-06-10 23:19:40.279745 EDT | AverageAbsY                31.9337
2017-06-10 23:19:40.280087 EDT | AverageAbsQYDiff            0.585924
2017-06-10 23:19:40.280431 EDT | AverageAction               0.950189
2017-06-10 23:19:40.280775 EDT | PolicyRegParamNorm         76.0358
2017-06-10 23:19:40.281118 EDT | QFunRegParamNorm           96.7616
2017-06-10 23:19:40.281462 EDT | -----------------------  -----------
2017-06-10 23:19:40.282005 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #534 | Training started
2017-06-10 23:19:54.937932 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #534 | Training finished
2017-06-10 23:19:55.019894 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #534 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 23:19:55.020165 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #534 | Collecting samples for evaluation
2017-06-10 23:20:08.215028 EDT | -----------------------  -----------
2017-06-10 23:20:08.215862 EDT | Epoch                     534
2017-06-10 23:20:08.216232 EDT | Iteration                 534
2017-06-10 23:20:08.216580 EDT | AverageReturn            1024.83
2017-06-10 23:20:08.216876 EDT | StdReturn                 254.958
2017-06-10 23:20:08.217199 EDT | MaxReturn                1661.12
2017-06-10 23:20:08.217518 EDT | MinReturn                 664.162
2017-06-10 23:20:08.217788 EDT | AverageEsReturn           250.951
2017-06-10 23:20:08.218051 EDT | StdEsReturn               133.71
2017-06-10 23:20:08.218292 EDT | MaxEsReturn               542.625
2017-06-10 23:20:08.218543 EDT | MinEsReturn               108.418
2017-06-10 23:20:08.218782 EDT | AverageDiscountedReturn   224.043
2017-06-10 23:20:08.219039 EDT | AverageQLoss                2.6436
2017-06-10 23:20:08.219277 EDT | AveragePolicySurr         -32.3449
2017-06-10 23:20:08.219511 EDT | AverageQ                   31.9166
2017-06-10 23:20:08.219750 EDT | AverageAbsQ                31.9432
2017-06-10 23:20:08.220072 EDT | AverageY                   31.9185
2017-06-10 23:20:08.220357 EDT | AverageAbsY                31.9301
2017-06-10 23:20:08.220608 EDT | AverageAbsQYDiff            0.617984
2017-06-10 23:20:08.220894 EDT | AverageAction               0.947867
2017-06-10 23:20:08.221234 EDT | PolicyRegParamNorm         76.1242
2017-06-10 23:20:08.221576 EDT | QFunRegParamNorm           96.801
2017-06-10 23:20:08.221931 EDT | -----------------------  -----------
2017-06-10 23:20:08.222447 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #535 | Training started
2017-06-10 23:20:24.226787 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #535 | Training finished
2017-06-10 23:20:24.227807 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #535 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 23:20:24.228030 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #535 | Collecting samples for evaluation
2017-06-10 23:20:36.333095 EDT | -----------------------  -----------
2017-06-10 23:20:36.333814 EDT | Epoch                     535
2017-06-10 23:20:36.334014 EDT | Iteration                 535
2017-06-10 23:20:36.335224 EDT | AverageReturn            1289.76
2017-06-10 23:20:36.335408 EDT | StdReturn                 590.065
2017-06-10 23:20:36.336001 EDT | MaxReturn                3160.05
2017-06-10 23:20:36.336267 EDT | MinReturn                 613.973
2017-06-10 23:20:36.336422 EDT | AverageEsReturn           549.155
2017-06-10 23:20:36.336603 EDT | StdEsReturn               522.599
2017-06-10 23:20:36.336789 EDT | MaxEsReturn              1319.43
2017-06-10 23:20:36.336940 EDT | MinEsReturn                10.5844
2017-06-10 23:20:36.337120 EDT | AverageDiscountedReturn   230.543
2017-06-10 23:20:36.337406 EDT | AverageQLoss                2.48196
2017-06-10 23:20:36.337691 EDT | AveragePolicySurr         -32.3243
2017-06-10 23:20:36.338017 EDT | AverageQ                   31.9099
2017-06-10 23:20:36.338338 EDT | AverageAbsQ                31.9347
2017-06-10 23:20:36.338673 EDT | AverageY                   31.9129
2017-06-10 23:20:36.338994 EDT | AverageAbsY                31.9235
2017-06-10 23:20:36.339327 EDT | AverageAbsQYDiff            0.587662
2017-06-10 23:20:36.339650 EDT | AverageAction               0.95231
2017-06-10 23:20:36.339974 EDT | PolicyRegParamNorm         76.1611
2017-06-10 23:20:36.340820 EDT | QFunRegParamNorm           96.9104
2017-06-10 23:20:36.341110 EDT | -----------------------  -----------
2017-06-10 23:20:36.341575 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #536 | Training started
2017-06-10 23:20:52.750289 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #536 | Training finished
2017-06-10 23:20:52.753877 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #536 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 23:20:52.754328 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #536 | Collecting samples for evaluation
2017-06-10 23:21:04.872718 EDT | -----------------------  -----------
2017-06-10 23:21:04.887024 EDT | Epoch                     536
2017-06-10 23:21:04.887345 EDT | Iteration                 536
2017-06-10 23:21:04.887628 EDT | AverageReturn            1350.27
2017-06-10 23:21:04.887896 EDT | StdReturn                 628.984
2017-06-10 23:21:04.888224 EDT | MaxReturn                3077.41
2017-06-10 23:21:04.888548 EDT | MinReturn                 607.355
2017-06-10 23:21:04.888862 EDT | AverageEsReturn           383.451
2017-06-10 23:21:04.889207 EDT | StdEsReturn               375.861
2017-06-10 23:21:04.889537 EDT | MaxEsReturn               989.953
2017-06-10 23:21:04.889876 EDT | MinEsReturn                10.4367
2017-06-10 23:21:04.890196 EDT | AverageDiscountedReturn   237.448
2017-06-10 23:21:04.890489 EDT | AverageQLoss                2.62011
2017-06-10 23:21:04.890814 EDT | AveragePolicySurr         -32.297
2017-06-10 23:21:04.891142 EDT | AverageQ                   31.869
2017-06-10 23:21:04.891402 EDT | AverageAbsQ                31.8994
2017-06-10 23:21:04.893002 EDT | AverageY                   31.8683
2017-06-10 23:21:04.893352 EDT | AverageAbsY                31.8843
2017-06-10 23:21:04.894040 EDT | AverageAbsQYDiff            0.606746
2017-06-10 23:21:04.894359 EDT | AverageAction               0.95112
2017-06-10 23:21:04.894655 EDT | PolicyRegParamNorm         76.1789
2017-06-10 23:21:04.894971 EDT | QFunRegParamNorm           97.027
2017-06-10 23:21:04.895240 EDT | -----------------------  -----------
2017-06-10 23:21:04.895709 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #537 | Training started
2017-06-10 23:21:20.014547 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #537 | Training finished
2017-06-10 23:21:20.015326 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #537 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 23:21:20.015518 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #537 | Collecting samples for evaluation
2017-06-10 23:21:34.724762 EDT | -----------------------  -----------
2017-06-10 23:21:34.725642 EDT | Epoch                     537
2017-06-10 23:21:34.725947 EDT | Iteration                 537
2017-06-10 23:21:34.726138 EDT | AverageReturn            1374.99
2017-06-10 23:21:34.726379 EDT | StdReturn                 589.231
2017-06-10 23:21:34.726693 EDT | MaxReturn                2762.11
2017-06-10 23:21:34.727017 EDT | MinReturn                 462.608
2017-06-10 23:21:34.727278 EDT | AverageEsReturn           416.559
2017-06-10 23:21:34.727520 EDT | StdEsReturn               180.485
2017-06-10 23:21:34.727765 EDT | MaxEsReturn               583.964
2017-06-10 23:21:34.728046 EDT | MinEsReturn               140.765
2017-06-10 23:21:34.728254 EDT | AverageDiscountedReturn   232.774
2017-06-10 23:21:34.728452 EDT | AverageQLoss                2.39722
2017-06-10 23:21:34.728738 EDT | AveragePolicySurr         -32.3326
2017-06-10 23:21:34.728890 EDT | AverageQ                   31.9084
2017-06-10 23:21:34.729168 EDT | AverageAbsQ                31.9446
2017-06-10 23:21:34.729456 EDT | AverageY                   31.9101
2017-06-10 23:21:34.729721 EDT | AverageAbsY                31.9299
2017-06-10 23:21:34.730017 EDT | AverageAbsQYDiff            0.590797
2017-06-10 23:21:34.730316 EDT | AverageAction               0.956105
2017-06-10 23:21:34.730640 EDT | PolicyRegParamNorm         76.188
2017-06-10 23:21:34.730953 EDT | QFunRegParamNorm           97.0839
2017-06-10 23:21:34.731143 EDT | -----------------------  -----------
2017-06-10 23:21:34.731448 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #538 | Training started
2017-06-10 23:21:49.203119 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #538 | Training finished
2017-06-10 23:21:49.205818 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #538 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 23:21:49.206224 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #538 | Collecting samples for evaluation
2017-06-10 23:22:01.521881 EDT | -----------------------  -----------
2017-06-10 23:22:01.522604 EDT | Epoch                     538
2017-06-10 23:22:01.522919 EDT | Iteration                 538
2017-06-10 23:22:01.523080 EDT | AverageReturn             854.181
2017-06-10 23:22:01.523233 EDT | StdReturn                 421.827
2017-06-10 23:22:01.523384 EDT | MaxReturn                2477.61
2017-06-10 23:22:01.523736 EDT | MinReturn                 572.341
2017-06-10 23:22:01.523934 EDT | AverageEsReturn           298.381
2017-06-10 23:22:01.524380 EDT | StdEsReturn               249.909
2017-06-10 23:22:01.524565 EDT | MaxEsReturn               847.345
2017-06-10 23:22:01.525109 EDT | MinEsReturn               106.769
2017-06-10 23:22:01.525444 EDT | AverageDiscountedReturn   209.434
2017-06-10 23:22:01.525840 EDT | AverageQLoss                2.71358
2017-06-10 23:22:01.526008 EDT | AveragePolicySurr         -32.3333
2017-06-10 23:22:01.526230 EDT | AverageQ                   31.9075
2017-06-10 23:22:01.527215 EDT | AverageAbsQ                31.9378
2017-06-10 23:22:01.527422 EDT | AverageY                   31.9099
2017-06-10 23:22:01.527606 EDT | AverageAbsY                31.9278
2017-06-10 23:22:01.527761 EDT | AverageAbsQYDiff            0.614172
2017-06-10 23:22:01.527995 EDT | AverageAction               0.969377
2017-06-10 23:22:01.528153 EDT | PolicyRegParamNorm         76.238
2017-06-10 23:22:01.528342 EDT | QFunRegParamNorm           97.1106
2017-06-10 23:22:01.528580 EDT | -----------------------  -----------
2017-06-10 23:22:01.528978 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #539 | Training started
2017-06-10 23:22:17.569451 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #539 | Training finished
2017-06-10 23:22:17.570083 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #539 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 23:22:17.570456 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #539 | Collecting samples for evaluation
2017-06-10 23:22:30.034856 EDT | -----------------------  -----------
2017-06-10 23:22:30.037745 EDT | Epoch                     539
2017-06-10 23:22:30.038116 EDT | Iteration                 539
2017-06-10 23:22:30.038438 EDT | AverageReturn             866.072
2017-06-10 23:22:30.038775 EDT | StdReturn                 266.407
2017-06-10 23:22:30.039254 EDT | MaxReturn                1660.58
2017-06-10 23:22:30.039623 EDT | MinReturn                 648.112
2017-06-10 23:22:30.040971 EDT | AverageEsReturn           628.714
2017-06-10 23:22:30.041291 EDT | StdEsReturn               231.861
2017-06-10 23:22:30.041961 EDT | MaxEsReturn               983.706
2017-06-10 23:22:30.042248 EDT | MinEsReturn               313.677
2017-06-10 23:22:30.042635 EDT | AverageDiscountedReturn   227.595
2017-06-10 23:22:30.043065 EDT | AverageQLoss                2.78553
2017-06-10 23:22:30.043387 EDT | AveragePolicySurr         -32.377
2017-06-10 23:22:30.043671 EDT | AverageQ                   31.9281
2017-06-10 23:22:30.044082 EDT | AverageAbsQ                31.9583
2017-06-10 23:22:30.044482 EDT | AverageY                   31.9272
2017-06-10 23:22:30.044913 EDT | AverageAbsY                31.9464
2017-06-10 23:22:30.045372 EDT | AverageAbsQYDiff            0.614023
2017-06-10 23:22:30.045811 EDT | AverageAction               0.965217
2017-06-10 23:22:30.046134 EDT | PolicyRegParamNorm         76.261
2017-06-10 23:22:30.046406 EDT | QFunRegParamNorm           97.2402
2017-06-10 23:22:30.046766 EDT | -----------------------  -----------
2017-06-10 23:22:30.047395 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #540 | Training started
2017-06-10 23:22:46.491950 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #540 | Training finished
2017-06-10 23:22:46.492979 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #540 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 23:22:46.493358 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #540 | Collecting samples for evaluation
2017-06-10 23:23:00.305416 EDT | -----------------------  -----------
2017-06-10 23:23:00.307503 EDT | Epoch                     540
2017-06-10 23:23:00.307773 EDT | Iteration                 540
2017-06-10 23:23:00.307985 EDT | AverageReturn            1420.61
2017-06-10 23:23:00.308155 EDT | StdReturn                 454.443
2017-06-10 23:23:00.308338 EDT | MaxReturn                2782.59
2017-06-10 23:23:00.308504 EDT | MinReturn                 907.567
2017-06-10 23:23:00.309407 EDT | AverageEsReturn           262
2017-06-10 23:23:00.309642 EDT | StdEsReturn               174.98
2017-06-10 23:23:00.309821 EDT | MaxEsReturn               553.582
2017-06-10 23:23:00.309976 EDT | MinEsReturn                61.5528
2017-06-10 23:23:00.310133 EDT | AverageDiscountedReturn   223.543
2017-06-10 23:23:00.310322 EDT | AverageQLoss                2.28785
2017-06-10 23:23:00.310578 EDT | AveragePolicySurr         -32.3504
2017-06-10 23:23:00.310770 EDT | AverageQ                   31.9248
2017-06-10 23:23:00.310921 EDT | AverageAbsQ                31.9517
2017-06-10 23:23:00.311070 EDT | AverageY                   31.9266
2017-06-10 23:23:00.311219 EDT | AverageAbsY                31.9409
2017-06-10 23:23:00.311367 EDT | AverageAbsQYDiff            0.592188
2017-06-10 23:23:00.311515 EDT | AverageAction               0.966768
2017-06-10 23:23:00.311717 EDT | PolicyRegParamNorm         76.3603
2017-06-10 23:23:00.311871 EDT | QFunRegParamNorm           97.3174
2017-06-10 23:23:00.312082 EDT | -----------------------  -----------
2017-06-10 23:23:00.312399 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #541 | Training started
2017-06-10 23:23:17.762058 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #541 | Training finished
2017-06-10 23:23:17.763687 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #541 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 23:23:17.764113 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #541 | Collecting samples for evaluation
2017-06-10 23:23:32.046672 EDT | -----------------------  -----------
2017-06-10 23:23:32.047669 EDT | Epoch                     541
2017-06-10 23:23:32.047990 EDT | Iteration                 541
2017-06-10 23:23:32.048313 EDT | AverageReturn            2153.43
2017-06-10 23:23:32.048629 EDT | StdReturn                 739.306
2017-06-10 23:23:32.048929 EDT | MaxReturn                3170.11
2017-06-10 23:23:32.049129 EDT | MinReturn                 992.864
2017-06-10 23:23:32.049437 EDT | AverageEsReturn           509.024
2017-06-10 23:23:32.049781 EDT | StdEsReturn               326.485
2017-06-10 23:23:32.050112 EDT | MaxEsReturn               972.471
2017-06-10 23:23:32.050334 EDT | MinEsReturn               109.341
2017-06-10 23:23:32.050653 EDT | AverageDiscountedReturn   248.582
2017-06-10 23:23:32.050980 EDT | AverageQLoss                2.74389
2017-06-10 23:23:32.051300 EDT | AveragePolicySurr         -32.3387
2017-06-10 23:23:32.051566 EDT | AverageQ                   31.9085
2017-06-10 23:23:32.051881 EDT | AverageAbsQ                31.9408
2017-06-10 23:23:32.052209 EDT | AverageY                   31.9113
2017-06-10 23:23:32.052541 EDT | AverageAbsY                31.9303
2017-06-10 23:23:32.052831 EDT | AverageAbsQYDiff            0.608148
2017-06-10 23:23:32.053159 EDT | AverageAction               0.952585
2017-06-10 23:23:32.053498 EDT | PolicyRegParamNorm         76.4266
2017-06-10 23:23:32.053825 EDT | QFunRegParamNorm           97.4028
2017-06-10 23:23:32.054149 EDT | -----------------------  -----------
2017-06-10 23:23:32.054657 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #542 | Training started
2017-06-10 23:23:48.431621 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #542 | Training finished
2017-06-10 23:23:48.432543 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #542 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 23:23:48.432765 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #542 | Collecting samples for evaluation
2017-06-10 23:24:02.813584 EDT | -----------------------  -----------
2017-06-10 23:24:02.814546 EDT | Epoch                     542
2017-06-10 23:24:02.814906 EDT | Iteration                 542
2017-06-10 23:24:02.815317 EDT | AverageReturn            2130.65
2017-06-10 23:24:02.815695 EDT | StdReturn                 769.219
2017-06-10 23:24:02.816038 EDT | MaxReturn                3099.75
2017-06-10 23:24:02.816408 EDT | MinReturn                 353.163
2017-06-10 23:24:02.816752 EDT | AverageEsReturn           632.717
2017-06-10 23:24:02.817114 EDT | StdEsReturn               520.552
2017-06-10 23:24:02.817512 EDT | MaxEsReturn              1412.37
2017-06-10 23:24:02.817873 EDT | MinEsReturn                10.2369
2017-06-10 23:24:02.818481 EDT | AverageDiscountedReturn   238.101
2017-06-10 23:24:02.818817 EDT | AverageQLoss                2.65023
2017-06-10 23:24:02.819222 EDT | AveragePolicySurr         -32.3946
2017-06-10 23:24:02.819484 EDT | AverageQ                   31.9775
2017-06-10 23:24:02.820565 EDT | AverageAbsQ                32.0143
2017-06-10 23:24:02.821908 EDT | AverageY                   31.9785
2017-06-10 23:24:02.822249 EDT | AverageAbsY                32.0017
2017-06-10 23:24:02.822593 EDT | AverageAbsQYDiff            0.605967
2017-06-10 23:24:02.822934 EDT | AverageAction               0.969569
2017-06-10 23:24:02.823283 EDT | PolicyRegParamNorm         76.5193
2017-06-10 23:24:02.823591 EDT | QFunRegParamNorm           97.4593
2017-06-10 23:24:02.823853 EDT | -----------------------  -----------
2017-06-10 23:24:02.824376 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #543 | Training started
2017-06-10 23:24:20.383646 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #543 | Training finished
2017-06-10 23:24:20.384648 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #543 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 23:24:20.385038 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #543 | Collecting samples for evaluation
2017-06-10 23:24:33.497361 EDT | -----------------------  -----------
2017-06-10 23:24:33.498548 EDT | Epoch                     543
2017-06-10 23:24:33.498753 EDT | Iteration                 543
2017-06-10 23:24:33.498924 EDT | AverageReturn             538.804
2017-06-10 23:24:33.499085 EDT | StdReturn                 347.162
2017-06-10 23:24:33.499281 EDT | MaxReturn                1362.28
2017-06-10 23:24:33.499479 EDT | MinReturn                 211.686
2017-06-10 23:24:33.499640 EDT | AverageEsReturn           634.358
2017-06-10 23:24:33.499798 EDT | StdEsReturn               387.085
2017-06-10 23:24:33.499955 EDT | MaxEsReturn              1152.09
2017-06-10 23:24:33.500111 EDT | MinEsReturn               189.833
2017-06-10 23:24:33.500441 EDT | AverageDiscountedReturn   182.724
2017-06-10 23:24:33.500809 EDT | AverageQLoss                2.71918
2017-06-10 23:24:33.501155 EDT | AveragePolicySurr         -32.3331
2017-06-10 23:24:33.501462 EDT | AverageQ                   31.9116
2017-06-10 23:24:33.501763 EDT | AverageAbsQ                31.9516
2017-06-10 23:24:33.501976 EDT | AverageY                   31.9146
2017-06-10 23:24:33.502129 EDT | AverageAbsY                31.9417
2017-06-10 23:24:33.502291 EDT | AverageAbsQYDiff            0.620841
2017-06-10 23:24:33.502533 EDT | AverageAction               0.965404
2017-06-10 23:24:33.502917 EDT | PolicyRegParamNorm         76.5116
2017-06-10 23:24:33.503239 EDT | QFunRegParamNorm           97.5331
2017-06-10 23:24:33.503556 EDT | -----------------------  -----------
2017-06-10 23:24:33.504031 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #544 | Training started
2017-06-10 23:24:50.296564 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #544 | Training finished
2017-06-10 23:24:50.297503 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #544 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 23:24:50.297889 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #544 | Collecting samples for evaluation
2017-06-10 23:25:03.211772 EDT | -----------------------  -----------
2017-06-10 23:25:03.212557 EDT | Epoch                     544
2017-06-10 23:25:03.212817 EDT | Iteration                 544
2017-06-10 23:25:03.213006 EDT | AverageReturn             977.033
2017-06-10 23:25:03.213190 EDT | StdReturn                 325.888
2017-06-10 23:25:03.213435 EDT | MaxReturn                1595
2017-06-10 23:25:03.213628 EDT | MinReturn                  84.0306
2017-06-10 23:25:03.213833 EDT | AverageEsReturn           387.232
2017-06-10 23:25:03.214015 EDT | StdEsReturn               261.138
2017-06-10 23:25:03.214196 EDT | MaxEsReturn               835.592
2017-06-10 23:25:03.214375 EDT | MinEsReturn                16.9141
2017-06-10 23:25:03.214635 EDT | AverageDiscountedReturn   227.516
2017-06-10 23:25:03.214813 EDT | AverageQLoss                2.70606
2017-06-10 23:25:03.214991 EDT | AveragePolicySurr         -32.2576
2017-06-10 23:25:03.215383 EDT | AverageQ                   31.8369
2017-06-10 23:25:03.215658 EDT | AverageAbsQ                31.8887
2017-06-10 23:25:03.215899 EDT | AverageY                   31.8364
2017-06-10 23:25:03.216085 EDT | AverageAbsY                31.8751
2017-06-10 23:25:03.216441 EDT | AverageAbsQYDiff            0.603883
2017-06-10 23:25:03.216702 EDT | AverageAction               0.968834
2017-06-10 23:25:03.216957 EDT | PolicyRegParamNorm         76.6137
2017-06-10 23:25:03.218931 EDT | QFunRegParamNorm           97.5762
2017-06-10 23:25:03.219570 EDT | -----------------------  -----------
2017-06-10 23:25:03.219934 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #545 | Training started
2017-06-10 23:25:20.811602 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #545 | Training finished
2017-06-10 23:25:20.812182 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #545 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 23:25:20.812546 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #545 | Collecting samples for evaluation
2017-06-10 23:25:34.393586 EDT | -----------------------  -----------
2017-06-10 23:25:34.394549 EDT | Epoch                     545
2017-06-10 23:25:34.394916 EDT | Iteration                 545
2017-06-10 23:25:34.395254 EDT | AverageReturn            2187.94
2017-06-10 23:25:34.395595 EDT | StdReturn                 779.833
2017-06-10 23:25:34.395924 EDT | MaxReturn                3228.37
2017-06-10 23:25:34.396251 EDT | MinReturn                 910.944
2017-06-10 23:25:34.396575 EDT | AverageEsReturn           316.633
2017-06-10 23:25:34.396898 EDT | StdEsReturn               194.314
2017-06-10 23:25:34.397223 EDT | MaxEsReturn               704.774
2017-06-10 23:25:34.397546 EDT | MinEsReturn                56.1927
2017-06-10 23:25:34.397881 EDT | AverageDiscountedReturn   243.664
2017-06-10 23:25:34.398203 EDT | AverageQLoss                2.77008
2017-06-10 23:25:34.398535 EDT | AveragePolicySurr         -32.2892
2017-06-10 23:25:34.398855 EDT | AverageQ                   31.8867
2017-06-10 23:25:34.399174 EDT | AverageAbsQ                31.934
2017-06-10 23:25:34.399492 EDT | AverageY                   31.8875
2017-06-10 23:25:34.399812 EDT | AverageAbsY                31.9236
2017-06-10 23:25:34.400139 EDT | AverageAbsQYDiff            0.608827
2017-06-10 23:25:34.400459 EDT | AverageAction               0.968852
2017-06-10 23:25:34.400778 EDT | PolicyRegParamNorm         76.6395
2017-06-10 23:25:34.401102 EDT | QFunRegParamNorm           97.6683
2017-06-10 23:25:34.401421 EDT | -----------------------  -----------
2017-06-10 23:25:34.401934 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #546 | Training started
2017-06-10 23:25:50.815852 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #546 | Training finished
2017-06-10 23:25:50.817383 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #546 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 23:25:50.818710 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #546 | Collecting samples for evaluation
2017-06-10 23:26:04.871869 EDT | -----------------------  -----------
2017-06-10 23:26:04.872779 EDT | Epoch                     546
2017-06-10 23:26:04.873021 EDT | Iteration                 546
2017-06-10 23:26:04.873212 EDT | AverageReturn            1491.77
2017-06-10 23:26:04.873501 EDT | StdReturn                 450.89
2017-06-10 23:26:04.873820 EDT | MaxReturn                2562.75
2017-06-10 23:26:04.874117 EDT | MinReturn                 666.38
2017-06-10 23:26:04.874365 EDT | AverageEsReturn           302.653
2017-06-10 23:26:04.874640 EDT | StdEsReturn               267.644
2017-06-10 23:26:04.874882 EDT | MaxEsReturn               846.213
2017-06-10 23:26:04.875089 EDT | MinEsReturn                75.3577
2017-06-10 23:26:04.875270 EDT | AverageDiscountedReturn   232.731
2017-06-10 23:26:04.875450 EDT | AverageQLoss                2.63684
2017-06-10 23:26:04.875664 EDT | AveragePolicySurr         -32.3243
2017-06-10 23:26:04.875928 EDT | AverageQ                   31.9372
2017-06-10 23:26:04.876108 EDT | AverageAbsQ                31.9797
2017-06-10 23:26:04.876319 EDT | AverageY                   31.9381
2017-06-10 23:26:04.876500 EDT | AverageAbsY                31.9668
2017-06-10 23:26:04.876680 EDT | AverageAbsQYDiff            0.607212
2017-06-10 23:26:04.876857 EDT | AverageAction               0.963047
2017-06-10 23:26:04.877036 EDT | PolicyRegParamNorm         76.6704
2017-06-10 23:26:04.877307 EDT | QFunRegParamNorm           97.7628
2017-06-10 23:26:04.877602 EDT | -----------------------  -----------
2017-06-10 23:26:04.878094 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #547 | Training started
2017-06-10 23:26:20.013765 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #547 | Training finished
2017-06-10 23:26:20.017367 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #547 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 23:26:20.017803 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #547 | Collecting samples for evaluation
2017-06-10 23:26:33.329012 EDT | -----------------------  -----------
2017-06-10 23:26:33.329890 EDT | Epoch                     547
2017-06-10 23:26:33.330214 EDT | Iteration                 547
2017-06-10 23:26:33.330570 EDT | AverageReturn            1459.14
2017-06-10 23:26:33.330872 EDT | StdReturn                 554.887
2017-06-10 23:26:33.331168 EDT | MaxReturn                2665.14
2017-06-10 23:26:33.332139 EDT | MinReturn                 835.22
2017-06-10 23:26:33.332452 EDT | AverageEsReturn           315.051
2017-06-10 23:26:33.332751 EDT | StdEsReturn               318.748
2017-06-10 23:26:33.333050 EDT | MaxEsReturn               901.938
2017-06-10 23:26:33.333347 EDT | MinEsReturn                11.2244
2017-06-10 23:26:33.333642 EDT | AverageDiscountedReturn   243.096
2017-06-10 23:26:33.333959 EDT | AverageQLoss                2.43854
2017-06-10 23:26:33.334251 EDT | AveragePolicySurr         -32.3594
2017-06-10 23:26:33.334541 EDT | AverageQ                   31.9475
2017-06-10 23:26:33.334830 EDT | AverageAbsQ                31.9898
2017-06-10 23:26:33.335115 EDT | AverageY                   31.9496
2017-06-10 23:26:33.335401 EDT | AverageAbsY                31.9781
2017-06-10 23:26:33.335683 EDT | AverageAbsQYDiff            0.586436
2017-06-10 23:26:33.335951 EDT | AverageAction               0.943957
2017-06-10 23:26:33.336223 EDT | PolicyRegParamNorm         76.7715
2017-06-10 23:26:33.336516 EDT | QFunRegParamNorm           97.8383
2017-06-10 23:26:33.336810 EDT | -----------------------  -----------
2017-06-10 23:26:33.337237 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #548 | Training started
2017-06-10 23:26:49.679924 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #548 | Training finished
2017-06-10 23:26:49.680737 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #548 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 23:26:49.680937 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #548 | Collecting samples for evaluation
2017-06-10 23:27:02.459043 EDT | -----------------------  -----------
2017-06-10 23:27:02.459988 EDT | Epoch                     548
2017-06-10 23:27:02.460175 EDT | Iteration                 548
2017-06-10 23:27:02.460486 EDT | AverageReturn            1494.61
2017-06-10 23:27:02.460756 EDT | StdReturn                 483.593
2017-06-10 23:27:02.461148 EDT | MaxReturn                2645.18
2017-06-10 23:27:02.461482 EDT | MinReturn                 866.06
2017-06-10 23:27:02.461817 EDT | AverageEsReturn           184.316
2017-06-10 23:27:02.462077 EDT | StdEsReturn               167.876
2017-06-10 23:27:02.462260 EDT | MaxEsReturn               539.698
2017-06-10 23:27:02.462652 EDT | MinEsReturn                 6.88965
2017-06-10 23:27:02.462838 EDT | AverageDiscountedReturn   218.545
2017-06-10 23:27:02.463170 EDT | AverageQLoss                3.17713
2017-06-10 23:27:02.463497 EDT | AveragePolicySurr         -32.1733
2017-06-10 23:27:02.464012 EDT | AverageQ                   31.7867
2017-06-10 23:27:02.464199 EDT | AverageAbsQ                31.8302
2017-06-10 23:27:02.464381 EDT | AverageY                   31.7868
2017-06-10 23:27:02.464561 EDT | AverageAbsY                31.8179
2017-06-10 23:27:02.464740 EDT | AverageAbsQYDiff            0.638805
2017-06-10 23:27:02.464918 EDT | AverageAction               0.969928
2017-06-10 23:27:02.465455 EDT | PolicyRegParamNorm         76.8209
2017-06-10 23:27:02.465763 EDT | QFunRegParamNorm           97.9494
2017-06-10 23:27:02.466040 EDT | -----------------------  -----------
2017-06-10 23:27:02.468394 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #549 | Training started
2017-06-10 23:27:18.161945 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #549 | Training finished
2017-06-10 23:27:18.165411 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #549 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 23:27:18.165838 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #549 | Collecting samples for evaluation
2017-06-10 23:27:30.515402 EDT | -----------------------  -----------
2017-06-10 23:27:30.516469 EDT | Epoch                     549
2017-06-10 23:27:30.516937 EDT | Iteration                 549
2017-06-10 23:27:30.517386 EDT | AverageReturn            1007.97
2017-06-10 23:27:30.517843 EDT | StdReturn                 353.494
2017-06-10 23:27:30.518291 EDT | MaxReturn                2288.09
2017-06-10 23:27:30.518734 EDT | MinReturn                 604.22
2017-06-10 23:27:30.519180 EDT | AverageEsReturn           807.712
2017-06-10 23:27:30.519626 EDT | StdEsReturn               693.958
2017-06-10 23:27:30.520071 EDT | MaxEsReturn              1736.13
2017-06-10 23:27:30.520519 EDT | MinEsReturn                68.0188
2017-06-10 23:27:30.520969 EDT | AverageDiscountedReturn   217.449
2017-06-10 23:27:30.521412 EDT | AverageQLoss                2.38289
2017-06-10 23:27:30.521871 EDT | AveragePolicySurr         -32.2363
2017-06-10 23:27:30.522313 EDT | AverageQ                   31.8094
2017-06-10 23:27:30.522764 EDT | AverageAbsQ                31.8569
2017-06-10 23:27:30.523206 EDT | AverageY                   31.8094
2017-06-10 23:27:30.523647 EDT | AverageAbsY                31.8463
2017-06-10 23:27:30.524087 EDT | AverageAbsQYDiff            0.577128
2017-06-10 23:27:30.524534 EDT | AverageAction               0.956746
2017-06-10 23:27:30.524979 EDT | PolicyRegParamNorm         76.8381
2017-06-10 23:27:30.525430 EDT | QFunRegParamNorm           98.0507
2017-06-10 23:27:30.525880 EDT | -----------------------  -----------
2017-06-10 23:27:30.526461 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #550 | Training started
2017-06-10 23:27:45.502106 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #550 | Training finished
2017-06-10 23:27:45.503150 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #550 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 23:27:45.503552 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #550 | Collecting samples for evaluation
2017-06-10 23:27:58.418645 EDT | -----------------------  -----------
2017-06-10 23:27:58.419825 EDT | Epoch                     550
2017-06-10 23:27:58.420451 EDT | Iteration                 550
2017-06-10 23:27:58.420893 EDT | AverageReturn             727.172
2017-06-10 23:27:58.421438 EDT | StdReturn                 250.987
2017-06-10 23:27:58.421875 EDT | MaxReturn                1059.83
2017-06-10 23:27:58.422313 EDT | MinReturn                  67.966
2017-06-10 23:27:58.422830 EDT | AverageEsReturn           493.964
2017-06-10 23:27:58.423261 EDT | StdEsReturn               369.703
2017-06-10 23:27:58.423801 EDT | MaxEsReturn              1146.91
2017-06-10 23:27:58.424211 EDT | MinEsReturn               111.719
2017-06-10 23:27:58.424644 EDT | AverageDiscountedReturn   214.734
2017-06-10 23:27:58.425168 EDT | AverageQLoss                2.85931
2017-06-10 23:27:58.425597 EDT | AveragePolicySurr         -32.2138
2017-06-10 23:27:58.426049 EDT | AverageQ                   31.8152
2017-06-10 23:27:58.426558 EDT | AverageAbsQ                31.862
2017-06-10 23:27:58.426987 EDT | AverageY                   31.8174
2017-06-10 23:27:58.427425 EDT | AverageAbsY                31.85
2017-06-10 23:27:58.427930 EDT | AverageAbsQYDiff            0.627514
2017-06-10 23:27:58.428342 EDT | AverageAction               0.951583
2017-06-10 23:27:58.428781 EDT | PolicyRegParamNorm         76.9273
2017-06-10 23:27:58.429316 EDT | QFunRegParamNorm           98.1442
2017-06-10 23:27:58.429749 EDT | -----------------------  -----------
2017-06-10 23:27:58.430359 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #551 | Training started
2017-06-10 23:28:13.266004 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #551 | Training finished
2017-06-10 23:28:13.266801 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #551 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 23:28:13.266993 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #551 | Collecting samples for evaluation
2017-06-10 23:28:26.322443 EDT | -----------------------  -----------
2017-06-10 23:28:26.323337 EDT | Epoch                     551
2017-06-10 23:28:26.323532 EDT | Iteration                 551
2017-06-10 23:28:26.323694 EDT | AverageReturn            1046.72
2017-06-10 23:28:26.323852 EDT | StdReturn                 595.855
2017-06-10 23:28:26.324021 EDT | MaxReturn                2576.43
2017-06-10 23:28:26.328195 EDT | MinReturn                  82.6207
2017-06-10 23:28:26.328728 EDT | AverageEsReturn           380.488
2017-06-10 23:28:26.329134 EDT | StdEsReturn               326.913
2017-06-10 23:28:26.329343 EDT | MaxEsReturn               954.283
2017-06-10 23:28:26.329512 EDT | MinEsReturn                85.0678
2017-06-10 23:28:26.329787 EDT | AverageDiscountedReturn   214.191
2017-06-10 23:28:26.329944 EDT | AverageQLoss                3.22526
2017-06-10 23:28:26.330096 EDT | AveragePolicySurr         -32.1162
2017-06-10 23:28:26.330247 EDT | AverageQ                   31.6714
2017-06-10 23:28:26.330398 EDT | AverageAbsQ                31.7201
2017-06-10 23:28:26.330598 EDT | AverageY                   31.6747
2017-06-10 23:28:26.330782 EDT | AverageAbsY                31.707
2017-06-10 23:28:26.330935 EDT | AverageAbsQYDiff            0.651485
2017-06-10 23:28:26.331184 EDT | AverageAction               0.948718
2017-06-10 23:28:26.331414 EDT | PolicyRegParamNorm         76.9875
2017-06-10 23:28:26.331565 EDT | QFunRegParamNorm           98.2737
2017-06-10 23:28:26.331807 EDT | -----------------------  -----------
2017-06-10 23:28:26.332166 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #552 | Training started
2017-06-10 23:28:40.681218 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #552 | Training finished
2017-06-10 23:28:40.682256 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #552 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 23:28:40.682663 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #552 | Collecting samples for evaluation
2017-06-10 23:28:53.794222 EDT | -----------------------  -----------
2017-06-10 23:28:53.794497 EDT | Epoch                     552
2017-06-10 23:28:53.794689 EDT | Iteration                 552
2017-06-10 23:28:53.795044 EDT | AverageReturn             674.458
2017-06-10 23:28:53.795349 EDT | StdReturn                 194.324
2017-06-10 23:28:53.795550 EDT | MaxReturn                1158.84
2017-06-10 23:28:53.795758 EDT | MinReturn                 307.588
2017-06-10 23:28:53.795951 EDT | AverageEsReturn           470.499
2017-06-10 23:28:53.796144 EDT | StdEsReturn               370.777
2017-06-10 23:28:53.796436 EDT | MaxEsReturn               944.816
2017-06-10 23:28:53.796638 EDT | MinEsReturn                79.3525
2017-06-10 23:28:53.796881 EDT | AverageDiscountedReturn   209.959
2017-06-10 23:28:53.797080 EDT | AverageQLoss                2.67103
2017-06-10 23:28:53.797273 EDT | AveragePolicySurr         -32.3127
2017-06-10 23:28:53.797480 EDT | AverageQ                   31.8867
2017-06-10 23:28:53.797829 EDT | AverageAbsQ                31.9202
2017-06-10 23:28:53.798135 EDT | AverageY                   31.8846
2017-06-10 23:28:53.798331 EDT | AverageAbsY                31.906
2017-06-10 23:28:53.798522 EDT | AverageAbsQYDiff            0.601553
2017-06-10 23:28:53.798713 EDT | AverageAction               0.945754
2017-06-10 23:28:53.798921 EDT | PolicyRegParamNorm         77.0522
2017-06-10 23:28:53.799112 EDT | QFunRegParamNorm           98.3279
2017-06-10 23:28:53.799305 EDT | -----------------------  -----------
2017-06-10 23:28:53.799621 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #553 | Training started
2017-06-10 23:29:09.253311 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #553 | Training finished
2017-06-10 23:29:09.257178 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #553 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 23:29:09.257859 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #553 | Collecting samples for evaluation
2017-06-10 23:29:22.250609 EDT | -----------------------  -----------
2017-06-10 23:29:22.253157 EDT | Epoch                     553
2017-06-10 23:29:22.253720 EDT | Iteration                 553
2017-06-10 23:29:22.254077 EDT | AverageReturn            1536.68
2017-06-10 23:29:22.254568 EDT | StdReturn                 530.527
2017-06-10 23:29:22.255088 EDT | MaxReturn                2983.25
2017-06-10 23:29:22.257011 EDT | MinReturn                 829.363
2017-06-10 23:29:22.257280 EDT | AverageEsReturn           635.351
2017-06-10 23:29:22.257642 EDT | StdEsReturn               210.489
2017-06-10 23:29:22.257925 EDT | MaxEsReturn               943.527
2017-06-10 23:29:22.258186 EDT | MinEsReturn               400.547
2017-06-10 23:29:22.258528 EDT | AverageDiscountedReturn   244.349
2017-06-10 23:29:22.258794 EDT | AverageQLoss                2.24288
2017-06-10 23:29:22.259583 EDT | AveragePolicySurr         -32.2845
2017-06-10 23:29:22.259794 EDT | AverageQ                   31.8401
2017-06-10 23:29:22.260023 EDT | AverageAbsQ                31.8758
2017-06-10 23:29:22.260295 EDT | AverageY                   31.841
2017-06-10 23:29:22.260503 EDT | AverageAbsY                31.8638
2017-06-10 23:29:22.260685 EDT | AverageAbsQYDiff            0.580587
2017-06-10 23:29:22.260865 EDT | AverageAction               0.963769
2017-06-10 23:29:22.261272 EDT | PolicyRegParamNorm         77.0804
2017-06-10 23:29:22.261574 EDT | QFunRegParamNorm           98.4339
2017-06-10 23:29:22.262036 EDT | -----------------------  -----------
2017-06-10 23:29:22.262427 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #554 | Training started
2017-06-10 23:29:38.520106 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #554 | Training finished
2017-06-10 23:29:38.520893 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #554 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 23:29:38.521086 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #554 | Collecting samples for evaluation
2017-06-10 23:29:51.543429 EDT | -----------------------  -----------
2017-06-10 23:29:51.544490 EDT | Epoch                     554
2017-06-10 23:29:51.544977 EDT | Iteration                 554
2017-06-10 23:29:51.545387 EDT | AverageReturn             799.085
2017-06-10 23:29:51.545856 EDT | StdReturn                 244.435
2017-06-10 23:29:51.546324 EDT | MaxReturn                1464.26
2017-06-10 23:29:51.546724 EDT | MinReturn                 466.054
2017-06-10 23:29:51.547185 EDT | AverageEsReturn           266.118
2017-06-10 23:29:51.547653 EDT | StdEsReturn               235.475
2017-06-10 23:29:51.548051 EDT | MaxEsReturn               759.459
2017-06-10 23:29:51.548509 EDT | MinEsReturn                32.9847
2017-06-10 23:29:51.548974 EDT | AverageDiscountedReturn   211.856
2017-06-10 23:29:51.549370 EDT | AverageQLoss                2.8862
2017-06-10 23:29:51.549835 EDT | AveragePolicySurr         -32.3456
2017-06-10 23:29:51.550298 EDT | AverageQ                   31.9023
2017-06-10 23:29:51.550696 EDT | AverageAbsQ                31.9356
2017-06-10 23:29:51.551157 EDT | AverageY                   31.9042
2017-06-10 23:29:51.551620 EDT | AverageAbsY                31.9272
2017-06-10 23:29:51.552016 EDT | AverageAbsQYDiff            0.632536
2017-06-10 23:29:51.552477 EDT | AverageAction               0.973286
2017-06-10 23:29:51.552942 EDT | PolicyRegParamNorm         77.1508
2017-06-10 23:29:51.553340 EDT | QFunRegParamNorm           98.5157
2017-06-10 23:29:51.553816 EDT | -----------------------  -----------
2017-06-10 23:29:51.554441 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #555 | Training started
2017-06-10 23:30:08.212006 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #555 | Training finished
2017-06-10 23:30:08.213002 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #555 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 23:30:08.213417 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #555 | Collecting samples for evaluation
2017-06-10 23:30:21.505901 EDT | -----------------------  -----------
2017-06-10 23:30:21.507589 EDT | Epoch                     555
2017-06-10 23:30:21.507934 EDT | Iteration                 555
2017-06-10 23:30:21.508178 EDT | AverageReturn             644.17
2017-06-10 23:30:21.508371 EDT | StdReturn                 158.325
2017-06-10 23:30:21.508639 EDT | MaxReturn                1248.24
2017-06-10 23:30:21.508926 EDT | MinReturn                 554.365
2017-06-10 23:30:21.509220 EDT | AverageEsReturn           306.946
2017-06-10 23:30:21.509503 EDT | StdEsReturn               209.163
2017-06-10 23:30:21.509814 EDT | MaxEsReturn               743.052
2017-06-10 23:30:21.510075 EDT | MinEsReturn                42.8612
2017-06-10 23:30:21.510326 EDT | AverageDiscountedReturn   200.351
2017-06-10 23:30:21.510578 EDT | AverageQLoss                2.96223
2017-06-10 23:30:21.510733 EDT | AveragePolicySurr         -32.2014
2017-06-10 23:30:21.510946 EDT | AverageQ                   31.7729
2017-06-10 23:30:21.511237 EDT | AverageAbsQ                31.811
2017-06-10 23:30:21.511490 EDT | AverageY                   31.7738
2017-06-10 23:30:21.511777 EDT | AverageAbsY                31.8009
2017-06-10 23:30:21.512062 EDT | AverageAbsQYDiff            0.618453
2017-06-10 23:30:21.512397 EDT | AverageAction               0.975115
2017-06-10 23:30:21.512714 EDT | PolicyRegParamNorm         77.2052
2017-06-10 23:30:21.513029 EDT | QFunRegParamNorm           98.5997
2017-06-10 23:30:21.513347 EDT | -----------------------  -----------
2017-06-10 23:30:21.513833 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #556 | Training started
2017-06-10 23:30:36.496801 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #556 | Training finished
2017-06-10 23:30:36.497958 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #556 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 23:30:36.498293 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #556 | Collecting samples for evaluation
2017-06-10 23:30:49.938830 EDT | -----------------------  -----------
2017-06-10 23:30:49.939907 EDT | Epoch                     556
2017-06-10 23:30:49.940225 EDT | Iteration                 556
2017-06-10 23:30:49.940572 EDT | AverageReturn             681.813
2017-06-10 23:30:49.940934 EDT | StdReturn                 138.788
2017-06-10 23:30:49.941368 EDT | MaxReturn                1279.59
2017-06-10 23:30:49.941732 EDT | MinReturn                 552.95
2017-06-10 23:30:49.942401 EDT | AverageEsReturn           372.805
2017-06-10 23:30:49.942787 EDT | StdEsReturn               232.407
2017-06-10 23:30:49.943066 EDT | MaxEsReturn               734.958
2017-06-10 23:30:49.943477 EDT | MinEsReturn               104.066
2017-06-10 23:30:49.943909 EDT | AverageDiscountedReturn   210.312
2017-06-10 23:30:49.944263 EDT | AverageQLoss                2.7941
2017-06-10 23:30:49.946256 EDT | AveragePolicySurr         -32.3668
2017-06-10 23:30:49.946594 EDT | AverageQ                   31.9258
2017-06-10 23:30:49.947041 EDT | AverageAbsQ                31.9606
2017-06-10 23:30:49.947386 EDT | AverageY                   31.9267
2017-06-10 23:30:49.947638 EDT | AverageAbsY                31.9483
2017-06-10 23:30:49.948060 EDT | AverageAbsQYDiff            0.611009
2017-06-10 23:30:49.948428 EDT | AverageAction               0.981979
2017-06-10 23:30:49.948783 EDT | PolicyRegParamNorm         77.2588
2017-06-10 23:30:49.949159 EDT | QFunRegParamNorm           98.6596
2017-06-10 23:30:49.949493 EDT | -----------------------  -----------
2017-06-10 23:30:49.950051 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #557 | Training started
2017-06-10 23:31:05.356217 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #557 | Training finished
2017-06-10 23:31:05.357159 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #557 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 23:31:05.357549 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #557 | Collecting samples for evaluation
2017-06-10 23:31:18.087241 EDT | -----------------------  -----------
2017-06-10 23:31:18.088242 EDT | Epoch                     557
2017-06-10 23:31:18.088661 EDT | Iteration                 557
2017-06-10 23:31:18.089118 EDT | AverageReturn            1274
2017-06-10 23:31:18.089561 EDT | StdReturn                 696.817
2017-06-10 23:31:18.090016 EDT | MaxReturn                2899.7
2017-06-10 23:31:18.090459 EDT | MinReturn                  78.0022
2017-06-10 23:31:18.090901 EDT | AverageEsReturn           292.227
2017-06-10 23:31:18.091344 EDT | StdEsReturn               232.263
2017-06-10 23:31:18.091797 EDT | MaxEsReturn               703.164
2017-06-10 23:31:18.092236 EDT | MinEsReturn                43.8929
2017-06-10 23:31:18.092677 EDT | AverageDiscountedReturn   219.775
2017-06-10 23:31:18.093123 EDT | AverageQLoss                2.73445
2017-06-10 23:31:18.093570 EDT | AveragePolicySurr         -32.3682
2017-06-10 23:31:18.094021 EDT | AverageQ                   31.9648
2017-06-10 23:31:18.094466 EDT | AverageAbsQ                31.9909
2017-06-10 23:31:18.094915 EDT | AverageY                   31.9672
2017-06-10 23:31:18.095359 EDT | AverageAbsY                31.9812
2017-06-10 23:31:18.095799 EDT | AverageAbsQYDiff            0.605173
2017-06-10 23:31:18.096244 EDT | AverageAction               0.979931
2017-06-10 23:31:18.096688 EDT | PolicyRegParamNorm         77.3015
2017-06-10 23:31:18.097139 EDT | QFunRegParamNorm           98.7347
2017-06-10 23:31:18.097579 EDT | -----------------------  -----------
2017-06-10 23:31:18.098146 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #558 | Training started
2017-06-10 23:31:34.493886 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #558 | Training finished
2017-06-10 23:31:34.494689 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #558 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 23:31:34.494985 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #558 | Collecting samples for evaluation
2017-06-10 23:31:47.410245 EDT | -----------------------  -----------
2017-06-10 23:31:47.411861 EDT | Epoch                     558
2017-06-10 23:31:47.412360 EDT | Iteration                 558
2017-06-10 23:31:47.412965 EDT | AverageReturn            1644.48
2017-06-10 23:31:47.413580 EDT | StdReturn                 592.692
2017-06-10 23:31:47.414086 EDT | MaxReturn                2790.77
2017-06-10 23:31:47.414561 EDT | MinReturn                 797.764
2017-06-10 23:31:47.415272 EDT | AverageEsReturn           407.977
2017-06-10 23:31:47.416020 EDT | StdEsReturn               175.96
2017-06-10 23:31:47.417764 EDT | MaxEsReturn               704.418
2017-06-10 23:31:47.418323 EDT | MinEsReturn               171.21
2017-06-10 23:31:47.418803 EDT | AverageDiscountedReturn   228.364
2017-06-10 23:31:47.419282 EDT | AverageQLoss                3.02095
2017-06-10 23:31:47.419880 EDT | AveragePolicySurr         -32.3203
2017-06-10 23:31:47.421762 EDT | AverageQ                   31.9167
2017-06-10 23:31:47.422455 EDT | AverageAbsQ                31.9496
2017-06-10 23:31:47.423204 EDT | AverageY                   31.9167
2017-06-10 23:31:47.423679 EDT | AverageAbsY                31.9322
2017-06-10 23:31:47.424270 EDT | AverageAbsQYDiff            0.623902
2017-06-10 23:31:47.424762 EDT | AverageAction               0.974832
2017-06-10 23:31:47.425324 EDT | PolicyRegParamNorm         77.4072
2017-06-10 23:31:47.425815 EDT | QFunRegParamNorm           98.7794
2017-06-10 23:31:47.426308 EDT | -----------------------  -----------
2017-06-10 23:31:47.427440 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #559 | Training started
2017-06-10 23:32:02.348780 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #559 | Training finished
2017-06-10 23:32:02.349467 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #559 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 23:32:02.349865 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #559 | Collecting samples for evaluation
2017-06-10 23:32:15.198718 EDT | -----------------------  -----------
2017-06-10 23:32:15.199806 EDT | Epoch                     559
2017-06-10 23:32:15.200173 EDT | Iteration                 559
2017-06-10 23:32:15.200515 EDT | AverageReturn             929.233
2017-06-10 23:32:15.200968 EDT | StdReturn                 302.491
2017-06-10 23:32:15.201391 EDT | MaxReturn                1818.98
2017-06-10 23:32:15.201847 EDT | MinReturn                 525.687
2017-06-10 23:32:15.202294 EDT | AverageEsReturn           430.894
2017-06-10 23:32:15.202738 EDT | StdEsReturn               369.087
2017-06-10 23:32:15.203181 EDT | MaxEsReturn              1143.08
2017-06-10 23:32:15.203621 EDT | MinEsReturn                82.5005
2017-06-10 23:32:15.203975 EDT | AverageDiscountedReturn   214.667
2017-06-10 23:32:15.204319 EDT | AverageQLoss                2.60982
2017-06-10 23:32:15.204656 EDT | AveragePolicySurr         -32.2307
2017-06-10 23:32:15.205011 EDT | AverageQ                   31.8143
2017-06-10 23:32:15.205367 EDT | AverageAbsQ                31.8492
2017-06-10 23:32:15.205785 EDT | AverageY                   31.8177
2017-06-10 23:32:15.206149 EDT | AverageAbsY                31.838
2017-06-10 23:32:15.206814 EDT | AverageAbsQYDiff            0.600896
2017-06-10 23:32:15.207172 EDT | AverageAction               0.959951
2017-06-10 23:32:15.207515 EDT | PolicyRegParamNorm         77.4822
2017-06-10 23:32:15.207856 EDT | QFunRegParamNorm           98.8968
2017-06-10 23:32:15.208294 EDT | -----------------------  -----------
2017-06-10 23:32:15.209199 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #560 | Training started
2017-06-10 23:32:29.944940 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #560 | Training finished
2017-06-10 23:32:29.945853 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #560 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 23:32:29.946228 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #560 | Collecting samples for evaluation
2017-06-10 23:32:42.812257 EDT | -----------------------  -----------
2017-06-10 23:32:42.813313 EDT | Epoch                     560
2017-06-10 23:32:42.813537 EDT | Iteration                 560
2017-06-10 23:32:42.814000 EDT | AverageReturn             826.777
2017-06-10 23:32:42.814591 EDT | StdReturn                 198.011
2017-06-10 23:32:42.814825 EDT | MaxReturn                1239.92
2017-06-10 23:32:42.815038 EDT | MinReturn                 571.982
2017-06-10 23:32:42.815233 EDT | AverageEsReturn           323.453
2017-06-10 23:32:42.815428 EDT | StdEsReturn               212.29
2017-06-10 23:32:42.815675 EDT | MaxEsReturn               725.676
2017-06-10 23:32:42.815878 EDT | MinEsReturn               102.767
2017-06-10 23:32:42.816112 EDT | AverageDiscountedReturn   217.761
2017-06-10 23:32:42.816309 EDT | AverageQLoss                2.89961
2017-06-10 23:32:42.816530 EDT | AveragePolicySurr         -32.2844
2017-06-10 23:32:42.816800 EDT | AverageQ                   31.8475
2017-06-10 23:32:42.817185 EDT | AverageAbsQ                31.8817
2017-06-10 23:32:42.817502 EDT | AverageY                   31.8478
2017-06-10 23:32:42.817760 EDT | AverageAbsY                31.8706
2017-06-10 23:32:42.818078 EDT | AverageAbsQYDiff            0.625298
2017-06-10 23:32:42.818345 EDT | AverageAction               0.95896
2017-06-10 23:32:42.818619 EDT | PolicyRegParamNorm         77.5119
2017-06-10 23:32:42.818928 EDT | QFunRegParamNorm           98.9455
2017-06-10 23:32:42.819125 EDT | -----------------------  -----------
2017-06-10 23:32:42.819414 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #561 | Training started
2017-06-10 23:32:59.286514 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #561 | Training finished
2017-06-10 23:32:59.287992 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #561 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 23:32:59.288403 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #561 | Collecting samples for evaluation
2017-06-10 23:33:13.078184 EDT | -----------------------  -----------
2017-06-10 23:33:13.097867 EDT | Epoch                     561
2017-06-10 23:33:13.098118 EDT | Iteration                 561
2017-06-10 23:33:13.098308 EDT | AverageReturn             778.952
2017-06-10 23:33:13.098470 EDT | StdReturn                 202.224
2017-06-10 23:33:13.098627 EDT | MaxReturn                1107.97
2017-06-10 23:33:13.098797 EDT | MinReturn                  88.3552
2017-06-10 23:33:13.098950 EDT | AverageEsReturn           414.043
2017-06-10 23:33:13.099219 EDT | StdEsReturn               240.846
2017-06-10 23:33:13.099402 EDT | MaxEsReturn               722.563
2017-06-10 23:33:13.099588 EDT | MinEsReturn                64.5888
2017-06-10 23:33:13.099779 EDT | AverageDiscountedReturn   218.6
2017-06-10 23:33:13.099933 EDT | AverageQLoss                2.20321
2017-06-10 23:33:13.100084 EDT | AveragePolicySurr         -32.3399
2017-06-10 23:33:13.100234 EDT | AverageQ                   31.9158
2017-06-10 23:33:13.100384 EDT | AverageAbsQ                31.9485
2017-06-10 23:33:13.100565 EDT | AverageY                   31.9146
2017-06-10 23:33:13.100849 EDT | AverageAbsY                31.9334
2017-06-10 23:33:13.101129 EDT | AverageAbsQYDiff            0.580422
2017-06-10 23:33:13.101378 EDT | AverageAction               0.945513
2017-06-10 23:33:13.101630 EDT | PolicyRegParamNorm         77.5947
2017-06-10 23:33:13.102707 EDT | QFunRegParamNorm           99.0328
2017-06-10 23:33:13.102969 EDT | -----------------------  -----------
2017-06-10 23:33:13.103653 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #562 | Training started
2017-06-10 23:33:28.530207 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #562 | Training finished
2017-06-10 23:33:28.530494 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #562 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 23:33:28.530712 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #562 | Collecting samples for evaluation
2017-06-10 23:33:40.415102 EDT | -----------------------  -----------
2017-06-10 23:33:40.416493 EDT | Epoch                     562
2017-06-10 23:33:40.416897 EDT | Iteration                 562
2017-06-10 23:33:40.417294 EDT | AverageReturn            1391.36
2017-06-10 23:33:40.417678 EDT | StdReturn                 407.826
2017-06-10 23:33:40.418080 EDT | MaxReturn                2461.31
2017-06-10 23:33:40.418585 EDT | MinReturn                 815.823
2017-06-10 23:33:40.419365 EDT | AverageEsReturn           386.458
2017-06-10 23:33:40.419758 EDT | StdEsReturn               338.918
2017-06-10 23:33:40.420128 EDT | MaxEsReturn              1039.49
2017-06-10 23:33:40.421113 EDT | MinEsReturn                 9.91868
2017-06-10 23:33:40.421582 EDT | AverageDiscountedReturn   232.697
2017-06-10 23:33:40.424611 EDT | AverageQLoss                2.24969
2017-06-10 23:33:40.424995 EDT | AveragePolicySurr         -32.2431
2017-06-10 23:33:40.425385 EDT | AverageQ                   31.8238
2017-06-10 23:33:40.425789 EDT | AverageAbsQ                31.8649
2017-06-10 23:33:40.426174 EDT | AverageY                   31.8258
2017-06-10 23:33:40.426621 EDT | AverageAbsY                31.8504
2017-06-10 23:33:40.427013 EDT | AverageAbsQYDiff            0.580772
2017-06-10 23:33:40.427386 EDT | AverageAction               0.946371
2017-06-10 23:33:40.427763 EDT | PolicyRegParamNorm         77.6345
2017-06-10 23:33:40.428147 EDT | QFunRegParamNorm           99.0833
2017-06-10 23:33:40.428548 EDT | -----------------------  -----------
2017-06-10 23:33:40.431997 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #563 | Training started
2017-06-10 23:33:56.521396 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #563 | Training finished
2017-06-10 23:33:56.521815 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #563 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 23:33:56.522097 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #563 | Collecting samples for evaluation
2017-06-10 23:34:09.176188 EDT | -----------------------  -----------
2017-06-10 23:34:09.177580 EDT | Epoch                     563
2017-06-10 23:34:09.178096 EDT | Iteration                 563
2017-06-10 23:34:09.178655 EDT | AverageReturn             756.654
2017-06-10 23:34:09.179134 EDT | StdReturn                 154.616
2017-06-10 23:34:09.179609 EDT | MaxReturn                1081.44
2017-06-10 23:34:09.180079 EDT | MinReturn                 351.379
2017-06-10 23:34:09.180552 EDT | AverageEsReturn           417.249
2017-06-10 23:34:09.182061 EDT | StdEsReturn               365.725
2017-06-10 23:34:09.182881 EDT | MaxEsReturn              1041.33
2017-06-10 23:34:09.183455 EDT | MinEsReturn                76.6219
2017-06-10 23:34:09.183929 EDT | AverageDiscountedReturn   215.227
2017-06-10 23:34:09.184405 EDT | AverageQLoss                2.16395
2017-06-10 23:34:09.185765 EDT | AveragePolicySurr         -32.342
2017-06-10 23:34:09.186900 EDT | AverageQ                   31.9329
2017-06-10 23:34:09.187383 EDT | AverageAbsQ                31.961
2017-06-10 23:34:09.187931 EDT | AverageY                   31.9351
2017-06-10 23:34:09.188599 EDT | AverageAbsY                31.9551
2017-06-10 23:34:09.189070 EDT | AverageAbsQYDiff            0.578091
2017-06-10 23:34:09.189540 EDT | AverageAction               0.957652
2017-06-10 23:34:09.190293 EDT | PolicyRegParamNorm         77.7482
2017-06-10 23:34:09.190775 EDT | QFunRegParamNorm           99.177
2017-06-10 23:34:09.191533 EDT | -----------------------  -----------
2017-06-10 23:34:09.192120 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #564 | Training started
2017-06-10 23:34:24.524679 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #564 | Training finished
2017-06-10 23:34:24.526064 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #564 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 23:34:24.526463 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #564 | Collecting samples for evaluation
2017-06-10 23:34:37.766640 EDT | -----------------------  -----------
2017-06-10 23:34:37.767593 EDT | Epoch                     564
2017-06-10 23:34:37.768116 EDT | Iteration                 564
2017-06-10 23:34:37.768517 EDT | AverageReturn             670.019
2017-06-10 23:34:37.768949 EDT | StdReturn                 239.004
2017-06-10 23:34:37.769428 EDT | MaxReturn                1347.1
2017-06-10 23:34:37.769865 EDT | MinReturn                 335.132
2017-06-10 23:34:37.770363 EDT | AverageEsReturn           314.073
2017-06-10 23:34:37.770771 EDT | StdEsReturn               342.974
2017-06-10 23:34:37.771199 EDT | MaxEsReturn              1004.04
2017-06-10 23:34:37.771717 EDT | MinEsReturn                14.8281
2017-06-10 23:34:37.772053 EDT | AverageDiscountedReturn   202.798
2017-06-10 23:34:37.772462 EDT | AverageQLoss                3.02583
2017-06-10 23:34:37.772885 EDT | AveragePolicySurr         -32.2635
2017-06-10 23:34:37.773374 EDT | AverageQ                   31.8501
2017-06-10 23:34:37.773718 EDT | AverageAbsQ                31.8858
2017-06-10 23:34:37.774055 EDT | AverageY                   31.8513
2017-06-10 23:34:37.774476 EDT | AverageAbsY                31.8746
2017-06-10 23:34:37.774824 EDT | AverageAbsQYDiff            0.619452
2017-06-10 23:34:37.775312 EDT | AverageAction               0.967979
2017-06-10 23:34:37.775647 EDT | PolicyRegParamNorm         77.7774
2017-06-10 23:34:37.776070 EDT | QFunRegParamNorm           99.2877
2017-06-10 23:34:37.776397 EDT | -----------------------  -----------
2017-06-10 23:34:37.777063 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #565 | Training started
2017-06-10 23:34:54.199757 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #565 | Training finished
2017-06-10 23:34:54.200773 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #565 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 23:34:54.201165 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #565 | Collecting samples for evaluation
2017-06-10 23:35:06.882449 EDT | -----------------------  -----------
2017-06-10 23:35:06.883533 EDT | Epoch                     565
2017-06-10 23:35:06.884004 EDT | Iteration                 565
2017-06-10 23:35:06.884456 EDT | AverageReturn             878.537
2017-06-10 23:35:06.884911 EDT | StdReturn                 176.448
2017-06-10 23:35:06.885360 EDT | MaxReturn                1316.86
2017-06-10 23:35:06.885821 EDT | MinReturn                 664.676
2017-06-10 23:35:06.886268 EDT | AverageEsReturn           598.6
2017-06-10 23:35:06.886712 EDT | StdEsReturn               475.905
2017-06-10 23:35:06.887159 EDT | MaxEsReturn              1259.32
2017-06-10 23:35:06.887603 EDT | MinEsReturn                44.2747
2017-06-10 23:35:06.901835 EDT | AverageDiscountedReturn   218.673
2017-06-10 23:35:06.902265 EDT | AverageQLoss                2.67968
2017-06-10 23:35:06.902617 EDT | AveragePolicySurr         -32.1997
2017-06-10 23:35:06.902961 EDT | AverageQ                   31.7943
2017-06-10 23:35:06.903310 EDT | AverageAbsQ                31.8341
2017-06-10 23:35:06.903658 EDT | AverageY                   31.7948
2017-06-10 23:35:06.904004 EDT | AverageAbsY                31.8192
2017-06-10 23:35:06.904349 EDT | AverageAbsQYDiff            0.598727
2017-06-10 23:35:06.904690 EDT | AverageAction               0.958343
2017-06-10 23:35:06.905033 EDT | PolicyRegParamNorm         77.8492
2017-06-10 23:35:06.905377 EDT | QFunRegParamNorm           99.345
2017-06-10 23:35:06.905734 EDT | -----------------------  -----------
2017-06-10 23:35:06.906267 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #566 | Training started
2017-06-10 23:35:23.397102 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #566 | Training finished
2017-06-10 23:35:23.469806 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #566 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 23:35:23.470267 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #566 | Collecting samples for evaluation
2017-06-10 23:35:36.049493 EDT | -----------------------  -----------
2017-06-10 23:35:36.050217 EDT | Epoch                     566
2017-06-10 23:35:36.051421 EDT | Iteration                 566
2017-06-10 23:35:36.052003 EDT | AverageReturn             485.194
2017-06-10 23:35:36.052194 EDT | StdReturn                 176.318
2017-06-10 23:35:36.052388 EDT | MaxReturn                1518.25
2017-06-10 23:35:36.052571 EDT | MinReturn                 320.203
2017-06-10 23:35:36.052752 EDT | AverageEsReturn           336.875
2017-06-10 23:35:36.052934 EDT | StdEsReturn               173.339
2017-06-10 23:35:36.053114 EDT | MaxEsReturn               578.732
2017-06-10 23:35:36.053292 EDT | MinEsReturn                 8.86334
2017-06-10 23:35:36.053478 EDT | AverageDiscountedReturn   185.41
2017-06-10 23:35:36.053733 EDT | AverageQLoss                2.56325
2017-06-10 23:35:36.053922 EDT | AveragePolicySurr         -32.2038
2017-06-10 23:35:36.054102 EDT | AverageQ                   31.7881
2017-06-10 23:35:36.054283 EDT | AverageAbsQ                31.8256
2017-06-10 23:35:36.054542 EDT | AverageY                   31.789
2017-06-10 23:35:36.054723 EDT | AverageAbsY                31.8161
2017-06-10 23:35:36.054902 EDT | AverageAbsQYDiff            0.583994
2017-06-10 23:35:36.055082 EDT | AverageAction               0.974541
2017-06-10 23:35:36.055261 EDT | PolicyRegParamNorm         77.8821
2017-06-10 23:35:36.055447 EDT | QFunRegParamNorm           99.4299
2017-06-10 23:35:36.055625 EDT | -----------------------  -----------
2017-06-10 23:35:36.055921 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #567 | Training started
2017-06-10 23:35:51.683231 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #567 | Training finished
2017-06-10 23:35:51.684177 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #567 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 23:35:51.684535 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #567 | Collecting samples for evaluation
2017-06-10 23:36:04.252840 EDT | -----------------------  -----------
2017-06-10 23:36:04.253948 EDT | Epoch                     567
2017-06-10 23:36:04.254413 EDT | Iteration                 567
2017-06-10 23:36:04.254857 EDT | AverageReturn             965.29
2017-06-10 23:36:04.255303 EDT | StdReturn                 404.914
2017-06-10 23:36:04.255752 EDT | MaxReturn                2459.21
2017-06-10 23:36:04.256197 EDT | MinReturn                 534.818
2017-06-10 23:36:04.256642 EDT | AverageEsReturn           476.032
2017-06-10 23:36:04.257083 EDT | StdEsReturn               159.776
2017-06-10 23:36:04.257526 EDT | MaxEsReturn               749.892
2017-06-10 23:36:04.257978 EDT | MinEsReturn               293.575
2017-06-10 23:36:04.258423 EDT | AverageDiscountedReturn   219.139
2017-06-10 23:36:04.258863 EDT | AverageQLoss                2.98848
2017-06-10 23:36:04.259303 EDT | AveragePolicySurr         -32.2934
2017-06-10 23:36:04.259746 EDT | AverageQ                   31.8863
2017-06-10 23:36:04.260187 EDT | AverageAbsQ                31.9259
2017-06-10 23:36:04.260628 EDT | AverageY                   31.8874
2017-06-10 23:36:04.261068 EDT | AverageAbsY                31.9095
2017-06-10 23:36:04.261508 EDT | AverageAbsQYDiff            0.624887
2017-06-10 23:36:04.261956 EDT | AverageAction               0.939112
2017-06-10 23:36:04.262393 EDT | PolicyRegParamNorm         77.9879
2017-06-10 23:36:04.262831 EDT | QFunRegParamNorm           99.5469
2017-06-10 23:36:04.263269 EDT | -----------------------  -----------
2017-06-10 23:36:04.263881 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #568 | Training started
2017-06-10 23:36:20.301509 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #568 | Training finished
2017-06-10 23:36:20.302268 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #568 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 23:36:20.302469 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #568 | Collecting samples for evaluation
2017-06-10 23:36:33.327730 EDT | -----------------------  -----------
2017-06-10 23:36:33.328528 EDT | Epoch                     568
2017-06-10 23:36:33.329007 EDT | Iteration                 568
2017-06-10 23:36:33.329362 EDT | AverageReturn             956.026
2017-06-10 23:36:33.329713 EDT | StdReturn                 267.212
2017-06-10 23:36:33.330168 EDT | MaxReturn                1752.25
2017-06-10 23:36:33.330582 EDT | MinReturn                 559.224
2017-06-10 23:36:33.331011 EDT | AverageEsReturn           495.26
2017-06-10 23:36:33.331361 EDT | StdEsReturn               300.906
2017-06-10 23:36:33.331692 EDT | MaxEsReturn               794.534
2017-06-10 23:36:33.332199 EDT | MinEsReturn               131.568
2017-06-10 23:36:33.332391 EDT | AverageDiscountedReturn   219.218
2017-06-10 23:36:33.332571 EDT | AverageQLoss                2.72777
2017-06-10 23:36:33.332806 EDT | AveragePolicySurr         -32.2247
2017-06-10 23:36:33.333129 EDT | AverageQ                   31.8432
2017-06-10 23:36:33.333462 EDT | AverageAbsQ                31.8819
2017-06-10 23:36:33.333808 EDT | AverageY                   31.8436
2017-06-10 23:36:33.334140 EDT | AverageAbsY                31.868
2017-06-10 23:36:33.334819 EDT | AverageAbsQYDiff            0.597865
2017-06-10 23:36:33.335386 EDT | AverageAction               0.968248
2017-06-10 23:36:33.335735 EDT | PolicyRegParamNorm         78.0081
2017-06-10 23:36:33.340624 EDT | QFunRegParamNorm           99.6454
2017-06-10 23:36:33.341050 EDT | -----------------------  -----------
2017-06-10 23:36:33.341675 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #569 | Training started
2017-06-10 23:36:47.675070 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #569 | Training finished
2017-06-10 23:36:47.675945 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #569 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 23:36:47.676649 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #569 | Collecting samples for evaluation
2017-06-10 23:37:00.662700 EDT | -----------------------  -----------
2017-06-10 23:37:00.663444 EDT | Epoch                     569
2017-06-10 23:37:00.663637 EDT | Iteration                 569
2017-06-10 23:37:00.663843 EDT | AverageReturn             676.961
2017-06-10 23:37:00.664028 EDT | StdReturn                 191.309
2017-06-10 23:37:00.664211 EDT | MaxReturn                1207.49
2017-06-10 23:37:00.664392 EDT | MinReturn                 402.723
2017-06-10 23:37:00.664572 EDT | AverageEsReturn           357.707
2017-06-10 23:37:00.664752 EDT | StdEsReturn               371.392
2017-06-10 23:37:00.664941 EDT | MaxEsReturn              1164.09
2017-06-10 23:37:00.665123 EDT | MinEsReturn                13.6521
2017-06-10 23:37:00.665301 EDT | AverageDiscountedReturn   208.892
2017-06-10 23:37:00.665480 EDT | AverageQLoss                2.41384
2017-06-10 23:37:00.665665 EDT | AveragePolicySurr         -32.1677
2017-06-10 23:37:00.665860 EDT | AverageQ                   31.755
2017-06-10 23:37:00.666045 EDT | AverageAbsQ                31.7957
2017-06-10 23:37:00.666224 EDT | AverageY                   31.7559
2017-06-10 23:37:00.666402 EDT | AverageAbsY                31.7841
2017-06-10 23:37:00.666579 EDT | AverageAbsQYDiff            0.588367
2017-06-10 23:37:00.666758 EDT | AverageAction               0.968814
2017-06-10 23:37:00.666935 EDT | PolicyRegParamNorm         78.1144
2017-06-10 23:37:00.667121 EDT | QFunRegParamNorm           99.7291
2017-06-10 23:37:00.667298 EDT | -----------------------  -----------
2017-06-10 23:37:00.667565 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #570 | Training started
2017-06-10 23:37:16.595502 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #570 | Training finished
2017-06-10 23:37:16.596288 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #570 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 23:37:16.596487 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #570 | Collecting samples for evaluation
2017-06-10 23:37:29.778794 EDT | -----------------------  ----------
2017-06-10 23:37:29.780070 EDT | Epoch                    570
2017-06-10 23:37:29.780293 EDT | Iteration                570
2017-06-10 23:37:29.780472 EDT | AverageReturn            597.365
2017-06-10 23:37:29.780640 EDT | StdReturn                154.771
2017-06-10 23:37:29.780795 EDT | MaxReturn                960.689
2017-06-10 23:37:29.780979 EDT | MinReturn                353.513
2017-06-10 23:37:29.781158 EDT | AverageEsReturn          231.056
2017-06-10 23:37:29.781333 EDT | StdEsReturn              120.409
2017-06-10 23:37:29.781487 EDT | MaxEsReturn              507.877
2017-06-10 23:37:29.781637 EDT | MinEsReturn               89.1848
2017-06-10 23:37:29.781818 EDT | AverageDiscountedReturn  202.141
2017-06-10 23:37:29.782026 EDT | AverageQLoss               2.84745
2017-06-10 23:37:29.782183 EDT | AveragePolicySurr        -32.1602
2017-06-10 23:37:29.782334 EDT | AverageQ                  31.7842
2017-06-10 23:37:29.782483 EDT | AverageAbsQ               31.8198
2017-06-10 23:37:29.782671 EDT | AverageY                  31.7845
2017-06-10 23:37:29.782960 EDT | AverageAbsY               31.806
2017-06-10 23:37:29.783224 EDT | AverageAbsQYDiff           0.61966
2017-06-10 23:37:29.783505 EDT | AverageAction              0.954709
2017-06-10 23:37:29.783658 EDT | PolicyRegParamNorm        78.1965
2017-06-10 23:37:29.783808 EDT | QFunRegParamNorm          99.7538
2017-06-10 23:37:29.783958 EDT | -----------------------  ----------
2017-06-10 23:37:29.784477 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #571 | Training started
2017-06-10 23:37:45.913394 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #571 | Training finished
2017-06-10 23:37:45.913969 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #571 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 23:37:45.914258 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #571 | Collecting samples for evaluation
2017-06-10 23:38:00.123948 EDT | -----------------------  -----------
2017-06-10 23:38:00.124683 EDT | Epoch                     571
2017-06-10 23:38:00.125031 EDT | Iteration                 571
2017-06-10 23:38:00.125353 EDT | AverageReturn             849.924
2017-06-10 23:38:00.125635 EDT | StdReturn                 232.831
2017-06-10 23:38:00.125865 EDT | MaxReturn                1275.87
2017-06-10 23:38:00.126021 EDT | MinReturn                  50.8827
2017-06-10 23:38:00.126175 EDT | AverageEsReturn           493.108
2017-06-10 23:38:00.126326 EDT | StdEsReturn               192.186
2017-06-10 23:38:00.126477 EDT | MaxEsReturn               779.364
2017-06-10 23:38:00.126626 EDT | MinEsReturn               237.513
2017-06-10 23:38:00.126823 EDT | AverageDiscountedReturn   216.071
2017-06-10 23:38:00.126976 EDT | AverageQLoss                2.41209
2017-06-10 23:38:00.127160 EDT | AveragePolicySurr         -32.1199
2017-06-10 23:38:00.127329 EDT | AverageQ                   31.7319
2017-06-10 23:38:00.127586 EDT | AverageAbsQ                31.7741
2017-06-10 23:38:00.127741 EDT | AverageY                   31.7335
2017-06-10 23:38:00.127892 EDT | AverageAbsY                31.7621
2017-06-10 23:38:00.128043 EDT | AverageAbsQYDiff            0.583583
2017-06-10 23:38:00.128306 EDT | AverageAction               0.931231
2017-06-10 23:38:00.128596 EDT | PolicyRegParamNorm         78.1755
2017-06-10 23:38:00.128856 EDT | QFunRegParamNorm           99.8405
2017-06-10 23:38:00.129074 EDT | -----------------------  -----------
2017-06-10 23:38:00.129335 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #572 | Training started
2017-06-10 23:38:16.170015 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #572 | Training finished
2017-06-10 23:38:16.171010 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #572 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 23:38:16.171241 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #572 | Collecting samples for evaluation
2017-06-10 23:38:29.291035 EDT | -----------------------  ----------
2017-06-10 23:38:29.291492 EDT | Epoch                     572
2017-06-10 23:38:29.291842 EDT | Iteration                 572
2017-06-10 23:38:29.292203 EDT | AverageReturn             708.625
2017-06-10 23:38:29.292558 EDT | StdReturn                 207.157
2017-06-10 23:38:29.292908 EDT | MaxReturn                1362.19
2017-06-10 23:38:29.293331 EDT | MinReturn                 325.268
2017-06-10 23:38:29.293701 EDT | AverageEsReturn           524.184
2017-06-10 23:38:29.294227 EDT | StdEsReturn               428.833
2017-06-10 23:38:29.294583 EDT | MaxEsReturn              1356.94
2017-06-10 23:38:29.295214 EDT | MinEsReturn                91.886
2017-06-10 23:38:29.295655 EDT | AverageDiscountedReturn   211.338
2017-06-10 23:38:29.296097 EDT | AverageQLoss                2.21848
2017-06-10 23:38:29.296533 EDT | AveragePolicySurr         -32.1643
2017-06-10 23:38:29.296878 EDT | AverageQ                   31.773
2017-06-10 23:38:29.297316 EDT | AverageAbsQ                31.8181
2017-06-10 23:38:29.297768 EDT | AverageY                   31.7725
2017-06-10 23:38:29.298188 EDT | AverageAbsY                31.804
2017-06-10 23:38:29.298538 EDT | AverageAbsQYDiff            0.57351
2017-06-10 23:38:29.298878 EDT | AverageAction               0.96544
2017-06-10 23:38:29.299216 EDT | PolicyRegParamNorm         78.2262
2017-06-10 23:38:29.299623 EDT | QFunRegParamNorm           99.9114
2017-06-10 23:38:29.299963 EDT | -----------------------  ----------
2017-06-10 23:38:29.300529 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #573 | Training started
2017-06-10 23:38:43.670382 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #573 | Training finished
2017-06-10 23:38:43.675872 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #573 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 23:38:43.676308 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #573 | Collecting samples for evaluation
2017-06-10 23:38:57.258579 EDT | -----------------------  -----------
2017-06-10 23:38:57.259100 EDT | Epoch                     573
2017-06-10 23:38:57.259469 EDT | Iteration                 573
2017-06-10 23:38:57.259820 EDT | AverageReturn            1342.25
2017-06-10 23:38:57.260181 EDT | StdReturn                 642.2
2017-06-10 23:38:57.260543 EDT | MaxReturn                2675.17
2017-06-10 23:38:57.260906 EDT | MinReturn                 681.425
2017-06-10 23:38:57.261258 EDT | AverageEsReturn           502.054
2017-06-10 23:38:57.261613 EDT | StdEsReturn               311.898
2017-06-10 23:38:57.261984 EDT | MaxEsReturn               976.874
2017-06-10 23:38:57.262343 EDT | MinEsReturn                63.0023
2017-06-10 23:38:57.262699 EDT | AverageDiscountedReturn   221.197
2017-06-10 23:38:57.263055 EDT | AverageQLoss                2.93526
2017-06-10 23:38:57.263411 EDT | AveragePolicySurr         -32.1516
2017-06-10 23:38:57.263770 EDT | AverageQ                   31.7683
2017-06-10 23:38:57.264910 EDT | AverageAbsQ                31.8065
2017-06-10 23:38:57.265394 EDT | AverageY                   31.7706
2017-06-10 23:38:57.270055 EDT | AverageAbsY                31.7928
2017-06-10 23:38:57.270601 EDT | AverageAbsQYDiff            0.633068
2017-06-10 23:38:57.270991 EDT | AverageAction               0.967933
2017-06-10 23:38:57.271417 EDT | PolicyRegParamNorm         78.239
2017-06-10 23:38:57.271790 EDT | QFunRegParamNorm           99.9983
2017-06-10 23:38:57.272142 EDT | -----------------------  -----------
2017-06-10 23:38:57.272757 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #574 | Training started
2017-06-10 23:39:11.942030 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #574 | Training finished
2017-06-10 23:39:11.943002 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #574 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 23:39:11.943369 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #574 | Collecting samples for evaluation
2017-06-10 23:39:24.708055 EDT | -----------------------  -----------
2017-06-10 23:39:24.709076 EDT | Epoch                     574
2017-06-10 23:39:24.709566 EDT | Iteration                 574
2017-06-10 23:39:24.710063 EDT | AverageReturn             807.456
2017-06-10 23:39:24.710659 EDT | StdReturn                 242.941
2017-06-10 23:39:24.711136 EDT | MaxReturn                1524.08
2017-06-10 23:39:24.711609 EDT | MinReturn                 517.689
2017-06-10 23:39:24.712080 EDT | AverageEsReturn           284.435
2017-06-10 23:39:24.712559 EDT | StdEsReturn               201.293
2017-06-10 23:39:24.712942 EDT | MaxEsReturn               555.995
2017-06-10 23:39:24.713312 EDT | MinEsReturn                 6.64686
2017-06-10 23:39:24.714775 EDT | AverageDiscountedReturn   212.798
2017-06-10 23:39:24.715256 EDT | AverageQLoss                2.68924
2017-06-10 23:39:24.715641 EDT | AveragePolicySurr         -32.0876
2017-06-10 23:39:24.716018 EDT | AverageQ                   31.7063
2017-06-10 23:39:24.716388 EDT | AverageAbsQ                31.7442
2017-06-10 23:39:24.716760 EDT | AverageY                   31.7082
2017-06-10 23:39:24.718291 EDT | AverageAbsY                31.7331
2017-06-10 23:39:24.718705 EDT | AverageAbsQYDiff            0.618271
2017-06-10 23:39:24.719100 EDT | AverageAction               0.96696
2017-06-10 23:39:24.719473 EDT | PolicyRegParamNorm         78.3242
2017-06-10 23:39:24.719844 EDT | QFunRegParamNorm          100.042
2017-06-10 23:39:24.720215 EDT | -----------------------  -----------
2017-06-10 23:39:24.720773 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #575 | Training started
2017-06-10 23:39:41.206791 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #575 | Training finished
2017-06-10 23:39:41.207147 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #575 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 23:39:41.207376 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #575 | Collecting samples for evaluation
2017-06-10 23:39:53.893243 EDT | -----------------------  -----------
2017-06-10 23:39:53.894286 EDT | Epoch                     575
2017-06-10 23:39:53.894634 EDT | Iteration                 575
2017-06-10 23:39:53.894929 EDT | AverageReturn             742.809
2017-06-10 23:39:53.895267 EDT | StdReturn                 268.97
2017-06-10 23:39:53.895614 EDT | MaxReturn                1948.32
2017-06-10 23:39:53.895961 EDT | MinReturn                 523.57
2017-06-10 23:39:53.896301 EDT | AverageEsReturn           349.443
2017-06-10 23:39:53.896728 EDT | StdEsReturn               252.025
2017-06-10 23:39:53.898802 EDT | MaxEsReturn               901.657
2017-06-10 23:39:53.899256 EDT | MinEsReturn                66.2404
2017-06-10 23:39:53.900188 EDT | AverageDiscountedReturn   210.917
2017-06-10 23:39:53.900562 EDT | AverageQLoss                2.47438
2017-06-10 23:39:53.900993 EDT | AveragePolicySurr         -32.0629
2017-06-10 23:39:53.901409 EDT | AverageQ                   31.6599
2017-06-10 23:39:53.902129 EDT | AverageAbsQ                31.6998
2017-06-10 23:39:53.902628 EDT | AverageY                   31.6599
2017-06-10 23:39:53.902980 EDT | AverageAbsY                31.6868
2017-06-10 23:39:53.905271 EDT | AverageAbsQYDiff            0.596559
2017-06-10 23:39:53.905642 EDT | AverageAction               0.955986
2017-06-10 23:39:53.905982 EDT | PolicyRegParamNorm         78.3592
2017-06-10 23:39:53.906323 EDT | QFunRegParamNorm          100.072
2017-06-10 23:39:53.906655 EDT | -----------------------  -----------
2017-06-10 23:39:53.907169 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #576 | Training started
2017-06-10 23:40:10.442209 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #576 | Training finished
2017-06-10 23:40:10.443002 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #576 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 23:40:10.443415 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #576 | Collecting samples for evaluation
2017-06-10 23:40:23.045811 EDT | -----------------------  -----------
2017-06-10 23:40:23.046757 EDT | Epoch                     576
2017-06-10 23:40:23.047204 EDT | Iteration                 576
2017-06-10 23:40:23.047561 EDT | AverageReturn            1399.95
2017-06-10 23:40:23.047899 EDT | StdReturn                 382.871
2017-06-10 23:40:23.048319 EDT | MaxReturn                2471.23
2017-06-10 23:40:23.048861 EDT | MinReturn                 730.542
2017-06-10 23:40:23.049308 EDT | AverageEsReturn           359.109
2017-06-10 23:40:23.049742 EDT | StdEsReturn               203.207
2017-06-10 23:40:23.050177 EDT | MaxEsReturn               650.135
2017-06-10 23:40:23.050837 EDT | MinEsReturn                 8.92655
2017-06-10 23:40:23.051174 EDT | AverageDiscountedReturn   223.441
2017-06-10 23:40:23.051366 EDT | AverageQLoss                2.54602
2017-06-10 23:40:23.051695 EDT | AveragePolicySurr         -31.9961
2017-06-10 23:40:23.052023 EDT | AverageQ                   31.6321
2017-06-10 23:40:23.053737 EDT | AverageAbsQ                31.6665
2017-06-10 23:40:23.054334 EDT | AverageY                   31.6337
2017-06-10 23:40:23.055807 EDT | AverageAbsY                31.6561
2017-06-10 23:40:23.062895 EDT | AverageAbsQYDiff            0.599673
2017-06-10 23:40:23.063293 EDT | AverageAction               0.961517
2017-06-10 23:40:23.063716 EDT | PolicyRegParamNorm         78.4718
2017-06-10 23:40:23.064136 EDT | QFunRegParamNorm          100.159
2017-06-10 23:40:23.064542 EDT | -----------------------  -----------
2017-06-10 23:40:23.065030 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #577 | Training started
2017-06-10 23:40:37.989895 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #577 | Training finished
2017-06-10 23:40:37.990983 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #577 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 23:40:37.991459 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #577 | Collecting samples for evaluation
2017-06-10 23:40:52.259845 EDT | -----------------------  -----------
2017-06-10 23:40:52.261140 EDT | Epoch                     577
2017-06-10 23:40:52.261522 EDT | Iteration                 577
2017-06-10 23:40:52.261885 EDT | AverageReturn            1900.74
2017-06-10 23:40:52.262233 EDT | StdReturn                 670.69
2017-06-10 23:40:52.262577 EDT | MaxReturn                2868.69
2017-06-10 23:40:52.262917 EDT | MinReturn                 822.445
2017-06-10 23:40:52.263254 EDT | AverageEsReturn           261.316
2017-06-10 23:40:52.263595 EDT | StdEsReturn               250.596
2017-06-10 23:40:52.263940 EDT | MaxEsReturn               838.039
2017-06-10 23:40:52.264279 EDT | MinEsReturn                64.1882
2017-06-10 23:40:52.264616 EDT | AverageDiscountedReturn   242.239
2017-06-10 23:40:52.264956 EDT | AverageQLoss                2.21761
2017-06-10 23:40:52.265299 EDT | AveragePolicySurr         -32.0393
2017-06-10 23:40:52.265640 EDT | AverageQ                   31.6474
2017-06-10 23:40:52.265988 EDT | AverageAbsQ                31.6833
2017-06-10 23:40:52.266328 EDT | AverageY                   31.6474
2017-06-10 23:40:52.266671 EDT | AverageAbsY                31.668
2017-06-10 23:40:52.267020 EDT | AverageAbsQYDiff            0.573214
2017-06-10 23:40:52.267360 EDT | AverageAction               0.954984
2017-06-10 23:40:52.267699 EDT | PolicyRegParamNorm         78.5182
2017-06-10 23:40:52.268040 EDT | QFunRegParamNorm          100.245
2017-06-10 23:40:52.268382 EDT | -----------------------  -----------
2017-06-10 23:40:52.268896 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #578 | Training started
2017-06-10 23:41:07.797884 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #578 | Training finished
2017-06-10 23:41:07.798799 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #578 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 23:41:07.799121 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #578 | Collecting samples for evaluation
2017-06-10 23:41:20.549156 EDT | -----------------------  -----------
2017-06-10 23:41:20.560691 EDT | Epoch                     578
2017-06-10 23:41:20.561223 EDT | Iteration                 578
2017-06-10 23:41:20.561584 EDT | AverageReturn            1321.95
2017-06-10 23:41:20.561961 EDT | StdReturn                 603.379
2017-06-10 23:41:20.562307 EDT | MaxReturn                2699
2017-06-10 23:41:20.562666 EDT | MinReturn                 667.004
2017-06-10 23:41:20.563188 EDT | AverageEsReturn           304.276
2017-06-10 23:41:20.563549 EDT | StdEsReturn               259.128
2017-06-10 23:41:20.564360 EDT | MaxEsReturn               781.819
2017-06-10 23:41:20.564775 EDT | MinEsReturn                38.0758
2017-06-10 23:41:20.565550 EDT | AverageDiscountedReturn   228.259
2017-06-10 23:41:20.565892 EDT | AverageQLoss                2.28521
2017-06-10 23:41:20.566214 EDT | AveragePolicySurr         -31.9685
2017-06-10 23:41:20.566599 EDT | AverageQ                   31.5619
2017-06-10 23:41:20.567303 EDT | AverageAbsQ                31.5944
2017-06-10 23:41:20.568026 EDT | AverageY                   31.5635
2017-06-10 23:41:20.569314 EDT | AverageAbsY                31.5849
2017-06-10 23:41:20.569775 EDT | AverageAbsQYDiff            0.572483
2017-06-10 23:41:20.570222 EDT | AverageAction               0.932714
2017-06-10 23:41:20.570666 EDT | PolicyRegParamNorm         78.5703
2017-06-10 23:41:20.571016 EDT | QFunRegParamNorm          100.333
2017-06-10 23:41:20.571365 EDT | -----------------------  -----------
2017-06-10 23:41:20.571988 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #579 | Training started
2017-06-10 23:41:36.606188 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #579 | Training finished
2017-06-10 23:41:36.607194 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #579 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 23:41:36.607584 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #579 | Collecting samples for evaluation
2017-06-10 23:41:49.029474 EDT | -----------------------  -----------
2017-06-10 23:41:49.030322 EDT | Epoch                     579
2017-06-10 23:41:49.030607 EDT | Iteration                 579
2017-06-10 23:41:49.030865 EDT | AverageReturn            1427.71
2017-06-10 23:41:49.031119 EDT | StdReturn                 638.168
2017-06-10 23:41:49.031369 EDT | MaxReturn                2596.55
2017-06-10 23:41:49.031617 EDT | MinReturn                 647.035
2017-06-10 23:41:49.031917 EDT | AverageEsReturn           281.648
2017-06-10 23:41:49.032211 EDT | StdEsReturn               238.376
2017-06-10 23:41:49.032372 EDT | MaxEsReturn               675.406
2017-06-10 23:41:49.032535 EDT | MinEsReturn                 6.69725
2017-06-10 23:41:49.032726 EDT | AverageDiscountedReturn   222.291
2017-06-10 23:41:49.032916 EDT | AverageQLoss                2.44801
2017-06-10 23:41:49.033097 EDT | AveragePolicySurr         -32.0254
2017-06-10 23:41:49.033287 EDT | AverageQ                   31.6132
2017-06-10 23:41:49.033463 EDT | AverageAbsQ                31.6454
2017-06-10 23:41:49.033642 EDT | AverageY                   31.6163
2017-06-10 23:41:49.033980 EDT | AverageAbsY                31.6333
2017-06-10 23:41:49.034434 EDT | AverageAbsQYDiff            0.591281
2017-06-10 23:41:49.034847 EDT | AverageAction               0.948008
2017-06-10 23:41:49.035311 EDT | PolicyRegParamNorm         78.635
2017-06-10 23:41:49.035738 EDT | QFunRegParamNorm          100.394
2017-06-10 23:41:49.036170 EDT | -----------------------  -----------
2017-06-10 23:41:49.036771 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #580 | Training started
2017-06-10 23:42:05.466386 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #580 | Training finished
2017-06-10 23:42:05.467332 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #580 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 23:42:05.467721 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #580 | Collecting samples for evaluation
2017-06-10 23:42:18.766570 EDT | -----------------------  -----------
2017-06-10 23:42:18.767572 EDT | Epoch                     580
2017-06-10 23:42:18.767883 EDT | Iteration                 580
2017-06-10 23:42:18.768205 EDT | AverageReturn            1205.71
2017-06-10 23:42:18.768504 EDT | StdReturn                 538.532
2017-06-10 23:42:18.768920 EDT | MaxReturn                2774.77
2017-06-10 23:42:18.769178 EDT | MinReturn                 610.967
2017-06-10 23:42:18.769362 EDT | AverageEsReturn           526.454
2017-06-10 23:42:18.769643 EDT | StdEsReturn               417.024
2017-06-10 23:42:18.769892 EDT | MaxEsReturn              1082.9
2017-06-10 23:42:18.770106 EDT | MinEsReturn                78.9903
2017-06-10 23:42:18.770366 EDT | AverageDiscountedReturn   228.864
2017-06-10 23:42:18.770550 EDT | AverageQLoss                2.66268
2017-06-10 23:42:18.770730 EDT | AveragePolicySurr         -32.0166
2017-06-10 23:42:18.771180 EDT | AverageQ                   31.6086
2017-06-10 23:42:18.771397 EDT | AverageAbsQ                31.6455
2017-06-10 23:42:18.771618 EDT | AverageY                   31.6083
2017-06-10 23:42:18.771884 EDT | AverageAbsY                31.6312
2017-06-10 23:42:18.772230 EDT | AverageAbsQYDiff            0.599292
2017-06-10 23:42:18.772413 EDT | AverageAction               0.954038
2017-06-10 23:42:18.772702 EDT | PolicyRegParamNorm         78.7366
2017-06-10 23:42:18.772885 EDT | QFunRegParamNorm          100.489
2017-06-10 23:42:18.773065 EDT | -----------------------  -----------
2017-06-10 23:42:18.773421 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #581 | Training started
2017-06-10 23:42:35.240064 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #581 | Training finished
2017-06-10 23:42:35.240838 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #581 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 23:42:35.241426 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #581 | Collecting samples for evaluation
2017-06-10 23:42:49.243608 EDT | -----------------------  -----------
2017-06-10 23:42:49.244444 EDT | Epoch                     581
2017-06-10 23:42:49.244627 EDT | Iteration                 581
2017-06-10 23:42:49.244788 EDT | AverageReturn             667.163
2017-06-10 23:42:49.244943 EDT | StdReturn                 184.164
2017-06-10 23:42:49.245168 EDT | MaxReturn                1177.17
2017-06-10 23:42:49.245321 EDT | MinReturn                 319.907
2017-06-10 23:42:49.245574 EDT | AverageEsReturn           696.669
2017-06-10 23:42:49.245782 EDT | StdEsReturn               406.124
2017-06-10 23:42:49.245943 EDT | MaxEsReturn              1211.5
2017-06-10 23:42:49.246094 EDT | MinEsReturn               179.435
2017-06-10 23:42:49.246337 EDT | AverageDiscountedReturn   201.621
2017-06-10 23:42:49.246520 EDT | AverageQLoss                2.49837
2017-06-10 23:42:49.246833 EDT | AveragePolicySurr         -31.9988
2017-06-10 23:42:49.247108 EDT | AverageQ                   31.5999
2017-06-10 23:42:49.247349 EDT | AverageAbsQ                31.6283
2017-06-10 23:42:49.247533 EDT | AverageY                   31.6006
2017-06-10 23:42:49.247713 EDT | AverageAbsY                31.6147
2017-06-10 23:42:49.247948 EDT | AverageAbsQYDiff            0.587765
2017-06-10 23:42:49.248155 EDT | AverageAction               0.947398
2017-06-10 23:42:49.248379 EDT | PolicyRegParamNorm         78.767
2017-06-10 23:42:49.248579 EDT | QFunRegParamNorm          100.544
2017-06-10 23:42:49.248760 EDT | -----------------------  -----------
2017-06-10 23:42:49.249152 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #582 | Training started
2017-06-10 23:43:03.776209 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #582 | Training finished
2017-06-10 23:43:03.776935 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #582 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 23:43:03.777391 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #582 | Collecting samples for evaluation
2017-06-10 23:43:16.882516 EDT | -----------------------  -----------
2017-06-10 23:43:16.882783 EDT | Epoch                     582
2017-06-10 23:43:16.882980 EDT | Iteration                 582
2017-06-10 23:43:16.883138 EDT | AverageReturn             873.753
2017-06-10 23:43:16.883298 EDT | StdReturn                 210.292
2017-06-10 23:43:16.883449 EDT | MaxReturn                1494.76
2017-06-10 23:43:16.883599 EDT | MinReturn                 550.346
2017-06-10 23:43:16.883748 EDT | AverageEsReturn           298.927
2017-06-10 23:43:16.883898 EDT | StdEsReturn               237.483
2017-06-10 23:43:16.884046 EDT | MaxEsReturn               741.556
2017-06-10 23:43:16.884193 EDT | MinEsReturn                 8.50891
2017-06-10 23:43:16.884341 EDT | AverageDiscountedReturn   216.945
2017-06-10 23:43:16.884489 EDT | AverageQLoss                2.73537
2017-06-10 23:43:16.884637 EDT | AveragePolicySurr         -32.0272
2017-06-10 23:43:16.884784 EDT | AverageQ                   31.6247
2017-06-10 23:43:16.884962 EDT | AverageAbsQ                31.6518
2017-06-10 23:43:16.885119 EDT | AverageY                   31.6254
2017-06-10 23:43:16.885274 EDT | AverageAbsY                31.6414
2017-06-10 23:43:16.885429 EDT | AverageAbsQYDiff            0.606849
2017-06-10 23:43:16.886195 EDT | AverageAction               0.933168
2017-06-10 23:43:16.886442 EDT | PolicyRegParamNorm         78.8139
2017-06-10 23:43:16.886602 EDT | QFunRegParamNorm          100.565
2017-06-10 23:43:16.886755 EDT | -----------------------  -----------
2017-06-10 23:43:16.886992 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #583 | Training started
2017-06-10 23:43:32.433463 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #583 | Training finished
2017-06-10 23:43:32.434507 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #583 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 23:43:32.434841 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #583 | Collecting samples for evaluation
2017-06-10 23:43:43.952419 EDT | -----------------------  -----------
2017-06-10 23:43:43.953629 EDT | Epoch                     583
2017-06-10 23:43:43.953885 EDT | Iteration                 583
2017-06-10 23:43:43.954081 EDT | AverageReturn            1160.18
2017-06-10 23:43:43.954293 EDT | StdReturn                 533.045
2017-06-10 23:43:43.954484 EDT | MaxReturn                2769.95
2017-06-10 23:43:43.954735 EDT | MinReturn                 678.417
2017-06-10 23:43:43.954917 EDT | AverageEsReturn           486.958
2017-06-10 23:43:43.955095 EDT | StdEsReturn               392.021
2017-06-10 23:43:43.955273 EDT | MaxEsReturn               967.309
2017-06-10 23:43:43.955452 EDT | MinEsReturn                32.315
2017-06-10 23:43:43.955639 EDT | AverageDiscountedReturn   230.948
2017-06-10 23:43:43.955806 EDT | AverageQLoss                2.33981
2017-06-10 23:43:43.955956 EDT | AveragePolicySurr         -32.0791
2017-06-10 23:43:43.956190 EDT | AverageQ                   31.6803
2017-06-10 23:43:43.956524 EDT | AverageAbsQ                31.7054
2017-06-10 23:43:43.956853 EDT | AverageY                   31.6838
2017-06-10 23:43:43.957196 EDT | AverageAbsY                31.6978
2017-06-10 23:43:43.957531 EDT | AverageAbsQYDiff            0.57816
2017-06-10 23:43:43.957865 EDT | AverageAction               0.955434
2017-06-10 23:43:43.958188 EDT | PolicyRegParamNorm         78.8392
2017-06-10 23:43:43.958476 EDT | QFunRegParamNorm          100.621
2017-06-10 23:43:43.958813 EDT | -----------------------  -----------
2017-06-10 23:43:43.959215 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #584 | Training started
2017-06-10 23:44:00.062400 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #584 | Training finished
2017-06-10 23:44:00.063186 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #584 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 23:44:00.063519 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #584 | Collecting samples for evaluation
2017-06-10 23:44:11.753027 EDT | -----------------------  ----------
2017-06-10 23:44:11.754269 EDT | Epoch                    584
2017-06-10 23:44:11.754573 EDT | Iteration                584
2017-06-10 23:44:11.754842 EDT | AverageReturn            585.19
2017-06-10 23:44:11.755106 EDT | StdReturn                125.993
2017-06-10 23:44:11.755367 EDT | MaxReturn                908.353
2017-06-10 23:44:11.755627 EDT | MinReturn                382.403
2017-06-10 23:44:11.755886 EDT | AverageEsReturn          348.398
2017-06-10 23:44:11.756145 EDT | StdEsReturn              256.49
2017-06-10 23:44:11.756407 EDT | MaxEsReturn              849.201
2017-06-10 23:44:11.756668 EDT | MinEsReturn               42.3345
2017-06-10 23:44:11.756925 EDT | AverageDiscountedReturn  206.112
2017-06-10 23:44:11.757182 EDT | AverageQLoss               2.69801
2017-06-10 23:44:11.757439 EDT | AveragePolicySurr        -32.0916
2017-06-10 23:44:11.757710 EDT | AverageQ                  31.6828
2017-06-10 23:44:11.757976 EDT | AverageAbsQ               31.7087
2017-06-10 23:44:11.758234 EDT | AverageY                  31.6846
2017-06-10 23:44:11.758491 EDT | AverageAbsY               31.7
2017-06-10 23:44:11.758749 EDT | AverageAbsQYDiff           0.590327
2017-06-10 23:44:11.759005 EDT | AverageAction              0.958822
2017-06-10 23:44:11.759262 EDT | PolicyRegParamNorm        78.9138
2017-06-10 23:44:11.759581 EDT | QFunRegParamNorm         100.699
2017-06-10 23:44:11.759839 EDT | -----------------------  ----------
2017-06-10 23:44:11.760242 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #585 | Training started
2017-06-10 23:44:26.798013 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #585 | Training finished
2017-06-10 23:44:26.798675 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #585 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 23:44:26.798966 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #585 | Collecting samples for evaluation
2017-06-10 23:44:40.156661 EDT | -----------------------  -----------
2017-06-10 23:44:40.157091 EDT | Epoch                     585
2017-06-10 23:44:40.157470 EDT | Iteration                 585
2017-06-10 23:44:40.157814 EDT | AverageReturn             834.68
2017-06-10 23:44:40.158144 EDT | StdReturn                 181.929
2017-06-10 23:44:40.158468 EDT | MaxReturn                1396.36
2017-06-10 23:44:40.158787 EDT | MinReturn                 614.258
2017-06-10 23:44:40.159112 EDT | AverageEsReturn           250.872
2017-06-10 23:44:40.159467 EDT | StdEsReturn               226.843
2017-06-10 23:44:40.159801 EDT | MaxEsReturn               680.305
2017-06-10 23:44:40.160143 EDT | MinEsReturn                 8.66587
2017-06-10 23:44:40.160517 EDT | AverageDiscountedReturn   223.282
2017-06-10 23:44:40.160904 EDT | AverageQLoss                2.38666
2017-06-10 23:44:40.161279 EDT | AveragePolicySurr         -31.9896
2017-06-10 23:44:40.161608 EDT | AverageQ                   31.5965
2017-06-10 23:44:40.161953 EDT | AverageAbsQ                31.6242
2017-06-10 23:44:40.162285 EDT | AverageY                   31.5971
2017-06-10 23:44:40.162612 EDT | AverageAbsY                31.6123
2017-06-10 23:44:40.162949 EDT | AverageAbsQYDiff            0.581622
2017-06-10 23:44:40.163273 EDT | AverageAction               0.966656
2017-06-10 23:44:40.163598 EDT | PolicyRegParamNorm         78.9357
2017-06-10 23:44:40.163920 EDT | QFunRegParamNorm          100.758
2017-06-10 23:44:40.164249 EDT | -----------------------  -----------
2017-06-10 23:44:40.164744 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #586 | Training started
2017-06-10 23:44:54.047165 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #586 | Training finished
2017-06-10 23:44:54.048132 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #586 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 23:44:54.048515 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #586 | Collecting samples for evaluation
2017-06-10 23:45:06.424326 EDT | -----------------------  -----------
2017-06-10 23:45:06.425389 EDT | Epoch                     586
2017-06-10 23:45:06.425770 EDT | Iteration                 586
2017-06-10 23:45:06.425959 EDT | AverageReturn             880.746
2017-06-10 23:45:06.426149 EDT | StdReturn                 218.055
2017-06-10 23:45:06.426332 EDT | MaxReturn                1370.1
2017-06-10 23:45:06.427856 EDT | MinReturn                 597.123
2017-06-10 23:45:06.428175 EDT | AverageEsReturn           305.14
2017-06-10 23:45:06.429377 EDT | StdEsReturn               213.175
2017-06-10 23:45:06.429615 EDT | MaxEsReturn               663.56
2017-06-10 23:45:06.429816 EDT | MinEsReturn                22.9259
2017-06-10 23:45:06.430000 EDT | AverageDiscountedReturn   228.51
2017-06-10 23:45:06.430185 EDT | AverageQLoss                2.50479
2017-06-10 23:45:06.430370 EDT | AveragePolicySurr         -31.9723
2017-06-10 23:45:06.430552 EDT | AverageQ                   31.5589
2017-06-10 23:45:06.430731 EDT | AverageAbsQ                31.5898
2017-06-10 23:45:06.430909 EDT | AverageY                   31.5591
2017-06-10 23:45:06.431089 EDT | AverageAbsY                31.5774
2017-06-10 23:45:06.431269 EDT | AverageAbsQYDiff            0.571832
2017-06-10 23:45:06.431446 EDT | AverageAction               0.949949
2017-06-10 23:45:06.431623 EDT | PolicyRegParamNorm         79.0167
2017-06-10 23:45:06.431800 EDT | QFunRegParamNorm          100.835
2017-06-10 23:45:06.431970 EDT | -----------------------  -----------
2017-06-10 23:45:06.432233 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #587 | Training started
2017-06-10 23:45:22.286090 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #587 | Training finished
2017-06-10 23:45:22.287079 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #587 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 23:45:22.287472 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #587 | Collecting samples for evaluation
2017-06-10 23:45:33.861395 EDT | -----------------------  -----------
2017-06-10 23:45:33.862259 EDT | Epoch                     587
2017-06-10 23:45:33.862462 EDT | Iteration                 587
2017-06-10 23:45:33.862749 EDT | AverageReturn             924.101
2017-06-10 23:45:33.862938 EDT | StdReturn                 266.616
2017-06-10 23:45:33.863129 EDT | MaxReturn                1568.36
2017-06-10 23:45:33.863311 EDT | MinReturn                 577.525
2017-06-10 23:45:33.863491 EDT | AverageEsReturn           413.965
2017-06-10 23:45:33.863673 EDT | StdEsReturn               286.514
2017-06-10 23:45:33.864072 EDT | MaxEsReturn               773.564
2017-06-10 23:45:33.864277 EDT | MinEsReturn                 7.21719
2017-06-10 23:45:33.865417 EDT | AverageDiscountedReturn   224.843
2017-06-10 23:45:33.865615 EDT | AverageQLoss                2.72034
2017-06-10 23:45:33.865865 EDT | AveragePolicySurr         -32.0533
2017-06-10 23:45:33.866283 EDT | AverageQ                   31.64
2017-06-10 23:45:33.866492 EDT | AverageAbsQ                31.6741
2017-06-10 23:45:33.866877 EDT | AverageY                   31.6409
2017-06-10 23:45:33.867062 EDT | AverageAbsY                31.6639
2017-06-10 23:45:33.867249 EDT | AverageAbsQYDiff            0.613307
2017-06-10 23:45:33.867429 EDT | AverageAction               0.953714
2017-06-10 23:45:33.867609 EDT | PolicyRegParamNorm         79.0447
2017-06-10 23:45:33.867789 EDT | QFunRegParamNorm          100.939
2017-06-10 23:45:33.867968 EDT | -----------------------  -----------
2017-06-10 23:45:33.868376 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #588 | Training started
2017-06-10 23:45:49.583014 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #588 | Training finished
2017-06-10 23:45:49.583981 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #588 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 23:45:49.584960 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #588 | Collecting samples for evaluation
2017-06-10 23:46:02.539392 EDT | -----------------------  -----------
2017-06-10 23:46:02.540987 EDT | Epoch                     588
2017-06-10 23:46:02.541519 EDT | Iteration                 588
2017-06-10 23:46:02.542251 EDT | AverageReturn            1127.17
2017-06-10 23:46:02.542724 EDT | StdReturn                 489.949
2017-06-10 23:46:02.543496 EDT | MaxReturn                2328.84
2017-06-10 23:46:02.544077 EDT | MinReturn                 554.841
2017-06-10 23:46:02.544554 EDT | AverageEsReturn           298.159
2017-06-10 23:46:02.544981 EDT | StdEsReturn               227.111
2017-06-10 23:46:02.545560 EDT | MaxEsReturn               628.624
2017-06-10 23:46:02.546045 EDT | MinEsReturn                 6.90671
2017-06-10 23:46:02.546623 EDT | AverageDiscountedReturn   222.57
2017-06-10 23:46:02.547093 EDT | AverageQLoss                2.77054
2017-06-10 23:46:02.547904 EDT | AveragePolicySurr         -32.1003
2017-06-10 23:46:02.548365 EDT | AverageQ                   31.6897
2017-06-10 23:46:02.548931 EDT | AverageAbsQ                31.7233
2017-06-10 23:46:02.549379 EDT | AverageY                   31.6916
2017-06-10 23:46:02.549961 EDT | AverageAbsY                31.7098
2017-06-10 23:46:02.550511 EDT | AverageAbsQYDiff            0.615083
2017-06-10 23:46:02.550976 EDT | AverageAction               0.934468
2017-06-10 23:46:02.551542 EDT | PolicyRegParamNorm         79.0398
2017-06-10 23:46:02.552055 EDT | QFunRegParamNorm          101.036
2017-06-10 23:46:02.552576 EDT | -----------------------  -----------
2017-06-10 23:46:02.553255 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #589 | Training started
2017-06-10 23:46:17.740148 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #589 | Training finished
2017-06-10 23:46:17.740984 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #589 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 23:46:17.741179 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #589 | Collecting samples for evaluation
2017-06-10 23:46:30.894739 EDT | -----------------------  -----------
2017-06-10 23:46:30.895447 EDT | Epoch                     589
2017-06-10 23:46:30.895647 EDT | Iteration                 589
2017-06-10 23:46:30.895842 EDT | AverageReturn             983.63
2017-06-10 23:46:30.896233 EDT | StdReturn                 409.776
2017-06-10 23:46:30.896426 EDT | MaxReturn                2621.57
2017-06-10 23:46:30.896611 EDT | MinReturn                 547.136
2017-06-10 23:46:30.896992 EDT | AverageEsReturn           461.824
2017-06-10 23:46:30.897430 EDT | StdEsReturn               266.053
2017-06-10 23:46:30.897875 EDT | MaxEsReturn               825.851
2017-06-10 23:46:30.898290 EDT | MinEsReturn                52.6515
2017-06-10 23:46:30.898961 EDT | AverageDiscountedReturn   212.222
2017-06-10 23:46:30.899318 EDT | AverageQLoss                2.25296
2017-06-10 23:46:30.899515 EDT | AveragePolicySurr         -32.1606
2017-06-10 23:46:30.899701 EDT | AverageQ                   31.7481
2017-06-10 23:46:30.899894 EDT | AverageAbsQ                31.7725
2017-06-10 23:46:30.900075 EDT | AverageY                   31.7494
2017-06-10 23:46:30.900254 EDT | AverageAbsY                31.7623
2017-06-10 23:46:30.900438 EDT | AverageAbsQYDiff            0.575018
2017-06-10 23:46:30.901001 EDT | AverageAction               0.954373
2017-06-10 23:46:30.901417 EDT | PolicyRegParamNorm         79.054
2017-06-10 23:46:30.901604 EDT | QFunRegParamNorm          101.121
2017-06-10 23:46:30.902187 EDT | -----------------------  -----------
2017-06-10 23:46:30.902686 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #590 | Training started
2017-06-10 23:46:46.539443 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #590 | Training finished
2017-06-10 23:46:46.540387 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #590 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 23:46:46.540763 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #590 | Collecting samples for evaluation
2017-06-10 23:46:59.649866 EDT | -----------------------  -----------
2017-06-10 23:46:59.651509 EDT | Epoch                     590
2017-06-10 23:46:59.653612 EDT | Iteration                 590
2017-06-10 23:46:59.653838 EDT | AverageReturn            1081.6
2017-06-10 23:46:59.654015 EDT | StdReturn                 410.194
2017-06-10 23:46:59.654240 EDT | MaxReturn                2088.9
2017-06-10 23:46:59.654432 EDT | MinReturn                 604.341
2017-06-10 23:46:59.654605 EDT | AverageEsReturn           321.604
2017-06-10 23:46:59.654774 EDT | StdEsReturn               361.593
2017-06-10 23:46:59.654969 EDT | MaxEsReturn              1098.61
2017-06-10 23:46:59.655140 EDT | MinEsReturn                66.0673
2017-06-10 23:46:59.655317 EDT | AverageDiscountedReturn   236.518
2017-06-10 23:46:59.655493 EDT | AverageQLoss                2.50989
2017-06-10 23:46:59.655681 EDT | AveragePolicySurr         -32.1235
2017-06-10 23:46:59.655850 EDT | AverageQ                   31.7421
2017-06-10 23:46:59.656016 EDT | AverageAbsQ                31.769
2017-06-10 23:46:59.656183 EDT | AverageY                   31.7427
2017-06-10 23:46:59.656361 EDT | AverageAbsY                31.7563
2017-06-10 23:46:59.656528 EDT | AverageAbsQYDiff            0.596045
2017-06-10 23:46:59.656702 EDT | AverageAction               0.968764
2017-06-10 23:46:59.656907 EDT | PolicyRegParamNorm         79.1392
2017-06-10 23:46:59.657087 EDT | QFunRegParamNorm          101.213
2017-06-10 23:46:59.657256 EDT | -----------------------  -----------
2017-06-10 23:46:59.657571 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #591 | Training started
2017-06-10 23:47:17.019558 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #591 | Training finished
2017-06-10 23:47:17.020440 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #591 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 23:47:17.020771 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #591 | Collecting samples for evaluation
2017-06-10 23:47:28.501850 EDT | -----------------------  -----------
2017-06-10 23:47:28.503453 EDT | Epoch                     591
2017-06-10 23:47:28.503939 EDT | Iteration                 591
2017-06-10 23:47:28.504388 EDT | AverageReturn             993.085
2017-06-10 23:47:28.505383 EDT | StdReturn                 517.51
2017-06-10 23:47:28.505899 EDT | MaxReturn                2733.23
2017-06-10 23:47:28.508317 EDT | MinReturn                 586.59
2017-06-10 23:47:28.510665 EDT | AverageEsReturn           449.784
2017-06-10 23:47:28.511128 EDT | StdEsReturn               318.252
2017-06-10 23:47:28.511851 EDT | MaxEsReturn               914.666
2017-06-10 23:47:28.512305 EDT | MinEsReturn               143.486
2017-06-10 23:47:28.512750 EDT | AverageDiscountedReturn   221.849
2017-06-10 23:47:28.513182 EDT | AverageQLoss                2.87133
2017-06-10 23:47:28.513629 EDT | AveragePolicySurr         -32.0883
2017-06-10 23:47:28.514081 EDT | AverageQ                   31.6778
2017-06-10 23:47:28.514527 EDT | AverageAbsQ                31.7035
2017-06-10 23:47:28.514952 EDT | AverageY                   31.6801
2017-06-10 23:47:28.515393 EDT | AverageAbsY                31.6911
2017-06-10 23:47:28.517909 EDT | AverageAbsQYDiff            0.625929
2017-06-10 23:47:28.518393 EDT | AverageAction               0.966664
2017-06-10 23:47:28.518823 EDT | PolicyRegParamNorm         79.2351
2017-06-10 23:47:28.519188 EDT | QFunRegParamNorm          101.297
2017-06-10 23:47:28.519527 EDT | -----------------------  -----------
2017-06-10 23:47:28.520081 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #592 | Training started
2017-06-10 23:47:44.785894 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #592 | Training finished
2017-06-10 23:47:44.799641 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #592 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 23:47:44.800019 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #592 | Collecting samples for evaluation
2017-06-10 23:47:58.203715 EDT | -----------------------  ----------
2017-06-10 23:47:58.218260 EDT | Epoch                    592
2017-06-10 23:47:58.218627 EDT | Iteration                592
2017-06-10 23:47:58.219019 EDT | AverageReturn            610.261
2017-06-10 23:47:58.219217 EDT | StdReturn                149.791
2017-06-10 23:47:58.219423 EDT | MaxReturn                888.407
2017-06-10 23:47:58.219656 EDT | MinReturn                360.127
2017-06-10 23:47:58.219839 EDT | AverageEsReturn          276.701
2017-06-10 23:47:58.220063 EDT | StdEsReturn              203.28
2017-06-10 23:47:58.220284 EDT | MaxEsReturn              791.345
2017-06-10 23:47:58.220477 EDT | MinEsReturn               66.3958
2017-06-10 23:47:58.220690 EDT | AverageDiscountedReturn  206.88
2017-06-10 23:47:58.220872 EDT | AverageQLoss               2.68687
2017-06-10 23:47:58.221059 EDT | AveragePolicySurr        -32.1435
2017-06-10 23:47:58.221276 EDT | AverageQ                  31.7371
2017-06-10 23:47:58.221471 EDT | AverageAbsQ               31.7599
2017-06-10 23:47:58.221863 EDT | AverageY                  31.7375
2017-06-10 23:47:58.222056 EDT | AverageAbsY               31.7473
2017-06-10 23:47:58.222240 EDT | AverageAbsQYDiff           0.585777
2017-06-10 23:47:58.222449 EDT | AverageAction              0.967985
2017-06-10 23:47:58.222696 EDT | PolicyRegParamNorm        79.269
2017-06-10 23:47:58.222878 EDT | QFunRegParamNorm         101.382
2017-06-10 23:47:58.223098 EDT | -----------------------  ----------
2017-06-10 23:47:58.223403 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #593 | Training started
2017-06-10 23:48:13.542185 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #593 | Training finished
2017-06-10 23:48:13.543093 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #593 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 23:48:13.543408 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #593 | Collecting samples for evaluation
2017-06-10 23:48:26.969846 EDT | -----------------------  -----------
2017-06-10 23:48:26.970676 EDT | Epoch                     593
2017-06-10 23:48:26.970960 EDT | Iteration                 593
2017-06-10 23:48:26.971218 EDT | AverageReturn            1047.71
2017-06-10 23:48:26.971469 EDT | StdReturn                 473.342
2017-06-10 23:48:26.971717 EDT | MaxReturn                2631.2
2017-06-10 23:48:26.971963 EDT | MinReturn                 540.002
2017-06-10 23:48:26.972205 EDT | AverageEsReturn           524.053
2017-06-10 23:48:26.972358 EDT | StdEsReturn               270.687
2017-06-10 23:48:26.972508 EDT | MaxEsReturn               777.824
2017-06-10 23:48:26.972656 EDT | MinEsReturn                53.987
2017-06-10 23:48:26.972871 EDT | AverageDiscountedReturn   217.268
2017-06-10 23:48:26.978076 EDT | AverageQLoss                2.5975
2017-06-10 23:48:26.978384 EDT | AveragePolicySurr         -32.1245
2017-06-10 23:48:26.978641 EDT | AverageQ                   31.7044
2017-06-10 23:48:26.978894 EDT | AverageAbsQ                31.7373
2017-06-10 23:48:26.979128 EDT | AverageY                   31.7067
2017-06-10 23:48:26.979280 EDT | AverageAbsY                31.7249
2017-06-10 23:48:26.979430 EDT | AverageAbsQYDiff            0.596815
2017-06-10 23:48:26.979579 EDT | AverageAction               0.973595
2017-06-10 23:48:26.979728 EDT | PolicyRegParamNorm         79.3488
2017-06-10 23:48:26.979877 EDT | QFunRegParamNorm          101.446
2017-06-10 23:48:26.980025 EDT | -----------------------  -----------
2017-06-10 23:48:26.980290 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #594 | Training started
2017-06-10 23:48:41.929630 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #594 | Training finished
2017-06-10 23:48:41.930148 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #594 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 23:48:41.930521 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #594 | Collecting samples for evaluation
2017-06-10 23:48:55.359567 EDT | -----------------------  -----------
2017-06-10 23:48:55.360533 EDT | Epoch                     594
2017-06-10 23:48:55.360881 EDT | Iteration                 594
2017-06-10 23:48:55.361212 EDT | AverageReturn            1090.99
2017-06-10 23:48:55.361541 EDT | StdReturn                 392.702
2017-06-10 23:48:55.361881 EDT | MaxReturn                2420.99
2017-06-10 23:48:55.362207 EDT | MinReturn                 573.455
2017-06-10 23:48:55.362530 EDT | AverageEsReturn           414.238
2017-06-10 23:48:55.362852 EDT | StdEsReturn               274.654
2017-06-10 23:48:55.363174 EDT | MaxEsReturn               848.22
2017-06-10 23:48:55.363494 EDT | MinEsReturn                66.8532
2017-06-10 23:48:55.363823 EDT | AverageDiscountedReturn   222.694
2017-06-10 23:48:55.364300 EDT | AverageQLoss                2.76285
2017-06-10 23:48:55.364635 EDT | AveragePolicySurr         -32.0716
2017-06-10 23:48:55.364960 EDT | AverageQ                   31.654
2017-06-10 23:48:55.365283 EDT | AverageAbsQ                31.6817
2017-06-10 23:48:55.365610 EDT | AverageY                   31.655
2017-06-10 23:48:55.365940 EDT | AverageAbsY                31.6717
2017-06-10 23:48:55.366262 EDT | AverageAbsQYDiff            0.622095
2017-06-10 23:48:55.366583 EDT | AverageAction               0.973323
2017-06-10 23:48:55.366908 EDT | PolicyRegParamNorm         79.3518
2017-06-10 23:48:55.367225 EDT | QFunRegParamNorm          101.541
2017-06-10 23:48:55.367544 EDT | -----------------------  -----------
2017-06-10 23:48:55.368015 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #595 | Training started
2017-06-10 23:49:11.551718 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #595 | Training finished
2017-06-10 23:49:11.551971 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #595 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 23:49:11.552151 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #595 | Collecting samples for evaluation
2017-06-10 23:49:24.203951 EDT | -----------------------  -----------
2017-06-10 23:49:24.204939 EDT | Epoch                     595
2017-06-10 23:49:24.205309 EDT | Iteration                 595
2017-06-10 23:49:24.205656 EDT | AverageReturn             771.019
2017-06-10 23:49:24.206022 EDT | StdReturn                 164.577
2017-06-10 23:49:24.206366 EDT | MaxReturn                1234.06
2017-06-10 23:49:24.206713 EDT | MinReturn                 567.69
2017-06-10 23:49:24.207055 EDT | AverageEsReturn           451.726
2017-06-10 23:49:24.207400 EDT | StdEsReturn               353.918
2017-06-10 23:49:24.207744 EDT | MaxEsReturn               889.198
2017-06-10 23:49:24.208084 EDT | MinEsReturn               128.168
2017-06-10 23:49:24.208427 EDT | AverageDiscountedReturn   218.506
2017-06-10 23:49:24.208769 EDT | AverageQLoss                2.49846
2017-06-10 23:49:24.209113 EDT | AveragePolicySurr         -32.1474
2017-06-10 23:49:24.209454 EDT | AverageQ                   31.7392
2017-06-10 23:49:24.209810 EDT | AverageAbsQ                31.7691
2017-06-10 23:49:24.210155 EDT | AverageY                   31.7396
2017-06-10 23:49:24.210502 EDT | AverageAbsY                31.755
2017-06-10 23:49:24.210843 EDT | AverageAbsQYDiff            0.590516
2017-06-10 23:49:24.211185 EDT | AverageAction               0.974577
2017-06-10 23:49:24.211527 EDT | PolicyRegParamNorm         79.4609
2017-06-10 23:49:24.211865 EDT | QFunRegParamNorm          101.66
2017-06-10 23:49:24.212207 EDT | -----------------------  -----------
2017-06-10 23:49:24.212730 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #596 | Training started
2017-06-10 23:49:40.752441 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #596 | Training finished
2017-06-10 23:49:40.752694 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #596 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 23:49:40.752872 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #596 | Collecting samples for evaluation
2017-06-10 23:49:54.373368 EDT | -----------------------  -----------
2017-06-10 23:49:54.374507 EDT | Epoch                     596
2017-06-10 23:49:54.374715 EDT | Iteration                 596
2017-06-10 23:49:54.374887 EDT | AverageReturn            1042.57
2017-06-10 23:49:54.375054 EDT | StdReturn                 303.797
2017-06-10 23:49:54.375245 EDT | MaxReturn                1840.65
2017-06-10 23:49:54.375427 EDT | MinReturn                 656.561
2017-06-10 23:49:54.375617 EDT | AverageEsReturn           466.156
2017-06-10 23:49:54.375800 EDT | StdEsReturn               273.274
2017-06-10 23:49:54.376051 EDT | MaxEsReturn               930.376
2017-06-10 23:49:54.376236 EDT | MinEsReturn               112.077
2017-06-10 23:49:54.376449 EDT | AverageDiscountedReturn   239.88
2017-06-10 23:49:54.376630 EDT | AverageQLoss                2.53468
2017-06-10 23:49:54.376868 EDT | AveragePolicySurr         -32.0787
2017-06-10 23:49:54.377125 EDT | AverageQ                   31.6577
2017-06-10 23:49:54.377415 EDT | AverageAbsQ                31.6967
2017-06-10 23:49:54.377640 EDT | AverageY                   31.6573
2017-06-10 23:49:54.377864 EDT | AverageAbsY                31.6834
2017-06-10 23:49:54.378047 EDT | AverageAbsQYDiff            0.595106
2017-06-10 23:49:54.378317 EDT | AverageAction               0.972484
2017-06-10 23:49:54.378478 EDT | PolicyRegParamNorm         79.4917
2017-06-10 23:49:54.378635 EDT | QFunRegParamNorm          101.731
2017-06-10 23:49:54.378867 EDT | -----------------------  -----------
2017-06-10 23:49:54.379282 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #597 | Training started
2017-06-10 23:50:11.008432 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #597 | Training finished
2017-06-10 23:50:11.009389 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #597 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 23:50:11.009824 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #597 | Collecting samples for evaluation
2017-06-10 23:50:23.736416 EDT | -----------------------  -----------
2017-06-10 23:50:23.737234 EDT | Epoch                     597
2017-06-10 23:50:23.737554 EDT | Iteration                 597
2017-06-10 23:50:23.737818 EDT | AverageReturn             949.162
2017-06-10 23:50:23.738002 EDT | StdReturn                 185.764
2017-06-10 23:50:23.738212 EDT | MaxReturn                1414.34
2017-06-10 23:50:23.738386 EDT | MinReturn                 556.239
2017-06-10 23:50:23.738541 EDT | AverageEsReturn           518.374
2017-06-10 23:50:23.738705 EDT | StdEsReturn               271.02
2017-06-10 23:50:23.738893 EDT | MaxEsReturn               937.847
2017-06-10 23:50:23.739112 EDT | MinEsReturn               155.752
2017-06-10 23:50:23.739463 EDT | AverageDiscountedReturn   232.623
2017-06-10 23:50:23.739645 EDT | AverageQLoss                2.57385
2017-06-10 23:50:23.740229 EDT | AveragePolicySurr         -32.1253
2017-06-10 23:50:23.740625 EDT | AverageQ                   31.7162
2017-06-10 23:50:23.740960 EDT | AverageAbsQ                31.7535
2017-06-10 23:50:23.741379 EDT | AverageY                   31.7171
2017-06-10 23:50:23.741735 EDT | AverageAbsY                31.7417
2017-06-10 23:50:23.742017 EDT | AverageAbsQYDiff            0.591404
2017-06-10 23:50:23.742353 EDT | AverageAction               0.975461
2017-06-10 23:50:23.742682 EDT | PolicyRegParamNorm         79.5349
2017-06-10 23:50:23.743006 EDT | QFunRegParamNorm          101.792
2017-06-10 23:50:23.743325 EDT | -----------------------  -----------
2017-06-10 23:50:23.743685 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #598 | Training started
2017-06-10 23:50:38.977074 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #598 | Training finished
2017-06-10 23:50:38.977850 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #598 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 23:50:38.978044 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #598 | Collecting samples for evaluation
2017-06-10 23:50:53.006851 EDT | -----------------------  -----------
2017-06-10 23:50:53.007853 EDT | Epoch                     598
2017-06-10 23:50:53.008342 EDT | Iteration                 598
2017-06-10 23:50:53.008745 EDT | AverageReturn             929.805
2017-06-10 23:50:53.009198 EDT | StdReturn                 309.931
2017-06-10 23:50:53.009678 EDT | MaxReturn                2074.91
2017-06-10 23:50:53.010145 EDT | MinReturn                 627.866
2017-06-10 23:50:53.010607 EDT | AverageEsReturn           421.732
2017-06-10 23:50:53.011040 EDT | StdEsReturn               335.303
2017-06-10 23:50:53.011475 EDT | MaxEsReturn              1015.37
2017-06-10 23:50:53.011941 EDT | MinEsReturn                13.387
2017-06-10 23:50:53.012397 EDT | AverageDiscountedReturn   233.805
2017-06-10 23:50:53.014447 EDT | AverageQLoss                2.74656
2017-06-10 23:50:53.014831 EDT | AveragePolicySurr         -32.1103
2017-06-10 23:50:53.015189 EDT | AverageQ                   31.6869
2017-06-10 23:50:53.018120 EDT | AverageAbsQ                31.729
2017-06-10 23:50:53.020401 EDT | AverageY                   31.6877
2017-06-10 23:50:53.020995 EDT | AverageAbsY                31.7137
2017-06-10 23:50:53.021388 EDT | AverageAbsQYDiff            0.62534
2017-06-10 23:50:53.021762 EDT | AverageAction               0.966423
2017-06-10 23:50:53.022122 EDT | PolicyRegParamNorm         79.6008
2017-06-10 23:50:53.022524 EDT | QFunRegParamNorm          101.884
2017-06-10 23:50:53.022868 EDT | -----------------------  -----------
2017-06-10 23:50:53.023697 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #599 | Training started
2017-06-10 23:51:09.914790 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #599 | Training finished
2017-06-10 23:51:09.915807 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #599 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 23:51:09.916207 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #599 | Collecting samples for evaluation
2017-06-10 23:51:22.483825 EDT | -----------------------  -----------
2017-06-10 23:51:22.484781 EDT | Epoch                     599
2017-06-10 23:51:22.485133 EDT | Iteration                 599
2017-06-10 23:51:22.485684 EDT | AverageReturn             878.437
2017-06-10 23:51:22.485910 EDT | StdReturn                 161.453
2017-06-10 23:51:22.486095 EDT | MaxReturn                1287.31
2017-06-10 23:51:22.486277 EDT | MinReturn                 663.702
2017-06-10 23:51:22.486459 EDT | AverageEsReturn           436.337
2017-06-10 23:51:22.486640 EDT | StdEsReturn               486.974
2017-06-10 23:51:22.486818 EDT | MaxEsReturn              1415.89
2017-06-10 23:51:22.486996 EDT | MinEsReturn                59.0763
2017-06-10 23:51:22.487175 EDT | AverageDiscountedReturn   240.475
2017-06-10 23:51:22.487353 EDT | AverageQLoss                2.76579
2017-06-10 23:51:22.487533 EDT | AveragePolicySurr         -32.1316
2017-06-10 23:51:22.487711 EDT | AverageQ                   31.7305
2017-06-10 23:51:22.487889 EDT | AverageAbsQ                31.7709
2017-06-10 23:51:22.488069 EDT | AverageY                   31.7334
2017-06-10 23:51:22.488246 EDT | AverageAbsY                31.7588
2017-06-10 23:51:22.488424 EDT | AverageAbsQYDiff            0.613797
2017-06-10 23:51:22.488601 EDT | AverageAction               0.974406
2017-06-10 23:51:22.488779 EDT | PolicyRegParamNorm         79.6822
2017-06-10 23:51:22.488957 EDT | QFunRegParamNorm          101.965
2017-06-10 23:51:22.489135 EDT | -----------------------  -----------
2017-06-10 23:51:22.489428 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #600 | Training started
2017-06-10 23:51:40.538552 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #600 | Training finished
2017-06-10 23:51:40.539404 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #600 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 23:51:40.539621 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #600 | Collecting samples for evaluation
2017-06-10 23:51:53.485018 EDT | -----------------------  -----------
2017-06-10 23:51:53.487927 EDT | Epoch                     600
2017-06-10 23:51:53.488352 EDT | Iteration                 600
2017-06-10 23:51:53.488738 EDT | AverageReturn             620.735
2017-06-10 23:51:53.489121 EDT | StdReturn                 231.679
2017-06-10 23:51:53.489502 EDT | MaxReturn                1182.88
2017-06-10 23:51:53.489886 EDT | MinReturn                 334.74
2017-06-10 23:51:53.490262 EDT | AverageEsReturn           331.558
2017-06-10 23:51:53.490637 EDT | StdEsReturn               282.98
2017-06-10 23:51:53.492551 EDT | MaxEsReturn               928.258
2017-06-10 23:51:53.492933 EDT | MinEsReturn                12.3648
2017-06-10 23:51:53.493313 EDT | AverageDiscountedReturn   204.92
2017-06-10 23:51:53.493688 EDT | AverageQLoss                2.57242
2017-06-10 23:51:53.494072 EDT | AveragePolicySurr         -32.0857
2017-06-10 23:51:53.494454 EDT | AverageQ                   31.6905
2017-06-10 23:51:53.494827 EDT | AverageAbsQ                31.7275
2017-06-10 23:51:53.495199 EDT | AverageY                   31.6928
2017-06-10 23:51:53.495582 EDT | AverageAbsY                31.7151
2017-06-10 23:51:53.495955 EDT | AverageAbsQYDiff            0.604982
2017-06-10 23:51:53.496325 EDT | AverageAction               0.965208
2017-06-10 23:51:53.496702 EDT | PolicyRegParamNorm         79.6833
2017-06-10 23:51:53.497074 EDT | QFunRegParamNorm          102.016
2017-06-10 23:51:53.497469 EDT | -----------------------  -----------
2017-06-10 23:51:53.498045 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #601 | Training started
2017-06-10 23:52:10.685054 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #601 | Training finished
2017-06-10 23:52:10.685857 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #601 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 23:52:10.686299 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #601 | Collecting samples for evaluation
2017-06-10 23:52:23.844227 EDT | -----------------------  -----------
2017-06-10 23:52:23.845129 EDT | Epoch                     601
2017-06-10 23:52:23.845586 EDT | Iteration                 601
2017-06-10 23:52:23.846028 EDT | AverageReturn             782.313
2017-06-10 23:52:23.846439 EDT | StdReturn                 224.934
2017-06-10 23:52:23.846925 EDT | MaxReturn                1414.64
2017-06-10 23:52:23.847288 EDT | MinReturn                 501.861
2017-06-10 23:52:23.847703 EDT | AverageEsReturn           355.174
2017-06-10 23:52:23.848058 EDT | StdEsReturn               338.142
2017-06-10 23:52:23.848479 EDT | MaxEsReturn               975.473
2017-06-10 23:52:23.848896 EDT | MinEsReturn                14.3768
2017-06-10 23:52:23.849304 EDT | AverageDiscountedReturn   220.182
2017-06-10 23:52:23.849815 EDT | AverageQLoss                2.58051
2017-06-10 23:52:23.850165 EDT | AveragePolicySurr         -32.0959
2017-06-10 23:52:23.850581 EDT | AverageQ                   31.7088
2017-06-10 23:52:23.850941 EDT | AverageAbsQ                31.743
2017-06-10 23:52:23.851325 EDT | AverageY                   31.7093
2017-06-10 23:52:23.851738 EDT | AverageAbsY                31.7301
2017-06-10 23:52:23.852149 EDT | AverageAbsQYDiff            0.595561
2017-06-10 23:52:23.852552 EDT | AverageAction               0.966436
2017-06-10 23:52:23.852948 EDT | PolicyRegParamNorm         79.6824
2017-06-10 23:52:23.853296 EDT | QFunRegParamNorm          102.084
2017-06-10 23:52:23.853684 EDT | -----------------------  -----------
2017-06-10 23:52:23.854247 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #602 | Training started
2017-06-10 23:52:39.048276 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #602 | Training finished
2017-06-10 23:52:39.049252 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #602 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 23:52:39.049624 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #602 | Collecting samples for evaluation
2017-06-10 23:52:52.552200 EDT | -----------------------  -----------
2017-06-10 23:52:52.552981 EDT | Epoch                     602
2017-06-10 23:52:52.553161 EDT | Iteration                 602
2017-06-10 23:52:52.553405 EDT | AverageReturn            1176.07
2017-06-10 23:52:52.553561 EDT | StdReturn                 406.474
2017-06-10 23:52:52.553839 EDT | MaxReturn                1935.66
2017-06-10 23:52:52.553999 EDT | MinReturn                 725.396
2017-06-10 23:52:52.554203 EDT | AverageEsReturn           674.351
2017-06-10 23:52:52.554358 EDT | StdEsReturn               351.661
2017-06-10 23:52:52.554541 EDT | MaxEsReturn              1000.37
2017-06-10 23:52:52.554693 EDT | MinEsReturn               186.1
2017-06-10 23:52:52.554842 EDT | AverageDiscountedReturn   248.086
2017-06-10 23:52:52.555050 EDT | AverageQLoss                2.37085
2017-06-10 23:52:52.555264 EDT | AveragePolicySurr         -32.1651
2017-06-10 23:52:52.555441 EDT | AverageQ                   31.7916
2017-06-10 23:52:52.555640 EDT | AverageAbsQ                31.8216
2017-06-10 23:52:52.555792 EDT | AverageY                   31.7925
2017-06-10 23:52:52.556010 EDT | AverageAbsY                31.8107
2017-06-10 23:52:52.556229 EDT | AverageAbsQYDiff            0.596762
2017-06-10 23:52:52.556378 EDT | AverageAction               0.958253
2017-06-10 23:52:52.556534 EDT | PolicyRegParamNorm         79.7243
2017-06-10 23:52:52.556710 EDT | QFunRegParamNorm          102.164
2017-06-10 23:52:52.556965 EDT | -----------------------  -----------
2017-06-10 23:52:52.557277 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #603 | Training started
2017-06-10 23:53:08.131409 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #603 | Training finished
2017-06-10 23:53:08.132367 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #603 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 23:53:08.133518 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #603 | Collecting samples for evaluation
2017-06-10 23:53:20.526901 EDT | -----------------------  -----------
2017-06-10 23:53:20.527619 EDT | Epoch                     603
2017-06-10 23:53:20.527808 EDT | Iteration                 603
2017-06-10 23:53:20.527974 EDT | AverageReturn             976.45
2017-06-10 23:53:20.528135 EDT | StdReturn                 180.703
2017-06-10 23:53:20.528338 EDT | MaxReturn                1316.56
2017-06-10 23:53:20.528548 EDT | MinReturn                 589.077
2017-06-10 23:53:20.528731 EDT | AverageEsReturn           663.354
2017-06-10 23:53:20.528913 EDT | StdEsReturn               293.179
2017-06-10 23:53:20.529090 EDT | MaxEsReturn              1132.34
2017-06-10 23:53:20.529280 EDT | MinEsReturn               232.098
2017-06-10 23:53:20.529461 EDT | AverageDiscountedReturn   227.861
2017-06-10 23:53:20.529643 EDT | AverageQLoss                2.47643
2017-06-10 23:53:20.529865 EDT | AveragePolicySurr         -32.0684
2017-06-10 23:53:20.530068 EDT | AverageQ                   31.6673
2017-06-10 23:53:20.530249 EDT | AverageAbsQ                31.7032
2017-06-10 23:53:20.530428 EDT | AverageY                   31.6676
2017-06-10 23:53:20.530607 EDT | AverageAbsY                31.689
2017-06-10 23:53:20.530983 EDT | AverageAbsQYDiff            0.593742
2017-06-10 23:53:20.531163 EDT | AverageAction               0.954245
2017-06-10 23:53:20.531342 EDT | PolicyRegParamNorm         79.7884
2017-06-10 23:53:20.531529 EDT | QFunRegParamNorm          102.239
2017-06-10 23:53:20.531907 EDT | -----------------------  -----------
2017-06-10 23:53:20.532182 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #604 | Training started
2017-06-10 23:53:36.939348 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #604 | Training finished
2017-06-10 23:53:36.940147 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #604 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 23:53:36.940369 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #604 | Collecting samples for evaluation
2017-06-10 23:53:49.431802 EDT | -----------------------  -----------
2017-06-10 23:53:49.432661 EDT | Epoch                     604
2017-06-10 23:53:49.432922 EDT | Iteration                 604
2017-06-10 23:53:49.433086 EDT | AverageReturn             952.722
2017-06-10 23:53:49.433298 EDT | StdReturn                 323.941
2017-06-10 23:53:49.433537 EDT | MaxReturn                1699.17
2017-06-10 23:53:49.433708 EDT | MinReturn                 602.594
2017-06-10 23:53:49.433869 EDT | AverageEsReturn           300.584
2017-06-10 23:53:49.434020 EDT | StdEsReturn               232.964
2017-06-10 23:53:49.434171 EDT | MaxEsReturn               762.722
2017-06-10 23:53:49.434340 EDT | MinEsReturn                 9.18743
2017-06-10 23:53:49.434522 EDT | AverageDiscountedReturn   234.083
2017-06-10 23:53:49.434674 EDT | AverageQLoss                2.38509
2017-06-10 23:53:49.434824 EDT | AveragePolicySurr         -32.0696
2017-06-10 23:53:49.435112 EDT | AverageQ                   31.7012
2017-06-10 23:53:49.435316 EDT | AverageAbsQ                31.7314
2017-06-10 23:53:49.435475 EDT | AverageY                   31.7033
2017-06-10 23:53:49.435675 EDT | AverageAbsY                31.7196
2017-06-10 23:53:49.435868 EDT | AverageAbsQYDiff            0.596899
2017-06-10 23:53:49.436158 EDT | AverageAction               0.959384
2017-06-10 23:53:49.436402 EDT | PolicyRegParamNorm         79.857
2017-06-10 23:53:49.436555 EDT | QFunRegParamNorm          102.346
2017-06-10 23:53:49.436785 EDT | -----------------------  -----------
2017-06-10 23:53:49.437090 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #605 | Training started
2017-06-10 23:54:05.799489 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #605 | Training finished
2017-06-10 23:54:05.800512 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #605 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 23:54:05.800909 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #605 | Collecting samples for evaluation
2017-06-10 23:54:18.003791 EDT | -----------------------  -----------
2017-06-10 23:54:18.004230 EDT | Epoch                     605
2017-06-10 23:54:18.004557 EDT | Iteration                 605
2017-06-10 23:54:18.004878 EDT | AverageReturn            1050.09
2017-06-10 23:54:18.005192 EDT | StdReturn                 337.829
2017-06-10 23:54:18.005466 EDT | MaxReturn                1761.54
2017-06-10 23:54:18.005793 EDT | MinReturn                 640.19
2017-06-10 23:54:18.006185 EDT | AverageEsReturn           237.211
2017-06-10 23:54:18.006527 EDT | StdEsReturn               269.906
2017-06-10 23:54:18.006858 EDT | MaxEsReturn               714.874
2017-06-10 23:54:18.007182 EDT | MinEsReturn                29.0104
2017-06-10 23:54:18.007501 EDT | AverageDiscountedReturn   234.988
2017-06-10 23:54:18.007767 EDT | AverageQLoss                2.1654
2017-06-10 23:54:18.008047 EDT | AveragePolicySurr         -32.0326
2017-06-10 23:54:18.008372 EDT | AverageQ                   31.6464
2017-06-10 23:54:18.008703 EDT | AverageAbsQ                31.6766
2017-06-10 23:54:18.009015 EDT | AverageY                   31.6469
2017-06-10 23:54:18.009330 EDT | AverageAbsY                31.6622
2017-06-10 23:54:18.009653 EDT | AverageAbsQYDiff            0.577447
2017-06-10 23:54:18.010997 EDT | AverageAction               0.968038
2017-06-10 23:54:18.012922 EDT | PolicyRegParamNorm         79.9769
2017-06-10 23:54:18.013262 EDT | QFunRegParamNorm          102.414
2017-06-10 23:54:18.014119 EDT | -----------------------  -----------
2017-06-10 23:54:18.014620 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #606 | Training started
2017-06-10 23:54:33.140406 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #606 | Training finished
2017-06-10 23:54:33.141465 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #606 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 23:54:33.141773 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #606 | Collecting samples for evaluation
2017-06-10 23:54:46.639111 EDT | -----------------------  -----------
2017-06-10 23:54:46.641545 EDT | Epoch                     606
2017-06-10 23:54:46.641779 EDT | Iteration                 606
2017-06-10 23:54:46.641948 EDT | AverageReturn            1028.67
2017-06-10 23:54:46.642240 EDT | StdReturn                 270.598
2017-06-10 23:54:46.642499 EDT | MaxReturn                1700.32
2017-06-10 23:54:46.642686 EDT | MinReturn                 578.429
2017-06-10 23:54:46.642866 EDT | AverageEsReturn           554.87
2017-06-10 23:54:46.643031 EDT | StdEsReturn               240.168
2017-06-10 23:54:46.643208 EDT | MaxEsReturn               902.593
2017-06-10 23:54:46.643365 EDT | MinEsReturn                99.1849
2017-06-10 23:54:46.643522 EDT | AverageDiscountedReturn   223.875
2017-06-10 23:54:46.643678 EDT | AverageQLoss                2.67914
2017-06-10 23:54:46.643839 EDT | AveragePolicySurr         -32.0776
2017-06-10 23:54:46.644090 EDT | AverageQ                   31.7034
2017-06-10 23:54:46.644339 EDT | AverageAbsQ                31.7326
2017-06-10 23:54:46.644596 EDT | AverageY                   31.7053
2017-06-10 23:54:46.644852 EDT | AverageAbsY                31.7211
2017-06-10 23:54:46.645104 EDT | AverageAbsQYDiff            0.603551
2017-06-10 23:54:46.645952 EDT | AverageAction               0.976901
2017-06-10 23:54:46.646219 EDT | PolicyRegParamNorm         80.028
2017-06-10 23:54:46.646515 EDT | QFunRegParamNorm          102.439
2017-06-10 23:54:46.646782 EDT | -----------------------  -----------
2017-06-10 23:54:46.647236 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #607 | Training started
2017-06-10 23:55:01.433993 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #607 | Training finished
2017-06-10 23:55:01.434755 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #607 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 23:55:01.434944 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #607 | Collecting samples for evaluation
2017-06-10 23:55:13.194490 EDT | -----------------------  -----------
2017-06-10 23:55:13.194768 EDT | Epoch                     607
2017-06-10 23:55:13.194996 EDT | Iteration                 607
2017-06-10 23:55:13.195182 EDT | AverageReturn            1109.65
2017-06-10 23:55:13.195415 EDT | StdReturn                 457.345
2017-06-10 23:55:13.195599 EDT | MaxReturn                2976.55
2017-06-10 23:55:13.195782 EDT | MinReturn                 557.632
2017-06-10 23:55:13.195969 EDT | AverageEsReturn           430.048
2017-06-10 23:55:13.196150 EDT | StdEsReturn               251.664
2017-06-10 23:55:13.196329 EDT | MaxEsReturn               801.547
2017-06-10 23:55:13.196506 EDT | MinEsReturn                51.6192
2017-06-10 23:55:13.196681 EDT | AverageDiscountedReturn   230.83
2017-06-10 23:55:13.196944 EDT | AverageQLoss                2.7909
2017-06-10 23:55:13.197230 EDT | AveragePolicySurr         -31.9419
2017-06-10 23:55:13.197411 EDT | AverageQ                   31.5585
2017-06-10 23:55:13.197612 EDT | AverageAbsQ                31.5884
2017-06-10 23:55:13.197990 EDT | AverageY                   31.5598
2017-06-10 23:55:13.198318 EDT | AverageAbsY                31.5774
2017-06-10 23:55:13.198507 EDT | AverageAbsQYDiff            0.616833
2017-06-10 23:55:13.198690 EDT | AverageAction               0.977174
2017-06-10 23:55:13.198871 EDT | PolicyRegParamNorm         80.0604
2017-06-10 23:55:13.199051 EDT | QFunRegParamNorm          102.532
2017-06-10 23:55:13.199415 EDT | -----------------------  -----------
2017-06-10 23:55:13.199688 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #608 | Training started
2017-06-10 23:55:27.844473 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #608 | Training finished
2017-06-10 23:55:27.845266 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #608 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 23:55:27.845640 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #608 | Collecting samples for evaluation
2017-06-10 23:55:40.507243 EDT | -----------------------  -----------
2017-06-10 23:55:40.508281 EDT | Epoch                     608
2017-06-10 23:55:40.508486 EDT | Iteration                 608
2017-06-10 23:55:40.508671 EDT | AverageReturn            1336.97
2017-06-10 23:55:40.510238 EDT | StdReturn                 449.878
2017-06-10 23:55:40.512386 EDT | MaxReturn                2321.35
2017-06-10 23:55:40.512590 EDT | MinReturn                 646.756
2017-06-10 23:55:40.512756 EDT | AverageEsReturn           213.688
2017-06-10 23:55:40.512917 EDT | StdEsReturn               184.592
2017-06-10 23:55:40.513074 EDT | MaxEsReturn               552.262
2017-06-10 23:55:40.513231 EDT | MinEsReturn                 9.37193
2017-06-10 23:55:40.513386 EDT | AverageDiscountedReturn   231.326
2017-06-10 23:55:40.513600 EDT | AverageQLoss                2.152
2017-06-10 23:55:40.513794 EDT | AveragePolicySurr         -31.9593
2017-06-10 23:55:40.513979 EDT | AverageQ                   31.5819
2017-06-10 23:55:40.514305 EDT | AverageAbsQ                31.6178
2017-06-10 23:55:40.514682 EDT | AverageY                   31.5816
2017-06-10 23:55:40.515055 EDT | AverageAbsY                31.6033
2017-06-10 23:55:40.515242 EDT | AverageAbsQYDiff            0.553422
2017-06-10 23:55:40.515428 EDT | AverageAction               0.980601
2017-06-10 23:55:40.515610 EDT | PolicyRegParamNorm         80.1128
2017-06-10 23:55:40.515825 EDT | QFunRegParamNorm          102.613
2017-06-10 23:55:40.516004 EDT | -----------------------  -----------
2017-06-10 23:55:40.516282 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #609 | Training started
2017-06-10 23:55:56.298367 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #609 | Training finished
2017-06-10 23:55:56.313816 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #609 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 23:55:56.314437 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #609 | Collecting samples for evaluation
2017-06-10 23:56:09.730709 EDT | -----------------------  -----------
2017-06-10 23:56:09.731703 EDT | Epoch                     609
2017-06-10 23:56:09.731919 EDT | Iteration                 609
2017-06-10 23:56:09.732112 EDT | AverageReturn            1085.63
2017-06-10 23:56:09.734304 EDT | StdReturn                 280.387
2017-06-10 23:56:09.734553 EDT | MaxReturn                1929.24
2017-06-10 23:56:09.734923 EDT | MinReturn                 882.08
2017-06-10 23:56:09.735152 EDT | AverageEsReturn           293.975
2017-06-10 23:56:09.735348 EDT | StdEsReturn               277.666
2017-06-10 23:56:09.735704 EDT | MaxEsReturn               745.659
2017-06-10 23:56:09.736252 EDT | MinEsReturn                44.7607
2017-06-10 23:56:09.736439 EDT | AverageDiscountedReturn   235.096
2017-06-10 23:56:09.736790 EDT | AverageQLoss                2.44706
2017-06-10 23:56:09.736999 EDT | AveragePolicySurr         -32.0524
2017-06-10 23:56:09.737300 EDT | AverageQ                   31.6734
2017-06-10 23:56:09.737494 EDT | AverageAbsQ                31.7066
2017-06-10 23:56:09.737681 EDT | AverageY                   31.6751
2017-06-10 23:56:09.738163 EDT | AverageAbsY                31.6967
2017-06-10 23:56:09.738393 EDT | AverageAbsQYDiff            0.579861
2017-06-10 23:56:09.738766 EDT | AverageAction               0.978405
2017-06-10 23:56:09.738944 EDT | PolicyRegParamNorm         80.1457
2017-06-10 23:56:09.739214 EDT | QFunRegParamNorm          102.728
2017-06-10 23:56:09.740198 EDT | -----------------------  -----------
2017-06-10 23:56:09.740517 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #610 | Training started
2017-06-10 23:56:25.074890 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #610 | Training finished
2017-06-10 23:56:25.075784 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #610 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 23:56:25.075997 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #610 | Collecting samples for evaluation
2017-06-10 23:56:38.321392 EDT | -----------------------  -----------
2017-06-10 23:56:38.322474 EDT | Epoch                     610
2017-06-10 23:56:38.322938 EDT | Iteration                 610
2017-06-10 23:56:38.323411 EDT | AverageReturn             488.35
2017-06-10 23:56:38.323858 EDT | StdReturn                 181.911
2017-06-10 23:56:38.324213 EDT | MaxReturn                1148.71
2017-06-10 23:56:38.324655 EDT | MinReturn                 364.462
2017-06-10 23:56:38.325098 EDT | AverageEsReturn           330.736
2017-06-10 23:56:38.325563 EDT | StdEsReturn               169.945
2017-06-10 23:56:38.325931 EDT | MaxEsReturn               654.173
2017-06-10 23:56:38.326297 EDT | MinEsReturn               156.373
2017-06-10 23:56:38.326654 EDT | AverageDiscountedReturn   188.021
2017-06-10 23:56:38.327010 EDT | AverageQLoss                2.33897
2017-06-10 23:56:38.327353 EDT | AveragePolicySurr         -32.0567
2017-06-10 23:56:38.327691 EDT | AverageQ                   31.6902
2017-06-10 23:56:38.328128 EDT | AverageAbsQ                31.7219
2017-06-10 23:56:38.328479 EDT | AverageY                   31.6924
2017-06-10 23:56:38.328917 EDT | AverageAbsY                31.7079
2017-06-10 23:56:38.329271 EDT | AverageAbsQYDiff            0.575965
2017-06-10 23:56:38.329610 EDT | AverageAction               0.981108
2017-06-10 23:56:38.329978 EDT | PolicyRegParamNorm         80.1484
2017-06-10 23:56:38.330319 EDT | QFunRegParamNorm          102.75
2017-06-10 23:56:38.330678 EDT | -----------------------  -----------
2017-06-10 23:56:38.331195 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #611 | Training started
2017-06-10 23:56:53.968824 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #611 | Training finished
2017-06-10 23:56:53.969252 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #611 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 23:56:53.969614 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #611 | Collecting samples for evaluation
2017-06-10 23:57:06.915597 EDT | -----------------------  -----------
2017-06-10 23:57:06.916689 EDT | Epoch                     611
2017-06-10 23:57:06.918107 EDT | Iteration                 611
2017-06-10 23:57:06.918795 EDT | AverageReturn             983.434
2017-06-10 23:57:06.919243 EDT | StdReturn                 294.406
2017-06-10 23:57:06.919686 EDT | MaxReturn                1454.05
2017-06-10 23:57:06.920127 EDT | MinReturn                 102.094
2017-06-10 23:57:06.920777 EDT | AverageEsReturn           204.582
2017-06-10 23:57:06.921137 EDT | StdEsReturn               137.099
2017-06-10 23:57:06.921564 EDT | MaxEsReturn               484.407
2017-06-10 23:57:06.921915 EDT | MinEsReturn                29.4852
2017-06-10 23:57:06.922273 EDT | AverageDiscountedReturn   227.971
2017-06-10 23:57:06.922612 EDT | AverageQLoss                2.80955
2017-06-10 23:57:06.922974 EDT | AveragePolicySurr         -31.9371
2017-06-10 23:57:06.923432 EDT | AverageQ                   31.5587
2017-06-10 23:57:06.923936 EDT | AverageAbsQ                31.589
2017-06-10 23:57:06.924277 EDT | AverageY                   31.5587
2017-06-10 23:57:06.924620 EDT | AverageAbsY                31.5781
2017-06-10 23:57:06.924956 EDT | AverageAbsQYDiff            0.601366
2017-06-10 23:57:06.925292 EDT | AverageAction               0.976091
2017-06-10 23:57:06.925631 EDT | PolicyRegParamNorm         80.1901
2017-06-10 23:57:06.927218 EDT | QFunRegParamNorm          102.812
2017-06-10 23:57:06.927581 EDT | -----------------------  -----------
2017-06-10 23:57:06.928102 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #612 | Training started
2017-06-10 23:57:22.939073 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #612 | Training finished
2017-06-10 23:57:22.939517 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #612 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 23:57:22.939873 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #612 | Collecting samples for evaluation
2017-06-10 23:57:36.519787 EDT | -----------------------  -----------
2017-06-10 23:57:36.520656 EDT | Epoch                     612
2017-06-10 23:57:36.520858 EDT | Iteration                 612
2017-06-10 23:57:36.521020 EDT | AverageReturn             719.078
2017-06-10 23:57:36.521177 EDT | StdReturn                 290.809
2017-06-10 23:57:36.521332 EDT | MaxReturn                1527.63
2017-06-10 23:57:36.521483 EDT | MinReturn                 205.043
2017-06-10 23:57:36.521731 EDT | AverageEsReturn           265.549
2017-06-10 23:57:36.523462 EDT | StdEsReturn               193.277
2017-06-10 23:57:36.523728 EDT | MaxEsReturn               595.142
2017-06-10 23:57:36.524366 EDT | MinEsReturn                35.2833
2017-06-10 23:57:36.524521 EDT | AverageDiscountedReturn   210.515
2017-06-10 23:57:36.525183 EDT | AverageQLoss                2.23296
2017-06-10 23:57:36.525507 EDT | AveragePolicySurr         -31.9479
2017-06-10 23:57:36.525833 EDT | AverageQ                   31.5963
2017-06-10 23:57:36.525990 EDT | AverageAbsQ                31.6304
2017-06-10 23:57:36.526142 EDT | AverageY                   31.5982
2017-06-10 23:57:36.526293 EDT | AverageAbsY                31.6207
2017-06-10 23:57:36.526442 EDT | AverageAbsQYDiff            0.564145
2017-06-10 23:57:36.526591 EDT | AverageAction               0.984473
2017-06-10 23:57:36.526741 EDT | PolicyRegParamNorm         80.3015
2017-06-10 23:57:36.526890 EDT | QFunRegParamNorm          102.879
2017-06-10 23:57:36.527038 EDT | -----------------------  -----------
2017-06-10 23:57:36.527274 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #613 | Training started
2017-06-10 23:57:53.104489 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #613 | Training finished
2017-06-10 23:57:53.105008 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #613 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 23:57:53.105392 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #613 | Collecting samples for evaluation
2017-06-10 23:58:06.482109 EDT | -----------------------  -----------
2017-06-10 23:58:06.482990 EDT | Epoch                     613
2017-06-10 23:58:06.483267 EDT | Iteration                 613
2017-06-10 23:58:06.483533 EDT | AverageReturn             575.187
2017-06-10 23:58:06.483793 EDT | StdReturn                 212.804
2017-06-10 23:58:06.484246 EDT | MaxReturn                1121.36
2017-06-10 23:58:06.484505 EDT | MinReturn                 177.016
2017-06-10 23:58:06.484880 EDT | AverageEsReturn           244.802
2017-06-10 23:58:06.485140 EDT | StdEsReturn               177.349
2017-06-10 23:58:06.485397 EDT | MaxEsReturn               541.894
2017-06-10 23:58:06.485760 EDT | MinEsReturn                23.3496
2017-06-10 23:58:06.486022 EDT | AverageDiscountedReturn   196.804
2017-06-10 23:58:06.486278 EDT | AverageQLoss                2.82189
2017-06-10 23:58:06.486534 EDT | AveragePolicySurr         -31.8676
2017-06-10 23:58:06.487019 EDT | AverageQ                   31.5142
2017-06-10 23:58:06.487277 EDT | AverageAbsQ                31.5521
2017-06-10 23:58:06.487666 EDT | AverageY                   31.514
2017-06-10 23:58:06.487926 EDT | AverageAbsY                31.539
2017-06-10 23:58:06.488182 EDT | AverageAbsQYDiff            0.597168
2017-06-10 23:58:06.488537 EDT | AverageAction               0.98404
2017-06-10 23:58:06.488794 EDT | PolicyRegParamNorm         80.3716
2017-06-10 23:58:06.489050 EDT | QFunRegParamNorm          102.982
2017-06-10 23:58:06.489502 EDT | -----------------------  -----------
2017-06-10 23:58:06.489920 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #614 | Training started
2017-06-10 23:58:22.183468 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #614 | Training finished
2017-06-10 23:58:22.183769 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #614 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 23:58:22.183987 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #614 | Collecting samples for evaluation
2017-06-10 23:58:34.456164 EDT | -----------------------  ----------
2017-06-10 23:58:34.457007 EDT | Epoch                    614
2017-06-10 23:58:34.457277 EDT | Iteration                614
2017-06-10 23:58:34.457526 EDT | AverageReturn            433.513
2017-06-10 23:58:34.457873 EDT | StdReturn                165.052
2017-06-10 23:58:34.458207 EDT | MaxReturn                891.351
2017-06-10 23:58:34.458536 EDT | MinReturn                195.119
2017-06-10 23:58:34.458860 EDT | AverageEsReturn          351.66
2017-06-10 23:58:34.459183 EDT | StdEsReturn              196.154
2017-06-10 23:58:34.459510 EDT | MaxEsReturn              679.163
2017-06-10 23:58:34.459831 EDT | MinEsReturn              113.477
2017-06-10 23:58:34.460155 EDT | AverageDiscountedReturn  179.072
2017-06-10 23:58:34.460482 EDT | AverageQLoss               2.47156
2017-06-10 23:58:34.460804 EDT | AveragePolicySurr        -31.8606
2017-06-10 23:58:34.461125 EDT | AverageQ                  31.5105
2017-06-10 23:58:34.461451 EDT | AverageAbsQ               31.5506
2017-06-10 23:58:34.461779 EDT | AverageY                  31.5106
2017-06-10 23:58:34.462124 EDT | AverageAbsY               31.5364
2017-06-10 23:58:34.462478 EDT | AverageAbsQYDiff           0.571193
2017-06-10 23:58:34.462868 EDT | AverageAction              0.984831
2017-06-10 23:58:34.463269 EDT | PolicyRegParamNorm        80.4214
2017-06-10 23:58:34.463642 EDT | QFunRegParamNorm         103.041
2017-06-10 23:58:34.463993 EDT | -----------------------  ----------
2017-06-10 23:58:34.464557 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #615 | Training started
2017-06-10 23:58:50.026958 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #615 | Training finished
2017-06-10 23:58:50.027977 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #615 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 23:58:50.028244 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #615 | Collecting samples for evaluation
2017-06-10 23:59:02.572769 EDT | -----------------------  ----------
2017-06-10 23:59:02.573612 EDT | Epoch                    615
2017-06-10 23:59:02.573890 EDT | Iteration                615
2017-06-10 23:59:02.574139 EDT | AverageReturn            367.196
2017-06-10 23:59:02.574725 EDT | StdReturn                139.331
2017-06-10 23:59:02.575726 EDT | MaxReturn                733.22
2017-06-10 23:59:02.575978 EDT | MinReturn                190.517
2017-06-10 23:59:02.576222 EDT | AverageEsReturn          512.076
2017-06-10 23:59:02.576465 EDT | StdEsReturn              234.034
2017-06-10 23:59:02.576707 EDT | MaxEsReturn              846.911
2017-06-10 23:59:02.576948 EDT | MinEsReturn              189.305
2017-06-10 23:59:02.577188 EDT | AverageDiscountedReturn  164.191
2017-06-10 23:59:02.577428 EDT | AverageQLoss               2.35163
2017-06-10 23:59:02.577668 EDT | AveragePolicySurr        -31.8226
2017-06-10 23:59:02.577919 EDT | AverageQ                  31.426
2017-06-10 23:59:02.578159 EDT | AverageAbsQ               31.467
2017-06-10 23:59:02.578398 EDT | AverageY                  31.428
2017-06-10 23:59:02.578637 EDT | AverageAbsY               31.4554
2017-06-10 23:59:02.578876 EDT | AverageAbsQYDiff           0.576015
2017-06-10 23:59:02.579119 EDT | AverageAction              0.983891
2017-06-10 23:59:02.579359 EDT | PolicyRegParamNorm        80.4458
2017-06-10 23:59:02.579597 EDT | QFunRegParamNorm         103.186
2017-06-10 23:59:02.579836 EDT | -----------------------  ----------
2017-06-10 23:59:02.580227 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #616 | Training started
2017-06-10 23:59:15.822212 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #616 | Training finished
2017-06-10 23:59:15.822970 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #616 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 23:59:15.823164 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #616 | Collecting samples for evaluation
2017-06-10 23:59:29.094702 EDT | -----------------------  -----------
2017-06-10 23:59:29.095517 EDT | Epoch                     616
2017-06-10 23:59:29.095777 EDT | Iteration                 616
2017-06-10 23:59:29.095949 EDT | AverageReturn             917.479
2017-06-10 23:59:29.096110 EDT | StdReturn                 181.619
2017-06-10 23:59:29.096268 EDT | MaxReturn                1437.58
2017-06-10 23:59:29.096466 EDT | MinReturn                 635.118
2017-06-10 23:59:29.096647 EDT | AverageEsReturn           209.084
2017-06-10 23:59:29.096810 EDT | StdEsReturn               180.86
2017-06-10 23:59:29.097179 EDT | MaxEsReturn               644.274
2017-06-10 23:59:29.097557 EDT | MinEsReturn                 7.53184
2017-06-10 23:59:29.097823 EDT | AverageDiscountedReturn   223.03
2017-06-10 23:59:29.098020 EDT | AverageQLoss                2.21228
2017-06-10 23:59:29.098203 EDT | AveragePolicySurr         -31.8698
2017-06-10 23:59:29.098427 EDT | AverageQ                   31.4832
2017-06-10 23:59:29.098608 EDT | AverageAbsQ                31.5156
2017-06-10 23:59:29.098788 EDT | AverageY                   31.4854
2017-06-10 23:59:29.098963 EDT | AverageAbsY                31.5038
2017-06-10 23:59:29.099161 EDT | AverageAbsQYDiff            0.562682
2017-06-10 23:59:29.099905 EDT | AverageAction               0.979397
2017-06-10 23:59:29.100094 EDT | PolicyRegParamNorm         80.5009
2017-06-10 23:59:29.100742 EDT | QFunRegParamNorm          103.238
2017-06-10 23:59:29.100922 EDT | -----------------------  -----------
2017-06-10 23:59:29.101218 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #617 | Training started
2017-06-10 23:59:45.429888 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #617 | Training finished
2017-06-10 23:59:45.430820 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #617 | Trained qf 1000 steps, policy 1000 steps
2017-06-10 23:59:45.431126 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #617 | Collecting samples for evaluation
2017-06-10 23:59:57.442585 EDT | -----------------------  -----------
2017-06-10 23:59:57.443335 EDT | Epoch                     617
2017-06-10 23:59:57.443610 EDT | Iteration                 617
2017-06-10 23:59:57.443815 EDT | AverageReturn            1077.15
2017-06-10 23:59:57.444182 EDT | StdReturn                 294.115
2017-06-10 23:59:57.444537 EDT | MaxReturn                1838.35
2017-06-10 23:59:57.444860 EDT | MinReturn                 606.07
2017-06-10 23:59:57.445198 EDT | AverageEsReturn           246.384
2017-06-10 23:59:57.445519 EDT | StdEsReturn               247.768
2017-06-10 23:59:57.445878 EDT | MaxEsReturn               710.923
2017-06-10 23:59:57.446178 EDT | MinEsReturn                 8.05862
2017-06-10 23:59:57.446719 EDT | AverageDiscountedReturn   230.625
2017-06-10 23:59:57.447106 EDT | AverageQLoss                2.78142
2017-06-10 23:59:57.448447 EDT | AveragePolicySurr         -31.7568
2017-06-10 23:59:57.448955 EDT | AverageQ                   31.3618
2017-06-10 23:59:57.449338 EDT | AverageAbsQ                31.3882
2017-06-10 23:59:57.449871 EDT | AverageY                   31.3637
2017-06-10 23:59:57.450242 EDT | AverageAbsY                31.375
2017-06-10 23:59:57.450627 EDT | AverageAbsQYDiff            0.602123
2017-06-10 23:59:57.450900 EDT | AverageAction               0.982364
2017-06-10 23:59:57.451272 EDT | PolicyRegParamNorm         80.5835
2017-06-10 23:59:57.451710 EDT | QFunRegParamNorm          103.348
2017-06-10 23:59:57.452372 EDT | -----------------------  -----------
2017-06-10 23:59:57.452932 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #618 | Training started
2017-06-11 00:00:14.362655 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #618 | Training finished
2017-06-11 00:00:14.363841 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #618 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 00:00:14.364867 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #618 | Collecting samples for evaluation
2017-06-11 00:00:27.081938 EDT | -----------------------  -----------
2017-06-11 00:00:27.083052 EDT | Epoch                     618
2017-06-11 00:00:27.083523 EDT | Iteration                 618
2017-06-11 00:00:27.083976 EDT | AverageReturn            1152.89
2017-06-11 00:00:27.084421 EDT | StdReturn                 224.066
2017-06-11 00:00:27.084801 EDT | MaxReturn                1826.87
2017-06-11 00:00:27.085245 EDT | MinReturn                 628.91
2017-06-11 00:00:27.085659 EDT | AverageEsReturn           227.31
2017-06-11 00:00:27.086075 EDT | StdEsReturn               236.839
2017-06-11 00:00:27.086516 EDT | MaxEsReturn               707.395
2017-06-11 00:00:27.086912 EDT | MinEsReturn                21.973
2017-06-11 00:00:27.087284 EDT | AverageDiscountedReturn   238.802
2017-06-11 00:00:27.087641 EDT | AverageQLoss                2.56407
2017-06-11 00:00:27.087971 EDT | AveragePolicySurr         -31.8178
2017-06-11 00:00:27.088295 EDT | AverageQ                   31.4315
2017-06-11 00:00:27.089787 EDT | AverageAbsQ                31.463
2017-06-11 00:00:27.090153 EDT | AverageY                   31.4324
2017-06-11 00:00:27.090522 EDT | AverageAbsY                31.4503
2017-06-11 00:00:27.090909 EDT | AverageAbsQYDiff            0.576067
2017-06-11 00:00:27.093805 EDT | AverageAction               0.979501
2017-06-11 00:00:27.094273 EDT | PolicyRegParamNorm         80.6154
2017-06-11 00:00:27.094728 EDT | QFunRegParamNorm          103.377
2017-06-11 00:00:27.095180 EDT | -----------------------  -----------
2017-06-11 00:00:27.095826 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #619 | Training started
2017-06-11 00:00:42.530320 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #619 | Training finished
2017-06-11 00:00:42.531414 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #619 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 00:00:42.531728 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #619 | Collecting samples for evaluation
2017-06-11 00:00:55.649357 EDT | -----------------------  -----------
2017-06-11 00:00:55.650070 EDT | Epoch                     619
2017-06-11 00:00:55.650399 EDT | Iteration                 619
2017-06-11 00:00:55.650885 EDT | AverageReturn            1239.6
2017-06-11 00:00:55.651280 EDT | StdReturn                 357.659
2017-06-11 00:00:55.651626 EDT | MaxReturn                2525.82
2017-06-11 00:00:55.651953 EDT | MinReturn                 715.388
2017-06-11 00:00:55.652274 EDT | AverageEsReturn           307.83
2017-06-11 00:00:55.652599 EDT | StdEsReturn               261.097
2017-06-11 00:00:55.652995 EDT | MaxEsReturn               947.201
2017-06-11 00:00:55.653404 EDT | MinEsReturn                36.848
2017-06-11 00:00:55.653804 EDT | AverageDiscountedReturn   245.684
2017-06-11 00:00:55.654174 EDT | AverageQLoss                2.42439
2017-06-11 00:00:55.655580 EDT | AveragePolicySurr         -31.8605
2017-06-11 00:00:55.656172 EDT | AverageQ                   31.5135
2017-06-11 00:00:55.656469 EDT | AverageAbsQ                31.5427
2017-06-11 00:00:55.656700 EDT | AverageY                   31.5158
2017-06-11 00:00:55.657079 EDT | AverageAbsY                31.5324
2017-06-11 00:00:55.657325 EDT | AverageAbsQYDiff            0.57337
2017-06-11 00:00:55.658627 EDT | AverageAction               0.973299
2017-06-11 00:00:55.658900 EDT | PolicyRegParamNorm         80.6687
2017-06-11 00:00:55.659066 EDT | QFunRegParamNorm          103.431
2017-06-11 00:00:55.659321 EDT | -----------------------  -----------
2017-06-11 00:00:55.659608 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #620 | Training started
2017-06-11 00:01:11.595944 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #620 | Training finished
2017-06-11 00:01:11.729890 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #620 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 00:01:11.731909 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #620 | Collecting samples for evaluation
2017-06-11 00:01:24.566332 EDT | -----------------------  -----------
2017-06-11 00:01:24.567092 EDT | Epoch                     620
2017-06-11 00:01:24.567270 EDT | Iteration                 620
2017-06-11 00:01:24.567427 EDT | AverageReturn            1154.44
2017-06-11 00:01:24.567671 EDT | StdReturn                 445.05
2017-06-11 00:01:24.567841 EDT | MaxReturn                2701.85
2017-06-11 00:01:24.568157 EDT | MinReturn                 406.261
2017-06-11 00:01:24.568463 EDT | AverageEsReturn           209.513
2017-06-11 00:01:24.568727 EDT | StdEsReturn               183.694
2017-06-11 00:01:24.568950 EDT | MaxEsReturn               525.955
2017-06-11 00:01:24.569177 EDT | MinEsReturn                17.068
2017-06-11 00:01:24.569344 EDT | AverageDiscountedReturn   241.069
2017-06-11 00:01:24.569501 EDT | AverageQLoss                2.45307
2017-06-11 00:01:24.569683 EDT | AveragePolicySurr         -31.773
2017-06-11 00:01:24.570095 EDT | AverageQ                   31.3747
2017-06-11 00:01:24.570760 EDT | AverageAbsQ                31.4059
2017-06-11 00:01:24.571146 EDT | AverageY                   31.3738
2017-06-11 00:01:24.571542 EDT | AverageAbsY                31.3941
2017-06-11 00:01:24.571820 EDT | AverageAbsQYDiff            0.595144
2017-06-11 00:01:24.572059 EDT | AverageAction               0.982403
2017-06-11 00:01:24.572221 EDT | PolicyRegParamNorm         80.6557
2017-06-11 00:01:24.572520 EDT | QFunRegParamNorm          103.462
2017-06-11 00:01:24.572866 EDT | -----------------------  -----------
2017-06-11 00:01:24.573766 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #621 | Training started
2017-06-11 00:01:39.286409 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #621 | Training finished
2017-06-11 00:01:39.287458 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #621 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 00:01:39.287846 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #621 | Collecting samples for evaluation
2017-06-11 00:01:52.178102 EDT | -----------------------  -----------
2017-06-11 00:01:52.179137 EDT | Epoch                     621
2017-06-11 00:01:52.179390 EDT | Iteration                 621
2017-06-11 00:01:52.179579 EDT | AverageReturn            1500.33
2017-06-11 00:01:52.179762 EDT | StdReturn                1061.95
2017-06-11 00:01:52.179943 EDT | MaxReturn                3243.72
2017-06-11 00:01:52.180285 EDT | MinReturn                 346.25
2017-06-11 00:01:52.180517 EDT | AverageEsReturn           342.691
2017-06-11 00:01:52.180699 EDT | StdEsReturn               208.451
2017-06-11 00:01:52.180879 EDT | MaxEsReturn               689.959
2017-06-11 00:01:52.181058 EDT | MinEsReturn                70.3781
2017-06-11 00:01:52.181236 EDT | AverageDiscountedReturn   220.134
2017-06-11 00:01:52.181412 EDT | AverageQLoss                2.52278
2017-06-11 00:01:52.183223 EDT | AveragePolicySurr         -31.7732
2017-06-11 00:01:52.183439 EDT | AverageQ                   31.382
2017-06-11 00:01:52.183624 EDT | AverageAbsQ                31.4076
2017-06-11 00:01:52.183806 EDT | AverageY                   31.3836
2017-06-11 00:01:52.183985 EDT | AverageAbsY                31.3955
2017-06-11 00:01:52.184163 EDT | AverageAbsQYDiff            0.580766
2017-06-11 00:01:52.184344 EDT | AverageAction               0.976653
2017-06-11 00:01:52.184522 EDT | PolicyRegParamNorm         80.6733
2017-06-11 00:01:52.184699 EDT | QFunRegParamNorm          103.507
2017-06-11 00:01:52.184876 EDT | -----------------------  -----------
2017-06-11 00:01:52.185179 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #622 | Training started
2017-06-11 00:02:07.986204 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #622 | Training finished
2017-06-11 00:02:07.987118 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #622 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 00:02:07.987496 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #622 | Collecting samples for evaluation
2017-06-11 00:02:20.155527 EDT | -----------------------  -----------
2017-06-11 00:02:20.155879 EDT | Epoch                     622
2017-06-11 00:02:20.156132 EDT | Iteration                 622
2017-06-11 00:02:20.156331 EDT | AverageReturn            1440.64
2017-06-11 00:02:20.156528 EDT | StdReturn                 556.672
2017-06-11 00:02:20.156727 EDT | MaxReturn                2913.91
2017-06-11 00:02:20.156919 EDT | MinReturn                 672.396
2017-06-11 00:02:20.157127 EDT | AverageEsReturn           319.083
2017-06-11 00:02:20.157559 EDT | StdEsReturn               309.126
2017-06-11 00:02:20.157985 EDT | MaxEsReturn               945.584
2017-06-11 00:02:20.158443 EDT | MinEsReturn                24.9586
2017-06-11 00:02:20.158871 EDT | AverageDiscountedReturn   243.606
2017-06-11 00:02:20.159367 EDT | AverageQLoss                2.56147
2017-06-11 00:02:20.159774 EDT | AveragePolicySurr         -31.7945
2017-06-11 00:02:20.160226 EDT | AverageQ                   31.4
2017-06-11 00:02:20.160673 EDT | AverageAbsQ                31.427
2017-06-11 00:02:20.161117 EDT | AverageY                   31.4006
2017-06-11 00:02:20.161466 EDT | AverageAbsY                31.4153
2017-06-11 00:02:20.161908 EDT | AverageAbsQYDiff            0.58298
2017-06-11 00:02:20.162360 EDT | AverageAction               0.966708
2017-06-11 00:02:20.162742 EDT | PolicyRegParamNorm         80.7496
2017-06-11 00:02:20.163201 EDT | QFunRegParamNorm          103.548
2017-06-11 00:02:20.163650 EDT | -----------------------  -----------
2017-06-11 00:02:20.164263 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #623 | Training started
2017-06-11 00:02:36.109079 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #623 | Training finished
2017-06-11 00:02:36.125811 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #623 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 00:02:36.126457 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #623 | Collecting samples for evaluation
2017-06-11 00:02:50.647939 EDT | -----------------------  -----------
2017-06-11 00:02:50.648904 EDT | Epoch                     623
2017-06-11 00:02:50.649152 EDT | Iteration                 623
2017-06-11 00:02:50.649350 EDT | AverageReturn            1212.26
2017-06-11 00:02:50.649538 EDT | StdReturn                 759.073
2017-06-11 00:02:50.649737 EDT | MaxReturn                3544.19
2017-06-11 00:02:50.649921 EDT | MinReturn                 684.715
2017-06-11 00:02:50.650166 EDT | AverageEsReturn           277.836
2017-06-11 00:02:50.650357 EDT | StdEsReturn               212.701
2017-06-11 00:02:50.650539 EDT | MaxEsReturn               725.782
2017-06-11 00:02:50.650720 EDT | MinEsReturn                48.0306
2017-06-11 00:02:50.650927 EDT | AverageDiscountedReturn   247.846
2017-06-11 00:02:50.651155 EDT | AverageQLoss                2.5502
2017-06-11 00:02:50.651338 EDT | AveragePolicySurr         -31.7412
2017-06-11 00:02:50.651563 EDT | AverageQ                   31.3829
2017-06-11 00:02:50.651745 EDT | AverageAbsQ                31.4122
2017-06-11 00:02:50.652528 EDT | AverageY                   31.3856
2017-06-11 00:02:50.652933 EDT | AverageAbsY                31.3965
2017-06-11 00:02:50.653143 EDT | AverageAbsQYDiff            0.586963
2017-06-11 00:02:50.653327 EDT | AverageAction               0.977858
2017-06-11 00:02:50.653568 EDT | PolicyRegParamNorm         80.8531
2017-06-11 00:02:50.653814 EDT | QFunRegParamNorm          103.629
2017-06-11 00:02:50.653998 EDT | -----------------------  -----------
2017-06-11 00:02:50.654325 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #624 | Training started
2017-06-11 00:03:05.891500 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #624 | Training finished
2017-06-11 00:03:05.892402 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #624 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 00:03:05.892716 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #624 | Collecting samples for evaluation
2017-06-11 00:03:18.447917 EDT | -----------------------  -----------
2017-06-11 00:03:18.448370 EDT | Epoch                     624
2017-06-11 00:03:18.448726 EDT | Iteration                 624
2017-06-11 00:03:18.449076 EDT | AverageReturn            1749.76
2017-06-11 00:03:18.449422 EDT | StdReturn                1030.36
2017-06-11 00:03:18.450378 EDT | MaxReturn                3561.8
2017-06-11 00:03:18.450744 EDT | MinReturn                 681.197
2017-06-11 00:03:18.451091 EDT | AverageEsReturn           465.677
2017-06-11 00:03:18.451434 EDT | StdEsReturn               225.685
2017-06-11 00:03:18.451783 EDT | MaxEsReturn               783.113
2017-06-11 00:03:18.452128 EDT | MinEsReturn               188.942
2017-06-11 00:03:18.452473 EDT | AverageDiscountedReturn   251.443
2017-06-11 00:03:18.452817 EDT | AverageQLoss                2.54923
2017-06-11 00:03:18.453164 EDT | AveragePolicySurr         -31.7275
2017-06-11 00:03:18.453512 EDT | AverageQ                   31.365
2017-06-11 00:03:18.453866 EDT | AverageAbsQ                31.3893
2017-06-11 00:03:18.454212 EDT | AverageY                   31.3649
2017-06-11 00:03:18.454555 EDT | AverageAbsY                31.3763
2017-06-11 00:03:18.454900 EDT | AverageAbsQYDiff            0.573997
2017-06-11 00:03:18.455244 EDT | AverageAction               0.963257
2017-06-11 00:03:18.455587 EDT | PolicyRegParamNorm         80.905
2017-06-11 00:03:18.455929 EDT | QFunRegParamNorm          103.751
2017-06-11 00:03:18.456273 EDT | -----------------------  -----------
2017-06-11 00:03:18.456754 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #625 | Training started
2017-06-11 00:03:34.235275 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #625 | Training finished
2017-06-11 00:03:34.236340 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #625 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 00:03:34.236753 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #625 | Collecting samples for evaluation
2017-06-11 00:03:47.144068 EDT | -----------------------  -----------
2017-06-11 00:03:47.145179 EDT | Epoch                     625
2017-06-11 00:03:47.145643 EDT | Iteration                 625
2017-06-11 00:03:47.146100 EDT | AverageReturn            1038.3
2017-06-11 00:03:47.146546 EDT | StdReturn                 355.606
2017-06-11 00:03:47.146991 EDT | MaxReturn                1928.79
2017-06-11 00:03:47.147431 EDT | MinReturn                 609.31
2017-06-11 00:03:47.147871 EDT | AverageEsReturn           266.422
2017-06-11 00:03:47.148311 EDT | StdEsReturn               276.565
2017-06-11 00:03:47.148753 EDT | MaxEsReturn               631.387
2017-06-11 00:03:47.149193 EDT | MinEsReturn                 6.76758
2017-06-11 00:03:47.149631 EDT | AverageDiscountedReturn   228.288
2017-06-11 00:03:47.150084 EDT | AverageQLoss                1.90518
2017-06-11 00:03:47.150523 EDT | AveragePolicySurr         -31.6818
2017-06-11 00:03:47.150959 EDT | AverageQ                   31.3103
2017-06-11 00:03:47.151397 EDT | AverageAbsQ                31.3366
2017-06-11 00:03:47.151835 EDT | AverageY                   31.3116
2017-06-11 00:03:47.152272 EDT | AverageAbsY                31.3263
2017-06-11 00:03:47.152708 EDT | AverageAbsQYDiff            0.533698
2017-06-11 00:03:47.153143 EDT | AverageAction               0.971131
2017-06-11 00:03:47.153580 EDT | PolicyRegParamNorm         80.9112
2017-06-11 00:03:47.154029 EDT | QFunRegParamNorm          103.759
2017-06-11 00:03:47.154465 EDT | -----------------------  -----------
2017-06-11 00:03:47.155082 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #626 | Training started
2017-06-11 00:04:03.236160 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #626 | Training finished
2017-06-11 00:04:03.237073 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #626 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 00:04:03.237370 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #626 | Collecting samples for evaluation
2017-06-11 00:04:15.415634 EDT | -----------------------  -----------
2017-06-11 00:04:15.416736 EDT | Epoch                     626
2017-06-11 00:04:15.418801 EDT | Iteration                 626
2017-06-11 00:04:15.420022 EDT | AverageReturn            1106.08
2017-06-11 00:04:15.420899 EDT | StdReturn                 453.614
2017-06-11 00:04:15.421262 EDT | MaxReturn                2639.62
2017-06-11 00:04:15.421608 EDT | MinReturn                 608.016
2017-06-11 00:04:15.421976 EDT | AverageEsReturn           285.049
2017-06-11 00:04:15.422321 EDT | StdEsReturn               226.982
2017-06-11 00:04:15.422663 EDT | MaxEsReturn               751.416
2017-06-11 00:04:15.423005 EDT | MinEsReturn                 9.98259
2017-06-11 00:04:15.423350 EDT | AverageDiscountedReturn   233.24
2017-06-11 00:04:15.423692 EDT | AverageQLoss                2.66584
2017-06-11 00:04:15.424033 EDT | AveragePolicySurr         -31.6524
2017-06-11 00:04:15.424505 EDT | AverageQ                   31.2794
2017-06-11 00:04:15.424850 EDT | AverageAbsQ                31.3084
2017-06-11 00:04:15.425191 EDT | AverageY                   31.2798
2017-06-11 00:04:15.425531 EDT | AverageAbsY                31.296
2017-06-11 00:04:15.425896 EDT | AverageAbsQYDiff            0.592785
2017-06-11 00:04:15.426240 EDT | AverageAction               0.97559
2017-06-11 00:04:15.426584 EDT | PolicyRegParamNorm         80.9434
2017-06-11 00:04:15.426929 EDT | QFunRegParamNorm          103.81
2017-06-11 00:04:15.427267 EDT | -----------------------  -----------
2017-06-11 00:04:15.427785 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #627 | Training started
2017-06-11 00:04:31.972977 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #627 | Training finished
2017-06-11 00:04:31.973926 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #627 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 00:04:31.974258 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #627 | Collecting samples for evaluation
2017-06-11 00:04:44.436424 EDT | -----------------------  -----------
2017-06-11 00:04:44.437493 EDT | Epoch                     627
2017-06-11 00:04:44.437908 EDT | Iteration                 627
2017-06-11 00:04:44.438285 EDT | AverageReturn            1013.54
2017-06-11 00:04:44.438672 EDT | StdReturn                 459.215
2017-06-11 00:04:44.439041 EDT | MaxReturn                2163.88
2017-06-11 00:04:44.439409 EDT | MinReturn                 561.164
2017-06-11 00:04:44.439806 EDT | AverageEsReturn           386.938
2017-06-11 00:04:44.441782 EDT | StdEsReturn               240.569
2017-06-11 00:04:44.442223 EDT | MaxEsReturn               675.641
2017-06-11 00:04:44.442766 EDT | MinEsReturn                 8.04764
2017-06-11 00:04:44.443437 EDT | AverageDiscountedReturn   222.132
2017-06-11 00:04:44.443824 EDT | AverageQLoss                2.36057
2017-06-11 00:04:44.444198 EDT | AveragePolicySurr         -31.6431
2017-06-11 00:04:44.444899 EDT | AverageQ                   31.2704
2017-06-11 00:04:44.445392 EDT | AverageAbsQ                31.2988
2017-06-11 00:04:44.445786 EDT | AverageY                   31.273
2017-06-11 00:04:44.446182 EDT | AverageAbsY                31.2864
2017-06-11 00:04:44.446558 EDT | AverageAbsQYDiff            0.574025
2017-06-11 00:04:44.447124 EDT | AverageAction               0.976217
2017-06-11 00:04:44.447574 EDT | PolicyRegParamNorm         80.9654
2017-06-11 00:04:44.447947 EDT | QFunRegParamNorm          103.862
2017-06-11 00:04:44.448341 EDT | -----------------------  -----------
2017-06-11 00:04:44.448889 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #628 | Training started
2017-06-11 00:05:00.157369 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #628 | Training finished
2017-06-11 00:05:00.158448 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #628 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 00:05:00.158982 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #628 | Collecting samples for evaluation
2017-06-11 00:05:13.645536 EDT | -----------------------  -----------
2017-06-11 00:05:13.647064 EDT | Epoch                     628
2017-06-11 00:05:13.647438 EDT | Iteration                 628
2017-06-11 00:05:13.647788 EDT | AverageReturn            1113.21
2017-06-11 00:05:13.648134 EDT | StdReturn                 534.107
2017-06-11 00:05:13.648481 EDT | MaxReturn                3032.51
2017-06-11 00:05:13.648827 EDT | MinReturn                 584.969
2017-06-11 00:05:13.649170 EDT | AverageEsReturn           502.939
2017-06-11 00:05:13.649516 EDT | StdEsReturn               333.888
2017-06-11 00:05:13.649869 EDT | MaxEsReturn               920.692
2017-06-11 00:05:13.654442 EDT | MinEsReturn               147.073
2017-06-11 00:05:13.654765 EDT | AverageDiscountedReturn   233.658
2017-06-11 00:05:13.655094 EDT | AverageQLoss                2.31529
2017-06-11 00:05:13.656245 EDT | AveragePolicySurr         -31.6804
2017-06-11 00:05:13.657423 EDT | AverageQ                   31.2908
2017-06-11 00:05:13.657795 EDT | AverageAbsQ                31.3157
2017-06-11 00:05:13.658129 EDT | AverageY                   31.2925
2017-06-11 00:05:13.658497 EDT | AverageAbsY                31.3064
2017-06-11 00:05:13.658885 EDT | AverageAbsQYDiff            0.574608
2017-06-11 00:05:13.659306 EDT | AverageAction               0.980899
2017-06-11 00:05:13.659668 EDT | PolicyRegParamNorm         81.0022
2017-06-11 00:05:13.660050 EDT | QFunRegParamNorm          103.863
2017-06-11 00:05:13.660454 EDT | -----------------------  -----------
2017-06-11 00:05:13.660957 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #629 | Training started
2017-06-11 00:05:28.156661 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #629 | Training finished
2017-06-11 00:05:28.165502 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #629 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 00:05:28.174144 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #629 | Collecting samples for evaluation
2017-06-11 00:05:41.397935 EDT | -----------------------  -----------
2017-06-11 00:05:41.399016 EDT | Epoch                     629
2017-06-11 00:05:41.399608 EDT | Iteration                 629
2017-06-11 00:05:41.400515 EDT | AverageReturn            1240.54
2017-06-11 00:05:41.401632 EDT | StdReturn                 453.974
2017-06-11 00:05:41.401989 EDT | MaxReturn                2478.73
2017-06-11 00:05:41.402383 EDT | MinReturn                 662.668
2017-06-11 00:05:41.404008 EDT | AverageEsReturn           423.293
2017-06-11 00:05:41.404441 EDT | StdEsReturn               257.056
2017-06-11 00:05:41.404814 EDT | MaxEsReturn               904.315
2017-06-11 00:05:41.408656 EDT | MinEsReturn                70.5109
2017-06-11 00:05:41.409024 EDT | AverageDiscountedReturn   234.655
2017-06-11 00:05:41.409317 EDT | AverageQLoss                2.38574
2017-06-11 00:05:41.409607 EDT | AveragePolicySurr         -31.6684
2017-06-11 00:05:41.409954 EDT | AverageQ                   31.3153
2017-06-11 00:05:41.410253 EDT | AverageAbsQ                31.3399
2017-06-11 00:05:41.410520 EDT | AverageY                   31.316
2017-06-11 00:05:41.410852 EDT | AverageAbsY                31.3286
2017-06-11 00:05:41.411173 EDT | AverageAbsQYDiff            0.570275
2017-06-11 00:05:41.411493 EDT | AverageAction               0.98156
2017-06-11 00:05:41.411807 EDT | PolicyRegParamNorm         81.011
2017-06-11 00:05:41.412218 EDT | QFunRegParamNorm          103.885
2017-06-11 00:05:41.412478 EDT | -----------------------  -----------
2017-06-11 00:05:41.412966 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #630 | Training started
2017-06-11 00:05:58.005378 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #630 | Training finished
2017-06-11 00:05:58.006835 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #630 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 00:05:58.007175 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #630 | Collecting samples for evaluation
2017-06-11 00:06:10.825586 EDT | -----------------------  -----------
2017-06-11 00:06:10.827701 EDT | Epoch                     630
2017-06-11 00:06:10.828103 EDT | Iteration                 630
2017-06-11 00:06:10.828557 EDT | AverageReturn            1153.11
2017-06-11 00:06:10.829009 EDT | StdReturn                 369.56
2017-06-11 00:06:10.829456 EDT | MaxReturn                2505.72
2017-06-11 00:06:10.829922 EDT | MinReturn                 871.359
2017-06-11 00:06:10.830274 EDT | AverageEsReturn           346.605
2017-06-11 00:06:10.830615 EDT | StdEsReturn               401.871
2017-06-11 00:06:10.830957 EDT | MaxEsReturn              1270.31
2017-06-11 00:06:10.831540 EDT | MinEsReturn                 6.30917
2017-06-11 00:06:10.831895 EDT | AverageDiscountedReturn   237.461
2017-06-11 00:06:10.832912 EDT | AverageQLoss                2.73314
2017-06-11 00:06:10.837011 EDT | AveragePolicySurr         -31.6313
2017-06-11 00:06:10.837365 EDT | AverageQ                   31.257
2017-06-11 00:06:10.837718 EDT | AverageAbsQ                31.2819
2017-06-11 00:06:10.838064 EDT | AverageY                   31.2578
2017-06-11 00:06:10.838408 EDT | AverageAbsY                31.2671
2017-06-11 00:06:10.838748 EDT | AverageAbsQYDiff            0.592683
2017-06-11 00:06:10.839089 EDT | AverageAction               0.981369
2017-06-11 00:06:10.839425 EDT | PolicyRegParamNorm         81.057
2017-06-11 00:06:10.839765 EDT | QFunRegParamNorm          103.97
2017-06-11 00:06:10.840100 EDT | -----------------------  -----------
2017-06-11 00:06:10.840624 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #631 | Training started
2017-06-11 00:06:27.369635 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #631 | Training finished
2017-06-11 00:06:27.370426 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #631 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 00:06:27.370674 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #631 | Collecting samples for evaluation
2017-06-11 00:06:39.212773 EDT | -----------------------  -----------
2017-06-11 00:06:39.216472 EDT | Epoch                     631
2017-06-11 00:06:39.216978 EDT | Iteration                 631
2017-06-11 00:06:39.217196 EDT | AverageReturn            1254.03
2017-06-11 00:06:39.217481 EDT | StdReturn                 600.573
2017-06-11 00:06:39.217847 EDT | MaxReturn                2756.94
2017-06-11 00:06:39.218076 EDT | MinReturn                 367.053
2017-06-11 00:06:39.218323 EDT | AverageEsReturn           387.888
2017-06-11 00:06:39.218476 EDT | StdEsReturn               255.598
2017-06-11 00:06:39.218626 EDT | MaxEsReturn               962.472
2017-06-11 00:06:39.218775 EDT | MinEsReturn               106.468
2017-06-11 00:06:39.218924 EDT | AverageDiscountedReturn   232.147
2017-06-11 00:06:39.219073 EDT | AverageQLoss                2.54301
2017-06-11 00:06:39.219220 EDT | AveragePolicySurr         -31.5278
2017-06-11 00:06:39.219368 EDT | AverageQ                   31.1563
2017-06-11 00:06:39.219516 EDT | AverageAbsQ                31.1852
2017-06-11 00:06:39.219742 EDT | AverageY                   31.159
2017-06-11 00:06:39.220074 EDT | AverageAbsY                31.1741
2017-06-11 00:06:39.220406 EDT | AverageAbsQYDiff            0.583101
2017-06-11 00:06:39.220571 EDT | AverageAction               0.980841
2017-06-11 00:06:39.220725 EDT | PolicyRegParamNorm         81.1069
2017-06-11 00:06:39.220950 EDT | QFunRegParamNorm          104.034
2017-06-11 00:06:39.221101 EDT | -----------------------  -----------
2017-06-11 00:06:39.221391 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #632 | Training started
2017-06-11 00:06:54.872855 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #632 | Training finished
2017-06-11 00:06:54.873913 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #632 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 00:06:54.874304 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #632 | Collecting samples for evaluation
2017-06-11 00:07:08.472411 EDT | -----------------------  -----------
2017-06-11 00:07:08.473828 EDT | Epoch                     632
2017-06-11 00:07:08.474187 EDT | Iteration                 632
2017-06-11 00:07:08.474508 EDT | AverageReturn            2242.91
2017-06-11 00:07:08.474828 EDT | StdReturn                 590.156
2017-06-11 00:07:08.475111 EDT | MaxReturn                3111.62
2017-06-11 00:07:08.475440 EDT | MinReturn                1364.92
2017-06-11 00:07:08.475780 EDT | AverageEsReturn           327.342
2017-06-11 00:07:08.476107 EDT | StdEsReturn               330.224
2017-06-11 00:07:08.476378 EDT | MaxEsReturn              1009.06
2017-06-11 00:07:08.476710 EDT | MinEsReturn                 7.96762
2017-06-11 00:07:08.477047 EDT | AverageDiscountedReturn   248.257
2017-06-11 00:07:08.477381 EDT | AverageQLoss                2.56629
2017-06-11 00:07:08.477648 EDT | AveragePolicySurr         -31.583
2017-06-11 00:07:08.477982 EDT | AverageQ                   31.2353
2017-06-11 00:07:08.478312 EDT | AverageAbsQ                31.2619
2017-06-11 00:07:08.478642 EDT | AverageY                   31.2369
2017-06-11 00:07:08.478969 EDT | AverageAbsY                31.2493
2017-06-11 00:07:08.479297 EDT | AverageAbsQYDiff            0.573579
2017-06-11 00:07:08.479632 EDT | AverageAction               0.983391
2017-06-11 00:07:08.479940 EDT | PolicyRegParamNorm         81.2419
2017-06-11 00:07:08.480273 EDT | QFunRegParamNorm          104.118
2017-06-11 00:07:08.480610 EDT | -----------------------  -----------
2017-06-11 00:07:08.481085 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #633 | Training started
2017-06-11 00:07:22.739353 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #633 | Training finished
2017-06-11 00:07:22.740272 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #633 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 00:07:22.740645 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #633 | Collecting samples for evaluation
2017-06-11 00:07:37.214786 EDT | -----------------------  -----------
2017-06-11 00:07:37.218024 EDT | Epoch                     633
2017-06-11 00:07:37.218396 EDT | Iteration                 633
2017-06-11 00:07:37.218747 EDT | AverageReturn            2463.51
2017-06-11 00:07:37.219116 EDT | StdReturn                 628.481
2017-06-11 00:07:37.219461 EDT | MaxReturn                3101.04
2017-06-11 00:07:37.219804 EDT | MinReturn                1180.07
2017-06-11 00:07:37.220147 EDT | AverageEsReturn           320.459
2017-06-11 00:07:37.220486 EDT | StdEsReturn               182.088
2017-06-11 00:07:37.220829 EDT | MaxEsReturn               649.865
2017-06-11 00:07:37.221169 EDT | MinEsReturn               104.976
2017-06-11 00:07:37.221514 EDT | AverageDiscountedReturn   240.52
2017-06-11 00:07:37.221865 EDT | AverageQLoss                2.79762
2017-06-11 00:07:37.222207 EDT | AveragePolicySurr         -31.4799
2017-06-11 00:07:37.222547 EDT | AverageQ                   31.1283
2017-06-11 00:07:37.222898 EDT | AverageAbsQ                31.1555
2017-06-11 00:07:37.223234 EDT | AverageY                   31.1283
2017-06-11 00:07:37.223576 EDT | AverageAbsY                31.14
2017-06-11 00:07:37.223918 EDT | AverageAbsQYDiff            0.59781
2017-06-11 00:07:37.224259 EDT | AverageAction               0.977704
2017-06-11 00:07:37.224596 EDT | PolicyRegParamNorm         81.3148
2017-06-11 00:07:37.224936 EDT | QFunRegParamNorm          104.157
2017-06-11 00:07:37.225277 EDT | -----------------------  -----------
2017-06-11 00:07:37.225808 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #634 | Training started
2017-06-11 00:07:53.067494 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #634 | Training finished
2017-06-11 00:07:53.068459 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #634 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 00:07:53.068859 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #634 | Collecting samples for evaluation
2017-06-11 00:08:05.851173 EDT | -----------------------  -----------
2017-06-11 00:08:05.852015 EDT | Epoch                     634
2017-06-11 00:08:05.852229 EDT | Iteration                 634
2017-06-11 00:08:05.852880 EDT | AverageReturn            2257.74
2017-06-11 00:08:05.855963 EDT | StdReturn                 789.639
2017-06-11 00:08:05.856422 EDT | MaxReturn                3189.76
2017-06-11 00:08:05.856844 EDT | MinReturn                 965.169
2017-06-11 00:08:05.857035 EDT | AverageEsReturn           321.766
2017-06-11 00:08:05.857234 EDT | StdEsReturn               204.733
2017-06-11 00:08:05.857463 EDT | MaxEsReturn               789.848
2017-06-11 00:08:05.857789 EDT | MinEsReturn               105.671
2017-06-11 00:08:05.857986 EDT | AverageDiscountedReturn   241.307
2017-06-11 00:08:05.858187 EDT | AverageQLoss                2.50766
2017-06-11 00:08:05.858381 EDT | AveragePolicySurr         -31.5227
2017-06-11 00:08:05.858682 EDT | AverageQ                   31.1786
2017-06-11 00:08:05.858879 EDT | AverageAbsQ                31.2008
2017-06-11 00:08:05.859073 EDT | AverageY                   31.179
2017-06-11 00:08:05.859361 EDT | AverageAbsY                31.1894
2017-06-11 00:08:05.859824 EDT | AverageAbsQYDiff            0.576348
2017-06-11 00:08:05.860021 EDT | AverageAction               0.976499
2017-06-11 00:08:05.860216 EDT | PolicyRegParamNorm         81.3252
2017-06-11 00:08:05.860476 EDT | QFunRegParamNorm          104.171
2017-06-11 00:08:05.860763 EDT | -----------------------  -----------
2017-06-11 00:08:05.861322 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #635 | Training started
2017-06-11 00:08:22.649532 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #635 | Training finished
2017-06-11 00:08:22.650510 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #635 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 00:08:22.650888 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #635 | Collecting samples for evaluation
2017-06-11 00:08:34.527586 EDT | -----------------------  -----------
2017-06-11 00:08:34.528740 EDT | Epoch                     635
2017-06-11 00:08:34.528975 EDT | Iteration                 635
2017-06-11 00:08:34.529138 EDT | AverageReturn            1148.05
2017-06-11 00:08:34.529332 EDT | StdReturn                 597.183
2017-06-11 00:08:34.529487 EDT | MaxReturn                3034.72
2017-06-11 00:08:34.529637 EDT | MinReturn                 598.025
2017-06-11 00:08:34.529853 EDT | AverageEsReturn           170.198
2017-06-11 00:08:34.530005 EDT | StdEsReturn               169.244
2017-06-11 00:08:34.530155 EDT | MaxEsReturn               517.238
2017-06-11 00:08:34.530304 EDT | MinEsReturn                 8.51148
2017-06-11 00:08:34.530460 EDT | AverageDiscountedReturn   229.475
2017-06-11 00:08:34.530638 EDT | AverageQLoss                2.08795
2017-06-11 00:08:34.530790 EDT | AveragePolicySurr         -31.5089
2017-06-11 00:08:34.530942 EDT | AverageQ                   31.151
2017-06-11 00:08:34.531280 EDT | AverageAbsQ                31.173
2017-06-11 00:08:34.531873 EDT | AverageY                   31.151
2017-06-11 00:08:34.532207 EDT | AverageAbsY                31.1623
2017-06-11 00:08:34.532526 EDT | AverageAbsQYDiff            0.548132
2017-06-11 00:08:34.532845 EDT | AverageAction               0.973389
2017-06-11 00:08:34.533152 EDT | PolicyRegParamNorm         81.4355
2017-06-11 00:08:34.533527 EDT | QFunRegParamNorm          104.166
2017-06-11 00:08:34.533827 EDT | -----------------------  -----------
2017-06-11 00:08:34.534191 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #636 | Training started
2017-06-11 00:08:50.776085 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #636 | Training finished
2017-06-11 00:08:50.776854 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #636 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 00:08:50.777045 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #636 | Collecting samples for evaluation
2017-06-11 00:09:03.957122 EDT | -----------------------  -----------
2017-06-11 00:09:03.957848 EDT | Epoch                     636
2017-06-11 00:09:03.958144 EDT | Iteration                 636
2017-06-11 00:09:03.958307 EDT | AverageReturn            1527.61
2017-06-11 00:09:03.958484 EDT | StdReturn                 544.566
2017-06-11 00:09:03.958643 EDT | MaxReturn                3300.84
2017-06-11 00:09:03.958794 EDT | MinReturn                 954.423
2017-06-11 00:09:03.958961 EDT | AverageEsReturn           395.801
2017-06-11 00:09:03.959126 EDT | StdEsReturn               257.92
2017-06-11 00:09:03.959277 EDT | MaxEsReturn               753.532
2017-06-11 00:09:03.959426 EDT | MinEsReturn                84.4066
2017-06-11 00:09:03.959575 EDT | AverageDiscountedReturn   245.182
2017-06-11 00:09:03.959724 EDT | AverageQLoss                2.33183
2017-06-11 00:09:03.959915 EDT | AveragePolicySurr         -31.3869
2017-06-11 00:09:03.960066 EDT | AverageQ                   31.0298
2017-06-11 00:09:03.960225 EDT | AverageAbsQ                31.0529
2017-06-11 00:09:03.960432 EDT | AverageY                   31.0315
2017-06-11 00:09:03.960673 EDT | AverageAbsY                31.0418
2017-06-11 00:09:03.960827 EDT | AverageAbsQYDiff            0.564667
2017-06-11 00:09:03.960977 EDT | AverageAction               0.977411
2017-06-11 00:09:03.961125 EDT | PolicyRegParamNorm         81.4763
2017-06-11 00:09:03.961305 EDT | QFunRegParamNorm          104.224
2017-06-11 00:09:03.961455 EDT | -----------------------  -----------
2017-06-11 00:09:03.961729 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #637 | Training started
2017-06-11 00:09:19.891747 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #637 | Training finished
2017-06-11 00:09:19.892286 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #637 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 00:09:19.892795 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #637 | Collecting samples for evaluation
2017-06-11 00:09:33.005262 EDT | -----------------------  -----------
2017-06-11 00:09:33.006273 EDT | Epoch                     637
2017-06-11 00:09:33.006674 EDT | Iteration                 637
2017-06-11 00:09:33.007062 EDT | AverageReturn             488.444
2017-06-11 00:09:33.007446 EDT | StdReturn                 153.744
2017-06-11 00:09:33.007916 EDT | MaxReturn                1092.56
2017-06-11 00:09:33.008416 EDT | MinReturn                 325.947
2017-06-11 00:09:33.008934 EDT | AverageEsReturn           263.88
2017-06-11 00:09:33.009475 EDT | StdEsReturn               125.715
2017-06-11 00:09:33.009877 EDT | MaxEsReturn               439.193
2017-06-11 00:09:33.010254 EDT | MinEsReturn                31.6091
2017-06-11 00:09:33.010556 EDT | AverageDiscountedReturn   194.415
2017-06-11 00:09:33.010851 EDT | AverageQLoss                2.24433
2017-06-11 00:09:33.011283 EDT | AveragePolicySurr         -31.3942
2017-06-11 00:09:33.011610 EDT | AverageQ                   31.0625
2017-06-11 00:09:33.011936 EDT | AverageAbsQ                31.0863
2017-06-11 00:09:33.012248 EDT | AverageY                   31.0627
2017-06-11 00:09:33.012569 EDT | AverageAbsY                31.0717
2017-06-11 00:09:33.013082 EDT | AverageAbsQYDiff            0.55102
2017-06-11 00:09:33.013483 EDT | AverageAction               0.981967
2017-06-11 00:09:33.013828 EDT | PolicyRegParamNorm         81.5346
2017-06-11 00:09:33.014214 EDT | QFunRegParamNorm          104.297
2017-06-11 00:09:33.014830 EDT | -----------------------  -----------
2017-06-11 00:09:33.015363 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #638 | Training started
2017-06-11 00:09:48.457670 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #638 | Training finished
2017-06-11 00:09:48.458458 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #638 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 00:09:48.458650 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #638 | Collecting samples for evaluation
2017-06-11 00:10:00.744176 EDT | -----------------------  -----------
2017-06-11 00:10:00.745149 EDT | Epoch                     638
2017-06-11 00:10:00.745564 EDT | Iteration                 638
2017-06-11 00:10:00.745821 EDT | AverageReturn             900.777
2017-06-11 00:10:00.746009 EDT | StdReturn                 270.128
2017-06-11 00:10:00.746192 EDT | MaxReturn                1706.88
2017-06-11 00:10:00.746372 EDT | MinReturn                 392.067
2017-06-11 00:10:00.746551 EDT | AverageEsReturn           372.23
2017-06-11 00:10:00.746731 EDT | StdEsReturn               151.143
2017-06-11 00:10:00.746909 EDT | MaxEsReturn               634.333
2017-06-11 00:10:00.747086 EDT | MinEsReturn               109.039
2017-06-11 00:10:00.747263 EDT | AverageDiscountedReturn   227.913
2017-06-11 00:10:00.747545 EDT | AverageQLoss                2.54967
2017-06-11 00:10:00.747935 EDT | AveragePolicySurr         -31.43
2017-06-11 00:10:00.748333 EDT | AverageQ                   31.1017
2017-06-11 00:10:00.748819 EDT | AverageAbsQ                31.1222
2017-06-11 00:10:00.749231 EDT | AverageY                   31.1017
2017-06-11 00:10:00.749725 EDT | AverageAbsY                31.1095
2017-06-11 00:10:00.750148 EDT | AverageAbsQYDiff            0.587706
2017-06-11 00:10:00.750564 EDT | AverageAction               0.977913
2017-06-11 00:10:00.752949 EDT | PolicyRegParamNorm         81.5819
2017-06-11 00:10:00.753628 EDT | QFunRegParamNorm          104.435
2017-06-11 00:10:00.753948 EDT | -----------------------  -----------
2017-06-11 00:10:00.754259 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #639 | Training started
2017-06-11 00:10:17.520095 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #639 | Training finished
2017-06-11 00:10:17.520882 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #639 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 00:10:17.521087 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #639 | Collecting samples for evaluation
2017-06-11 00:10:29.622815 EDT | -----------------------  -----------
2017-06-11 00:10:29.623768 EDT | Epoch                     639
2017-06-11 00:10:29.624036 EDT | Iteration                 639
2017-06-11 00:10:29.624251 EDT | AverageReturn             384.811
2017-06-11 00:10:29.624584 EDT | StdReturn                 366.646
2017-06-11 00:10:29.624996 EDT | MaxReturn                1624.7
2017-06-11 00:10:29.625226 EDT | MinReturn                 139.567
2017-06-11 00:10:29.625410 EDT | AverageEsReturn           189.819
2017-06-11 00:10:29.625591 EDT | StdEsReturn               103.625
2017-06-11 00:10:29.628367 EDT | MaxEsReturn               509.752
2017-06-11 00:10:29.630102 EDT | MinEsReturn                86.6561
2017-06-11 00:10:29.630287 EDT | AverageDiscountedReturn   147.312
2017-06-11 00:10:29.630477 EDT | AverageQLoss                2.31143
2017-06-11 00:10:29.630662 EDT | AveragePolicySurr         -31.3658
2017-06-11 00:10:29.630845 EDT | AverageQ                   30.984
2017-06-11 00:10:29.631026 EDT | AverageAbsQ                31.0037
2017-06-11 00:10:29.631205 EDT | AverageY                   30.989
2017-06-11 00:10:29.631384 EDT | AverageAbsY                30.9979
2017-06-11 00:10:29.631561 EDT | AverageAbsQYDiff            0.572744
2017-06-11 00:10:29.631739 EDT | AverageAction               0.98547
2017-06-11 00:10:29.631925 EDT | PolicyRegParamNorm         81.5872
2017-06-11 00:10:29.632215 EDT | QFunRegParamNorm          104.538
2017-06-11 00:10:29.632653 EDT | -----------------------  -----------
2017-06-11 00:10:29.633061 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #640 | Training started
2017-06-11 00:10:45.307950 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #640 | Training finished
2017-06-11 00:10:45.308914 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #640 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 00:10:45.309301 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #640 | Collecting samples for evaluation
2017-06-11 00:10:58.119938 EDT | -----------------------  -----------
2017-06-11 00:10:58.121010 EDT | Epoch                     640
2017-06-11 00:10:58.121389 EDT | Iteration                 640
2017-06-11 00:10:58.121737 EDT | AverageReturn             798.261
2017-06-11 00:10:58.122067 EDT | StdReturn                 186.612
2017-06-11 00:10:58.122390 EDT | MaxReturn                1146.89
2017-06-11 00:10:58.122708 EDT | MinReturn                 409.224
2017-06-11 00:10:58.123028 EDT | AverageEsReturn           202.673
2017-06-11 00:10:58.123364 EDT | StdEsReturn               203.852
2017-06-11 00:10:58.123728 EDT | MaxEsReturn               679.643
2017-06-11 00:10:58.124091 EDT | MinEsReturn                24.5232
2017-06-11 00:10:58.124436 EDT | AverageDiscountedReturn   221.591
2017-06-11 00:10:58.124775 EDT | AverageQLoss                2.30589
2017-06-11 00:10:58.125105 EDT | AveragePolicySurr         -31.373
2017-06-11 00:10:58.125434 EDT | AverageQ                   31.0163
2017-06-11 00:10:58.125772 EDT | AverageAbsQ                31.0418
2017-06-11 00:10:58.126103 EDT | AverageY                   31.0147
2017-06-11 00:10:58.126430 EDT | AverageAbsY                31.0325
2017-06-11 00:10:58.126760 EDT | AverageAbsQYDiff            0.56631
2017-06-11 00:10:58.127088 EDT | AverageAction               0.981807
2017-06-11 00:10:58.127416 EDT | PolicyRegParamNorm         81.6408
2017-06-11 00:10:58.127789 EDT | QFunRegParamNorm          104.651
2017-06-11 00:10:58.128287 EDT | -----------------------  -----------
2017-06-11 00:10:58.128789 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #641 | Training started
2017-06-11 00:11:12.909375 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #641 | Training finished
2017-06-11 00:11:12.910127 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #641 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 00:11:12.910338 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #641 | Collecting samples for evaluation
2017-06-11 00:11:27.484870 EDT | -----------------------  -----------
2017-06-11 00:11:27.485760 EDT | Epoch                     641
2017-06-11 00:11:27.486059 EDT | Iteration                 641
2017-06-11 00:11:27.486268 EDT | AverageReturn             642.131
2017-06-11 00:11:27.486466 EDT | StdReturn                 696.805
2017-06-11 00:11:27.486683 EDT | MaxReturn                2961.48
2017-06-11 00:11:27.486877 EDT | MinReturn                 150.48
2017-06-11 00:11:27.487070 EDT | AverageEsReturn           219.5
2017-06-11 00:11:27.487262 EDT | StdEsReturn               206.131
2017-06-11 00:11:27.487618 EDT | MaxEsReturn               583.235
2017-06-11 00:11:27.488011 EDT | MinEsReturn                19.8177
2017-06-11 00:11:27.488235 EDT | AverageDiscountedReturn   162.53
2017-06-11 00:11:27.488433 EDT | AverageQLoss                2.97651
2017-06-11 00:11:27.488627 EDT | AveragePolicySurr         -31.2349
2017-06-11 00:11:27.488824 EDT | AverageQ                   30.8949
2017-06-11 00:11:27.489191 EDT | AverageAbsQ                30.9218
2017-06-11 00:11:27.489382 EDT | AverageY                   30.8972
2017-06-11 00:11:27.489578 EDT | AverageAbsY                30.908
2017-06-11 00:11:27.489793 EDT | AverageAbsQYDiff            0.620715
2017-06-11 00:11:27.489986 EDT | AverageAction               0.98123
2017-06-11 00:11:27.490177 EDT | PolicyRegParamNorm         81.6991
2017-06-11 00:11:27.490367 EDT | QFunRegParamNorm          104.685
2017-06-11 00:11:27.490557 EDT | -----------------------  -----------
2017-06-11 00:11:27.490848 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #642 | Training started
2017-06-11 00:11:41.620577 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #642 | Training finished
2017-06-11 00:11:41.621494 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #642 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 00:11:41.621902 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #642 | Collecting samples for evaluation
2017-06-11 00:11:54.893031 EDT | -----------------------  -----------
2017-06-11 00:11:54.893801 EDT | Epoch                     642
2017-06-11 00:11:54.894168 EDT | Iteration                 642
2017-06-11 00:11:54.894352 EDT | AverageReturn            1328.03
2017-06-11 00:11:54.894542 EDT | StdReturn                 706.706
2017-06-11 00:11:54.894871 EDT | MaxReturn                3310.94
2017-06-11 00:11:54.895108 EDT | MinReturn                 552.17
2017-06-11 00:11:54.895291 EDT | AverageEsReturn           305.689
2017-06-11 00:11:54.895472 EDT | StdEsReturn               412.092
2017-06-11 00:11:54.895654 EDT | MaxEsReturn              1339
2017-06-11 00:11:54.895962 EDT | MinEsReturn                 9.61217
2017-06-11 00:11:54.896171 EDT | AverageDiscountedReturn   238.559
2017-06-11 00:11:54.896338 EDT | AverageQLoss                2.67251
2017-06-11 00:11:54.896600 EDT | AveragePolicySurr         -31.2992
2017-06-11 00:11:54.896782 EDT | AverageQ                   30.9552
2017-06-11 00:11:54.897862 EDT | AverageAbsQ                30.977
2017-06-11 00:11:54.898152 EDT | AverageY                   30.9561
2017-06-11 00:11:54.898486 EDT | AverageAbsY                30.9655
2017-06-11 00:11:54.898664 EDT | AverageAbsQYDiff            0.577623
2017-06-11 00:11:54.898851 EDT | AverageAction               0.983982
2017-06-11 00:11:54.899135 EDT | PolicyRegParamNorm         81.7329
2017-06-11 00:11:54.899321 EDT | QFunRegParamNorm          104.737
2017-06-11 00:11:54.900046 EDT | -----------------------  -----------
2017-06-11 00:11:54.900820 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #643 | Training started
2017-06-11 00:12:10.593128 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #643 | Training finished
2017-06-11 00:12:10.593981 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #643 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 00:12:10.594205 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #643 | Collecting samples for evaluation
2017-06-11 00:12:23.142306 EDT | -----------------------  -----------
2017-06-11 00:12:23.142590 EDT | Epoch                     643
2017-06-11 00:12:23.142755 EDT | Iteration                 643
2017-06-11 00:12:23.142912 EDT | AverageReturn             164.563
2017-06-11 00:12:23.143095 EDT | StdReturn                  91.743
2017-06-11 00:12:23.143249 EDT | MaxReturn                1176.91
2017-06-11 00:12:23.143400 EDT | MinReturn                 143.693
2017-06-11 00:12:23.143551 EDT | AverageEsReturn           319.956
2017-06-11 00:12:23.143700 EDT | StdEsReturn               199.106
2017-06-11 00:12:23.143849 EDT | MaxEsReturn               630.303
2017-06-11 00:12:23.143999 EDT | MinEsReturn                47.6079
2017-06-11 00:12:23.144147 EDT | AverageDiscountedReturn   105.294
2017-06-11 00:12:23.144296 EDT | AverageQLoss                2.21925
2017-06-11 00:12:23.144444 EDT | AveragePolicySurr         -31.1791
2017-06-11 00:12:23.144593 EDT | AverageQ                   30.8186
2017-06-11 00:12:23.144742 EDT | AverageAbsQ                30.839
2017-06-11 00:12:23.144893 EDT | AverageY                   30.8186
2017-06-11 00:12:23.145047 EDT | AverageAbsY                30.8286
2017-06-11 00:12:23.145215 EDT | AverageAbsQYDiff            0.558942
2017-06-11 00:12:23.145380 EDT | AverageAction               0.988113
2017-06-11 00:12:23.145530 EDT | PolicyRegParamNorm         81.7923
2017-06-11 00:12:23.145680 EDT | QFunRegParamNorm          104.833
2017-06-11 00:12:23.145841 EDT | -----------------------  -----------
2017-06-11 00:12:23.146099 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #644 | Training started
2017-06-11 00:12:39.421599 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #644 | Training finished
2017-06-11 00:12:39.422442 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #644 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 00:12:39.422803 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #644 | Collecting samples for evaluation
2017-06-11 00:12:53.294492 EDT | -----------------------  -----------
2017-06-11 00:12:53.294960 EDT | Epoch                     644
2017-06-11 00:12:53.295522 EDT | Iteration                 644
2017-06-11 00:12:53.295884 EDT | AverageReturn            1312.39
2017-06-11 00:12:53.296245 EDT | StdReturn                 623.156
2017-06-11 00:12:53.296604 EDT | MaxReturn                2682.44
2017-06-11 00:12:53.296959 EDT | MinReturn                 448.686
2017-06-11 00:12:53.297317 EDT | AverageEsReturn           193.6
2017-06-11 00:12:53.298334 EDT | StdEsReturn               117.533
2017-06-11 00:12:53.298702 EDT | MaxEsReturn               477.128
2017-06-11 00:12:53.299061 EDT | MinEsReturn                 4.66838
2017-06-11 00:12:53.299420 EDT | AverageDiscountedReturn   214.258
2017-06-11 00:12:53.299849 EDT | AverageQLoss                2.2653
2017-06-11 00:12:53.301602 EDT | AveragePolicySurr         -31.2404
2017-06-11 00:12:53.302077 EDT | AverageQ                   30.8796
2017-06-11 00:12:53.302515 EDT | AverageAbsQ                30.8984
2017-06-11 00:12:53.302874 EDT | AverageY                   30.8828
2017-06-11 00:12:53.303328 EDT | AverageAbsY                30.89
2017-06-11 00:12:53.303750 EDT | AverageAbsQYDiff            0.554959
2017-06-11 00:12:53.304114 EDT | AverageAction               0.983974
2017-06-11 00:12:53.304753 EDT | PolicyRegParamNorm         81.8472
2017-06-11 00:12:53.305266 EDT | QFunRegParamNorm          104.874
2017-06-11 00:12:53.305631 EDT | -----------------------  -----------
2017-06-11 00:12:53.306461 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #645 | Training started
2017-06-11 00:13:08.663600 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #645 | Training finished
2017-06-11 00:13:08.664566 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #645 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 00:13:08.664962 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #645 | Collecting samples for evaluation
2017-06-11 00:13:22.779954 EDT | -----------------------  -----------
2017-06-11 00:13:22.780334 EDT | Epoch                     645
2017-06-11 00:13:22.780596 EDT | Iteration                 645
2017-06-11 00:13:22.780847 EDT | AverageReturn            1708.58
2017-06-11 00:13:22.781097 EDT | StdReturn                 899.684
2017-06-11 00:13:22.781344 EDT | MaxReturn                3017.94
2017-06-11 00:13:22.781590 EDT | MinReturn                 443.965
2017-06-11 00:13:22.781848 EDT | AverageEsReturn           349.999
2017-06-11 00:13:22.782094 EDT | StdEsReturn               388.562
2017-06-11 00:13:22.782340 EDT | MaxEsReturn              1004.36
2017-06-11 00:13:22.782585 EDT | MinEsReturn                13.7804
2017-06-11 00:13:22.782830 EDT | AverageDiscountedReturn   226.863
2017-06-11 00:13:22.783074 EDT | AverageQLoss                2.26836
2017-06-11 00:13:22.783318 EDT | AveragePolicySurr         -31.258
2017-06-11 00:13:22.783561 EDT | AverageQ                   30.9135
2017-06-11 00:13:22.783806 EDT | AverageAbsQ                30.9359
2017-06-11 00:13:22.784048 EDT | AverageY                   30.9154
2017-06-11 00:13:22.784291 EDT | AverageAbsY                30.9229
2017-06-11 00:13:22.784534 EDT | AverageAbsQYDiff            0.557128
2017-06-11 00:13:22.784777 EDT | AverageAction               0.98112
2017-06-11 00:13:22.785020 EDT | PolicyRegParamNorm         81.9169
2017-06-11 00:13:22.785265 EDT | QFunRegParamNorm          104.938
2017-06-11 00:13:22.785510 EDT | -----------------------  -----------
2017-06-11 00:13:22.785920 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #646 | Training started
2017-06-11 00:13:37.355899 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #646 | Training finished
2017-06-11 00:13:37.356681 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #646 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 00:13:37.356874 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #646 | Collecting samples for evaluation
2017-06-11 00:13:49.959962 EDT | -----------------------  -----------
2017-06-11 00:13:49.962128 EDT | Epoch                     646
2017-06-11 00:13:49.962319 EDT | Iteration                 646
2017-06-11 00:13:49.962511 EDT | AverageReturn            1559.22
2017-06-11 00:13:49.962670 EDT | StdReturn                 850.963
2017-06-11 00:13:49.962822 EDT | MaxReturn                2841.84
2017-06-11 00:13:49.963263 EDT | MinReturn                 314.369
2017-06-11 00:13:49.963417 EDT | AverageEsReturn           435.825
2017-06-11 00:13:49.963570 EDT | StdEsReturn               323.539
2017-06-11 00:13:49.964947 EDT | MaxEsReturn               925.743
2017-06-11 00:13:49.965117 EDT | MinEsReturn                82.566
2017-06-11 00:13:49.965305 EDT | AverageDiscountedReturn   221.122
2017-06-11 00:13:49.965503 EDT | AverageQLoss                2.60192
2017-06-11 00:13:49.965659 EDT | AveragePolicySurr         -31.0949
2017-06-11 00:13:49.966263 EDT | AverageQ                   30.7195
2017-06-11 00:13:49.966531 EDT | AverageAbsQ                30.7467
2017-06-11 00:13:49.966755 EDT | AverageY                   30.7154
2017-06-11 00:13:49.966910 EDT | AverageAbsY                30.7282
2017-06-11 00:13:49.967061 EDT | AverageAbsQYDiff            0.583115
2017-06-11 00:13:49.967221 EDT | AverageAction               0.986345
2017-06-11 00:13:49.967374 EDT | PolicyRegParamNorm         81.958
2017-06-11 00:13:49.967524 EDT | QFunRegParamNorm          104.994
2017-06-11 00:13:49.967675 EDT | -----------------------  -----------
2017-06-11 00:13:49.967999 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #647 | Training started
2017-06-11 00:14:05.959263 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #647 | Training finished
2017-06-11 00:14:05.960084 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #647 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 00:14:05.960301 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #647 | Collecting samples for evaluation
2017-06-11 00:14:18.419903 EDT | -----------------------  -----------
2017-06-11 00:14:18.420821 EDT | Epoch                     647
2017-06-11 00:14:18.421180 EDT | Iteration                 647
2017-06-11 00:14:18.421508 EDT | AverageReturn             330.35
2017-06-11 00:14:18.421849 EDT | StdReturn                 242.395
2017-06-11 00:14:18.422182 EDT | MaxReturn                1479.71
2017-06-11 00:14:18.422510 EDT | MinReturn                 201.932
2017-06-11 00:14:18.422769 EDT | AverageEsReturn           236.844
2017-06-11 00:14:18.423176 EDT | StdEsReturn               209.907
2017-06-11 00:14:18.423722 EDT | MaxEsReturn               645.17
2017-06-11 00:14:18.423993 EDT | MinEsReturn                12.7596
2017-06-11 00:14:18.424324 EDT | AverageDiscountedReturn   146.213
2017-06-11 00:14:18.424658 EDT | AverageQLoss                2.38107
2017-06-11 00:14:18.425183 EDT | AveragePolicySurr         -31.1078
2017-06-11 00:14:18.425765 EDT | AverageQ                   30.7225
2017-06-11 00:14:18.426069 EDT | AverageAbsQ                30.7514
2017-06-11 00:14:18.426491 EDT | AverageY                   30.7265
2017-06-11 00:14:18.427149 EDT | AverageAbsY                30.7413
2017-06-11 00:14:18.427489 EDT | AverageAbsQYDiff            0.564141
2017-06-11 00:14:18.427857 EDT | AverageAction               0.988219
2017-06-11 00:14:18.428216 EDT | PolicyRegParamNorm         81.9789
2017-06-11 00:14:18.428553 EDT | QFunRegParamNorm          105.046
2017-06-11 00:14:18.428866 EDT | -----------------------  -----------
2017-06-11 00:14:18.429296 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #648 | Training started
2017-06-11 00:14:35.291889 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #648 | Training finished
2017-06-11 00:14:35.292904 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #648 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 00:14:35.293290 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #648 | Collecting samples for evaluation
2017-06-11 00:14:47.858317 EDT | -----------------------  -----------
2017-06-11 00:14:47.861999 EDT | Epoch                     648
2017-06-11 00:14:47.862485 EDT | Iteration                 648
2017-06-11 00:14:47.862880 EDT | AverageReturn            1361.78
2017-06-11 00:14:47.863180 EDT | StdReturn                 595.922
2017-06-11 00:14:47.863581 EDT | MaxReturn                2885.35
2017-06-11 00:14:47.863944 EDT | MinReturn                 340.528
2017-06-11 00:14:47.864230 EDT | AverageEsReturn           270.66
2017-06-11 00:14:47.864618 EDT | StdEsReturn               143.932
2017-06-11 00:14:47.864952 EDT | MaxEsReturn               588.691
2017-06-11 00:14:47.865257 EDT | MinEsReturn                40.2428
2017-06-11 00:14:47.865571 EDT | AverageDiscountedReturn   236.476
2017-06-11 00:14:47.865936 EDT | AverageQLoss                2.26091
2017-06-11 00:14:47.866102 EDT | AveragePolicySurr         -31.2618
2017-06-11 00:14:47.866408 EDT | AverageQ                   30.8994
2017-06-11 00:14:47.866716 EDT | AverageAbsQ                30.9237
2017-06-11 00:14:47.867024 EDT | AverageY                   30.9017
2017-06-11 00:14:47.867367 EDT | AverageAbsY                30.9146
2017-06-11 00:14:47.867691 EDT | AverageAbsQYDiff            0.550854
2017-06-11 00:14:47.868007 EDT | AverageAction               0.985723
2017-06-11 00:14:47.868333 EDT | PolicyRegParamNorm         82.0393
2017-06-11 00:14:47.868558 EDT | QFunRegParamNorm          105.138
2017-06-11 00:14:47.868978 EDT | -----------------------  -----------
2017-06-11 00:14:47.869386 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #649 | Training started
2017-06-11 00:15:03.121296 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #649 | Training finished
2017-06-11 00:15:03.137811 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #649 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 00:15:03.138283 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #649 | Collecting samples for evaluation
2017-06-11 00:15:16.011691 EDT | -----------------------  -----------
2017-06-11 00:15:16.012617 EDT | Epoch                     649
2017-06-11 00:15:16.012985 EDT | Iteration                 649
2017-06-11 00:15:16.013433 EDT | AverageReturn             915.771
2017-06-11 00:15:16.013894 EDT | StdReturn                 430.064
2017-06-11 00:15:16.014321 EDT | MaxReturn                2039.53
2017-06-11 00:15:16.014677 EDT | MinReturn                 242.536
2017-06-11 00:15:16.015036 EDT | AverageEsReturn           368.027
2017-06-11 00:15:16.019486 EDT | StdEsReturn               248.09
2017-06-11 00:15:16.019862 EDT | MaxEsReturn               783.164
2017-06-11 00:15:16.020211 EDT | MinEsReturn                32.428
2017-06-11 00:15:16.020686 EDT | AverageDiscountedReturn   210.826
2017-06-11 00:15:16.021042 EDT | AverageQLoss                2.65684
2017-06-11 00:15:16.021386 EDT | AveragePolicySurr         -31.1085
2017-06-11 00:15:16.021881 EDT | AverageQ                   30.7465
2017-06-11 00:15:16.022228 EDT | AverageAbsQ                30.7694
2017-06-11 00:15:16.022618 EDT | AverageY                   30.7461
2017-06-11 00:15:16.022969 EDT | AverageAbsY                30.7574
2017-06-11 00:15:16.023312 EDT | AverageAbsQYDiff            0.593052
2017-06-11 00:15:16.023955 EDT | AverageAction               0.988224
2017-06-11 00:15:16.025163 EDT | PolicyRegParamNorm         82.1132
2017-06-11 00:15:16.037788 EDT | QFunRegParamNorm          105.169
2017-06-11 00:15:16.038217 EDT | -----------------------  -----------
2017-06-11 00:15:16.038712 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #650 | Training started
2017-06-11 00:15:31.671752 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #650 | Training finished
2017-06-11 00:15:31.672568 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #650 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 00:15:31.673091 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #650 | Collecting samples for evaluation
2017-06-11 00:15:44.405627 EDT | -----------------------  -----------
2017-06-11 00:15:44.406486 EDT | Epoch                     650
2017-06-11 00:15:44.406673 EDT | Iteration                 650
2017-06-11 00:15:44.406956 EDT | AverageReturn            1214.29
2017-06-11 00:15:44.407270 EDT | StdReturn                 397.428
2017-06-11 00:15:44.407448 EDT | MaxReturn                2470.08
2017-06-11 00:15:44.409590 EDT | MinReturn                 717.888
2017-06-11 00:15:44.410095 EDT | AverageEsReturn           584.637
2017-06-11 00:15:44.410270 EDT | StdEsReturn               590.852
2017-06-11 00:15:44.410531 EDT | MaxEsReturn              1729.53
2017-06-11 00:15:44.410775 EDT | MinEsReturn               145.518
2017-06-11 00:15:44.411257 EDT | AverageDiscountedReturn   243.977
2017-06-11 00:15:44.411646 EDT | AverageQLoss                2.19064
2017-06-11 00:15:44.411813 EDT | AveragePolicySurr         -31.1227
2017-06-11 00:15:44.411968 EDT | AverageQ                   30.7711
2017-06-11 00:15:44.412120 EDT | AverageAbsQ                30.7891
2017-06-11 00:15:44.412434 EDT | AverageY                   30.7757
2017-06-11 00:15:44.412616 EDT | AverageAbsY                30.7815
2017-06-11 00:15:44.412769 EDT | AverageAbsQYDiff            0.554521
2017-06-11 00:15:44.412919 EDT | AverageAction               0.986041
2017-06-11 00:15:44.413208 EDT | PolicyRegParamNorm         82.1699
2017-06-11 00:15:44.413460 EDT | QFunRegParamNorm          105.255
2017-06-11 00:15:44.414732 EDT | -----------------------  -----------
2017-06-11 00:15:44.415202 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #651 | Training started
2017-06-11 00:16:01.357336 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #651 | Training finished
2017-06-11 00:16:01.358372 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #651 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 00:16:01.358741 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #651 | Collecting samples for evaluation
2017-06-11 00:16:14.286920 EDT | -----------------------  -----------
2017-06-11 00:16:14.287857 EDT | Epoch                     651
2017-06-11 00:16:14.288229 EDT | Iteration                 651
2017-06-11 00:16:14.288578 EDT | AverageReturn             926.85
2017-06-11 00:16:14.288930 EDT | StdReturn                 300.09
2017-06-11 00:16:14.289279 EDT | MaxReturn                1894.55
2017-06-11 00:16:14.289621 EDT | MinReturn                  75.2014
2017-06-11 00:16:14.290246 EDT | AverageEsReturn           498.4
2017-06-11 00:16:14.290595 EDT | StdEsReturn               455.623
2017-06-11 00:16:14.290942 EDT | MaxEsReturn              1194.45
2017-06-11 00:16:14.291280 EDT | MinEsReturn                15.8767
2017-06-11 00:16:14.291624 EDT | AverageDiscountedReturn   225.363
2017-06-11 00:16:14.291971 EDT | AverageQLoss                2.15437
2017-06-11 00:16:14.292382 EDT | AveragePolicySurr         -31.1232
2017-06-11 00:16:14.292722 EDT | AverageQ                   30.7693
2017-06-11 00:16:14.293066 EDT | AverageAbsQ                30.7899
2017-06-11 00:16:14.293410 EDT | AverageY                   30.7688
2017-06-11 00:16:14.293762 EDT | AverageAbsY                30.7782
2017-06-11 00:16:14.294108 EDT | AverageAbsQYDiff            0.553239
2017-06-11 00:16:14.294454 EDT | AverageAction               0.985651
2017-06-11 00:16:14.294798 EDT | PolicyRegParamNorm         82.2355
2017-06-11 00:16:14.295138 EDT | QFunRegParamNorm          105.303
2017-06-11 00:16:14.295478 EDT | -----------------------  -----------
2017-06-11 00:16:14.296006 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #652 | Training started
2017-06-11 00:16:32.370489 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #652 | Training finished
2017-06-11 00:16:32.371404 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #652 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 00:16:32.371741 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #652 | Collecting samples for evaluation
2017-06-11 00:16:45.602621 EDT | -----------------------  -----------
2017-06-11 00:16:45.604508 EDT | Epoch                     652
2017-06-11 00:16:45.604802 EDT | Iteration                 652
2017-06-11 00:16:45.605060 EDT | AverageReturn             996.983
2017-06-11 00:16:45.605319 EDT | StdReturn                 390.344
2017-06-11 00:16:45.605618 EDT | MaxReturn                2107.55
2017-06-11 00:16:45.605939 EDT | MinReturn                 381.69
2017-06-11 00:16:45.606229 EDT | AverageEsReturn           353.643
2017-06-11 00:16:45.606530 EDT | StdEsReturn               333.056
2017-06-11 00:16:45.606853 EDT | MaxEsReturn               920.824
2017-06-11 00:16:45.607142 EDT | MinEsReturn                16.3609
2017-06-11 00:16:45.607421 EDT | AverageDiscountedReturn   216.627
2017-06-11 00:16:45.607860 EDT | AverageQLoss                2.71837
2017-06-11 00:16:45.608190 EDT | AveragePolicySurr         -31.0704
2017-06-11 00:16:45.608849 EDT | AverageQ                   30.7214
2017-06-11 00:16:45.609211 EDT | AverageAbsQ                30.7413
2017-06-11 00:16:45.609548 EDT | AverageY                   30.7215
2017-06-11 00:16:45.609913 EDT | AverageAbsY                30.7284
2017-06-11 00:16:45.610490 EDT | AverageAbsQYDiff            0.584651
2017-06-11 00:16:45.610921 EDT | AverageAction               0.985389
2017-06-11 00:16:45.611286 EDT | PolicyRegParamNorm         82.2603
2017-06-11 00:16:45.611641 EDT | QFunRegParamNorm          105.35
2017-06-11 00:16:45.611995 EDT | -----------------------  -----------
2017-06-11 00:16:45.612501 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #653 | Training started
2017-06-11 00:17:02.180075 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #653 | Training finished
2017-06-11 00:17:02.181386 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #653 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 00:17:02.181595 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #653 | Collecting samples for evaluation
2017-06-11 00:17:15.936855 EDT | -----------------------  -----------
2017-06-11 00:17:15.937920 EDT | Epoch                     653
2017-06-11 00:17:15.938118 EDT | Iteration                 653
2017-06-11 00:17:15.938326 EDT | AverageReturn             680.843
2017-06-11 00:17:15.938836 EDT | StdReturn                 159.512
2017-06-11 00:17:15.939210 EDT | MaxReturn                1481.39
2017-06-11 00:17:15.939574 EDT | MinReturn                 548.247
2017-06-11 00:17:15.940004 EDT | AverageEsReturn           273.98
2017-06-11 00:17:15.940470 EDT | StdEsReturn               193.846
2017-06-11 00:17:15.940851 EDT | MaxEsReturn               610.26
2017-06-11 00:17:15.941226 EDT | MinEsReturn                26.6249
2017-06-11 00:17:15.941689 EDT | AverageDiscountedReturn   217.814
2017-06-11 00:17:15.942158 EDT | AverageQLoss                2.53976
2017-06-11 00:17:15.942596 EDT | AveragePolicySurr         -31.144
2017-06-11 00:17:15.942972 EDT | AverageQ                   30.7776
2017-06-11 00:17:15.943355 EDT | AverageAbsQ                30.7995
2017-06-11 00:17:15.943766 EDT | AverageY                   30.7802
2017-06-11 00:17:15.944228 EDT | AverageAbsY                30.787
2017-06-11 00:17:15.944691 EDT | AverageAbsQYDiff            0.574443
2017-06-11 00:17:15.945134 EDT | AverageAction               0.985607
2017-06-11 00:17:15.945480 EDT | PolicyRegParamNorm         82.3505
2017-06-11 00:17:15.945957 EDT | QFunRegParamNorm          105.382
2017-06-11 00:17:15.946422 EDT | -----------------------  -----------
2017-06-11 00:17:15.947004 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #654 | Training started
2017-06-11 00:17:31.943633 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #654 | Training finished
2017-06-11 00:17:31.944431 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #654 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 00:17:31.944648 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #654 | Collecting samples for evaluation
2017-06-11 00:17:44.379455 EDT | -----------------------  -----------
2017-06-11 00:17:44.381072 EDT | Epoch                     654
2017-06-11 00:17:44.381453 EDT | Iteration                 654
2017-06-11 00:17:44.381830 EDT | AverageReturn             356.826
2017-06-11 00:17:44.382934 EDT | StdReturn                 361.228
2017-06-11 00:17:44.383315 EDT | MaxReturn                1288.78
2017-06-11 00:17:44.384772 EDT | MinReturn                  45.7461
2017-06-11 00:17:44.385098 EDT | AverageEsReturn           174.575
2017-06-11 00:17:44.385444 EDT | StdEsReturn               144.6
2017-06-11 00:17:44.385795 EDT | MaxEsReturn               467.039
2017-06-11 00:17:44.386139 EDT | MinEsReturn                17.7811
2017-06-11 00:17:44.386479 EDT | AverageDiscountedReturn   120.584
2017-06-11 00:17:44.386820 EDT | AverageQLoss                2.18746
2017-06-11 00:17:44.387232 EDT | AveragePolicySurr         -31.0504
2017-06-11 00:17:44.388845 EDT | AverageQ                   30.6898
2017-06-11 00:17:44.389208 EDT | AverageAbsQ                30.7082
2017-06-11 00:17:44.389652 EDT | AverageY                   30.6883
2017-06-11 00:17:44.390113 EDT | AverageAbsY                30.6936
2017-06-11 00:17:44.390557 EDT | AverageAbsQYDiff            0.554009
2017-06-11 00:17:44.391000 EDT | AverageAction               0.984134
2017-06-11 00:17:44.393001 EDT | PolicyRegParamNorm         82.3551
2017-06-11 00:17:44.394182 EDT | QFunRegParamNorm          105.446
2017-06-11 00:17:44.396106 EDT | -----------------------  -----------
2017-06-11 00:17:44.399377 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #655 | Training started
2017-06-11 00:17:59.804222 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #655 | Training finished
2017-06-11 00:17:59.805248 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #655 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 00:17:59.805644 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #655 | Collecting samples for evaluation
2017-06-11 00:18:13.517814 EDT | -----------------------  -----------
2017-06-11 00:18:13.518794 EDT | Epoch                     655
2017-06-11 00:18:13.519166 EDT | Iteration                 655
2017-06-11 00:18:13.519510 EDT | AverageReturn             649.231
2017-06-11 00:18:13.519853 EDT | StdReturn                 171.493
2017-06-11 00:18:13.520182 EDT | MaxReturn                1149.02
2017-06-11 00:18:13.520533 EDT | MinReturn                 470.718
2017-06-11 00:18:13.520877 EDT | AverageEsReturn           263.164
2017-06-11 00:18:13.521229 EDT | StdEsReturn               217.368
2017-06-11 00:18:13.521570 EDT | MaxEsReturn               562.844
2017-06-11 00:18:13.521932 EDT | MinEsReturn                33.1893
2017-06-11 00:18:13.522275 EDT | AverageDiscountedReturn   205.664
2017-06-11 00:18:13.522621 EDT | AverageQLoss                2.05858
2017-06-11 00:18:13.522971 EDT | AveragePolicySurr         -31.0944
2017-06-11 00:18:13.523327 EDT | AverageQ                   30.7457
2017-06-11 00:18:13.523675 EDT | AverageAbsQ                30.7639
2017-06-11 00:18:13.524012 EDT | AverageY                   30.7476
2017-06-11 00:18:13.524351 EDT | AverageAbsY                30.752
2017-06-11 00:18:13.524707 EDT | AverageAbsQYDiff            0.547061
2017-06-11 00:18:13.525047 EDT | AverageAction               0.983866
2017-06-11 00:18:13.525402 EDT | PolicyRegParamNorm         82.3886
2017-06-11 00:18:13.525757 EDT | QFunRegParamNorm          105.518
2017-06-11 00:18:13.526167 EDT | -----------------------  -----------
2017-06-11 00:18:13.526690 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #656 | Training started
2017-06-11 00:18:30.395754 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #656 | Training finished
2017-06-11 00:18:30.397211 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #656 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 00:18:30.397624 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #656 | Collecting samples for evaluation
2017-06-11 00:18:43.197177 EDT | -----------------------  ----------
2017-06-11 00:18:43.203218 EDT | Epoch                    656
2017-06-11 00:18:43.203492 EDT | Iteration                656
2017-06-11 00:18:43.203828 EDT | AverageReturn            586.516
2017-06-11 00:18:43.204152 EDT | StdReturn                132.498
2017-06-11 00:18:43.204484 EDT | MaxReturn                857.394
2017-06-11 00:18:43.204801 EDT | MinReturn                302.342
2017-06-11 00:18:43.206869 EDT | AverageEsReturn          317.023
2017-06-11 00:18:43.208239 EDT | StdEsReturn              196.447
2017-06-11 00:18:43.208550 EDT | MaxEsReturn              620.448
2017-06-11 00:18:43.208884 EDT | MinEsReturn               60.68
2017-06-11 00:18:43.209183 EDT | AverageDiscountedReturn  199.043
2017-06-11 00:18:43.209478 EDT | AverageQLoss               2.09452
2017-06-11 00:18:43.209817 EDT | AveragePolicySurr        -31.032
2017-06-11 00:18:43.210168 EDT | AverageQ                  30.6615
2017-06-11 00:18:43.210395 EDT | AverageAbsQ               30.6821
2017-06-11 00:18:43.210555 EDT | AverageY                  30.6621
2017-06-11 00:18:43.210727 EDT | AverageAbsY               30.6706
2017-06-11 00:18:43.210952 EDT | AverageAbsQYDiff           0.555883
2017-06-11 00:18:43.211107 EDT | AverageAction              0.982747
2017-06-11 00:18:43.211388 EDT | PolicyRegParamNorm        82.4818
2017-06-11 00:18:43.211705 EDT | QFunRegParamNorm         105.599
2017-06-11 00:18:43.212022 EDT | -----------------------  ----------
2017-06-11 00:18:43.212514 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #657 | Training started
2017-06-11 00:19:00.255931 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #657 | Training finished
2017-06-11 00:19:00.256961 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #657 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 00:19:00.257389 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #657 | Collecting samples for evaluation
2017-06-11 00:19:14.258631 EDT | -----------------------  -----------
2017-06-11 00:19:14.259550 EDT | Epoch                     657
2017-06-11 00:19:14.259833 EDT | Iteration                 657
2017-06-11 00:19:14.260087 EDT | AverageReturn             738.651
2017-06-11 00:19:14.260335 EDT | StdReturn                 139.307
2017-06-11 00:19:14.260588 EDT | MaxReturn                1055.83
2017-06-11 00:19:14.260831 EDT | MinReturn                 509.649
2017-06-11 00:19:14.261073 EDT | AverageEsReturn           348.023
2017-06-11 00:19:14.261315 EDT | StdEsReturn               251.734
2017-06-11 00:19:14.261558 EDT | MaxEsReturn               628.177
2017-06-11 00:19:14.261822 EDT | MinEsReturn                 7.73728
2017-06-11 00:19:14.262065 EDT | AverageDiscountedReturn   218.699
2017-06-11 00:19:14.262307 EDT | AverageQLoss                2.44859
2017-06-11 00:19:14.262549 EDT | AveragePolicySurr         -31.0708
2017-06-11 00:19:14.262789 EDT | AverageQ                   30.6996
2017-06-11 00:19:14.263029 EDT | AverageAbsQ                30.7196
2017-06-11 00:19:14.263270 EDT | AverageY                   30.7012
2017-06-11 00:19:14.263514 EDT | AverageAbsY                30.7068
2017-06-11 00:19:14.263755 EDT | AverageAbsQYDiff            0.574957
2017-06-11 00:19:14.264000 EDT | AverageAction               0.983872
2017-06-11 00:19:14.264241 EDT | PolicyRegParamNorm         82.5465
2017-06-11 00:19:14.264480 EDT | QFunRegParamNorm          105.632
2017-06-11 00:19:14.264729 EDT | -----------------------  -----------
2017-06-11 00:19:14.265124 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #658 | Training started
2017-06-11 00:19:29.419624 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #658 | Training finished
2017-06-11 00:19:29.419917 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #658 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 00:19:29.420142 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #658 | Collecting samples for evaluation
2017-06-11 00:19:44.076995 EDT | -----------------------  -----------
2017-06-11 00:19:44.077895 EDT | Epoch                     658
2017-06-11 00:19:44.079143 EDT | Iteration                 658
2017-06-11 00:19:44.079320 EDT | AverageReturn            1632.16
2017-06-11 00:19:44.079514 EDT | StdReturn                 672.234
2017-06-11 00:19:44.079807 EDT | MaxReturn                2433.53
2017-06-11 00:19:44.079992 EDT | MinReturn                 303.761
2017-06-11 00:19:44.080174 EDT | AverageEsReturn           532.95
2017-06-11 00:19:44.080357 EDT | StdEsReturn               283.67
2017-06-11 00:19:44.080537 EDT | MaxEsReturn               925.311
2017-06-11 00:19:44.080716 EDT | MinEsReturn                68.4219
2017-06-11 00:19:44.080903 EDT | AverageDiscountedReturn   208.615
2017-06-11 00:19:44.081081 EDT | AverageQLoss                2.64067
2017-06-11 00:19:44.081259 EDT | AveragePolicySurr         -31.0492
2017-06-11 00:19:44.081437 EDT | AverageQ                   30.6903
2017-06-11 00:19:44.081615 EDT | AverageAbsQ                30.711
2017-06-11 00:19:44.081807 EDT | AverageY                   30.69
2017-06-11 00:19:44.081991 EDT | AverageAbsY                30.6971
2017-06-11 00:19:44.082170 EDT | AverageAbsQYDiff            0.592235
2017-06-11 00:19:44.082447 EDT | AverageAction               0.987113
2017-06-11 00:19:44.082684 EDT | PolicyRegParamNorm         82.5553
2017-06-11 00:19:44.082895 EDT | QFunRegParamNorm          105.651
2017-06-11 00:19:44.083077 EDT | -----------------------  -----------
2017-06-11 00:19:44.083373 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #659 | Training started
2017-06-11 00:20:00.636009 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #659 | Training finished
2017-06-11 00:20:00.636961 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #659 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 00:20:00.637337 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #659 | Collecting samples for evaluation
2017-06-11 00:20:13.855661 EDT | -----------------------  -----------
2017-06-11 00:20:13.856579 EDT | Epoch                     659
2017-06-11 00:20:13.856889 EDT | Iteration                 659
2017-06-11 00:20:13.857217 EDT | AverageReturn             765.026
2017-06-11 00:20:13.857469 EDT | StdReturn                 203.407
2017-06-11 00:20:13.861918 EDT | MaxReturn                1257.6
2017-06-11 00:20:13.862213 EDT | MinReturn                 539.662
2017-06-11 00:20:13.862475 EDT | AverageEsReturn           399.294
2017-06-11 00:20:13.862731 EDT | StdEsReturn               248.869
2017-06-11 00:20:13.862946 EDT | MaxEsReturn               676.316
2017-06-11 00:20:13.863098 EDT | MinEsReturn                71.374
2017-06-11 00:20:13.863281 EDT | AverageDiscountedReturn   219.484
2017-06-11 00:20:13.863550 EDT | AverageQLoss                2.08592
2017-06-11 00:20:13.863723 EDT | AveragePolicySurr         -31.0356
2017-06-11 00:20:13.863903 EDT | AverageQ                   30.6526
2017-06-11 00:20:13.864060 EDT | AverageAbsQ                30.6759
2017-06-11 00:20:13.864260 EDT | AverageY                   30.6553
2017-06-11 00:20:13.864435 EDT | AverageAbsY                30.6635
2017-06-11 00:20:13.864607 EDT | AverageAbsQYDiff            0.559703
2017-06-11 00:20:13.864764 EDT | AverageAction               0.985637
2017-06-11 00:20:13.864979 EDT | PolicyRegParamNorm         82.572
2017-06-11 00:20:13.865142 EDT | QFunRegParamNorm          105.705
2017-06-11 00:20:13.867016 EDT | -----------------------  -----------
2017-06-11 00:20:13.867817 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #660 | Training started
2017-06-11 00:20:29.285995 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #660 | Training finished
2017-06-11 00:20:29.286959 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #660 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 00:20:29.287164 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #660 | Collecting samples for evaluation
2017-06-11 00:20:41.877454 EDT | -----------------------  -----------
2017-06-11 00:20:41.878578 EDT | Epoch                     660
2017-06-11 00:20:41.878784 EDT | Iteration                 660
2017-06-11 00:20:41.878948 EDT | AverageReturn             559.272
2017-06-11 00:20:41.879104 EDT | StdReturn                  59.3954
2017-06-11 00:20:41.879365 EDT | MaxReturn                 696.978
2017-06-11 00:20:41.879733 EDT | MinReturn                 379.009
2017-06-11 00:20:41.880168 EDT | AverageEsReturn           670.022
2017-06-11 00:20:41.880535 EDT | StdEsReturn               483.51
2017-06-11 00:20:41.880874 EDT | MaxEsReturn              1327.25
2017-06-11 00:20:41.881211 EDT | MinEsReturn                16.827
2017-06-11 00:20:41.881550 EDT | AverageDiscountedReturn   200.613
2017-06-11 00:20:41.881901 EDT | AverageQLoss                2.56894
2017-06-11 00:20:41.882221 EDT | AveragePolicySurr         -31.0065
2017-06-11 00:20:41.882550 EDT | AverageQ                   30.6365
2017-06-11 00:20:41.882940 EDT | AverageAbsQ                30.6571
2017-06-11 00:20:41.883318 EDT | AverageY                   30.6373
2017-06-11 00:20:41.883504 EDT | AverageAbsY                30.6471
2017-06-11 00:20:41.883690 EDT | AverageAbsQYDiff            0.585076
2017-06-11 00:20:41.883874 EDT | AverageAction               0.986515
2017-06-11 00:20:41.884056 EDT | PolicyRegParamNorm         82.6164
2017-06-11 00:20:41.884236 EDT | QFunRegParamNorm          105.75
2017-06-11 00:20:41.884555 EDT | -----------------------  -----------
2017-06-11 00:20:41.884868 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #661 | Training started
2017-06-11 00:20:56.730742 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #661 | Training finished
2017-06-11 00:20:56.731695 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #661 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 00:20:56.732050 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #661 | Collecting samples for evaluation
2017-06-11 00:21:10.294397 EDT | -----------------------  -----------
2017-06-11 00:21:10.297713 EDT | Epoch                     661
2017-06-11 00:21:10.298087 EDT | Iteration                 661
2017-06-11 00:21:10.298422 EDT | AverageReturn             650.153
2017-06-11 00:21:10.298740 EDT | StdReturn                 109.475
2017-06-11 00:21:10.299060 EDT | MaxReturn                1045.49
2017-06-11 00:21:10.299363 EDT | MinReturn                 437.601
2017-06-11 00:21:10.299667 EDT | AverageEsReturn           318.329
2017-06-11 00:21:10.299991 EDT | StdEsReturn               221.118
2017-06-11 00:21:10.300199 EDT | MaxEsReturn               673.275
2017-06-11 00:21:10.300511 EDT | MinEsReturn                54.8044
2017-06-11 00:21:10.300832 EDT | AverageDiscountedReturn   200.841
2017-06-11 00:21:10.301151 EDT | AverageQLoss                2.25716
2017-06-11 00:21:10.301719 EDT | AveragePolicySurr         -30.914
2017-06-11 00:21:10.302035 EDT | AverageQ                   30.5609
2017-06-11 00:21:10.302270 EDT | AverageAbsQ                30.5813
2017-06-11 00:21:10.302426 EDT | AverageY                   30.5612
2017-06-11 00:21:10.302579 EDT | AverageAbsY                30.5694
2017-06-11 00:21:10.302769 EDT | AverageAbsQYDiff            0.565082
2017-06-11 00:21:10.303019 EDT | AverageAction               0.985719
2017-06-11 00:21:10.303195 EDT | PolicyRegParamNorm         82.6617
2017-06-11 00:21:10.303345 EDT | QFunRegParamNorm          105.803
2017-06-11 00:21:10.303493 EDT | -----------------------  -----------
2017-06-11 00:21:10.303802 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #662 | Training started
2017-06-11 00:21:26.797751 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #662 | Training finished
2017-06-11 00:21:26.798726 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #662 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 00:21:26.799115 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #662 | Collecting samples for evaluation
2017-06-11 00:21:39.542720 EDT | -----------------------  -----------
2017-06-11 00:21:39.543926 EDT | Epoch                     662
2017-06-11 00:21:39.544228 EDT | Iteration                 662
2017-06-11 00:21:39.544523 EDT | AverageReturn             522.939
2017-06-11 00:21:39.545095 EDT | StdReturn                 216.784
2017-06-11 00:21:39.545284 EDT | MaxReturn                1104.23
2017-06-11 00:21:39.545466 EDT | MinReturn                 190.166
2017-06-11 00:21:39.545658 EDT | AverageEsReturn           384.913
2017-06-11 00:21:39.545947 EDT | StdEsReturn               288.877
2017-06-11 00:21:39.546176 EDT | MaxEsReturn               815.838
2017-06-11 00:21:39.547719 EDT | MinEsReturn                67.7382
2017-06-11 00:21:39.548073 EDT | AverageDiscountedReturn   184.415
2017-06-11 00:21:39.548422 EDT | AverageQLoss                2.07444
2017-06-11 00:21:39.548734 EDT | AveragePolicySurr         -31.1263
2017-06-11 00:21:39.549035 EDT | AverageQ                   30.7551
2017-06-11 00:21:39.549316 EDT | AverageAbsQ                30.7757
2017-06-11 00:21:39.549521 EDT | AverageY                   30.7564
2017-06-11 00:21:39.549716 EDT | AverageAbsY                30.7645
2017-06-11 00:21:39.549916 EDT | AverageAbsQYDiff            0.56064
2017-06-11 00:21:39.550181 EDT | AverageAction               0.988734
2017-06-11 00:21:39.550365 EDT | PolicyRegParamNorm         82.6886
2017-06-11 00:21:39.550607 EDT | QFunRegParamNorm          105.851
2017-06-11 00:21:39.550873 EDT | -----------------------  -----------
2017-06-11 00:21:39.551403 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #663 | Training started
2017-06-11 00:21:56.468339 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #663 | Training finished
2017-06-11 00:21:56.469288 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #663 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 00:21:56.469644 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #663 | Collecting samples for evaluation
2017-06-11 00:22:09.640737 EDT | -----------------------  -----------
2017-06-11 00:22:09.642668 EDT | Epoch                     663
2017-06-11 00:22:09.643164 EDT | Iteration                 663
2017-06-11 00:22:09.643636 EDT | AverageReturn             624.698
2017-06-11 00:22:09.644113 EDT | StdReturn                 135.08
2017-06-11 00:22:09.644583 EDT | MaxReturn                1276.2
2017-06-11 00:22:09.645047 EDT | MinReturn                 440.328
2017-06-11 00:22:09.645518 EDT | AverageEsReturn           387.337
2017-06-11 00:22:09.646010 EDT | StdEsReturn               364.776
2017-06-11 00:22:09.646476 EDT | MaxEsReturn              1194.85
2017-06-11 00:22:09.646942 EDT | MinEsReturn                45.5098
2017-06-11 00:22:09.647412 EDT | AverageDiscountedReturn   208.873
2017-06-11 00:22:09.647877 EDT | AverageQLoss                2.38294
2017-06-11 00:22:09.648342 EDT | AveragePolicySurr         -30.9855
2017-06-11 00:22:09.648815 EDT | AverageQ                   30.6382
2017-06-11 00:22:09.649284 EDT | AverageAbsQ                30.6553
2017-06-11 00:22:09.649757 EDT | AverageY                   30.6399
2017-06-11 00:22:09.650225 EDT | AverageAbsY                30.6465
2017-06-11 00:22:09.650697 EDT | AverageAbsQYDiff            0.563339
2017-06-11 00:22:09.651158 EDT | AverageAction               0.986411
2017-06-11 00:22:09.651624 EDT | PolicyRegParamNorm         82.8069
2017-06-11 00:22:09.652089 EDT | QFunRegParamNorm          105.912
2017-06-11 00:22:09.652548 EDT | -----------------------  -----------
2017-06-11 00:22:09.653144 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #664 | Training started
2017-06-11 00:22:25.133519 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #664 | Training finished
2017-06-11 00:22:25.134127 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #664 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 00:22:25.134333 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #664 | Collecting samples for evaluation
2017-06-11 00:22:37.835284 EDT | -----------------------  -----------
2017-06-11 00:22:37.836989 EDT | Epoch                     664
2017-06-11 00:22:37.837327 EDT | Iteration                 664
2017-06-11 00:22:37.837677 EDT | AverageReturn             708.466
2017-06-11 00:22:37.838085 EDT | StdReturn                 339.695
2017-06-11 00:22:37.838623 EDT | MaxReturn                1986.93
2017-06-11 00:22:37.838915 EDT | MinReturn                 455.323
2017-06-11 00:22:37.839181 EDT | AverageEsReturn           285.364
2017-06-11 00:22:37.839384 EDT | StdEsReturn               221.722
2017-06-11 00:22:37.839577 EDT | MaxEsReturn               621.245
2017-06-11 00:22:37.839863 EDT | MinEsReturn                21.994
2017-06-11 00:22:37.840061 EDT | AverageDiscountedReturn   201.71
2017-06-11 00:22:37.840256 EDT | AverageQLoss                2.50319
2017-06-11 00:22:37.840449 EDT | AveragePolicySurr         -31.0074
2017-06-11 00:22:37.840651 EDT | AverageQ                   30.6164
2017-06-11 00:22:37.840845 EDT | AverageAbsQ                30.6402
2017-06-11 00:22:37.841047 EDT | AverageY                   30.6169
2017-06-11 00:22:37.841241 EDT | AverageAbsY                30.6263
2017-06-11 00:22:37.841600 EDT | AverageAbsQYDiff            0.581665
2017-06-11 00:22:37.841828 EDT | AverageAction               0.986637
2017-06-11 00:22:37.841993 EDT | PolicyRegParamNorm         82.8486
2017-06-11 00:22:37.842484 EDT | QFunRegParamNorm          105.94
2017-06-11 00:22:37.842800 EDT | -----------------------  -----------
2017-06-11 00:22:37.843177 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #665 | Training started
2017-06-11 00:22:53.267478 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #665 | Training finished
2017-06-11 00:22:53.268284 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #665 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 00:22:53.268505 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #665 | Collecting samples for evaluation
2017-06-11 00:23:07.212540 EDT | -----------------------  -----------
2017-06-11 00:23:07.213490 EDT | Epoch                     665
2017-06-11 00:23:07.213873 EDT | Iteration                 665
2017-06-11 00:23:07.214221 EDT | AverageReturn             830.97
2017-06-11 00:23:07.214578 EDT | StdReturn                 322.354
2017-06-11 00:23:07.214927 EDT | MaxReturn                2017.29
2017-06-11 00:23:07.215272 EDT | MinReturn                 306.587
2017-06-11 00:23:07.215610 EDT | AverageEsReturn           287.512
2017-06-11 00:23:07.215953 EDT | StdEsReturn               247.958
2017-06-11 00:23:07.216292 EDT | MaxEsReturn               676.708
2017-06-11 00:23:07.216633 EDT | MinEsReturn                27.5799
2017-06-11 00:23:07.216974 EDT | AverageDiscountedReturn   213.089
2017-06-11 00:23:07.217315 EDT | AverageQLoss                2.38142
2017-06-11 00:23:07.217656 EDT | AveragePolicySurr         -31.0486
2017-06-11 00:23:07.218012 EDT | AverageQ                   30.674
2017-06-11 00:23:07.218355 EDT | AverageAbsQ                30.6993
2017-06-11 00:23:07.223116 EDT | AverageY                   30.6736
2017-06-11 00:23:07.223518 EDT | AverageAbsY                30.6843
2017-06-11 00:23:07.224379 EDT | AverageAbsQYDiff            0.563058
2017-06-11 00:23:07.224750 EDT | AverageAction               0.988512
2017-06-11 00:23:07.226976 EDT | PolicyRegParamNorm         82.8219
2017-06-11 00:23:07.227446 EDT | QFunRegParamNorm          106.02
2017-06-11 00:23:07.227899 EDT | -----------------------  -----------
2017-06-11 00:23:07.229685 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #666 | Training started
2017-06-11 00:23:22.608582 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #666 | Training finished
2017-06-11 00:23:22.612896 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #666 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 00:23:22.613326 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #666 | Collecting samples for evaluation
2017-06-11 00:23:35.860062 EDT | -----------------------  -----------
2017-06-11 00:23:35.860803 EDT | Epoch                     666
2017-06-11 00:23:35.861095 EDT | Iteration                 666
2017-06-11 00:23:35.861425 EDT | AverageReturn            1163.28
2017-06-11 00:23:35.861853 EDT | StdReturn                 740.182
2017-06-11 00:23:35.863196 EDT | MaxReturn                2896.17
2017-06-11 00:23:35.863574 EDT | MinReturn                 307.425
2017-06-11 00:23:35.863932 EDT | AverageEsReturn           384.911
2017-06-11 00:23:35.864217 EDT | StdEsReturn               212.367
2017-06-11 00:23:35.864557 EDT | MaxEsReturn               651.768
2017-06-11 00:23:35.864888 EDT | MinEsReturn               104.812
2017-06-11 00:23:35.865209 EDT | AverageDiscountedReturn   223.838
2017-06-11 00:23:35.865497 EDT | AverageQLoss                2.83061
2017-06-11 00:23:35.866059 EDT | AveragePolicySurr         -30.9363
2017-06-11 00:23:35.866345 EDT | AverageQ                   30.5421
2017-06-11 00:23:35.866645 EDT | AverageAbsQ                30.5708
2017-06-11 00:23:35.866970 EDT | AverageY                   30.5442
2017-06-11 00:23:35.867262 EDT | AverageAbsY                30.5577
2017-06-11 00:23:35.867578 EDT | AverageAbsQYDiff            0.605936
2017-06-11 00:23:35.868088 EDT | AverageAction               0.989773
2017-06-11 00:23:35.868451 EDT | PolicyRegParamNorm         82.8379
2017-06-11 00:23:35.868800 EDT | QFunRegParamNorm          106.093
2017-06-11 00:23:35.869127 EDT | -----------------------  -----------
2017-06-11 00:23:35.869615 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #667 | Training started
2017-06-11 00:23:51.701922 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #667 | Training finished
2017-06-11 00:23:51.702985 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #667 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 00:23:51.703374 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #667 | Collecting samples for evaluation
2017-06-11 00:24:03.836339 EDT | -----------------------  ----------
2017-06-11 00:24:03.837654 EDT | Epoch                    667
2017-06-11 00:24:03.837900 EDT | Iteration                667
2017-06-11 00:24:03.838106 EDT | AverageReturn            369.445
2017-06-11 00:24:03.838302 EDT | StdReturn                192.449
2017-06-11 00:24:03.838496 EDT | MaxReturn                927.002
2017-06-11 00:24:03.838799 EDT | MinReturn                182.278
2017-06-11 00:24:03.838991 EDT | AverageEsReturn          348.341
2017-06-11 00:24:03.839187 EDT | StdEsReturn              232.85
2017-06-11 00:24:03.839428 EDT | MaxEsReturn              859.544
2017-06-11 00:24:03.839672 EDT | MinEsReturn               18.1629
2017-06-11 00:24:03.839937 EDT | AverageDiscountedReturn  164.834
2017-06-11 00:24:03.840139 EDT | AverageQLoss               2.33446
2017-06-11 00:24:03.840329 EDT | AveragePolicySurr        -30.9914
2017-06-11 00:24:03.840519 EDT | AverageQ                  30.6176
2017-06-11 00:24:03.840742 EDT | AverageAbsQ               30.6426
2017-06-11 00:24:03.841151 EDT | AverageY                  30.6184
2017-06-11 00:24:03.841352 EDT | AverageAbsY               30.6314
2017-06-11 00:24:03.841548 EDT | AverageAbsQYDiff           0.565002
2017-06-11 00:24:03.841913 EDT | AverageAction              0.99154
2017-06-11 00:24:03.842283 EDT | PolicyRegParamNorm        82.8659
2017-06-11 00:24:03.842639 EDT | QFunRegParamNorm         106.148
2017-06-11 00:24:03.842999 EDT | -----------------------  ----------
2017-06-11 00:24:03.843511 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #668 | Training started
2017-06-11 00:24:19.293276 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #668 | Training finished
2017-06-11 00:24:19.294260 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #668 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 00:24:19.294661 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #668 | Collecting samples for evaluation
2017-06-11 00:24:32.556873 EDT | -----------------------  -----------
2017-06-11 00:24:32.557686 EDT | Epoch                     668
2017-06-11 00:24:32.557994 EDT | Iteration                 668
2017-06-11 00:24:32.558284 EDT | AverageReturn            1200.1
2017-06-11 00:24:32.558570 EDT | StdReturn                 674.454
2017-06-11 00:24:32.558854 EDT | MaxReturn                3162.19
2017-06-11 00:24:32.559132 EDT | MinReturn                 293.72
2017-06-11 00:24:32.559383 EDT | AverageEsReturn           222.751
2017-06-11 00:24:32.559626 EDT | StdEsReturn               210.437
2017-06-11 00:24:32.559867 EDT | MaxEsReturn               618.245
2017-06-11 00:24:32.560117 EDT | MinEsReturn                65.507
2017-06-11 00:24:32.560378 EDT | AverageDiscountedReturn   240.905
2017-06-11 00:24:32.560622 EDT | AverageQLoss                2.50251
2017-06-11 00:24:32.560876 EDT | AveragePolicySurr         -31.047
2017-06-11 00:24:32.561133 EDT | AverageQ                   30.6784
2017-06-11 00:24:32.561467 EDT | AverageAbsQ                30.7106
2017-06-11 00:24:32.561864 EDT | AverageY                   30.6793
2017-06-11 00:24:32.562248 EDT | AverageAbsY                30.6966
2017-06-11 00:24:32.562548 EDT | AverageAbsQYDiff            0.584831
2017-06-11 00:24:32.562876 EDT | AverageAction               0.989013
2017-06-11 00:24:32.563116 EDT | PolicyRegParamNorm         82.8771
2017-06-11 00:24:32.563332 EDT | QFunRegParamNorm          106.279
2017-06-11 00:24:32.563539 EDT | -----------------------  -----------
2017-06-11 00:24:32.563861 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #669 | Training started
2017-06-11 00:24:47.451809 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #669 | Training finished
2017-06-11 00:24:47.453133 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #669 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 00:24:47.453452 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #669 | Collecting samples for evaluation
2017-06-11 00:25:00.286183 EDT | -----------------------  -----------
2017-06-11 00:25:00.296960 EDT | Epoch                     669
2017-06-11 00:25:00.297737 EDT | Iteration                 669
2017-06-11 00:25:00.298229 EDT | AverageReturn             930.83
2017-06-11 00:25:00.299251 EDT | StdReturn                 449.932
2017-06-11 00:25:00.300036 EDT | MaxReturn                1775.19
2017-06-11 00:25:00.300526 EDT | MinReturn                 305.458
2017-06-11 00:25:00.301006 EDT | AverageEsReturn           397.917
2017-06-11 00:25:00.301483 EDT | StdEsReturn               261.52
2017-06-11 00:25:00.301964 EDT | MaxEsReturn               809.169
2017-06-11 00:25:00.302440 EDT | MinEsReturn                54.9772
2017-06-11 00:25:00.303211 EDT | AverageDiscountedReturn   208.71
2017-06-11 00:25:00.303692 EDT | AverageQLoss                2.77815
2017-06-11 00:25:00.305415 EDT | AveragePolicySurr         -30.9708
2017-06-11 00:25:00.307277 EDT | AverageQ                   30.5973
2017-06-11 00:25:00.307768 EDT | AverageAbsQ                30.6287
2017-06-11 00:25:00.310693 EDT | AverageY                   30.598
2017-06-11 00:25:00.311105 EDT | AverageAbsY                30.6174
2017-06-11 00:25:00.311489 EDT | AverageAbsQYDiff            0.597032
2017-06-11 00:25:00.311869 EDT | AverageAction               0.989158
2017-06-11 00:25:00.312244 EDT | PolicyRegParamNorm         82.9741
2017-06-11 00:25:00.312624 EDT | QFunRegParamNorm          106.316
2017-06-11 00:25:00.313002 EDT | -----------------------  -----------
2017-06-11 00:25:00.313518 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #670 | Training started
2017-06-11 00:25:16.158417 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #670 | Training finished
2017-06-11 00:25:16.160234 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #670 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 00:25:16.160595 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #670 | Collecting samples for evaluation
2017-06-11 00:25:30.418699 EDT | -----------------------  -----------
2017-06-11 00:25:30.419956 EDT | Epoch                     670
2017-06-11 00:25:30.420430 EDT | Iteration                 670
2017-06-11 00:25:30.420808 EDT | AverageReturn            1936.09
2017-06-11 00:25:30.421236 EDT | StdReturn                 488.187
2017-06-11 00:25:30.421672 EDT | MaxReturn                2348.54
2017-06-11 00:25:30.422067 EDT | MinReturn                1065.38
2017-06-11 00:25:30.422495 EDT | AverageEsReturn           553.557
2017-06-11 00:25:30.422921 EDT | StdEsReturn               604.596
2017-06-11 00:25:30.423272 EDT | MaxEsReturn              1700.68
2017-06-11 00:25:30.423613 EDT | MinEsReturn                22.3332
2017-06-11 00:25:30.423968 EDT | AverageDiscountedReturn   212.13
2017-06-11 00:25:30.424295 EDT | AverageQLoss                2.53843
2017-06-11 00:25:30.424569 EDT | AveragePolicySurr         -31.0813
2017-06-11 00:25:30.424909 EDT | AverageQ                   30.7122
2017-06-11 00:25:30.425341 EDT | AverageAbsQ                30.7425
2017-06-11 00:25:30.425738 EDT | AverageY                   30.7124
2017-06-11 00:25:30.426134 EDT | AverageAbsY                30.7297
2017-06-11 00:25:30.426566 EDT | AverageAbsQYDiff            0.580788
2017-06-11 00:25:30.426957 EDT | AverageAction               0.988064
2017-06-11 00:25:30.427226 EDT | PolicyRegParamNorm         83.0152
2017-06-11 00:25:30.427553 EDT | QFunRegParamNorm          106.406
2017-06-11 00:25:30.427898 EDT | -----------------------  -----------
2017-06-11 00:25:30.428389 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #671 | Training started
2017-06-11 00:25:46.288790 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #671 | Training finished
2017-06-11 00:25:46.290524 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #671 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 00:25:46.290920 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #671 | Collecting samples for evaluation
2017-06-11 00:25:58.273352 EDT | -----------------------  -----------
2017-06-11 00:25:58.275916 EDT | Epoch                     671
2017-06-11 00:25:58.276276 EDT | Iteration                 671
2017-06-11 00:25:58.277051 EDT | AverageReturn             977.713
2017-06-11 00:25:58.277610 EDT | StdReturn                 320.667
2017-06-11 00:25:58.278024 EDT | MaxReturn                1546.62
2017-06-11 00:25:58.278393 EDT | MinReturn                 491.775
2017-06-11 00:25:58.278921 EDT | AverageEsReturn           435.402
2017-06-11 00:25:58.279341 EDT | StdEsReturn               386.646
2017-06-11 00:25:58.279916 EDT | MaxEsReturn              1015.91
2017-06-11 00:25:58.280351 EDT | MinEsReturn                 7.06011
2017-06-11 00:25:58.280876 EDT | AverageDiscountedReturn   221.68
2017-06-11 00:25:58.281239 EDT | AverageQLoss                2.34532
2017-06-11 00:25:58.281892 EDT | AveragePolicySurr         -31.0184
2017-06-11 00:25:58.282288 EDT | AverageQ                   30.6318
2017-06-11 00:25:58.282998 EDT | AverageAbsQ                30.6585
2017-06-11 00:25:58.283548 EDT | AverageY                   30.6326
2017-06-11 00:25:58.283901 EDT | AverageAbsY                30.6455
2017-06-11 00:25:58.284408 EDT | AverageAbsQYDiff            0.584555
2017-06-11 00:25:58.284846 EDT | AverageAction               0.989256
2017-06-11 00:25:58.285206 EDT | PolicyRegParamNorm         83.0752
2017-06-11 00:25:58.285714 EDT | QFunRegParamNorm          106.505
2017-06-11 00:25:58.286059 EDT | -----------------------  -----------
2017-06-11 00:25:58.286612 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #672 | Training started
2017-06-11 00:26:14.769595 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #672 | Training finished
2017-06-11 00:26:14.770804 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #672 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 00:26:14.771014 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #672 | Collecting samples for evaluation
2017-06-11 00:26:27.675426 EDT | -----------------------  -----------
2017-06-11 00:26:27.676325 EDT | Epoch                     672
2017-06-11 00:26:27.676644 EDT | Iteration                 672
2017-06-11 00:26:27.676942 EDT | AverageReturn             962.195
2017-06-11 00:26:27.677236 EDT | StdReturn                 253.692
2017-06-11 00:26:27.677505 EDT | MaxReturn                1516.78
2017-06-11 00:26:27.677819 EDT | MinReturn                 506.168
2017-06-11 00:26:27.682051 EDT | AverageEsReturn           452.236
2017-06-11 00:26:27.682913 EDT | StdEsReturn               327.48
2017-06-11 00:26:27.683188 EDT | MaxEsReturn               908.888
2017-06-11 00:26:27.683680 EDT | MinEsReturn                77.4982
2017-06-11 00:26:27.683960 EDT | AverageDiscountedReturn   224.408
2017-06-11 00:26:27.684260 EDT | AverageQLoss                2.47817
2017-06-11 00:26:27.684574 EDT | AveragePolicySurr         -31.1559
2017-06-11 00:26:27.684866 EDT | AverageQ                   30.8042
2017-06-11 00:26:27.685162 EDT | AverageAbsQ                30.8259
2017-06-11 00:26:27.685453 EDT | AverageY                   30.8057
2017-06-11 00:26:27.685775 EDT | AverageAbsY                30.8146
2017-06-11 00:26:27.686065 EDT | AverageAbsQYDiff            0.57906
2017-06-11 00:26:27.686364 EDT | AverageAction               0.989708
2017-06-11 00:26:27.686679 EDT | PolicyRegParamNorm         83.1123
2017-06-11 00:26:27.686949 EDT | QFunRegParamNorm          106.591
2017-06-11 00:26:27.687214 EDT | -----------------------  -----------
2017-06-11 00:26:27.687668 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #673 | Training started
2017-06-11 00:26:43.309497 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #673 | Training finished
2017-06-11 00:26:43.310473 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #673 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 00:26:43.310887 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #673 | Collecting samples for evaluation
2017-06-11 00:26:56.614075 EDT | -----------------------  -----------
2017-06-11 00:26:56.614987 EDT | Epoch                     673
2017-06-11 00:26:56.615339 EDT | Iteration                 673
2017-06-11 00:26:56.615688 EDT | AverageReturn             790.409
2017-06-11 00:26:56.616113 EDT | StdReturn                 313.54
2017-06-11 00:26:56.616425 EDT | MaxReturn                1765.43
2017-06-11 00:26:56.616765 EDT | MinReturn                 470.457
2017-06-11 00:26:56.617118 EDT | AverageEsReturn           467.515
2017-06-11 00:26:56.617829 EDT | StdEsReturn               259.553
2017-06-11 00:26:56.618369 EDT | MaxEsReturn               705.03
2017-06-11 00:26:56.618805 EDT | MinEsReturn                97.4856
2017-06-11 00:26:56.619242 EDT | AverageDiscountedReturn   216.912
2017-06-11 00:26:56.619740 EDT | AverageQLoss                2.08944
2017-06-11 00:26:56.620174 EDT | AveragePolicySurr         -31.0096
2017-06-11 00:26:56.620808 EDT | AverageQ                   30.628
2017-06-11 00:26:56.621251 EDT | AverageAbsQ                30.6494
2017-06-11 00:26:56.621913 EDT | AverageY                   30.6291
2017-06-11 00:26:56.622360 EDT | AverageAbsY                30.6386
2017-06-11 00:26:56.622910 EDT | AverageAbsQYDiff            0.55231
2017-06-11 00:26:56.623339 EDT | AverageAction               0.988633
2017-06-11 00:26:56.623843 EDT | PolicyRegParamNorm         83.1198
2017-06-11 00:26:56.624249 EDT | QFunRegParamNorm          106.643
2017-06-11 00:26:56.624677 EDT | -----------------------  -----------
2017-06-11 00:26:56.625333 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #674 | Training started
2017-06-11 00:27:11.239445 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #674 | Training finished
2017-06-11 00:27:11.240236 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #674 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 00:27:11.240441 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #674 | Collecting samples for evaluation
2017-06-11 00:27:23.738259 EDT | -----------------------  -----------
2017-06-11 00:27:23.740809 EDT | Epoch                     674
2017-06-11 00:27:23.741175 EDT | Iteration                 674
2017-06-11 00:27:23.741482 EDT | AverageReturn             726.487
2017-06-11 00:27:23.741752 EDT | StdReturn                 177.28
2017-06-11 00:27:23.742088 EDT | MaxReturn                1172.65
2017-06-11 00:27:23.742430 EDT | MinReturn                 458.613
2017-06-11 00:27:23.742737 EDT | AverageEsReturn           404.765
2017-06-11 00:27:23.742994 EDT | StdEsReturn               180.7
2017-06-11 00:27:23.743313 EDT | MaxEsReturn               564.863
2017-06-11 00:27:23.743649 EDT | MinEsReturn                24.6931
2017-06-11 00:27:23.743969 EDT | AverageDiscountedReturn   213.065
2017-06-11 00:27:23.744237 EDT | AverageQLoss                2.28247
2017-06-11 00:27:23.744546 EDT | AveragePolicySurr         -31.0083
2017-06-11 00:27:23.744883 EDT | AverageQ                   30.6485
2017-06-11 00:27:23.745214 EDT | AverageAbsQ                30.6744
2017-06-11 00:27:23.745478 EDT | AverageY                   30.65
2017-06-11 00:27:23.745776 EDT | AverageAbsY                30.6634
2017-06-11 00:27:23.746103 EDT | AverageAbsQYDiff            0.554755
2017-06-11 00:27:23.746436 EDT | AverageAction               0.982247
2017-06-11 00:27:23.746712 EDT | PolicyRegParamNorm         83.183
2017-06-11 00:27:23.746982 EDT | QFunRegParamNorm          106.69
2017-06-11 00:27:23.747310 EDT | -----------------------  -----------
2017-06-11 00:27:23.747804 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #675 | Training started
2017-06-11 00:27:39.041862 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #675 | Training finished
2017-06-11 00:27:39.042744 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #675 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 00:27:39.042968 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #675 | Collecting samples for evaluation
2017-06-11 00:27:51.059603 EDT | -----------------------  -----------
2017-06-11 00:27:51.059913 EDT | Epoch                     675
2017-06-11 00:27:51.060135 EDT | Iteration                 675
2017-06-11 00:27:51.060321 EDT | AverageReturn             735.1
2017-06-11 00:27:51.060702 EDT | StdReturn                 213.789
2017-06-11 00:27:51.060892 EDT | MaxReturn                1210.94
2017-06-11 00:27:51.061237 EDT | MinReturn                 512.188
2017-06-11 00:27:51.061429 EDT | AverageEsReturn           463.381
2017-06-11 00:27:51.061628 EDT | StdEsReturn               395.188
2017-06-11 00:27:51.061859 EDT | MaxEsReturn              1070.18
2017-06-11 00:27:51.062125 EDT | MinEsReturn                36.0038
2017-06-11 00:27:51.062439 EDT | AverageDiscountedReturn   216.404
2017-06-11 00:27:51.062634 EDT | AverageQLoss                2.73243
2017-06-11 00:27:51.063041 EDT | AveragePolicySurr         -30.9759
2017-06-11 00:27:51.063230 EDT | AverageQ                   30.6144
2017-06-11 00:27:51.064099 EDT | AverageAbsQ                30.6382
2017-06-11 00:27:51.064289 EDT | AverageY                   30.6168
2017-06-11 00:27:51.064479 EDT | AverageAbsY                30.6272
2017-06-11 00:27:51.064663 EDT | AverageAbsQYDiff            0.595692
2017-06-11 00:27:51.064848 EDT | AverageAction               0.981136
2017-06-11 00:27:51.065028 EDT | PolicyRegParamNorm         83.2021
2017-06-11 00:27:51.065259 EDT | QFunRegParamNorm          106.748
2017-06-11 00:27:51.065442 EDT | -----------------------  -----------
2017-06-11 00:27:51.066728 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #676 | Training started
2017-06-11 00:28:05.863051 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #676 | Training finished
2017-06-11 00:28:05.863870 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #676 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 00:28:05.864142 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #676 | Collecting samples for evaluation
2017-06-11 00:28:18.794255 EDT | -----------------------  -----------
2017-06-11 00:28:18.795158 EDT | Epoch                     676
2017-06-11 00:28:18.795537 EDT | Iteration                 676
2017-06-11 00:28:18.795898 EDT | AverageReturn             660.301
2017-06-11 00:28:18.796210 EDT | StdReturn                 108.226
2017-06-11 00:28:18.796483 EDT | MaxReturn                1013.62
2017-06-11 00:28:18.796831 EDT | MinReturn                 538.325
2017-06-11 00:28:18.797179 EDT | AverageEsReturn           455.067
2017-06-11 00:28:18.797498 EDT | StdEsReturn               219.627
2017-06-11 00:28:18.797787 EDT | MaxEsReturn               718.384
2017-06-11 00:28:18.798145 EDT | MinEsReturn               170.503
2017-06-11 00:28:18.798919 EDT | AverageDiscountedReturn   214.268
2017-06-11 00:28:18.799264 EDT | AverageQLoss                2.75701
2017-06-11 00:28:18.799613 EDT | AveragePolicySurr         -31.0474
2017-06-11 00:28:18.799955 EDT | AverageQ                   30.6681
2017-06-11 00:28:18.800233 EDT | AverageAbsQ                30.692
2017-06-11 00:28:18.805065 EDT | AverageY                   30.6689
2017-06-11 00:28:18.805415 EDT | AverageAbsY                30.6773
2017-06-11 00:28:18.805801 EDT | AverageAbsQYDiff            0.603535
2017-06-11 00:28:18.806236 EDT | AverageAction               0.981938
2017-06-11 00:28:18.806603 EDT | PolicyRegParamNorm         83.2286
2017-06-11 00:28:18.807050 EDT | QFunRegParamNorm          106.812
2017-06-11 00:28:18.807438 EDT | -----------------------  -----------
2017-06-11 00:28:18.807948 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #677 | Training started
2017-06-11 00:28:33.911982 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #677 | Training finished
2017-06-11 00:28:33.912991 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #677 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 00:28:33.913388 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #677 | Collecting samples for evaluation
2017-06-11 00:28:47.134644 EDT | -----------------------  -----------
2017-06-11 00:28:47.136476 EDT | Epoch                     677
2017-06-11 00:28:47.136962 EDT | Iteration                 677
2017-06-11 00:28:47.137328 EDT | AverageReturn             623.651
2017-06-11 00:28:47.137709 EDT | StdReturn                 131.622
2017-06-11 00:28:47.138074 EDT | MaxReturn                1001.93
2017-06-11 00:28:47.138427 EDT | MinReturn                 326.544
2017-06-11 00:28:47.138780 EDT | AverageEsReturn           470.591
2017-06-11 00:28:47.139502 EDT | StdEsReturn               270.255
2017-06-11 00:28:47.140242 EDT | MaxEsReturn               837.739
2017-06-11 00:28:47.140618 EDT | MinEsReturn                38.7193
2017-06-11 00:28:47.142712 EDT | AverageDiscountedReturn   206.793
2017-06-11 00:28:47.143094 EDT | AverageQLoss                2.0244
2017-06-11 00:28:47.144361 EDT | AveragePolicySurr         -30.9829
2017-06-11 00:28:47.144722 EDT | AverageQ                   30.6164
2017-06-11 00:28:47.145067 EDT | AverageAbsQ                30.637
2017-06-11 00:28:47.145412 EDT | AverageY                   30.6165
2017-06-11 00:28:47.145773 EDT | AverageAbsY                30.6234
2017-06-11 00:28:47.146126 EDT | AverageAbsQYDiff            0.547443
2017-06-11 00:28:47.146481 EDT | AverageAction               0.979875
2017-06-11 00:28:47.146833 EDT | PolicyRegParamNorm         83.3122
2017-06-11 00:28:47.147184 EDT | QFunRegParamNorm          106.849
2017-06-11 00:28:47.147776 EDT | -----------------------  -----------
2017-06-11 00:28:47.149651 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #678 | Training started
2017-06-11 00:29:03.667147 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #678 | Training finished
2017-06-11 00:29:03.668635 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #678 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 00:29:03.669038 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #678 | Collecting samples for evaluation
2017-06-11 00:29:16.415719 EDT | -----------------------  ----------
2017-06-11 00:29:16.416818 EDT | Epoch                    678
2017-06-11 00:29:16.417910 EDT | Iteration                678
2017-06-11 00:29:16.418148 EDT | AverageReturn            427.443
2017-06-11 00:29:16.418348 EDT | StdReturn                 85.2531
2017-06-11 00:29:16.418557 EDT | MaxReturn                690.629
2017-06-11 00:29:16.418741 EDT | MinReturn                309.411
2017-06-11 00:29:16.418942 EDT | AverageEsReturn          316.907
2017-06-11 00:29:16.419137 EDT | StdEsReturn              270.043
2017-06-11 00:29:16.419336 EDT | MaxEsReturn              799.483
2017-06-11 00:29:16.419528 EDT | MinEsReturn                4.54806
2017-06-11 00:29:16.419719 EDT | AverageDiscountedReturn  181.148
2017-06-11 00:29:16.419994 EDT | AverageQLoss               2.76059
2017-06-11 00:29:16.420184 EDT | AveragePolicySurr        -31.006
2017-06-11 00:29:16.420387 EDT | AverageQ                  30.6525
2017-06-11 00:29:16.420579 EDT | AverageAbsQ               30.6717
2017-06-11 00:29:16.420769 EDT | AverageY                  30.6521
2017-06-11 00:29:16.420961 EDT | AverageAbsY               30.6592
2017-06-11 00:29:16.421155 EDT | AverageAbsQYDiff           0.591495
2017-06-11 00:29:16.421360 EDT | AverageAction              0.98896
2017-06-11 00:29:16.421552 EDT | PolicyRegParamNorm        83.3918
2017-06-11 00:29:16.421752 EDT | QFunRegParamNorm         106.935
2017-06-11 00:29:16.421943 EDT | -----------------------  ----------
2017-06-11 00:29:16.422266 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #679 | Training started
2017-06-11 00:29:33.013641 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #679 | Training finished
2017-06-11 00:29:33.014698 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #679 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 00:29:33.015084 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #679 | Collecting samples for evaluation
2017-06-11 00:29:45.456148 EDT | -----------------------  ----------
2017-06-11 00:29:45.460405 EDT | Epoch                    679
2017-06-11 00:29:45.460773 EDT | Iteration                679
2017-06-11 00:29:45.461090 EDT | AverageReturn            586.757
2017-06-11 00:29:45.461451 EDT | StdReturn                 98.4814
2017-06-11 00:29:45.461795 EDT | MaxReturn                846.132
2017-06-11 00:29:45.462881 EDT | MinReturn                348.165
2017-06-11 00:29:45.463482 EDT | AverageEsReturn          325.213
2017-06-11 00:29:45.463933 EDT | StdEsReturn              341.883
2017-06-11 00:29:45.464444 EDT | MaxEsReturn              890.422
2017-06-11 00:29:45.464894 EDT | MinEsReturn               18.8969
2017-06-11 00:29:45.465317 EDT | AverageDiscountedReturn  211.144
2017-06-11 00:29:45.465658 EDT | AverageQLoss               2.15771
2017-06-11 00:29:45.466090 EDT | AveragePolicySurr        -31.003
2017-06-11 00:29:45.466494 EDT | AverageQ                  30.6499
2017-06-11 00:29:45.466908 EDT | AverageAbsQ               30.6705
2017-06-11 00:29:45.467380 EDT | AverageY                  30.6505
2017-06-11 00:29:45.467540 EDT | AverageAbsY               30.6569
2017-06-11 00:29:45.467707 EDT | AverageAbsQYDiff           0.548948
2017-06-11 00:29:45.467891 EDT | AverageAction              0.985693
2017-06-11 00:29:45.468050 EDT | PolicyRegParamNorm        83.4081
2017-06-11 00:29:45.468206 EDT | QFunRegParamNorm         107.023
2017-06-11 00:29:45.468367 EDT | -----------------------  ----------
2017-06-11 00:29:45.468668 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #680 | Training started
2017-06-11 00:30:00.499924 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #680 | Training finished
2017-06-11 00:30:00.501802 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #680 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 00:30:00.502188 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #680 | Collecting samples for evaluation
2017-06-11 00:30:14.261563 EDT | -----------------------  ----------
2017-06-11 00:30:14.266110 EDT | Epoch                    680
2017-06-11 00:30:14.266495 EDT | Iteration                680
2017-06-11 00:30:14.266909 EDT | AverageReturn            443.673
2017-06-11 00:30:14.267294 EDT | StdReturn                137.902
2017-06-11 00:30:14.267661 EDT | MaxReturn                808.438
2017-06-11 00:30:14.268066 EDT | MinReturn                284.948
2017-06-11 00:30:14.268487 EDT | AverageEsReturn          365.707
2017-06-11 00:30:14.268884 EDT | StdEsReturn              225.15
2017-06-11 00:30:14.269302 EDT | MaxEsReturn              649.862
2017-06-11 00:30:14.269672 EDT | MinEsReturn                9.69879
2017-06-11 00:30:14.270035 EDT | AverageDiscountedReturn  181.274
2017-06-11 00:30:14.270450 EDT | AverageQLoss               2.43586
2017-06-11 00:30:14.270822 EDT | AveragePolicySurr        -31.0369
2017-06-11 00:30:14.271171 EDT | AverageQ                  30.6747
2017-06-11 00:30:14.271592 EDT | AverageAbsQ               30.692
2017-06-11 00:30:14.271980 EDT | AverageY                  30.6763
2017-06-11 00:30:14.272354 EDT | AverageAbsY               30.6817
2017-06-11 00:30:14.272735 EDT | AverageAbsQYDiff           0.570376
2017-06-11 00:30:14.273140 EDT | AverageAction              0.984094
2017-06-11 00:30:14.273532 EDT | PolicyRegParamNorm        83.4267
2017-06-11 00:30:14.273943 EDT | QFunRegParamNorm         107.114
2017-06-11 00:30:14.274341 EDT | -----------------------  ----------
2017-06-11 00:30:14.274965 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #681 | Training started
2017-06-11 00:30:28.946614 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #681 | Training finished
2017-06-11 00:30:28.947848 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #681 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 00:30:28.948418 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #681 | Collecting samples for evaluation
2017-06-11 00:30:42.057998 EDT | -----------------------  -----------
2017-06-11 00:30:42.069389 EDT | Epoch                     681
2017-06-11 00:30:42.069800 EDT | Iteration                 681
2017-06-11 00:30:42.070405 EDT | AverageReturn             651.605
2017-06-11 00:30:42.070716 EDT | StdReturn                 167.638
2017-06-11 00:30:42.071022 EDT | MaxReturn                1095.32
2017-06-11 00:30:42.071369 EDT | MinReturn                 308.695
2017-06-11 00:30:42.071672 EDT | AverageEsReturn           385.924
2017-06-11 00:30:42.071971 EDT | StdEsReturn               179.585
2017-06-11 00:30:42.072272 EDT | MaxEsReturn               699.048
2017-06-11 00:30:42.072572 EDT | MinEsReturn               130.478
2017-06-11 00:30:42.073626 EDT | AverageDiscountedReturn   208.254
2017-06-11 00:30:42.074379 EDT | AverageQLoss                2.57678
2017-06-11 00:30:42.074676 EDT | AveragePolicySurr         -31.0106
2017-06-11 00:30:42.074976 EDT | AverageQ                   30.6412
2017-06-11 00:30:42.075257 EDT | AverageAbsQ                30.6618
2017-06-11 00:30:42.075555 EDT | AverageY                   30.6427
2017-06-11 00:30:42.075853 EDT | AverageAbsY                30.6513
2017-06-11 00:30:42.076151 EDT | AverageAbsQYDiff            0.58718
2017-06-11 00:30:42.076448 EDT | AverageAction               0.985193
2017-06-11 00:30:42.076737 EDT | PolicyRegParamNorm         83.4874
2017-06-11 00:30:42.077017 EDT | QFunRegParamNorm          107.181
2017-06-11 00:30:42.077394 EDT | -----------------------  -----------
2017-06-11 00:30:42.077954 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #682 | Training started
2017-06-11 00:30:57.675105 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #682 | Training finished
2017-06-11 00:30:57.676101 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #682 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 00:30:57.676457 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #682 | Collecting samples for evaluation
2017-06-11 00:31:10.021676 EDT | -----------------------  -----------
2017-06-11 00:31:10.022608 EDT | Epoch                     682
2017-06-11 00:31:10.022911 EDT | Iteration                 682
2017-06-11 00:31:10.023126 EDT | AverageReturn             782.871
2017-06-11 00:31:10.023285 EDT | StdReturn                 171.536
2017-06-11 00:31:10.024035 EDT | MaxReturn                1111.19
2017-06-11 00:31:10.024335 EDT | MinReturn                 523.597
2017-06-11 00:31:10.024666 EDT | AverageEsReturn           370.336
2017-06-11 00:31:10.024832 EDT | StdEsReturn               306.079
2017-06-11 00:31:10.024986 EDT | MaxEsReturn               986.95
2017-06-11 00:31:10.025172 EDT | MinEsReturn                91.9938
2017-06-11 00:31:10.025354 EDT | AverageDiscountedReturn   221.591
2017-06-11 00:31:10.025523 EDT | AverageQLoss                2.65873
2017-06-11 00:31:10.025677 EDT | AveragePolicySurr         -30.9719
2017-06-11 00:31:10.025858 EDT | AverageQ                   30.5846
2017-06-11 00:31:10.026010 EDT | AverageAbsQ                30.6032
2017-06-11 00:31:10.026208 EDT | AverageY                   30.5843
2017-06-11 00:31:10.026406 EDT | AverageAbsY                30.5927
2017-06-11 00:31:10.026603 EDT | AverageAbsQYDiff            0.600801
2017-06-11 00:31:10.026759 EDT | AverageAction               0.986423
2017-06-11 00:31:10.026916 EDT | PolicyRegParamNorm         83.5724
2017-06-11 00:31:10.027068 EDT | QFunRegParamNorm          107.253
2017-06-11 00:31:10.027219 EDT | -----------------------  -----------
2017-06-11 00:31:10.027527 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #683 | Training started
2017-06-11 00:31:26.100749 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #683 | Training finished
2017-06-11 00:31:26.101930 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #683 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 00:31:26.102454 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #683 | Collecting samples for evaluation
2017-06-11 00:31:37.503830 EDT | -----------------------  -----------
2017-06-11 00:31:37.505964 EDT | Epoch                     683
2017-06-11 00:31:37.506348 EDT | Iteration                 683
2017-06-11 00:31:37.506820 EDT | AverageReturn             857.997
2017-06-11 00:31:37.507282 EDT | StdReturn                 452.06
2017-06-11 00:31:37.507756 EDT | MaxReturn                2714.73
2017-06-11 00:31:37.508222 EDT | MinReturn                 346.305
2017-06-11 00:31:37.508610 EDT | AverageEsReturn           533.502
2017-06-11 00:31:37.509076 EDT | StdEsReturn               350.704
2017-06-11 00:31:37.509449 EDT | MaxEsReturn               948.598
2017-06-11 00:31:37.509792 EDT | MinEsReturn                 1.99795
2017-06-11 00:31:37.510160 EDT | AverageDiscountedReturn   217.455
2017-06-11 00:31:37.510693 EDT | AverageQLoss                2.56216
2017-06-11 00:31:37.511020 EDT | AveragePolicySurr         -30.9953
2017-06-11 00:31:37.511397 EDT | AverageQ                   30.6114
2017-06-11 00:31:37.511855 EDT | AverageAbsQ                30.6281
2017-06-11 00:31:37.512148 EDT | AverageY                   30.6132
2017-06-11 00:31:37.512514 EDT | AverageAbsY                30.6217
2017-06-11 00:31:37.512921 EDT | AverageAbsQYDiff            0.597303
2017-06-11 00:31:37.513275 EDT | AverageAction               0.985478
2017-06-11 00:31:37.513651 EDT | PolicyRegParamNorm         83.5928
2017-06-11 00:31:37.514037 EDT | QFunRegParamNorm          107.311
2017-06-11 00:31:37.514383 EDT | -----------------------  -----------
2017-06-11 00:31:37.515414 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #684 | Training started
2017-06-11 00:31:53.268170 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #684 | Training finished
2017-06-11 00:31:53.269108 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #684 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 00:31:53.269503 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #684 | Collecting samples for evaluation
2017-06-11 00:32:06.136191 EDT | -----------------------  -----------
2017-06-11 00:32:06.137171 EDT | Epoch                     684
2017-06-11 00:32:06.137542 EDT | Iteration                 684
2017-06-11 00:32:06.137912 EDT | AverageReturn             970.585
2017-06-11 00:32:06.138334 EDT | StdReturn                 429.263
2017-06-11 00:32:06.138685 EDT | MaxReturn                2749.98
2017-06-11 00:32:06.139032 EDT | MinReturn                 573.43
2017-06-11 00:32:06.139479 EDT | AverageEsReturn           327.376
2017-06-11 00:32:06.139822 EDT | StdEsReturn               338.453
2017-06-11 00:32:06.140258 EDT | MaxEsReturn              1005.11
2017-06-11 00:32:06.140614 EDT | MinEsReturn                48.7222
2017-06-11 00:32:06.140956 EDT | AverageDiscountedReturn   220.599
2017-06-11 00:32:06.141501 EDT | AverageQLoss                2.06681
2017-06-11 00:32:06.141871 EDT | AveragePolicySurr         -31.0867
2017-06-11 00:32:06.142343 EDT | AverageQ                   30.7043
2017-06-11 00:32:06.142693 EDT | AverageAbsQ                30.722
2017-06-11 00:32:06.143040 EDT | AverageY                   30.7046
2017-06-11 00:32:06.143496 EDT | AverageAbsY                30.7124
2017-06-11 00:32:06.143839 EDT | AverageAbsQYDiff            0.546925
2017-06-11 00:32:06.144242 EDT | AverageAction               0.987429
2017-06-11 00:32:06.144589 EDT | PolicyRegParamNorm         83.6262
2017-06-11 00:32:06.144930 EDT | QFunRegParamNorm          107.374
2017-06-11 00:32:06.145330 EDT | -----------------------  -----------
2017-06-11 00:32:06.145824 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #685 | Training started
2017-06-11 00:32:20.678825 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #685 | Training finished
2017-06-11 00:32:20.679337 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #685 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 00:32:20.679710 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #685 | Collecting samples for evaluation
2017-06-11 00:32:34.457282 EDT | -----------------------  -----------
2017-06-11 00:32:34.459003 EDT | Epoch                     685
2017-06-11 00:32:34.459217 EDT | Iteration                 685
2017-06-11 00:32:34.459382 EDT | AverageReturn            1371.56
2017-06-11 00:32:34.459540 EDT | StdReturn                 659.906
2017-06-11 00:32:34.459807 EDT | MaxReturn                2977.5
2017-06-11 00:32:34.460099 EDT | MinReturn                 662.322
2017-06-11 00:32:34.460379 EDT | AverageEsReturn           589.446
2017-06-11 00:32:34.460569 EDT | StdEsReturn               533.325
2017-06-11 00:32:34.460723 EDT | MaxEsReturn              1529.81
2017-06-11 00:32:34.460892 EDT | MinEsReturn                15.7939
2017-06-11 00:32:34.461074 EDT | AverageDiscountedReturn   227.82
2017-06-11 00:32:34.461246 EDT | AverageQLoss                2.33601
2017-06-11 00:32:34.461415 EDT | AveragePolicySurr         -31.0941
2017-06-11 00:32:34.461589 EDT | AverageQ                   30.7299
2017-06-11 00:32:34.461797 EDT | AverageAbsQ                30.7528
2017-06-11 00:32:34.461961 EDT | AverageY                   30.7305
2017-06-11 00:32:34.462112 EDT | AverageAbsY                30.7412
2017-06-11 00:32:34.462263 EDT | AverageAbsQYDiff            0.564286
2017-06-11 00:32:34.462480 EDT | AverageAction               0.990345
2017-06-11 00:32:34.462637 EDT | PolicyRegParamNorm         83.6804
2017-06-11 00:32:34.462796 EDT | QFunRegParamNorm          107.46
2017-06-11 00:32:34.462957 EDT | -----------------------  -----------
2017-06-11 00:32:34.463229 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #686 | Training started
2017-06-11 00:32:49.987035 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #686 | Training finished
2017-06-11 00:32:49.988016 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #686 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 00:32:49.988397 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #686 | Collecting samples for evaluation
2017-06-11 00:33:02.310499 EDT | -----------------------  -----------
2017-06-11 00:33:02.311408 EDT | Epoch                     686
2017-06-11 00:33:02.311753 EDT | Iteration                 686
2017-06-11 00:33:02.312094 EDT | AverageReturn            1238.73
2017-06-11 00:33:02.312374 EDT | StdReturn                 542.287
2017-06-11 00:33:02.312770 EDT | MaxReturn                2742.01
2017-06-11 00:33:02.313104 EDT | MinReturn                 370.937
2017-06-11 00:33:02.313435 EDT | AverageEsReturn           233.63
2017-06-11 00:33:02.313765 EDT | StdEsReturn               145.967
2017-06-11 00:33:02.314084 EDT | MaxEsReturn               434.176
2017-06-11 00:33:02.314419 EDT | MinEsReturn                27.6632
2017-06-11 00:33:02.314789 EDT | AverageDiscountedReturn   226.781
2017-06-11 00:33:02.315123 EDT | AverageQLoss                2.4741
2017-06-11 00:33:02.315445 EDT | AveragePolicySurr         -31.1127
2017-06-11 00:33:02.315898 EDT | AverageQ                   30.7245
2017-06-11 00:33:02.316116 EDT | AverageAbsQ                30.753
2017-06-11 00:33:02.316273 EDT | AverageY                   30.726
2017-06-11 00:33:02.316424 EDT | AverageAbsY                30.7389
2017-06-11 00:33:02.316586 EDT | AverageAbsQYDiff            0.58236
2017-06-11 00:33:02.318070 EDT | AverageAction               0.988745
2017-06-11 00:33:02.318905 EDT | PolicyRegParamNorm         83.7195
2017-06-11 00:33:02.319517 EDT | QFunRegParamNorm          107.478
2017-06-11 00:33:02.319846 EDT | -----------------------  -----------
2017-06-11 00:33:02.320271 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #687 | Training started
2017-06-11 00:33:18.801455 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #687 | Training finished
2017-06-11 00:33:18.802456 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #687 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 00:33:18.802880 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #687 | Collecting samples for evaluation
2017-06-11 00:33:30.575410 EDT | -----------------------  -----------
2017-06-11 00:33:30.576342 EDT | Epoch                     687
2017-06-11 00:33:30.576795 EDT | Iteration                 687
2017-06-11 00:33:30.577147 EDT | AverageReturn            1044.32
2017-06-11 00:33:30.577490 EDT | StdReturn                 474.083
2017-06-11 00:33:30.577849 EDT | MaxReturn                2603.49
2017-06-11 00:33:30.578248 EDT | MinReturn                 429.641
2017-06-11 00:33:30.578587 EDT | AverageEsReturn           259.942
2017-06-11 00:33:30.578925 EDT | StdEsReturn               145.966
2017-06-11 00:33:30.579357 EDT | MaxEsReturn               517.816
2017-06-11 00:33:30.579707 EDT | MinEsReturn                49.9661
2017-06-11 00:33:30.580047 EDT | AverageDiscountedReturn   223.683
2017-06-11 00:33:30.580449 EDT | AverageQLoss                2.22049
2017-06-11 00:33:30.580790 EDT | AveragePolicySurr         -31.0353
2017-06-11 00:33:30.581131 EDT | AverageQ                   30.6882
2017-06-11 00:33:30.581535 EDT | AverageAbsQ                30.7084
2017-06-11 00:33:30.581900 EDT | AverageY                   30.6892
2017-06-11 00:33:30.582240 EDT | AverageAbsY                30.7
2017-06-11 00:33:30.582579 EDT | AverageAbsQYDiff            0.556721
2017-06-11 00:33:30.583061 EDT | AverageAction               0.991557
2017-06-11 00:33:30.583404 EDT | PolicyRegParamNorm         83.8135
2017-06-11 00:33:30.583746 EDT | QFunRegParamNorm          107.572
2017-06-11 00:33:30.584084 EDT | -----------------------  -----------
2017-06-11 00:33:30.584560 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #688 | Training started
2017-06-11 00:33:45.584174 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #688 | Training finished
2017-06-11 00:33:45.586038 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #688 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 00:33:45.586438 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #688 | Collecting samples for evaluation
2017-06-11 00:33:58.649938 EDT | -----------------------  -----------
2017-06-11 00:33:58.650826 EDT | Epoch                     688
2017-06-11 00:33:58.651712 EDT | Iteration                 688
2017-06-11 00:33:58.651969 EDT | AverageReturn             658.291
2017-06-11 00:33:58.652232 EDT | StdReturn                 332.05
2017-06-11 00:33:58.652500 EDT | MaxReturn                1634.12
2017-06-11 00:33:58.652679 EDT | MinReturn                 292.129
2017-06-11 00:33:58.652862 EDT | AverageEsReturn           454.727
2017-06-11 00:33:58.653043 EDT | StdEsReturn               333.218
2017-06-11 00:33:58.653263 EDT | MaxEsReturn               935.839
2017-06-11 00:33:58.653536 EDT | MinEsReturn                23.3475
2017-06-11 00:33:58.653735 EDT | AverageDiscountedReturn   203.032
2017-06-11 00:33:58.653934 EDT | AverageQLoss                2.27353
2017-06-11 00:33:58.654117 EDT | AveragePolicySurr         -31.068
2017-06-11 00:33:58.654297 EDT | AverageQ                   30.6849
2017-06-11 00:33:58.654527 EDT | AverageAbsQ                30.71
2017-06-11 00:33:58.654775 EDT | AverageY                   30.6862
2017-06-11 00:33:58.654956 EDT | AverageAbsY                30.6987
2017-06-11 00:33:58.655174 EDT | AverageAbsQYDiff            0.564951
2017-06-11 00:33:58.655409 EDT | AverageAction               0.991858
2017-06-11 00:33:58.655589 EDT | PolicyRegParamNorm         83.8314
2017-06-11 00:33:58.655768 EDT | QFunRegParamNorm          107.641
2017-06-11 00:33:58.655977 EDT | -----------------------  -----------
2017-06-11 00:33:58.658257 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #689 | Training started
2017-06-11 00:34:13.126706 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #689 | Training finished
2017-06-11 00:34:13.128034 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #689 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 00:34:13.128439 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #689 | Collecting samples for evaluation
2017-06-11 00:34:26.340096 EDT | -----------------------  -----------
2017-06-11 00:34:26.341431 EDT | Epoch                     689
2017-06-11 00:34:26.341724 EDT | Iteration                 689
2017-06-11 00:34:26.342215 EDT | AverageReturn             913.053
2017-06-11 00:34:26.342411 EDT | StdReturn                 465.267
2017-06-11 00:34:26.342594 EDT | MaxReturn                2150.27
2017-06-11 00:34:26.342782 EDT | MinReturn                 379.262
2017-06-11 00:34:26.342961 EDT | AverageEsReturn           384.677
2017-06-11 00:34:26.343179 EDT | StdEsReturn               323.175
2017-06-11 00:34:26.343468 EDT | MaxEsReturn               840.169
2017-06-11 00:34:26.343754 EDT | MinEsReturn                28.2827
2017-06-11 00:34:26.344024 EDT | AverageDiscountedReturn   209.603
2017-06-11 00:34:26.344294 EDT | AverageQLoss                2.64474
2017-06-11 00:34:26.344547 EDT | AveragePolicySurr         -31.119
2017-06-11 00:34:26.344793 EDT | AverageQ                   30.7443
2017-06-11 00:34:26.345038 EDT | AverageAbsQ                30.767
2017-06-11 00:34:26.345307 EDT | AverageY                   30.744
2017-06-11 00:34:26.345545 EDT | AverageAbsY                30.757
2017-06-11 00:34:26.345846 EDT | AverageAbsQYDiff            0.588182
2017-06-11 00:34:26.346090 EDT | AverageAction               0.987052
2017-06-11 00:34:26.346354 EDT | PolicyRegParamNorm         83.9006
2017-06-11 00:34:26.346633 EDT | QFunRegParamNorm          107.67
2017-06-11 00:34:26.347045 EDT | -----------------------  -----------
2017-06-11 00:34:26.347331 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #690 | Training started
2017-06-11 00:34:41.197295 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #690 | Training finished
2017-06-11 00:34:41.197739 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #690 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 00:34:41.197943 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #690 | Collecting samples for evaluation
2017-06-11 00:34:53.077931 EDT | -----------------------  -----------
2017-06-11 00:34:53.078871 EDT | Epoch                     690
2017-06-11 00:34:53.079252 EDT | Iteration                 690
2017-06-11 00:34:53.079588 EDT | AverageReturn             158.915
2017-06-11 00:34:53.079923 EDT | StdReturn                  20.9419
2017-06-11 00:34:53.080278 EDT | MaxReturn                 369.383
2017-06-11 00:34:53.080616 EDT | MinReturn                 139.187
2017-06-11 00:34:53.080956 EDT | AverageEsReturn           261.21
2017-06-11 00:34:53.081323 EDT | StdEsReturn               310.357
2017-06-11 00:34:53.081794 EDT | MaxEsReturn              1107.29
2017-06-11 00:34:53.082168 EDT | MinEsReturn                30.9817
2017-06-11 00:34:53.082530 EDT | AverageDiscountedReturn   104.015
2017-06-11 00:34:53.082877 EDT | AverageQLoss                2.47593
2017-06-11 00:34:53.085424 EDT | AveragePolicySurr         -31.0734
2017-06-11 00:34:53.085845 EDT | AverageQ                   30.7293
2017-06-11 00:34:53.086240 EDT | AverageAbsQ                30.7564
2017-06-11 00:34:53.086616 EDT | AverageY                   30.7297
2017-06-11 00:34:53.086959 EDT | AverageAbsY                30.7435
2017-06-11 00:34:53.087296 EDT | AverageAbsQYDiff            0.571617
2017-06-11 00:34:53.087763 EDT | AverageAction               0.989215
2017-06-11 00:34:53.088127 EDT | PolicyRegParamNorm         83.8989
2017-06-11 00:34:53.088536 EDT | QFunRegParamNorm          107.738
2017-06-11 00:34:53.089070 EDT | -----------------------  -----------
2017-06-11 00:34:53.089830 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #691 | Training started
2017-06-11 00:35:09.577662 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #691 | Training finished
2017-06-11 00:35:09.579591 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #691 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 00:35:09.579860 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #691 | Collecting samples for evaluation
2017-06-11 00:35:21.764994 EDT | -----------------------  -----------
2017-06-11 00:35:21.772217 EDT | Epoch                     691
2017-06-11 00:35:21.772615 EDT | Iteration                 691
2017-06-11 00:35:21.772971 EDT | AverageReturn             819.912
2017-06-11 00:35:21.773315 EDT | StdReturn                 309.813
2017-06-11 00:35:21.773663 EDT | MaxReturn                1791.49
2017-06-11 00:35:21.774034 EDT | MinReturn                 506.086
2017-06-11 00:35:21.774388 EDT | AverageEsReturn           164.516
2017-06-11 00:35:21.774731 EDT | StdEsReturn               167.105
2017-06-11 00:35:21.775076 EDT | MaxEsReturn               636.096
2017-06-11 00:35:21.775418 EDT | MinEsReturn                40.0047
2017-06-11 00:35:21.775759 EDT | AverageDiscountedReturn   204.053
2017-06-11 00:35:21.776112 EDT | AverageQLoss                2.34637
2017-06-11 00:35:21.776467 EDT | AveragePolicySurr         -31.0517
2017-06-11 00:35:21.776813 EDT | AverageQ                   30.7034
2017-06-11 00:35:21.777152 EDT | AverageAbsQ                30.7282
2017-06-11 00:35:21.777490 EDT | AverageY                   30.707
2017-06-11 00:35:21.777918 EDT | AverageAbsY                30.7169
2017-06-11 00:35:21.778269 EDT | AverageAbsQYDiff            0.56286
2017-06-11 00:35:21.793841 EDT | AverageAction               0.987062
2017-06-11 00:35:21.794342 EDT | PolicyRegParamNorm         84.0087
2017-06-11 00:35:21.794795 EDT | QFunRegParamNorm          107.816
2017-06-11 00:35:21.795245 EDT | -----------------------  -----------
2017-06-11 00:35:21.795866 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #692 | Training started
2017-06-11 00:35:36.946964 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #692 | Training finished
2017-06-11 00:35:36.948447 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #692 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 00:35:36.948833 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #692 | Collecting samples for evaluation
2017-06-11 00:35:50.921857 EDT | -----------------------  -----------
2017-06-11 00:35:50.923309 EDT | Epoch                     692
2017-06-11 00:35:50.923777 EDT | Iteration                 692
2017-06-11 00:35:50.925830 EDT | AverageReturn             712.143
2017-06-11 00:35:50.926191 EDT | StdReturn                 418.614
2017-06-11 00:35:50.926516 EDT | MaxReturn                2101.29
2017-06-11 00:35:50.926915 EDT | MinReturn                 112.244
2017-06-11 00:35:50.927215 EDT | AverageEsReturn           374.527
2017-06-11 00:35:50.927536 EDT | StdEsReturn               200.828
2017-06-11 00:35:50.927817 EDT | MaxEsReturn               579.507
2017-06-11 00:35:50.928134 EDT | MinEsReturn               116.62
2017-06-11 00:35:50.928441 EDT | AverageDiscountedReturn   194.182
2017-06-11 00:35:50.928840 EDT | AverageQLoss                2.12814
2017-06-11 00:35:50.929160 EDT | AveragePolicySurr         -31.0958
2017-06-11 00:35:50.929480 EDT | AverageQ                   30.7438
2017-06-11 00:35:50.929833 EDT | AverageAbsQ                30.7733
2017-06-11 00:35:50.930171 EDT | AverageY                   30.7459
2017-06-11 00:35:50.930475 EDT | AverageAbsY                30.7626
2017-06-11 00:35:50.930755 EDT | AverageAbsQYDiff            0.554522
2017-06-11 00:35:50.931065 EDT | AverageAction               0.987287
2017-06-11 00:35:50.931387 EDT | PolicyRegParamNorm         84.0588
2017-06-11 00:35:50.932513 EDT | QFunRegParamNorm          107.848
2017-06-11 00:35:50.932845 EDT | -----------------------  -----------
2017-06-11 00:35:50.933234 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #693 | Training started
2017-06-11 00:36:05.714892 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #693 | Training finished
2017-06-11 00:36:05.719839 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #693 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 00:36:05.723935 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #693 | Collecting samples for evaluation
2017-06-11 00:36:19.151682 EDT | -----------------------  -----------
2017-06-11 00:36:19.152483 EDT | Epoch                     693
2017-06-11 00:36:19.152660 EDT | Iteration                 693
2017-06-11 00:36:19.152824 EDT | AverageReturn            1443.03
2017-06-11 00:36:19.153022 EDT | StdReturn                 601.872
2017-06-11 00:36:19.153316 EDT | MaxReturn                2788.36
2017-06-11 00:36:19.153577 EDT | MinReturn                 698.859
2017-06-11 00:36:19.153862 EDT | AverageEsReturn           272.335
2017-06-11 00:36:19.154050 EDT | StdEsReturn               185.324
2017-06-11 00:36:19.154204 EDT | MaxEsReturn               554.775
2017-06-11 00:36:19.154432 EDT | MinEsReturn                66.0726
2017-06-11 00:36:19.154660 EDT | AverageDiscountedReturn   229.162
2017-06-11 00:36:19.154813 EDT | AverageQLoss                2.35891
2017-06-11 00:36:19.154963 EDT | AveragePolicySurr         -31.0549
2017-06-11 00:36:19.155271 EDT | AverageQ                   30.7055
2017-06-11 00:36:19.155435 EDT | AverageAbsQ                30.7411
2017-06-11 00:36:19.155676 EDT | AverageY                   30.7046
2017-06-11 00:36:19.155915 EDT | AverageAbsY                30.7214
2017-06-11 00:36:19.156153 EDT | AverageAbsQYDiff            0.575698
2017-06-11 00:36:19.156391 EDT | AverageAction               0.987085
2017-06-11 00:36:19.156626 EDT | PolicyRegParamNorm         84.096
2017-06-11 00:36:19.156778 EDT | QFunRegParamNorm          107.882
2017-06-11 00:36:19.156928 EDT | -----------------------  -----------
2017-06-11 00:36:19.157243 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #694 | Training started
2017-06-11 00:36:34.566853 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #694 | Training finished
2017-06-11 00:36:34.567784 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #694 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 00:36:34.568164 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #694 | Collecting samples for evaluation
2017-06-11 00:36:47.991693 EDT | -----------------------  -----------
2017-06-11 00:36:47.992676 EDT | Epoch                     694
2017-06-11 00:36:47.994757 EDT | Iteration                 694
2017-06-11 00:36:47.995542 EDT | AverageReturn            1009.9
2017-06-11 00:36:47.995801 EDT | StdReturn                 264.522
2017-06-11 00:36:47.996058 EDT | MaxReturn                1637.59
2017-06-11 00:36:47.996637 EDT | MinReturn                 394.472
2017-06-11 00:36:47.996889 EDT | AverageEsReturn           360.368
2017-06-11 00:36:47.997137 EDT | StdEsReturn               189.541
2017-06-11 00:36:47.997386 EDT | MaxEsReturn               626.965
2017-06-11 00:36:47.997632 EDT | MinEsReturn                71.8405
2017-06-11 00:36:47.997890 EDT | AverageDiscountedReturn   238.567
2017-06-11 00:36:47.998138 EDT | AverageQLoss                2.80856
2017-06-11 00:36:47.998384 EDT | AveragePolicySurr         -30.9447
2017-06-11 00:36:47.998629 EDT | AverageQ                   30.5932
2017-06-11 00:36:47.998876 EDT | AverageAbsQ                30.6199
2017-06-11 00:36:47.999120 EDT | AverageY                   30.5967
2017-06-11 00:36:47.999364 EDT | AverageAbsY                30.6129
2017-06-11 00:36:47.999609 EDT | AverageAbsQYDiff            0.598343
2017-06-11 00:36:47.999857 EDT | AverageAction               0.987369
2017-06-11 00:36:48.000101 EDT | PolicyRegParamNorm         84.1349
2017-06-11 00:36:48.000345 EDT | QFunRegParamNorm          107.899
2017-06-11 00:36:48.000590 EDT | -----------------------  -----------
2017-06-11 00:36:48.000958 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #695 | Training started
2017-06-11 00:37:05.170993 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #695 | Training finished
2017-06-11 00:37:05.182735 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #695 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 00:37:05.186474 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #695 | Collecting samples for evaluation
2017-06-11 00:37:17.778761 EDT | -----------------------  -----------
2017-06-11 00:37:17.779477 EDT | Epoch                     695
2017-06-11 00:37:17.779657 EDT | Iteration                 695
2017-06-11 00:37:17.779823 EDT | AverageReturn            1275.23
2017-06-11 00:37:17.779991 EDT | StdReturn                 538.475
2017-06-11 00:37:17.780177 EDT | MaxReturn                2662.78
2017-06-11 00:37:17.780338 EDT | MinReturn                 688.182
2017-06-11 00:37:17.780496 EDT | AverageEsReturn           253.082
2017-06-11 00:37:17.780675 EDT | StdEsReturn               221.875
2017-06-11 00:37:17.780845 EDT | MaxEsReturn               565.488
2017-06-11 00:37:17.781030 EDT | MinEsReturn                17.747
2017-06-11 00:37:17.781212 EDT | AverageDiscountedReturn   229.754
2017-06-11 00:37:17.781393 EDT | AverageQLoss                2.63015
2017-06-11 00:37:17.781572 EDT | AveragePolicySurr         -31.0439
2017-06-11 00:37:17.782040 EDT | AverageQ                   30.695
2017-06-11 00:37:17.782209 EDT | AverageAbsQ                30.7253
2017-06-11 00:37:17.782386 EDT | AverageY                   30.6943
2017-06-11 00:37:17.782543 EDT | AverageAbsY                30.7123
2017-06-11 00:37:17.782699 EDT | AverageAbsQYDiff            0.581603
2017-06-11 00:37:17.783074 EDT | AverageAction               0.988807
2017-06-11 00:37:17.783251 EDT | PolicyRegParamNorm         84.2353
2017-06-11 00:37:17.783409 EDT | QFunRegParamNorm          107.971
2017-06-11 00:37:17.783565 EDT | -----------------------  -----------
2017-06-11 00:37:17.785448 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #696 | Training started
2017-06-11 00:37:33.646087 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #696 | Training finished
2017-06-11 00:37:33.647300 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #696 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 00:37:33.647581 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #696 | Collecting samples for evaluation
2017-06-11 00:37:46.417041 EDT | -----------------------  -----------
2017-06-11 00:37:46.417780 EDT | Epoch                     696
2017-06-11 00:37:46.417956 EDT | Iteration                 696
2017-06-11 00:37:46.418113 EDT | AverageReturn             876.621
2017-06-11 00:37:46.418268 EDT | StdReturn                 513.379
2017-06-11 00:37:46.418433 EDT | MaxReturn                2050.81
2017-06-11 00:37:46.418597 EDT | MinReturn                 325.972
2017-06-11 00:37:46.418828 EDT | AverageEsReturn           341.996
2017-06-11 00:37:46.418982 EDT | StdEsReturn               193.095
2017-06-11 00:37:46.419132 EDT | MaxEsReturn               613.975
2017-06-11 00:37:46.419282 EDT | MinEsReturn                42.2929
2017-06-11 00:37:46.419456 EDT | AverageDiscountedReturn   205.365
2017-06-11 00:37:46.419624 EDT | AverageQLoss                2.5309
2017-06-11 00:37:46.419775 EDT | AveragePolicySurr         -31.0122
2017-06-11 00:37:46.419925 EDT | AverageQ                   30.669
2017-06-11 00:37:46.420074 EDT | AverageAbsQ                30.6995
2017-06-11 00:37:46.420223 EDT | AverageY                   30.6689
2017-06-11 00:37:46.420373 EDT | AverageAbsY                30.6852
2017-06-11 00:37:46.420535 EDT | AverageAbsQYDiff            0.574898
2017-06-11 00:37:46.420684 EDT | AverageAction               0.989939
2017-06-11 00:37:46.420856 EDT | PolicyRegParamNorm         84.2455
2017-06-11 00:37:46.421185 EDT | QFunRegParamNorm          108.073
2017-06-11 00:37:46.421373 EDT | -----------------------  -----------
2017-06-11 00:37:46.421647 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #697 | Training started
2017-06-11 00:38:01.543384 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #697 | Training finished
2017-06-11 00:38:01.544294 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #697 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 00:38:01.544586 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #697 | Collecting samples for evaluation
2017-06-11 00:38:14.708232 EDT | -----------------------  -----------
2017-06-11 00:38:14.708983 EDT | Epoch                     697
2017-06-11 00:38:14.709274 EDT | Iteration                 697
2017-06-11 00:38:14.709576 EDT | AverageReturn             727.345
2017-06-11 00:38:14.709878 EDT | StdReturn                 279.956
2017-06-11 00:38:14.710156 EDT | MaxReturn                1575.64
2017-06-11 00:38:14.710426 EDT | MinReturn                 277.362
2017-06-11 00:38:14.710697 EDT | AverageEsReturn           296.504
2017-06-11 00:38:14.710965 EDT | StdEsReturn               301.139
2017-06-11 00:38:14.711236 EDT | MaxEsReturn              1010.51
2017-06-11 00:38:14.711503 EDT | MinEsReturn                52.1359
2017-06-11 00:38:14.711770 EDT | AverageDiscountedReturn   191.734
2017-06-11 00:38:14.712632 EDT | AverageQLoss                2.46886
2017-06-11 00:38:14.712901 EDT | AveragePolicySurr         -31.0131
2017-06-11 00:38:14.713218 EDT | AverageQ                   30.6844
2017-06-11 00:38:14.713544 EDT | AverageAbsQ                30.7087
2017-06-11 00:38:14.713731 EDT | AverageY                   30.6848
2017-06-11 00:38:14.713933 EDT | AverageAbsY                30.6982
2017-06-11 00:38:14.714115 EDT | AverageAbsQYDiff            0.575178
2017-06-11 00:38:14.714303 EDT | AverageAction               0.987479
2017-06-11 00:38:14.714483 EDT | PolicyRegParamNorm         84.3189
2017-06-11 00:38:14.714661 EDT | QFunRegParamNorm          108.111
2017-06-11 00:38:14.715117 EDT | -----------------------  -----------
2017-06-11 00:38:14.715617 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #698 | Training started
2017-06-11 00:38:30.492139 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #698 | Training finished
2017-06-11 00:38:30.492974 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #698 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 00:38:30.493180 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #698 | Collecting samples for evaluation
2017-06-11 00:38:43.762983 EDT | -----------------------  -----------
2017-06-11 00:38:43.763640 EDT | Epoch                     698
2017-06-11 00:38:43.764093 EDT | Iteration                 698
2017-06-11 00:38:43.764557 EDT | AverageReturn            1342.51
2017-06-11 00:38:43.765002 EDT | StdReturn                 540.952
2017-06-11 00:38:43.765448 EDT | MaxReturn                2584.51
2017-06-11 00:38:43.765903 EDT | MinReturn                 690.344
2017-06-11 00:38:43.766343 EDT | AverageEsReturn           341.658
2017-06-11 00:38:43.766784 EDT | StdEsReturn               255.641
2017-06-11 00:38:43.767241 EDT | MaxEsReturn               869.757
2017-06-11 00:38:43.767677 EDT | MinEsReturn               122.541
2017-06-11 00:38:43.768113 EDT | AverageDiscountedReturn   217.14
2017-06-11 00:38:43.768551 EDT | AverageQLoss                2.64923
2017-06-11 00:38:43.768984 EDT | AveragePolicySurr         -31.0346
2017-06-11 00:38:43.769420 EDT | AverageQ                   30.6667
2017-06-11 00:38:43.769871 EDT | AverageAbsQ                30.6863
2017-06-11 00:38:43.770943 EDT | AverageY                   30.6695
2017-06-11 00:38:43.775848 EDT | AverageAbsY                30.6775
2017-06-11 00:38:43.776209 EDT | AverageAbsQYDiff            0.598752
2017-06-11 00:38:43.776552 EDT | AverageAction               0.986234
2017-06-11 00:38:43.776888 EDT | PolicyRegParamNorm         84.3983
2017-06-11 00:38:43.777218 EDT | QFunRegParamNorm          108.161
2017-06-11 00:38:43.777557 EDT | -----------------------  -----------
2017-06-11 00:38:43.778062 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #699 | Training started
2017-06-11 00:38:59.958191 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #699 | Training finished
2017-06-11 00:38:59.958674 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #699 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 00:38:59.958863 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #699 | Collecting samples for evaluation
2017-06-11 00:39:11.799421 EDT | -----------------------  -----------
2017-06-11 00:39:11.799700 EDT | Epoch                     699
2017-06-11 00:39:11.799918 EDT | Iteration                 699
2017-06-11 00:39:11.800107 EDT | AverageReturn            1241.76
2017-06-11 00:39:11.800971 EDT | StdReturn                 529.159
2017-06-11 00:39:11.802378 EDT | MaxReturn                2308.23
2017-06-11 00:39:11.802721 EDT | MinReturn                 577.556
2017-06-11 00:39:11.803097 EDT | AverageEsReturn           638.624
2017-06-11 00:39:11.803466 EDT | StdEsReturn               356.459
2017-06-11 00:39:11.803877 EDT | MaxEsReturn              1140.23
2017-06-11 00:39:11.804356 EDT | MinEsReturn               153.669
2017-06-11 00:39:11.804780 EDT | AverageDiscountedReturn   218.735
2017-06-11 00:39:11.804965 EDT | AverageQLoss                2.41492
2017-06-11 00:39:11.805152 EDT | AveragePolicySurr         -30.9376
2017-06-11 00:39:11.805334 EDT | AverageQ                   30.56
2017-06-11 00:39:11.805515 EDT | AverageAbsQ                30.5783
2017-06-11 00:39:11.805701 EDT | AverageY                   30.561
2017-06-11 00:39:11.805887 EDT | AverageAbsY                30.5666
2017-06-11 00:39:11.806066 EDT | AverageAbsQYDiff            0.583058
2017-06-11 00:39:11.806405 EDT | AverageAction               0.984199
2017-06-11 00:39:11.806583 EDT | PolicyRegParamNorm         84.4232
2017-06-11 00:39:11.806767 EDT | QFunRegParamNorm          108.195
2017-06-11 00:39:11.806983 EDT | -----------------------  -----------
2017-06-11 00:39:11.807259 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #700 | Training started
2017-06-11 00:39:28.414829 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #700 | Training finished
2017-06-11 00:39:28.415849 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #700 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 00:39:28.416239 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #700 | Collecting samples for evaluation
2017-06-11 00:39:40.980268 EDT | -----------------------  -----------
2017-06-11 00:39:40.980948 EDT | Epoch                     700
2017-06-11 00:39:40.981252 EDT | Iteration                 700
2017-06-11 00:39:40.981578 EDT | AverageReturn             727.151
2017-06-11 00:39:40.981892 EDT | StdReturn                 231.229
2017-06-11 00:39:40.982229 EDT | MaxReturn                1399.96
2017-06-11 00:39:40.982552 EDT | MinReturn                 198.214
2017-06-11 00:39:40.982875 EDT | AverageEsReturn           448.937
2017-06-11 00:39:40.983187 EDT | StdEsReturn               439.08
2017-06-11 00:39:40.983508 EDT | MaxEsReturn              1354.35
2017-06-11 00:39:40.983898 EDT | MinEsReturn                42.3576
2017-06-11 00:39:40.984238 EDT | AverageDiscountedReturn   203.907
2017-06-11 00:39:40.984565 EDT | AverageQLoss                2.79296
2017-06-11 00:39:40.984888 EDT | AveragePolicySurr         -30.9646
2017-06-11 00:39:40.985182 EDT | AverageQ                   30.5989
2017-06-11 00:39:40.985474 EDT | AverageAbsQ                30.6189
2017-06-11 00:39:40.986345 EDT | AverageY                   30.6004
2017-06-11 00:39:40.986670 EDT | AverageAbsY                30.6088
2017-06-11 00:39:40.986984 EDT | AverageAbsQYDiff            0.603097
2017-06-11 00:39:40.987246 EDT | AverageAction               0.987641
2017-06-11 00:39:40.987568 EDT | PolicyRegParamNorm         84.4548
2017-06-11 00:39:40.987849 EDT | QFunRegParamNorm          108.251
2017-06-11 00:39:40.988039 EDT | -----------------------  -----------
2017-06-11 00:39:40.988303 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #701 | Training started
2017-06-11 00:39:56.552405 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #701 | Training finished
2017-06-11 00:39:56.554769 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #701 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 00:39:56.555325 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #701 | Collecting samples for evaluation
2017-06-11 00:40:09.668284 EDT | -----------------------  -----------
2017-06-11 00:40:09.669758 EDT | Epoch                     701
2017-06-11 00:40:09.673776 EDT | Iteration                 701
2017-06-11 00:40:09.674074 EDT | AverageReturn            1228.13
2017-06-11 00:40:09.674243 EDT | StdReturn                 485.67
2017-06-11 00:40:09.674405 EDT | MaxReturn                2459.54
2017-06-11 00:40:09.674567 EDT | MinReturn                 739.725
2017-06-11 00:40:09.674724 EDT | AverageEsReturn           296.983
2017-06-11 00:40:09.674878 EDT | StdEsReturn                99.3196
2017-06-11 00:40:09.675029 EDT | MaxEsReturn               424.485
2017-06-11 00:40:09.675179 EDT | MinEsReturn               195.326
2017-06-11 00:40:09.675330 EDT | AverageDiscountedReturn   229.513
2017-06-11 00:40:09.675479 EDT | AverageQLoss                2.35548
2017-06-11 00:40:09.675629 EDT | AveragePolicySurr         -30.9576
2017-06-11 00:40:09.675778 EDT | AverageQ                   30.6014
2017-06-11 00:40:09.675928 EDT | AverageAbsQ                30.621
2017-06-11 00:40:09.676079 EDT | AverageY                   30.603
2017-06-11 00:40:09.676228 EDT | AverageAbsY                30.6123
2017-06-11 00:40:09.676378 EDT | AverageAbsQYDiff            0.569054
2017-06-11 00:40:09.676528 EDT | AverageAction               0.987503
2017-06-11 00:40:09.676677 EDT | PolicyRegParamNorm         84.5056
2017-06-11 00:40:09.676828 EDT | QFunRegParamNorm          108.266
2017-06-11 00:40:09.676977 EDT | -----------------------  -----------
2017-06-11 00:40:09.677263 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #702 | Training started
2017-06-11 00:40:25.033540 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #702 | Training finished
2017-06-11 00:40:25.034583 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #702 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 00:40:25.034972 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #702 | Collecting samples for evaluation
2017-06-11 00:40:39.008269 EDT | -----------------------  -----------
2017-06-11 00:40:39.009123 EDT | Epoch                     702
2017-06-11 00:40:39.009444 EDT | Iteration                 702
2017-06-11 00:40:39.009729 EDT | AverageReturn            1113.8
2017-06-11 00:40:39.009996 EDT | StdReturn                 710.813
2017-06-11 00:40:39.010290 EDT | MaxReturn                2599.9
2017-06-11 00:40:39.010602 EDT | MinReturn                 290.715
2017-06-11 00:40:39.010896 EDT | AverageEsReturn           659.865
2017-06-11 00:40:39.011181 EDT | StdEsReturn               299.422
2017-06-11 00:40:39.011439 EDT | MaxEsReturn               991.969
2017-06-11 00:40:39.011697 EDT | MinEsReturn               176.384
2017-06-11 00:40:39.011949 EDT | AverageDiscountedReturn   205.878
2017-06-11 00:40:39.012202 EDT | AverageQLoss                2.25661
2017-06-11 00:40:39.012465 EDT | AveragePolicySurr         -30.926
2017-06-11 00:40:39.012719 EDT | AverageQ                   30.5876
2017-06-11 00:40:39.012971 EDT | AverageAbsQ                30.61
2017-06-11 00:40:39.013223 EDT | AverageY                   30.5879
2017-06-11 00:40:39.013474 EDT | AverageAbsY                30.5988
2017-06-11 00:40:39.013730 EDT | AverageAbsQYDiff            0.573952
2017-06-11 00:40:39.014108 EDT | AverageAction               0.989155
2017-06-11 00:40:39.014443 EDT | PolicyRegParamNorm         84.6227
2017-06-11 00:40:39.014783 EDT | QFunRegParamNorm          108.294
2017-06-11 00:40:39.015126 EDT | -----------------------  -----------
2017-06-11 00:40:39.015612 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #703 | Training started
2017-06-11 00:40:54.309919 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #703 | Training finished
2017-06-11 00:40:54.310694 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #703 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 00:40:54.310963 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #703 | Collecting samples for evaluation
2017-06-11 00:41:06.512752 EDT | -----------------------  -----------
2017-06-11 00:41:06.515345 EDT | Epoch                     703
2017-06-11 00:41:06.516108 EDT | Iteration                 703
2017-06-11 00:41:06.516486 EDT | AverageReturn             720.146
2017-06-11 00:41:06.516652 EDT | StdReturn                 342.888
2017-06-11 00:41:06.516816 EDT | MaxReturn                1648.72
2017-06-11 00:41:06.516982 EDT | MinReturn                 245.956
2017-06-11 00:41:06.517251 EDT | AverageEsReturn           263.438
2017-06-11 00:41:06.517424 EDT | StdEsReturn               190.049
2017-06-11 00:41:06.517591 EDT | MaxEsReturn               614.887
2017-06-11 00:41:06.517813 EDT | MinEsReturn                 7.85324
2017-06-11 00:41:06.517998 EDT | AverageDiscountedReturn   196.361
2017-06-11 00:41:06.518178 EDT | AverageQLoss                2.21571
2017-06-11 00:41:06.518352 EDT | AveragePolicySurr         -30.9574
2017-06-11 00:41:06.518515 EDT | AverageQ                   30.6161
2017-06-11 00:41:06.518672 EDT | AverageAbsQ                30.6364
2017-06-11 00:41:06.518828 EDT | AverageY                   30.619
2017-06-11 00:41:06.518984 EDT | AverageAbsY                30.6278
2017-06-11 00:41:06.519138 EDT | AverageAbsQYDiff            0.555815
2017-06-11 00:41:06.519295 EDT | AverageAction               0.983927
2017-06-11 00:41:06.519450 EDT | PolicyRegParamNorm         84.6875
2017-06-11 00:41:06.519638 EDT | QFunRegParamNorm          108.321
2017-06-11 00:41:06.519796 EDT | -----------------------  -----------
2017-06-11 00:41:06.520068 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #704 | Training started
2017-06-11 00:41:23.150599 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #704 | Training finished
2017-06-11 00:41:23.151351 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #704 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 00:41:23.151811 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #704 | Collecting samples for evaluation
2017-06-11 00:41:35.250623 EDT | -----------------------  -----------
2017-06-11 00:41:35.251386 EDT | Epoch                     704
2017-06-11 00:41:35.251809 EDT | Iteration                 704
2017-06-11 00:41:35.252232 EDT | AverageReturn             612.687
2017-06-11 00:41:35.252647 EDT | StdReturn                 210.849
2017-06-11 00:41:35.252874 EDT | MaxReturn                1139.64
2017-06-11 00:41:35.253062 EDT | MinReturn                 282.401
2017-06-11 00:41:35.253390 EDT | AverageEsReturn           337.056
2017-06-11 00:41:35.253798 EDT | StdEsReturn               174.363
2017-06-11 00:41:35.254220 EDT | MaxEsReturn               689.78
2017-06-11 00:41:35.254424 EDT | MinEsReturn               156.608
2017-06-11 00:41:35.254583 EDT | AverageDiscountedReturn   193.231
2017-06-11 00:41:35.254742 EDT | AverageQLoss                2.40067
2017-06-11 00:41:35.254900 EDT | AveragePolicySurr         -30.8837
2017-06-11 00:41:35.255056 EDT | AverageQ                   30.5392
2017-06-11 00:41:35.255218 EDT | AverageAbsQ                30.5683
2017-06-11 00:41:35.255402 EDT | AverageY                   30.5425
2017-06-11 00:41:35.255694 EDT | AverageAbsY                30.5565
2017-06-11 00:41:35.256008 EDT | AverageAbsQYDiff            0.574031
2017-06-11 00:41:35.256185 EDT | AverageAction               0.985929
2017-06-11 00:41:35.256366 EDT | PolicyRegParamNorm         84.6995
2017-06-11 00:41:35.256545 EDT | QFunRegParamNorm          108.414
2017-06-11 00:41:35.256723 EDT | -----------------------  -----------
2017-06-11 00:41:35.257028 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #705 | Training started
2017-06-11 00:41:51.662868 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #705 | Training finished
2017-06-11 00:41:51.664070 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #705 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 00:41:51.664582 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #705 | Collecting samples for evaluation
2017-06-11 00:42:06.096197 EDT | -----------------------  -----------
2017-06-11 00:42:06.097193 EDT | Epoch                     705
2017-06-11 00:42:06.097742 EDT | Iteration                 705
2017-06-11 00:42:06.098650 EDT | AverageReturn             888.548
2017-06-11 00:42:06.099219 EDT | StdReturn                 239.184
2017-06-11 00:42:06.099774 EDT | MaxReturn                1385.14
2017-06-11 00:42:06.100306 EDT | MinReturn                 434.015
2017-06-11 00:42:06.100765 EDT | AverageEsReturn           455.814
2017-06-11 00:42:06.101216 EDT | StdEsReturn               238.54
2017-06-11 00:42:06.101664 EDT | MaxEsReturn               673.377
2017-06-11 00:42:06.102209 EDT | MinEsReturn                23.7257
2017-06-11 00:42:06.102656 EDT | AverageDiscountedReturn   231.006
2017-06-11 00:42:06.103102 EDT | AverageQLoss                2.32996
2017-06-11 00:42:06.103548 EDT | AveragePolicySurr         -30.9338
2017-06-11 00:42:06.103993 EDT | AverageQ                   30.5947
2017-06-11 00:42:06.104436 EDT | AverageAbsQ                30.6163
2017-06-11 00:42:06.105769 EDT | AverageY                   30.5941
2017-06-11 00:42:06.106234 EDT | AverageAbsY                30.6053
2017-06-11 00:42:06.106904 EDT | AverageAbsQYDiff            0.584603
2017-06-11 00:42:06.107625 EDT | AverageAction               0.982328
2017-06-11 00:42:06.108813 EDT | PolicyRegParamNorm         84.7139
2017-06-11 00:42:06.109302 EDT | QFunRegParamNorm          108.477
2017-06-11 00:42:06.109765 EDT | -----------------------  -----------
2017-06-11 00:42:06.110477 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #706 | Training started
2017-06-11 00:42:21.793821 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #706 | Training finished
2017-06-11 00:42:21.794571 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #706 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 00:42:21.794762 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #706 | Collecting samples for evaluation
2017-06-11 00:42:35.982260 EDT | -----------------------  -----------
2017-06-11 00:42:36.342844 EDT | Epoch                     706
2017-06-11 00:42:36.343122 EDT | Iteration                 706
2017-06-11 00:42:36.343299 EDT | AverageReturn            1269.83
2017-06-11 00:42:36.343470 EDT | StdReturn                 272.509
2017-06-11 00:42:36.343630 EDT | MaxReturn                2110.26
2017-06-11 00:42:36.343808 EDT | MinReturn                 865.869
2017-06-11 00:42:36.344003 EDT | AverageEsReturn           487.148
2017-06-11 00:42:36.344181 EDT | StdEsReturn               352.727
2017-06-11 00:42:36.344371 EDT | MaxEsReturn               915.35
2017-06-11 00:42:36.344561 EDT | MinEsReturn                42.5929
2017-06-11 00:42:36.344755 EDT | AverageDiscountedReturn   245.622
2017-06-11 00:42:36.344944 EDT | AverageQLoss                2.3656
2017-06-11 00:42:36.345222 EDT | AveragePolicySurr         -30.8771
2017-06-11 00:42:36.345403 EDT | AverageQ                   30.5312
2017-06-11 00:42:36.345567 EDT | AverageAbsQ                30.5635
2017-06-11 00:42:36.345770 EDT | AverageY                   30.5332
2017-06-11 00:42:36.349120 EDT | AverageAbsY                30.5525
2017-06-11 00:42:36.349893 EDT | AverageAbsQYDiff            0.564223
2017-06-11 00:42:36.350333 EDT | AverageAction               0.985916
2017-06-11 00:42:36.350770 EDT | PolicyRegParamNorm         84.7392
2017-06-11 00:42:36.351100 EDT | QFunRegParamNorm          108.552
2017-06-11 00:42:36.351430 EDT | -----------------------  -----------
2017-06-11 00:42:36.351957 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #707 | Training started
2017-06-11 00:42:52.942352 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #707 | Training finished
2017-06-11 00:42:52.943098 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #707 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 00:42:52.943300 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #707 | Collecting samples for evaluation
2017-06-11 00:43:05.855257 EDT | -----------------------  -----------
2017-06-11 00:43:05.856444 EDT | Epoch                     707
2017-06-11 00:43:05.856919 EDT | Iteration                 707
2017-06-11 00:43:05.857370 EDT | AverageReturn             995.599
2017-06-11 00:43:05.857835 EDT | StdReturn                 215.852
2017-06-11 00:43:05.858284 EDT | MaxReturn                1361.15
2017-06-11 00:43:05.858731 EDT | MinReturn                 680.747
2017-06-11 00:43:05.860044 EDT | AverageEsReturn           310.634
2017-06-11 00:43:05.860494 EDT | StdEsReturn               194.162
2017-06-11 00:43:05.861452 EDT | MaxEsReturn               713.189
2017-06-11 00:43:05.861922 EDT | MinEsReturn                20.8279
2017-06-11 00:43:05.865906 EDT | AverageDiscountedReturn   255.078
2017-06-11 00:43:05.866432 EDT | AverageQLoss                2.70529
2017-06-11 00:43:05.866885 EDT | AveragePolicySurr         -30.9977
2017-06-11 00:43:05.867402 EDT | AverageQ                   30.6273
2017-06-11 00:43:05.867866 EDT | AverageAbsQ                30.6613
2017-06-11 00:43:05.868319 EDT | AverageY                   30.6249
2017-06-11 00:43:05.868861 EDT | AverageAbsY                30.6446
2017-06-11 00:43:05.869530 EDT | AverageAbsQYDiff            0.577018
2017-06-11 00:43:05.869995 EDT | AverageAction               0.98962
2017-06-11 00:43:05.871352 EDT | PolicyRegParamNorm         84.7704
2017-06-11 00:43:05.872255 EDT | QFunRegParamNorm          108.662
2017-06-11 00:43:05.873585 EDT | -----------------------  -----------
2017-06-11 00:43:05.874102 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #708 | Training started
2017-06-11 00:43:23.325325 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #708 | Training finished
2017-06-11 00:43:23.326355 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #708 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 00:43:23.326745 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #708 | Collecting samples for evaluation
2017-06-11 00:43:36.990722 EDT | -----------------------  -----------
2017-06-11 00:43:36.991678 EDT | Epoch                     708
2017-06-11 00:43:36.992067 EDT | Iteration                 708
2017-06-11 00:43:36.992432 EDT | AverageReturn            1103.73
2017-06-11 00:43:36.992790 EDT | StdReturn                 387.346
2017-06-11 00:43:36.993153 EDT | MaxReturn                2384.81
2017-06-11 00:43:36.993514 EDT | MinReturn                 499.717
2017-06-11 00:43:36.993974 EDT | AverageEsReturn           361.567
2017-06-11 00:43:36.994458 EDT | StdEsReturn               292.686
2017-06-11 00:43:36.994818 EDT | MaxEsReturn               962.01
2017-06-11 00:43:36.995177 EDT | MinEsReturn                50.8936
2017-06-11 00:43:36.995639 EDT | AverageDiscountedReturn   217.618
2017-06-11 00:43:36.996023 EDT | AverageQLoss                2.13674
2017-06-11 00:43:36.996379 EDT | AveragePolicySurr         -30.9482
2017-06-11 00:43:36.996722 EDT | AverageQ                   30.5827
2017-06-11 00:43:36.997074 EDT | AverageAbsQ                30.6086
2017-06-11 00:43:36.997417 EDT | AverageY                   30.5848
2017-06-11 00:43:36.997866 EDT | AverageAbsY                30.5975
2017-06-11 00:43:36.998238 EDT | AverageAbsQYDiff            0.543889
2017-06-11 00:43:36.998800 EDT | AverageAction               0.988119
2017-06-11 00:43:36.999244 EDT | PolicyRegParamNorm         84.7779
2017-06-11 00:43:36.999686 EDT | QFunRegParamNorm          108.709
2017-06-11 00:43:37.000608 EDT | -----------------------  -----------
2017-06-11 00:43:37.001272 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #709 | Training started
2017-06-11 00:43:54.141515 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #709 | Training finished
2017-06-11 00:43:54.142175 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #709 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 00:43:54.142465 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #709 | Collecting samples for evaluation
2017-06-11 00:44:08.525968 EDT | -----------------------  -----------
2017-06-11 00:44:08.526884 EDT | Epoch                     709
2017-06-11 00:44:08.527256 EDT | Iteration                 709
2017-06-11 00:44:08.527611 EDT | AverageReturn            1538.22
2017-06-11 00:44:08.528038 EDT | StdReturn                 648.026
2017-06-11 00:44:08.528436 EDT | MaxReturn                3139.73
2017-06-11 00:44:08.528877 EDT | MinReturn                 673.977
2017-06-11 00:44:08.529302 EDT | AverageEsReturn           504.661
2017-06-11 00:44:08.529666 EDT | StdEsReturn               335.308
2017-06-11 00:44:08.530100 EDT | MaxEsReturn               903.86
2017-06-11 00:44:08.530537 EDT | MinEsReturn               111.542
2017-06-11 00:44:08.530916 EDT | AverageDiscountedReturn   252.454
2017-06-11 00:44:08.531334 EDT | AverageQLoss                2.28839
2017-06-11 00:44:08.531771 EDT | AveragePolicySurr         -30.934
2017-06-11 00:44:08.532178 EDT | AverageQ                   30.5677
2017-06-11 00:44:08.532567 EDT | AverageAbsQ                30.5965
2017-06-11 00:44:08.532989 EDT | AverageY                   30.5679
2017-06-11 00:44:08.533361 EDT | AverageAbsY                30.5879
2017-06-11 00:44:08.533725 EDT | AverageAbsQYDiff            0.547943
2017-06-11 00:44:08.534225 EDT | AverageAction               0.988539
2017-06-11 00:44:08.534668 EDT | PolicyRegParamNorm         84.8001
2017-06-11 00:44:08.535092 EDT | QFunRegParamNorm          108.764
2017-06-11 00:44:08.535509 EDT | -----------------------  -----------
2017-06-11 00:44:08.536104 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #710 | Training started
2017-06-11 00:44:24.557164 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #710 | Training finished
2017-06-11 00:44:24.558644 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #710 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 00:44:24.558941 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #710 | Collecting samples for evaluation
2017-06-11 00:44:38.583908 EDT | -----------------------  -----------
2017-06-11 00:44:38.584721 EDT | Epoch                     710
2017-06-11 00:44:38.584922 EDT | Iteration                 710
2017-06-11 00:44:38.585193 EDT | AverageReturn             934.943
2017-06-11 00:44:38.585381 EDT | StdReturn                 151.036
2017-06-11 00:44:38.585573 EDT | MaxReturn                1170.3
2017-06-11 00:44:38.585760 EDT | MinReturn                 669.817
2017-06-11 00:44:38.586052 EDT | AverageEsReturn           466.828
2017-06-11 00:44:38.586418 EDT | StdEsReturn               253.372
2017-06-11 00:44:38.586748 EDT | MaxEsReturn               827.907
2017-06-11 00:44:38.587067 EDT | MinEsReturn                11.6681
2017-06-11 00:44:38.587385 EDT | AverageDiscountedReturn   251.329
2017-06-11 00:44:38.587733 EDT | AverageQLoss                2.32511
2017-06-11 00:44:38.588067 EDT | AveragePolicySurr         -31.0049
2017-06-11 00:44:38.588400 EDT | AverageQ                   30.6441
2017-06-11 00:44:38.588667 EDT | AverageAbsQ                30.67
2017-06-11 00:44:38.589021 EDT | AverageY                   30.6463
2017-06-11 00:44:38.589307 EDT | AverageAbsY                30.6617
2017-06-11 00:44:38.589522 EDT | AverageAbsQYDiff            0.550752
2017-06-11 00:44:38.589718 EDT | AverageAction               0.989885
2017-06-11 00:44:38.589899 EDT | PolicyRegParamNorm         84.8662
2017-06-11 00:44:38.590064 EDT | QFunRegParamNorm          108.824
2017-06-11 00:44:38.590245 EDT | -----------------------  -----------
2017-06-11 00:44:38.590525 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #711 | Training started
2017-06-11 00:44:54.792283 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #711 | Training finished
2017-06-11 00:44:54.793114 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #711 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 00:44:54.794246 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #711 | Collecting samples for evaluation
2017-06-11 00:45:09.891655 EDT | -----------------------  -----------
2017-06-11 00:45:09.893045 EDT | Epoch                     711
2017-06-11 00:45:09.893829 EDT | Iteration                 711
2017-06-11 00:45:09.894106 EDT | AverageReturn            1282.3
2017-06-11 00:45:09.894437 EDT | StdReturn                 496.783
2017-06-11 00:45:09.894796 EDT | MaxReturn                2464.82
2017-06-11 00:45:09.895105 EDT | MinReturn                 699.503
2017-06-11 00:45:09.895365 EDT | AverageEsReturn           436.862
2017-06-11 00:45:09.895688 EDT | StdEsReturn               279.248
2017-06-11 00:45:09.896043 EDT | MaxEsReturn               730.904
2017-06-11 00:45:09.896616 EDT | MinEsReturn                17.4245
2017-06-11 00:45:09.897510 EDT | AverageDiscountedReturn   239.435
2017-06-11 00:45:09.897812 EDT | AverageQLoss                2.30161
2017-06-11 00:45:09.898133 EDT | AveragePolicySurr         -30.8486
2017-06-11 00:45:09.899145 EDT | AverageQ                   30.5034
2017-06-11 00:45:09.899491 EDT | AverageAbsQ                30.534
2017-06-11 00:45:09.900988 EDT | AverageY                   30.5037
2017-06-11 00:45:09.901445 EDT | AverageAbsY                30.5235
2017-06-11 00:45:09.901858 EDT | AverageAbsQYDiff            0.549929
2017-06-11 00:45:09.902159 EDT | AverageAction               0.987245
2017-06-11 00:45:09.902506 EDT | PolicyRegParamNorm         84.9678
2017-06-11 00:45:09.903052 EDT | QFunRegParamNorm          108.893
2017-06-11 00:45:09.903355 EDT | -----------------------  -----------
2017-06-11 00:45:09.905186 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #712 | Training started
2017-06-11 00:45:26.756588 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #712 | Training finished
2017-06-11 00:45:26.756829 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #712 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 00:45:26.757005 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #712 | Collecting samples for evaluation
2017-06-11 00:45:39.992755 EDT | -----------------------  -----------
2017-06-11 00:45:39.993536 EDT | Epoch                     712
2017-06-11 00:45:39.993912 EDT | Iteration                 712
2017-06-11 00:45:39.994268 EDT | AverageReturn            1515.81
2017-06-11 00:45:39.994601 EDT | StdReturn                 427.64
2017-06-11 00:45:39.994883 EDT | MaxReturn                2398.99
2017-06-11 00:45:39.995239 EDT | MinReturn                 863.009
2017-06-11 00:45:39.995503 EDT | AverageEsReturn           396.582
2017-06-11 00:45:39.995823 EDT | StdEsReturn               385.817
2017-06-11 00:45:39.996140 EDT | MaxEsReturn              1324.82
2017-06-11 00:45:39.996492 EDT | MinEsReturn               120.635
2017-06-11 00:45:39.996816 EDT | AverageDiscountedReturn   247.836
2017-06-11 00:45:39.997139 EDT | AverageQLoss                2.5159
2017-06-11 00:45:39.997405 EDT | AveragePolicySurr         -30.8967
2017-06-11 00:45:39.997750 EDT | AverageQ                   30.5274
2017-06-11 00:45:39.997972 EDT | AverageAbsQ                30.5554
2017-06-11 00:45:39.998297 EDT | AverageY                   30.5303
2017-06-11 00:45:39.998484 EDT | AverageAbsY                30.5477
2017-06-11 00:45:39.998830 EDT | AverageAbsQYDiff            0.583095
2017-06-11 00:45:39.999160 EDT | AverageAction               0.989716
2017-06-11 00:45:39.999486 EDT | PolicyRegParamNorm         84.9418
2017-06-11 00:45:39.999790 EDT | QFunRegParamNorm          108.972
2017-06-11 00:45:40.001581 EDT | -----------------------  -----------
2017-06-11 00:45:40.002038 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #713 | Training started
2017-06-11 00:45:57.602099 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #713 | Training finished
2017-06-11 00:45:57.602452 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #713 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 00:45:57.602628 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #713 | Collecting samples for evaluation
2017-06-11 00:46:12.124132 EDT | -----------------------  -----------
2017-06-11 00:46:12.125080 EDT | Epoch                     713
2017-06-11 00:46:12.125286 EDT | Iteration                 713
2017-06-11 00:46:12.125529 EDT | AverageReturn            2701.54
2017-06-11 00:46:12.125689 EDT | StdReturn                 485.045
2017-06-11 00:46:12.125901 EDT | MaxReturn                3245.01
2017-06-11 00:46:12.126069 EDT | MinReturn                1730.33
2017-06-11 00:46:12.126244 EDT | AverageEsReturn           282.826
2017-06-11 00:46:12.126435 EDT | StdEsReturn               194.54
2017-06-11 00:46:12.126589 EDT | MaxEsReturn               670.417
2017-06-11 00:46:12.126746 EDT | MinEsReturn                21.8209
2017-06-11 00:46:12.126897 EDT | AverageDiscountedReturn   244.226
2017-06-11 00:46:12.127045 EDT | AverageQLoss                2.6261
2017-06-11 00:46:12.127240 EDT | AveragePolicySurr         -30.8807
2017-06-11 00:46:12.127441 EDT | AverageQ                   30.5067
2017-06-11 00:46:12.127594 EDT | AverageAbsQ                30.5279
2017-06-11 00:46:12.127744 EDT | AverageY                   30.5069
2017-06-11 00:46:12.127894 EDT | AverageAbsY                30.5192
2017-06-11 00:46:12.128051 EDT | AverageAbsQYDiff            0.580599
2017-06-11 00:46:12.128210 EDT | AverageAction               0.988488
2017-06-11 00:46:12.128365 EDT | PolicyRegParamNorm         85.0102
2017-06-11 00:46:12.128531 EDT | QFunRegParamNorm          109.01
2017-06-11 00:46:12.128700 EDT | -----------------------  -----------
2017-06-11 00:46:12.129086 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #714 | Training started
2017-06-11 00:46:28.850695 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #714 | Training finished
2017-06-11 00:46:28.851639 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #714 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 00:46:28.852044 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #714 | Collecting samples for evaluation
2017-06-11 00:46:43.082621 EDT | -----------------------  -----------
2017-06-11 00:46:43.083540 EDT | Epoch                     714
2017-06-11 00:46:43.083880 EDT | Iteration                 714
2017-06-11 00:46:43.084179 EDT | AverageReturn            1513.41
2017-06-11 00:46:43.084486 EDT | StdReturn                 479.965
2017-06-11 00:46:43.084815 EDT | MaxReturn                2741.48
2017-06-11 00:46:43.085134 EDT | MinReturn                 938.268
2017-06-11 00:46:43.085448 EDT | AverageEsReturn           416.861
2017-06-11 00:46:43.085771 EDT | StdEsReturn               349.456
2017-06-11 00:46:43.086076 EDT | MaxEsReturn              1003.43
2017-06-11 00:46:43.086349 EDT | MinEsReturn               116.928
2017-06-11 00:46:43.086660 EDT | AverageDiscountedReturn   248.535
2017-06-11 00:46:43.086969 EDT | AverageQLoss                2.43349
2017-06-11 00:46:43.087278 EDT | AveragePolicySurr         -30.8887
2017-06-11 00:46:43.087604 EDT | AverageQ                   30.5575
2017-06-11 00:46:43.087921 EDT | AverageAbsQ                30.5725
2017-06-11 00:46:43.088233 EDT | AverageY                   30.5598
2017-06-11 00:46:43.088541 EDT | AverageAbsY                30.5682
2017-06-11 00:46:43.088786 EDT | AverageAbsQYDiff            0.5641
2017-06-11 00:46:43.089096 EDT | AverageAction               0.987908
2017-06-11 00:46:43.089355 EDT | PolicyRegParamNorm         85.0521
2017-06-11 00:46:43.089659 EDT | QFunRegParamNorm          109.079
2017-06-11 00:46:43.090086 EDT | -----------------------  -----------
2017-06-11 00:46:43.090583 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #715 | Training started
2017-06-11 00:46:59.835646 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #715 | Training finished
2017-06-11 00:46:59.838480 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #715 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 00:46:59.839027 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #715 | Collecting samples for evaluation
2017-06-11 00:47:13.952282 EDT | -----------------------  -----------
2017-06-11 00:47:13.953233 EDT | Epoch                     715
2017-06-11 00:47:13.953580 EDT | Iteration                 715
2017-06-11 00:47:13.953929 EDT | AverageReturn            1015.52
2017-06-11 00:47:13.954257 EDT | StdReturn                 165.631
2017-06-11 00:47:13.954584 EDT | MaxReturn                1453.05
2017-06-11 00:47:13.954909 EDT | MinReturn                 758.921
2017-06-11 00:47:13.955231 EDT | AverageEsReturn           590.152
2017-06-11 00:47:13.955553 EDT | StdEsReturn               322.477
2017-06-11 00:47:13.955874 EDT | MaxEsReturn               921.337
2017-06-11 00:47:13.956194 EDT | MinEsReturn                97.4364
2017-06-11 00:47:13.956515 EDT | AverageDiscountedReturn   247.26
2017-06-11 00:47:13.956834 EDT | AverageQLoss                2.37391
2017-06-11 00:47:13.957158 EDT | AveragePolicySurr         -30.8204
2017-06-11 00:47:13.957485 EDT | AverageQ                   30.4939
2017-06-11 00:47:13.957813 EDT | AverageAbsQ                30.5166
2017-06-11 00:47:13.958134 EDT | AverageY                   30.4942
2017-06-11 00:47:13.958454 EDT | AverageAbsY                30.505
2017-06-11 00:47:13.958779 EDT | AverageAbsQYDiff            0.572145
2017-06-11 00:47:13.959098 EDT | AverageAction               0.988779
2017-06-11 00:47:13.959420 EDT | PolicyRegParamNorm         85.1341
2017-06-11 00:47:13.959739 EDT | QFunRegParamNorm          109.131
2017-06-11 00:47:13.960057 EDT | -----------------------  -----------
2017-06-11 00:47:13.960523 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #716 | Training started
2017-06-11 00:47:30.384341 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #716 | Training finished
2017-06-11 00:47:30.385189 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #716 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 00:47:30.385602 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #716 | Collecting samples for evaluation
2017-06-11 00:47:44.942627 EDT | -----------------------  -----------
2017-06-11 00:47:44.943688 EDT | Epoch                     716
2017-06-11 00:47:44.944144 EDT | Iteration                 716
2017-06-11 00:47:44.944528 EDT | AverageReturn            1150.74
2017-06-11 00:47:44.944915 EDT | StdReturn                 220.477
2017-06-11 00:47:44.945346 EDT | MaxReturn                1672.62
2017-06-11 00:47:44.945765 EDT | MinReturn                 694.085
2017-06-11 00:47:44.946127 EDT | AverageEsReturn           398.509
2017-06-11 00:47:44.946540 EDT | StdEsReturn               206.64
2017-06-11 00:47:44.946962 EDT | MaxEsReturn               729.018
2017-06-11 00:47:44.947310 EDT | MinEsReturn                27.9717
2017-06-11 00:47:44.947722 EDT | AverageDiscountedReturn   241.739
2017-06-11 00:47:44.948152 EDT | AverageQLoss                2.62934
2017-06-11 00:47:44.948528 EDT | AveragePolicySurr         -30.8397
2017-06-11 00:47:44.948913 EDT | AverageQ                   30.5124
2017-06-11 00:47:44.949340 EDT | AverageAbsQ                30.5378
2017-06-11 00:47:44.949752 EDT | AverageY                   30.5148
2017-06-11 00:47:44.950112 EDT | AverageAbsY                30.5244
2017-06-11 00:47:44.950533 EDT | AverageAbsQYDiff            0.578576
2017-06-11 00:47:44.950954 EDT | AverageAction               0.989908
2017-06-11 00:47:44.951307 EDT | PolicyRegParamNorm         85.206
2017-06-11 00:47:44.951727 EDT | QFunRegParamNorm          109.203
2017-06-11 00:47:44.952153 EDT | -----------------------  -----------
2017-06-11 00:47:44.952680 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #717 | Training started
2017-06-11 00:48:03.322396 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #717 | Training finished
2017-06-11 00:48:03.323417 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #717 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 00:48:03.323802 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #717 | Collecting samples for evaluation
2017-06-11 00:48:17.294262 EDT | -----------------------  -----------
2017-06-11 00:48:17.297905 EDT | Epoch                     717
2017-06-11 00:48:17.298195 EDT | Iteration                 717
2017-06-11 00:48:17.298451 EDT | AverageReturn            1032.27
2017-06-11 00:48:17.298704 EDT | StdReturn                 232.626
2017-06-11 00:48:17.298953 EDT | MaxReturn                1451.48
2017-06-11 00:48:17.299200 EDT | MinReturn                 632.666
2017-06-11 00:48:17.299447 EDT | AverageEsReturn           573.601
2017-06-11 00:48:17.299692 EDT | StdEsReturn               281.674
2017-06-11 00:48:17.299945 EDT | MaxEsReturn               911.647
2017-06-11 00:48:17.300190 EDT | MinEsReturn                95.2273
2017-06-11 00:48:17.300435 EDT | AverageDiscountedReturn   228.089
2017-06-11 00:48:17.300679 EDT | AverageQLoss                2.58603
2017-06-11 00:48:17.300923 EDT | AveragePolicySurr         -30.8314
2017-06-11 00:48:17.301166 EDT | AverageQ                   30.5014
2017-06-11 00:48:17.301410 EDT | AverageAbsQ                30.5221
2017-06-11 00:48:17.301653 EDT | AverageY                   30.4995
2017-06-11 00:48:17.301910 EDT | AverageAbsY                30.5088
2017-06-11 00:48:17.302154 EDT | AverageAbsQYDiff            0.582532
2017-06-11 00:48:17.302397 EDT | AverageAction               0.990032
2017-06-11 00:48:17.302640 EDT | PolicyRegParamNorm         85.289
2017-06-11 00:48:17.302883 EDT | QFunRegParamNorm          109.268
2017-06-11 00:48:17.303125 EDT | -----------------------  -----------
2017-06-11 00:48:17.303512 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #718 | Training started
2017-06-11 00:48:35.133578 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #718 | Training finished
2017-06-11 00:48:35.134423 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #718 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 00:48:35.134632 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #718 | Collecting samples for evaluation
2017-06-11 00:48:49.279515 EDT | -----------------------  -----------
2017-06-11 00:48:49.280588 EDT | Epoch                     718
2017-06-11 00:48:49.281022 EDT | Iteration                 718
2017-06-11 00:48:49.281532 EDT | AverageReturn             781.284
2017-06-11 00:48:49.281987 EDT | StdReturn                 143.673
2017-06-11 00:48:49.282410 EDT | MaxReturn                1046.67
2017-06-11 00:48:49.282970 EDT | MinReturn                 535.849
2017-06-11 00:48:49.283701 EDT | AverageEsReturn           266.96
2017-06-11 00:48:49.284134 EDT | StdEsReturn               131.996
2017-06-11 00:48:49.284553 EDT | MaxEsReturn               493.312
2017-06-11 00:48:49.285206 EDT | MinEsReturn               115.789
2017-06-11 00:48:49.285854 EDT | AverageDiscountedReturn   218.001
2017-06-11 00:48:49.287129 EDT | AverageQLoss                2.26933
2017-06-11 00:48:49.287618 EDT | AveragePolicySurr         -30.8201
2017-06-11 00:48:49.288281 EDT | AverageQ                   30.4703
2017-06-11 00:48:49.288717 EDT | AverageAbsQ                30.4935
2017-06-11 00:48:49.289141 EDT | AverageY                   30.4719
2017-06-11 00:48:49.290670 EDT | AverageAbsY                30.4848
2017-06-11 00:48:49.291011 EDT | AverageAbsQYDiff            0.567409
2017-06-11 00:48:49.291355 EDT | AverageAction               0.990782
2017-06-11 00:48:49.291686 EDT | PolicyRegParamNorm         85.3509
2017-06-11 00:48:49.292003 EDT | QFunRegParamNorm          109.318
2017-06-11 00:48:49.292321 EDT | -----------------------  -----------
2017-06-11 00:48:49.292843 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #719 | Training started
2017-06-11 00:49:07.170543 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #719 | Training finished
2017-06-11 00:49:07.172097 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #719 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 00:49:07.172420 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #719 | Collecting samples for evaluation
2017-06-11 00:49:21.377566 EDT | -----------------------  -----------
2017-06-11 00:49:21.378532 EDT | Epoch                     719
2017-06-11 00:49:21.378900 EDT | Iteration                 719
2017-06-11 00:49:21.379342 EDT | AverageReturn            1084.5
2017-06-11 00:49:21.379689 EDT | StdReturn                 517.452
2017-06-11 00:49:21.380091 EDT | MaxReturn                3193.88
2017-06-11 00:49:21.380440 EDT | MinReturn                 714.164
2017-06-11 00:49:21.380785 EDT | AverageEsReturn           354.674
2017-06-11 00:49:21.381188 EDT | StdEsReturn               270.037
2017-06-11 00:49:21.381533 EDT | MaxEsReturn               857.865
2017-06-11 00:49:21.382050 EDT | MinEsReturn                28.4464
2017-06-11 00:49:21.382397 EDT | AverageDiscountedReturn   242.62
2017-06-11 00:49:21.382872 EDT | AverageQLoss                2.49332
2017-06-11 00:49:21.383221 EDT | AveragePolicySurr         -30.7737
2017-06-11 00:49:21.383637 EDT | AverageQ                   30.4261
2017-06-11 00:49:21.383983 EDT | AverageAbsQ                30.4473
2017-06-11 00:49:21.384325 EDT | AverageY                   30.4272
2017-06-11 00:49:21.384757 EDT | AverageAbsY                30.4405
2017-06-11 00:49:21.385100 EDT | AverageAbsQYDiff            0.570285
2017-06-11 00:49:21.385618 EDT | AverageAction               0.982196
2017-06-11 00:49:21.385976 EDT | PolicyRegParamNorm         85.393
2017-06-11 00:49:21.386317 EDT | QFunRegParamNorm          109.426
2017-06-11 00:49:21.386713 EDT | -----------------------  -----------
2017-06-11 00:49:21.387221 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #720 | Training started
2017-06-11 00:49:38.150454 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #720 | Training finished
2017-06-11 00:49:38.151223 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #720 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 00:49:38.151420 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #720 | Collecting samples for evaluation
2017-06-11 00:49:52.216851 EDT | -----------------------  -----------
2017-06-11 00:49:52.217996 EDT | Epoch                     720
2017-06-11 00:49:52.218344 EDT | Iteration                 720
2017-06-11 00:49:52.220800 EDT | AverageReturn            1248.48
2017-06-11 00:49:52.222782 EDT | StdReturn                 626.297
2017-06-11 00:49:52.223118 EDT | MaxReturn                3375.74
2017-06-11 00:49:52.223447 EDT | MinReturn                 612.978
2017-06-11 00:49:52.223714 EDT | AverageEsReturn           260.011
2017-06-11 00:49:52.224005 EDT | StdEsReturn               162.778
2017-06-11 00:49:52.224334 EDT | MaxEsReturn               602.57
2017-06-11 00:49:52.224663 EDT | MinEsReturn                80.2656
2017-06-11 00:49:52.224929 EDT | AverageDiscountedReturn   247.559
2017-06-11 00:49:52.225228 EDT | AverageQLoss                2.11717
2017-06-11 00:49:52.225553 EDT | AveragePolicySurr         -30.8109
2017-06-11 00:49:52.225898 EDT | AverageQ                   30.4744
2017-06-11 00:49:52.226200 EDT | AverageAbsQ                30.5011
2017-06-11 00:49:52.226526 EDT | AverageY                   30.4763
2017-06-11 00:49:52.226858 EDT | AverageAbsY                30.4884
2017-06-11 00:49:52.227130 EDT | AverageAbsQYDiff            0.551098
2017-06-11 00:49:52.227396 EDT | AverageAction               0.988597
2017-06-11 00:49:52.227716 EDT | PolicyRegParamNorm         85.3964
2017-06-11 00:49:52.228060 EDT | QFunRegParamNorm          109.485
2017-06-11 00:49:52.232055 EDT | -----------------------  -----------
2017-06-11 00:49:52.234668 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #721 | Training started
2017-06-11 00:50:08.778458 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #721 | Training finished
2017-06-11 00:50:08.779525 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #721 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 00:50:08.779939 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #721 | Collecting samples for evaluation
2017-06-11 00:50:22.507163 EDT | -----------------------  -----------
2017-06-11 00:50:22.507902 EDT | Epoch                     721
2017-06-11 00:50:22.508238 EDT | Iteration                 721
2017-06-11 00:50:22.508547 EDT | AverageReturn             911.872
2017-06-11 00:50:22.508887 EDT | StdReturn                 688.53
2017-06-11 00:50:22.509219 EDT | MaxReturn                2994.52
2017-06-11 00:50:22.510395 EDT | MinReturn                 293.938
2017-06-11 00:50:22.510801 EDT | AverageEsReturn           337.478
2017-06-11 00:50:22.511249 EDT | StdEsReturn               257.213
2017-06-11 00:50:22.511638 EDT | MaxEsReturn               879.842
2017-06-11 00:50:22.511993 EDT | MinEsReturn                61.7118
2017-06-11 00:50:22.512419 EDT | AverageDiscountedReturn   211.847
2017-06-11 00:50:22.512810 EDT | AverageQLoss                2.38106
2017-06-11 00:50:22.513142 EDT | AveragePolicySurr         -30.7757
2017-06-11 00:50:22.513463 EDT | AverageQ                   30.4453
2017-06-11 00:50:22.513824 EDT | AverageAbsQ                30.474
2017-06-11 00:50:22.514151 EDT | AverageY                   30.4466
2017-06-11 00:50:22.514438 EDT | AverageAbsY                30.4638
2017-06-11 00:50:22.514749 EDT | AverageAbsQYDiff            0.577337
2017-06-11 00:50:22.515071 EDT | AverageAction               0.992751
2017-06-11 00:50:22.515384 EDT | PolicyRegParamNorm         85.5445
2017-06-11 00:50:22.515678 EDT | QFunRegParamNorm          109.575
2017-06-11 00:50:22.515899 EDT | -----------------------  -----------
2017-06-11 00:50:22.516342 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #722 | Training started
2017-06-11 00:50:40.312520 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #722 | Training finished
2017-06-11 00:50:40.313418 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #722 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 00:50:40.313785 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #722 | Collecting samples for evaluation
2017-06-11 00:50:54.425205 EDT | -----------------------  -----------
2017-06-11 00:50:54.425930 EDT | Epoch                     722
2017-06-11 00:50:54.426261 EDT | Iteration                 722
2017-06-11 00:50:54.426531 EDT | AverageReturn             985.909
2017-06-11 00:50:54.426691 EDT | StdReturn                 225.437
2017-06-11 00:50:54.426844 EDT | MaxReturn                1672.04
2017-06-11 00:50:54.427028 EDT | MinReturn                 658.027
2017-06-11 00:50:54.427181 EDT | AverageEsReturn           186.036
2017-06-11 00:50:54.427335 EDT | StdEsReturn               110.835
2017-06-11 00:50:54.427591 EDT | MaxEsReturn               355.283
2017-06-11 00:50:54.427743 EDT | MinEsReturn                34.4318
2017-06-11 00:50:54.427893 EDT | AverageDiscountedReturn   235.705
2017-06-11 00:50:54.428116 EDT | AverageQLoss                1.9979
2017-06-11 00:50:54.428388 EDT | AveragePolicySurr         -30.8279
2017-06-11 00:50:54.430234 EDT | AverageQ                   30.4818
2017-06-11 00:50:54.432097 EDT | AverageAbsQ                30.508
2017-06-11 00:50:54.432373 EDT | AverageY                   30.4817
2017-06-11 00:50:54.432783 EDT | AverageAbsY                30.497
2017-06-11 00:50:54.433039 EDT | AverageAbsQYDiff            0.536941
2017-06-11 00:50:54.433640 EDT | AverageAction               0.990347
2017-06-11 00:50:54.435529 EDT | PolicyRegParamNorm         85.5975
2017-06-11 00:50:54.435725 EDT | QFunRegParamNorm          109.633
2017-06-11 00:50:54.435896 EDT | -----------------------  -----------
2017-06-11 00:50:54.436171 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #723 | Training started
2017-06-11 00:51:11.956825 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #723 | Training finished
2017-06-11 00:51:11.957874 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #723 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 00:51:11.958230 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #723 | Collecting samples for evaluation
2017-06-11 00:51:26.099342 EDT | -----------------------  -----------
2017-06-11 00:51:26.099829 EDT | Epoch                     723
2017-06-11 00:51:26.100329 EDT | Iteration                 723
2017-06-11 00:51:26.100782 EDT | AverageReturn            1502.48
2017-06-11 00:51:26.101257 EDT | StdReturn                 569.017
2017-06-11 00:51:26.101617 EDT | MaxReturn                2580.48
2017-06-11 00:51:26.101980 EDT | MinReturn                 334.669
2017-06-11 00:51:26.102325 EDT | AverageEsReturn           434.812
2017-06-11 00:51:26.102667 EDT | StdEsReturn               325.802
2017-06-11 00:51:26.103008 EDT | MaxEsReturn              1058.13
2017-06-11 00:51:26.103348 EDT | MinEsReturn                73.7872
2017-06-11 00:51:26.103690 EDT | AverageDiscountedReturn   241.693
2017-06-11 00:51:26.104030 EDT | AverageQLoss                2.52082
2017-06-11 00:51:26.104645 EDT | AveragePolicySurr         -30.8365
2017-06-11 00:51:26.104989 EDT | AverageQ                   30.4857
2017-06-11 00:51:26.105508 EDT | AverageAbsQ                30.515
2017-06-11 00:51:26.105867 EDT | AverageY                   30.4882
2017-06-11 00:51:26.106212 EDT | AverageAbsY                30.5028
2017-06-11 00:51:26.107867 EDT | AverageAbsQYDiff            0.582056
2017-06-11 00:51:26.108238 EDT | AverageAction               0.993919
2017-06-11 00:51:26.109060 EDT | PolicyRegParamNorm         85.6307
2017-06-11 00:51:26.109530 EDT | QFunRegParamNorm          109.713
2017-06-11 00:51:26.109886 EDT | -----------------------  -----------
2017-06-11 00:51:26.110404 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #724 | Training started
2017-06-11 00:51:43.938034 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #724 | Training finished
2017-06-11 00:51:43.939225 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #724 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 00:51:43.939875 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #724 | Collecting samples for evaluation
2017-06-11 00:51:58.516848 EDT | -----------------------  -----------
2017-06-11 00:51:58.524773 EDT | Epoch                     724
2017-06-11 00:51:58.525152 EDT | Iteration                 724
2017-06-11 00:51:58.525502 EDT | AverageReturn            1153.77
2017-06-11 00:51:58.525863 EDT | StdReturn                 291.304
2017-06-11 00:51:58.526207 EDT | MaxReturn                2050.72
2017-06-11 00:51:58.526554 EDT | MinReturn                 640.683
2017-06-11 00:51:58.526897 EDT | AverageEsReturn           347.446
2017-06-11 00:51:58.527243 EDT | StdEsReturn               204.265
2017-06-11 00:51:58.527586 EDT | MaxEsReturn               723.36
2017-06-11 00:51:58.527929 EDT | MinEsReturn               110.576
2017-06-11 00:51:58.528272 EDT | AverageDiscountedReturn   254.522
2017-06-11 00:51:58.528616 EDT | AverageQLoss                2.28994
2017-06-11 00:51:58.528957 EDT | AveragePolicySurr         -30.8002
2017-06-11 00:51:58.529300 EDT | AverageQ                   30.4542
2017-06-11 00:51:58.529637 EDT | AverageAbsQ                30.4871
2017-06-11 00:51:58.529994 EDT | AverageY                   30.4536
2017-06-11 00:51:58.530341 EDT | AverageAbsY                30.4735
2017-06-11 00:51:58.530691 EDT | AverageAbsQYDiff            0.561919
2017-06-11 00:51:58.531032 EDT | AverageAction               0.991031
2017-06-11 00:51:58.531369 EDT | PolicyRegParamNorm         85.711
2017-06-11 00:51:58.531712 EDT | QFunRegParamNorm          109.76
2017-06-11 00:51:58.532055 EDT | -----------------------  -----------
2017-06-11 00:51:58.532561 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #725 | Training started
2017-06-11 00:52:15.197731 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #725 | Training finished
2017-06-11 00:52:15.204682 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #725 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 00:52:15.205156 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #725 | Collecting samples for evaluation
2017-06-11 00:52:30.497934 EDT | -----------------------  -----------
2017-06-11 00:52:30.498882 EDT | Epoch                     725
2017-06-11 00:52:30.499206 EDT | Iteration                 725
2017-06-11 00:52:30.499591 EDT | AverageReturn            1018.79
2017-06-11 00:52:30.499967 EDT | StdReturn                 319.609
2017-06-11 00:52:30.500426 EDT | MaxReturn                2269.34
2017-06-11 00:52:30.500617 EDT | MinReturn                 716.094
2017-06-11 00:52:30.500803 EDT | AverageEsReturn           303.521
2017-06-11 00:52:30.504711 EDT | StdEsReturn               250.263
2017-06-11 00:52:30.504931 EDT | MaxEsReturn               725.225
2017-06-11 00:52:30.505439 EDT | MinEsReturn                50.7642
2017-06-11 00:52:30.505627 EDT | AverageDiscountedReturn   240.646
2017-06-11 00:52:30.505887 EDT | AverageQLoss                2.20867
2017-06-11 00:52:30.506079 EDT | AveragePolicySurr         -30.7353
2017-06-11 00:52:30.506261 EDT | AverageQ                   30.3944
2017-06-11 00:52:30.506443 EDT | AverageAbsQ                30.4273
2017-06-11 00:52:30.506624 EDT | AverageY                   30.3942
2017-06-11 00:52:30.506806 EDT | AverageAbsY                30.4161
2017-06-11 00:52:30.506984 EDT | AverageAbsQYDiff            0.561072
2017-06-11 00:52:30.507163 EDT | AverageAction               0.990191
2017-06-11 00:52:30.507343 EDT | PolicyRegParamNorm         85.7304
2017-06-11 00:52:30.507520 EDT | QFunRegParamNorm          109.816
2017-06-11 00:52:30.507697 EDT | -----------------------  -----------
2017-06-11 00:52:30.508010 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #726 | Training started
2017-06-11 00:52:48.136544 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #726 | Training finished
2017-06-11 00:52:48.137280 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #726 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 00:52:48.137639 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #726 | Collecting samples for evaluation
2017-06-11 00:53:02.050352 EDT | -----------------------  ----------
2017-06-11 00:53:02.051302 EDT | Epoch                     726
2017-06-11 00:53:02.051661 EDT | Iteration                 726
2017-06-11 00:53:02.052033 EDT | AverageReturn             890.884
2017-06-11 00:53:02.052372 EDT | StdReturn                 137.489
2017-06-11 00:53:02.052689 EDT | MaxReturn                1359.26
2017-06-11 00:53:02.053006 EDT | MinReturn                 751.653
2017-06-11 00:53:02.053425 EDT | AverageEsReturn           319.185
2017-06-11 00:53:02.053751 EDT | StdEsReturn               144.8
2017-06-11 00:53:02.053916 EDT | MaxEsReturn               631.124
2017-06-11 00:53:02.054191 EDT | MinEsReturn               115.327
2017-06-11 00:53:02.056661 EDT | AverageDiscountedReturn   236.462
2017-06-11 00:53:02.057603 EDT | AverageQLoss                2.24953
2017-06-11 00:53:02.057890 EDT | AveragePolicySurr         -30.763
2017-06-11 00:53:02.062121 EDT | AverageQ                   30.4082
2017-06-11 00:53:02.062402 EDT | AverageAbsQ                30.4408
2017-06-11 00:53:02.062618 EDT | AverageY                   30.4123
2017-06-11 00:53:02.062772 EDT | AverageAbsY                30.4287
2017-06-11 00:53:02.062923 EDT | AverageAbsQYDiff            0.57244
2017-06-11 00:53:02.063082 EDT | AverageAction               0.99145
2017-06-11 00:53:02.063232 EDT | PolicyRegParamNorm         85.7288
2017-06-11 00:53:02.063381 EDT | QFunRegParamNorm          109.937
2017-06-11 00:53:02.063530 EDT | -----------------------  ----------
2017-06-11 00:53:02.063799 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #727 | Training started
2017-06-11 00:53:18.921390 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #727 | Training finished
2017-06-11 00:53:18.922311 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #727 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 00:53:18.922603 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #727 | Collecting samples for evaluation
2017-06-11 00:53:33.217611 EDT | -----------------------  -----------
2017-06-11 00:53:33.218813 EDT | Epoch                     727
2017-06-11 00:53:33.219190 EDT | Iteration                 727
2017-06-11 00:53:33.224405 EDT | AverageReturn             177.738
2017-06-11 00:53:33.224799 EDT | StdReturn                 267.297
2017-06-11 00:53:33.225155 EDT | MaxReturn                1249.7
2017-06-11 00:53:33.225423 EDT | MinReturn                  73.4899
2017-06-11 00:53:33.228805 EDT | AverageEsReturn           587.808
2017-06-11 00:53:33.229152 EDT | StdEsReturn               301.321
2017-06-11 00:53:33.229520 EDT | MaxEsReturn               889.827
2017-06-11 00:53:33.229870 EDT | MinEsReturn                24.8865
2017-06-11 00:53:33.230214 EDT | AverageDiscountedReturn    86.3407
2017-06-11 00:53:33.230581 EDT | AverageQLoss                2.28425
2017-06-11 00:53:33.230924 EDT | AveragePolicySurr         -30.7115
2017-06-11 00:53:33.231264 EDT | AverageQ                   30.3396
2017-06-11 00:53:33.231632 EDT | AverageAbsQ                30.3683
2017-06-11 00:53:33.231972 EDT | AverageY                   30.34
2017-06-11 00:53:33.232495 EDT | AverageAbsY                30.3591
2017-06-11 00:53:33.232862 EDT | AverageAbsQYDiff            0.573484
2017-06-11 00:53:33.233203 EDT | AverageAction               0.994221
2017-06-11 00:53:33.233547 EDT | PolicyRegParamNorm         85.743
2017-06-11 00:53:33.233925 EDT | QFunRegParamNorm          110.028
2017-06-11 00:53:33.234269 EDT | -----------------------  -----------
2017-06-11 00:53:33.234960 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #728 | Training started
2017-06-11 00:53:51.725870 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #728 | Training finished
2017-06-11 00:53:51.726294 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #728 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 00:53:51.726590 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #728 | Collecting samples for evaluation
2017-06-11 00:54:04.628054 EDT | -----------------------  -----------
2017-06-11 00:54:04.629019 EDT | Epoch                     728
2017-06-11 00:54:04.629356 EDT | Iteration                 728
2017-06-11 00:54:04.629645 EDT | AverageReturn            1152.24
2017-06-11 00:54:04.629968 EDT | StdReturn                 321.38
2017-06-11 00:54:04.630299 EDT | MaxReturn                2369.68
2017-06-11 00:54:04.630619 EDT | MinReturn                 845.164
2017-06-11 00:54:04.630942 EDT | AverageEsReturn           347.626
2017-06-11 00:54:04.631246 EDT | StdEsReturn               294.37
2017-06-11 00:54:04.631557 EDT | MaxEsReturn               922.067
2017-06-11 00:54:04.631881 EDT | MinEsReturn                83.715
2017-06-11 00:54:04.632172 EDT | AverageDiscountedReturn   251.806
2017-06-11 00:54:04.633630 EDT | AverageQLoss                2.36665
2017-06-11 00:54:04.633834 EDT | AveragePolicySurr         -30.7647
2017-06-11 00:54:04.634007 EDT | AverageQ                   30.4049
2017-06-11 00:54:04.634181 EDT | AverageAbsQ                30.4269
2017-06-11 00:54:04.634366 EDT | AverageY                   30.4062
2017-06-11 00:54:04.634549 EDT | AverageAbsY                30.4189
2017-06-11 00:54:04.634830 EDT | AverageAbsQYDiff            0.561792
2017-06-11 00:54:04.635009 EDT | AverageAction               0.990422
2017-06-11 00:54:04.635191 EDT | PolicyRegParamNorm         85.8594
2017-06-11 00:54:04.635371 EDT | QFunRegParamNorm          110.088
2017-06-11 00:54:04.635610 EDT | -----------------------  -----------
2017-06-11 00:54:04.635905 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #729 | Training started
2017-06-11 00:54:21.912934 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #729 | Training finished
2017-06-11 00:54:21.913251 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #729 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 00:54:21.913464 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #729 | Collecting samples for evaluation
2017-06-11 00:54:35.911198 EDT | -----------------------  -----------
2017-06-11 00:54:35.912198 EDT | Epoch                     729
2017-06-11 00:54:35.912552 EDT | Iteration                 729
2017-06-11 00:54:35.912879 EDT | AverageReturn             789.122
2017-06-11 00:54:35.913172 EDT | StdReturn                 144.296
2017-06-11 00:54:35.913516 EDT | MaxReturn                1354.73
2017-06-11 00:54:35.913999 EDT | MinReturn                 583.842
2017-06-11 00:54:35.914420 EDT | AverageEsReturn           228.916
2017-06-11 00:54:35.915021 EDT | StdEsReturn               174.923
2017-06-11 00:54:35.915393 EDT | MaxEsReturn               638.669
2017-06-11 00:54:35.915836 EDT | MinEsReturn                30.7106
2017-06-11 00:54:35.916276 EDT | AverageDiscountedReturn   215.936
2017-06-11 00:54:35.916719 EDT | AverageQLoss                2.26725
2017-06-11 00:54:35.917158 EDT | AveragePolicySurr         -30.7037
2017-06-11 00:54:35.917597 EDT | AverageQ                   30.362
2017-06-11 00:54:35.918053 EDT | AverageAbsQ                30.391
2017-06-11 00:54:35.918493 EDT | AverageY                   30.3626
2017-06-11 00:54:35.918933 EDT | AverageAbsY                30.3771
2017-06-11 00:54:35.919373 EDT | AverageAbsQYDiff            0.568472
2017-06-11 00:54:35.919812 EDT | AverageAction               0.991468
2017-06-11 00:54:35.920255 EDT | PolicyRegParamNorm         85.9255
2017-06-11 00:54:35.920694 EDT | QFunRegParamNorm          110.166
2017-06-11 00:54:35.921133 EDT | -----------------------  -----------
2017-06-11 00:54:35.921761 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #730 | Training started
2017-06-11 00:54:51.834600 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #730 | Training finished
2017-06-11 00:54:51.836084 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #730 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 00:54:51.836302 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #730 | Collecting samples for evaluation
2017-06-11 00:55:06.085736 EDT | -----------------------  -----------
2017-06-11 00:55:06.087219 EDT | Epoch                     730
2017-06-11 00:55:06.087502 EDT | Iteration                 730
2017-06-11 00:55:06.087741 EDT | AverageReturn             509.212
2017-06-11 00:55:06.087900 EDT | StdReturn                 495.953
2017-06-11 00:55:06.088161 EDT | MaxReturn                2294.28
2017-06-11 00:55:06.088376 EDT | MinReturn                  71.5129
2017-06-11 00:55:06.088530 EDT | AverageEsReturn           423.443
2017-06-11 00:55:06.088698 EDT | StdEsReturn               337.609
2017-06-11 00:55:06.088966 EDT | MaxEsReturn               885.249
2017-06-11 00:55:06.089192 EDT | MinEsReturn                25.7581
2017-06-11 00:55:06.089347 EDT | AverageDiscountedReturn   156.421
2017-06-11 00:55:06.089594 EDT | AverageQLoss                2.25642
2017-06-11 00:55:06.089782 EDT | AveragePolicySurr         -30.7905
2017-06-11 00:55:06.090090 EDT | AverageQ                   30.4147
2017-06-11 00:55:06.090410 EDT | AverageAbsQ                30.4445
2017-06-11 00:55:06.090725 EDT | AverageY                   30.417
2017-06-11 00:55:06.091030 EDT | AverageAbsY                30.4339
2017-06-11 00:55:06.091448 EDT | AverageAbsQYDiff            0.566047
2017-06-11 00:55:06.091611 EDT | AverageAction               0.98973
2017-06-11 00:55:06.091766 EDT | PolicyRegParamNorm         85.9635
2017-06-11 00:55:06.091917 EDT | QFunRegParamNorm          110.248
2017-06-11 00:55:06.092069 EDT | -----------------------  -----------
2017-06-11 00:55:06.092316 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #731 | Training started
2017-06-11 00:55:23.251521 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #731 | Training finished
2017-06-11 00:55:23.252331 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #731 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 00:55:23.252686 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #731 | Collecting samples for evaluation
2017-06-11 00:55:36.784384 EDT | -----------------------  -----------
2017-06-11 00:55:36.786011 EDT | Epoch                     731
2017-06-11 00:55:36.786461 EDT | Iteration                 731
2017-06-11 00:55:36.786889 EDT | AverageReturn            1000.48
2017-06-11 00:55:36.787242 EDT | StdReturn                 518.541
2017-06-11 00:55:36.787665 EDT | MaxReturn                2538.91
2017-06-11 00:55:36.788101 EDT | MinReturn                 262.131
2017-06-11 00:55:36.788492 EDT | AverageEsReturn           554.571
2017-06-11 00:55:36.788859 EDT | StdEsReturn               495.037
2017-06-11 00:55:36.789278 EDT | MaxEsReturn              1362.87
2017-06-11 00:55:36.789712 EDT | MinEsReturn                26.1783
2017-06-11 00:55:36.791333 EDT | AverageDiscountedReturn   200.019
2017-06-11 00:55:36.791713 EDT | AverageQLoss                2.4403
2017-06-11 00:55:36.792136 EDT | AveragePolicySurr         -30.7087
2017-06-11 00:55:36.792569 EDT | AverageQ                   30.3793
2017-06-11 00:55:36.792934 EDT | AverageAbsQ                30.404
2017-06-11 00:55:36.793331 EDT | AverageY                   30.3797
2017-06-11 00:55:36.793764 EDT | AverageAbsY                30.3922
2017-06-11 00:55:36.794179 EDT | AverageAbsQYDiff            0.576766
2017-06-11 00:55:36.794530 EDT | AverageAction               0.991533
2017-06-11 00:55:36.794950 EDT | PolicyRegParamNorm         85.9512
2017-06-11 00:55:36.795382 EDT | QFunRegParamNorm          110.297
2017-06-11 00:55:36.795763 EDT | -----------------------  -----------
2017-06-11 00:55:36.796269 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #732 | Training started
2017-06-11 00:55:55.612609 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #732 | Training finished
2017-06-11 00:55:55.613057 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #732 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 00:55:55.613403 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #732 | Collecting samples for evaluation
2017-06-11 00:56:10.292766 EDT | -----------------------  -----------
2017-06-11 00:56:10.293865 EDT | Epoch                     732
2017-06-11 00:56:10.294179 EDT | Iteration                 732
2017-06-11 00:56:10.294439 EDT | AverageReturn             346.418
2017-06-11 00:56:10.294690 EDT | StdReturn                 259.915
2017-06-11 00:56:10.294937 EDT | MaxReturn                1756.02
2017-06-11 00:56:10.295211 EDT | MinReturn                 238.945
2017-06-11 00:56:10.295472 EDT | AverageEsReturn           581.213
2017-06-11 00:56:10.295726 EDT | StdEsReturn               425.902
2017-06-11 00:56:10.295977 EDT | MaxEsReturn              1152.26
2017-06-11 00:56:10.296228 EDT | MinEsReturn                24.1054
2017-06-11 00:56:10.296498 EDT | AverageDiscountedReturn   155.182
2017-06-11 00:56:10.296751 EDT | AverageQLoss                2.19819
2017-06-11 00:56:10.297346 EDT | AveragePolicySurr         -30.7193
2017-06-11 00:56:10.297632 EDT | AverageQ                   30.3787
2017-06-11 00:56:10.298698 EDT | AverageAbsQ                30.4036
2017-06-11 00:56:10.299041 EDT | AverageY                   30.3808
2017-06-11 00:56:10.300173 EDT | AverageAbsY                30.3931
2017-06-11 00:56:10.300480 EDT | AverageAbsQYDiff            0.562939
2017-06-11 00:56:10.300824 EDT | AverageAction               0.995121
2017-06-11 00:56:10.301161 EDT | PolicyRegParamNorm         86.0479
2017-06-11 00:56:10.301588 EDT | QFunRegParamNorm          110.344
2017-06-11 00:56:10.301951 EDT | -----------------------  -----------
2017-06-11 00:56:10.302460 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #733 | Training started
2017-06-11 00:56:29.256116 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #733 | Training finished
2017-06-11 00:56:29.256922 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #733 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 00:56:29.257131 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #733 | Collecting samples for evaluation
2017-06-11 00:56:42.684182 EDT | -----------------------  -----------
2017-06-11 00:56:42.684905 EDT | Epoch                     733
2017-06-11 00:56:42.685255 EDT | Iteration                 733
2017-06-11 00:56:42.685617 EDT | AverageReturn             717.645
2017-06-11 00:56:42.685992 EDT | StdReturn                 671.905
2017-06-11 00:56:42.686366 EDT | MaxReturn                2495.31
2017-06-11 00:56:42.686695 EDT | MinReturn                  14.8662
2017-06-11 00:56:42.687022 EDT | AverageEsReturn           263.471
2017-06-11 00:56:42.687343 EDT | StdEsReturn               224.253
2017-06-11 00:56:42.687778 EDT | MaxEsReturn               647.709
2017-06-11 00:56:42.688045 EDT | MinEsReturn                24.3097
2017-06-11 00:56:42.688374 EDT | AverageDiscountedReturn   152.241
2017-06-11 00:56:42.688683 EDT | AverageQLoss                2.28937
2017-06-11 00:56:42.688967 EDT | AveragePolicySurr         -30.7065
2017-06-11 00:56:42.689309 EDT | AverageQ                   30.376
2017-06-11 00:56:42.689647 EDT | AverageAbsQ                30.3973
2017-06-11 00:56:42.689977 EDT | AverageY                   30.3771
2017-06-11 00:56:42.690475 EDT | AverageAbsY                30.3897
2017-06-11 00:56:42.690760 EDT | AverageAbsQYDiff            0.563349
2017-06-11 00:56:42.691078 EDT | AverageAction               0.986949
2017-06-11 00:56:42.691443 EDT | PolicyRegParamNorm         86.1466
2017-06-11 00:56:42.691733 EDT | QFunRegParamNorm          110.407
2017-06-11 00:56:42.692052 EDT | -----------------------  -----------
2017-06-11 00:56:42.692537 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #734 | Training started
2017-06-11 00:56:59.405409 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #734 | Training finished
2017-06-11 00:56:59.406428 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #734 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 00:56:59.406835 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #734 | Collecting samples for evaluation
2017-06-11 00:57:14.415096 EDT | -----------------------  -----------
2017-06-11 00:57:14.419027 EDT | Epoch                     734
2017-06-11 00:57:14.419530 EDT | Iteration                 734
2017-06-11 00:57:14.419917 EDT | AverageReturn            1138.52
2017-06-11 00:57:14.420354 EDT | StdReturn                 379.857
2017-06-11 00:57:14.420777 EDT | MaxReturn                2319.46
2017-06-11 00:57:14.421276 EDT | MinReturn                 788.546
2017-06-11 00:57:14.421631 EDT | AverageEsReturn           312.436
2017-06-11 00:57:14.422044 EDT | StdEsReturn               269.553
2017-06-11 00:57:14.422447 EDT | MaxEsReturn               801.454
2017-06-11 00:57:14.422812 EDT | MinEsReturn                30.4643
2017-06-11 00:57:14.423246 EDT | AverageDiscountedReturn   235.646
2017-06-11 00:57:14.423662 EDT | AverageQLoss                2.526
2017-06-11 00:57:14.424072 EDT | AveragePolicySurr         -30.7247
2017-06-11 00:57:14.424575 EDT | AverageQ                   30.3724
2017-06-11 00:57:14.424947 EDT | AverageAbsQ                30.399
2017-06-11 00:57:14.425357 EDT | AverageY                   30.3718
2017-06-11 00:57:14.425713 EDT | AverageAbsY                30.3847
2017-06-11 00:57:14.426123 EDT | AverageAbsQYDiff            0.587122
2017-06-11 00:57:14.426543 EDT | AverageAction               0.988773
2017-06-11 00:57:14.426959 EDT | PolicyRegParamNorm         86.2717
2017-06-11 00:57:14.427340 EDT | QFunRegParamNorm          110.459
2017-06-11 00:57:14.427692 EDT | -----------------------  -----------
2017-06-11 00:57:14.428273 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #735 | Training started
2017-06-11 00:57:33.627660 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #735 | Training finished
2017-06-11 00:57:33.630237 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #735 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 00:57:33.630620 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #735 | Collecting samples for evaluation
2017-06-11 00:57:48.231301 EDT | -----------------------  -----------
2017-06-11 00:57:48.232225 EDT | Epoch                     735
2017-06-11 00:57:48.232612 EDT | Iteration                 735
2017-06-11 00:57:48.232974 EDT | AverageReturn            1116.25
2017-06-11 00:57:48.233332 EDT | StdReturn                 435.561
2017-06-11 00:57:48.233690 EDT | MaxReturn                2447.48
2017-06-11 00:57:48.234056 EDT | MinReturn                 690.743
2017-06-11 00:57:48.234412 EDT | AverageEsReturn           201.834
2017-06-11 00:57:48.234769 EDT | StdEsReturn               161.158
2017-06-11 00:57:48.235127 EDT | MaxEsReturn               657.232
2017-06-11 00:57:48.235485 EDT | MinEsReturn                85.3904
2017-06-11 00:57:48.235838 EDT | AverageDiscountedReturn   228.525
2017-06-11 00:57:48.236196 EDT | AverageQLoss                2.38952
2017-06-11 00:57:48.236554 EDT | AveragePolicySurr         -30.7595
2017-06-11 00:57:48.236909 EDT | AverageQ                   30.4039
2017-06-11 00:57:48.237265 EDT | AverageAbsQ                30.4323
2017-06-11 00:57:48.237618 EDT | AverageY                   30.4064
2017-06-11 00:57:48.237950 EDT | AverageAbsY                30.4243
2017-06-11 00:57:48.238367 EDT | AverageAbsQYDiff            0.572045
2017-06-11 00:57:48.238770 EDT | AverageAction               0.987785
2017-06-11 00:57:48.239146 EDT | PolicyRegParamNorm         86.2821
2017-06-11 00:57:48.241152 EDT | QFunRegParamNorm          110.494
2017-06-11 00:57:48.241887 EDT | -----------------------  -----------
2017-06-11 00:57:48.244265 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #736 | Training started
2017-06-11 00:58:05.679760 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #736 | Training finished
2017-06-11 00:58:05.680563 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #736 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 00:58:05.680775 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #736 | Collecting samples for evaluation
2017-06-11 00:58:20.224301 EDT | -----------------------  -----------
2017-06-11 00:58:20.225205 EDT | Epoch                     736
2017-06-11 00:58:20.225589 EDT | Iteration                 736
2017-06-11 00:58:20.225937 EDT | AverageReturn            1423.37
2017-06-11 00:58:20.226265 EDT | StdReturn                 955.638
2017-06-11 00:58:20.226673 EDT | MaxReturn                3110.35
2017-06-11 00:58:20.226988 EDT | MinReturn                 239.813
2017-06-11 00:58:20.227302 EDT | AverageEsReturn           409.605
2017-06-11 00:58:20.227602 EDT | StdEsReturn               323.566
2017-06-11 00:58:20.228261 EDT | MaxEsReturn               936.906
2017-06-11 00:58:20.228592 EDT | MinEsReturn                31.2771
2017-06-11 00:58:20.228908 EDT | AverageDiscountedReturn   232.463
2017-06-11 00:58:20.229209 EDT | AverageQLoss                2.5011
2017-06-11 00:58:20.229538 EDT | AveragePolicySurr         -30.7938
2017-06-11 00:58:20.230191 EDT | AverageQ                   30.4411
2017-06-11 00:58:20.230512 EDT | AverageAbsQ                30.4707
2017-06-11 00:58:20.230833 EDT | AverageY                   30.4431
2017-06-11 00:58:20.230998 EDT | AverageAbsY                30.4586
2017-06-11 00:58:20.231991 EDT | AverageAbsQYDiff            0.572415
2017-06-11 00:58:20.232317 EDT | AverageAction               0.991229
2017-06-11 00:58:20.232747 EDT | PolicyRegParamNorm         86.2867
2017-06-11 00:58:20.232999 EDT | QFunRegParamNorm          110.566
2017-06-11 00:58:20.233398 EDT | -----------------------  -----------
2017-06-11 00:58:20.233888 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #737 | Training started
2017-06-11 00:58:37.243884 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #737 | Training finished
2017-06-11 00:58:37.244923 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #737 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 00:58:37.245312 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #737 | Collecting samples for evaluation
2017-06-11 00:58:52.229023 EDT | -----------------------  -----------
2017-06-11 00:58:52.229908 EDT | Epoch                     737
2017-06-11 00:58:52.230197 EDT | Iteration                 737
2017-06-11 00:58:52.230458 EDT | AverageReturn            1131.31
2017-06-11 00:58:52.230778 EDT | StdReturn                 676.478
2017-06-11 00:58:52.231093 EDT | MaxReturn                3058.17
2017-06-11 00:58:52.231355 EDT | MinReturn                 295.926
2017-06-11 00:58:52.231672 EDT | AverageEsReturn           276.947
2017-06-11 00:58:52.232002 EDT | StdEsReturn               203.828
2017-06-11 00:58:52.232324 EDT | MaxEsReturn               700.994
2017-06-11 00:58:52.232642 EDT | MinEsReturn                14.4658
2017-06-11 00:58:52.232954 EDT | AverageDiscountedReturn   223.74
2017-06-11 00:58:52.233226 EDT | AverageQLoss                2.12701
2017-06-11 00:58:52.233481 EDT | AveragePolicySurr         -30.8669
2017-06-11 00:58:52.233740 EDT | AverageQ                   30.5057
2017-06-11 00:58:52.234022 EDT | AverageAbsQ                30.5321
2017-06-11 00:58:52.234348 EDT | AverageY                   30.5062
2017-06-11 00:58:52.234628 EDT | AverageAbsY                30.5203
2017-06-11 00:58:52.234889 EDT | AverageAbsQYDiff            0.549364
2017-06-11 00:58:52.235206 EDT | AverageAction               0.9908
2017-06-11 00:58:52.235529 EDT | PolicyRegParamNorm         86.3887
2017-06-11 00:58:52.235850 EDT | QFunRegParamNorm          110.581
2017-06-11 00:58:52.236152 EDT | -----------------------  -----------
2017-06-11 00:58:52.236636 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #738 | Training started
2017-06-11 00:59:08.737211 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #738 | Training finished
2017-06-11 00:59:08.738331 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #738 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 00:59:08.738745 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #738 | Collecting samples for evaluation
2017-06-11 00:59:23.193606 EDT | -----------------------  -----------
2017-06-11 00:59:23.194549 EDT | Epoch                     738
2017-06-11 00:59:23.194831 EDT | Iteration                 738
2017-06-11 00:59:23.195004 EDT | AverageReturn            1094.56
2017-06-11 00:59:23.195185 EDT | StdReturn                 602.764
2017-06-11 00:59:23.195449 EDT | MaxReturn                2988.97
2017-06-11 00:59:23.195742 EDT | MinReturn                 252.269
2017-06-11 00:59:23.196272 EDT | AverageEsReturn           311.153
2017-06-11 00:59:23.196567 EDT | StdEsReturn               292.453
2017-06-11 00:59:23.197265 EDT | MaxEsReturn               842.365
2017-06-11 00:59:23.197466 EDT | MinEsReturn                14.7217
2017-06-11 00:59:23.197649 EDT | AverageDiscountedReturn   221.503
2017-06-11 00:59:23.197883 EDT | AverageQLoss                2.15441
2017-06-11 00:59:23.198154 EDT | AveragePolicySurr         -30.8604
2017-06-11 00:59:23.201761 EDT | AverageQ                   30.4691
2017-06-11 00:59:23.202076 EDT | AverageAbsQ                30.495
2017-06-11 00:59:23.202265 EDT | AverageY                   30.4713
2017-06-11 00:59:23.202449 EDT | AverageAbsY                30.4863
2017-06-11 00:59:23.202635 EDT | AverageAbsQYDiff            0.570519
2017-06-11 00:59:23.202827 EDT | AverageAction               0.991644
2017-06-11 00:59:23.203043 EDT | PolicyRegParamNorm         86.4164
2017-06-11 00:59:23.203343 EDT | QFunRegParamNorm          110.632
2017-06-11 00:59:23.203528 EDT | -----------------------  -----------
2017-06-11 00:59:23.203832 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #739 | Training started
2017-06-11 00:59:40.139537 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #739 | Training finished
2017-06-11 00:59:40.140004 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #739 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 00:59:40.140375 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #739 | Collecting samples for evaluation
2017-06-11 00:59:53.397858 EDT | -----------------------  -----------
2017-06-11 00:59:53.399003 EDT | Epoch                     739
2017-06-11 00:59:53.399371 EDT | Iteration                 739
2017-06-11 00:59:53.399708 EDT | AverageReturn            1774.32
2017-06-11 00:59:53.400051 EDT | StdReturn                 868.947
2017-06-11 00:59:53.404638 EDT | MaxReturn                3071.59
2017-06-11 00:59:53.405020 EDT | MinReturn                 286.406
2017-06-11 00:59:53.405367 EDT | AverageEsReturn           411.103
2017-06-11 00:59:53.405706 EDT | StdEsReturn               176.406
2017-06-11 00:59:53.406038 EDT | MaxEsReturn               727.244
2017-06-11 00:59:53.406367 EDT | MinEsReturn               235.708
2017-06-11 00:59:53.406692 EDT | AverageDiscountedReturn   233.065
2017-06-11 00:59:53.407017 EDT | AverageQLoss                2.33625
2017-06-11 00:59:53.407340 EDT | AveragePolicySurr         -30.9208
2017-06-11 00:59:53.407665 EDT | AverageQ                   30.5598
2017-06-11 00:59:53.407987 EDT | AverageAbsQ                30.5832
2017-06-11 00:59:53.408311 EDT | AverageY                   30.56
2017-06-11 00:59:53.408633 EDT | AverageAbsY                30.5713
2017-06-11 00:59:53.408957 EDT | AverageAbsQYDiff            0.556735
2017-06-11 00:59:53.409279 EDT | AverageAction               0.989974
2017-06-11 00:59:53.421901 EDT | PolicyRegParamNorm         86.4697
2017-06-11 00:59:53.422328 EDT | QFunRegParamNorm          110.678
2017-06-11 00:59:53.422666 EDT | -----------------------  -----------
2017-06-11 00:59:53.423171 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #740 | Training started
2017-06-11 01:00:12.181849 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #740 | Training finished
2017-06-11 01:00:12.182343 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #740 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 01:00:12.182738 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #740 | Collecting samples for evaluation
2017-06-11 01:00:25.722999 EDT | -----------------------  -----------
2017-06-11 01:00:25.724065 EDT | Epoch                     740
2017-06-11 01:00:25.724417 EDT | Iteration                 740
2017-06-11 01:00:25.724754 EDT | AverageReturn            1762.89
2017-06-11 01:00:25.725088 EDT | StdReturn                1034.62
2017-06-11 01:00:25.725420 EDT | MaxReturn                2986.57
2017-06-11 01:00:25.725776 EDT | MinReturn                 262.633
2017-06-11 01:00:25.726111 EDT | AverageEsReturn           362.447
2017-06-11 01:00:25.726441 EDT | StdEsReturn               229.029
2017-06-11 01:00:25.726773 EDT | MaxEsReturn               791.444
2017-06-11 01:00:25.727110 EDT | MinEsReturn                46.4856
2017-06-11 01:00:25.727443 EDT | AverageDiscountedReturn   230.632
2017-06-11 01:00:25.727771 EDT | AverageQLoss                2.43613
2017-06-11 01:00:25.728098 EDT | AveragePolicySurr         -30.7757
2017-06-11 01:00:25.728423 EDT | AverageQ                   30.428
2017-06-11 01:00:25.728748 EDT | AverageAbsQ                30.4483
2017-06-11 01:00:25.729073 EDT | AverageY                   30.4302
2017-06-11 01:00:25.729398 EDT | AverageAbsY                30.4383
2017-06-11 01:00:25.729728 EDT | AverageAbsQYDiff            0.574
2017-06-11 01:00:25.730055 EDT | AverageAction               0.991766
2017-06-11 01:00:25.730382 EDT | PolicyRegParamNorm         86.4983
2017-06-11 01:00:25.730705 EDT | QFunRegParamNorm          110.721
2017-06-11 01:00:25.731029 EDT | -----------------------  -----------
2017-06-11 01:00:25.731494 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #741 | Training started
2017-06-11 01:00:43.198265 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #741 | Training finished
2017-06-11 01:00:43.198938 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #741 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 01:00:43.199464 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #741 | Collecting samples for evaluation
2017-06-11 01:00:57.932192 EDT | -----------------------  -----------
2017-06-11 01:00:57.933159 EDT | Epoch                     741
2017-06-11 01:00:57.933530 EDT | Iteration                 741
2017-06-11 01:00:57.933900 EDT | AverageReturn             917.231
2017-06-11 01:00:57.934247 EDT | StdReturn                 345.006
2017-06-11 01:00:57.934595 EDT | MaxReturn                1673.26
2017-06-11 01:00:57.934941 EDT | MinReturn                 143.388
2017-06-11 01:00:57.935286 EDT | AverageEsReturn           255.47
2017-06-11 01:00:57.935629 EDT | StdEsReturn               194.19
2017-06-11 01:00:57.935968 EDT | MaxEsReturn               686.074
2017-06-11 01:00:57.936314 EDT | MinEsReturn                15.3895
2017-06-11 01:00:57.936658 EDT | AverageDiscountedReturn   211.402
2017-06-11 01:00:57.936998 EDT | AverageQLoss                1.86084
2017-06-11 01:00:57.938633 EDT | AveragePolicySurr         -30.9251
2017-06-11 01:00:57.939165 EDT | AverageQ                   30.5665
2017-06-11 01:00:57.939621 EDT | AverageAbsQ                30.5897
2017-06-11 01:00:57.939974 EDT | AverageY                   30.5654
2017-06-11 01:00:57.940316 EDT | AverageAbsY                30.5762
2017-06-11 01:00:57.940663 EDT | AverageAbsQYDiff            0.539273
2017-06-11 01:00:57.941618 EDT | AverageAction               0.991175
2017-06-11 01:00:57.941990 EDT | PolicyRegParamNorm         86.5892
2017-06-11 01:00:57.942337 EDT | QFunRegParamNorm          110.715
2017-06-11 01:00:57.942680 EDT | -----------------------  -----------
2017-06-11 01:00:57.943196 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #742 | Training started
2017-06-11 01:01:14.103209 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #742 | Training finished
2017-06-11 01:01:14.104436 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #742 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 01:01:14.104897 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #742 | Collecting samples for evaluation
2017-06-11 01:01:29.205019 EDT | -----------------------  -----------
2017-06-11 01:01:29.206767 EDT | Epoch                     742
2017-06-11 01:01:29.207468 EDT | Iteration                 742
2017-06-11 01:01:29.207908 EDT | AverageReturn            1129.51
2017-06-11 01:01:29.208353 EDT | StdReturn                 799.089
2017-06-11 01:01:29.208801 EDT | MaxReturn                2558.98
2017-06-11 01:01:29.209247 EDT | MinReturn                 281.668
2017-06-11 01:01:29.209707 EDT | AverageEsReturn           547.935
2017-06-11 01:01:29.210156 EDT | StdEsReturn               612.088
2017-06-11 01:01:29.210604 EDT | MaxEsReturn              1593.21
2017-06-11 01:01:29.211049 EDT | MinEsReturn                48.2105
2017-06-11 01:01:29.211484 EDT | AverageDiscountedReturn   204.297
2017-06-11 01:01:29.211840 EDT | AverageQLoss                2.50082
2017-06-11 01:01:29.212219 EDT | AveragePolicySurr         -30.9025
2017-06-11 01:01:29.212565 EDT | AverageQ                   30.5682
2017-06-11 01:01:29.212899 EDT | AverageAbsQ                30.59
2017-06-11 01:01:29.213228 EDT | AverageY                   30.5701
2017-06-11 01:01:29.213556 EDT | AverageAbsY                30.5775
2017-06-11 01:01:29.213894 EDT | AverageAbsQYDiff            0.572906
2017-06-11 01:01:29.214225 EDT | AverageAction               0.989449
2017-06-11 01:01:29.214710 EDT | PolicyRegParamNorm         86.6132
2017-06-11 01:01:29.215255 EDT | QFunRegParamNorm          110.777
2017-06-11 01:01:29.215700 EDT | -----------------------  -----------
2017-06-11 01:01:29.216433 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #743 | Training started
2017-06-11 01:01:45.435902 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #743 | Training finished
2017-06-11 01:01:45.436645 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #743 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 01:01:45.437038 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #743 | Collecting samples for evaluation
2017-06-11 01:01:59.174606 EDT | -----------------------  -----------
2017-06-11 01:01:59.175469 EDT | Epoch                     743
2017-06-11 01:01:59.175834 EDT | Iteration                 743
2017-06-11 01:01:59.176022 EDT | AverageReturn            2338.95
2017-06-11 01:01:59.176208 EDT | StdReturn                 717.008
2017-06-11 01:01:59.176413 EDT | MaxReturn                3072.31
2017-06-11 01:01:59.176675 EDT | MinReturn                 887.192
2017-06-11 01:01:59.176857 EDT | AverageEsReturn           567.669
2017-06-11 01:01:59.177154 EDT | StdEsReturn               483.423
2017-06-11 01:01:59.177395 EDT | MaxEsReturn              1474.81
2017-06-11 01:01:59.177581 EDT | MinEsReturn               112.373
2017-06-11 01:01:59.177905 EDT | AverageDiscountedReturn   249.818
2017-06-11 01:01:59.178087 EDT | AverageQLoss                2.36099
2017-06-11 01:01:59.178267 EDT | AveragePolicySurr         -30.7646
2017-06-11 01:01:59.178447 EDT | AverageQ                   30.4289
2017-06-11 01:01:59.178626 EDT | AverageAbsQ                30.4478
2017-06-11 01:01:59.178811 EDT | AverageY                   30.429
2017-06-11 01:01:59.178988 EDT | AverageAbsY                30.4368
2017-06-11 01:01:59.179166 EDT | AverageAbsQYDiff            0.563884
2017-06-11 01:01:59.179939 EDT | AverageAction               0.991664
2017-06-11 01:01:59.180147 EDT | PolicyRegParamNorm         86.6411
2017-06-11 01:01:59.180408 EDT | QFunRegParamNorm          110.814
2017-06-11 01:01:59.180771 EDT | -----------------------  -----------
2017-06-11 01:01:59.181140 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #744 | Training started
2017-06-11 01:02:17.134280 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #744 | Training finished
2017-06-11 01:02:17.135027 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #744 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 01:02:17.135215 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #744 | Collecting samples for evaluation
2017-06-11 01:02:29.820906 EDT | -----------------------  -----------
2017-06-11 01:02:29.822149 EDT | Epoch                     744
2017-06-11 01:02:29.822535 EDT | Iteration                 744
2017-06-11 01:02:29.822898 EDT | AverageReturn             204.478
2017-06-11 01:02:29.823254 EDT | StdReturn                 176.577
2017-06-11 01:02:29.823612 EDT | MaxReturn                1794.82
2017-06-11 01:02:29.823969 EDT | MinReturn                 153.224
2017-06-11 01:02:29.824328 EDT | AverageEsReturn           250.966
2017-06-11 01:02:29.824687 EDT | StdEsReturn               184.589
2017-06-11 01:02:29.825137 EDT | MaxEsReturn               570.222
2017-06-11 01:02:29.825721 EDT | MinEsReturn                28.9986
2017-06-11 01:02:29.826179 EDT | AverageDiscountedReturn   116.383
2017-06-11 01:02:29.826626 EDT | AverageQLoss                2.37333
2017-06-11 01:02:29.827072 EDT | AveragePolicySurr         -30.859
2017-06-11 01:02:29.827517 EDT | AverageQ                   30.5277
2017-06-11 01:02:29.827961 EDT | AverageAbsQ                30.552
2017-06-11 01:02:29.828404 EDT | AverageY                   30.5296
2017-06-11 01:02:29.828846 EDT | AverageAbsY                30.5392
2017-06-11 01:02:29.829288 EDT | AverageAbsQYDiff            0.565695
2017-06-11 01:02:29.830518 EDT | AverageAction               0.994116
2017-06-11 01:02:29.830982 EDT | PolicyRegParamNorm         86.662
2017-06-11 01:02:29.832796 EDT | QFunRegParamNorm          110.86
2017-06-11 01:02:29.833254 EDT | -----------------------  -----------
2017-06-11 01:02:29.833862 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #745 | Training started
2017-06-11 01:02:48.545937 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #745 | Training finished
2017-06-11 01:02:48.546689 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #745 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 01:02:48.546886 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #745 | Collecting samples for evaluation
2017-06-11 01:03:04.006183 EDT | -----------------------  -----------
2017-06-11 01:03:04.007336 EDT | Epoch                     745
2017-06-11 01:03:04.007828 EDT | Iteration                 745
2017-06-11 01:03:04.009053 EDT | AverageReturn            1449.55
2017-06-11 01:03:04.009435 EDT | StdReturn                 653.086
2017-06-11 01:03:04.009883 EDT | MaxReturn                2550.32
2017-06-11 01:03:04.010264 EDT | MinReturn                 495.496
2017-06-11 01:03:04.010697 EDT | AverageEsReturn           286.197
2017-06-11 01:03:04.011077 EDT | StdEsReturn               139.281
2017-06-11 01:03:04.011513 EDT | MaxEsReturn               533.364
2017-06-11 01:03:04.011932 EDT | MinEsReturn               114.093
2017-06-11 01:03:04.012421 EDT | AverageDiscountedReturn   207.448
2017-06-11 01:03:04.012778 EDT | AverageQLoss                2.1261
2017-06-11 01:03:04.013195 EDT | AveragePolicySurr         -30.799
2017-06-11 01:03:04.014749 EDT | AverageQ                   30.4755
2017-06-11 01:03:04.015100 EDT | AverageAbsQ                30.4948
2017-06-11 01:03:04.015445 EDT | AverageY                   30.4757
2017-06-11 01:03:04.015790 EDT | AverageAbsY                30.4848
2017-06-11 01:03:04.016131 EDT | AverageAbsQYDiff            0.534092
2017-06-11 01:03:04.016470 EDT | AverageAction               0.992744
2017-06-11 01:03:04.016812 EDT | PolicyRegParamNorm         86.7908
2017-06-11 01:03:04.017153 EDT | QFunRegParamNorm          110.907
2017-06-11 01:03:04.017495 EDT | -----------------------  -----------
2017-06-11 01:03:04.018028 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #746 | Training started
2017-06-11 01:03:20.098095 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #746 | Training finished
2017-06-11 01:03:20.100106 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #746 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 01:03:20.100500 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #746 | Collecting samples for evaluation
2017-06-11 01:03:35.438432 EDT | -----------------------  -----------
2017-06-11 01:03:35.439107 EDT | Epoch                     746
2017-06-11 01:03:35.439354 EDT | Iteration                 746
2017-06-11 01:03:35.439550 EDT | AverageReturn            1550.88
2017-06-11 01:03:35.439773 EDT | StdReturn                 522.143
2017-06-11 01:03:35.439960 EDT | MaxReturn                2420.22
2017-06-11 01:03:35.440142 EDT | MinReturn                 817.513
2017-06-11 01:03:35.440469 EDT | AverageEsReturn           563.223
2017-06-11 01:03:35.440659 EDT | StdEsReturn               137.993
2017-06-11 01:03:35.440849 EDT | MaxEsReturn               729.917
2017-06-11 01:03:35.441204 EDT | MinEsReturn               351.334
2017-06-11 01:03:35.441389 EDT | AverageDiscountedReturn   213.543
2017-06-11 01:03:35.441719 EDT | AverageQLoss                2.56228
2017-06-11 01:03:35.442143 EDT | AveragePolicySurr         -30.7557
2017-06-11 01:03:35.442613 EDT | AverageQ                   30.4343
2017-06-11 01:03:35.442808 EDT | AverageAbsQ                30.4626
2017-06-11 01:03:35.443365 EDT | AverageY                   30.4352
2017-06-11 01:03:35.443550 EDT | AverageAbsY                30.4438
2017-06-11 01:03:35.443732 EDT | AverageAbsQYDiff            0.571392
2017-06-11 01:03:35.444829 EDT | AverageAction               0.991645
2017-06-11 01:03:35.445156 EDT | PolicyRegParamNorm         86.8386
2017-06-11 01:03:35.445400 EDT | QFunRegParamNorm          110.939
2017-06-11 01:03:35.445591 EDT | -----------------------  -----------
2017-06-11 01:03:35.446027 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #747 | Training started
2017-06-11 01:03:51.596826 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #747 | Training finished
2017-06-11 01:03:51.597748 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #747 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 01:03:51.598168 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #747 | Collecting samples for evaluation
2017-06-11 01:04:05.678128 EDT | -----------------------  ----------
2017-06-11 01:04:05.679243 EDT | Epoch                    747
2017-06-11 01:04:05.679532 EDT | Iteration                747
2017-06-11 01:04:05.679792 EDT | AverageReturn            600.764
2017-06-11 01:04:05.680039 EDT | StdReturn                159.225
2017-06-11 01:04:05.680283 EDT | MaxReturn                878.268
2017-06-11 01:04:05.680525 EDT | MinReturn                336.264
2017-06-11 01:04:05.680773 EDT | AverageEsReturn          558.274
2017-06-11 01:04:05.681014 EDT | StdEsReturn              223.385
2017-06-11 01:04:05.681254 EDT | MaxEsReturn              855.685
2017-06-11 01:04:05.681494 EDT | MinEsReturn              200.752
2017-06-11 01:04:05.681744 EDT | AverageDiscountedReturn  205.772
2017-06-11 01:04:05.681990 EDT | AverageQLoss               2.27493
2017-06-11 01:04:05.682234 EDT | AveragePolicySurr        -30.7623
2017-06-11 01:04:05.682473 EDT | AverageQ                  30.4251
2017-06-11 01:04:05.682712 EDT | AverageAbsQ               30.4506
2017-06-11 01:04:05.682960 EDT | AverageY                  30.426
2017-06-11 01:04:05.683199 EDT | AverageAbsY               30.4374
2017-06-11 01:04:05.683438 EDT | AverageAbsQYDiff           0.550991
2017-06-11 01:04:05.683677 EDT | AverageAction              0.993705
2017-06-11 01:04:05.683921 EDT | PolicyRegParamNorm        86.8687
2017-06-11 01:04:05.684160 EDT | QFunRegParamNorm         111.012
2017-06-11 01:04:05.684399 EDT | -----------------------  ----------
2017-06-11 01:04:05.684783 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #748 | Training started
2017-06-11 01:04:23.384553 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #748 | Training finished
2017-06-11 01:04:23.385357 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #748 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 01:04:23.385544 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #748 | Collecting samples for evaluation
2017-06-11 01:04:36.355607 EDT | -----------------------  -----------
2017-06-11 01:04:36.356890 EDT | Epoch                     748
2017-06-11 01:04:36.357233 EDT | Iteration                 748
2017-06-11 01:04:36.357790 EDT | AverageReturn            1132.08
2017-06-11 01:04:36.358102 EDT | StdReturn                 281.698
2017-06-11 01:04:36.358681 EDT | MaxReturn                2006.53
2017-06-11 01:04:36.359020 EDT | MinReturn                 693.395
2017-06-11 01:04:36.359765 EDT | AverageEsReturn           233.59
2017-06-11 01:04:36.359928 EDT | StdEsReturn               226.321
2017-06-11 01:04:36.360096 EDT | MaxEsReturn               757.96
2017-06-11 01:04:36.360855 EDT | MinEsReturn                26.9383
2017-06-11 01:04:36.361464 EDT | AverageDiscountedReturn   219.971
2017-06-11 01:04:36.362063 EDT | AverageQLoss                2.43224
2017-06-11 01:04:36.362395 EDT | AveragePolicySurr         -30.8346
2017-06-11 01:04:36.362724 EDT | AverageQ                   30.5064
2017-06-11 01:04:36.363161 EDT | AverageAbsQ                30.5307
2017-06-11 01:04:36.363501 EDT | AverageY                   30.507
2017-06-11 01:04:36.364912 EDT | AverageAbsY                30.5195
2017-06-11 01:04:36.365268 EDT | AverageAbsQYDiff            0.567472
2017-06-11 01:04:36.365615 EDT | AverageAction               0.99171
2017-06-11 01:04:36.365990 EDT | PolicyRegParamNorm         86.9424
2017-06-11 01:04:36.366348 EDT | QFunRegParamNorm          111.038
2017-06-11 01:04:36.366702 EDT | -----------------------  -----------
2017-06-11 01:04:36.367239 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #749 | Training started
2017-06-11 01:04:53.545891 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #749 | Training finished
2017-06-11 01:04:53.546946 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #749 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 01:04:53.547401 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #749 | Collecting samples for evaluation
2017-06-11 01:05:07.922749 EDT | -----------------------  -----------
2017-06-11 01:05:07.923644 EDT | Epoch                     749
2017-06-11 01:05:07.924001 EDT | Iteration                 749
2017-06-11 01:05:07.924342 EDT | AverageReturn            1355.99
2017-06-11 01:05:07.924686 EDT | StdReturn                 825.07
2017-06-11 01:05:07.924961 EDT | MaxReturn                2741.31
2017-06-11 01:05:07.925263 EDT | MinReturn                 112.657
2017-06-11 01:05:07.925594 EDT | AverageEsReturn           203.939
2017-06-11 01:05:07.925942 EDT | StdEsReturn               142.977
2017-06-11 01:05:07.926255 EDT | MaxEsReturn               433.633
2017-06-11 01:05:07.926514 EDT | MinEsReturn                43.71
2017-06-11 01:05:07.926848 EDT | AverageDiscountedReturn   216.242
2017-06-11 01:05:07.927183 EDT | AverageQLoss                2.15468
2017-06-11 01:05:07.927519 EDT | AveragePolicySurr         -30.692
2017-06-11 01:05:07.927793 EDT | AverageQ                   30.3517
2017-06-11 01:05:07.928092 EDT | AverageAbsQ                30.3758
2017-06-11 01:05:07.928418 EDT | AverageY                   30.3522
2017-06-11 01:05:07.928751 EDT | AverageAbsY                30.365
2017-06-11 01:05:07.929066 EDT | AverageAbsQYDiff            0.557499
2017-06-11 01:05:07.929325 EDT | AverageAction               0.992492
2017-06-11 01:05:07.929655 EDT | PolicyRegParamNorm         86.9856
2017-06-11 01:05:07.929998 EDT | QFunRegParamNorm          111.095
2017-06-11 01:05:07.930333 EDT | -----------------------  -----------
2017-06-11 01:05:07.930774 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #750 | Training started
2017-06-11 01:05:24.242903 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #750 | Training finished
2017-06-11 01:05:24.243671 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #750 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 01:05:24.243857 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #750 | Collecting samples for evaluation
2017-06-11 01:05:39.831730 EDT | -----------------------  -----------
2017-06-11 01:05:39.835383 EDT | Epoch                     750
2017-06-11 01:05:39.835787 EDT | Iteration                 750
2017-06-11 01:05:39.836171 EDT | AverageReturn            1096.57
2017-06-11 01:05:39.836516 EDT | StdReturn                 996.739
2017-06-11 01:05:39.836859 EDT | MaxReturn                2831.3
2017-06-11 01:05:39.837275 EDT | MinReturn                 204.459
2017-06-11 01:05:39.837647 EDT | AverageEsReturn           340.744
2017-06-11 01:05:39.838054 EDT | StdEsReturn               227.187
2017-06-11 01:05:39.838459 EDT | MaxEsReturn               823.351
2017-06-11 01:05:39.838818 EDT | MinEsReturn                98.3043
2017-06-11 01:05:39.839252 EDT | AverageDiscountedReturn   196.859
2017-06-11 01:05:39.839667 EDT | AverageQLoss                2.44092
2017-06-11 01:05:39.840078 EDT | AveragePolicySurr         -30.7201
2017-06-11 01:05:39.840471 EDT | AverageQ                   30.3725
2017-06-11 01:05:39.840813 EDT | AverageAbsQ                30.4006
2017-06-11 01:05:39.841151 EDT | AverageY                   30.3746
2017-06-11 01:05:39.841561 EDT | AverageAbsY                30.3888
2017-06-11 01:05:39.841953 EDT | AverageAbsQYDiff            0.580156
2017-06-11 01:05:39.842343 EDT | AverageAction               0.992401
2017-06-11 01:05:39.842767 EDT | PolicyRegParamNorm         86.983
2017-06-11 01:05:39.843181 EDT | QFunRegParamNorm          111.189
2017-06-11 01:05:39.843582 EDT | -----------------------  -----------
2017-06-11 01:05:39.844070 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #751 | Training started
2017-06-11 01:05:55.888775 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #751 | Training finished
2017-06-11 01:05:55.889055 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #751 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 01:05:55.889229 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #751 | Collecting samples for evaluation
2017-06-11 01:06:10.676530 EDT | -----------------------  -----------
2017-06-11 01:06:10.679849 EDT | Epoch                     751
2017-06-11 01:06:10.680194 EDT | Iteration                 751
2017-06-11 01:06:10.680515 EDT | AverageReturn            1814.14
2017-06-11 01:06:10.681101 EDT | StdReturn                 698.228
2017-06-11 01:06:10.681438 EDT | MaxReturn                2768.89
2017-06-11 01:06:10.681789 EDT | MinReturn                 782.156
2017-06-11 01:06:10.682216 EDT | AverageEsReturn           522.644
2017-06-11 01:06:10.682675 EDT | StdEsReturn               286.15
2017-06-11 01:06:10.683159 EDT | MaxEsReturn               935.274
2017-06-11 01:06:10.683485 EDT | MinEsReturn                82.4418
2017-06-11 01:06:10.683804 EDT | AverageDiscountedReturn   231.212
2017-06-11 01:06:10.684140 EDT | AverageQLoss                2.35073
2017-06-11 01:06:10.685089 EDT | AveragePolicySurr         -30.6803
2017-06-11 01:06:10.685441 EDT | AverageQ                   30.3362
2017-06-11 01:06:10.685664 EDT | AverageAbsQ                30.3615
2017-06-11 01:06:10.685826 EDT | AverageY                   30.3354
2017-06-11 01:06:10.685976 EDT | AverageAbsY                30.3484
2017-06-11 01:06:10.686125 EDT | AverageAbsQYDiff            0.573071
2017-06-11 01:06:10.686272 EDT | AverageAction               0.99119
2017-06-11 01:06:10.686419 EDT | PolicyRegParamNorm         87.0673
2017-06-11 01:06:10.686579 EDT | QFunRegParamNorm          111.291
2017-06-11 01:06:10.688231 EDT | -----------------------  -----------
2017-06-11 01:06:10.688653 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #752 | Training started
2017-06-11 01:06:28.424867 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #752 | Training finished
2017-06-11 01:06:28.427262 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #752 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 01:06:28.428062 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #752 | Collecting samples for evaluation
2017-06-11 01:06:42.431622 EDT | -----------------------  -----------
2017-06-11 01:06:42.434867 EDT | Epoch                     752
2017-06-11 01:06:42.435365 EDT | Iteration                 752
2017-06-11 01:06:42.435806 EDT | AverageReturn            1963.32
2017-06-11 01:06:42.436140 EDT | StdReturn                 848.284
2017-06-11 01:06:42.436465 EDT | MaxReturn                2890.39
2017-06-11 01:06:42.436852 EDT | MinReturn                 597.066
2017-06-11 01:06:42.437164 EDT | AverageEsReturn           546.226
2017-06-11 01:06:42.437486 EDT | StdEsReturn               242.673
2017-06-11 01:06:42.437859 EDT | MaxEsReturn               914.298
2017-06-11 01:06:42.438188 EDT | MinEsReturn               259.618
2017-06-11 01:06:42.438584 EDT | AverageDiscountedReturn   235.886
2017-06-11 01:06:42.438915 EDT | AverageQLoss                2.51142
2017-06-11 01:06:42.439318 EDT | AveragePolicySurr         -30.6962
2017-06-11 01:06:42.439597 EDT | AverageQ                   30.3577
2017-06-11 01:06:42.439851 EDT | AverageAbsQ                30.3838
2017-06-11 01:06:42.440156 EDT | AverageY                   30.3608
2017-06-11 01:06:42.440473 EDT | AverageAbsY                30.3749
2017-06-11 01:06:42.440735 EDT | AverageAbsQYDiff            0.582975
2017-06-11 01:06:42.441035 EDT | AverageAction               0.992623
2017-06-11 01:06:42.441349 EDT | PolicyRegParamNorm         87.1052
2017-06-11 01:06:42.441662 EDT | QFunRegParamNorm          111.4
2017-06-11 01:06:42.442093 EDT | -----------------------  -----------
2017-06-11 01:06:42.442631 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #753 | Training started
2017-06-11 01:06:59.748818 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #753 | Training finished
2017-06-11 01:06:59.749798 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #753 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 01:06:59.750159 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #753 | Collecting samples for evaluation
2017-06-11 01:07:14.874356 EDT | -----------------------  -----------
2017-06-11 01:07:14.877117 EDT | Epoch                     753
2017-06-11 01:07:14.877460 EDT | Iteration                 753
2017-06-11 01:07:14.877657 EDT | AverageReturn            1910.02
2017-06-11 01:07:14.877942 EDT | StdReturn                 723.573
2017-06-11 01:07:14.878204 EDT | MaxReturn                2846.83
2017-06-11 01:07:14.878486 EDT | MinReturn                 907.822
2017-06-11 01:07:14.878747 EDT | AverageEsReturn           383.638
2017-06-11 01:07:14.879005 EDT | StdEsReturn               478.483
2017-06-11 01:07:14.879261 EDT | MaxEsReturn              1414.56
2017-06-11 01:07:14.879535 EDT | MinEsReturn                24.5858
2017-06-11 01:07:14.879792 EDT | AverageDiscountedReturn   240.676
2017-06-11 01:07:14.880047 EDT | AverageQLoss                2.4302
2017-06-11 01:07:14.880303 EDT | AveragePolicySurr         -30.7623
2017-06-11 01:07:14.880574 EDT | AverageQ                   30.3851
2017-06-11 01:07:14.880832 EDT | AverageAbsQ                30.4111
2017-06-11 01:07:14.881088 EDT | AverageY                   30.3855
2017-06-11 01:07:14.881343 EDT | AverageAbsY                30.3962
2017-06-11 01:07:14.881612 EDT | AverageAbsQYDiff            0.576779
2017-06-11 01:07:14.881877 EDT | AverageAction               0.992992
2017-06-11 01:07:14.882133 EDT | PolicyRegParamNorm         87.0883
2017-06-11 01:07:14.882388 EDT | QFunRegParamNorm          111.439
2017-06-11 01:07:14.882656 EDT | -----------------------  -----------
2017-06-11 01:07:14.883068 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #754 | Training started
2017-06-11 01:07:31.765905 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #754 | Training finished
2017-06-11 01:07:31.766925 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #754 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 01:07:31.767156 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #754 | Collecting samples for evaluation
2017-06-11 01:07:47.235007 EDT | -----------------------  -----------
2017-06-11 01:07:47.235929 EDT | Epoch                     754
2017-06-11 01:07:47.236330 EDT | Iteration                 754
2017-06-11 01:07:47.237000 EDT | AverageReturn            1337.16
2017-06-11 01:07:47.237829 EDT | StdReturn                 604.217
2017-06-11 01:07:47.238265 EDT | MaxReturn                2872.04
2017-06-11 01:07:47.238652 EDT | MinReturn                 823.341
2017-06-11 01:07:47.239133 EDT | AverageEsReturn           388.394
2017-06-11 01:07:47.239436 EDT | StdEsReturn               288.973
2017-06-11 01:07:47.239770 EDT | MaxEsReturn               880.481
2017-06-11 01:07:47.240545 EDT | MinEsReturn                42.1082
2017-06-11 01:07:47.240873 EDT | AverageDiscountedReturn   236.739
2017-06-11 01:07:47.241249 EDT | AverageQLoss                2.11793
2017-06-11 01:07:47.241547 EDT | AveragePolicySurr         -30.815
2017-06-11 01:07:47.241878 EDT | AverageQ                   30.4782
2017-06-11 01:07:47.242198 EDT | AverageAbsQ                30.5005
2017-06-11 01:07:47.242517 EDT | AverageY                   30.48
2017-06-11 01:07:47.242844 EDT | AverageAbsY                30.4909
2017-06-11 01:07:47.243187 EDT | AverageAbsQYDiff            0.539394
2017-06-11 01:07:47.243933 EDT | AverageAction               0.993353
2017-06-11 01:07:47.244263 EDT | PolicyRegParamNorm         87.168
2017-06-11 01:07:47.244580 EDT | QFunRegParamNorm          111.444
2017-06-11 01:07:47.244954 EDT | -----------------------  -----------
2017-06-11 01:07:47.245477 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #755 | Training started
2017-06-11 01:08:04.991029 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #755 | Training finished
2017-06-11 01:08:04.991967 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #755 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 01:08:04.992299 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #755 | Collecting samples for evaluation
2017-06-11 01:08:19.209723 EDT | -----------------------  -----------
2017-06-11 01:08:19.210773 EDT | Epoch                     755
2017-06-11 01:08:19.211007 EDT | Iteration                 755
2017-06-11 01:08:19.211220 EDT | AverageReturn            1103.45
2017-06-11 01:08:19.211498 EDT | StdReturn                 691.711
2017-06-11 01:08:19.211823 EDT | MaxReturn                2667.08
2017-06-11 01:08:19.212101 EDT | MinReturn                 290.037
2017-06-11 01:08:19.212355 EDT | AverageEsReturn           291.003
2017-06-11 01:08:19.212596 EDT | StdEsReturn               121.324
2017-06-11 01:08:19.212834 EDT | MaxEsReturn               482.106
2017-06-11 01:08:19.213071 EDT | MinEsReturn                69.9051
2017-06-11 01:08:19.213299 EDT | AverageDiscountedReturn   212.329
2017-06-11 01:08:19.213451 EDT | AverageQLoss                2.5887
2017-06-11 01:08:19.213689 EDT | AveragePolicySurr         -30.7682
2017-06-11 01:08:19.213955 EDT | AverageQ                   30.4217
2017-06-11 01:08:19.214210 EDT | AverageAbsQ                30.4424
2017-06-11 01:08:19.214365 EDT | AverageY                   30.4217
2017-06-11 01:08:19.214514 EDT | AverageAbsY                30.429
2017-06-11 01:08:19.214662 EDT | AverageAbsQYDiff            0.576927
2017-06-11 01:08:19.214825 EDT | AverageAction               0.993508
2017-06-11 01:08:19.215050 EDT | PolicyRegParamNorm         87.1678
2017-06-11 01:08:19.215203 EDT | QFunRegParamNorm          111.543
2017-06-11 01:08:19.215447 EDT | -----------------------  -----------
2017-06-11 01:08:19.215726 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #756 | Training started
2017-06-11 01:08:36.562281 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #756 | Training finished
2017-06-11 01:08:36.563063 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #756 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 01:08:36.563372 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #756 | Collecting samples for evaluation
2017-06-11 01:08:50.753494 EDT | -----------------------  -----------
2017-06-11 01:08:50.754359 EDT | Epoch                     756
2017-06-11 01:08:50.754915 EDT | Iteration                 756
2017-06-11 01:08:50.756324 EDT | AverageReturn            1315.6
2017-06-11 01:08:50.756740 EDT | StdReturn                 663.197
2017-06-11 01:08:50.757090 EDT | MaxReturn                2413.5
2017-06-11 01:08:50.757477 EDT | MinReturn                 314.408
2017-06-11 01:08:50.757839 EDT | AverageEsReturn           373.388
2017-06-11 01:08:50.758177 EDT | StdEsReturn               162.713
2017-06-11 01:08:50.758511 EDT | MaxEsReturn               718.956
2017-06-11 01:08:50.759911 EDT | MinEsReturn               204.787
2017-06-11 01:08:50.760098 EDT | AverageDiscountedReturn   212.672
2017-06-11 01:08:50.760264 EDT | AverageQLoss                2.27145
2017-06-11 01:08:50.760430 EDT | AveragePolicySurr         -30.7497
2017-06-11 01:08:50.761205 EDT | AverageQ                   30.4211
2017-06-11 01:08:50.761386 EDT | AverageAbsQ                30.4417
2017-06-11 01:08:50.761543 EDT | AverageY                   30.4228
2017-06-11 01:08:50.761715 EDT | AverageAbsY                30.432
2017-06-11 01:08:50.761868 EDT | AverageAbsQYDiff            0.560267
2017-06-11 01:08:50.762018 EDT | AverageAction               0.992926
2017-06-11 01:08:50.762167 EDT | PolicyRegParamNorm         87.2068
2017-06-11 01:08:50.762315 EDT | QFunRegParamNorm          111.625
2017-06-11 01:08:50.762463 EDT | -----------------------  -----------
2017-06-11 01:08:50.762732 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #757 | Training started
2017-06-11 01:09:08.022929 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #757 | Training finished
2017-06-11 01:09:08.023739 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #757 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 01:09:08.023957 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #757 | Collecting samples for evaluation
2017-06-11 01:09:22.957514 EDT | -----------------------  -----------
2017-06-11 01:09:22.958512 EDT | Epoch                     757
2017-06-11 01:09:22.958766 EDT | Iteration                 757
2017-06-11 01:09:22.959027 EDT | AverageReturn            1792.71
2017-06-11 01:09:22.959215 EDT | StdReturn                 635.398
2017-06-11 01:09:22.959432 EDT | MaxReturn                2800.48
2017-06-11 01:09:22.959655 EDT | MinReturn                 806.198
2017-06-11 01:09:22.959838 EDT | AverageEsReturn           712.59
2017-06-11 01:09:22.960033 EDT | StdEsReturn               939.048
2017-06-11 01:09:22.960215 EDT | MaxEsReturn              2332.45
2017-06-11 01:09:22.960581 EDT | MinEsReturn                36.881
2017-06-11 01:09:22.960767 EDT | AverageDiscountedReturn   238.776
2017-06-11 01:09:22.961054 EDT | AverageQLoss                2.46745
2017-06-11 01:09:22.961265 EDT | AveragePolicySurr         -30.7387
2017-06-11 01:09:22.961448 EDT | AverageQ                   30.3892
2017-06-11 01:09:22.961628 EDT | AverageAbsQ                30.4122
2017-06-11 01:09:22.961826 EDT | AverageY                   30.3897
2017-06-11 01:09:22.962006 EDT | AverageAbsY                30.4011
2017-06-11 01:09:22.962200 EDT | AverageAbsQYDiff            0.567644
2017-06-11 01:09:22.962593 EDT | AverageAction               0.990775
2017-06-11 01:09:22.962857 EDT | PolicyRegParamNorm         87.2838
2017-06-11 01:09:22.963125 EDT | QFunRegParamNorm          111.668
2017-06-11 01:09:22.963391 EDT | -----------------------  -----------
2017-06-11 01:09:22.963809 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #758 | Training started
2017-06-11 01:09:40.313328 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #758 | Training finished
2017-06-11 01:09:40.313753 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #758 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 01:09:40.314035 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #758 | Collecting samples for evaluation
2017-06-11 01:09:55.622609 EDT | -----------------------  -----------
2017-06-11 01:09:55.623538 EDT | Epoch                     758
2017-06-11 01:09:55.624005 EDT | Iteration                 758
2017-06-11 01:09:55.624450 EDT | AverageReturn            1688.81
2017-06-11 01:09:55.624892 EDT | StdReturn                 746.727
2017-06-11 01:09:55.625336 EDT | MaxReturn                2860.69
2017-06-11 01:09:55.625796 EDT | MinReturn                 876.685
2017-06-11 01:09:55.626253 EDT | AverageEsReturn           444.728
2017-06-11 01:09:55.627441 EDT | StdEsReturn               340.861
2017-06-11 01:09:55.627807 EDT | MaxEsReturn              1044.43
2017-06-11 01:09:55.628151 EDT | MinEsReturn                71.2
2017-06-11 01:09:55.628495 EDT | AverageDiscountedReturn   239.93
2017-06-11 01:09:55.628840 EDT | AverageQLoss                2.24779
2017-06-11 01:09:55.629190 EDT | AveragePolicySurr         -30.8233
2017-06-11 01:09:55.629533 EDT | AverageQ                   30.4747
2017-06-11 01:09:55.629889 EDT | AverageAbsQ                30.4952
2017-06-11 01:09:55.630227 EDT | AverageY                   30.4743
2017-06-11 01:09:55.631403 EDT | AverageAbsY                30.4841
2017-06-11 01:09:55.631758 EDT | AverageAbsQYDiff            0.549547
2017-06-11 01:09:55.632101 EDT | AverageAction               0.991558
2017-06-11 01:09:55.632443 EDT | PolicyRegParamNorm         87.3247
2017-06-11 01:09:55.632936 EDT | QFunRegParamNorm          111.704
2017-06-11 01:09:55.633336 EDT | -----------------------  -----------
2017-06-11 01:09:55.633876 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #759 | Training started
2017-06-11 01:10:12.835617 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #759 | Training finished
2017-06-11 01:10:12.836760 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #759 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 01:10:12.837179 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #759 | Collecting samples for evaluation
2017-06-11 01:10:27.498284 EDT | -----------------------  -----------
2017-06-11 01:10:27.499123 EDT | Epoch                     759
2017-06-11 01:10:27.499391 EDT | Iteration                 759
2017-06-11 01:10:27.499659 EDT | AverageReturn            1264.37
2017-06-11 01:10:27.499906 EDT | StdReturn                 651.101
2017-06-11 01:10:27.500149 EDT | MaxReturn                2565.64
2017-06-11 01:10:27.500392 EDT | MinReturn                 331.089
2017-06-11 01:10:27.500653 EDT | AverageEsReturn           368.241
2017-06-11 01:10:27.500895 EDT | StdEsReturn               216.977
2017-06-11 01:10:27.501136 EDT | MaxEsReturn               795.912
2017-06-11 01:10:27.501376 EDT | MinEsReturn                47.1012
2017-06-11 01:10:27.501637 EDT | AverageDiscountedReturn   215.469
2017-06-11 01:10:27.501891 EDT | AverageQLoss                2.38381
2017-06-11 01:10:27.502132 EDT | AveragePolicySurr         -30.8064
2017-06-11 01:10:27.502372 EDT | AverageQ                   30.4581
2017-06-11 01:10:27.502629 EDT | AverageAbsQ                30.4822
2017-06-11 01:10:27.502871 EDT | AverageY                   30.4617
2017-06-11 01:10:27.503111 EDT | AverageAbsY                30.4714
2017-06-11 01:10:27.503350 EDT | AverageAbsQYDiff            0.562532
2017-06-11 01:10:27.503589 EDT | AverageAction               0.990584
2017-06-11 01:10:27.503851 EDT | PolicyRegParamNorm         87.3561
2017-06-11 01:10:27.504091 EDT | QFunRegParamNorm          111.771
2017-06-11 01:10:27.504330 EDT | -----------------------  -----------
2017-06-11 01:10:27.504727 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #760 | Training started
2017-06-11 01:10:45.158090 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #760 | Training finished
2017-06-11 01:10:45.158518 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #760 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 01:10:45.158870 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #760 | Collecting samples for evaluation
2017-06-11 01:11:00.166016 EDT | -----------------------  -----------
2017-06-11 01:11:00.167067 EDT | Epoch                     760
2017-06-11 01:11:00.167450 EDT | Iteration                 760
2017-06-11 01:11:00.167787 EDT | AverageReturn            1669.27
2017-06-11 01:11:00.168146 EDT | StdReturn                 918.893
2017-06-11 01:11:00.168479 EDT | MaxReturn                3080.11
2017-06-11 01:11:00.168806 EDT | MinReturn                 624.395
2017-06-11 01:11:00.169132 EDT | AverageEsReturn           291.778
2017-06-11 01:11:00.169458 EDT | StdEsReturn               252.997
2017-06-11 01:11:00.169798 EDT | MaxEsReturn               700.308
2017-06-11 01:11:00.170128 EDT | MinEsReturn                52.6142
2017-06-11 01:11:00.170455 EDT | AverageDiscountedReturn   238.599
2017-06-11 01:11:00.170779 EDT | AverageQLoss                2.44733
2017-06-11 01:11:00.171104 EDT | AveragePolicySurr         -30.904
2017-06-11 01:11:00.171429 EDT | AverageQ                   30.5719
2017-06-11 01:11:00.171757 EDT | AverageAbsQ                30.5931
2017-06-11 01:11:00.172083 EDT | AverageY                   30.5712
2017-06-11 01:11:00.172404 EDT | AverageAbsY                30.5806
2017-06-11 01:11:00.172725 EDT | AverageAbsQYDiff            0.569867
2017-06-11 01:11:00.173047 EDT | AverageAction               0.989589
2017-06-11 01:11:00.173376 EDT | PolicyRegParamNorm         87.3861
2017-06-11 01:11:00.173705 EDT | QFunRegParamNorm          111.853
2017-06-11 01:11:00.174036 EDT | -----------------------  -----------
2017-06-11 01:11:00.174523 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #761 | Training started
2017-06-11 01:11:19.145268 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #761 | Training finished
2017-06-11 01:11:19.146643 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #761 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 01:11:19.147072 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #761 | Collecting samples for evaluation
2017-06-11 01:11:34.322944 EDT | -----------------------  -----------
2017-06-11 01:11:34.328962 EDT | Epoch                     761
2017-06-11 01:11:34.329181 EDT | Iteration                 761
2017-06-11 01:11:34.329409 EDT | AverageReturn            1362.65
2017-06-11 01:11:34.329683 EDT | StdReturn                 691.62
2017-06-11 01:11:34.329882 EDT | MaxReturn                2875.15
2017-06-11 01:11:34.330066 EDT | MinReturn                 571.099
2017-06-11 01:11:34.330246 EDT | AverageEsReturn           392.031
2017-06-11 01:11:34.330470 EDT | StdEsReturn               279.882
2017-06-11 01:11:34.330657 EDT | MaxEsReturn               915.951
2017-06-11 01:11:34.330849 EDT | MinEsReturn                76.9122
2017-06-11 01:11:34.331028 EDT | AverageDiscountedReturn   235.807
2017-06-11 01:11:34.331206 EDT | AverageQLoss                2.08159
2017-06-11 01:11:34.331385 EDT | AveragePolicySurr         -30.8855
2017-06-11 01:11:34.331563 EDT | AverageQ                   30.5336
2017-06-11 01:11:34.331777 EDT | AverageAbsQ                30.557
2017-06-11 01:11:34.331964 EDT | AverageY                   30.5327
2017-06-11 01:11:34.332426 EDT | AverageAbsY                30.5438
2017-06-11 01:11:34.332608 EDT | AverageAbsQYDiff            0.552271
2017-06-11 01:11:34.332831 EDT | AverageAction               0.991837
2017-06-11 01:11:34.333314 EDT | PolicyRegParamNorm         87.45
2017-06-11 01:11:34.333497 EDT | QFunRegParamNorm          111.927
2017-06-11 01:11:34.333676 EDT | -----------------------  -----------
2017-06-11 01:11:34.334073 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #762 | Training started
2017-06-11 01:11:52.651929 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #762 | Training finished
2017-06-11 01:11:52.652798 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #762 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 01:11:52.653193 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #762 | Collecting samples for evaluation
2017-06-11 01:12:06.880061 EDT | -----------------------  -----------
2017-06-11 01:12:06.881231 EDT | Epoch                     762
2017-06-11 01:12:06.881735 EDT | Iteration                 762
2017-06-11 01:12:06.882213 EDT | AverageReturn            1312.99
2017-06-11 01:12:06.882682 EDT | StdReturn                 614.338
2017-06-11 01:12:06.883153 EDT | MaxReturn                2758.9
2017-06-11 01:12:06.883628 EDT | MinReturn                 675.253
2017-06-11 01:12:06.884097 EDT | AverageEsReturn           369.722
2017-06-11 01:12:06.884566 EDT | StdEsReturn               233.511
2017-06-11 01:12:06.885042 EDT | MaxEsReturn               869.806
2017-06-11 01:12:06.885427 EDT | MinEsReturn               174.973
2017-06-11 01:12:06.885808 EDT | AverageDiscountedReturn   235.994
2017-06-11 01:12:06.886180 EDT | AverageQLoss                2.28513
2017-06-11 01:12:06.886554 EDT | AveragePolicySurr         -30.8566
2017-06-11 01:12:06.886931 EDT | AverageQ                   30.5001
2017-06-11 01:12:06.887298 EDT | AverageAbsQ                30.5181
2017-06-11 01:12:06.887669 EDT | AverageY                   30.5025
2017-06-11 01:12:06.888044 EDT | AverageAbsY                30.5125
2017-06-11 01:12:06.888419 EDT | AverageAbsQYDiff            0.563997
2017-06-11 01:12:06.888785 EDT | AverageAction               0.991412
2017-06-11 01:12:06.889156 EDT | PolicyRegParamNorm         87.3931
2017-06-11 01:12:06.889532 EDT | QFunRegParamNorm          111.963
2017-06-11 01:12:06.889917 EDT | -----------------------  -----------
2017-06-11 01:12:06.890461 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #763 | Training started
2017-06-11 01:12:25.020868 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #763 | Training finished
2017-06-11 01:12:25.021955 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #763 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 01:12:25.022416 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #763 | Collecting samples for evaluation
2017-06-11 01:12:39.662298 EDT | -----------------------  ----------
2017-06-11 01:12:39.663124 EDT | Epoch                     763
2017-06-11 01:12:39.663394 EDT | Iteration                 763
2017-06-11 01:12:39.663644 EDT | AverageReturn            1583.14
2017-06-11 01:12:39.663889 EDT | StdReturn                 795.733
2017-06-11 01:12:39.664132 EDT | MaxReturn                2928.3
2017-06-11 01:12:39.664373 EDT | MinReturn                 362.178
2017-06-11 01:12:39.664615 EDT | AverageEsReturn           256.982
2017-06-11 01:12:39.664857 EDT | StdEsReturn               140.815
2017-06-11 01:12:39.665099 EDT | MaxEsReturn               534.89
2017-06-11 01:12:39.665339 EDT | MinEsReturn                27.4853
2017-06-11 01:12:39.665579 EDT | AverageDiscountedReturn   231.363
2017-06-11 01:12:39.665833 EDT | AverageQLoss                2.20746
2017-06-11 01:12:39.666075 EDT | AveragePolicySurr         -30.821
2017-06-11 01:12:39.666316 EDT | AverageQ                   30.4655
2017-06-11 01:12:39.666557 EDT | AverageAbsQ                30.4898
2017-06-11 01:12:39.666799 EDT | AverageY                   30.4671
2017-06-11 01:12:39.667039 EDT | AverageAbsY                30.4773
2017-06-11 01:12:39.667278 EDT | AverageAbsQYDiff            0.56836
2017-06-11 01:12:39.667518 EDT | AverageAction               0.99145
2017-06-11 01:12:39.667757 EDT | PolicyRegParamNorm         87.4422
2017-06-11 01:12:39.667997 EDT | QFunRegParamNorm          112.004
2017-06-11 01:12:39.668236 EDT | -----------------------  ----------
2017-06-11 01:12:39.668612 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #764 | Training started
2017-06-11 01:12:57.069004 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #764 | Training finished
2017-06-11 01:12:57.069944 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #764 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 01:12:57.070395 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #764 | Collecting samples for evaluation
2017-06-11 01:13:11.310360 EDT | -----------------------  -----------
2017-06-11 01:13:11.311280 EDT | Epoch                     764
2017-06-11 01:13:11.311646 EDT | Iteration                 764
2017-06-11 01:13:11.311997 EDT | AverageReturn            1040.89
2017-06-11 01:13:11.312340 EDT | StdReturn                 499.465
2017-06-11 01:13:11.312684 EDT | MaxReturn                2253.1
2017-06-11 01:13:11.313022 EDT | MinReturn                 310.338
2017-06-11 01:13:11.313363 EDT | AverageEsReturn           656.263
2017-06-11 01:13:11.313709 EDT | StdEsReturn               742.697
2017-06-11 01:13:11.313984 EDT | MaxEsReturn              1890.84
2017-06-11 01:13:11.314238 EDT | MinEsReturn                49.9724
2017-06-11 01:13:11.314488 EDT | AverageDiscountedReturn   220.751
2017-06-11 01:13:11.314745 EDT | AverageQLoss                2.56855
2017-06-11 01:13:11.314991 EDT | AveragePolicySurr         -30.8775
2017-06-11 01:13:11.315238 EDT | AverageQ                   30.524
2017-06-11 01:13:11.315487 EDT | AverageAbsQ                30.5468
2017-06-11 01:13:11.315731 EDT | AverageY                   30.5252
2017-06-11 01:13:11.315976 EDT | AverageAbsY                30.5338
2017-06-11 01:13:11.316221 EDT | AverageAbsQYDiff            0.574731
2017-06-11 01:13:11.316465 EDT | AverageAction               0.991738
2017-06-11 01:13:11.316710 EDT | PolicyRegParamNorm         87.4421
2017-06-11 01:13:11.316954 EDT | QFunRegParamNorm          112.126
2017-06-11 01:13:11.317197 EDT | -----------------------  -----------
2017-06-11 01:13:11.317573 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #765 | Training started
2017-06-11 01:13:28.771557 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #765 | Training finished
2017-06-11 01:13:28.773097 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #765 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 01:13:28.773562 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #765 | Collecting samples for evaluation
2017-06-11 01:13:44.242183 EDT | -----------------------  -----------
2017-06-11 01:13:44.243065 EDT | Epoch                     765
2017-06-11 01:13:44.243412 EDT | Iteration                 765
2017-06-11 01:13:44.243727 EDT | AverageReturn            1967.98
2017-06-11 01:13:44.244054 EDT | StdReturn                 682.988
2017-06-11 01:13:44.244266 EDT | MaxReturn                3133.14
2017-06-11 01:13:44.244423 EDT | MinReturn                1007.34
2017-06-11 01:13:44.244622 EDT | AverageEsReturn           392.787
2017-06-11 01:13:44.244798 EDT | StdEsReturn               302.311
2017-06-11 01:13:44.244952 EDT | MaxEsReturn               891.618
2017-06-11 01:13:44.245101 EDT | MinEsReturn                93.3746
2017-06-11 01:13:44.245269 EDT | AverageDiscountedReturn   245.739
2017-06-11 01:13:44.245432 EDT | AverageQLoss                2.45726
2017-06-11 01:13:44.245868 EDT | AveragePolicySurr         -30.8052
2017-06-11 01:13:44.246151 EDT | AverageQ                   30.4456
2017-06-11 01:13:44.246380 EDT | AverageAbsQ                30.468
2017-06-11 01:13:44.246533 EDT | AverageY                   30.4472
2017-06-11 01:13:44.246682 EDT | AverageAbsY                30.4566
2017-06-11 01:13:44.246831 EDT | AverageAbsQYDiff            0.574445
2017-06-11 01:13:44.246979 EDT | AverageAction               0.991176
2017-06-11 01:13:44.247128 EDT | PolicyRegParamNorm         87.4444
2017-06-11 01:13:44.247276 EDT | QFunRegParamNorm          112.236
2017-06-11 01:13:44.247424 EDT | -----------------------  -----------
2017-06-11 01:13:44.247712 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #766 | Training started
2017-06-11 01:14:04.190843 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #766 | Training finished
2017-06-11 01:14:04.191844 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #766 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 01:14:04.192225 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #766 | Collecting samples for evaluation
2017-06-11 01:14:18.234669 EDT | -----------------------  -----------
2017-06-11 01:14:18.234933 EDT | Epoch                     766
2017-06-11 01:14:18.235096 EDT | Iteration                 766
2017-06-11 01:14:18.235252 EDT | AverageReturn            2001.79
2017-06-11 01:14:18.235404 EDT | StdReturn                 799.022
2017-06-11 01:14:18.235557 EDT | MaxReturn                2842.75
2017-06-11 01:14:18.235784 EDT | MinReturn                 321.944
2017-06-11 01:14:18.235938 EDT | AverageEsReturn           476.983
2017-06-11 01:14:18.236088 EDT | StdEsReturn               175.988
2017-06-11 01:14:18.236304 EDT | MaxEsReturn               640.493
2017-06-11 01:14:18.236587 EDT | MinEsReturn               234.649
2017-06-11 01:14:18.236859 EDT | AverageDiscountedReturn   227.46
2017-06-11 01:14:18.237138 EDT | AverageQLoss                2.51972
2017-06-11 01:14:18.237320 EDT | AveragePolicySurr         -30.7367
2017-06-11 01:14:18.237471 EDT | AverageQ                   30.3745
2017-06-11 01:14:18.237619 EDT | AverageAbsQ                30.3977
2017-06-11 01:14:18.237860 EDT | AverageY                   30.3764
2017-06-11 01:14:18.238051 EDT | AverageAbsY                30.3869
2017-06-11 01:14:18.238201 EDT | AverageAbsQYDiff            0.582178
2017-06-11 01:14:18.238350 EDT | AverageAction               0.992888
2017-06-11 01:14:18.238545 EDT | PolicyRegParamNorm         87.4733
2017-06-11 01:14:18.238696 EDT | QFunRegParamNorm          112.309
2017-06-11 01:14:18.238844 EDT | -----------------------  -----------
2017-06-11 01:14:18.239094 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #767 | Training started
2017-06-11 01:14:35.470345 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #767 | Training finished
2017-06-11 01:14:35.472065 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #767 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 01:14:35.472469 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #767 | Collecting samples for evaluation
2017-06-11 01:14:49.792837 EDT | -----------------------  -----------
2017-06-11 01:14:49.793732 EDT | Epoch                     767
2017-06-11 01:14:49.794026 EDT | Iteration                 767
2017-06-11 01:14:49.794291 EDT | AverageReturn            1937.23
2017-06-11 01:14:49.794551 EDT | StdReturn                 834.259
2017-06-11 01:14:49.794827 EDT | MaxReturn                2821.85
2017-06-11 01:14:49.795083 EDT | MinReturn                 673.723
2017-06-11 01:14:49.795337 EDT | AverageEsReturn           773.728
2017-06-11 01:14:49.795591 EDT | StdEsReturn               474.957
2017-06-11 01:14:49.795863 EDT | MaxEsReturn              1380.26
2017-06-11 01:14:49.796117 EDT | MinEsReturn               133.563
2017-06-11 01:14:49.796370 EDT | AverageDiscountedReturn   232.477
2017-06-11 01:14:49.796622 EDT | AverageQLoss                2.13833
2017-06-11 01:14:49.796891 EDT | AveragePolicySurr         -30.9186
2017-06-11 01:14:49.797144 EDT | AverageQ                   30.5968
2017-06-11 01:14:49.797396 EDT | AverageAbsQ                30.6148
2017-06-11 01:14:49.797648 EDT | AverageY                   30.5969
2017-06-11 01:14:49.797974 EDT | AverageAbsY                30.6054
2017-06-11 01:14:49.798272 EDT | AverageAbsQYDiff            0.536766
2017-06-11 01:14:49.798581 EDT | AverageAction               0.990928
2017-06-11 01:14:49.798857 EDT | PolicyRegParamNorm         87.4586
2017-06-11 01:14:49.799111 EDT | QFunRegParamNorm          112.407
2017-06-11 01:14:49.799362 EDT | -----------------------  -----------
2017-06-11 01:14:49.799756 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #768 | Training started
2017-06-11 01:15:07.029459 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #768 | Training finished
2017-06-11 01:15:07.031366 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #768 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 01:15:07.031584 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #768 | Collecting samples for evaluation
2017-06-11 01:15:21.360371 EDT | -----------------------  -----------
2017-06-11 01:15:21.361717 EDT | Epoch                     768
2017-06-11 01:15:21.362158 EDT | Iteration                 768
2017-06-11 01:15:21.362816 EDT | AverageReturn            1289.07
2017-06-11 01:15:21.363261 EDT | StdReturn                 562.825
2017-06-11 01:15:21.363750 EDT | MaxReturn                2305.87
2017-06-11 01:15:21.364183 EDT | MinReturn                 588.598
2017-06-11 01:15:21.364842 EDT | AverageEsReturn           312.957
2017-06-11 01:15:21.365376 EDT | StdEsReturn               202.871
2017-06-11 01:15:21.365817 EDT | MaxEsReturn               805.18
2017-06-11 01:15:21.366314 EDT | MinEsReturn               150.914
2017-06-11 01:15:21.366733 EDT | AverageDiscountedReturn   221.03
2017-06-11 01:15:21.367317 EDT | AverageQLoss                2.32138
2017-06-11 01:15:21.367753 EDT | AveragePolicySurr         -30.8127
2017-06-11 01:15:21.368296 EDT | AverageQ                   30.4789
2017-06-11 01:15:21.368722 EDT | AverageAbsQ                30.5018
2017-06-11 01:15:21.369206 EDT | AverageY                   30.4808
2017-06-11 01:15:21.369636 EDT | AverageAbsY                30.4913
2017-06-11 01:15:21.370132 EDT | AverageAbsQYDiff            0.555644
2017-06-11 01:15:21.370535 EDT | AverageAction               0.990485
2017-06-11 01:15:21.370967 EDT | PolicyRegParamNorm         87.4839
2017-06-11 01:15:21.371619 EDT | QFunRegParamNorm          112.487
2017-06-11 01:15:21.372442 EDT | -----------------------  -----------
2017-06-11 01:15:21.373092 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #769 | Training started
2017-06-11 01:15:38.708891 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #769 | Training finished
2017-06-11 01:15:38.710381 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #769 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 01:15:38.710900 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #769 | Collecting samples for evaluation
2017-06-11 01:15:52.731886 EDT | -----------------------  -----------
2017-06-11 01:15:52.732799 EDT | Epoch                     769
2017-06-11 01:15:52.733025 EDT | Iteration                 769
2017-06-11 01:15:52.733317 EDT | AverageReturn            1026.38
2017-06-11 01:15:52.733684 EDT | StdReturn                 701.007
2017-06-11 01:15:52.733991 EDT | MaxReturn                3106.32
2017-06-11 01:15:52.734156 EDT | MinReturn                 265.77
2017-06-11 01:15:52.734322 EDT | AverageEsReturn           710.306
2017-06-11 01:15:52.734508 EDT | StdEsReturn               675.399
2017-06-11 01:15:52.734743 EDT | MaxEsReturn              1778.53
2017-06-11 01:15:52.734931 EDT | MinEsReturn                92.3621
2017-06-11 01:15:52.735110 EDT | AverageDiscountedReturn   214.205
2017-06-11 01:15:52.735336 EDT | AverageQLoss                2.6354
2017-06-11 01:15:52.735514 EDT | AveragePolicySurr         -30.9097
2017-06-11 01:15:52.735705 EDT | AverageQ                   30.5608
2017-06-11 01:15:52.735882 EDT | AverageAbsQ                30.5867
2017-06-11 01:15:52.736392 EDT | AverageY                   30.5601
2017-06-11 01:15:52.736581 EDT | AverageAbsY                30.5754
2017-06-11 01:15:52.736763 EDT | AverageAbsQYDiff            0.570813
2017-06-11 01:15:52.736957 EDT | AverageAction               0.992818
2017-06-11 01:15:52.737399 EDT | PolicyRegParamNorm         87.5225
2017-06-11 01:15:52.737581 EDT | QFunRegParamNorm          112.564
2017-06-11 01:15:52.737915 EDT | -----------------------  -----------
2017-06-11 01:15:52.738511 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #770 | Training started
2017-06-11 01:16:10.766674 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #770 | Training finished
2017-06-11 01:16:10.767687 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #770 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 01:16:10.768087 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #770 | Collecting samples for evaluation
2017-06-11 01:16:25.679985 EDT | -----------------------  -----------
2017-06-11 01:16:25.680447 EDT | Epoch                     770
2017-06-11 01:16:25.680786 EDT | Iteration                 770
2017-06-11 01:16:25.681139 EDT | AverageReturn             782.955
2017-06-11 01:16:25.681405 EDT | StdReturn                 350.639
2017-06-11 01:16:25.681661 EDT | MaxReturn                1787.91
2017-06-11 01:16:25.681977 EDT | MinReturn                 265.967
2017-06-11 01:16:25.682325 EDT | AverageEsReturn           365.085
2017-06-11 01:16:25.682619 EDT | StdEsReturn               198.161
2017-06-11 01:16:25.682893 EDT | MaxEsReturn               673.999
2017-06-11 01:16:25.683206 EDT | MinEsReturn                55.166
2017-06-11 01:16:25.683553 EDT | AverageDiscountedReturn   207.582
2017-06-11 01:16:25.683870 EDT | AverageQLoss                1.93058
2017-06-11 01:16:25.684191 EDT | AveragePolicySurr         -30.9472
2017-06-11 01:16:25.685111 EDT | AverageQ                   30.605
2017-06-11 01:16:25.685477 EDT | AverageAbsQ                30.6294
2017-06-11 01:16:25.685795 EDT | AverageY                   30.6074
2017-06-11 01:16:25.686619 EDT | AverageAbsY                30.6224
2017-06-11 01:16:25.686948 EDT | AverageAbsQYDiff            0.526955
2017-06-11 01:16:25.690442 EDT | AverageAction               0.992021
2017-06-11 01:16:25.690633 EDT | PolicyRegParamNorm         87.5793
2017-06-11 01:16:25.690800 EDT | QFunRegParamNorm          112.605
2017-06-11 01:16:25.690956 EDT | -----------------------  -----------
2017-06-11 01:16:25.691232 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #771 | Training started
2017-06-11 01:16:43.237577 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #771 | Training finished
2017-06-11 01:16:43.239060 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #771 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 01:16:43.239435 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #771 | Collecting samples for evaluation
2017-06-11 01:16:58.334180 EDT | -----------------------  -----------
2017-06-11 01:16:58.335022 EDT | Epoch                     771
2017-06-11 01:16:58.335292 EDT | Iteration                 771
2017-06-11 01:16:58.335541 EDT | AverageReturn            1068.8
2017-06-11 01:16:58.335787 EDT | StdReturn                 380.999
2017-06-11 01:16:58.336030 EDT | MaxReturn                2253.84
2017-06-11 01:16:58.336272 EDT | MinReturn                 192.032
2017-06-11 01:16:58.336514 EDT | AverageEsReturn           505.354
2017-06-11 01:16:58.336756 EDT | StdEsReturn               391.481
2017-06-11 01:16:58.336998 EDT | MaxEsReturn              1148.64
2017-06-11 01:16:58.337249 EDT | MinEsReturn               126.694
2017-06-11 01:16:58.337491 EDT | AverageDiscountedReturn   238.36
2017-06-11 01:16:58.337740 EDT | AverageQLoss                2.34882
2017-06-11 01:16:58.337984 EDT | AveragePolicySurr         -30.8902
2017-06-11 01:16:58.338225 EDT | AverageQ                   30.5191
2017-06-11 01:16:58.338466 EDT | AverageAbsQ                30.5463
2017-06-11 01:16:58.338706 EDT | AverageY                   30.5199
2017-06-11 01:16:58.338947 EDT | AverageAbsY                30.535
2017-06-11 01:16:58.339187 EDT | AverageAbsQYDiff            0.57086
2017-06-11 01:16:58.339427 EDT | AverageAction               0.990675
2017-06-11 01:16:58.339666 EDT | PolicyRegParamNorm         87.6254
2017-06-11 01:16:58.339905 EDT | QFunRegParamNorm          112.687
2017-06-11 01:16:58.340144 EDT | -----------------------  -----------
2017-06-11 01:16:58.340528 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #772 | Training started
2017-06-11 01:17:16.213135 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #772 | Training finished
2017-06-11 01:17:16.214015 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #772 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 01:17:16.214402 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #772 | Collecting samples for evaluation
2017-06-11 01:17:30.839132 EDT | -----------------------  -----------
2017-06-11 01:17:30.840331 EDT | Epoch                     772
2017-06-11 01:17:30.840678 EDT | Iteration                 772
2017-06-11 01:17:30.841022 EDT | AverageReturn            1026.03
2017-06-11 01:17:30.841336 EDT | StdReturn                 697.726
2017-06-11 01:17:30.841596 EDT | MaxReturn                2899.9
2017-06-11 01:17:30.841925 EDT | MinReturn                 208.618
2017-06-11 01:17:30.842257 EDT | AverageEsReturn           412.378
2017-06-11 01:17:30.842592 EDT | StdEsReturn               307.578
2017-06-11 01:17:30.842883 EDT | MaxEsReturn              1041.25
2017-06-11 01:17:30.843146 EDT | MinEsReturn                22.0781
2017-06-11 01:17:30.843476 EDT | AverageDiscountedReturn   221.957
2017-06-11 01:17:30.843817 EDT | AverageQLoss                2.26481
2017-06-11 01:17:30.844144 EDT | AveragePolicySurr         -30.8758
2017-06-11 01:17:30.844409 EDT | AverageQ                   30.523
2017-06-11 01:17:30.844699 EDT | AverageAbsQ                30.5548
2017-06-11 01:17:30.845023 EDT | AverageY                   30.525
2017-06-11 01:17:30.845362 EDT | AverageAbsY                30.5431
2017-06-11 01:17:30.845672 EDT | AverageAbsQYDiff            0.561666
2017-06-11 01:17:30.845942 EDT | AverageAction               0.992336
2017-06-11 01:17:30.846255 EDT | PolicyRegParamNorm         87.6553
2017-06-11 01:17:30.846583 EDT | QFunRegParamNorm          112.745
2017-06-11 01:17:30.846918 EDT | -----------------------  -----------
2017-06-11 01:17:30.847363 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #773 | Training started
2017-06-11 01:17:48.755634 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #773 | Training finished
2017-06-11 01:17:48.756630 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #773 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 01:17:48.757137 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #773 | Collecting samples for evaluation
2017-06-11 01:18:02.056118 EDT | -----------------------  -----------
2017-06-11 01:18:02.056964 EDT | Epoch                     773
2017-06-11 01:18:02.057274 EDT | Iteration                 773
2017-06-11 01:18:02.057627 EDT | AverageReturn             690.599
2017-06-11 01:18:02.057987 EDT | StdReturn                 200.193
2017-06-11 01:18:02.058320 EDT | MaxReturn                1851.44
2017-06-11 01:18:02.058650 EDT | MinReturn                 444.704
2017-06-11 01:18:02.058981 EDT | AverageEsReturn           410.983
2017-06-11 01:18:02.059331 EDT | StdEsReturn               248.219
2017-06-11 01:18:02.059681 EDT | MaxEsReturn               677.21
2017-06-11 01:18:02.060009 EDT | MinEsReturn                 5.01505
2017-06-11 01:18:02.060360 EDT | AverageDiscountedReturn   232.178
2017-06-11 01:18:02.060627 EDT | AverageQLoss                2.098
2017-06-11 01:18:02.060806 EDT | AveragePolicySurr         -30.9226
2017-06-11 01:18:02.060968 EDT | AverageQ                   30.5682
2017-06-11 01:18:02.061127 EDT | AverageAbsQ                30.6002
2017-06-11 01:18:02.061365 EDT | AverageY                   30.5705
2017-06-11 01:18:02.061526 EDT | AverageAbsY                30.5887
2017-06-11 01:18:02.061683 EDT | AverageAbsQYDiff            0.545061
2017-06-11 01:18:02.061939 EDT | AverageAction               0.993768
2017-06-11 01:18:02.062122 EDT | PolicyRegParamNorm         87.7281
2017-06-11 01:18:02.062303 EDT | QFunRegParamNorm          112.777
2017-06-11 01:18:02.062482 EDT | -----------------------  -----------
2017-06-11 01:18:02.062804 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #774 | Training started
2017-06-11 01:18:18.512518 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #774 | Training finished
2017-06-11 01:18:18.513418 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #774 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 01:18:18.513624 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #774 | Collecting samples for evaluation
2017-06-11 01:18:32.592338 EDT | -----------------------  -----------
2017-06-11 01:18:32.594403 EDT | Epoch                     774
2017-06-11 01:18:32.594961 EDT | Iteration                 774
2017-06-11 01:18:32.595320 EDT | AverageReturn             857.448
2017-06-11 01:18:32.595675 EDT | StdReturn                 605.561
2017-06-11 01:18:32.596022 EDT | MaxReturn                2871.9
2017-06-11 01:18:32.596374 EDT | MinReturn                 270.581
2017-06-11 01:18:32.596860 EDT | AverageEsReturn           416.586
2017-06-11 01:18:32.597372 EDT | StdEsReturn               225.737
2017-06-11 01:18:32.597738 EDT | MaxEsReturn               670.641
2017-06-11 01:18:32.598304 EDT | MinEsReturn                13.4012
2017-06-11 01:18:32.598759 EDT | AverageDiscountedReturn   203.088
2017-06-11 01:18:32.599104 EDT | AverageQLoss                2.11609
2017-06-11 01:18:32.599451 EDT | AveragePolicySurr         -30.8729
2017-06-11 01:18:32.599799 EDT | AverageQ                   30.5202
2017-06-11 01:18:32.600147 EDT | AverageAbsQ                30.5479
2017-06-11 01:18:32.600489 EDT | AverageY                   30.5217
2017-06-11 01:18:32.600835 EDT | AverageAbsY                30.5386
2017-06-11 01:18:32.601185 EDT | AverageAbsQYDiff            0.541516
2017-06-11 01:18:32.601530 EDT | AverageAction               0.993012
2017-06-11 01:18:32.602126 EDT | PolicyRegParamNorm         87.8262
2017-06-11 01:18:32.602714 EDT | QFunRegParamNorm          112.9
2017-06-11 01:18:32.604403 EDT | -----------------------  -----------
2017-06-11 01:18:32.605005 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #775 | Training started
2017-06-11 01:18:51.151196 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #775 | Training finished
2017-06-11 01:18:51.169708 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #775 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 01:18:51.170183 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #775 | Collecting samples for evaluation
2017-06-11 01:19:05.396374 EDT | -----------------------  -----------
2017-06-11 01:19:05.397221 EDT | Epoch                     775
2017-06-11 01:19:05.397522 EDT | Iteration                 775
2017-06-11 01:19:05.397784 EDT | AverageReturn             922.493
2017-06-11 01:19:05.398004 EDT | StdReturn                 552.477
2017-06-11 01:19:05.398162 EDT | MaxReturn                2212.5
2017-06-11 01:19:05.398314 EDT | MinReturn                 296.562
2017-06-11 01:19:05.398554 EDT | AverageEsReturn           344.439
2017-06-11 01:19:05.398725 EDT | StdEsReturn               199.84
2017-06-11 01:19:05.398894 EDT | MaxEsReturn               750.381
2017-06-11 01:19:05.399369 EDT | MinEsReturn               111.187
2017-06-11 01:19:05.399563 EDT | AverageDiscountedReturn   215.17
2017-06-11 01:19:05.399759 EDT | AverageQLoss                2.80847
2017-06-11 01:19:05.399948 EDT | AveragePolicySurr         -30.8839
2017-06-11 01:19:05.400121 EDT | AverageQ                   30.5295
2017-06-11 01:19:05.400353 EDT | AverageAbsQ                30.5503
2017-06-11 01:19:05.400623 EDT | AverageY                   30.53
2017-06-11 01:19:05.400847 EDT | AverageAbsY                30.5394
2017-06-11 01:19:05.401199 EDT | AverageAbsQYDiff            0.583626
2017-06-11 01:19:05.401519 EDT | AverageAction               0.992765
2017-06-11 01:19:05.401831 EDT | PolicyRegParamNorm         87.9147
2017-06-11 01:19:05.402147 EDT | QFunRegParamNorm          112.981
2017-06-11 01:19:05.402423 EDT | -----------------------  -----------
2017-06-11 01:19:05.402892 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #776 | Training started
2017-06-11 01:19:24.180607 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #776 | Training finished
2017-06-11 01:19:24.181134 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #776 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 01:19:24.181324 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #776 | Collecting samples for evaluation
2017-06-11 01:19:37.051022 EDT | -----------------------  -----------
2017-06-11 01:19:37.051962 EDT | Epoch                     776
2017-06-11 01:19:37.052253 EDT | Iteration                 776
2017-06-11 01:19:37.052513 EDT | AverageReturn             950.95
2017-06-11 01:19:37.052782 EDT | StdReturn                 600.377
2017-06-11 01:19:37.053034 EDT | MaxReturn                2965.23
2017-06-11 01:19:37.053284 EDT | MinReturn                  77.5275
2017-06-11 01:19:37.053533 EDT | AverageEsReturn           293.642
2017-06-11 01:19:37.053810 EDT | StdEsReturn               226.336
2017-06-11 01:19:37.054066 EDT | MaxEsReturn               681.762
2017-06-11 01:19:37.054314 EDT | MinEsReturn                28.5115
2017-06-11 01:19:37.054562 EDT | AverageDiscountedReturn   227.583
2017-06-11 01:19:37.054808 EDT | AverageQLoss                2.05091
2017-06-11 01:19:37.055055 EDT | AveragePolicySurr         -30.8257
2017-06-11 01:19:37.055299 EDT | AverageQ                   30.4967
2017-06-11 01:19:37.055544 EDT | AverageAbsQ                30.5186
2017-06-11 01:19:37.055789 EDT | AverageY                   30.4991
2017-06-11 01:19:37.056033 EDT | AverageAbsY                30.5093
2017-06-11 01:19:37.056278 EDT | AverageAbsQYDiff            0.540511
2017-06-11 01:19:37.056522 EDT | AverageAction               0.993434
2017-06-11 01:19:37.056766 EDT | PolicyRegParamNorm         87.9281
2017-06-11 01:19:37.057009 EDT | QFunRegParamNorm          113.048
2017-06-11 01:19:37.057254 EDT | -----------------------  -----------
2017-06-11 01:19:37.057640 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #777 | Training started
2017-06-11 01:19:53.846140 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #777 | Training finished
2017-06-11 01:19:53.847007 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #777 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 01:19:53.847401 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #777 | Collecting samples for evaluation
2017-06-11 01:20:08.071295 EDT | -----------------------  -----------
2017-06-11 01:20:08.072267 EDT | Epoch                     777
2017-06-11 01:20:08.072640 EDT | Iteration                 777
2017-06-11 01:20:08.072991 EDT | AverageReturn             478.289
2017-06-11 01:20:08.073340 EDT | StdReturn                 498.743
2017-06-11 01:20:08.073688 EDT | MaxReturn                2311.84
2017-06-11 01:20:08.074043 EDT | MinReturn                  63.1252
2017-06-11 01:20:08.074386 EDT | AverageEsReturn           518.402
2017-06-11 01:20:08.074731 EDT | StdEsReturn               298.347
2017-06-11 01:20:08.075078 EDT | MaxEsReturn               967.348
2017-06-11 01:20:08.075422 EDT | MinEsReturn                64.8301
2017-06-11 01:20:08.075767 EDT | AverageDiscountedReturn   149.324
2017-06-11 01:20:08.076113 EDT | AverageQLoss                2.239
2017-06-11 01:20:08.076460 EDT | AveragePolicySurr         -30.7857
2017-06-11 01:20:08.076802 EDT | AverageQ                   30.4483
2017-06-11 01:20:08.077151 EDT | AverageAbsQ                30.4729
2017-06-11 01:20:08.077496 EDT | AverageY                   30.4503
2017-06-11 01:20:08.077853 EDT | AverageAbsY                30.4637
2017-06-11 01:20:08.078200 EDT | AverageAbsQYDiff            0.553861
2017-06-11 01:20:08.078547 EDT | AverageAction               0.993177
2017-06-11 01:20:08.078889 EDT | PolicyRegParamNorm         87.9469
2017-06-11 01:20:08.079234 EDT | QFunRegParamNorm          113.103
2017-06-11 01:20:08.079579 EDT | -----------------------  -----------
2017-06-11 01:20:08.080100 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #778 | Training started
2017-06-11 01:20:23.954202 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #778 | Training finished
2017-06-11 01:20:23.956923 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #778 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 01:20:23.957165 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #778 | Collecting samples for evaluation
2017-06-11 01:20:38.823193 EDT | -----------------------  -----------
2017-06-11 01:20:38.826606 EDT | Epoch                     778
2017-06-11 01:20:38.826917 EDT | Iteration                 778
2017-06-11 01:20:38.827187 EDT | AverageReturn            1330.89
2017-06-11 01:20:38.827453 EDT | StdReturn                 490.542
2017-06-11 01:20:38.828400 EDT | MaxReturn                3163.38
2017-06-11 01:20:38.829914 EDT | MinReturn                 853.33
2017-06-11 01:20:38.830210 EDT | AverageEsReturn           435.557
2017-06-11 01:20:38.831697 EDT | StdEsReturn               565.05
2017-06-11 01:20:38.832073 EDT | MaxEsReturn              1592.33
2017-06-11 01:20:38.833804 EDT | MinEsReturn                57.04
2017-06-11 01:20:38.834186 EDT | AverageDiscountedReturn   248.45
2017-06-11 01:20:38.835927 EDT | AverageQLoss                2.13253
2017-06-11 01:20:38.836315 EDT | AveragePolicySurr         -30.8524
2017-06-11 01:20:38.836677 EDT | AverageQ                   30.4796
2017-06-11 01:20:38.838390 EDT | AverageAbsQ                30.5021
2017-06-11 01:20:38.838698 EDT | AverageY                   30.481
2017-06-11 01:20:38.840203 EDT | AverageAbsY                30.4935
2017-06-11 01:20:38.840499 EDT | AverageAbsQYDiff            0.558255
2017-06-11 01:20:38.840764 EDT | AverageAction               0.992626
2017-06-11 01:20:38.842237 EDT | PolicyRegParamNorm         87.9729
2017-06-11 01:20:38.842535 EDT | QFunRegParamNorm          113.181
2017-06-11 01:20:38.844004 EDT | -----------------------  -----------
2017-06-11 01:20:38.844468 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #779 | Training started
2017-06-11 01:20:55.409329 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #779 | Training finished
2017-06-11 01:20:55.409825 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #779 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 01:20:55.410168 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #779 | Collecting samples for evaluation
2017-06-11 01:21:09.938522 EDT | -----------------------  -----------
2017-06-11 01:21:09.939786 EDT | Epoch                     779
2017-06-11 01:21:09.940252 EDT | Iteration                 779
2017-06-11 01:21:09.940703 EDT | AverageReturn             659.59
2017-06-11 01:21:09.941147 EDT | StdReturn                 648.133
2017-06-11 01:21:09.941594 EDT | MaxReturn                2908.51
2017-06-11 01:21:09.942058 EDT | MinReturn                 261.577
2017-06-11 01:21:09.942501 EDT | AverageEsReturn           397.905
2017-06-11 01:21:09.942941 EDT | StdEsReturn               207.939
2017-06-11 01:21:09.943382 EDT | MaxEsReturn               752.376
2017-06-11 01:21:09.943827 EDT | MinEsReturn               113.03
2017-06-11 01:21:09.944267 EDT | AverageDiscountedReturn   179.949
2017-06-11 01:21:09.944712 EDT | AverageQLoss                2.01649
2017-06-11 01:21:09.945152 EDT | AveragePolicySurr         -30.8115
2017-06-11 01:21:09.945598 EDT | AverageQ                   30.4624
2017-06-11 01:21:09.946053 EDT | AverageAbsQ                30.4925
2017-06-11 01:21:09.946506 EDT | AverageY                   30.4627
2017-06-11 01:21:09.946946 EDT | AverageAbsY                30.477
2017-06-11 01:21:09.947389 EDT | AverageAbsQYDiff            0.550179
2017-06-11 01:21:09.947828 EDT | AverageAction               0.994331
2017-06-11 01:21:09.948268 EDT | PolicyRegParamNorm         88.0241
2017-06-11 01:21:09.948710 EDT | QFunRegParamNorm          113.229
2017-06-11 01:21:09.949153 EDT | -----------------------  -----------
2017-06-11 01:21:09.949789 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #780 | Training started
2017-06-11 01:21:27.083645 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #780 | Training finished
2017-06-11 01:21:27.084065 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #780 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 01:21:27.084421 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #780 | Collecting samples for evaluation
2017-06-11 01:21:39.804656 EDT | -----------------------  -----------
2017-06-11 01:21:39.805781 EDT | Epoch                     780
2017-06-11 01:21:39.806323 EDT | Iteration                 780
2017-06-11 01:21:39.806772 EDT | AverageReturn            1770.6
2017-06-11 01:21:39.807984 EDT | StdReturn                 868.352
2017-06-11 01:21:39.808454 EDT | MaxReturn                3080.34
2017-06-11 01:21:39.808903 EDT | MinReturn                 316.913
2017-06-11 01:21:39.809346 EDT | AverageEsReturn           433.721
2017-06-11 01:21:39.809808 EDT | StdEsReturn               428.772
2017-06-11 01:21:39.810253 EDT | MaxEsReturn              1222.16
2017-06-11 01:21:39.810697 EDT | MinEsReturn                38.5743
2017-06-11 01:21:39.811233 EDT | AverageDiscountedReturn   233.165
2017-06-11 01:21:39.813317 EDT | AverageQLoss                1.76616
2017-06-11 01:21:39.813937 EDT | AveragePolicySurr         -30.9303
2017-06-11 01:21:39.814651 EDT | AverageQ                   30.5885
2017-06-11 01:21:39.815112 EDT | AverageAbsQ                30.6131
2017-06-11 01:21:39.815561 EDT | AverageY                   30.591
2017-06-11 01:21:39.816118 EDT | AverageAbsY                30.6023
2017-06-11 01:21:39.816566 EDT | AverageAbsQYDiff            0.519979
2017-06-11 01:21:39.817142 EDT | AverageAction               0.992283
2017-06-11 01:21:39.817605 EDT | PolicyRegParamNorm         88.0471
2017-06-11 01:21:39.818058 EDT | QFunRegParamNorm          113.282
2017-06-11 01:21:39.818606 EDT | -----------------------  -----------
2017-06-11 01:21:39.819334 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #781 | Training started
2017-06-11 01:21:57.904746 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #781 | Training finished
2017-06-11 01:21:57.905690 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #781 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 01:21:57.906427 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #781 | Collecting samples for evaluation
2017-06-11 01:22:12.087587 EDT | -----------------------  -----------
2017-06-11 01:22:12.088375 EDT | Epoch                     781
2017-06-11 01:22:12.089554 EDT | Iteration                 781
2017-06-11 01:22:12.089832 EDT | AverageReturn             976.914
2017-06-11 01:22:12.089992 EDT | StdReturn                 741.918
2017-06-11 01:22:12.090220 EDT | MaxReturn                2927.07
2017-06-11 01:22:12.090382 EDT | MinReturn                 308.173
2017-06-11 01:22:12.090537 EDT | AverageEsReturn           686.545
2017-06-11 01:22:12.090689 EDT | StdEsReturn               334.789
2017-06-11 01:22:12.090897 EDT | MaxEsReturn              1129.82
2017-06-11 01:22:12.091149 EDT | MinEsReturn               275.682
2017-06-11 01:22:12.091306 EDT | AverageDiscountedReturn   213.258
2017-06-11 01:22:12.091460 EDT | AverageQLoss                2.28833
2017-06-11 01:22:12.091619 EDT | AveragePolicySurr         -30.8542
2017-06-11 01:22:12.091839 EDT | AverageQ                   30.5187
2017-06-11 01:22:12.092013 EDT | AverageAbsQ                30.5463
2017-06-11 01:22:12.092166 EDT | AverageY                   30.5204
2017-06-11 01:22:12.092317 EDT | AverageAbsY                30.5345
2017-06-11 01:22:12.092552 EDT | AverageAbsQYDiff            0.559187
2017-06-11 01:22:12.092708 EDT | AverageAction               0.993456
2017-06-11 01:22:12.092909 EDT | PolicyRegParamNorm         88.0703
2017-06-11 01:22:12.093065 EDT | QFunRegParamNorm          113.37
2017-06-11 01:22:12.093217 EDT | -----------------------  -----------
2017-06-11 01:22:12.093474 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #782 | Training started
2017-06-11 01:22:29.583207 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #782 | Training finished
2017-06-11 01:22:29.584203 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #782 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 01:22:29.584431 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #782 | Collecting samples for evaluation
2017-06-11 01:22:43.772678 EDT | -----------------------  -----------
2017-06-11 01:22:43.773659 EDT | Epoch                     782
2017-06-11 01:22:43.774029 EDT | Iteration                 782
2017-06-11 01:22:43.774372 EDT | AverageReturn             890.608
2017-06-11 01:22:43.774744 EDT | StdReturn                 677.477
2017-06-11 01:22:43.775123 EDT | MaxReturn                2261.53
2017-06-11 01:22:43.775491 EDT | MinReturn                 194.197
2017-06-11 01:22:43.775856 EDT | AverageEsReturn           536.481
2017-06-11 01:22:43.776189 EDT | StdEsReturn               170.301
2017-06-11 01:22:43.776539 EDT | MaxEsReturn               717.12
2017-06-11 01:22:43.776871 EDT | MinEsReturn               327.974
2017-06-11 01:22:43.777213 EDT | AverageDiscountedReturn   196.324
2017-06-11 01:22:43.777541 EDT | AverageQLoss                2.68627
2017-06-11 01:22:43.777879 EDT | AveragePolicySurr         -30.9024
2017-06-11 01:22:43.778225 EDT | AverageQ                   30.5689
2017-06-11 01:22:43.778585 EDT | AverageAbsQ                30.5887
2017-06-11 01:22:43.778918 EDT | AverageY                   30.5709
2017-06-11 01:22:43.779244 EDT | AverageAbsY                30.582
2017-06-11 01:22:43.779569 EDT | AverageAbsQYDiff            0.572452
2017-06-11 01:22:43.779894 EDT | AverageAction               0.9934
2017-06-11 01:22:43.780216 EDT | PolicyRegParamNorm         88.0819
2017-06-11 01:22:43.780593 EDT | QFunRegParamNorm          113.442
2017-06-11 01:22:43.780947 EDT | -----------------------  -----------
2017-06-11 01:22:43.781455 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #783 | Training started
2017-06-11 01:23:01.654368 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #783 | Training finished
2017-06-11 01:23:01.655169 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #783 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 01:23:01.655381 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #783 | Collecting samples for evaluation
2017-06-11 01:23:17.142163 EDT | -----------------------  -----------
2017-06-11 01:23:17.143282 EDT | Epoch                     783
2017-06-11 01:23:17.143648 EDT | Iteration                 783
2017-06-11 01:23:17.143994 EDT | AverageReturn            1910.45
2017-06-11 01:23:17.144345 EDT | StdReturn                1115.27
2017-06-11 01:23:17.144703 EDT | MaxReturn                3421.85
2017-06-11 01:23:17.145058 EDT | MinReturn                 285.429
2017-06-11 01:23:17.145327 EDT | AverageEsReturn           599.145
2017-06-11 01:23:17.149786 EDT | StdEsReturn               276.754
2017-06-11 01:23:17.150277 EDT | MaxEsReturn               959.776
2017-06-11 01:23:17.150704 EDT | MinEsReturn               240.698
2017-06-11 01:23:17.151150 EDT | AverageDiscountedReturn   244.5
2017-06-11 01:23:17.151596 EDT | AverageQLoss                2.38858
2017-06-11 01:23:17.152046 EDT | AveragePolicySurr         -30.8525
2017-06-11 01:23:17.152698 EDT | AverageQ                   30.5256
2017-06-11 01:23:17.153143 EDT | AverageAbsQ                30.5496
2017-06-11 01:23:17.153583 EDT | AverageY                   30.5253
2017-06-11 01:23:17.154035 EDT | AverageAbsY                30.5346
2017-06-11 01:23:17.154451 EDT | AverageAbsQYDiff            0.556075
2017-06-11 01:23:17.154894 EDT | AverageAction               0.991584
2017-06-11 01:23:17.155337 EDT | PolicyRegParamNorm         88.1229
2017-06-11 01:23:17.155777 EDT | QFunRegParamNorm          113.504
2017-06-11 01:23:17.156130 EDT | -----------------------  -----------
2017-06-11 01:23:17.156672 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #784 | Training started
2017-06-11 01:23:36.290609 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #784 | Training finished
2017-06-11 01:23:36.291438 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #784 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 01:23:36.291657 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #784 | Collecting samples for evaluation
2017-06-11 01:23:51.091139 EDT | -----------------------  -----------
2017-06-11 01:23:51.093212 EDT | Epoch                     784
2017-06-11 01:23:51.093601 EDT | Iteration                 784
2017-06-11 01:23:51.094416 EDT | AverageReturn            1248.45
2017-06-11 01:23:51.095391 EDT | StdReturn                 536.773
2017-06-11 01:23:51.095566 EDT | MaxReturn                3048.75
2017-06-11 01:23:51.095802 EDT | MinReturn                 579.081
2017-06-11 01:23:51.095970 EDT | AverageEsReturn           422.667
2017-06-11 01:23:51.096135 EDT | StdEsReturn               197.477
2017-06-11 01:23:51.096355 EDT | MaxEsReturn               748.358
2017-06-11 01:23:51.096520 EDT | MinEsReturn                66.6693
2017-06-11 01:23:51.096691 EDT | AverageDiscountedReturn   241.848
2017-06-11 01:23:51.096853 EDT | AverageQLoss                2.13444
2017-06-11 01:23:51.097153 EDT | AveragePolicySurr         -30.8792
2017-06-11 01:23:51.097320 EDT | AverageQ                   30.5264
2017-06-11 01:23:51.097702 EDT | AverageAbsQ                30.549
2017-06-11 01:23:51.100600 EDT | AverageY                   30.5281
2017-06-11 01:23:51.101447 EDT | AverageAbsY                30.5363
2017-06-11 01:23:51.102177 EDT | AverageAbsQYDiff            0.549319
2017-06-11 01:23:51.102712 EDT | AverageAction               0.991303
2017-06-11 01:23:51.103167 EDT | PolicyRegParamNorm         88.1669
2017-06-11 01:23:51.103595 EDT | QFunRegParamNorm          113.574
2017-06-11 01:23:51.104238 EDT | -----------------------  -----------
2017-06-11 01:23:51.104877 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #785 | Training started
2017-06-11 01:24:10.020535 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #785 | Training finished
2017-06-11 01:24:10.021462 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #785 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 01:24:10.021689 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #785 | Collecting samples for evaluation
2017-06-11 01:24:25.704813 EDT | -----------------------  -----------
2017-06-11 01:24:25.705268 EDT | Epoch                     785
2017-06-11 01:24:25.705578 EDT | Iteration                 785
2017-06-11 01:24:25.705908 EDT | AverageReturn            1119.74
2017-06-11 01:24:25.706193 EDT | StdReturn                 494.132
2017-06-11 01:24:25.706475 EDT | MaxReturn                3177.61
2017-06-11 01:24:25.706810 EDT | MinReturn                 797.359
2017-06-11 01:24:25.707128 EDT | AverageEsReturn           356.4
2017-06-11 01:24:25.707447 EDT | StdEsReturn               231.405
2017-06-11 01:24:25.707757 EDT | MaxEsReturn               728.04
2017-06-11 01:24:25.708053 EDT | MinEsReturn                 4.6933
2017-06-11 01:24:25.708312 EDT | AverageDiscountedReturn   238.844
2017-06-11 01:24:25.708593 EDT | AverageQLoss                2.12039
2017-06-11 01:24:25.708909 EDT | AveragePolicySurr         -30.8129
2017-06-11 01:24:25.709196 EDT | AverageQ                   30.4932
2017-06-11 01:24:25.709473 EDT | AverageAbsQ                30.5193
2017-06-11 01:24:25.709823 EDT | AverageY                   30.4929
2017-06-11 01:24:25.710143 EDT | AverageAbsY                30.5065
2017-06-11 01:24:25.710468 EDT | AverageAbsQYDiff            0.543561
2017-06-11 01:24:25.710776 EDT | AverageAction               0.993349
2017-06-11 01:24:25.711069 EDT | PolicyRegParamNorm         88.2577
2017-06-11 01:24:25.711375 EDT | QFunRegParamNorm          113.635
2017-06-11 01:24:25.711705 EDT | -----------------------  -----------
2017-06-11 01:24:25.712189 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #786 | Training started
2017-06-11 01:24:45.518202 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #786 | Training finished
2017-06-11 01:24:45.519111 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #786 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 01:24:45.519872 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #786 | Collecting samples for evaluation
2017-06-11 01:24:59.889262 EDT | -----------------------  -----------
2017-06-11 01:24:59.890091 EDT | Epoch                     786
2017-06-11 01:24:59.890374 EDT | Iteration                 786
2017-06-11 01:24:59.890626 EDT | AverageReturn            1985.78
2017-06-11 01:24:59.890874 EDT | StdReturn                 614.239
2017-06-11 01:24:59.891127 EDT | MaxReturn                2704.75
2017-06-11 01:24:59.891377 EDT | MinReturn                1154.32
2017-06-11 01:24:59.891621 EDT | AverageEsReturn           381.733
2017-06-11 01:24:59.891863 EDT | StdEsReturn               251.103
2017-06-11 01:24:59.892103 EDT | MaxEsReturn               832.22
2017-06-11 01:24:59.892343 EDT | MinEsReturn               106.765
2017-06-11 01:24:59.892581 EDT | AverageDiscountedReturn   220.415
2017-06-11 01:24:59.892820 EDT | AverageQLoss                2.26195
2017-06-11 01:24:59.893059 EDT | AveragePolicySurr         -30.8274
2017-06-11 01:24:59.893298 EDT | AverageQ                   30.49
2017-06-11 01:24:59.893537 EDT | AverageAbsQ                30.5156
2017-06-11 01:24:59.893798 EDT | AverageY                   30.4903
2017-06-11 01:24:59.894039 EDT | AverageAbsY                30.5005
2017-06-11 01:24:59.894280 EDT | AverageAbsQYDiff            0.546241
2017-06-11 01:24:59.894520 EDT | AverageAction               0.990532
2017-06-11 01:24:59.894760 EDT | PolicyRegParamNorm         88.3008
2017-06-11 01:24:59.895000 EDT | QFunRegParamNorm          113.643
2017-06-11 01:24:59.895240 EDT | -----------------------  -----------
2017-06-11 01:24:59.895626 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #787 | Training started
2017-06-11 01:25:16.487259 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #787 | Training finished
2017-06-11 01:25:16.489034 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #787 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 01:25:16.489265 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #787 | Collecting samples for evaluation
2017-06-11 01:25:33.361586 EDT | -----------------------  -----------
2017-06-11 01:25:33.365801 EDT | Epoch                     787
2017-06-11 01:25:33.366189 EDT | Iteration                 787
2017-06-11 01:25:33.366531 EDT | AverageReturn            1689.42
2017-06-11 01:25:33.366873 EDT | StdReturn                 836.099
2017-06-11 01:25:33.367205 EDT | MaxReturn                3403.52
2017-06-11 01:25:33.367533 EDT | MinReturn                 806.252
2017-06-11 01:25:33.367859 EDT | AverageEsReturn           341.115
2017-06-11 01:25:33.368184 EDT | StdEsReturn               211.682
2017-06-11 01:25:33.368509 EDT | MaxEsReturn               752.348
2017-06-11 01:25:33.368852 EDT | MinEsReturn               104.087
2017-06-11 01:25:33.369176 EDT | AverageDiscountedReturn   254.645
2017-06-11 01:25:33.369498 EDT | AverageQLoss                2.02197
2017-06-11 01:25:33.369833 EDT | AveragePolicySurr         -30.8656
2017-06-11 01:25:33.370232 EDT | AverageQ                   30.5201
2017-06-11 01:25:33.370565 EDT | AverageAbsQ                30.545
2017-06-11 01:25:33.370888 EDT | AverageY                   30.521
2017-06-11 01:25:33.371210 EDT | AverageAbsY                30.5333
2017-06-11 01:25:33.371531 EDT | AverageAbsQYDiff            0.533234
2017-06-11 01:25:33.371853 EDT | AverageAction               0.989877
2017-06-11 01:25:33.372175 EDT | PolicyRegParamNorm         88.3297
2017-06-11 01:25:33.372497 EDT | QFunRegParamNorm          113.735
2017-06-11 01:25:33.372817 EDT | -----------------------  -----------
2017-06-11 01:25:33.373292 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #788 | Training started
2017-06-11 01:25:51.404668 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #788 | Training finished
2017-06-11 01:25:51.404963 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #788 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 01:25:51.405194 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #788 | Collecting samples for evaluation
2017-06-11 01:26:06.223224 EDT | -----------------------  -----------
2017-06-11 01:26:06.226299 EDT | Epoch                     788
2017-06-11 01:26:06.226605 EDT | Iteration                 788
2017-06-11 01:26:06.226873 EDT | AverageReturn             677.798
2017-06-11 01:26:06.227133 EDT | StdReturn                 716.383
2017-06-11 01:26:06.227389 EDT | MaxReturn                3047.86
2017-06-11 01:26:06.227642 EDT | MinReturn                 250.598
2017-06-11 01:26:06.227894 EDT | AverageEsReturn           297.66
2017-06-11 01:26:06.228144 EDT | StdEsReturn               289.261
2017-06-11 01:26:06.228476 EDT | MaxEsReturn               897.685
2017-06-11 01:26:06.228802 EDT | MinEsReturn                13.8873
2017-06-11 01:26:06.229056 EDT | AverageDiscountedReturn   175.794
2017-06-11 01:26:06.229298 EDT | AverageQLoss                2.43665
2017-06-11 01:26:06.229539 EDT | AveragePolicySurr         -30.7503
2017-06-11 01:26:06.229870 EDT | AverageQ                   30.4086
2017-06-11 01:26:06.230193 EDT | AverageAbsQ                30.4363
2017-06-11 01:26:06.230515 EDT | AverageY                   30.4085
2017-06-11 01:26:06.230835 EDT | AverageAbsY                30.4239
2017-06-11 01:26:06.231182 EDT | AverageAbsQYDiff            0.558049
2017-06-11 01:26:06.231507 EDT | AverageAction               0.991165
2017-06-11 01:26:06.231830 EDT | PolicyRegParamNorm         88.3844
2017-06-11 01:26:06.232152 EDT | QFunRegParamNorm          113.794
2017-06-11 01:26:06.232471 EDT | -----------------------  -----------
2017-06-11 01:26:06.232955 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #789 | Training started
2017-06-11 01:26:24.407065 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #789 | Training finished
2017-06-11 01:26:24.407841 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #789 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 01:26:24.408036 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #789 | Collecting samples for evaluation
2017-06-11 01:26:40.398719 EDT | -----------------------  -----------
2017-06-11 01:26:40.401444 EDT | Epoch                     789
2017-06-11 01:26:40.401822 EDT | Iteration                 789
2017-06-11 01:26:40.402140 EDT | AverageReturn            1695.42
2017-06-11 01:26:40.402425 EDT | StdReturn                 601.702
2017-06-11 01:26:40.402708 EDT | MaxReturn                3057.27
2017-06-11 01:26:40.402987 EDT | MinReturn                1044.14
2017-06-11 01:26:40.403396 EDT | AverageEsReturn           240.14
2017-06-11 01:26:40.403763 EDT | StdEsReturn               173.333
2017-06-11 01:26:40.404125 EDT | MaxEsReturn               667.672
2017-06-11 01:26:40.404493 EDT | MinEsReturn                17.7222
2017-06-11 01:26:40.404882 EDT | AverageDiscountedReturn   242.565
2017-06-11 01:26:40.405239 EDT | AverageQLoss                2.40143
2017-06-11 01:26:40.405593 EDT | AveragePolicySurr         -30.8771
2017-06-11 01:26:40.405991 EDT | AverageQ                   30.5254
2017-06-11 01:26:40.406360 EDT | AverageAbsQ                30.5483
2017-06-11 01:26:40.406715 EDT | AverageY                   30.528
2017-06-11 01:26:40.407072 EDT | AverageAbsY                30.5377
2017-06-11 01:26:40.407460 EDT | AverageAbsQYDiff            0.556212
2017-06-11 01:26:40.407817 EDT | AverageAction               0.990835
2017-06-11 01:26:40.408169 EDT | PolicyRegParamNorm         88.4188
2017-06-11 01:26:40.408529 EDT | QFunRegParamNorm          113.855
2017-06-11 01:26:40.408914 EDT | -----------------------  -----------
2017-06-11 01:26:40.409428 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #790 | Training started
2017-06-11 01:26:59.513578 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #790 | Training finished
2017-06-11 01:26:59.514651 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #790 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 01:26:59.514913 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #790 | Collecting samples for evaluation
2017-06-11 01:27:14.183554 EDT | -----------------------  -----------
2017-06-11 01:27:14.184535 EDT | Epoch                     790
2017-06-11 01:27:14.184873 EDT | Iteration                 790
2017-06-11 01:27:14.185219 EDT | AverageReturn            1402.41
2017-06-11 01:27:14.185644 EDT | StdReturn                 327.972
2017-06-11 01:27:14.185979 EDT | MaxReturn                2422.46
2017-06-11 01:27:14.186324 EDT | MinReturn                 917.963
2017-06-11 01:27:14.186749 EDT | AverageEsReturn           327.36
2017-06-11 01:27:14.187068 EDT | StdEsReturn               354.629
2017-06-11 01:27:14.187414 EDT | MaxEsReturn              1014.97
2017-06-11 01:27:14.187977 EDT | MinEsReturn                28.2463
2017-06-11 01:27:14.188324 EDT | AverageDiscountedReturn   238.908
2017-06-11 01:27:14.188720 EDT | AverageQLoss                2.93636
2017-06-11 01:27:14.189061 EDT | AveragePolicySurr         -30.7831
2017-06-11 01:27:14.189407 EDT | AverageQ                   30.4508
2017-06-11 01:27:14.189946 EDT | AverageAbsQ                30.4784
2017-06-11 01:27:14.190300 EDT | AverageY                   30.4512
2017-06-11 01:27:14.190749 EDT | AverageAbsY                30.465
2017-06-11 01:27:14.191097 EDT | AverageAbsQYDiff            0.598034
2017-06-11 01:27:14.191501 EDT | AverageAction               0.990268
2017-06-11 01:27:14.191834 EDT | PolicyRegParamNorm         88.4899
2017-06-11 01:27:14.192189 EDT | QFunRegParamNorm          113.884
2017-06-11 01:27:14.192591 EDT | -----------------------  -----------
2017-06-11 01:27:14.193094 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #791 | Training started
2017-06-11 01:27:31.335110 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #791 | Training finished
2017-06-11 01:27:31.336006 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #791 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 01:27:31.336566 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #791 | Collecting samples for evaluation
2017-06-11 01:27:46.033790 EDT | -----------------------  -----------
2017-06-11 01:27:46.036775 EDT | Epoch                     791
2017-06-11 01:27:46.037210 EDT | Iteration                 791
2017-06-11 01:27:46.037606 EDT | AverageReturn            1351.38
2017-06-11 01:27:46.038020 EDT | StdReturn                 452.265
2017-06-11 01:27:46.038450 EDT | MaxReturn                2415.35
2017-06-11 01:27:46.038838 EDT | MinReturn                 879.907
2017-06-11 01:27:46.039771 EDT | AverageEsReturn           399.566
2017-06-11 01:27:46.040137 EDT | StdEsReturn               220.35
2017-06-11 01:27:46.040333 EDT | MaxEsReturn               774.143
2017-06-11 01:27:46.040517 EDT | MinEsReturn               108.87
2017-06-11 01:27:46.040699 EDT | AverageDiscountedReturn   243.41
2017-06-11 01:27:46.040892 EDT | AverageQLoss                2.49779
2017-06-11 01:27:46.041073 EDT | AveragePolicySurr         -30.7636
2017-06-11 01:27:46.043778 EDT | AverageQ                   30.4306
2017-06-11 01:27:46.044145 EDT | AverageAbsQ                30.4523
2017-06-11 01:27:46.044419 EDT | AverageY                   30.4295
2017-06-11 01:27:46.044607 EDT | AverageAbsY                30.444
2017-06-11 01:27:46.044790 EDT | AverageAbsQYDiff            0.562669
2017-06-11 01:27:46.044971 EDT | AverageAction               0.990725
2017-06-11 01:27:46.045161 EDT | PolicyRegParamNorm         88.5467
2017-06-11 01:27:46.045343 EDT | QFunRegParamNorm          113.925
2017-06-11 01:27:46.045522 EDT | -----------------------  -----------
2017-06-11 01:27:46.045828 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #792 | Training started
2017-06-11 01:28:04.201414 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #792 | Training finished
2017-06-11 01:28:04.224202 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #792 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 01:28:04.224576 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #792 | Collecting samples for evaluation
2017-06-11 01:28:18.693072 EDT | -----------------------  -----------
2017-06-11 01:28:18.700955 EDT | Epoch                     792
2017-06-11 01:28:18.701261 EDT | Iteration                 792
2017-06-11 01:28:18.701517 EDT | AverageReturn            1904.78
2017-06-11 01:28:18.701779 EDT | StdReturn                 551.699
2017-06-11 01:28:18.702027 EDT | MaxReturn                2922.76
2017-06-11 01:28:18.702274 EDT | MinReturn                1106.31
2017-06-11 01:28:18.702518 EDT | AverageEsReturn           486.532
2017-06-11 01:28:18.702761 EDT | StdEsReturn               260.579
2017-06-11 01:28:18.703003 EDT | MaxEsReturn               714.959
2017-06-11 01:28:18.703244 EDT | MinEsReturn                51.0555
2017-06-11 01:28:18.703485 EDT | AverageDiscountedReturn   235.744
2017-06-11 01:28:18.703725 EDT | AverageQLoss                2.46435
2017-06-11 01:28:18.703966 EDT | AveragePolicySurr         -30.7809
2017-06-11 01:28:18.704205 EDT | AverageQ                   30.4517
2017-06-11 01:28:18.704446 EDT | AverageAbsQ                30.4745
2017-06-11 01:28:18.704686 EDT | AverageY                   30.4543
2017-06-11 01:28:18.704928 EDT | AverageAbsY                30.4674
2017-06-11 01:28:18.705168 EDT | AverageAbsQYDiff            0.573677
2017-06-11 01:28:18.705409 EDT | AverageAction               0.991738
2017-06-11 01:28:18.705650 EDT | PolicyRegParamNorm         88.6423
2017-06-11 01:28:18.705903 EDT | QFunRegParamNorm          114.024
2017-06-11 01:28:18.706144 EDT | -----------------------  -----------
2017-06-11 01:28:18.706520 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #793 | Training started
2017-06-11 01:28:36.150848 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #793 | Training finished
2017-06-11 01:28:36.162469 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #793 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 01:28:36.162911 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #793 | Collecting samples for evaluation
2017-06-11 01:28:49.939491 EDT | -----------------------  -----------
2017-06-11 01:28:49.940006 EDT | Epoch                     793
2017-06-11 01:28:49.940358 EDT | Iteration                 793
2017-06-11 01:28:49.940704 EDT | AverageReturn            1522.13
2017-06-11 01:28:49.941048 EDT | StdReturn                 665.989
2017-06-11 01:28:49.941391 EDT | MaxReturn                2918.99
2017-06-11 01:28:49.941749 EDT | MinReturn                 801.64
2017-06-11 01:28:49.942097 EDT | AverageEsReturn           466.47
2017-06-11 01:28:49.942445 EDT | StdEsReturn               333.669
2017-06-11 01:28:49.942786 EDT | MaxEsReturn               950.951
2017-06-11 01:28:49.943130 EDT | MinEsReturn                13.2405
2017-06-11 01:28:49.943475 EDT | AverageDiscountedReturn   230.926
2017-06-11 01:28:49.943819 EDT | AverageQLoss                2.19276
2017-06-11 01:28:49.944162 EDT | AveragePolicySurr         -30.7599
2017-06-11 01:28:49.944502 EDT | AverageQ                   30.4204
2017-06-11 01:28:49.944838 EDT | AverageAbsQ                30.443
2017-06-11 01:28:49.945182 EDT | AverageY                   30.4212
2017-06-11 01:28:49.945524 EDT | AverageAbsY                30.4333
2017-06-11 01:28:49.945876 EDT | AverageAbsQYDiff            0.546662
2017-06-11 01:28:49.946214 EDT | AverageAction               0.994386
2017-06-11 01:28:49.946556 EDT | PolicyRegParamNorm         88.677
2017-06-11 01:28:49.946909 EDT | QFunRegParamNorm          114.06
2017-06-11 01:28:49.947254 EDT | -----------------------  -----------
2017-06-11 01:28:49.947772 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #794 | Training started
2017-06-11 01:29:06.295608 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #794 | Training finished
2017-06-11 01:29:06.296426 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #794 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 01:29:06.296624 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #794 | Collecting samples for evaluation
2017-06-11 01:29:19.945558 EDT | -----------------------  -----------
2017-06-11 01:29:19.946075 EDT | Epoch                     794
2017-06-11 01:29:19.946438 EDT | Iteration                 794
2017-06-11 01:29:19.946667 EDT | AverageReturn            1196.71
2017-06-11 01:29:19.947118 EDT | StdReturn                 489.376
2017-06-11 01:29:19.947558 EDT | MaxReturn                3000.72
2017-06-11 01:29:19.947977 EDT | MinReturn                 809.629
2017-06-11 01:29:19.948405 EDT | AverageEsReturn           447.072
2017-06-11 01:29:19.948806 EDT | StdEsReturn               259.039
2017-06-11 01:29:19.949228 EDT | MaxEsReturn               823.294
2017-06-11 01:29:19.949606 EDT | MinEsReturn               122.596
2017-06-11 01:29:19.950034 EDT | AverageDiscountedReturn   230.699
2017-06-11 01:29:19.950468 EDT | AverageQLoss                2.10427
2017-06-11 01:29:19.950889 EDT | AveragePolicySurr         -30.8521
2017-06-11 01:29:19.951249 EDT | AverageQ                   30.5159
2017-06-11 01:29:19.951678 EDT | AverageAbsQ                30.5406
2017-06-11 01:29:19.952067 EDT | AverageY                   30.5188
2017-06-11 01:29:19.952558 EDT | AverageAbsY                30.5315
2017-06-11 01:29:19.953192 EDT | AverageAbsQYDiff            0.545555
2017-06-11 01:29:19.953592 EDT | AverageAction               0.995105
2017-06-11 01:29:19.954092 EDT | PolicyRegParamNorm         88.6992
2017-06-11 01:29:19.954682 EDT | QFunRegParamNorm          114.116
2017-06-11 01:29:19.955110 EDT | -----------------------  -----------
2017-06-11 01:29:19.955751 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #795 | Training started
2017-06-11 01:29:35.613832 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #795 | Training finished
2017-06-11 01:29:35.614927 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #795 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 01:29:35.615168 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #795 | Collecting samples for evaluation
2017-06-11 01:29:50.432366 EDT | -----------------------  -----------
2017-06-11 01:29:50.433499 EDT | Epoch                     795
2017-06-11 01:29:50.435615 EDT | Iteration                 795
2017-06-11 01:29:50.435809 EDT | AverageReturn            1323.23
2017-06-11 01:29:50.435971 EDT | StdReturn                 512.825
2017-06-11 01:29:50.436173 EDT | MaxReturn                3067.6
2017-06-11 01:29:50.436337 EDT | MinReturn                 884.379
2017-06-11 01:29:50.436522 EDT | AverageEsReturn           574.915
2017-06-11 01:29:50.436725 EDT | StdEsReturn               242.964
2017-06-11 01:29:50.436880 EDT | MaxEsReturn               875.458
2017-06-11 01:29:50.437033 EDT | MinEsReturn               123.655
2017-06-11 01:29:50.437185 EDT | AverageDiscountedReturn   230.375
2017-06-11 01:29:50.437337 EDT | AverageQLoss                2.21123
2017-06-11 01:29:50.437488 EDT | AveragePolicySurr         -30.8688
2017-06-11 01:29:50.437644 EDT | AverageQ                   30.5133
2017-06-11 01:29:50.437864 EDT | AverageAbsQ                30.5354
2017-06-11 01:29:50.438027 EDT | AverageY                   30.5128
2017-06-11 01:29:50.438192 EDT | AverageAbsY                30.5217
2017-06-11 01:29:50.438373 EDT | AverageAbsQYDiff            0.554674
2017-06-11 01:29:50.438534 EDT | AverageAction               0.994626
2017-06-11 01:29:50.438692 EDT | PolicyRegParamNorm         88.7801
2017-06-11 01:29:50.438848 EDT | QFunRegParamNorm          114.162
2017-06-11 01:29:50.439005 EDT | -----------------------  -----------
2017-06-11 01:29:50.439285 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #796 | Training started
2017-06-11 01:30:06.768122 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #796 | Training finished
2017-06-11 01:30:06.769571 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #796 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 01:30:06.769808 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #796 | Collecting samples for evaluation
2017-06-11 01:30:21.244960 EDT | -----------------------  -----------
2017-06-11 01:30:21.245977 EDT | Epoch                     796
2017-06-11 01:30:21.246399 EDT | Iteration                 796
2017-06-11 01:30:21.246796 EDT | AverageReturn            1289.65
2017-06-11 01:30:21.247191 EDT | StdReturn                 372.505
2017-06-11 01:30:21.247580 EDT | MaxReturn                2182.94
2017-06-11 01:30:21.247969 EDT | MinReturn                 848.013
2017-06-11 01:30:21.248338 EDT | AverageEsReturn           367.379
2017-06-11 01:30:21.248730 EDT | StdEsReturn               318.506
2017-06-11 01:30:21.249117 EDT | MaxEsReturn               961.323
2017-06-11 01:30:21.249508 EDT | MinEsReturn                48.0203
2017-06-11 01:30:21.249906 EDT | AverageDiscountedReturn   227.642
2017-06-11 01:30:21.250261 EDT | AverageQLoss                2.34413
2017-06-11 01:30:21.250635 EDT | AveragePolicySurr         -30.8526
2017-06-11 01:30:21.251026 EDT | AverageQ                   30.5288
2017-06-11 01:30:21.251414 EDT | AverageAbsQ                30.546
2017-06-11 01:30:21.251808 EDT | AverageY                   30.5299
2017-06-11 01:30:21.252195 EDT | AverageAbsY                30.5355
2017-06-11 01:30:21.252581 EDT | AverageAbsQYDiff            0.561143
2017-06-11 01:30:21.252971 EDT | AverageAction               0.993445
2017-06-11 01:30:21.253365 EDT | PolicyRegParamNorm         88.8648
2017-06-11 01:30:21.253764 EDT | QFunRegParamNorm          114.211
2017-06-11 01:30:21.254150 EDT | -----------------------  -----------
2017-06-11 01:30:21.254700 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #797 | Training started
2017-06-11 01:30:38.867327 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #797 | Training finished
2017-06-11 01:30:38.868364 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #797 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 01:30:38.868913 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #797 | Collecting samples for evaluation
2017-06-11 01:30:52.240519 EDT | -----------------------  -----------
2017-06-11 01:30:52.240776 EDT | Epoch                     797
2017-06-11 01:30:52.240943 EDT | Iteration                 797
2017-06-11 01:30:52.241100 EDT | AverageReturn            1588.77
2017-06-11 01:30:52.241255 EDT | StdReturn                 782.426
2017-06-11 01:30:52.241457 EDT | MaxReturn                3512.93
2017-06-11 01:30:52.241683 EDT | MinReturn                 645.397
2017-06-11 01:30:52.241978 EDT | AverageEsReturn           256.665
2017-06-11 01:30:52.242241 EDT | StdEsReturn               256.4
2017-06-11 01:30:52.242516 EDT | MaxEsReturn               709.671
2017-06-11 01:30:52.242804 EDT | MinEsReturn                23.4326
2017-06-11 01:30:52.243081 EDT | AverageDiscountedReturn   220.359
2017-06-11 01:30:52.243355 EDT | AverageQLoss                2.03905
2017-06-11 01:30:52.243608 EDT | AveragePolicySurr         -30.8915
2017-06-11 01:30:52.243862 EDT | AverageQ                   30.5387
2017-06-11 01:30:52.244147 EDT | AverageAbsQ                30.5613
2017-06-11 01:30:52.244453 EDT | AverageY                   30.5394
2017-06-11 01:30:52.244713 EDT | AverageAbsY                30.5465
2017-06-11 01:30:52.244965 EDT | AverageAbsQYDiff            0.549658
2017-06-11 01:30:52.245200 EDT | AverageAction               0.992276
2017-06-11 01:30:52.245480 EDT | PolicyRegParamNorm         88.9736
2017-06-11 01:30:52.245746 EDT | QFunRegParamNorm          114.256
2017-06-11 01:30:52.246003 EDT | -----------------------  -----------
2017-06-11 01:30:52.246418 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #798 | Training started
2017-06-11 01:31:10.149510 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #798 | Training finished
2017-06-11 01:31:10.150559 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #798 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 01:31:10.150981 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #798 | Collecting samples for evaluation
2017-06-11 01:31:24.121703 EDT | -----------------------  ----------
2017-06-11 01:31:24.122066 EDT | Epoch                    798
2017-06-11 01:31:24.122339 EDT | Iteration                798
2017-06-11 01:31:24.122604 EDT | AverageReturn            713.384
2017-06-11 01:31:24.122865 EDT | StdReturn                 97.8644
2017-06-11 01:31:24.123127 EDT | MaxReturn                950.966
2017-06-11 01:31:24.123384 EDT | MinReturn                603.5
2017-06-11 01:31:24.123641 EDT | AverageEsReturn          505.799
2017-06-11 01:31:24.123897 EDT | StdEsReturn              178.685
2017-06-11 01:31:24.124152 EDT | MaxEsReturn              755.625
2017-06-11 01:31:24.124406 EDT | MinEsReturn              304.288
2017-06-11 01:31:24.124660 EDT | AverageDiscountedReturn  221.516
2017-06-11 01:31:24.124912 EDT | AverageQLoss               2.38209
2017-06-11 01:31:24.125165 EDT | AveragePolicySurr        -30.8881
2017-06-11 01:31:24.125418 EDT | AverageQ                  30.5441
2017-06-11 01:31:24.125669 EDT | AverageAbsQ               30.5615
2017-06-11 01:31:24.132830 EDT | AverageY                  30.5461
2017-06-11 01:31:24.133084 EDT | AverageAbsY               30.554
2017-06-11 01:31:24.133336 EDT | AverageAbsQYDiff           0.546341
2017-06-11 01:31:24.133587 EDT | AverageAction              0.9944
2017-06-11 01:31:24.133849 EDT | PolicyRegParamNorm        88.9791
2017-06-11 01:31:24.134100 EDT | QFunRegParamNorm         114.337
2017-06-11 01:31:24.134350 EDT | -----------------------  ----------
2017-06-11 01:31:24.134747 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #799 | Training started
2017-06-11 01:31:40.016474 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #799 | Training finished
2017-06-11 01:31:40.017457 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #799 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 01:31:40.017655 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #799 | Collecting samples for evaluation
2017-06-11 01:31:54.681005 EDT | -----------------------  -----------
2017-06-11 01:31:54.684229 EDT | Epoch                     799
2017-06-11 01:31:54.685358 EDT | Iteration                 799
2017-06-11 01:31:54.685879 EDT | AverageReturn            1433.43
2017-06-11 01:31:54.686248 EDT | StdReturn                 460.138
2017-06-11 01:31:54.686598 EDT | MaxReturn                3172.67
2017-06-11 01:31:54.687108 EDT | MinReturn                 946.071
2017-06-11 01:31:54.687511 EDT | AverageEsReturn           676.454
2017-06-11 01:31:54.687879 EDT | StdEsReturn               160.642
2017-06-11 01:31:54.688288 EDT | MaxEsReturn               867.905
2017-06-11 01:31:54.688715 EDT | MinEsReturn               447.649
2017-06-11 01:31:54.689672 EDT | AverageDiscountedReturn   230.856
2017-06-11 01:31:54.690055 EDT | AverageQLoss                2.03081
2017-06-11 01:31:54.690437 EDT | AveragePolicySurr         -30.8591
2017-06-11 01:31:54.690850 EDT | AverageQ                   30.5304
2017-06-11 01:31:54.694285 EDT | AverageAbsQ                30.5526
2017-06-11 01:31:54.694655 EDT | AverageY                   30.5298
2017-06-11 01:31:54.696158 EDT | AverageAbsY                30.5377
2017-06-11 01:31:54.696893 EDT | AverageAbsQYDiff            0.534045
2017-06-11 01:31:54.697246 EDT | AverageAction               0.992376
2017-06-11 01:31:54.697680 EDT | PolicyRegParamNorm         89.0373
2017-06-11 01:31:54.698117 EDT | QFunRegParamNorm          114.34
2017-06-11 01:31:54.698531 EDT | -----------------------  -----------
2017-06-11 01:31:54.699062 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #800 | Training started
2017-06-11 01:32:09.281913 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #800 | Training finished
2017-06-11 01:32:09.282957 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #800 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 01:32:09.283375 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #800 | Collecting samples for evaluation
2017-06-11 01:32:22.959783 EDT | -----------------------  -----------
2017-06-11 01:32:22.970070 EDT | Epoch                     800
2017-06-11 01:32:22.974086 EDT | Iteration                 800
2017-06-11 01:32:22.977000 EDT | AverageReturn            2116.66
2017-06-11 01:32:22.979565 EDT | StdReturn                 591.665
2017-06-11 01:32:22.982024 EDT | MaxReturn                2915.71
2017-06-11 01:32:22.983676 EDT | MinReturn                1222.09
2017-06-11 01:32:22.985255 EDT | AverageEsReturn           395.73
2017-06-11 01:32:22.986816 EDT | StdEsReturn               347.115
2017-06-11 01:32:22.988448 EDT | MaxEsReturn               951.548
2017-06-11 01:32:22.990007 EDT | MinEsReturn                61.7815
2017-06-11 01:32:22.991591 EDT | AverageDiscountedReturn   233.315
2017-06-11 01:32:22.993192 EDT | AverageQLoss                2.46134
2017-06-11 01:32:22.994789 EDT | AveragePolicySurr         -30.7782
2017-06-11 01:32:22.996392 EDT | AverageQ                   30.4364
2017-06-11 01:32:22.997975 EDT | AverageAbsQ                30.4565
2017-06-11 01:32:22.999573 EDT | AverageY                   30.4379
2017-06-11 01:32:23.001177 EDT | AverageAbsY                30.4449
2017-06-11 01:32:23.002724 EDT | AverageAbsQYDiff            0.560853
2017-06-11 01:32:23.004292 EDT | AverageAction               0.992048
2017-06-11 01:32:23.005836 EDT | PolicyRegParamNorm         89.0632
2017-06-11 01:32:23.007415 EDT | QFunRegParamNorm          114.378
2017-06-11 01:32:23.008974 EDT | -----------------------  -----------
2017-06-11 01:32:23.010740 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #801 | Training started
2017-06-11 01:32:40.894173 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #801 | Training finished
2017-06-11 01:32:40.896779 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #801 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 01:32:40.897190 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #801 | Collecting samples for evaluation
2017-06-11 01:32:55.299116 EDT | -----------------------  -----------
2017-06-11 01:32:55.306588 EDT | Epoch                     801
2017-06-11 01:32:55.306929 EDT | Iteration                 801
2017-06-11 01:32:55.307179 EDT | AverageReturn            2743.24
2017-06-11 01:32:55.307457 EDT | StdReturn                 753.594
2017-06-11 01:32:55.307719 EDT | MaxReturn                3334.3
2017-06-11 01:32:55.307917 EDT | MinReturn                1244.19
2017-06-11 01:32:55.308072 EDT | AverageEsReturn           434.137
2017-06-11 01:32:55.308226 EDT | StdEsReturn               228.386
2017-06-11 01:32:55.308437 EDT | MaxEsReturn               908.041
2017-06-11 01:32:55.308616 EDT | MinEsReturn               229.428
2017-06-11 01:32:55.308861 EDT | AverageDiscountedReturn   261.477
2017-06-11 01:32:55.309134 EDT | AverageQLoss                2.06966
2017-06-11 01:32:55.309379 EDT | AveragePolicySurr         -30.9105
2017-06-11 01:32:55.309595 EDT | AverageQ                   30.5769
2017-06-11 01:32:55.309841 EDT | AverageAbsQ                30.5967
2017-06-11 01:32:55.309993 EDT | AverageY                   30.5773
2017-06-11 01:32:55.310145 EDT | AverageAbsY                30.5837
2017-06-11 01:32:55.310295 EDT | AverageAbsQYDiff            0.539019
2017-06-11 01:32:55.310444 EDT | AverageAction               0.991564
2017-06-11 01:32:55.310594 EDT | PolicyRegParamNorm         89.0983
2017-06-11 01:32:55.310754 EDT | QFunRegParamNorm          114.46
2017-06-11 01:32:55.310905 EDT | -----------------------  -----------
2017-06-11 01:32:55.311177 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #802 | Training started
2017-06-11 01:33:12.952214 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #802 | Training finished
2017-06-11 01:33:12.954414 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #802 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 01:33:12.955153 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #802 | Collecting samples for evaluation
2017-06-11 01:33:26.235799 EDT | -----------------------  -----------
2017-06-11 01:33:26.236759 EDT | Epoch                     802
2017-06-11 01:33:26.237113 EDT | Iteration                 802
2017-06-11 01:33:26.237564 EDT | AverageReturn            1409.74
2017-06-11 01:33:26.237919 EDT | StdReturn                 654.672
2017-06-11 01:33:26.238251 EDT | MaxReturn                2546.14
2017-06-11 01:33:26.238597 EDT | MinReturn                 690.252
2017-06-11 01:33:26.238927 EDT | AverageEsReturn           337.055
2017-06-11 01:33:26.239310 EDT | StdEsReturn               180.143
2017-06-11 01:33:26.239671 EDT | MaxEsReturn               571.12
2017-06-11 01:33:26.239998 EDT | MinEsReturn               103.195
2017-06-11 01:33:26.240322 EDT | AverageDiscountedReturn   222.602
2017-06-11 01:33:26.240660 EDT | AverageQLoss                2.57473
2017-06-11 01:33:26.240985 EDT | AveragePolicySurr         -30.9259
2017-06-11 01:33:26.241334 EDT | AverageQ                   30.5896
2017-06-11 01:33:26.241679 EDT | AverageAbsQ                30.611
2017-06-11 01:33:26.242012 EDT | AverageY                   30.5911
2017-06-11 01:33:26.242335 EDT | AverageAbsY                30.5989
2017-06-11 01:33:26.242666 EDT | AverageAbsQYDiff            0.580342
2017-06-11 01:33:26.242991 EDT | AverageAction               0.993562
2017-06-11 01:33:26.243425 EDT | PolicyRegParamNorm         89.1431
2017-06-11 01:33:26.243763 EDT | QFunRegParamNorm          114.528
2017-06-11 01:33:26.244088 EDT | -----------------------  -----------
2017-06-11 01:33:26.244525 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #803 | Training started
2017-06-11 01:33:43.902024 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #803 | Training finished
2017-06-11 01:33:43.903085 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #803 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 01:33:43.903380 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #803 | Collecting samples for evaluation
2017-06-11 01:33:58.533245 EDT | -----------------------  -----------
2017-06-11 01:33:58.534170 EDT | Epoch                     803
2017-06-11 01:33:58.534494 EDT | Iteration                 803
2017-06-11 01:33:58.534828 EDT | AverageReturn            1114.79
2017-06-11 01:33:58.535182 EDT | StdReturn                 389.089
2017-06-11 01:33:58.535573 EDT | MaxReturn                2190.53
2017-06-11 01:33:58.535919 EDT | MinReturn                  96.621
2017-06-11 01:33:58.536267 EDT | AverageEsReturn           540.918
2017-06-11 01:33:58.536644 EDT | StdEsReturn               364.625
2017-06-11 01:33:58.536986 EDT | MaxEsReturn              1167.53
2017-06-11 01:33:58.537333 EDT | MinEsReturn                44.3075
2017-06-11 01:33:58.537881 EDT | AverageDiscountedReturn   250.18
2017-06-11 01:33:58.538226 EDT | AverageQLoss                2.15466
2017-06-11 01:33:58.538521 EDT | AveragePolicySurr         -30.892
2017-06-11 01:33:58.538855 EDT | AverageQ                   30.5444
2017-06-11 01:33:58.539189 EDT | AverageAbsQ                30.5646
2017-06-11 01:33:58.539533 EDT | AverageY                   30.5468
2017-06-11 01:33:58.539862 EDT | AverageAbsY                30.5547
2017-06-11 01:33:58.540196 EDT | AverageAbsQYDiff            0.549599
2017-06-11 01:33:58.540497 EDT | AverageAction               0.994384
2017-06-11 01:33:58.540783 EDT | PolicyRegParamNorm         89.2087
2017-06-11 01:33:58.541185 EDT | QFunRegParamNorm          114.656
2017-06-11 01:33:58.541610 EDT | -----------------------  -----------
2017-06-11 01:33:58.542108 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #804 | Training started
2017-06-11 01:34:15.025341 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #804 | Training finished
2017-06-11 01:34:15.026273 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #804 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 01:34:15.026651 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #804 | Collecting samples for evaluation
2017-06-11 01:34:28.889035 EDT | -----------------------  -----------
2017-06-11 01:34:28.889942 EDT | Epoch                     804
2017-06-11 01:34:28.890314 EDT | Iteration                 804
2017-06-11 01:34:28.890664 EDT | AverageReturn            1537.8
2017-06-11 01:34:28.891009 EDT | StdReturn                 705.677
2017-06-11 01:34:28.891353 EDT | MaxReturn                3232.31
2017-06-11 01:34:28.891700 EDT | MinReturn                 888.239
2017-06-11 01:34:28.892044 EDT | AverageEsReturn           598.312
2017-06-11 01:34:28.892386 EDT | StdEsReturn               282.336
2017-06-11 01:34:28.892727 EDT | MaxEsReturn              1104.37
2017-06-11 01:34:28.893068 EDT | MinEsReturn               312.496
2017-06-11 01:34:28.893412 EDT | AverageDiscountedReturn   258.973
2017-06-11 01:34:28.893765 EDT | AverageQLoss                1.8972
2017-06-11 01:34:28.894107 EDT | AveragePolicySurr         -30.9116
2017-06-11 01:34:28.894449 EDT | AverageQ                   30.5637
2017-06-11 01:34:28.894798 EDT | AverageAbsQ                30.5834
2017-06-11 01:34:28.895138 EDT | AverageY                   30.5642
2017-06-11 01:34:28.895476 EDT | AverageAbsY                30.5719
2017-06-11 01:34:28.895816 EDT | AverageAbsQYDiff            0.533364
2017-06-11 01:34:28.896158 EDT | AverageAction               0.994827
2017-06-11 01:34:28.896496 EDT | PolicyRegParamNorm         89.2632
2017-06-11 01:34:28.896837 EDT | QFunRegParamNorm          114.702
2017-06-11 01:34:28.897178 EDT | -----------------------  -----------
2017-06-11 01:34:28.897667 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #805 | Training started
2017-06-11 01:34:46.624003 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #805 | Training finished
2017-06-11 01:34:46.625050 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #805 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 01:34:46.625445 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #805 | Collecting samples for evaluation
2017-06-11 01:34:59.987627 EDT | -----------------------  -----------
2017-06-11 01:34:59.988353 EDT | Epoch                     805
2017-06-11 01:34:59.988543 EDT | Iteration                 805
2017-06-11 01:34:59.988714 EDT | AverageReturn            1466.01
2017-06-11 01:34:59.988981 EDT | StdReturn                 697.189
2017-06-11 01:34:59.989161 EDT | MaxReturn                2711.18
2017-06-11 01:34:59.989373 EDT | MinReturn                 720.471
2017-06-11 01:34:59.989539 EDT | AverageEsReturn           874.947
2017-06-11 01:34:59.989719 EDT | StdEsReturn               638.043
2017-06-11 01:34:59.995169 EDT | MaxEsReturn              1739.68
2017-06-11 01:34:59.995394 EDT | MinEsReturn               219.37
2017-06-11 01:34:59.995579 EDT | AverageDiscountedReturn   223.937
2017-06-11 01:34:59.995770 EDT | AverageQLoss                1.90386
2017-06-11 01:34:59.995937 EDT | AveragePolicySurr         -30.9303
2017-06-11 01:34:59.996102 EDT | AverageQ                   30.5947
2017-06-11 01:34:59.996262 EDT | AverageAbsQ                30.6167
2017-06-11 01:34:59.996444 EDT | AverageY                   30.5953
2017-06-11 01:34:59.996611 EDT | AverageAbsY                30.605
2017-06-11 01:34:59.996772 EDT | AverageAbsQYDiff            0.515039
2017-06-11 01:34:59.996934 EDT | AverageAction               0.992977
2017-06-11 01:34:59.997097 EDT | PolicyRegParamNorm         89.3161
2017-06-11 01:34:59.997257 EDT | QFunRegParamNorm          114.733
2017-06-11 01:34:59.997417 EDT | -----------------------  -----------
2017-06-11 01:34:59.997707 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #806 | Training started
2017-06-11 01:35:17.603743 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #806 | Training finished
2017-06-11 01:35:17.605106 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #806 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 01:35:17.606081 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #806 | Collecting samples for evaluation
2017-06-11 01:35:31.910906 EDT | -----------------------  -----------
2017-06-11 01:35:31.911722 EDT | Epoch                     806
2017-06-11 01:35:31.912017 EDT | Iteration                 806
2017-06-11 01:35:31.912251 EDT | AverageReturn            1050.03
2017-06-11 01:35:31.912456 EDT | StdReturn                 355.299
2017-06-11 01:35:31.912671 EDT | MaxReturn                2906.96
2017-06-11 01:35:31.912962 EDT | MinReturn                 801.678
2017-06-11 01:35:31.913159 EDT | AverageEsReturn           465.865
2017-06-11 01:35:31.913400 EDT | StdEsReturn               260.887
2017-06-11 01:35:31.913622 EDT | MaxEsReturn               876.891
2017-06-11 01:35:31.913834 EDT | MinEsReturn               176.421
2017-06-11 01:35:31.914015 EDT | AverageDiscountedReturn   250.633
2017-06-11 01:35:31.914242 EDT | AverageQLoss                2.08734
2017-06-11 01:35:31.914424 EDT | AveragePolicySurr         -30.9232
2017-06-11 01:35:31.914667 EDT | AverageQ                   30.5893
2017-06-11 01:35:31.914858 EDT | AverageAbsQ                30.6132
2017-06-11 01:35:31.915038 EDT | AverageY                   30.5914
2017-06-11 01:35:31.915217 EDT | AverageAbsY                30.6021
2017-06-11 01:35:31.915474 EDT | AverageAbsQYDiff            0.536804
2017-06-11 01:35:31.915657 EDT | AverageAction               0.993044
2017-06-11 01:35:31.915838 EDT | PolicyRegParamNorm         89.3059
2017-06-11 01:35:31.916060 EDT | QFunRegParamNorm          114.818
2017-06-11 01:35:31.916354 EDT | -----------------------  -----------
2017-06-11 01:35:31.916729 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #807 | Training started
2017-06-11 01:35:49.681332 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #807 | Training finished
2017-06-11 01:35:49.681633 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #807 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 01:35:49.681890 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #807 | Collecting samples for evaluation
2017-06-11 01:36:03.656489 EDT | -----------------------  -----------
2017-06-11 01:36:03.657392 EDT | Epoch                     807
2017-06-11 01:36:03.658008 EDT | Iteration                 807
2017-06-11 01:36:03.658398 EDT | AverageReturn             868.982
2017-06-11 01:36:03.659231 EDT | StdReturn                  98.406
2017-06-11 01:36:03.659420 EDT | MaxReturn                1103.21
2017-06-11 01:36:03.659716 EDT | MinReturn                 762.134
2017-06-11 01:36:03.660784 EDT | AverageEsReturn           339.17
2017-06-11 01:36:03.661159 EDT | StdEsReturn               283.504
2017-06-11 01:36:03.661534 EDT | MaxEsReturn               749.896
2017-06-11 01:36:03.661917 EDT | MinEsReturn                10.2964
2017-06-11 01:36:03.662455 EDT | AverageDiscountedReturn   249.604
2017-06-11 01:36:03.663779 EDT | AverageQLoss                2.10799
2017-06-11 01:36:03.664156 EDT | AveragePolicySurr         -30.9639
2017-06-11 01:36:03.664508 EDT | AverageQ                   30.6429
2017-06-11 01:36:03.664841 EDT | AverageAbsQ                30.6675
2017-06-11 01:36:03.665212 EDT | AverageY                   30.6446
2017-06-11 01:36:03.665556 EDT | AverageAbsY                30.6561
2017-06-11 01:36:03.665910 EDT | AverageAbsQYDiff            0.532943
2017-06-11 01:36:03.666284 EDT | AverageAction               0.99498
2017-06-11 01:36:03.666652 EDT | PolicyRegParamNorm         89.3231
2017-06-11 01:36:03.667020 EDT | QFunRegParamNorm          114.918
2017-06-11 01:36:03.668414 EDT | -----------------------  -----------
2017-06-11 01:36:03.668970 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #808 | Training started
2017-06-11 01:36:20.147837 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #808 | Training finished
2017-06-11 01:36:20.148481 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #808 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 01:36:20.148770 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #808 | Collecting samples for evaluation
2017-06-11 01:36:34.018842 EDT | -----------------------  -----------
2017-06-11 01:36:34.019718 EDT | Epoch                     808
2017-06-11 01:36:34.020073 EDT | Iteration                 808
2017-06-11 01:36:34.020484 EDT | AverageReturn             796.636
2017-06-11 01:36:34.020754 EDT | StdReturn                 225.047
2017-06-11 01:36:34.021008 EDT | MaxReturn                1128.94
2017-06-11 01:36:34.023076 EDT | MinReturn                 170.583
2017-06-11 01:36:34.023550 EDT | AverageEsReturn           348.142
2017-06-11 01:36:34.024012 EDT | StdEsReturn               181.62
2017-06-11 01:36:34.024270 EDT | MaxEsReturn               587.042
2017-06-11 01:36:34.024520 EDT | MinEsReturn                41.3598
2017-06-11 01:36:34.024759 EDT | AverageDiscountedReturn   232.895
2017-06-11 01:36:34.025013 EDT | AverageQLoss                2.32694
2017-06-11 01:36:34.025396 EDT | AveragePolicySurr         -30.9144
2017-06-11 01:36:34.025643 EDT | AverageQ                   30.5812
2017-06-11 01:36:34.026101 EDT | AverageAbsQ                30.6039
2017-06-11 01:36:34.026649 EDT | AverageY                   30.5839
2017-06-11 01:36:34.028615 EDT | AverageAbsY                30.5938
2017-06-11 01:36:34.029413 EDT | AverageAbsQYDiff            0.549869
2017-06-11 01:36:34.029733 EDT | AverageAction               0.994051
2017-06-11 01:36:34.030113 EDT | PolicyRegParamNorm         89.3566
2017-06-11 01:36:34.030899 EDT | QFunRegParamNorm          114.99
2017-06-11 01:36:34.031662 EDT | -----------------------  -----------
2017-06-11 01:36:34.032798 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #809 | Training started
2017-06-11 01:36:51.008170 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #809 | Training finished
2017-06-11 01:36:51.009133 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #809 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 01:36:51.009527 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #809 | Collecting samples for evaluation
2017-06-11 01:37:04.982848 EDT | -----------------------  -----------
2017-06-11 01:37:04.983834 EDT | Epoch                     809
2017-06-11 01:37:04.984081 EDT | Iteration                 809
2017-06-11 01:37:04.984286 EDT | AverageReturn             853.428
2017-06-11 01:37:04.984481 EDT | StdReturn                 659.252
2017-06-11 01:37:04.984657 EDT | MaxReturn                2752.31
2017-06-11 01:37:04.984829 EDT | MinReturn                 155.319
2017-06-11 01:37:04.985001 EDT | AverageEsReturn           298.267
2017-06-11 01:37:04.985180 EDT | StdEsReturn               234.208
2017-06-11 01:37:04.985350 EDT | MaxEsReturn               797.859
2017-06-11 01:37:04.985520 EDT | MinEsReturn                12.5756
2017-06-11 01:37:04.985744 EDT | AverageDiscountedReturn   182.968
2017-06-11 01:37:04.985922 EDT | AverageQLoss                2.25533
2017-06-11 01:37:04.986099 EDT | AveragePolicySurr         -30.9296
2017-06-11 01:37:04.986271 EDT | AverageQ                   30.6054
2017-06-11 01:37:04.986477 EDT | AverageAbsQ                30.6278
2017-06-11 01:37:04.986675 EDT | AverageY                   30.6055
2017-06-11 01:37:04.986868 EDT | AverageAbsY                30.6134
2017-06-11 01:37:04.987061 EDT | AverageAbsQYDiff            0.550088
2017-06-11 01:37:04.987268 EDT | AverageAction               0.992819
2017-06-11 01:37:04.987582 EDT | PolicyRegParamNorm         89.375
2017-06-11 01:37:04.987873 EDT | QFunRegParamNorm          115.042
2017-06-11 01:37:04.988163 EDT | -----------------------  -----------
2017-06-11 01:37:04.988615 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #810 | Training started
2017-06-11 01:37:21.981081 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #810 | Training finished
2017-06-11 01:37:21.981821 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #810 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 01:37:21.982021 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #810 | Collecting samples for evaluation
2017-06-11 01:37:36.331675 EDT | -----------------------  -----------
2017-06-11 01:37:36.332394 EDT | Epoch                     810
2017-06-11 01:37:36.332582 EDT | Iteration                 810
2017-06-11 01:37:36.332778 EDT | AverageReturn            1638.64
2017-06-11 01:37:36.332948 EDT | StdReturn                 808.396
2017-06-11 01:37:36.333134 EDT | MaxReturn                3381.86
2017-06-11 01:37:36.333312 EDT | MinReturn                 320.045
2017-06-11 01:37:36.333471 EDT | AverageEsReturn           450.315
2017-06-11 01:37:36.333628 EDT | StdEsReturn               271.519
2017-06-11 01:37:36.333822 EDT | MaxEsReturn               920.777
2017-06-11 01:37:36.334025 EDT | MinEsReturn               116.712
2017-06-11 01:37:36.334184 EDT | AverageDiscountedReturn   251.355
2017-06-11 01:37:36.334341 EDT | AverageQLoss                2.49074
2017-06-11 01:37:36.334496 EDT | AveragePolicySurr         -30.9685
2017-06-11 01:37:36.334660 EDT | AverageQ                   30.6224
2017-06-11 01:37:36.334832 EDT | AverageAbsQ                30.6432
2017-06-11 01:37:36.335015 EDT | AverageY                   30.6237
2017-06-11 01:37:36.335254 EDT | AverageAbsY                30.6322
2017-06-11 01:37:36.335427 EDT | AverageAbsQYDiff            0.566826
2017-06-11 01:37:36.335593 EDT | AverageAction               0.992872
2017-06-11 01:37:36.335776 EDT | PolicyRegParamNorm         89.4058
2017-06-11 01:37:36.335956 EDT | QFunRegParamNorm          115.119
2017-06-11 01:37:36.336113 EDT | -----------------------  -----------
2017-06-11 01:37:36.336361 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #811 | Training started
2017-06-11 01:37:53.356710 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #811 | Training finished
2017-06-11 01:37:53.357388 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #811 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 01:37:53.357685 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #811 | Collecting samples for evaluation
2017-06-11 01:38:08.005428 EDT | -----------------------  -----------
2017-06-11 01:38:08.006384 EDT | Epoch                     811
2017-06-11 01:38:08.006783 EDT | Iteration                 811
2017-06-11 01:38:08.007142 EDT | AverageReturn             859.441
2017-06-11 01:38:08.007578 EDT | StdReturn                 863.386
2017-06-11 01:38:08.007973 EDT | MaxReturn                3484.06
2017-06-11 01:38:08.008310 EDT | MinReturn                 312.358
2017-06-11 01:38:08.008667 EDT | AverageEsReturn           385.091
2017-06-11 01:38:08.009088 EDT | StdEsReturn               363.427
2017-06-11 01:38:08.009525 EDT | MaxEsReturn               890.768
2017-06-11 01:38:08.009921 EDT | MinEsReturn                26.5197
2017-06-11 01:38:08.010259 EDT | AverageDiscountedReturn   191.696
2017-06-11 01:38:08.010588 EDT | AverageQLoss                2.16729
2017-06-11 01:38:08.010922 EDT | AveragePolicySurr         -30.9293
2017-06-11 01:38:08.011345 EDT | AverageQ                   30.5807
2017-06-11 01:38:08.011779 EDT | AverageAbsQ                30.6076
2017-06-11 01:38:08.012183 EDT | AverageY                   30.5811
2017-06-11 01:38:08.012521 EDT | AverageAbsY                30.594
2017-06-11 01:38:08.012850 EDT | AverageAbsQYDiff            0.552728
2017-06-11 01:38:08.013177 EDT | AverageAction               0.992786
2017-06-11 01:38:08.013863 EDT | PolicyRegParamNorm         89.4047
2017-06-11 01:38:08.014665 EDT | QFunRegParamNorm          115.189
2017-06-11 01:38:08.015297 EDT | -----------------------  -----------
2017-06-11 01:38:08.016113 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #812 | Training started
2017-06-11 01:38:23.639681 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #812 | Training finished
2017-06-11 01:38:23.640236 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #812 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 01:38:23.640436 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #812 | Collecting samples for evaluation
2017-06-11 01:38:38.048543 EDT | -----------------------  -----------
2017-06-11 01:38:38.049393 EDT | Epoch                     812
2017-06-11 01:38:38.049574 EDT | Iteration                 812
2017-06-11 01:38:38.049749 EDT | AverageReturn            1699.91
2017-06-11 01:38:38.049990 EDT | StdReturn                 673.583
2017-06-11 01:38:38.050254 EDT | MaxReturn                2890.81
2017-06-11 01:38:38.050457 EDT | MinReturn                 725.385
2017-06-11 01:38:38.050615 EDT | AverageEsReturn           369.1
2017-06-11 01:38:38.050802 EDT | StdEsReturn               197.171
2017-06-11 01:38:38.050963 EDT | MaxEsReturn               667.716
2017-06-11 01:38:38.051115 EDT | MinEsReturn               182.63
2017-06-11 01:38:38.051267 EDT | AverageDiscountedReturn   229.883
2017-06-11 01:38:38.051417 EDT | AverageQLoss                1.93038
2017-06-11 01:38:38.051652 EDT | AveragePolicySurr         -30.9476
2017-06-11 01:38:38.051804 EDT | AverageQ                   30.5932
2017-06-11 01:38:38.051954 EDT | AverageAbsQ                30.6177
2017-06-11 01:38:38.052104 EDT | AverageY                   30.5943
2017-06-11 01:38:38.052255 EDT | AverageAbsY                30.6069
2017-06-11 01:38:38.052406 EDT | AverageAbsQYDiff            0.521786
2017-06-11 01:38:38.052602 EDT | AverageAction               0.99207
2017-06-11 01:38:38.052859 EDT | PolicyRegParamNorm         89.4759
2017-06-11 01:38:38.053103 EDT | QFunRegParamNorm          115.264
2017-06-11 01:38:38.053341 EDT | -----------------------  -----------
2017-06-11 01:38:38.053757 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #813 | Training started
2017-06-11 01:38:55.253627 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #813 | Training finished
2017-06-11 01:38:55.254509 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #813 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 01:38:55.254935 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #813 | Collecting samples for evaluation
2017-06-11 01:39:09.689573 EDT | -----------------------  -----------
2017-06-11 01:39:09.690341 EDT | Epoch                     813
2017-06-11 01:39:09.690631 EDT | Iteration                 813
2017-06-11 01:39:09.691779 EDT | AverageReturn             546.428
2017-06-11 01:39:09.692055 EDT | StdReturn                 349.168
2017-06-11 01:39:09.697485 EDT | MaxReturn                1690.67
2017-06-11 01:39:09.697797 EDT | MinReturn                 257.46
2017-06-11 01:39:09.698072 EDT | AverageEsReturn           442.769
2017-06-11 01:39:09.698342 EDT | StdEsReturn               470.321
2017-06-11 01:39:09.698610 EDT | MaxEsReturn              1443.71
2017-06-11 01:39:09.698877 EDT | MinEsReturn                58.7554
2017-06-11 01:39:09.699143 EDT | AverageDiscountedReturn   187.077
2017-06-11 01:39:09.699407 EDT | AverageQLoss                2.3394
2017-06-11 01:39:09.699670 EDT | AveragePolicySurr         -31.0251
2017-06-11 01:39:09.699937 EDT | AverageQ                   30.6613
2017-06-11 01:39:09.700224 EDT | AverageAbsQ                30.6882
2017-06-11 01:39:09.700498 EDT | AverageY                   30.6641
2017-06-11 01:39:09.700792 EDT | AverageAbsY                30.6755
2017-06-11 01:39:09.707528 EDT | AverageAbsQYDiff            0.567061
2017-06-11 01:39:09.707914 EDT | AverageAction               0.994503
2017-06-11 01:39:09.708198 EDT | PolicyRegParamNorm         89.5599
2017-06-11 01:39:09.708471 EDT | QFunRegParamNorm          115.32
2017-06-11 01:39:09.708740 EDT | -----------------------  -----------
2017-06-11 01:39:09.709178 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #814 | Training started
2017-06-11 01:39:28.288841 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #814 | Training finished
2017-06-11 01:39:28.289687 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #814 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 01:39:28.290096 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #814 | Collecting samples for evaluation
2017-06-11 01:39:43.325502 EDT | -----------------------  -----------
2017-06-11 01:39:43.326248 EDT | Epoch                     814
2017-06-11 01:39:43.326511 EDT | Iteration                 814
2017-06-11 01:39:43.326703 EDT | AverageReturn             810.43
2017-06-11 01:39:43.326859 EDT | StdReturn                 342.853
2017-06-11 01:39:43.327140 EDT | MaxReturn                2454.97
2017-06-11 01:39:43.327304 EDT | MinReturn                 491.373
2017-06-11 01:39:43.327459 EDT | AverageEsReturn           349.242
2017-06-11 01:39:43.327648 EDT | StdEsReturn               162.894
2017-06-11 01:39:43.327827 EDT | MaxEsReturn               729.555
2017-06-11 01:39:43.327980 EDT | MinEsReturn               154.996
2017-06-11 01:39:43.328131 EDT | AverageDiscountedReturn   241.319
2017-06-11 01:39:43.328448 EDT | AverageQLoss                2.01534
2017-06-11 01:39:43.328779 EDT | AveragePolicySurr         -30.9731
2017-06-11 01:39:43.329106 EDT | AverageQ                   30.6016
2017-06-11 01:39:43.329421 EDT | AverageAbsQ                30.6256
2017-06-11 01:39:43.329766 EDT | AverageY                   30.6017
2017-06-11 01:39:43.330075 EDT | AverageAbsY                30.6145
2017-06-11 01:39:43.330237 EDT | AverageAbsQYDiff            0.543354
2017-06-11 01:39:43.330393 EDT | AverageAction               0.995379
2017-06-11 01:39:43.330543 EDT | PolicyRegParamNorm         89.5766
2017-06-11 01:39:43.330827 EDT | QFunRegParamNorm          115.351
2017-06-11 01:39:43.331155 EDT | -----------------------  -----------
2017-06-11 01:39:43.331637 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #815 | Training started
2017-06-11 01:40:01.631307 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #815 | Training finished
2017-06-11 01:40:01.634183 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #815 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 01:40:01.634596 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #815 | Collecting samples for evaluation
2017-06-11 01:40:15.582565 EDT | -----------------------  -----------
2017-06-11 01:40:15.583110 EDT | Epoch                     815
2017-06-11 01:40:15.583452 EDT | Iteration                 815
2017-06-11 01:40:15.583765 EDT | AverageReturn             466.437
2017-06-11 01:40:15.584178 EDT | StdReturn                 520.357
2017-06-11 01:40:15.584502 EDT | MaxReturn                2682.5
2017-06-11 01:40:15.584907 EDT | MinReturn                  98.5549
2017-06-11 01:40:15.585342 EDT | AverageEsReturn           233.485
2017-06-11 01:40:15.585733 EDT | StdEsReturn               157.234
2017-06-11 01:40:15.586148 EDT | MaxEsReturn               467.149
2017-06-11 01:40:15.586519 EDT | MinEsReturn                15.6577
2017-06-11 01:40:15.586783 EDT | AverageDiscountedReturn   144.643
2017-06-11 01:40:15.587051 EDT | AverageQLoss                2.25703
2017-06-11 01:40:15.588840 EDT | AveragePolicySurr         -31.0608
2017-06-11 01:40:15.589177 EDT | AverageQ                   30.6973
2017-06-11 01:40:15.589501 EDT | AverageAbsQ                30.7199
2017-06-11 01:40:15.589927 EDT | AverageY                   30.6988
2017-06-11 01:40:15.590341 EDT | AverageAbsY                30.7099
2017-06-11 01:40:15.590738 EDT | AverageAbsQYDiff            0.562291
2017-06-11 01:40:15.591103 EDT | AverageAction               0.994959
2017-06-11 01:40:15.591442 EDT | PolicyRegParamNorm         89.6235
2017-06-11 01:40:15.591776 EDT | QFunRegParamNorm          115.417
2017-06-11 01:40:15.592124 EDT | -----------------------  -----------
2017-06-11 01:40:15.592633 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #816 | Training started
2017-06-11 01:40:32.890834 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #816 | Training finished
2017-06-11 01:40:32.891935 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #816 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 01:40:32.892445 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #816 | Collecting samples for evaluation
2017-06-11 01:40:48.217183 EDT | -----------------------  -----------
2017-06-11 01:40:48.218872 EDT | Epoch                     816
2017-06-11 01:40:48.219179 EDT | Iteration                 816
2017-06-11 01:40:48.219507 EDT | AverageReturn             889.928
2017-06-11 01:40:48.220531 EDT | StdReturn                 343.198
2017-06-11 01:40:48.220849 EDT | MaxReturn                2219.53
2017-06-11 01:40:48.221558 EDT | MinReturn                 143.932
2017-06-11 01:40:48.222114 EDT | AverageEsReturn           191.495
2017-06-11 01:40:48.227349 EDT | StdEsReturn               230.266
2017-06-11 01:40:48.228489 EDT | MaxEsReturn               700.66
2017-06-11 01:40:48.228817 EDT | MinEsReturn                18.3266
2017-06-11 01:40:48.229180 EDT | AverageDiscountedReturn   245.072
2017-06-11 01:40:48.229488 EDT | AverageQLoss                2.44659
2017-06-11 01:40:48.229797 EDT | AveragePolicySurr         -31.0098
2017-06-11 01:40:48.230092 EDT | AverageQ                   30.6393
2017-06-11 01:40:48.230636 EDT | AverageAbsQ                30.6613
2017-06-11 01:40:48.231322 EDT | AverageY                   30.6416
2017-06-11 01:40:48.231909 EDT | AverageAbsY                30.6509
2017-06-11 01:40:48.232607 EDT | AverageAbsQYDiff            0.564276
2017-06-11 01:40:48.233298 EDT | AverageAction               0.995633
2017-06-11 01:40:48.234059 EDT | PolicyRegParamNorm         89.6644
2017-06-11 01:40:48.234839 EDT | QFunRegParamNorm          115.488
2017-06-11 01:40:48.235536 EDT | -----------------------  -----------
2017-06-11 01:40:48.236487 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #817 | Training started
2017-06-11 01:41:05.721118 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #817 | Training finished
2017-06-11 01:41:05.722945 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #817 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 01:41:05.723355 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #817 | Collecting samples for evaluation
2017-06-11 01:41:19.785831 EDT | -----------------------  -----------
2017-06-11 01:41:19.787666 EDT | Epoch                     817
2017-06-11 01:41:19.789435 EDT | Iteration                 817
2017-06-11 01:41:19.790449 EDT | AverageReturn             768.305
2017-06-11 01:41:19.790753 EDT | StdReturn                  99.463
2017-06-11 01:41:19.790975 EDT | MaxReturn                1375.12
2017-06-11 01:41:19.791320 EDT | MinReturn                 535.335
2017-06-11 01:41:19.791621 EDT | AverageEsReturn           312.709
2017-06-11 01:41:19.791919 EDT | StdEsReturn               159.321
2017-06-11 01:41:19.792119 EDT | MaxEsReturn               701.993
2017-06-11 01:41:19.792355 EDT | MinEsReturn               117.84
2017-06-11 01:41:19.792541 EDT | AverageDiscountedReturn   244.79
2017-06-11 01:41:19.792724 EDT | AverageQLoss                2.14975
2017-06-11 01:41:19.792906 EDT | AveragePolicySurr         -31.0831
2017-06-11 01:41:19.793148 EDT | AverageQ                   30.7242
2017-06-11 01:41:19.793362 EDT | AverageAbsQ                30.7471
2017-06-11 01:41:19.793546 EDT | AverageY                   30.7252
2017-06-11 01:41:19.793738 EDT | AverageAbsY                30.7373
2017-06-11 01:41:19.793921 EDT | AverageAbsQYDiff            0.5383
2017-06-11 01:41:19.794126 EDT | AverageAction               0.995203
2017-06-11 01:41:19.794308 EDT | PolicyRegParamNorm         89.683
2017-06-11 01:41:19.794488 EDT | QFunRegParamNorm          115.545
2017-06-11 01:41:19.794717 EDT | -----------------------  -----------
2017-06-11 01:41:19.795542 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #818 | Training started
2017-06-11 01:41:36.724911 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #818 | Training finished
2017-06-11 01:41:36.726325 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #818 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 01:41:36.726715 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #818 | Collecting samples for evaluation
2017-06-11 01:41:51.504080 EDT | -----------------------  -----------
2017-06-11 01:41:51.508094 EDT | Epoch                     818
2017-06-11 01:41:51.508767 EDT | Iteration                 818
2017-06-11 01:41:51.509665 EDT | AverageReturn            2601.67
2017-06-11 01:41:51.510589 EDT | StdReturn                 881.174
2017-06-11 01:41:51.511492 EDT | MaxReturn                3502.31
2017-06-11 01:41:51.512372 EDT | MinReturn                 822.488
2017-06-11 01:41:51.513256 EDT | AverageEsReturn           379.098
2017-06-11 01:41:51.514131 EDT | StdEsReturn               275.447
2017-06-11 01:41:51.515026 EDT | MaxEsReturn               723.592
2017-06-11 01:41:51.515897 EDT | MinEsReturn                14.6502
2017-06-11 01:41:51.516766 EDT | AverageDiscountedReturn   264.795
2017-06-11 01:41:51.517655 EDT | AverageQLoss                2.19731
2017-06-11 01:41:51.518542 EDT | AveragePolicySurr         -31.0858
2017-06-11 01:41:51.519422 EDT | AverageQ                   30.7357
2017-06-11 01:41:51.520285 EDT | AverageAbsQ                30.7592
2017-06-11 01:41:51.521161 EDT | AverageY                   30.7363
2017-06-11 01:41:51.522041 EDT | AverageAbsY                30.7468
2017-06-11 01:41:51.522923 EDT | AverageAbsQYDiff            0.543916
2017-06-11 01:41:51.523807 EDT | AverageAction               0.992378
2017-06-11 01:41:51.524680 EDT | PolicyRegParamNorm         89.7444
2017-06-11 01:41:51.525544 EDT | QFunRegParamNorm          115.632
2017-06-11 01:41:51.526476 EDT | -----------------------  -----------
2017-06-11 01:41:51.527523 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #819 | Training started
2017-06-11 01:42:09.031000 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #819 | Training finished
2017-06-11 01:42:09.031784 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #819 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 01:42:09.031975 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #819 | Collecting samples for evaluation
2017-06-11 01:42:23.345495 EDT | -----------------------  -----------
2017-06-11 01:42:23.346326 EDT | Epoch                     819
2017-06-11 01:42:23.346636 EDT | Iteration                 819
2017-06-11 01:42:23.346898 EDT | AverageReturn             736.936
2017-06-11 01:42:23.347188 EDT | StdReturn                  62.0629
2017-06-11 01:42:23.347486 EDT | MaxReturn                1027.44
2017-06-11 01:42:23.347674 EDT | MinReturn                 619.789
2017-06-11 01:42:23.347861 EDT | AverageEsReturn           219.492
2017-06-11 01:42:23.348044 EDT | StdEsReturn               198.022
2017-06-11 01:42:23.348216 EDT | MaxEsReturn               618.892
2017-06-11 01:42:23.348371 EDT | MinEsReturn                12.435
2017-06-11 01:42:23.348521 EDT | AverageDiscountedReturn   242.268
2017-06-11 01:42:23.348670 EDT | AverageQLoss                2.12757
2017-06-11 01:42:23.348860 EDT | AveragePolicySurr         -31.0021
2017-06-11 01:42:23.349012 EDT | AverageQ                   30.6294
2017-06-11 01:42:23.349179 EDT | AverageAbsQ                30.6562
2017-06-11 01:42:23.349456 EDT | AverageY                   30.6307
2017-06-11 01:42:23.350003 EDT | AverageAbsY                30.6426
2017-06-11 01:42:23.350374 EDT | AverageAbsQYDiff            0.535078
2017-06-11 01:42:23.350535 EDT | AverageAction               0.994517
2017-06-11 01:42:23.350710 EDT | PolicyRegParamNorm         89.7338
2017-06-11 01:42:23.350866 EDT | QFunRegParamNorm          115.715
2017-06-11 01:42:23.351018 EDT | -----------------------  -----------
2017-06-11 01:42:23.351314 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #820 | Training started
2017-06-11 01:42:40.542596 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #820 | Training finished
2017-06-11 01:42:40.543752 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #820 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 01:42:40.544192 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #820 | Collecting samples for evaluation
2017-06-11 01:42:54.830145 EDT | -----------------------  -----------
2017-06-11 01:42:54.831097 EDT | Epoch                     820
2017-06-11 01:42:54.831460 EDT | Iteration                 820
2017-06-11 01:42:54.831853 EDT | AverageReturn            1832.98
2017-06-11 01:42:54.832157 EDT | StdReturn                 770.162
2017-06-11 01:42:54.832480 EDT | MaxReturn                3307.07
2017-06-11 01:42:54.832822 EDT | MinReturn                 868.456
2017-06-11 01:42:54.833214 EDT | AverageEsReturn           425.359
2017-06-11 01:42:54.833507 EDT | StdEsReturn               186.713
2017-06-11 01:42:54.833848 EDT | MaxEsReturn               728.38
2017-06-11 01:42:54.834188 EDT | MinEsReturn                61.0451
2017-06-11 01:42:54.834585 EDT | AverageDiscountedReturn   258.574
2017-06-11 01:42:54.834871 EDT | AverageQLoss                2.14152
2017-06-11 01:42:54.835196 EDT | AveragePolicySurr         -31.1078
2017-06-11 01:42:54.835536 EDT | AverageQ                   30.7603
2017-06-11 01:42:54.835934 EDT | AverageAbsQ                30.7818
2017-06-11 01:42:54.836213 EDT | AverageY                   30.7608
2017-06-11 01:42:54.836539 EDT | AverageAbsY                30.769
2017-06-11 01:42:54.836874 EDT | AverageAbsQYDiff            0.52688
2017-06-11 01:42:54.837276 EDT | AverageAction               0.994413
2017-06-11 01:42:54.837547 EDT | PolicyRegParamNorm         89.7996
2017-06-11 01:42:54.837887 EDT | QFunRegParamNorm          115.771
2017-06-11 01:42:54.838223 EDT | -----------------------  -----------
2017-06-11 01:42:54.838767 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #821 | Training started
2017-06-11 01:43:12.333707 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #821 | Training finished
2017-06-11 01:43:12.334546 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #821 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 01:43:12.335679 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #821 | Collecting samples for evaluation
2017-06-11 01:43:26.514188 EDT | -----------------------  -----------
2017-06-11 01:43:26.515044 EDT | Epoch                     821
2017-06-11 01:43:26.515333 EDT | Iteration                 821
2017-06-11 01:43:26.515594 EDT | AverageReturn            1779.14
2017-06-11 01:43:26.515849 EDT | StdReturn                 777.563
2017-06-11 01:43:26.516111 EDT | MaxReturn                3323.68
2017-06-11 01:43:26.516361 EDT | MinReturn                 839.099
2017-06-11 01:43:26.516611 EDT | AverageEsReturn           528.206
2017-06-11 01:43:26.516860 EDT | StdEsReturn               266.141
2017-06-11 01:43:26.517108 EDT | MaxEsReturn               742.017
2017-06-11 01:43:26.517356 EDT | MinEsReturn                 8.40897
2017-06-11 01:43:26.517605 EDT | AverageDiscountedReturn   261.188
2017-06-11 01:43:26.517870 EDT | AverageQLoss                2.06927
2017-06-11 01:43:26.518119 EDT | AveragePolicySurr         -31.1177
2017-06-11 01:43:26.518367 EDT | AverageQ                   30.7588
2017-06-11 01:43:26.518614 EDT | AverageAbsQ                30.7824
2017-06-11 01:43:26.518861 EDT | AverageY                   30.7596
2017-06-11 01:43:26.519108 EDT | AverageAbsY                30.7683
2017-06-11 01:43:26.519358 EDT | AverageAbsQYDiff            0.517041
2017-06-11 01:43:26.519618 EDT | AverageAction               0.99408
2017-06-11 01:43:26.519866 EDT | PolicyRegParamNorm         89.8268
2017-06-11 01:43:26.520112 EDT | QFunRegParamNorm          115.808
2017-06-11 01:43:26.520359 EDT | -----------------------  -----------
2017-06-11 01:43:26.520756 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #822 | Training started
2017-06-11 01:43:43.780919 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #822 | Training finished
2017-06-11 01:43:43.791550 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #822 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 01:43:43.792661 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #822 | Collecting samples for evaluation
2017-06-11 01:43:57.520463 EDT | -----------------------  ----------
2017-06-11 01:43:57.521243 EDT | Epoch                    822
2017-06-11 01:43:57.521737 EDT | Iteration                822
2017-06-11 01:43:57.522168 EDT | AverageReturn            359.291
2017-06-11 01:43:57.522504 EDT | StdReturn                286.848
2017-06-11 01:43:57.523135 EDT | MaxReturn                925.1
2017-06-11 01:43:57.523475 EDT | MinReturn                150.083
2017-06-11 01:43:57.523897 EDT | AverageEsReturn          444.704
2017-06-11 01:43:57.524227 EDT | StdEsReturn              205.252
2017-06-11 01:43:57.524564 EDT | MaxEsReturn              724.994
2017-06-11 01:43:57.525009 EDT | MinEsReturn              158.962
2017-06-11 01:43:57.525344 EDT | AverageDiscountedReturn  146.517
2017-06-11 01:43:57.525685 EDT | AverageQLoss               2.12873
2017-06-11 01:43:57.526360 EDT | AveragePolicySurr        -31.0767
2017-06-11 01:43:57.526700 EDT | AverageQ                  30.6968
2017-06-11 01:43:57.527000 EDT | AverageAbsQ               30.7235
2017-06-11 01:43:57.527383 EDT | AverageY                  30.6987
2017-06-11 01:43:57.527714 EDT | AverageAbsY               30.7086
2017-06-11 01:43:57.528058 EDT | AverageAbsQYDiff           0.544518
2017-06-11 01:43:57.528396 EDT | AverageAction              0.99536
2017-06-11 01:43:57.528740 EDT | PolicyRegParamNorm        89.8649
2017-06-11 01:43:57.529076 EDT | QFunRegParamNorm         115.88
2017-06-11 01:43:57.529415 EDT | -----------------------  ----------
2017-06-11 01:43:57.530102 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #823 | Training started
2017-06-11 01:44:13.378486 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #823 | Training finished
2017-06-11 01:44:13.380731 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #823 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 01:44:13.381062 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #823 | Collecting samples for evaluation
2017-06-11 01:44:27.742096 EDT | -----------------------  -----------
2017-06-11 01:44:27.742915 EDT | Epoch                     823
2017-06-11 01:44:27.743110 EDT | Iteration                 823
2017-06-11 01:44:27.743327 EDT | AverageReturn            1517.76
2017-06-11 01:44:27.743513 EDT | StdReturn                 680.553
2017-06-11 01:44:27.743697 EDT | MaxReturn                3086.75
2017-06-11 01:44:27.743887 EDT | MinReturn                 822.811
2017-06-11 01:44:27.744067 EDT | AverageEsReturn           283.706
2017-06-11 01:44:27.744247 EDT | StdEsReturn               290.57
2017-06-11 01:44:27.744488 EDT | MaxEsReturn               828.018
2017-06-11 01:44:27.744672 EDT | MinEsReturn                13.2483
2017-06-11 01:44:27.744859 EDT | AverageDiscountedReturn   249.082
2017-06-11 01:44:27.745038 EDT | AverageQLoss                2.24468
2017-06-11 01:44:27.745217 EDT | AveragePolicySurr         -31.2178
2017-06-11 01:44:27.745397 EDT | AverageQ                   30.8558
2017-06-11 01:44:27.745585 EDT | AverageAbsQ                30.8792
2017-06-11 01:44:27.745786 EDT | AverageY                   30.8558
2017-06-11 01:44:27.746181 EDT | AverageAbsY                30.867
2017-06-11 01:44:27.746704 EDT | AverageAbsQYDiff            0.548495
2017-06-11 01:44:27.746889 EDT | AverageAction               0.992793
2017-06-11 01:44:27.747314 EDT | PolicyRegParamNorm         89.8995
2017-06-11 01:44:27.747579 EDT | QFunRegParamNorm          115.949
2017-06-11 01:44:27.747763 EDT | -----------------------  -----------
2017-06-11 01:44:27.748336 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #824 | Training started
2017-06-11 01:44:45.170153 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #824 | Training finished
2017-06-11 01:44:45.170948 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #824 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 01:44:45.171150 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #824 | Collecting samples for evaluation
2017-06-11 01:44:58.956978 EDT | -----------------------  -----------
2017-06-11 01:44:58.958064 EDT | Epoch                     824
2017-06-11 01:44:58.958376 EDT | Iteration                 824
2017-06-11 01:44:58.958588 EDT | AverageReturn            1868.31
2017-06-11 01:44:58.958780 EDT | StdReturn                 751.962
2017-06-11 01:44:58.959055 EDT | MaxReturn                3310.22
2017-06-11 01:44:58.959249 EDT | MinReturn                 983.589
2017-06-11 01:44:58.959430 EDT | AverageEsReturn           510.144
2017-06-11 01:44:58.959667 EDT | StdEsReturn               305.173
2017-06-11 01:44:58.959849 EDT | MaxEsReturn               914.503
2017-06-11 01:44:58.960029 EDT | MinEsReturn               148.624
2017-06-11 01:44:58.960208 EDT | AverageDiscountedReturn   252.242
2017-06-11 01:44:58.960386 EDT | AverageQLoss                2.21289
2017-06-11 01:44:58.960625 EDT | AveragePolicySurr         -31.1579
2017-06-11 01:44:58.960807 EDT | AverageQ                   30.7995
2017-06-11 01:44:58.960987 EDT | AverageAbsQ                30.8244
2017-06-11 01:44:58.961166 EDT | AverageY                   30.8021
2017-06-11 01:44:58.961364 EDT | AverageAbsY                30.8149
2017-06-11 01:44:58.961604 EDT | AverageAbsQYDiff            0.536128
2017-06-11 01:44:58.961879 EDT | AverageAction               0.992346
2017-06-11 01:44:58.962209 EDT | PolicyRegParamNorm         89.9583
2017-06-11 01:44:58.962542 EDT | QFunRegParamNorm          116.016
2017-06-11 01:44:58.962877 EDT | -----------------------  -----------
2017-06-11 01:44:58.963349 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #825 | Training started
2017-06-11 01:45:15.757624 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #825 | Training finished
2017-06-11 01:45:15.758127 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #825 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 01:45:15.758496 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #825 | Collecting samples for evaluation
2017-06-11 01:45:29.107780 EDT | -----------------------  -----------
2017-06-11 01:45:29.110987 EDT | Epoch                     825
2017-06-11 01:45:29.111343 EDT | Iteration                 825
2017-06-11 01:45:29.111755 EDT | AverageReturn            1723.22
2017-06-11 01:45:29.112020 EDT | StdReturn                1053.81
2017-06-11 01:45:29.112224 EDT | MaxReturn                3480.52
2017-06-11 01:45:29.112420 EDT | MinReturn                 286.986
2017-06-11 01:45:29.112616 EDT | AverageEsReturn           372.564
2017-06-11 01:45:29.112814 EDT | StdEsReturn               276.35
2017-06-11 01:45:29.113147 EDT | MaxEsReturn               755.923
2017-06-11 01:45:29.113469 EDT | MinEsReturn                 8.7502
2017-06-11 01:45:29.113661 EDT | AverageDiscountedReturn   252.577
2017-06-11 01:45:29.113883 EDT | AverageQLoss                2.26339
2017-06-11 01:45:29.114167 EDT | AveragePolicySurr         -31.2649
2017-06-11 01:45:29.114632 EDT | AverageQ                   30.909
2017-06-11 01:45:29.114828 EDT | AverageAbsQ                30.9355
2017-06-11 01:45:29.115023 EDT | AverageY                   30.9101
2017-06-11 01:45:29.116066 EDT | AverageAbsY                30.9251
2017-06-11 01:45:29.116444 EDT | AverageAbsQYDiff            0.535418
2017-06-11 01:45:29.116809 EDT | AverageAction               0.993453
2017-06-11 01:45:29.117168 EDT | PolicyRegParamNorm         90.0333
2017-06-11 01:45:29.117511 EDT | QFunRegParamNorm          116.108
2017-06-11 01:45:29.117872 EDT | -----------------------  -----------
2017-06-11 01:45:29.118415 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #826 | Training started
2017-06-11 01:45:45.972793 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #826 | Training finished
2017-06-11 01:45:45.973156 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #826 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 01:45:45.973391 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #826 | Collecting samples for evaluation
2017-06-11 01:46:00.279250 EDT | -----------------------  -----------
2017-06-11 01:46:00.280080 EDT | Epoch                     826
2017-06-11 01:46:00.280518 EDT | Iteration                 826
2017-06-11 01:46:00.281091 EDT | AverageReturn            2547.28
2017-06-11 01:46:00.281476 EDT | StdReturn                 873.739
2017-06-11 01:46:00.281980 EDT | MaxReturn                3271.51
2017-06-11 01:46:00.282417 EDT | MinReturn                 914.54
2017-06-11 01:46:00.282839 EDT | AverageEsReturn           616.244
2017-06-11 01:46:00.284127 EDT | StdEsReturn               519.729
2017-06-11 01:46:00.284685 EDT | MaxEsReturn              1625.8
2017-06-11 01:46:00.286844 EDT | MinEsReturn               267.683
2017-06-11 01:46:00.287193 EDT | AverageDiscountedReturn   258.451
2017-06-11 01:46:00.287568 EDT | AverageQLoss                2.87249
2017-06-11 01:46:00.287898 EDT | AveragePolicySurr         -31.2213
2017-06-11 01:46:00.288259 EDT | AverageQ                   30.8759
2017-06-11 01:46:00.288566 EDT | AverageAbsQ                30.9019
2017-06-11 01:46:00.288744 EDT | AverageY                   30.878
2017-06-11 01:46:00.288940 EDT | AverageAbsY                30.8906
2017-06-11 01:46:00.289129 EDT | AverageAbsQYDiff            0.572392
2017-06-11 01:46:00.289426 EDT | AverageAction               0.992356
2017-06-11 01:46:00.289690 EDT | PolicyRegParamNorm         90.0722
2017-06-11 01:46:00.289915 EDT | QFunRegParamNorm          116.181
2017-06-11 01:46:00.290102 EDT | -----------------------  -----------
2017-06-11 01:46:00.290381 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #827 | Training started
2017-06-11 01:46:16.882493 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #827 | Training finished
2017-06-11 01:46:16.882735 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #827 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 01:46:16.882921 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #827 | Collecting samples for evaluation
2017-06-11 01:46:30.649603 EDT | -----------------------  -----------
2017-06-11 01:46:30.650727 EDT | Epoch                     827
2017-06-11 01:46:30.651096 EDT | Iteration                 827
2017-06-11 01:46:30.651436 EDT | AverageReturn             980.698
2017-06-11 01:46:30.651772 EDT | StdReturn                 364.82
2017-06-11 01:46:30.652103 EDT | MaxReturn                2514.69
2017-06-11 01:46:30.652442 EDT | MinReturn                 713.569
2017-06-11 01:46:30.652772 EDT | AverageEsReturn           415.128
2017-06-11 01:46:30.654602 EDT | StdEsReturn               226.314
2017-06-11 01:46:30.654959 EDT | MaxEsReturn               717.594
2017-06-11 01:46:30.655288 EDT | MinEsReturn                32.482
2017-06-11 01:46:30.655617 EDT | AverageDiscountedReturn   252.013
2017-06-11 01:46:30.656677 EDT | AverageQLoss                2.33654
2017-06-11 01:46:30.658829 EDT | AveragePolicySurr         -31.2618
2017-06-11 01:46:30.660318 EDT | AverageQ                   30.9159
2017-06-11 01:46:30.660991 EDT | AverageAbsQ                30.9418
2017-06-11 01:46:30.662430 EDT | AverageY                   30.9156
2017-06-11 01:46:30.664343 EDT | AverageAbsY                30.9278
2017-06-11 01:46:30.665027 EDT | AverageAbsQYDiff            0.536148
2017-06-11 01:46:30.665648 EDT | AverageAction               0.99456
2017-06-11 01:46:30.666296 EDT | PolicyRegParamNorm         90.0804
2017-06-11 01:46:30.668642 EDT | QFunRegParamNorm          116.239
2017-06-11 01:46:30.670043 EDT | -----------------------  -----------
2017-06-11 01:46:30.670855 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #828 | Training started
2017-06-11 01:46:47.855745 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #828 | Training finished
2017-06-11 01:46:47.856493 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #828 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 01:46:47.856841 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #828 | Collecting samples for evaluation
2017-06-11 01:47:01.731012 EDT | -----------------------  -----------
2017-06-11 01:47:01.732183 EDT | Epoch                     828
2017-06-11 01:47:01.732648 EDT | Iteration                 828
2017-06-11 01:47:01.733104 EDT | AverageReturn            1014.56
2017-06-11 01:47:01.733551 EDT | StdReturn                 234.357
2017-06-11 01:47:01.734017 EDT | MaxReturn                1755.92
2017-06-11 01:47:01.734464 EDT | MinReturn                 591.688
2017-06-11 01:47:01.734910 EDT | AverageEsReturn           314.437
2017-06-11 01:47:01.735356 EDT | StdEsReturn               249.884
2017-06-11 01:47:01.735800 EDT | MaxEsReturn               762.961
2017-06-11 01:47:01.736247 EDT | MinEsReturn                14.7817
2017-06-11 01:47:01.736691 EDT | AverageDiscountedReturn   227.409
2017-06-11 01:47:01.737142 EDT | AverageQLoss                2.25984
2017-06-11 01:47:01.737586 EDT | AveragePolicySurr         -31.213
2017-06-11 01:47:01.738039 EDT | AverageQ                   30.8848
2017-06-11 01:47:01.738482 EDT | AverageAbsQ                30.9075
2017-06-11 01:47:01.738921 EDT | AverageY                   30.8873
2017-06-11 01:47:01.739370 EDT | AverageAbsY                30.8961
2017-06-11 01:47:01.739814 EDT | AverageAbsQYDiff            0.551993
2017-06-11 01:47:01.740258 EDT | AverageAction               0.992774
2017-06-11 01:47:01.740700 EDT | PolicyRegParamNorm         90.1484
2017-06-11 01:47:01.741143 EDT | QFunRegParamNorm          116.338
2017-06-11 01:47:01.741586 EDT | -----------------------  -----------
2017-06-11 01:47:01.742208 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #829 | Training started
2017-06-11 01:47:18.936900 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #829 | Training finished
2017-06-11 01:47:18.938045 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #829 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 01:47:18.938610 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #829 | Collecting samples for evaluation
2017-06-11 01:47:32.896232 EDT | -----------------------  -----------
2017-06-11 01:47:32.897327 EDT | Epoch                     829
2017-06-11 01:47:32.897750 EDT | Iteration                 829
2017-06-11 01:47:32.898142 EDT | AverageReturn            1264.39
2017-06-11 01:47:32.898842 EDT | StdReturn                 456.822
2017-06-11 01:47:32.899347 EDT | MaxReturn                2936.29
2017-06-11 01:47:32.899734 EDT | MinReturn                 755.973
2017-06-11 01:47:32.900120 EDT | AverageEsReturn           618.793
2017-06-11 01:47:32.900598 EDT | StdEsReturn               487.685
2017-06-11 01:47:32.901067 EDT | MaxEsReturn              1304.97
2017-06-11 01:47:32.901540 EDT | MinEsReturn               128.778
2017-06-11 01:47:32.902892 EDT | AverageDiscountedReturn   234.737
2017-06-11 01:47:32.903457 EDT | AverageQLoss                2.31907
2017-06-11 01:47:32.904004 EDT | AveragePolicySurr         -31.2101
2017-06-11 01:47:32.904475 EDT | AverageQ                   30.8801
2017-06-11 01:47:32.905071 EDT | AverageAbsQ                30.9048
2017-06-11 01:47:32.905887 EDT | AverageY                   30.881
2017-06-11 01:47:32.906411 EDT | AverageAbsY                30.8912
2017-06-11 01:47:32.907261 EDT | AverageAbsQYDiff            0.53787
2017-06-11 01:47:32.908058 EDT | AverageAction               0.992724
2017-06-11 01:47:32.908536 EDT | PolicyRegParamNorm         90.1389
2017-06-11 01:47:32.909006 EDT | QFunRegParamNorm          116.381
2017-06-11 01:47:32.909617 EDT | -----------------------  -----------
2017-06-11 01:47:32.910229 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #830 | Training started
2017-06-11 01:47:50.259722 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #830 | Training finished
2017-06-11 01:47:50.260524 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #830 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 01:47:50.260827 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #830 | Collecting samples for evaluation
2017-06-11 01:48:04.620937 EDT | -----------------------  -----------
2017-06-11 01:48:04.621934 EDT | Epoch                     830
2017-06-11 01:48:04.622321 EDT | Iteration                 830
2017-06-11 01:48:04.622693 EDT | AverageReturn            1281.62
2017-06-11 01:48:04.623038 EDT | StdReturn                 460.098
2017-06-11 01:48:04.623368 EDT | MaxReturn                2998.56
2017-06-11 01:48:04.623696 EDT | MinReturn                 847.525
2017-06-11 01:48:04.624024 EDT | AverageEsReturn           449.363
2017-06-11 01:48:04.624349 EDT | StdEsReturn               526.554
2017-06-11 01:48:04.624678 EDT | MaxEsReturn              1351.52
2017-06-11 01:48:04.625002 EDT | MinEsReturn                18.0119
2017-06-11 01:48:04.625323 EDT | AverageDiscountedReturn   230.964
2017-06-11 01:48:04.625645 EDT | AverageQLoss                1.86694
2017-06-11 01:48:04.641902 EDT | AveragePolicySurr         -31.1786
2017-06-11 01:48:04.642327 EDT | AverageQ                   30.8539
2017-06-11 01:48:04.642671 EDT | AverageAbsQ                30.8751
2017-06-11 01:48:04.643016 EDT | AverageY                   30.8545
2017-06-11 01:48:04.643348 EDT | AverageAbsY                30.8656
2017-06-11 01:48:04.643677 EDT | AverageAbsQYDiff            0.513338
2017-06-11 01:48:04.644005 EDT | AverageAction               0.992965
2017-06-11 01:48:04.644332 EDT | PolicyRegParamNorm         90.2024
2017-06-11 01:48:04.644656 EDT | QFunRegParamNorm          116.475
2017-06-11 01:48:04.644985 EDT | -----------------------  -----------
2017-06-11 01:48:04.645482 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #831 | Training started
2017-06-11 01:48:21.300732 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #831 | Training finished
2017-06-11 01:48:21.301739 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #831 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 01:48:21.302099 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #831 | Collecting samples for evaluation
2017-06-11 01:48:35.162311 EDT | -----------------------  -----------
2017-06-11 01:48:35.163375 EDT | Epoch                     831
2017-06-11 01:48:35.163588 EDT | Iteration                 831
2017-06-11 01:48:35.163867 EDT | AverageReturn            1252.75
2017-06-11 01:48:35.164512 EDT | StdReturn                 429.678
2017-06-11 01:48:35.164725 EDT | MaxReturn                2520.21
2017-06-11 01:48:35.166642 EDT | MinReturn                 783.803
2017-06-11 01:48:35.166993 EDT | AverageEsReturn           317.869
2017-06-11 01:48:35.167465 EDT | StdEsReturn               233.376
2017-06-11 01:48:35.167757 EDT | MaxEsReturn               656.499
2017-06-11 01:48:35.168202 EDT | MinEsReturn                52.3705
2017-06-11 01:48:35.168406 EDT | AverageDiscountedReturn   226.829
2017-06-11 01:48:35.168605 EDT | AverageQLoss                1.99326
2017-06-11 01:48:35.168801 EDT | AveragePolicySurr         -31.1577
2017-06-11 01:48:35.168995 EDT | AverageQ                   30.8324
2017-06-11 01:48:35.169190 EDT | AverageAbsQ                30.8558
2017-06-11 01:48:35.169389 EDT | AverageY                   30.8339
2017-06-11 01:48:35.169583 EDT | AverageAbsY                30.8454
2017-06-11 01:48:35.169797 EDT | AverageAbsQYDiff            0.513815
2017-06-11 01:48:35.169990 EDT | AverageAction               0.9939
2017-06-11 01:48:35.170183 EDT | PolicyRegParamNorm         90.2166
2017-06-11 01:48:35.170418 EDT | QFunRegParamNorm          116.495
2017-06-11 01:48:35.170611 EDT | -----------------------  -----------
2017-06-11 01:48:35.171343 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #832 | Training started
2017-06-11 01:48:51.617535 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #832 | Training finished
2017-06-11 01:48:51.618666 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #832 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 01:48:51.620395 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #832 | Collecting samples for evaluation
2017-06-11 01:49:04.733321 EDT | -----------------------  -----------
2017-06-11 01:49:04.734152 EDT | Epoch                     832
2017-06-11 01:49:04.734538 EDT | Iteration                 832
2017-06-11 01:49:04.734960 EDT | AverageReturn             962.077
2017-06-11 01:49:04.735739 EDT | StdReturn                 227.283
2017-06-11 01:49:04.736093 EDT | MaxReturn                1688.44
2017-06-11 01:49:04.736526 EDT | MinReturn                 752.647
2017-06-11 01:49:04.739582 EDT | AverageEsReturn           471.898
2017-06-11 01:49:04.740566 EDT | StdEsReturn               252.555
2017-06-11 01:49:04.740882 EDT | MaxEsReturn               793.276
2017-06-11 01:49:04.741964 EDT | MinEsReturn               167.347
2017-06-11 01:49:04.742249 EDT | AverageDiscountedReturn   232.979
2017-06-11 01:49:04.742645 EDT | AverageQLoss                2.26607
2017-06-11 01:49:04.742973 EDT | AveragePolicySurr         -31.1946
2017-06-11 01:49:04.743316 EDT | AverageQ                   30.8484
2017-06-11 01:49:04.743643 EDT | AverageAbsQ                30.8719
2017-06-11 01:49:04.744003 EDT | AverageY                   30.8496
2017-06-11 01:49:04.744302 EDT | AverageAbsY                30.8609
2017-06-11 01:49:04.744681 EDT | AverageAbsQYDiff            0.541009
2017-06-11 01:49:04.745008 EDT | AverageAction               0.993863
2017-06-11 01:49:04.747518 EDT | PolicyRegParamNorm         90.251
2017-06-11 01:49:04.748760 EDT | QFunRegParamNorm          116.546
2017-06-11 01:49:04.749183 EDT | -----------------------  -----------
2017-06-11 01:49:04.751428 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #833 | Training started
2017-06-11 01:49:22.151026 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #833 | Training finished
2017-06-11 01:49:22.151816 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #833 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 01:49:22.152013 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #833 | Collecting samples for evaluation
2017-06-11 01:49:35.507480 EDT | -----------------------  -----------
2017-06-11 01:49:35.508383 EDT | Epoch                     833
2017-06-11 01:49:35.513277 EDT | Iteration                 833
2017-06-11 01:49:35.513604 EDT | AverageReturn            1319.82
2017-06-11 01:49:35.514106 EDT | StdReturn                 568.528
2017-06-11 01:49:35.514456 EDT | MaxReturn                2662.38
2017-06-11 01:49:35.514779 EDT | MinReturn                 737.38
2017-06-11 01:49:35.515106 EDT | AverageEsReturn           294.495
2017-06-11 01:49:35.515440 EDT | StdEsReturn               290.848
2017-06-11 01:49:35.515853 EDT | MaxEsReturn               993.199
2017-06-11 01:49:35.516634 EDT | MinEsReturn                48.1466
2017-06-11 01:49:35.516964 EDT | AverageDiscountedReturn   226.032
2017-06-11 01:49:35.517292 EDT | AverageQLoss                2.45633
2017-06-11 01:49:35.517622 EDT | AveragePolicySurr         -31.2098
2017-06-11 01:49:35.517937 EDT | AverageQ                   30.8504
2017-06-11 01:49:35.518261 EDT | AverageAbsQ                30.8715
2017-06-11 01:49:35.518603 EDT | AverageY                   30.8517
2017-06-11 01:49:35.518930 EDT | AverageAbsY                30.8641
2017-06-11 01:49:35.519258 EDT | AverageAbsQYDiff            0.55033
2017-06-11 01:49:35.519582 EDT | AverageAction               0.994067
2017-06-11 01:49:35.519916 EDT | PolicyRegParamNorm         90.371
2017-06-11 01:49:35.520248 EDT | QFunRegParamNorm          116.579
2017-06-11 01:49:35.520462 EDT | -----------------------  -----------
2017-06-11 01:49:35.520958 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #834 | Training started
2017-06-11 01:49:53.027246 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #834 | Training finished
2017-06-11 01:49:53.028076 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #834 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 01:49:53.028279 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #834 | Collecting samples for evaluation
2017-06-11 01:50:07.165960 EDT | -----------------------  -----------
2017-06-11 01:50:07.167284 EDT | Epoch                     834
2017-06-11 01:50:07.167558 EDT | Iteration                 834
2017-06-11 01:50:07.167781 EDT | AverageReturn             517.231
2017-06-11 01:50:07.167940 EDT | StdReturn                 304.007
2017-06-11 01:50:07.168094 EDT | MaxReturn                1224.93
2017-06-11 01:50:07.168256 EDT | MinReturn                 189.194
2017-06-11 01:50:07.168422 EDT | AverageEsReturn           337.735
2017-06-11 01:50:07.168575 EDT | StdEsReturn               300.482
2017-06-11 01:50:07.168754 EDT | MaxEsReturn               801.903
2017-06-11 01:50:07.168907 EDT | MinEsReturn                12.0352
2017-06-11 01:50:07.169057 EDT | AverageDiscountedReturn   171.586
2017-06-11 01:50:07.169208 EDT | AverageQLoss                1.85197
2017-06-11 01:50:07.169397 EDT | AveragePolicySurr         -31.1816
2017-06-11 01:50:07.169642 EDT | AverageQ                   30.8516
2017-06-11 01:50:07.169908 EDT | AverageAbsQ                30.8791
2017-06-11 01:50:07.170095 EDT | AverageY                   30.8522
2017-06-11 01:50:07.170249 EDT | AverageAbsY                30.8655
2017-06-11 01:50:07.170400 EDT | AverageAbsQYDiff            0.527043
2017-06-11 01:50:07.170551 EDT | AverageAction               0.994032
2017-06-11 01:50:07.170835 EDT | PolicyRegParamNorm         90.3681
2017-06-11 01:50:07.171076 EDT | QFunRegParamNorm          116.639
2017-06-11 01:50:07.171268 EDT | -----------------------  -----------
2017-06-11 01:50:07.171550 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #835 | Training started
2017-06-11 01:50:23.833452 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #835 | Training finished
2017-06-11 01:50:23.834306 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #835 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 01:50:23.834514 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #835 | Collecting samples for evaluation
2017-06-11 01:50:38.495941 EDT | -----------------------  -----------
2017-06-11 01:50:38.496831 EDT | Epoch                     835
2017-06-11 01:50:38.497122 EDT | Iteration                 835
2017-06-11 01:50:38.497395 EDT | AverageReturn            1020.85
2017-06-11 01:50:38.497765 EDT | StdReturn                 483.667
2017-06-11 01:50:38.498101 EDT | MaxReturn                2594.08
2017-06-11 01:50:38.498429 EDT | MinReturn                 165.485
2017-06-11 01:50:38.498754 EDT | AverageEsReturn           490.708
2017-06-11 01:50:38.499077 EDT | StdEsReturn               269.379
2017-06-11 01:50:38.499400 EDT | MaxEsReturn               965.146
2017-06-11 01:50:38.499721 EDT | MinEsReturn               207.706
2017-06-11 01:50:38.500041 EDT | AverageDiscountedReturn   232.413
2017-06-11 01:50:38.500360 EDT | AverageQLoss                2.56845
2017-06-11 01:50:38.500680 EDT | AveragePolicySurr         -31.1283
2017-06-11 01:50:38.501079 EDT | AverageQ                   30.7954
2017-06-11 01:50:38.501420 EDT | AverageAbsQ                30.8217
2017-06-11 01:50:38.501754 EDT | AverageY                   30.7968
2017-06-11 01:50:38.502084 EDT | AverageAbsY                30.8082
2017-06-11 01:50:38.502413 EDT | AverageAbsQYDiff            0.564033
2017-06-11 01:50:38.502737 EDT | AverageAction               0.992946
2017-06-11 01:50:38.503076 EDT | PolicyRegParamNorm         90.4638
2017-06-11 01:50:38.503401 EDT | QFunRegParamNorm          116.714
2017-06-11 01:50:38.503722 EDT | -----------------------  -----------
2017-06-11 01:50:38.504202 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #836 | Training started
2017-06-11 01:50:55.778244 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #836 | Training finished
2017-06-11 01:50:55.779100 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #836 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 01:50:55.779751 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #836 | Collecting samples for evaluation
2017-06-11 01:51:08.859208 EDT | -----------------------  -----------
2017-06-11 01:51:08.860825 EDT | Epoch                     836
2017-06-11 01:51:08.861055 EDT | Iteration                 836
2017-06-11 01:51:08.861252 EDT | AverageReturn            1815.64
2017-06-11 01:51:08.861439 EDT | StdReturn                 776.486
2017-06-11 01:51:08.861623 EDT | MaxReturn                3054.62
2017-06-11 01:51:08.861916 EDT | MinReturn                 978.857
2017-06-11 01:51:08.862231 EDT | AverageEsReturn           418.085
2017-06-11 01:51:08.862493 EDT | StdEsReturn               288.282
2017-06-11 01:51:08.862821 EDT | MaxEsReturn               980.52
2017-06-11 01:51:08.863128 EDT | MinEsReturn                76.464
2017-06-11 01:51:08.863316 EDT | AverageDiscountedReturn   248.627
2017-06-11 01:51:08.863499 EDT | AverageQLoss                2.04521
2017-06-11 01:51:08.863679 EDT | AveragePolicySurr         -31.1952
2017-06-11 01:51:08.863859 EDT | AverageQ                   30.8492
2017-06-11 01:51:08.864039 EDT | AverageAbsQ                30.8745
2017-06-11 01:51:08.864226 EDT | AverageY                   30.8485
2017-06-11 01:51:08.864403 EDT | AverageAbsY                30.8615
2017-06-11 01:51:08.864582 EDT | AverageAbsQYDiff            0.518404
2017-06-11 01:51:08.864759 EDT | AverageAction               0.993801
2017-06-11 01:51:08.864938 EDT | PolicyRegParamNorm         90.4609
2017-06-11 01:51:08.865116 EDT | QFunRegParamNorm          116.756
2017-06-11 01:51:08.865293 EDT | -----------------------  -----------
2017-06-11 01:51:08.865591 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #837 | Training started
2017-06-11 01:51:27.979295 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #837 | Training finished
2017-06-11 01:51:27.979719 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #837 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 01:51:27.980024 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #837 | Collecting samples for evaluation
2017-06-11 01:51:40.816077 EDT | -----------------------  -----------
2017-06-11 01:51:40.817114 EDT | Epoch                     837
2017-06-11 01:51:40.817493 EDT | Iteration                 837
2017-06-11 01:51:40.817859 EDT | AverageReturn            1714.59
2017-06-11 01:51:40.818204 EDT | StdReturn                 807.73
2017-06-11 01:51:40.818544 EDT | MaxReturn                2805.31
2017-06-11 01:51:40.818985 EDT | MinReturn                 789.884
2017-06-11 01:51:40.819331 EDT | AverageEsReturn           322.731
2017-06-11 01:51:40.819669 EDT | StdEsReturn               177.587
2017-06-11 01:51:40.820010 EDT | MaxEsReturn               541.286
2017-06-11 01:51:40.820351 EDT | MinEsReturn                55.1414
2017-06-11 01:51:40.820692 EDT | AverageDiscountedReturn   239.986
2017-06-11 01:51:40.821030 EDT | AverageQLoss                2.71981
2017-06-11 01:51:40.821369 EDT | AveragePolicySurr         -31.2058
2017-06-11 01:51:40.821716 EDT | AverageQ                   30.8371
2017-06-11 01:51:40.822059 EDT | AverageAbsQ                30.8597
2017-06-11 01:51:40.823210 EDT | AverageY                   30.8399
2017-06-11 01:51:40.823561 EDT | AverageAbsY                30.8526
2017-06-11 01:51:40.823904 EDT | AverageAbsQYDiff            0.568236
2017-06-11 01:51:40.824294 EDT | AverageAction               0.99325
2017-06-11 01:51:40.824640 EDT | PolicyRegParamNorm         90.5239
2017-06-11 01:51:40.825069 EDT | QFunRegParamNorm          116.814
2017-06-11 01:51:40.825433 EDT | -----------------------  -----------
2017-06-11 01:51:40.825964 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #838 | Training started
2017-06-11 01:51:57.616178 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #838 | Training finished
2017-06-11 01:51:57.616559 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #838 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 01:51:57.616770 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #838 | Collecting samples for evaluation
2017-06-11 01:52:12.231581 EDT | -----------------------  -----------
2017-06-11 01:52:12.232599 EDT | Epoch                     838
2017-06-11 01:52:12.233009 EDT | Iteration                 838
2017-06-11 01:52:12.233396 EDT | AverageReturn            1632.68
2017-06-11 01:52:12.233798 EDT | StdReturn                 712.898
2017-06-11 01:52:12.234179 EDT | MaxReturn                2984.43
2017-06-11 01:52:12.234558 EDT | MinReturn                 886.656
2017-06-11 01:52:12.234933 EDT | AverageEsReturn           269.423
2017-06-11 01:52:12.235306 EDT | StdEsReturn               470.344
2017-06-11 01:52:12.235679 EDT | MaxEsReturn              1540.71
2017-06-11 01:52:12.236050 EDT | MinEsReturn                27.3856
2017-06-11 01:52:12.236431 EDT | AverageDiscountedReturn   242.656
2017-06-11 01:52:12.236804 EDT | AverageQLoss                2.63284
2017-06-11 01:52:12.237174 EDT | AveragePolicySurr         -31.2258
2017-06-11 01:52:12.237544 EDT | AverageQ                   30.84
2017-06-11 01:52:12.237923 EDT | AverageAbsQ                30.8646
2017-06-11 01:52:12.238296 EDT | AverageY                   30.842
2017-06-11 01:52:12.238666 EDT | AverageAbsY                30.8566
2017-06-11 01:52:12.239041 EDT | AverageAbsQYDiff            0.566917
2017-06-11 01:52:12.239414 EDT | AverageAction               0.992776
2017-06-11 01:52:12.239786 EDT | PolicyRegParamNorm         90.5457
2017-06-11 01:52:12.240156 EDT | QFunRegParamNorm          116.88
2017-06-11 01:52:12.240523 EDT | -----------------------  -----------
2017-06-11 01:52:12.241061 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #839 | Training started
2017-06-11 01:52:28.352109 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #839 | Training finished
2017-06-11 01:52:28.354164 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #839 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 01:52:28.354546 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #839 | Collecting samples for evaluation
2017-06-11 01:52:43.035573 EDT | -----------------------  -----------
2017-06-11 01:52:43.036885 EDT | Epoch                     839
2017-06-11 01:52:43.037257 EDT | Iteration                 839
2017-06-11 01:52:43.037463 EDT | AverageReturn            1419.83
2017-06-11 01:52:43.037672 EDT | StdReturn                 595.742
2017-06-11 01:52:43.037891 EDT | MaxReturn                2783.99
2017-06-11 01:52:43.038274 EDT | MinReturn                 844.216
2017-06-11 01:52:43.038478 EDT | AverageEsReturn           495.797
2017-06-11 01:52:43.038767 EDT | StdEsReturn               411.731
2017-06-11 01:52:43.039182 EDT | MaxEsReturn              1268.16
2017-06-11 01:52:43.039440 EDT | MinEsReturn                30.8887
2017-06-11 01:52:43.039639 EDT | AverageDiscountedReturn   238.838
2017-06-11 01:52:43.039879 EDT | AverageQLoss                2.09191
2017-06-11 01:52:43.040074 EDT | AveragePolicySurr         -31.238
2017-06-11 01:52:43.040268 EDT | AverageQ                   30.8905
2017-06-11 01:52:43.040505 EDT | AverageAbsQ                30.9139
2017-06-11 01:52:43.040701 EDT | AverageY                   30.8907
2017-06-11 01:52:43.041085 EDT | AverageAbsY                30.9037
2017-06-11 01:52:43.041281 EDT | AverageAbsQYDiff            0.527
2017-06-11 01:52:43.043295 EDT | AverageAction               0.993675
2017-06-11 01:52:43.044904 EDT | PolicyRegParamNorm         90.6062
2017-06-11 01:52:43.045340 EDT | QFunRegParamNorm          116.964
2017-06-11 01:52:43.045672 EDT | -----------------------  -----------
2017-06-11 01:52:43.046017 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #840 | Training started
2017-06-11 01:53:00.145434 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #840 | Training finished
2017-06-11 01:53:00.145729 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #840 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 01:53:00.145906 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #840 | Collecting samples for evaluation
2017-06-11 01:53:13.479896 EDT | -----------------------  -----------
2017-06-11 01:53:13.481373 EDT | Epoch                     840
2017-06-11 01:53:13.481576 EDT | Iteration                 840
2017-06-11 01:53:13.481823 EDT | AverageReturn             906.66
2017-06-11 01:53:13.482041 EDT | StdReturn                 295.2
2017-06-11 01:53:13.483459 EDT | MaxReturn                1852.05
2017-06-11 01:53:13.483746 EDT | MinReturn                 510.051
2017-06-11 01:53:13.484018 EDT | AverageEsReturn           371.173
2017-06-11 01:53:13.484201 EDT | StdEsReturn               207.514
2017-06-11 01:53:13.484384 EDT | MaxEsReturn               599.865
2017-06-11 01:53:13.484594 EDT | MinEsReturn                77.1232
2017-06-11 01:53:13.484879 EDT | AverageDiscountedReturn   242.72
2017-06-11 01:53:13.485173 EDT | AverageQLoss                2.63486
2017-06-11 01:53:13.485453 EDT | AveragePolicySurr         -31.1989
2017-06-11 01:53:13.485705 EDT | AverageQ                   30.8649
2017-06-11 01:53:13.485963 EDT | AverageAbsQ                30.8908
2017-06-11 01:53:13.486224 EDT | AverageY                   30.8652
2017-06-11 01:53:13.486474 EDT | AverageAbsY                30.8788
2017-06-11 01:53:13.486729 EDT | AverageAbsQYDiff            0.571292
2017-06-11 01:53:13.486991 EDT | AverageAction               0.994535
2017-06-11 01:53:13.487252 EDT | PolicyRegParamNorm         90.5876
2017-06-11 01:53:13.487524 EDT | QFunRegParamNorm          117.057
2017-06-11 01:53:13.487826 EDT | -----------------------  -----------
2017-06-11 01:53:13.488269 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #841 | Training started
2017-06-11 01:53:30.729295 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #841 | Training finished
2017-06-11 01:53:30.730029 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #841 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 01:53:30.730213 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #841 | Collecting samples for evaluation
2017-06-11 01:53:44.340352 EDT | -----------------------  -----------
2017-06-11 01:53:44.341461 EDT | Epoch                     841
2017-06-11 01:53:44.341930 EDT | Iteration                 841
2017-06-11 01:53:44.342376 EDT | AverageReturn            1378.41
2017-06-11 01:53:44.342888 EDT | StdReturn                1144.54
2017-06-11 01:53:44.343327 EDT | MaxReturn                2896.57
2017-06-11 01:53:44.343762 EDT | MinReturn                  76.6644
2017-06-11 01:53:44.344199 EDT | AverageEsReturn           393.727
2017-06-11 01:53:44.344636 EDT | StdEsReturn               214.533
2017-06-11 01:53:44.345071 EDT | MaxEsReturn               635.05
2017-06-11 01:53:44.345509 EDT | MinEsReturn                36.4
2017-06-11 01:53:44.345949 EDT | AverageDiscountedReturn   184.749
2017-06-11 01:53:44.346385 EDT | AverageQLoss                2.18016
2017-06-11 01:53:44.346825 EDT | AveragePolicySurr         -31.2246
2017-06-11 01:53:44.347262 EDT | AverageQ                   30.8956
2017-06-11 01:53:44.347698 EDT | AverageAbsQ                30.9201
2017-06-11 01:53:44.348133 EDT | AverageY                   30.8966
2017-06-11 01:53:44.348565 EDT | AverageAbsY                30.9103
2017-06-11 01:53:44.349002 EDT | AverageAbsQYDiff            0.523095
2017-06-11 01:53:44.349439 EDT | AverageAction               0.992867
2017-06-11 01:53:44.349886 EDT | PolicyRegParamNorm         90.618
2017-06-11 01:53:44.350321 EDT | QFunRegParamNorm          117.13
2017-06-11 01:53:44.350756 EDT | -----------------------  -----------
2017-06-11 01:53:44.351336 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #842 | Training started
2017-06-11 01:54:02.315061 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #842 | Training finished
2017-06-11 01:54:02.319389 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #842 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 01:54:02.319808 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #842 | Collecting samples for evaluation
2017-06-11 01:54:17.813546 EDT | -----------------------  -----------
2017-06-11 01:54:17.817160 EDT | Epoch                     842
2017-06-11 01:54:17.817472 EDT | Iteration                 842
2017-06-11 01:54:17.817766 EDT | AverageReturn            2641.13
2017-06-11 01:54:17.818113 EDT | StdReturn                 515.989
2017-06-11 01:54:17.818453 EDT | MaxReturn                3056.99
2017-06-11 01:54:17.818791 EDT | MinReturn                1243.75
2017-06-11 01:54:17.819134 EDT | AverageEsReturn           335.453
2017-06-11 01:54:17.819474 EDT | StdEsReturn               325.004
2017-06-11 01:54:17.819814 EDT | MaxEsReturn               818.074
2017-06-11 01:54:17.820154 EDT | MinEsReturn                59.0741
2017-06-11 01:54:17.820495 EDT | AverageDiscountedReturn   245.232
2017-06-11 01:54:17.820835 EDT | AverageQLoss                1.91387
2017-06-11 01:54:17.821175 EDT | AveragePolicySurr         -31.1854
2017-06-11 01:54:17.821516 EDT | AverageQ                   30.8556
2017-06-11 01:54:17.821867 EDT | AverageAbsQ                30.8758
2017-06-11 01:54:17.822203 EDT | AverageY                   30.8558
2017-06-11 01:54:17.822540 EDT | AverageAbsY                30.8671
2017-06-11 01:54:17.822880 EDT | AverageAbsQYDiff            0.52414
2017-06-11 01:54:17.823223 EDT | AverageAction               0.992363
2017-06-11 01:54:17.823571 EDT | PolicyRegParamNorm         90.6406
2017-06-11 01:54:17.823909 EDT | QFunRegParamNorm          117.16
2017-06-11 01:54:17.824250 EDT | -----------------------  -----------
2017-06-11 01:54:17.824746 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #843 | Training started
2017-06-11 01:54:33.575063 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #843 | Training finished
2017-06-11 01:54:33.575968 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #843 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 01:54:33.576332 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #843 | Collecting samples for evaluation
2017-06-11 01:54:48.869254 EDT | -----------------------  -----------
2017-06-11 01:54:48.870290 EDT | Epoch                     843
2017-06-11 01:54:48.870733 EDT | Iteration                 843
2017-06-11 01:54:48.871175 EDT | AverageReturn            1822.33
2017-06-11 01:54:48.871591 EDT | StdReturn                 864.375
2017-06-11 01:54:48.871879 EDT | MaxReturn                3160.66
2017-06-11 01:54:48.872307 EDT | MinReturn                  76.783
2017-06-11 01:54:48.872731 EDT | AverageEsReturn           467.862
2017-06-11 01:54:48.873083 EDT | StdEsReturn               344.834
2017-06-11 01:54:48.873507 EDT | MaxEsReturn              1149.71
2017-06-11 01:54:48.873947 EDT | MinEsReturn                43.4268
2017-06-11 01:54:48.874304 EDT | AverageDiscountedReturn   235.458
2017-06-11 01:54:48.874714 EDT | AverageQLoss                2.19099
2017-06-11 01:54:48.875149 EDT | AveragePolicySurr         -31.2128
2017-06-11 01:54:48.875524 EDT | AverageQ                   30.8731
2017-06-11 01:54:48.875821 EDT | AverageAbsQ                30.8946
2017-06-11 01:54:48.876236 EDT | AverageY                   30.875
2017-06-11 01:54:48.876659 EDT | AverageAbsY                30.8843
2017-06-11 01:54:48.877015 EDT | AverageAbsQYDiff            0.553446
2017-06-11 01:54:48.877443 EDT | AverageAction               0.993438
2017-06-11 01:54:48.877888 EDT | PolicyRegParamNorm         90.7036
2017-06-11 01:54:48.878284 EDT | QFunRegParamNorm          117.233
2017-06-11 01:54:48.878687 EDT | -----------------------  -----------
2017-06-11 01:54:48.879250 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #844 | Training started
2017-06-11 01:55:06.954891 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #844 | Training finished
2017-06-11 01:55:06.955916 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #844 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 01:55:06.956304 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #844 | Collecting samples for evaluation
2017-06-11 01:55:21.077290 EDT | -----------------------  -----------
2017-06-11 01:55:21.078180 EDT | Epoch                     844
2017-06-11 01:55:21.078455 EDT | Iteration                 844
2017-06-11 01:55:21.078706 EDT | AverageReturn            2051
2017-06-11 01:55:21.078952 EDT | StdReturn                 645.06
2017-06-11 01:55:21.079197 EDT | MaxReturn                2794.35
2017-06-11 01:55:21.079440 EDT | MinReturn                1044.11
2017-06-11 01:55:21.079683 EDT | AverageEsReturn           607.629
2017-06-11 01:55:21.080262 EDT | StdEsReturn               178.057
2017-06-11 01:55:21.080515 EDT | MaxEsReturn               828.029
2017-06-11 01:55:21.080758 EDT | MinEsReturn               423.898
2017-06-11 01:55:21.081000 EDT | AverageDiscountedReturn   227.113
2017-06-11 01:55:21.081240 EDT | AverageQLoss                2.17059
2017-06-11 01:55:21.081480 EDT | AveragePolicySurr         -31.2633
2017-06-11 01:55:21.081727 EDT | AverageQ                   30.9108
2017-06-11 01:55:21.081971 EDT | AverageAbsQ                30.9271
2017-06-11 01:55:21.082211 EDT | AverageY                   30.9102
2017-06-11 01:55:21.082452 EDT | AverageAbsY                30.915
2017-06-11 01:55:21.082692 EDT | AverageAbsQYDiff            0.538749
2017-06-11 01:55:21.082935 EDT | AverageAction               0.993434
2017-06-11 01:55:21.083180 EDT | PolicyRegParamNorm         90.7241
2017-06-11 01:55:21.083420 EDT | QFunRegParamNorm          117.314
2017-06-11 01:55:21.083664 EDT | -----------------------  -----------
2017-06-11 01:55:21.084053 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #845 | Training started
2017-06-11 01:55:39.693558 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #845 | Training finished
2017-06-11 01:55:39.694230 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #845 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 01:55:39.694591 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #845 | Collecting samples for evaluation
2017-06-11 01:55:53.373449 EDT | -----------------------  -----------
2017-06-11 01:55:53.373931 EDT | Epoch                     845
2017-06-11 01:55:53.374289 EDT | Iteration                 845
2017-06-11 01:55:53.374646 EDT | AverageReturn            1904.37
2017-06-11 01:55:53.375005 EDT | StdReturn                 703.806
2017-06-11 01:55:53.375360 EDT | MaxReturn                2769.38
2017-06-11 01:55:53.375719 EDT | MinReturn                 794.738
2017-06-11 01:55:53.376040 EDT | AverageEsReturn           597.755
2017-06-11 01:55:53.376344 EDT | StdEsReturn               440.686
2017-06-11 01:55:53.376648 EDT | MaxEsReturn              1320.08
2017-06-11 01:55:53.376971 EDT | MinEsReturn               163.689
2017-06-11 01:55:53.377322 EDT | AverageDiscountedReturn   228.656
2017-06-11 01:55:53.377679 EDT | AverageQLoss                2.04811
2017-06-11 01:55:53.378044 EDT | AveragePolicySurr         -31.207
2017-06-11 01:55:53.378396 EDT | AverageQ                   30.8611
2017-06-11 01:55:53.378755 EDT | AverageAbsQ                30.8803
2017-06-11 01:55:53.379116 EDT | AverageY                   30.8633
2017-06-11 01:55:53.379470 EDT | AverageAbsY                30.8721
2017-06-11 01:55:53.379824 EDT | AverageAbsQYDiff            0.531908
2017-06-11 01:55:53.380175 EDT | AverageAction               0.99442
2017-06-11 01:55:53.380534 EDT | PolicyRegParamNorm         90.767
2017-06-11 01:55:53.380890 EDT | QFunRegParamNorm          117.371
2017-06-11 01:55:53.381246 EDT | -----------------------  -----------
2017-06-11 01:55:53.381750 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #846 | Training started
2017-06-11 01:56:12.599788 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #846 | Training finished
2017-06-11 01:56:12.600798 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #846 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 01:56:12.601189 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #846 | Collecting samples for evaluation
2017-06-11 01:56:26.734555 EDT | -----------------------  -----------
2017-06-11 01:56:26.735563 EDT | Epoch                     846
2017-06-11 01:56:26.735772 EDT | Iteration                 846
2017-06-11 01:56:26.735967 EDT | AverageReturn            1988.44
2017-06-11 01:56:26.736214 EDT | StdReturn                1035.21
2017-06-11 01:56:26.736416 EDT | MaxReturn                3194.48
2017-06-11 01:56:26.736653 EDT | MinReturn                 690.291
2017-06-11 01:56:26.736835 EDT | AverageEsReturn           688.788
2017-06-11 01:56:26.737072 EDT | StdEsReturn               397.416
2017-06-11 01:56:26.737255 EDT | MaxEsReturn              1318.41
2017-06-11 01:56:26.737453 EDT | MinEsReturn               250.398
2017-06-11 01:56:26.737632 EDT | AverageDiscountedReturn   240.078
2017-06-11 01:56:26.737871 EDT | AverageQLoss                1.92065
2017-06-11 01:56:26.738082 EDT | AveragePolicySurr         -31.1828
2017-06-11 01:56:26.738270 EDT | AverageQ                   30.8378
2017-06-11 01:56:26.738461 EDT | AverageAbsQ                30.8594
2017-06-11 01:56:26.738640 EDT | AverageY                   30.8388
2017-06-11 01:56:26.738819 EDT | AverageAbsY                30.8475
2017-06-11 01:56:26.739012 EDT | AverageAbsQYDiff            0.524106
2017-06-11 01:56:26.739280 EDT | AverageAction               0.99363
2017-06-11 01:56:26.739500 EDT | PolicyRegParamNorm         90.7957
2017-06-11 01:56:26.739679 EDT | QFunRegParamNorm          117.409
2017-06-11 01:56:26.739858 EDT | -----------------------  -----------
2017-06-11 01:56:26.740206 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #847 | Training started
2017-06-11 01:56:43.954190 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #847 | Training finished
2017-06-11 01:56:43.955151 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #847 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 01:56:43.955633 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #847 | Collecting samples for evaluation
2017-06-11 01:56:58.739591 EDT | -----------------------  -----------
2017-06-11 01:56:58.740768 EDT | Epoch                     847
2017-06-11 01:56:58.741238 EDT | Iteration                 847
2017-06-11 01:56:58.741689 EDT | AverageReturn            2167.56
2017-06-11 01:56:58.742148 EDT | StdReturn                 793.922
2017-06-11 01:56:58.742595 EDT | MaxReturn                3164.4
2017-06-11 01:56:58.743040 EDT | MinReturn                 720.566
2017-06-11 01:56:58.743484 EDT | AverageEsReturn           361.236
2017-06-11 01:56:58.743929 EDT | StdEsReturn               247.23
2017-06-11 01:56:58.744375 EDT | MaxEsReturn               848.681
2017-06-11 01:56:58.744826 EDT | MinEsReturn                16.5548
2017-06-11 01:56:58.745270 EDT | AverageDiscountedReturn   244.234
2017-06-11 01:56:58.745719 EDT | AverageQLoss                2.59815
2017-06-11 01:56:58.746067 EDT | AveragePolicySurr         -31.1851
2017-06-11 01:56:58.746397 EDT | AverageQ                   30.8406
2017-06-11 01:56:58.746771 EDT | AverageAbsQ                30.8669
2017-06-11 01:56:58.747199 EDT | AverageY                   30.8422
2017-06-11 01:56:58.748338 EDT | AverageAbsY                30.8527
2017-06-11 01:56:58.748788 EDT | AverageAbsQYDiff            0.563575
2017-06-11 01:56:58.749233 EDT | AverageAction               0.993271
2017-06-11 01:56:58.749680 EDT | PolicyRegParamNorm         90.8748
2017-06-11 01:56:58.750134 EDT | QFunRegParamNorm          117.455
2017-06-11 01:56:58.750588 EDT | -----------------------  -----------
2017-06-11 01:56:58.751214 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #848 | Training started
2017-06-11 01:57:15.332470 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #848 | Training finished
2017-06-11 01:57:15.341929 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #848 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 01:57:15.351108 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #848 | Collecting samples for evaluation
2017-06-11 01:57:30.117447 EDT | -----------------------  -----------
2017-06-11 01:57:30.118284 EDT | Epoch                     848
2017-06-11 01:57:30.118566 EDT | Iteration                 848
2017-06-11 01:57:30.118821 EDT | AverageReturn            2531.93
2017-06-11 01:57:30.119070 EDT | StdReturn                1010.96
2017-06-11 01:57:30.119317 EDT | MaxReturn                3283.24
2017-06-11 01:57:30.119562 EDT | MinReturn                  75.9437
2017-06-11 01:57:30.119798 EDT | AverageEsReturn           678.033
2017-06-11 01:57:30.120029 EDT | StdEsReturn               741.304
2017-06-11 01:57:30.120259 EDT | MaxEsReturn              1921.46
2017-06-11 01:57:30.120489 EDT | MinEsReturn                35.6893
2017-06-11 01:57:30.120721 EDT | AverageDiscountedReturn   238.722
2017-06-11 01:57:30.120950 EDT | AverageQLoss                2.38304
2017-06-11 01:57:30.121181 EDT | AveragePolicySurr         -31.2409
2017-06-11 01:57:30.121412 EDT | AverageQ                   30.9031
2017-06-11 01:57:30.121643 EDT | AverageAbsQ                30.9228
2017-06-11 01:57:30.121887 EDT | AverageY                   30.9045
2017-06-11 01:57:30.122123 EDT | AverageAbsY                30.9126
2017-06-11 01:57:30.122353 EDT | AverageAbsQYDiff            0.53762
2017-06-11 01:57:30.122581 EDT | AverageAction               0.993104
2017-06-11 01:57:30.122816 EDT | PolicyRegParamNorm         90.8667
2017-06-11 01:57:30.123046 EDT | QFunRegParamNorm          117.503
2017-06-11 01:57:30.123273 EDT | -----------------------  -----------
2017-06-11 01:57:30.123628 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #849 | Training started
2017-06-11 01:57:47.541430 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #849 | Training finished
2017-06-11 01:57:47.542446 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #849 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 01:57:47.542842 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #849 | Collecting samples for evaluation
2017-06-11 01:58:02.764057 EDT | -----------------------  -----------
2017-06-11 01:58:02.764961 EDT | Epoch                     849
2017-06-11 01:58:02.765271 EDT | Iteration                 849
2017-06-11 01:58:02.765558 EDT | AverageReturn             998.249
2017-06-11 01:58:02.765890 EDT | StdReturn                1093.93
2017-06-11 01:58:02.766175 EDT | MaxReturn                2948.78
2017-06-11 01:58:02.766419 EDT | MinReturn                  48.9612
2017-06-11 01:58:02.767006 EDT | AverageEsReturn           568.561
2017-06-11 01:58:02.767342 EDT | StdEsReturn               273.258
2017-06-11 01:58:02.767888 EDT | MaxEsReturn              1031.69
2017-06-11 01:58:02.768229 EDT | MinEsReturn               358.748
2017-06-11 01:58:02.768505 EDT | AverageDiscountedReturn   144.762
2017-06-11 01:58:02.768841 EDT | AverageQLoss                2.52352
2017-06-11 01:58:02.769185 EDT | AveragePolicySurr         -31.2397
2017-06-11 01:58:02.769529 EDT | AverageQ                   30.8836
2017-06-11 01:58:02.769885 EDT | AverageAbsQ                30.9095
2017-06-11 01:58:02.770228 EDT | AverageY                   30.8851
2017-06-11 01:58:02.770581 EDT | AverageAbsY                30.8964
2017-06-11 01:58:02.770931 EDT | AverageAbsQYDiff            0.567567
2017-06-11 01:58:02.771272 EDT | AverageAction               0.992983
2017-06-11 01:58:02.771535 EDT | PolicyRegParamNorm         90.9195
2017-06-11 01:58:02.771824 EDT | QFunRegParamNorm          117.508
2017-06-11 01:58:02.772141 EDT | -----------------------  -----------
2017-06-11 01:58:02.772652 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #850 | Training started
2017-06-11 01:58:20.823875 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #850 | Training finished
2017-06-11 01:58:20.824932 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #850 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 01:58:20.825345 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #850 | Collecting samples for evaluation
2017-06-11 01:58:36.039423 EDT | -----------------------  -----------
2017-06-11 01:58:36.040483 EDT | Epoch                     850
2017-06-11 01:58:36.040898 EDT | Iteration                 850
2017-06-11 01:58:36.041294 EDT | AverageReturn            1581.12
2017-06-11 01:58:36.041686 EDT | StdReturn                 768.656
2017-06-11 01:58:36.042088 EDT | MaxReturn                3531.84
2017-06-11 01:58:36.042477 EDT | MinReturn                 263.514
2017-06-11 01:58:36.042871 EDT | AverageEsReturn           329.276
2017-06-11 01:58:36.043263 EDT | StdEsReturn               317.966
2017-06-11 01:58:36.043653 EDT | MaxEsReturn               889.286
2017-06-11 01:58:36.044041 EDT | MinEsReturn                46.606
2017-06-11 01:58:36.044426 EDT | AverageDiscountedReturn   249.33
2017-06-11 01:58:36.044815 EDT | AverageQLoss                2.45246
2017-06-11 01:58:36.045203 EDT | AveragePolicySurr         -31.2106
2017-06-11 01:58:36.045588 EDT | AverageQ                   30.8631
2017-06-11 01:58:36.045989 EDT | AverageAbsQ                30.8867
2017-06-11 01:58:36.046371 EDT | AverageY                   30.8633
2017-06-11 01:58:36.046758 EDT | AverageAbsY                30.8742
2017-06-11 01:58:36.047143 EDT | AverageAbsQYDiff            0.543662
2017-06-11 01:58:36.047527 EDT | AverageAction               0.993749
2017-06-11 01:58:36.047912 EDT | PolicyRegParamNorm         90.9561
2017-06-11 01:58:36.048295 EDT | QFunRegParamNorm          117.539
2017-06-11 01:58:36.048683 EDT | -----------------------  -----------
2017-06-11 01:58:36.053810 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #851 | Training started
2017-06-11 01:58:53.362438 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #851 | Training finished
2017-06-11 01:58:53.362901 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #851 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 01:58:53.363215 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #851 | Collecting samples for evaluation
2017-06-11 01:59:08.221684 EDT | -----------------------  -----------
2017-06-11 01:59:08.223280 EDT | Epoch                     851
2017-06-11 01:59:08.223879 EDT | Iteration                 851
2017-06-11 01:59:08.224351 EDT | AverageReturn            1604.98
2017-06-11 01:59:08.224813 EDT | StdReturn                 828.926
2017-06-11 01:59:08.225170 EDT | MaxReturn                3171.2
2017-06-11 01:59:08.225716 EDT | MinReturn                  68.9617
2017-06-11 01:59:08.226096 EDT | AverageEsReturn           448.853
2017-06-11 01:59:08.226517 EDT | StdEsReturn               476.416
2017-06-11 01:59:08.226954 EDT | MaxEsReturn              1364.33
2017-06-11 01:59:08.227409 EDT | MinEsReturn                54.2007
2017-06-11 01:59:08.227842 EDT | AverageDiscountedReturn   240.206
2017-06-11 01:59:08.228284 EDT | AverageQLoss                2.31704
2017-06-11 01:59:08.228739 EDT | AveragePolicySurr         -31.1969
2017-06-11 01:59:08.229146 EDT | AverageQ                   30.8871
2017-06-11 01:59:08.229602 EDT | AverageAbsQ                30.9057
2017-06-11 01:59:08.230937 EDT | AverageY                   30.8896
2017-06-11 01:59:08.231143 EDT | AverageAbsY                30.8983
2017-06-11 01:59:08.231334 EDT | AverageAbsQYDiff            0.540608
2017-06-11 01:59:08.231510 EDT | AverageAction               0.994572
2017-06-11 01:59:08.231691 EDT | PolicyRegParamNorm         91.0248
2017-06-11 01:59:08.231888 EDT | QFunRegParamNorm          117.599
2017-06-11 01:59:08.232081 EDT | -----------------------  -----------
2017-06-11 01:59:08.232388 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #852 | Training started
2017-06-11 01:59:24.998861 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #852 | Training finished
2017-06-11 01:59:25.001569 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #852 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 01:59:25.001909 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #852 | Collecting samples for evaluation
2017-06-11 01:59:39.503542 EDT | -----------------------  -----------
2017-06-11 01:59:39.503954 EDT | Epoch                     852
2017-06-11 01:59:39.504126 EDT | Iteration                 852
2017-06-11 01:59:39.504291 EDT | AverageReturn            2287.86
2017-06-11 01:59:39.504458 EDT | StdReturn                 863.135
2017-06-11 01:59:39.504653 EDT | MaxReturn                3138.78
2017-06-11 01:59:39.504838 EDT | MinReturn                1018.81
2017-06-11 01:59:39.505020 EDT | AverageEsReturn           384.183
2017-06-11 01:59:39.505203 EDT | StdEsReturn               223.901
2017-06-11 01:59:39.505385 EDT | MaxEsReturn               717.858
2017-06-11 01:59:39.505770 EDT | MinEsReturn                59.908
2017-06-11 01:59:39.506047 EDT | AverageDiscountedReturn   259.564
2017-06-11 01:59:39.506236 EDT | AverageQLoss                2.42673
2017-06-11 01:59:39.506634 EDT | AveragePolicySurr         -31.1677
2017-06-11 01:59:39.506947 EDT | AverageQ                   30.8483
2017-06-11 01:59:39.507275 EDT | AverageAbsQ                30.875
2017-06-11 01:59:39.507623 EDT | AverageY                   30.8482
2017-06-11 01:59:39.507997 EDT | AverageAbsY                30.8624
2017-06-11 01:59:39.508359 EDT | AverageAbsQYDiff            0.550291
2017-06-11 01:59:39.508540 EDT | AverageAction               0.992639
2017-06-11 01:59:39.508728 EDT | PolicyRegParamNorm         91.0801
2017-06-11 01:59:39.509071 EDT | QFunRegParamNorm          117.712
2017-06-11 01:59:39.509247 EDT | -----------------------  -----------
2017-06-11 01:59:39.509553 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #853 | Training started
2017-06-11 01:59:57.172807 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #853 | Training finished
2017-06-11 01:59:57.173846 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #853 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 01:59:57.174268 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #853 | Collecting samples for evaluation
2017-06-11 02:00:09.896083 EDT | -----------------------  -----------
2017-06-11 02:00:09.896714 EDT | Epoch                     853
2017-06-11 02:00:09.897167 EDT | Iteration                 853
2017-06-11 02:00:09.897616 EDT | AverageReturn             654.119
2017-06-11 02:00:09.898088 EDT | StdReturn                 362.656
2017-06-11 02:00:09.898537 EDT | MaxReturn                1963.01
2017-06-11 02:00:09.898984 EDT | MinReturn                  55.5163
2017-06-11 02:00:09.899426 EDT | AverageEsReturn           240.76
2017-06-11 02:00:09.899879 EDT | StdEsReturn               197.955
2017-06-11 02:00:09.900321 EDT | MaxEsReturn               651.749
2017-06-11 02:00:09.900764 EDT | MinEsReturn                64.6134
2017-06-11 02:00:09.901208 EDT | AverageDiscountedReturn   187.683
2017-06-11 02:00:09.901651 EDT | AverageQLoss                2.43318
2017-06-11 02:00:09.902117 EDT | AveragePolicySurr         -31.0761
2017-06-11 02:00:09.902562 EDT | AverageQ                   30.7502
2017-06-11 02:00:09.903004 EDT | AverageAbsQ                30.7739
2017-06-11 02:00:09.903449 EDT | AverageY                   30.7526
2017-06-11 02:00:09.903890 EDT | AverageAbsY                30.7639
2017-06-11 02:00:09.904333 EDT | AverageAbsQYDiff            0.561233
2017-06-11 02:00:09.904774 EDT | AverageAction               0.99348
2017-06-11 02:00:09.905215 EDT | PolicyRegParamNorm         91.1177
2017-06-11 02:00:09.905656 EDT | QFunRegParamNorm          117.807
2017-06-11 02:00:09.910219 EDT | -----------------------  -----------
2017-06-11 02:00:09.910838 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #854 | Training started
2017-06-11 02:00:27.409349 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #854 | Training finished
2017-06-11 02:00:27.410776 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #854 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 02:00:27.411177 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #854 | Collecting samples for evaluation
2017-06-11 02:00:40.960421 EDT | -----------------------  -----------
2017-06-11 02:00:40.961278 EDT | Epoch                     854
2017-06-11 02:00:40.961560 EDT | Iteration                 854
2017-06-11 02:00:40.961864 EDT | AverageReturn            1019.56
2017-06-11 02:00:40.962133 EDT | StdReturn                 733.54
2017-06-11 02:00:40.962400 EDT | MaxReturn                3090.13
2017-06-11 02:00:40.962665 EDT | MinReturn                  80.8439
2017-06-11 02:00:40.962949 EDT | AverageEsReturn           440.564
2017-06-11 02:00:40.963214 EDT | StdEsReturn               401.801
2017-06-11 02:00:40.963477 EDT | MaxEsReturn              1176.92
2017-06-11 02:00:40.963741 EDT | MinEsReturn                24.2322
2017-06-11 02:00:40.964021 EDT | AverageDiscountedReturn   216.33
2017-06-11 02:00:40.964284 EDT | AverageQLoss                2.39728
2017-06-11 02:00:40.964549 EDT | AveragePolicySurr         -31.0589
2017-06-11 02:00:40.964811 EDT | AverageQ                   30.7333
2017-06-11 02:00:40.965088 EDT | AverageAbsQ                30.7587
2017-06-11 02:00:40.965350 EDT | AverageY                   30.734
2017-06-11 02:00:40.965611 EDT | AverageAbsY                30.7466
2017-06-11 02:00:40.965895 EDT | AverageAbsQYDiff            0.549174
2017-06-11 02:00:40.966162 EDT | AverageAction               0.993974
2017-06-11 02:00:40.966425 EDT | PolicyRegParamNorm         91.1115
2017-06-11 02:00:40.966688 EDT | QFunRegParamNorm          117.895
2017-06-11 02:00:40.966962 EDT | -----------------------  -----------
2017-06-11 02:00:40.967369 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #855 | Training started
2017-06-11 02:00:58.624025 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #855 | Training finished
2017-06-11 02:00:58.624826 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #855 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 02:00:58.625042 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #855 | Collecting samples for evaluation
2017-06-11 02:01:12.999909 EDT | -----------------------  -----------
2017-06-11 02:01:13.000737 EDT | Epoch                     855
2017-06-11 02:01:13.000969 EDT | Iteration                 855
2017-06-11 02:01:13.001381 EDT | AverageReturn            1030.73
2017-06-11 02:01:13.001665 EDT | StdReturn                 567.716
2017-06-11 02:01:13.001944 EDT | MaxReturn                3319.88
2017-06-11 02:01:13.002189 EDT | MinReturn                 494.138
2017-06-11 02:01:13.002429 EDT | AverageEsReturn           337.596
2017-06-11 02:01:13.002665 EDT | StdEsReturn               262.565
2017-06-11 02:01:13.002905 EDT | MaxEsReturn               844.789
2017-06-11 02:01:13.003169 EDT | MinEsReturn                61.2772
2017-06-11 02:01:13.003341 EDT | AverageDiscountedReturn   248.317
2017-06-11 02:01:13.003610 EDT | AverageQLoss                2.03477
2017-06-11 02:01:13.003858 EDT | AveragePolicySurr         -31.1523
2017-06-11 02:01:13.004103 EDT | AverageQ                   30.8166
2017-06-11 02:01:13.004368 EDT | AverageAbsQ                30.8459
2017-06-11 02:01:13.004617 EDT | AverageY                   30.8173
2017-06-11 02:01:13.004863 EDT | AverageAbsY                30.8318
2017-06-11 02:01:13.005107 EDT | AverageAbsQYDiff            0.518936
2017-06-11 02:01:13.005351 EDT | AverageAction               0.995407
2017-06-11 02:01:13.005606 EDT | PolicyRegParamNorm         91.18
2017-06-11 02:01:13.005871 EDT | QFunRegParamNorm          117.945
2017-06-11 02:01:13.006129 EDT | -----------------------  -----------
2017-06-11 02:01:13.006514 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #856 | Training started
2017-06-11 02:01:29.299134 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #856 | Training finished
2017-06-11 02:01:29.300529 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #856 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 02:01:29.300737 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #856 | Collecting samples for evaluation
2017-06-11 02:01:42.947480 EDT | -----------------------  -----------
2017-06-11 02:01:42.948296 EDT | Epoch                     856
2017-06-11 02:01:42.948566 EDT | Iteration                 856
2017-06-11 02:01:42.948812 EDT | AverageReturn            1664.57
2017-06-11 02:01:42.949068 EDT | StdReturn                 827.39
2017-06-11 02:01:42.949316 EDT | MaxReturn                2919.43
2017-06-11 02:01:42.949556 EDT | MinReturn                 772.181
2017-06-11 02:01:42.949816 EDT | AverageEsReturn           570.032
2017-06-11 02:01:42.950055 EDT | StdEsReturn               398.272
2017-06-11 02:01:42.950317 EDT | MaxEsReturn              1030.64
2017-06-11 02:01:42.950556 EDT | MinEsReturn                73.9227
2017-06-11 02:01:42.950798 EDT | AverageDiscountedReturn   238.714
2017-06-11 02:01:42.951032 EDT | AverageQLoss                2.48286
2017-06-11 02:01:42.951292 EDT | AveragePolicySurr         -30.988
2017-06-11 02:01:42.951532 EDT | AverageQ                   30.6613
2017-06-11 02:01:42.951770 EDT | AverageAbsQ                30.696
2017-06-11 02:01:42.952007 EDT | AverageY                   30.6618
2017-06-11 02:01:42.952774 EDT | AverageAbsY                30.6812
2017-06-11 02:01:42.953019 EDT | AverageAbsQYDiff            0.558072
2017-06-11 02:01:42.953255 EDT | AverageAction               0.992507
2017-06-11 02:01:42.967153 EDT | PolicyRegParamNorm         91.2297
2017-06-11 02:01:42.967423 EDT | QFunRegParamNorm          118.029
2017-06-11 02:01:42.967679 EDT | -----------------------  -----------
2017-06-11 02:01:42.968086 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #857 | Training started
2017-06-11 02:02:00.494689 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #857 | Training finished
2017-06-11 02:02:00.495645 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #857 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 02:02:00.496055 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #857 | Collecting samples for evaluation
2017-06-11 02:02:15.062578 EDT | -----------------------  -----------
2017-06-11 02:02:15.062986 EDT | Epoch                     857
2017-06-11 02:02:15.063269 EDT | Iteration                 857
2017-06-11 02:02:15.063513 EDT | AverageReturn            1978.84
2017-06-11 02:02:15.063708 EDT | StdReturn                 951.731
2017-06-11 02:02:15.063928 EDT | MaxReturn                2888.79
2017-06-11 02:02:15.064160 EDT | MinReturn                 285.639
2017-06-11 02:02:15.064312 EDT | AverageEsReturn           379.316
2017-06-11 02:02:15.064462 EDT | StdEsReturn               161.847
2017-06-11 02:02:15.064618 EDT | MaxEsReturn               691.899
2017-06-11 02:02:15.064776 EDT | MinEsReturn               246.225
2017-06-11 02:02:15.064933 EDT | AverageDiscountedReturn   220.391
2017-06-11 02:02:15.065090 EDT | AverageQLoss                2.27214
2017-06-11 02:02:15.065247 EDT | AveragePolicySurr         -31.0983
2017-06-11 02:02:15.065403 EDT | AverageQ                   30.7769
2017-06-11 02:02:15.065559 EDT | AverageAbsQ                30.8068
2017-06-11 02:02:15.065825 EDT | AverageY                   30.7781
2017-06-11 02:02:15.065988 EDT | AverageAbsY                30.7953
2017-06-11 02:02:15.066145 EDT | AverageAbsQYDiff            0.545914
2017-06-11 02:02:15.066301 EDT | AverageAction               0.992953
2017-06-11 02:02:15.066467 EDT | PolicyRegParamNorm         91.2755
2017-06-11 02:02:15.066648 EDT | QFunRegParamNorm          118.104
2017-06-11 02:02:15.066845 EDT | -----------------------  -----------
2017-06-11 02:02:15.067135 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #858 | Training started
2017-06-11 02:02:32.170139 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #858 | Training finished
2017-06-11 02:02:32.171048 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #858 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 02:02:32.171498 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #858 | Collecting samples for evaluation
2017-06-11 02:02:46.412173 EDT | -----------------------  -----------
2017-06-11 02:02:46.412679 EDT | Epoch                     858
2017-06-11 02:02:46.412867 EDT | Iteration                 858
2017-06-11 02:02:46.413203 EDT | AverageReturn             651.94
2017-06-11 02:02:46.413383 EDT | StdReturn                 513.464
2017-06-11 02:02:46.413610 EDT | MaxReturn                3007.13
2017-06-11 02:02:46.413819 EDT | MinReturn                 261.483
2017-06-11 02:02:46.414176 EDT | AverageEsReturn           450.44
2017-06-11 02:02:46.414538 EDT | StdEsReturn               138.375
2017-06-11 02:02:46.414758 EDT | MaxEsReturn               578.48
2017-06-11 02:02:46.414944 EDT | MinEsReturn               258.257
2017-06-11 02:02:46.415228 EDT | AverageDiscountedReturn   196.666
2017-06-11 02:02:46.415406 EDT | AverageQLoss                2.51798
2017-06-11 02:02:46.415592 EDT | AveragePolicySurr         -31.0717
2017-06-11 02:02:46.415772 EDT | AverageQ                   30.738
2017-06-11 02:02:46.415950 EDT | AverageAbsQ                30.7632
2017-06-11 02:02:46.416131 EDT | AverageY                   30.7407
2017-06-11 02:02:46.416315 EDT | AverageAbsY                30.7552
2017-06-11 02:02:46.416495 EDT | AverageAbsQYDiff            0.552493
2017-06-11 02:02:46.416771 EDT | AverageAction               0.993487
2017-06-11 02:02:46.416998 EDT | PolicyRegParamNorm         91.3542
2017-06-11 02:02:46.417228 EDT | QFunRegParamNorm          118.123
2017-06-11 02:02:46.417410 EDT | -----------------------  -----------
2017-06-11 02:02:46.417719 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #859 | Training started
2017-06-11 02:03:04.267816 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #859 | Training finished
2017-06-11 02:03:04.268682 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #859 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 02:03:04.268949 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #859 | Collecting samples for evaluation
2017-06-11 02:03:18.258653 EDT | -----------------------  -----------
2017-06-11 02:03:18.259401 EDT | Epoch                     859
2017-06-11 02:03:18.259764 EDT | Iteration                 859
2017-06-11 02:03:18.260111 EDT | AverageReturn             563.061
2017-06-11 02:03:18.260451 EDT | StdReturn                 144.64
2017-06-11 02:03:18.260731 EDT | MaxReturn                1063.7
2017-06-11 02:03:18.261045 EDT | MinReturn                 431.156
2017-06-11 02:03:18.261383 EDT | AverageEsReturn           657.978
2017-06-11 02:03:18.261742 EDT | StdEsReturn               573.709
2017-06-11 02:03:18.262074 EDT | MaxEsReturn              1990.24
2017-06-11 02:03:18.262374 EDT | MinEsReturn                57.829
2017-06-11 02:03:18.262654 EDT | AverageDiscountedReturn   217.988
2017-06-11 02:03:18.262978 EDT | AverageQLoss                2.22331
2017-06-11 02:03:18.263308 EDT | AveragePolicySurr         -31.1055
2017-06-11 02:03:18.263635 EDT | AverageQ                   30.7774
2017-06-11 02:03:18.263909 EDT | AverageAbsQ                30.7976
2017-06-11 02:03:18.264214 EDT | AverageY                   30.7771
2017-06-11 02:03:18.264532 EDT | AverageAbsY                30.7866
2017-06-11 02:03:18.264866 EDT | AverageAbsQYDiff            0.532278
2017-06-11 02:03:18.265186 EDT | AverageAction               0.995918
2017-06-11 02:03:18.265460 EDT | PolicyRegParamNorm         91.3892
2017-06-11 02:03:18.265794 EDT | QFunRegParamNorm          118.191
2017-06-11 02:03:18.266124 EDT | -----------------------  -----------
2017-06-11 02:03:18.266619 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #860 | Training started
2017-06-11 02:03:34.255974 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #860 | Training finished
2017-06-11 02:03:34.256791 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #860 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 02:03:34.257086 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #860 | Collecting samples for evaluation
2017-06-11 02:03:47.832463 EDT | -----------------------  -----------
2017-06-11 02:03:47.832974 EDT | Epoch                     860
2017-06-11 02:03:47.833328 EDT | Iteration                 860
2017-06-11 02:03:47.833674 EDT | AverageReturn             285.44
2017-06-11 02:03:47.834031 EDT | StdReturn                  39.1093
2017-06-11 02:03:47.834375 EDT | MaxReturn                 616.866
2017-06-11 02:03:47.834716 EDT | MinReturn                 252.03
2017-06-11 02:03:47.835062 EDT | AverageEsReturn           514.603
2017-06-11 02:03:47.835450 EDT | StdEsReturn               472.267
2017-06-11 02:03:47.835800 EDT | MaxEsReturn              1457.41
2017-06-11 02:03:47.836141 EDT | MinEsReturn               241.566
2017-06-11 02:03:47.836485 EDT | AverageDiscountedReturn   150.036
2017-06-11 02:03:47.836835 EDT | AverageQLoss                2.21658
2017-06-11 02:03:47.837180 EDT | AveragePolicySurr         -31.1543
2017-06-11 02:03:47.837523 EDT | AverageQ                   30.8048
2017-06-11 02:03:47.837877 EDT | AverageAbsQ                30.8281
2017-06-11 02:03:47.840657 EDT | AverageY                   30.8068
2017-06-11 02:03:47.841742 EDT | AverageAbsY                30.8151
2017-06-11 02:03:47.842101 EDT | AverageAbsQYDiff            0.539634
2017-06-11 02:03:47.843631 EDT | AverageAction               0.99425
2017-06-11 02:03:47.845708 EDT | PolicyRegParamNorm         91.4258
2017-06-11 02:03:47.846083 EDT | QFunRegParamNorm          118.236
2017-06-11 02:03:47.847888 EDT | -----------------------  -----------
2017-06-11 02:03:47.848439 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #861 | Training started
2017-06-11 02:04:04.768226 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #861 | Training finished
2017-06-11 02:04:04.769146 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #861 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 02:04:04.769525 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #861 | Collecting samples for evaluation
2017-06-11 02:04:18.686962 EDT | -----------------------  -----------
2017-06-11 02:04:18.687760 EDT | Epoch                     861
2017-06-11 02:04:18.687956 EDT | Iteration                 861
2017-06-11 02:04:18.688124 EDT | AverageReturn             521.327
2017-06-11 02:04:18.688292 EDT | StdReturn                 658.744
2017-06-11 02:04:18.688478 EDT | MaxReturn                3040.54
2017-06-11 02:04:18.688639 EDT | MinReturn                 258.743
2017-06-11 02:04:18.688798 EDT | AverageEsReturn           444.99
2017-06-11 02:04:18.688994 EDT | StdEsReturn               275.707
2017-06-11 02:04:18.689179 EDT | MaxEsReturn               855.951
2017-06-11 02:04:18.689355 EDT | MinEsReturn               188.129
2017-06-11 02:04:18.689520 EDT | AverageDiscountedReturn   165.318
2017-06-11 02:04:18.689720 EDT | AverageQLoss                2.90554
2017-06-11 02:04:18.689898 EDT | AveragePolicySurr         -31.0585
2017-06-11 02:04:18.690059 EDT | AverageQ                   30.7117
2017-06-11 02:04:18.690224 EDT | AverageAbsQ                30.7352
2017-06-11 02:04:18.690482 EDT | AverageY                   30.7138
2017-06-11 02:04:18.690659 EDT | AverageAbsY                30.7246
2017-06-11 02:04:18.690927 EDT | AverageAbsQYDiff            0.573716
2017-06-11 02:04:18.691192 EDT | AverageAction               0.994361
2017-06-11 02:04:18.691349 EDT | PolicyRegParamNorm         91.4283
2017-06-11 02:04:18.691505 EDT | QFunRegParamNorm          118.321
2017-06-11 02:04:18.691711 EDT | -----------------------  -----------
2017-06-11 02:04:18.692005 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #862 | Training started
2017-06-11 02:04:36.648060 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #862 | Training finished
2017-06-11 02:04:36.648956 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #862 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 02:04:36.649182 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #862 | Collecting samples for evaluation
2017-06-11 02:04:50.730962 EDT | -----------------------  ----------
2017-06-11 02:04:50.731854 EDT | Epoch                     862
2017-06-11 02:04:50.734851 EDT | Iteration                 862
2017-06-11 02:04:50.735243 EDT | AverageReturn            2777.07
2017-06-11 02:04:50.735622 EDT | StdReturn                 871.572
2017-06-11 02:04:50.735954 EDT | MaxReturn                3348.67
2017-06-11 02:04:50.736290 EDT | MinReturn                 317.117
2017-06-11 02:04:50.736660 EDT | AverageEsReturn           414.267
2017-06-11 02:04:50.737029 EDT | StdEsReturn               246.809
2017-06-11 02:04:50.737351 EDT | MaxEsReturn               704.446
2017-06-11 02:04:50.737681 EDT | MinEsReturn               140.303
2017-06-11 02:04:50.738080 EDT | AverageDiscountedReturn   236.445
2017-06-11 02:04:50.738450 EDT | AverageQLoss                2.3979
2017-06-11 02:04:50.738764 EDT | AveragePolicySurr         -31.1133
2017-06-11 02:04:50.739106 EDT | AverageQ                   30.7494
2017-06-11 02:04:50.739475 EDT | AverageAbsQ                30.7739
2017-06-11 02:04:50.739841 EDT | AverageY                   30.7513
2017-06-11 02:04:50.740150 EDT | AverageAbsY                30.7615
2017-06-11 02:04:50.740509 EDT | AverageAbsQYDiff            0.54602
2017-06-11 02:04:50.740875 EDT | AverageAction               0.99355
2017-06-11 02:04:50.741241 EDT | PolicyRegParamNorm         91.4795
2017-06-11 02:04:50.741550 EDT | QFunRegParamNorm          118.368
2017-06-11 02:04:50.741927 EDT | -----------------------  ----------
2017-06-11 02:04:50.742479 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #863 | Training started
2017-06-11 02:05:07.914809 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #863 | Training finished
2017-06-11 02:05:07.915790 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #863 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 02:05:07.916212 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #863 | Collecting samples for evaluation
2017-06-11 02:05:21.491190 EDT | -----------------------  -----------
2017-06-11 02:05:21.491459 EDT | Epoch                     863
2017-06-11 02:05:21.491679 EDT | Iteration                 863
2017-06-11 02:05:21.491907 EDT | AverageReturn            1859.91
2017-06-11 02:05:21.492073 EDT | StdReturn                1167.09
2017-06-11 02:05:21.492236 EDT | MaxReturn                3588.08
2017-06-11 02:05:21.492453 EDT | MinReturn                 770.392
2017-06-11 02:05:21.492650 EDT | AverageEsReturn           367.878
2017-06-11 02:05:21.492848 EDT | StdEsReturn               203.641
2017-06-11 02:05:21.493165 EDT | MaxEsReturn               582.296
2017-06-11 02:05:21.493449 EDT | MinEsReturn                27.6541
2017-06-11 02:05:21.493643 EDT | AverageDiscountedReturn   247.408
2017-06-11 02:05:21.493846 EDT | AverageQLoss                2.12065
2017-06-11 02:05:21.494009 EDT | AveragePolicySurr         -31.1618
2017-06-11 02:05:21.494170 EDT | AverageQ                   30.8057
2017-06-11 02:05:21.494388 EDT | AverageAbsQ                30.8296
2017-06-11 02:05:21.494570 EDT | AverageY                   30.8062
2017-06-11 02:05:21.494859 EDT | AverageAbsY                30.8182
2017-06-11 02:05:21.495022 EDT | AverageAbsQYDiff            0.522789
2017-06-11 02:05:21.495183 EDT | AverageAction               0.994802
2017-06-11 02:05:21.495388 EDT | PolicyRegParamNorm         91.4426
2017-06-11 02:05:21.495617 EDT | QFunRegParamNorm          118.453
2017-06-11 02:05:21.495781 EDT | -----------------------  -----------
2017-06-11 02:05:21.496027 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #864 | Training started
2017-06-11 02:05:38.631783 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #864 | Training finished
2017-06-11 02:05:38.645495 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #864 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 02:05:38.647157 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #864 | Collecting samples for evaluation
2017-06-11 02:05:52.399596 EDT | -----------------------  -----------
2017-06-11 02:05:52.399966 EDT | Epoch                     864
2017-06-11 02:05:52.400184 EDT | Iteration                 864
2017-06-11 02:05:52.400407 EDT | AverageReturn            1628.32
2017-06-11 02:05:52.400592 EDT | StdReturn                1432.76
2017-06-11 02:05:52.400785 EDT | MaxReturn                3391.22
2017-06-11 02:05:52.401077 EDT | MinReturn                 273.886
2017-06-11 02:05:52.401366 EDT | AverageEsReturn           386.918
2017-06-11 02:05:52.401633 EDT | StdEsReturn               370.225
2017-06-11 02:05:52.401935 EDT | MaxEsReturn              1208.98
2017-06-11 02:05:52.402116 EDT | MinEsReturn                72.7058
2017-06-11 02:05:52.402297 EDT | AverageDiscountedReturn   199.783
2017-06-11 02:05:52.402543 EDT | AverageQLoss                2.37382
2017-06-11 02:05:52.402841 EDT | AveragePolicySurr         -30.9955
2017-06-11 02:05:52.403128 EDT | AverageQ                   30.6971
2017-06-11 02:05:52.403393 EDT | AverageAbsQ                30.7176
2017-06-11 02:05:52.403670 EDT | AverageY                   30.6978
2017-06-11 02:05:52.403925 EDT | AverageAbsY                30.7116
2017-06-11 02:05:52.404114 EDT | AverageAbsQYDiff            0.533107
2017-06-11 02:05:52.407331 EDT | AverageAction               0.994247
2017-06-11 02:05:52.408570 EDT | PolicyRegParamNorm         91.508
2017-06-11 02:05:52.409328 EDT | QFunRegParamNorm          118.519
2017-06-11 02:05:52.409525 EDT | -----------------------  -----------
2017-06-11 02:05:52.409896 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #865 | Training started
2017-06-11 02:06:08.985530 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #865 | Training finished
2017-06-11 02:06:08.986408 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #865 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 02:06:08.986797 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #865 | Collecting samples for evaluation
2017-06-11 02:06:23.005372 EDT | -----------------------  -----------
2017-06-11 02:06:23.006033 EDT | Epoch                     865
2017-06-11 02:06:23.006505 EDT | Iteration                 865
2017-06-11 02:06:23.006950 EDT | AverageReturn            1733.54
2017-06-11 02:06:23.012758 EDT | StdReturn                1270.01
2017-06-11 02:06:23.014196 EDT | MaxReturn                3368.24
2017-06-11 02:06:23.014728 EDT | MinReturn                 265.475
2017-06-11 02:06:23.015178 EDT | AverageEsReturn           260.581
2017-06-11 02:06:23.015627 EDT | StdEsReturn               178.169
2017-06-11 02:06:23.016394 EDT | MaxEsReturn               537.056
2017-06-11 02:06:23.016848 EDT | MinEsReturn                19.5935
2017-06-11 02:06:23.017295 EDT | AverageDiscountedReturn   211.848
2017-06-11 02:06:23.017745 EDT | AverageQLoss                2.07145
2017-06-11 02:06:23.018192 EDT | AveragePolicySurr         -31.0241
2017-06-11 02:06:23.018637 EDT | AverageQ                   30.716
2017-06-11 02:06:23.019079 EDT | AverageAbsQ                30.7461
2017-06-11 02:06:23.019516 EDT | AverageY                   30.7156
2017-06-11 02:06:23.019959 EDT | AverageAbsY                30.7317
2017-06-11 02:06:23.020402 EDT | AverageAbsQYDiff            0.516071
2017-06-11 02:06:23.020844 EDT | AverageAction               0.993622
2017-06-11 02:06:23.021287 EDT | PolicyRegParamNorm         91.5801
2017-06-11 02:06:23.021732 EDT | QFunRegParamNorm          118.623
2017-06-11 02:06:23.022178 EDT | -----------------------  -----------
2017-06-11 02:06:23.024788 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #866 | Training started
2017-06-11 02:06:40.175511 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #866 | Training finished
2017-06-11 02:06:40.178308 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #866 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 02:06:40.178540 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #866 | Collecting samples for evaluation
2017-06-11 02:06:53.635847 EDT | -----------------------  -----------
2017-06-11 02:06:53.636498 EDT | Epoch                     866
2017-06-11 02:06:53.636967 EDT | Iteration                 866
2017-06-11 02:06:53.637473 EDT | AverageReturn            2873.84
2017-06-11 02:06:53.637936 EDT | StdReturn                 660.837
2017-06-11 02:06:53.638291 EDT | MaxReturn                3402.39
2017-06-11 02:06:53.638736 EDT | MinReturn                 824.443
2017-06-11 02:06:53.639184 EDT | AverageEsReturn           623.642
2017-06-11 02:06:53.639540 EDT | StdEsReturn               747.837
2017-06-11 02:06:53.639895 EDT | MaxEsReturn              1907.09
2017-06-11 02:06:53.640339 EDT | MinEsReturn                31.0995
2017-06-11 02:06:53.640696 EDT | AverageDiscountedReturn   239.273
2017-06-11 02:06:53.641057 EDT | AverageQLoss                2.44446
2017-06-11 02:06:53.641499 EDT | AveragePolicySurr         -31.0517
2017-06-11 02:06:53.641934 EDT | AverageQ                   30.7308
2017-06-11 02:06:53.642302 EDT | AverageAbsQ                30.7572
2017-06-11 02:06:53.657831 EDT | AverageY                   30.7315
2017-06-11 02:06:53.658271 EDT | AverageAbsY                30.746
2017-06-11 02:06:53.658639 EDT | AverageAbsQYDiff            0.543063
2017-06-11 02:06:53.658989 EDT | AverageAction               0.992587
2017-06-11 02:06:53.659358 EDT | PolicyRegParamNorm         91.637
2017-06-11 02:06:53.659709 EDT | QFunRegParamNorm          118.683
2017-06-11 02:06:53.660055 EDT | -----------------------  -----------
2017-06-11 02:06:53.660576 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #867 | Training started
2017-06-11 02:07:12.848639 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #867 | Training finished
2017-06-11 02:07:12.849750 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #867 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 02:07:12.850247 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #867 | Collecting samples for evaluation
2017-06-11 02:07:27.136480 EDT | -----------------------  -----------
2017-06-11 02:07:27.139477 EDT | Epoch                     867
2017-06-11 02:07:27.139823 EDT | Iteration                 867
2017-06-11 02:07:27.140134 EDT | AverageReturn            1102.62
2017-06-11 02:07:27.140438 EDT | StdReturn                 222.769
2017-06-11 02:07:27.140765 EDT | MaxReturn                1597.78
2017-06-11 02:07:27.141149 EDT | MinReturn                 682.737
2017-06-11 02:07:27.141541 EDT | AverageEsReturn           470.181
2017-06-11 02:07:27.141948 EDT | StdEsReturn               272.37
2017-06-11 02:07:27.142341 EDT | MaxEsReturn               911.369
2017-06-11 02:07:27.142736 EDT | MinEsReturn               207.569
2017-06-11 02:07:27.143130 EDT | AverageDiscountedReturn   241.151
2017-06-11 02:07:27.143521 EDT | AverageQLoss                2.36446
2017-06-11 02:07:27.143916 EDT | AveragePolicySurr         -31.0904
2017-06-11 02:07:27.144307 EDT | AverageQ                   30.7435
2017-06-11 02:07:27.144696 EDT | AverageAbsQ                30.7693
2017-06-11 02:07:27.145083 EDT | AverageY                   30.7438
2017-06-11 02:07:27.145474 EDT | AverageAbsY                30.7585
2017-06-11 02:07:27.145931 EDT | AverageAbsQYDiff            0.551229
2017-06-11 02:07:27.146317 EDT | AverageAction               0.994528
2017-06-11 02:07:27.146704 EDT | PolicyRegParamNorm         91.6755
2017-06-11 02:07:27.147077 EDT | QFunRegParamNorm          118.767
2017-06-11 02:07:27.147448 EDT | -----------------------  -----------
2017-06-11 02:07:27.147976 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #868 | Training started
2017-06-11 02:07:45.337400 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #868 | Training finished
2017-06-11 02:07:45.338238 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #868 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 02:07:45.338650 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #868 | Collecting samples for evaluation
2017-06-11 02:08:00.479059 EDT | -----------------------  -----------
2017-06-11 02:08:00.480145 EDT | Epoch                     868
2017-06-11 02:08:00.480619 EDT | Iteration                 868
2017-06-11 02:08:00.481066 EDT | AverageReturn            1204.53
2017-06-11 02:08:00.481523 EDT | StdReturn                 154.64
2017-06-11 02:08:00.481989 EDT | MaxReturn                1469.93
2017-06-11 02:08:00.482439 EDT | MinReturn                 770.557
2017-06-11 02:08:00.482884 EDT | AverageEsReturn           673.771
2017-06-11 02:08:00.483326 EDT | StdEsReturn               349.637
2017-06-11 02:08:00.483778 EDT | MaxEsReturn              1351.16
2017-06-11 02:08:00.484226 EDT | MinEsReturn               337.41
2017-06-11 02:08:00.484673 EDT | AverageDiscountedReturn   256.562
2017-06-11 02:08:00.485121 EDT | AverageQLoss                2.06732
2017-06-11 02:08:00.485567 EDT | AveragePolicySurr         -31.0349
2017-06-11 02:08:00.486027 EDT | AverageQ                   30.7155
2017-06-11 02:08:00.486476 EDT | AverageAbsQ                30.7427
2017-06-11 02:08:00.486922 EDT | AverageY                   30.7173
2017-06-11 02:08:00.488516 EDT | AverageAbsY                30.7334
2017-06-11 02:08:00.488887 EDT | AverageAbsQYDiff            0.512836
2017-06-11 02:08:00.490124 EDT | AverageAction               0.994464
2017-06-11 02:08:00.490491 EDT | PolicyRegParamNorm         91.7331
2017-06-11 02:08:00.501891 EDT | QFunRegParamNorm          118.878
2017-06-11 02:08:00.507788 EDT | -----------------------  -----------
2017-06-11 02:08:00.508335 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #869 | Training started
2017-06-11 02:08:18.006599 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #869 | Training finished
2017-06-11 02:08:18.017766 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #869 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 02:08:18.018221 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #869 | Collecting samples for evaluation
2017-06-11 02:08:32.890100 EDT | -----------------------  -----------
2017-06-11 02:08:32.890815 EDT | Epoch                     869
2017-06-11 02:08:32.891375 EDT | Iteration                 869
2017-06-11 02:08:32.891978 EDT | AverageReturn            1814.32
2017-06-11 02:08:32.892230 EDT | StdReturn                 774.518
2017-06-11 02:08:32.892418 EDT | MaxReturn                3268.96
2017-06-11 02:08:32.892602 EDT | MinReturn                 896.729
2017-06-11 02:08:32.892830 EDT | AverageEsReturn           486.917
2017-06-11 02:08:32.893014 EDT | StdEsReturn               262.71
2017-06-11 02:08:32.893658 EDT | MaxEsReturn               801.215
2017-06-11 02:08:32.893957 EDT | MinEsReturn                98.5116
2017-06-11 02:08:32.894301 EDT | AverageDiscountedReturn   248.08
2017-06-11 02:08:32.894538 EDT | AverageQLoss                2.34793
2017-06-11 02:08:32.895010 EDT | AveragePolicySurr         -30.9722
2017-06-11 02:08:32.895207 EDT | AverageQ                   30.6461
2017-06-11 02:08:32.895388 EDT | AverageAbsQ                30.6745
2017-06-11 02:08:32.895568 EDT | AverageY                   30.6462
2017-06-11 02:08:32.895786 EDT | AverageAbsY                30.6596
2017-06-11 02:08:32.895966 EDT | AverageAbsQYDiff            0.532638
2017-06-11 02:08:32.896301 EDT | AverageAction               0.993823
2017-06-11 02:08:32.896730 EDT | PolicyRegParamNorm         91.7495
2017-06-11 02:08:32.898798 EDT | QFunRegParamNorm          118.966
2017-06-11 02:08:32.899355 EDT | -----------------------  -----------
2017-06-11 02:08:32.899701 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #870 | Training started
2017-06-11 02:08:50.479568 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #870 | Training finished
2017-06-11 02:08:50.480331 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #870 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 02:08:50.480725 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #870 | Collecting samples for evaluation
2017-06-11 02:09:05.466292 EDT | -----------------------  -----------
2017-06-11 02:09:05.467269 EDT | Epoch                     870
2017-06-11 02:09:05.467644 EDT | Iteration                 870
2017-06-11 02:09:05.467993 EDT | AverageReturn            1570.34
2017-06-11 02:09:05.468340 EDT | StdReturn                 483.34
2017-06-11 02:09:05.468682 EDT | MaxReturn                3003.53
2017-06-11 02:09:05.469026 EDT | MinReturn                1085.14
2017-06-11 02:09:05.469371 EDT | AverageEsReturn           618.782
2017-06-11 02:09:05.474437 EDT | StdEsReturn               345.804
2017-06-11 02:09:05.474922 EDT | MaxEsReturn              1052.67
2017-06-11 02:09:05.475314 EDT | MinEsReturn               115.559
2017-06-11 02:09:05.477176 EDT | AverageDiscountedReturn   253.565
2017-06-11 02:09:05.477545 EDT | AverageQLoss                2.11192
2017-06-11 02:09:05.479550 EDT | AveragePolicySurr         -30.9859
2017-06-11 02:09:05.480019 EDT | AverageQ                   30.6509
2017-06-11 02:09:05.480448 EDT | AverageAbsQ                30.6791
2017-06-11 02:09:05.482467 EDT | AverageY                   30.6523
2017-06-11 02:09:05.482940 EDT | AverageAbsY                30.6675
2017-06-11 02:09:05.483387 EDT | AverageAbsQYDiff            0.524199
2017-06-11 02:09:05.485323 EDT | AverageAction               0.993939
2017-06-11 02:09:05.485689 EDT | PolicyRegParamNorm         91.8141
2017-06-11 02:09:05.486034 EDT | QFunRegParamNorm          119.031
2017-06-11 02:09:05.487719 EDT | -----------------------  -----------
2017-06-11 02:09:05.488267 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #871 | Training started
2017-06-11 02:09:22.839618 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #871 | Training finished
2017-06-11 02:09:22.840150 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #871 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 02:09:22.840557 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #871 | Collecting samples for evaluation
2017-06-11 02:09:36.549970 EDT | -----------------------  -----------
2017-06-11 02:09:36.550996 EDT | Epoch                     871
2017-06-11 02:09:36.551522 EDT | Iteration                 871
2017-06-11 02:09:36.551885 EDT | AverageReturn            1023.43
2017-06-11 02:09:36.552303 EDT | StdReturn                 217.447
2017-06-11 02:09:36.552648 EDT | MaxReturn                1451.1
2017-06-11 02:09:36.553180 EDT | MinReturn                 727.383
2017-06-11 02:09:36.553529 EDT | AverageEsReturn           287.046
2017-06-11 02:09:36.553880 EDT | StdEsReturn               189.304
2017-06-11 02:09:36.554313 EDT | MaxEsReturn               562.319
2017-06-11 02:09:36.554688 EDT | MinEsReturn                50.5637
2017-06-11 02:09:36.555320 EDT | AverageDiscountedReturn   251.926
2017-06-11 02:09:36.556007 EDT | AverageQLoss                2.01669
2017-06-11 02:09:36.556374 EDT | AveragePolicySurr         -30.9633
2017-06-11 02:09:36.557394 EDT | AverageQ                   30.6421
2017-06-11 02:09:36.557764 EDT | AverageAbsQ                30.668
2017-06-11 02:09:36.558189 EDT | AverageY                   30.643
2017-06-11 02:09:36.558625 EDT | AverageAbsY                30.6557
2017-06-11 02:09:36.558995 EDT | AverageAbsQYDiff            0.516591
2017-06-11 02:09:36.559646 EDT | AverageAction               0.995097
2017-06-11 02:09:36.560935 EDT | PolicyRegParamNorm         91.7885
2017-06-11 02:09:36.561433 EDT | QFunRegParamNorm          119.091
2017-06-11 02:09:36.561753 EDT | -----------------------  -----------
2017-06-11 02:09:36.562317 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #872 | Training started
2017-06-11 02:09:54.481982 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #872 | Training finished
2017-06-11 02:09:54.482891 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #872 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 02:09:54.483259 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #872 | Collecting samples for evaluation
2017-06-11 02:10:08.568058 EDT | -----------------------  -----------
2017-06-11 02:10:08.568900 EDT | Epoch                     872
2017-06-11 02:10:08.569303 EDT | Iteration                 872
2017-06-11 02:10:08.569686 EDT | AverageReturn            2075
2017-06-11 02:10:08.570078 EDT | StdReturn                 766.094
2017-06-11 02:10:08.570460 EDT | MaxReturn                3226.84
2017-06-11 02:10:08.570841 EDT | MinReturn                 945.25
2017-06-11 02:10:08.571216 EDT | AverageEsReturn           306.179
2017-06-11 02:10:08.571589 EDT | StdEsReturn               348.079
2017-06-11 02:10:08.571963 EDT | MaxEsReturn              1162.21
2017-06-11 02:10:08.572333 EDT | MinEsReturn                20.8599
2017-06-11 02:10:08.572704 EDT | AverageDiscountedReturn   247.306
2017-06-11 02:10:08.573074 EDT | AverageQLoss                2.35616
2017-06-11 02:10:08.573444 EDT | AveragePolicySurr         -30.993
2017-06-11 02:10:08.573822 EDT | AverageQ                   30.6798
2017-06-11 02:10:08.574193 EDT | AverageAbsQ                30.7051
2017-06-11 02:10:08.574562 EDT | AverageY                   30.6817
2017-06-11 02:10:08.574930 EDT | AverageAbsY                30.6945
2017-06-11 02:10:08.575298 EDT | AverageAbsQYDiff            0.546882
2017-06-11 02:10:08.575671 EDT | AverageAction               0.993518
2017-06-11 02:10:08.576042 EDT | PolicyRegParamNorm         91.8606
2017-06-11 02:10:08.576413 EDT | QFunRegParamNorm          119.182
2017-06-11 02:10:08.576781 EDT | -----------------------  -----------
2017-06-11 02:10:08.577296 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #873 | Training started
2017-06-11 02:10:25.756070 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #873 | Training finished
2017-06-11 02:10:25.757090 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #873 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 02:10:25.757500 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #873 | Collecting samples for evaluation
2017-06-11 02:10:40.675591 EDT | -----------------------  -----------
2017-06-11 02:10:40.676433 EDT | Epoch                     873
2017-06-11 02:10:40.676739 EDT | Iteration                 873
2017-06-11 02:10:40.677013 EDT | AverageReturn            1501.5
2017-06-11 02:10:40.677294 EDT | StdReturn                 493.513
2017-06-11 02:10:40.677569 EDT | MaxReturn                2830.94
2017-06-11 02:10:40.677827 EDT | MinReturn                1011.28
2017-06-11 02:10:40.678069 EDT | AverageEsReturn           490.199
2017-06-11 02:10:40.678308 EDT | StdEsReturn               328.692
2017-06-11 02:10:40.678547 EDT | MaxEsReturn              1034.83
2017-06-11 02:10:40.678795 EDT | MinEsReturn               163.821
2017-06-11 02:10:40.679034 EDT | AverageDiscountedReturn   232.859
2017-06-11 02:10:40.679272 EDT | AverageQLoss                2.20213
2017-06-11 02:10:40.679524 EDT | AveragePolicySurr         -30.9884
2017-06-11 02:10:40.679858 EDT | AverageQ                   30.6677
2017-06-11 02:10:40.680199 EDT | AverageAbsQ                30.6924
2017-06-11 02:10:40.680544 EDT | AverageY                   30.6713
2017-06-11 02:10:40.680982 EDT | AverageAbsY                30.6819
2017-06-11 02:10:40.681336 EDT | AverageAbsQYDiff            0.528117
2017-06-11 02:10:40.681866 EDT | AverageAction               0.993919
2017-06-11 02:10:40.682219 EDT | PolicyRegParamNorm         91.9167
2017-06-11 02:10:40.682567 EDT | QFunRegParamNorm          119.223
2017-06-11 02:10:40.682912 EDT | -----------------------  -----------
2017-06-11 02:10:40.683418 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #874 | Training started
2017-06-11 02:10:58.610922 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #874 | Training finished
2017-06-11 02:10:58.611299 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #874 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 02:10:58.611589 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #874 | Collecting samples for evaluation
2017-06-11 02:11:13.481613 EDT | -----------------------  -----------
2017-06-11 02:11:13.482611 EDT | Epoch                     874
2017-06-11 02:11:13.482982 EDT | Iteration                 874
2017-06-11 02:11:13.483331 EDT | AverageReturn            1522.6
2017-06-11 02:11:13.483676 EDT | StdReturn                 695.46
2017-06-11 02:11:13.484018 EDT | MaxReturn                3401.36
2017-06-11 02:11:13.484364 EDT | MinReturn                 745.869
2017-06-11 02:11:13.484705 EDT | AverageEsReturn           658.419
2017-06-11 02:11:13.485049 EDT | StdEsReturn               123.049
2017-06-11 02:11:13.485388 EDT | MaxEsReturn               779.403
2017-06-11 02:11:13.485743 EDT | MinEsReturn               438.193
2017-06-11 02:11:13.486090 EDT | AverageDiscountedReturn   245.91
2017-06-11 02:11:13.486433 EDT | AverageQLoss                2.25639
2017-06-11 02:11:13.486774 EDT | AveragePolicySurr         -31.1124
2017-06-11 02:11:13.487114 EDT | AverageQ                   30.7785
2017-06-11 02:11:13.487458 EDT | AverageAbsQ                30.801
2017-06-11 02:11:13.487800 EDT | AverageY                   30.7783
2017-06-11 02:11:13.488141 EDT | AverageAbsY                30.7897
2017-06-11 02:11:13.488478 EDT | AverageAbsQYDiff            0.519622
2017-06-11 02:11:13.488820 EDT | AverageAction               0.991985
2017-06-11 02:11:13.489167 EDT | PolicyRegParamNorm         91.9571
2017-06-11 02:11:13.489506 EDT | QFunRegParamNorm          119.305
2017-06-11 02:11:13.489857 EDT | -----------------------  -----------
2017-06-11 02:11:13.490371 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #875 | Training started
2017-06-11 02:11:31.213259 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #875 | Training finished
2017-06-11 02:11:31.214040 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #875 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 02:11:31.214361 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #875 | Collecting samples for evaluation
2017-06-11 02:11:45.273378 EDT | -----------------------  -----------
2017-06-11 02:11:45.274360 EDT | Epoch                     875
2017-06-11 02:11:45.274730 EDT | Iteration                 875
2017-06-11 02:11:45.275079 EDT | AverageReturn            1428.45
2017-06-11 02:11:45.275427 EDT | StdReturn                 382.401
2017-06-11 02:11:45.275770 EDT | MaxReturn                2489.99
2017-06-11 02:11:45.276115 EDT | MinReturn                1038.9
2017-06-11 02:11:45.276462 EDT | AverageEsReturn           412.378
2017-06-11 02:11:45.276801 EDT | StdEsReturn               240.42
2017-06-11 02:11:45.277145 EDT | MaxEsReturn               850.1
2017-06-11 02:11:45.277491 EDT | MinEsReturn               104.814
2017-06-11 02:11:45.277855 EDT | AverageDiscountedReturn   258.872
2017-06-11 02:11:45.278200 EDT | AverageQLoss                2.09475
2017-06-11 02:11:45.278549 EDT | AveragePolicySurr         -30.9345
2017-06-11 02:11:45.278892 EDT | AverageQ                   30.6216
2017-06-11 02:11:45.279233 EDT | AverageAbsQ                30.652
2017-06-11 02:11:45.279576 EDT | AverageY                   30.6216
2017-06-11 02:11:45.279918 EDT | AverageAbsY                30.6373
2017-06-11 02:11:45.280258 EDT | AverageAbsQYDiff            0.518832
2017-06-11 02:11:45.280606 EDT | AverageAction               0.994567
2017-06-11 02:11:45.280959 EDT | PolicyRegParamNorm         92.0302
2017-06-11 02:11:45.281303 EDT | QFunRegParamNorm          119.363
2017-06-11 02:11:45.281644 EDT | -----------------------  -----------
2017-06-11 02:11:45.282151 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #876 | Training started
2017-06-11 02:12:02.879283 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #876 | Training finished
2017-06-11 02:12:02.880197 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #876 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 02:12:02.880588 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #876 | Collecting samples for evaluation
2017-06-11 02:12:17.933890 EDT | -----------------------  -----------
2017-06-11 02:12:17.935766 EDT | Epoch                     876
2017-06-11 02:12:17.936117 EDT | Iteration                 876
2017-06-11 02:12:17.936513 EDT | AverageReturn            2302.65
2017-06-11 02:12:17.937292 EDT | StdReturn                 942.899
2017-06-11 02:12:17.938357 EDT | MaxReturn                3539.58
2017-06-11 02:12:17.939275 EDT | MinReturn                 711.444
2017-06-11 02:12:17.940164 EDT | AverageEsReturn           633.302
2017-06-11 02:12:17.941366 EDT | StdEsReturn               380.673
2017-06-11 02:12:17.942343 EDT | MaxEsReturn              1068.51
2017-06-11 02:12:17.943667 EDT | MinEsReturn                79.7818
2017-06-11 02:12:17.944715 EDT | AverageDiscountedReturn   257.386
2017-06-11 02:12:17.945888 EDT | AverageQLoss                2.31033
2017-06-11 02:12:17.946869 EDT | AveragePolicySurr         -30.978
2017-06-11 02:12:17.947996 EDT | AverageQ                   30.6157
2017-06-11 02:12:17.948965 EDT | AverageAbsQ                30.6428
2017-06-11 02:12:17.950042 EDT | AverageY                   30.6178
2017-06-11 02:12:17.951071 EDT | AverageAbsY                30.6295
2017-06-11 02:12:17.951983 EDT | AverageAbsQYDiff            0.54666
2017-06-11 02:12:17.953158 EDT | AverageAction               0.993732
2017-06-11 02:12:17.957625 EDT | PolicyRegParamNorm         92.0586
2017-06-11 02:12:17.958665 EDT | QFunRegParamNorm          119.347
2017-06-11 02:12:17.959774 EDT | -----------------------  -----------
2017-06-11 02:12:17.960927 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #877 | Training started
2017-06-11 02:12:35.284689 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #877 | Training finished
2017-06-11 02:12:35.285442 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #877 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 02:12:35.285764 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #877 | Collecting samples for evaluation
2017-06-11 02:12:51.116020 EDT | -----------------------  -----------
2017-06-11 02:12:51.117142 EDT | Epoch                     877
2017-06-11 02:12:51.117532 EDT | Iteration                 877
2017-06-11 02:12:51.117910 EDT | AverageReturn            2808.96
2017-06-11 02:12:51.118290 EDT | StdReturn                 835.979
2017-06-11 02:12:51.118648 EDT | MaxReturn                3656.75
2017-06-11 02:12:51.119006 EDT | MinReturn                1536.06
2017-06-11 02:12:51.119646 EDT | AverageEsReturn           456.86
2017-06-11 02:12:51.120187 EDT | StdEsReturn               353.943
2017-06-11 02:12:51.120567 EDT | MaxEsReturn               909.177
2017-06-11 02:12:51.120925 EDT | MinEsReturn                85.3051
2017-06-11 02:12:51.121882 EDT | AverageDiscountedReturn   263.525
2017-06-11 02:12:51.122569 EDT | AverageQLoss                2.17022
2017-06-11 02:12:51.123915 EDT | AveragePolicySurr         -30.8901
2017-06-11 02:12:51.124295 EDT | AverageQ                   30.56
2017-06-11 02:12:51.124761 EDT | AverageAbsQ                30.5838
2017-06-11 02:12:51.125192 EDT | AverageY                   30.562
2017-06-11 02:12:51.125560 EDT | AverageAbsY                30.5701
2017-06-11 02:12:51.125929 EDT | AverageAbsQYDiff            0.522094
2017-06-11 02:12:51.126645 EDT | AverageAction               0.994275
2017-06-11 02:12:51.129337 EDT | PolicyRegParamNorm         92.0984
2017-06-11 02:12:51.130078 EDT | QFunRegParamNorm          119.377
2017-06-11 02:12:51.130440 EDT | -----------------------  -----------
2017-06-11 02:12:51.131148 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #878 | Training started
2017-06-11 02:13:07.514243 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #878 | Training finished
2017-06-11 02:13:07.515095 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #878 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 02:13:07.515401 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #878 | Collecting samples for evaluation
2017-06-11 02:13:22.894588 EDT | -----------------------  -----------
2017-06-11 02:13:22.895700 EDT | Epoch                     878
2017-06-11 02:13:22.896189 EDT | Iteration                 878
2017-06-11 02:13:22.896633 EDT | AverageReturn            3439.84
2017-06-11 02:13:22.897088 EDT | StdReturn                 130.146
2017-06-11 02:13:22.897537 EDT | MaxReturn                3522.52
2017-06-11 02:13:22.897993 EDT | MinReturn                3038.96
2017-06-11 02:13:22.898458 EDT | AverageEsReturn           416.324
2017-06-11 02:13:22.898902 EDT | StdEsReturn               283.702
2017-06-11 02:13:22.899363 EDT | MaxEsReturn               984.972
2017-06-11 02:13:22.899805 EDT | MinEsReturn                54.0863
2017-06-11 02:13:22.900270 EDT | AverageDiscountedReturn   256.743
2017-06-11 02:13:22.900716 EDT | AverageQLoss                2.67031
2017-06-11 02:13:22.901159 EDT | AveragePolicySurr         -30.9141
2017-06-11 02:13:22.901624 EDT | AverageQ                   30.5561
2017-06-11 02:13:22.902083 EDT | AverageAbsQ                30.5792
2017-06-11 02:13:22.902550 EDT | AverageY                   30.5578
2017-06-11 02:13:22.902989 EDT | AverageAbsY                30.5661
2017-06-11 02:13:22.903445 EDT | AverageAbsQYDiff            0.542178
2017-06-11 02:13:22.903889 EDT | AverageAction               0.991421
2017-06-11 02:13:22.904334 EDT | PolicyRegParamNorm         92.1323
2017-06-11 02:13:22.904798 EDT | QFunRegParamNorm          119.412
2017-06-11 02:13:22.905241 EDT | -----------------------  -----------
2017-06-11 02:13:22.905885 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #879 | Training started
2017-06-11 02:13:39.338609 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #879 | Training finished
2017-06-11 02:13:39.339485 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #879 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 02:13:39.339782 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #879 | Collecting samples for evaluation
2017-06-11 02:13:52.596421 EDT | -----------------------  -----------
2017-06-11 02:13:52.597334 EDT | Epoch                     879
2017-06-11 02:13:52.597684 EDT | Iteration                 879
2017-06-11 02:13:52.597977 EDT | AverageReturn            1383.42
2017-06-11 02:13:52.598225 EDT | StdReturn                 526.472
2017-06-11 02:13:52.598499 EDT | MaxReturn                3008.46
2017-06-11 02:13:52.598756 EDT | MinReturn                 682.481
2017-06-11 02:13:52.599009 EDT | AverageEsReturn           378.111
2017-06-11 02:13:52.599322 EDT | StdEsReturn               271.327
2017-06-11 02:13:52.599626 EDT | MaxEsReturn               907.746
2017-06-11 02:13:52.599919 EDT | MinEsReturn                81.623
2017-06-11 02:13:52.600256 EDT | AverageDiscountedReturn   254.712
2017-06-11 02:13:52.600544 EDT | AverageQLoss                2.62649
2017-06-11 02:13:52.600863 EDT | AveragePolicySurr         -30.92
2017-06-11 02:13:52.601197 EDT | AverageQ                   30.5845
2017-06-11 02:13:52.601521 EDT | AverageAbsQ                30.6078
2017-06-11 02:13:52.601859 EDT | AverageY                   30.5852
2017-06-11 02:13:52.602157 EDT | AverageAbsY                30.5955
2017-06-11 02:13:52.602416 EDT | AverageAbsQYDiff            0.549798
2017-06-11 02:13:52.602674 EDT | AverageAction               0.993563
2017-06-11 02:13:52.602998 EDT | PolicyRegParamNorm         92.1814
2017-06-11 02:13:52.603305 EDT | QFunRegParamNorm          119.491
2017-06-11 02:13:52.603566 EDT | -----------------------  -----------
2017-06-11 02:13:52.603997 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #880 | Training started
2017-06-11 02:14:09.796831 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #880 | Training finished
2017-06-11 02:14:09.797363 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #880 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 02:14:09.797547 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #880 | Collecting samples for evaluation
2017-06-11 02:14:24.138772 EDT | -----------------------  -----------
2017-06-11 02:14:24.140150 EDT | Epoch                     880
2017-06-11 02:14:24.140512 EDT | Iteration                 880
2017-06-11 02:14:24.140852 EDT | AverageReturn            2296.65
2017-06-11 02:14:24.141549 EDT | StdReturn                1081.79
2017-06-11 02:14:24.141915 EDT | MaxReturn                3540.16
2017-06-11 02:14:24.142380 EDT | MinReturn                 254.96
2017-06-11 02:14:24.142718 EDT | AverageEsReturn           342.832
2017-06-11 02:14:24.143051 EDT | StdEsReturn               339.381
2017-06-11 02:14:24.143512 EDT | MaxEsReturn               973.574
2017-06-11 02:14:24.143849 EDT | MinEsReturn                55.4841
2017-06-11 02:14:24.144186 EDT | AverageDiscountedReturn   240.732
2017-06-11 02:14:24.144762 EDT | AverageQLoss                2.0048
2017-06-11 02:14:24.145097 EDT | AveragePolicySurr         -30.9846
2017-06-11 02:14:24.145433 EDT | AverageQ                   30.6608
2017-06-11 02:14:24.145897 EDT | AverageAbsQ                30.6829
2017-06-11 02:14:24.146232 EDT | AverageY                   30.6615
2017-06-11 02:14:24.146567 EDT | AverageAbsY                30.6719
2017-06-11 02:14:24.147020 EDT | AverageAbsQYDiff            0.50878
2017-06-11 02:14:24.147358 EDT | AverageAction               0.993032
2017-06-11 02:14:24.147693 EDT | PolicyRegParamNorm         92.229
2017-06-11 02:14:24.148345 EDT | QFunRegParamNorm          119.561
2017-06-11 02:14:24.148690 EDT | -----------------------  -----------
2017-06-11 02:14:24.149319 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #881 | Training started
2017-06-11 02:14:40.575285 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #881 | Training finished
2017-06-11 02:14:40.575652 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #881 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 02:14:40.575928 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #881 | Collecting samples for evaluation
2017-06-11 02:14:54.083649 EDT | -----------------------  -----------
2017-06-11 02:14:54.084514 EDT | Epoch                     881
2017-06-11 02:14:54.085392 EDT | Iteration                 881
2017-06-11 02:14:54.086997 EDT | AverageReturn            1516.7
2017-06-11 02:14:54.087483 EDT | StdReturn                1093.33
2017-06-11 02:14:54.088102 EDT | MaxReturn                3274.97
2017-06-11 02:14:54.088662 EDT | MinReturn                 392.116
2017-06-11 02:14:54.089103 EDT | AverageEsReturn           296.743
2017-06-11 02:14:54.089453 EDT | StdEsReturn               206.035
2017-06-11 02:14:54.089814 EDT | MaxEsReturn               639.024
2017-06-11 02:14:54.090230 EDT | MinEsReturn                21.7726
2017-06-11 02:14:54.090568 EDT | AverageDiscountedReturn   228.474
2017-06-11 02:14:54.091027 EDT | AverageQLoss                2.16623
2017-06-11 02:14:54.091416 EDT | AveragePolicySurr         -30.9347
2017-06-11 02:14:54.091772 EDT | AverageQ                   30.615
2017-06-11 02:14:54.092126 EDT | AverageAbsQ                30.6404
2017-06-11 02:14:54.092454 EDT | AverageY                   30.6168
2017-06-11 02:14:54.092832 EDT | AverageAbsY                30.6296
2017-06-11 02:14:54.093179 EDT | AverageAbsQYDiff            0.523679
2017-06-11 02:14:54.093559 EDT | AverageAction               0.992718
2017-06-11 02:14:54.094060 EDT | PolicyRegParamNorm         92.2849
2017-06-11 02:14:54.094413 EDT | QFunRegParamNorm          119.663
2017-06-11 02:14:54.094716 EDT | -----------------------  -----------
2017-06-11 02:14:54.095227 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #882 | Training started
2017-06-11 02:15:09.725177 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #882 | Training finished
2017-06-11 02:15:09.726020 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #882 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 02:15:09.726355 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #882 | Collecting samples for evaluation
2017-06-11 02:15:24.056248 EDT | -----------------------  -----------
2017-06-11 02:15:24.057162 EDT | Epoch                     882
2017-06-11 02:15:24.057372 EDT | Iteration                 882
2017-06-11 02:15:24.057744 EDT | AverageReturn            1578.67
2017-06-11 02:15:24.058985 EDT | StdReturn                 838.433
2017-06-11 02:15:24.060530 EDT | MaxReturn                3309.15
2017-06-11 02:15:24.060800 EDT | MinReturn                 697.204
2017-06-11 02:15:24.061013 EDT | AverageEsReturn           249.393
2017-06-11 02:15:24.061170 EDT | StdEsReturn               190.672
2017-06-11 02:15:24.061336 EDT | MaxEsReturn               701.939
2017-06-11 02:15:24.061495 EDT | MinEsReturn                14.2808
2017-06-11 02:15:24.061647 EDT | AverageDiscountedReturn   243.947
2017-06-11 02:15:24.061808 EDT | AverageQLoss                2.5158
2017-06-11 02:15:24.062138 EDT | AveragePolicySurr         -30.9123
2017-06-11 02:15:24.062296 EDT | AverageQ                   30.5841
2017-06-11 02:15:24.062449 EDT | AverageAbsQ                30.6076
2017-06-11 02:15:24.062600 EDT | AverageY                   30.5857
2017-06-11 02:15:24.062749 EDT | AverageAbsY                30.5976
2017-06-11 02:15:24.062898 EDT | AverageAbsQYDiff            0.533175
2017-06-11 02:15:24.063075 EDT | AverageAction               0.993472
2017-06-11 02:15:24.063227 EDT | PolicyRegParamNorm         92.3226
2017-06-11 02:15:24.063379 EDT | QFunRegParamNorm          119.658
2017-06-11 02:15:24.063540 EDT | -----------------------  -----------
2017-06-11 02:15:24.063827 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #883 | Training started
2017-06-11 02:15:40.140660 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #883 | Training finished
2017-06-11 02:15:40.141718 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #883 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 02:15:40.142148 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #883 | Collecting samples for evaluation
2017-06-11 02:15:53.883970 EDT | -----------------------  -----------
2017-06-11 02:15:53.884940 EDT | Epoch                     883
2017-06-11 02:15:53.885360 EDT | Iteration                 883
2017-06-11 02:15:53.885766 EDT | AverageReturn            2642.69
2017-06-11 02:15:53.886149 EDT | StdReturn                 754.983
2017-06-11 02:15:53.886526 EDT | MaxReturn                3541.43
2017-06-11 02:15:53.886898 EDT | MinReturn                1434.39
2017-06-11 02:15:53.887283 EDT | AverageEsReturn           429.546
2017-06-11 02:15:53.887669 EDT | StdEsReturn               290.724
2017-06-11 02:15:53.888136 EDT | MaxEsReturn               798.491
2017-06-11 02:15:53.888603 EDT | MinEsReturn                15.0251
2017-06-11 02:15:53.889073 EDT | AverageDiscountedReturn   258.512
2017-06-11 02:15:53.889542 EDT | AverageQLoss                2.48127
2017-06-11 02:15:53.890018 EDT | AveragePolicySurr         -30.8616
2017-06-11 02:15:53.890484 EDT | AverageQ                   30.5414
2017-06-11 02:15:53.890956 EDT | AverageAbsQ                30.5652
2017-06-11 02:15:53.891425 EDT | AverageY                   30.541
2017-06-11 02:15:53.891891 EDT | AverageAbsY                30.5511
2017-06-11 02:15:53.892361 EDT | AverageAbsQYDiff            0.530749
2017-06-11 02:15:53.892835 EDT | AverageAction               0.994286
2017-06-11 02:15:53.893301 EDT | PolicyRegParamNorm         92.3436
2017-06-11 02:15:53.893680 EDT | QFunRegParamNorm          119.74
2017-06-11 02:15:53.894104 EDT | -----------------------  -----------
2017-06-11 02:15:53.894668 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #884 | Training started
2017-06-11 02:16:10.906291 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #884 | Training finished
2017-06-11 02:16:10.907306 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #884 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 02:16:10.907710 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #884 | Collecting samples for evaluation
2017-06-11 02:16:24.643847 EDT | -----------------------  -----------
2017-06-11 02:16:24.644561 EDT | Epoch                     884
2017-06-11 02:16:24.644982 EDT | Iteration                 884
2017-06-11 02:16:24.645301 EDT | AverageReturn             340.009
2017-06-11 02:16:24.645553 EDT | StdReturn                 938.809
2017-06-11 02:16:24.645757 EDT | MaxReturn                3497.85
2017-06-11 02:16:24.645947 EDT | MinReturn                  26.1535
2017-06-11 02:16:24.646128 EDT | AverageEsReturn           301.116
2017-06-11 02:16:24.646310 EDT | StdEsReturn               244.795
2017-06-11 02:16:24.646490 EDT | MaxEsReturn               690.417
2017-06-11 02:16:24.646718 EDT | MinEsReturn                34.5088
2017-06-11 02:16:24.646906 EDT | AverageDiscountedReturn    51.679
2017-06-11 02:16:24.647088 EDT | AverageQLoss                2.30425
2017-06-11 02:16:24.647267 EDT | AveragePolicySurr         -30.8834
2017-06-11 02:16:24.647447 EDT | AverageQ                   30.5563
2017-06-11 02:16:24.647626 EDT | AverageAbsQ                30.5825
2017-06-11 02:16:24.647805 EDT | AverageY                   30.5582
2017-06-11 02:16:24.647993 EDT | AverageAbsY                30.5685
2017-06-11 02:16:24.648173 EDT | AverageAbsQYDiff            0.530462
2017-06-11 02:16:24.648353 EDT | AverageAction               0.990945
2017-06-11 02:16:24.648649 EDT | PolicyRegParamNorm         92.3406
2017-06-11 02:16:24.648829 EDT | QFunRegParamNorm          119.797
2017-06-11 02:16:24.649020 EDT | -----------------------  -----------
2017-06-11 02:16:24.649324 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #885 | Training started
2017-06-11 02:16:42.774369 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #885 | Training finished
2017-06-11 02:16:42.775539 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #885 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 02:16:42.775939 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #885 | Collecting samples for evaluation
2017-06-11 02:16:56.345656 EDT | -----------------------  -----------
2017-06-11 02:16:56.346508 EDT | Epoch                     885
2017-06-11 02:16:56.346871 EDT | Iteration                 885
2017-06-11 02:16:56.347148 EDT | AverageReturn            1850.85
2017-06-11 02:16:56.347488 EDT | StdReturn                 764.297
2017-06-11 02:16:56.347817 EDT | MaxReturn                3229.55
2017-06-11 02:16:56.348151 EDT | MinReturn                1040.16
2017-06-11 02:16:56.348481 EDT | AverageEsReturn            69.728
2017-06-11 02:16:56.348806 EDT | StdEsReturn               139.468
2017-06-11 02:16:56.352293 EDT | MaxEsReturn               613.109
2017-06-11 02:16:56.352548 EDT | MinEsReturn                17.2243
2017-06-11 02:16:56.352723 EDT | AverageDiscountedReturn   251.75
2017-06-11 02:16:56.353026 EDT | AverageQLoss                2.32844
2017-06-11 02:16:56.353333 EDT | AveragePolicySurr         -30.7716
2017-06-11 02:16:56.353612 EDT | AverageQ                   30.4763
2017-06-11 02:16:56.353952 EDT | AverageAbsQ                30.4993
2017-06-11 02:16:56.354242 EDT | AverageY                   30.4783
2017-06-11 02:16:56.354533 EDT | AverageAbsY                30.4891
2017-06-11 02:16:56.354857 EDT | AverageAbsQYDiff            0.539722
2017-06-11 02:16:56.355176 EDT | AverageAction               0.994801
2017-06-11 02:16:56.355497 EDT | PolicyRegParamNorm         92.334
2017-06-11 02:16:56.355809 EDT | QFunRegParamNorm          119.843
2017-06-11 02:16:56.356009 EDT | -----------------------  -----------
2017-06-11 02:16:56.356507 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #886 | Training started
2017-06-11 02:17:12.655795 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #886 | Training finished
2017-06-11 02:17:12.656778 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #886 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 02:17:12.657157 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #886 | Collecting samples for evaluation
2017-06-11 02:17:27.412968 EDT | -----------------------  -----------
2017-06-11 02:17:27.413847 EDT | Epoch                     886
2017-06-11 02:17:27.414216 EDT | Iteration                 886
2017-06-11 02:17:27.414727 EDT | AverageReturn            2935.41
2017-06-11 02:17:27.415015 EDT | StdReturn                 407.827
2017-06-11 02:17:27.415976 EDT | MaxReturn                3153.11
2017-06-11 02:17:27.417054 EDT | MinReturn                1935.88
2017-06-11 02:17:27.417332 EDT | AverageEsReturn           325.58
2017-06-11 02:17:27.417666 EDT | StdEsReturn               376.251
2017-06-11 02:17:27.418027 EDT | MaxEsReturn              1341.22
2017-06-11 02:17:27.418359 EDT | MinEsReturn                23.9244
2017-06-11 02:17:27.418630 EDT | AverageDiscountedReturn   247.217
2017-06-11 02:17:27.418955 EDT | AverageQLoss                2.51464
2017-06-11 02:17:27.419302 EDT | AveragePolicySurr         -30.817
2017-06-11 02:17:27.419633 EDT | AverageQ                   30.496
2017-06-11 02:17:27.419902 EDT | AverageAbsQ                30.5175
2017-06-11 02:17:27.420226 EDT | AverageY                   30.4973
2017-06-11 02:17:27.420558 EDT | AverageAbsY                30.5046
2017-06-11 02:17:27.420878 EDT | AverageAbsQYDiff            0.53317
2017-06-11 02:17:27.421206 EDT | AverageAction               0.994564
2017-06-11 02:17:27.421538 EDT | PolicyRegParamNorm         92.38
2017-06-11 02:17:27.421868 EDT | QFunRegParamNorm          119.871
2017-06-11 02:17:27.422196 EDT | -----------------------  -----------
2017-06-11 02:17:27.422776 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #887 | Training started
2017-06-11 02:17:43.836174 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #887 | Training finished
2017-06-11 02:17:43.837256 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #887 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 02:17:43.837472 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #887 | Collecting samples for evaluation
2017-06-11 02:17:57.337429 EDT | -----------------------  -----------
2017-06-11 02:17:57.339171 EDT | Epoch                     887
2017-06-11 02:17:57.341071 EDT | Iteration                 887
2017-06-11 02:17:57.341261 EDT | AverageReturn            2434.48
2017-06-11 02:17:57.341445 EDT | StdReturn                 616.578
2017-06-11 02:17:57.341715 EDT | MaxReturn                3356.11
2017-06-11 02:17:57.341881 EDT | MinReturn                1355.81
2017-06-11 02:17:57.342037 EDT | AverageEsReturn           255.14
2017-06-11 02:17:57.342190 EDT | StdEsReturn               237.016
2017-06-11 02:17:57.342340 EDT | MaxEsReturn               606.881
2017-06-11 02:17:57.342555 EDT | MinEsReturn                18.4971
2017-06-11 02:17:57.342708 EDT | AverageDiscountedReturn   258.937
2017-06-11 02:17:57.342859 EDT | AverageQLoss                2.22351
2017-06-11 02:17:57.343023 EDT | AveragePolicySurr         -30.7872
2017-06-11 02:17:57.343311 EDT | AverageQ                   30.4815
2017-06-11 02:17:57.343477 EDT | AverageAbsQ                30.5072
2017-06-11 02:17:57.343668 EDT | AverageY                   30.4816
2017-06-11 02:17:57.343839 EDT | AverageAbsY                30.4957
2017-06-11 02:17:57.343992 EDT | AverageAbsQYDiff            0.523528
2017-06-11 02:17:57.344143 EDT | AverageAction               0.995421
2017-06-11 02:17:57.344472 EDT | PolicyRegParamNorm         92.4053
2017-06-11 02:17:57.344636 EDT | QFunRegParamNorm          119.936
2017-06-11 02:17:57.344789 EDT | -----------------------  -----------
2017-06-11 02:17:57.345155 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #888 | Training started
2017-06-11 02:18:15.597674 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #888 | Training finished
2017-06-11 02:18:15.598693 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #888 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 02:18:15.598935 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #888 | Collecting samples for evaluation
2017-06-11 02:18:29.343310 EDT | -----------------------  -----------
2017-06-11 02:18:29.344358 EDT | Epoch                     888
2017-06-11 02:18:29.344725 EDT | Iteration                 888
2017-06-11 02:18:29.345076 EDT | AverageReturn            1094.25
2017-06-11 02:18:29.345419 EDT | StdReturn                 845.713
2017-06-11 02:18:29.345772 EDT | MaxReturn                3490.63
2017-06-11 02:18:29.346112 EDT | MinReturn                  66.8422
2017-06-11 02:18:29.346458 EDT | AverageEsReturn           464.428
2017-06-11 02:18:29.346807 EDT | StdEsReturn               383.016
2017-06-11 02:18:29.347153 EDT | MaxEsReturn              1034.61
2017-06-11 02:18:29.347499 EDT | MinEsReturn                68.5482
2017-06-11 02:18:29.347840 EDT | AverageDiscountedReturn   207.238
2017-06-11 02:18:29.348181 EDT | AverageQLoss                2.10441
2017-06-11 02:18:29.348525 EDT | AveragePolicySurr         -30.7988
2017-06-11 02:18:29.348864 EDT | AverageQ                   30.4694
2017-06-11 02:18:29.349206 EDT | AverageAbsQ                30.4964
2017-06-11 02:18:29.349545 EDT | AverageY                   30.4716
2017-06-11 02:18:29.349899 EDT | AverageAbsY                30.4831
2017-06-11 02:18:29.350239 EDT | AverageAbsQYDiff            0.524979
2017-06-11 02:18:29.350580 EDT | AverageAction               0.995893
2017-06-11 02:18:29.350924 EDT | PolicyRegParamNorm         92.4793
2017-06-11 02:18:29.351277 EDT | QFunRegParamNorm          119.991
2017-06-11 02:18:29.351617 EDT | -----------------------  -----------
2017-06-11 02:18:29.352127 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #889 | Training started
2017-06-11 02:18:48.255773 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #889 | Training finished
2017-06-11 02:18:48.256037 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #889 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 02:18:48.256231 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #889 | Collecting samples for evaluation
2017-06-11 02:19:01.693483 EDT | -----------------------  -----------
2017-06-11 02:19:01.699077 EDT | Epoch                     889
2017-06-11 02:19:01.699601 EDT | Iteration                 889
2017-06-11 02:19:01.700060 EDT | AverageReturn             378.208
2017-06-11 02:19:01.700513 EDT | StdReturn                 535.982
2017-06-11 02:19:01.701101 EDT | MaxReturn                3268.67
2017-06-11 02:19:01.701463 EDT | MinReturn                  62.2391
2017-06-11 02:19:01.701822 EDT | AverageEsReturn           219.927
2017-06-11 02:19:01.702170 EDT | StdEsReturn               197.497
2017-06-11 02:19:01.702518 EDT | MaxEsReturn               769.596
2017-06-11 02:19:01.702863 EDT | MinEsReturn                67.0292
2017-06-11 02:19:01.703213 EDT | AverageDiscountedReturn   121.463
2017-06-11 02:19:01.703662 EDT | AverageQLoss                2.26764
2017-06-11 02:19:01.706833 EDT | AveragePolicySurr         -30.8059
2017-06-11 02:19:01.707239 EDT | AverageQ                   30.4681
2017-06-11 02:19:01.707594 EDT | AverageAbsQ                30.4915
2017-06-11 02:19:01.708045 EDT | AverageY                   30.4673
2017-06-11 02:19:01.708403 EDT | AverageAbsY                30.476
2017-06-11 02:19:01.708754 EDT | AverageAbsQYDiff            0.549362
2017-06-11 02:19:01.709104 EDT | AverageAction               0.995567
2017-06-11 02:19:01.709452 EDT | PolicyRegParamNorm         92.4928
2017-06-11 02:19:01.709808 EDT | QFunRegParamNorm          120.048
2017-06-11 02:19:01.710153 EDT | -----------------------  -----------
2017-06-11 02:19:01.715443 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #890 | Training started
2017-06-11 02:19:18.434039 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #890 | Training finished
2017-06-11 02:19:18.434532 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #890 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 02:19:18.434872 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #890 | Collecting samples for evaluation
2017-06-11 02:19:32.701672 EDT | -----------------------  ----------
2017-06-11 02:19:32.706287 EDT | Epoch                    890
2017-06-11 02:19:32.706765 EDT | Iteration                890
2017-06-11 02:19:32.707200 EDT | AverageReturn             68.0688
2017-06-11 02:19:32.707607 EDT | StdReturn                  2.69757
2017-06-11 02:19:32.708016 EDT | MaxReturn                 81.6401
2017-06-11 02:19:32.708465 EDT | MinReturn                 62.3929
2017-06-11 02:19:32.711687 EDT | AverageEsReturn          201.681
2017-06-11 02:19:32.712358 EDT | StdEsReturn              197.339
2017-06-11 02:19:32.712872 EDT | MaxEsReturn              665.47
2017-06-11 02:19:32.713321 EDT | MinEsReturn               20.8796
2017-06-11 02:19:32.713776 EDT | AverageDiscountedReturn   55.3568
2017-06-11 02:19:32.714218 EDT | AverageQLoss               2.26271
2017-06-11 02:19:32.714653 EDT | AveragePolicySurr        -30.8
2017-06-11 02:19:32.715088 EDT | AverageQ                  30.4853
2017-06-11 02:19:32.715527 EDT | AverageAbsQ               30.5067
2017-06-11 02:19:32.715965 EDT | AverageY                  30.4844
2017-06-11 02:19:32.716437 EDT | AverageAbsY               30.4945
2017-06-11 02:19:32.716874 EDT | AverageAbsQYDiff           0.540995
2017-06-11 02:19:32.717316 EDT | AverageAction              0.998064
2017-06-11 02:19:32.717910 EDT | PolicyRegParamNorm        92.5521
2017-06-11 02:19:32.718254 EDT | QFunRegParamNorm         120.1
2017-06-11 02:19:32.718975 EDT | -----------------------  ----------
2017-06-11 02:19:32.719516 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #891 | Training started
2017-06-11 02:19:49.760486 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #891 | Training finished
2017-06-11 02:19:49.761283 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #891 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 02:19:49.761489 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #891 | Collecting samples for evaluation
2017-06-11 02:20:03.978689 EDT | -----------------------  -----------
2017-06-11 02:20:03.982991 EDT | Epoch                     891
2017-06-11 02:20:03.983469 EDT | Iteration                 891
2017-06-11 02:20:03.984049 EDT | AverageReturn             316.62
2017-06-11 02:20:03.985554 EDT | StdReturn                 340.231
2017-06-11 02:20:03.986274 EDT | MaxReturn                1042.37
2017-06-11 02:20:03.986628 EDT | MinReturn                  68.6817
2017-06-11 02:20:03.986972 EDT | AverageEsReturn           206.718
2017-06-11 02:20:03.987372 EDT | StdEsReturn               253.913
2017-06-11 02:20:03.987779 EDT | MaxEsReturn               753.653
2017-06-11 02:20:03.987971 EDT | MinEsReturn                63.0413
2017-06-11 02:20:03.988263 EDT | AverageDiscountedReturn   123.004
2017-06-11 02:20:03.988448 EDT | AverageQLoss                2.52324
2017-06-11 02:20:03.989126 EDT | AveragePolicySurr         -30.701
2017-06-11 02:20:03.989588 EDT | AverageQ                   30.4068
2017-06-11 02:20:03.989985 EDT | AverageAbsQ                30.4331
2017-06-11 02:20:03.990321 EDT | AverageY                   30.4084
2017-06-11 02:20:03.990518 EDT | AverageAbsY                30.4201
2017-06-11 02:20:03.990939 EDT | AverageAbsQYDiff            0.553372
2017-06-11 02:20:03.991123 EDT | AverageAction               0.995613
2017-06-11 02:20:03.991572 EDT | PolicyRegParamNorm         92.65
2017-06-11 02:20:03.993092 EDT | QFunRegParamNorm          120.152
2017-06-11 02:20:03.993824 EDT | -----------------------  -----------
2017-06-11 02:20:03.995630 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #892 | Training started
2017-06-11 02:20:22.400565 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #892 | Training finished
2017-06-11 02:20:22.400845 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #892 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 02:20:22.401024 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #892 | Collecting samples for evaluation
2017-06-11 02:20:36.686705 EDT | -----------------------  -----------
2017-06-11 02:20:36.687492 EDT | Epoch                     892
2017-06-11 02:20:36.687685 EDT | Iteration                 892
2017-06-11 02:20:36.687875 EDT | AverageReturn            1019.57
2017-06-11 02:20:36.688086 EDT | StdReturn                 358.241
2017-06-11 02:20:36.688270 EDT | MaxReturn                2031.79
2017-06-11 02:20:36.688452 EDT | MinReturn                  76.9484
2017-06-11 02:20:36.688667 EDT | AverageEsReturn           287.232
2017-06-11 02:20:36.688851 EDT | StdEsReturn               211.987
2017-06-11 02:20:36.689033 EDT | MaxEsReturn               688.963
2017-06-11 02:20:36.689214 EDT | MinEsReturn                67.8658
2017-06-11 02:20:36.689395 EDT | AverageDiscountedReturn   237.857
2017-06-11 02:20:36.689584 EDT | AverageQLoss                2.42265
2017-06-11 02:20:36.689788 EDT | AveragePolicySurr         -30.7414
2017-06-11 02:20:36.689968 EDT | AverageQ                   30.3985
2017-06-11 02:20:36.690148 EDT | AverageAbsQ                30.4228
2017-06-11 02:20:36.690327 EDT | AverageY                   30.401
2017-06-11 02:20:36.690508 EDT | AverageAbsY                30.4129
2017-06-11 02:20:36.690687 EDT | AverageAbsQYDiff            0.54268
2017-06-11 02:20:36.690866 EDT | AverageAction               0.995068
2017-06-11 02:20:36.691227 EDT | PolicyRegParamNorm         92.6984
2017-06-11 02:20:36.692277 EDT | QFunRegParamNorm          120.249
2017-06-11 02:20:36.692477 EDT | -----------------------  -----------
2017-06-11 02:20:36.692817 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #893 | Training started
2017-06-11 02:20:54.248655 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #893 | Training finished
2017-06-11 02:20:54.248970 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #893 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 02:20:54.249329 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #893 | Collecting samples for evaluation
2017-06-11 02:21:07.989464 EDT | -----------------------  -----------
2017-06-11 02:21:07.990284 EDT | Epoch                     893
2017-06-11 02:21:07.990620 EDT | Iteration                 893
2017-06-11 02:21:07.990957 EDT | AverageReturn            1831.89
2017-06-11 02:21:07.991294 EDT | StdReturn                 674.23
2017-06-11 02:21:07.991622 EDT | MaxReturn                2749.06
2017-06-11 02:21:07.992015 EDT | MinReturn                 787.228
2017-06-11 02:21:07.992446 EDT | AverageEsReturn           540.274
2017-06-11 02:21:07.992801 EDT | StdEsReturn               260.379
2017-06-11 02:21:07.993073 EDT | MaxEsReturn               874.174
2017-06-11 02:21:07.993392 EDT | MinEsReturn                92.0598
2017-06-11 02:21:07.993722 EDT | AverageDiscountedReturn   233.332
2017-06-11 02:21:07.994057 EDT | AverageQLoss                2.21888
2017-06-11 02:21:07.994469 EDT | AveragePolicySurr         -30.672
2017-06-11 02:21:07.994857 EDT | AverageQ                   30.3489
2017-06-11 02:21:07.995200 EDT | AverageAbsQ                30.372
2017-06-11 02:21:07.995604 EDT | AverageY                   30.3508
2017-06-11 02:21:07.995932 EDT | AverageAbsY                30.3592
2017-06-11 02:21:07.996277 EDT | AverageAbsQYDiff            0.537844
2017-06-11 02:21:07.997364 EDT | AverageAction               0.994916
2017-06-11 02:21:07.997873 EDT | PolicyRegParamNorm         92.7578
2017-06-11 02:21:07.998313 EDT | QFunRegParamNorm          120.257
2017-06-11 02:21:07.998741 EDT | -----------------------  -----------
2017-06-11 02:21:07.999173 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #894 | Training started
2017-06-11 02:21:25.458360 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #894 | Training finished
2017-06-11 02:21:25.461344 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #894 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 02:21:25.462003 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #894 | Collecting samples for evaluation
2017-06-11 02:21:39.549472 EDT | -----------------------  -----------
2017-06-11 02:21:39.550287 EDT | Epoch                     894
2017-06-11 02:21:39.550494 EDT | Iteration                 894
2017-06-11 02:21:39.550683 EDT | AverageReturn            1863.9
2017-06-11 02:21:39.550848 EDT | StdReturn                 670.926
2017-06-11 02:21:39.551002 EDT | MaxReturn                2891.45
2017-06-11 02:21:39.551152 EDT | MinReturn                1094.07
2017-06-11 02:21:39.551302 EDT | AverageEsReturn           281.671
2017-06-11 02:21:39.551459 EDT | StdEsReturn               183.153
2017-06-11 02:21:39.551745 EDT | MaxEsReturn               530.362
2017-06-11 02:21:39.551901 EDT | MinEsReturn                48.88
2017-06-11 02:21:39.552171 EDT | AverageDiscountedReturn   237.888
2017-06-11 02:21:39.552363 EDT | AverageQLoss                2.06879
2017-06-11 02:21:39.552547 EDT | AveragePolicySurr         -30.6574
2017-06-11 02:21:39.552729 EDT | AverageQ                   30.3324
2017-06-11 02:21:39.552912 EDT | AverageAbsQ                30.3538
2017-06-11 02:21:39.553094 EDT | AverageY                   30.3312
2017-06-11 02:21:39.553274 EDT | AverageAbsY                30.3427
2017-06-11 02:21:39.553455 EDT | AverageAbsQYDiff            0.522721
2017-06-11 02:21:39.553636 EDT | AverageAction               0.994217
2017-06-11 02:21:39.553829 EDT | PolicyRegParamNorm         92.8026
2017-06-11 02:21:39.554010 EDT | QFunRegParamNorm          120.322
2017-06-11 02:21:39.555439 EDT | -----------------------  -----------
2017-06-11 02:21:39.556092 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #895 | Training started
2017-06-11 02:21:55.500703 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #895 | Training finished
2017-06-11 02:21:55.501953 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #895 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 02:21:55.502243 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #895 | Collecting samples for evaluation
2017-06-11 02:22:09.615172 EDT | -----------------------  -----------
2017-06-11 02:22:09.616087 EDT | Epoch                     895
2017-06-11 02:22:09.616560 EDT | Iteration                 895
2017-06-11 02:22:09.617015 EDT | AverageReturn            1796.1
2017-06-11 02:22:09.617471 EDT | StdReturn                 755.403
2017-06-11 02:22:09.617932 EDT | MaxReturn                2789.27
2017-06-11 02:22:09.618378 EDT | MinReturn                 664.895
2017-06-11 02:22:09.618823 EDT | AverageEsReturn           505.325
2017-06-11 02:22:09.619264 EDT | StdEsReturn               245.423
2017-06-11 02:22:09.619707 EDT | MaxEsReturn               772.978
2017-06-11 02:22:09.620148 EDT | MinEsReturn                79.6495
2017-06-11 02:22:09.620587 EDT | AverageDiscountedReturn   235.013
2017-06-11 02:22:09.621027 EDT | AverageQLoss                2.16565
2017-06-11 02:22:09.621469 EDT | AveragePolicySurr         -30.7001
2017-06-11 02:22:09.622014 EDT | AverageQ                   30.3613
2017-06-11 02:22:09.622836 EDT | AverageAbsQ                30.3849
2017-06-11 02:22:09.623683 EDT | AverageY                   30.3652
2017-06-11 02:22:09.624531 EDT | AverageAbsY                30.3765
2017-06-11 02:22:09.625368 EDT | AverageAbsQYDiff            0.521754
2017-06-11 02:22:09.626249 EDT | AverageAction               0.994925
2017-06-11 02:22:09.627101 EDT | PolicyRegParamNorm         92.9018
2017-06-11 02:22:09.627940 EDT | QFunRegParamNorm          120.409
2017-06-11 02:22:09.628790 EDT | -----------------------  -----------
2017-06-11 02:22:09.629818 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #896 | Training started
2017-06-11 02:22:27.317297 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #896 | Training finished
2017-06-11 02:22:27.318347 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #896 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 02:22:27.318827 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #896 | Collecting samples for evaluation
2017-06-11 02:22:41.304668 EDT | -----------------------  -----------
2017-06-11 02:22:41.305914 EDT | Epoch                     896
2017-06-11 02:22:41.306322 EDT | Iteration                 896
2017-06-11 02:22:41.306656 EDT | AverageReturn            1926.89
2017-06-11 02:22:41.307055 EDT | StdReturn                 684.45
2017-06-11 02:22:41.307401 EDT | MaxReturn                3179.31
2017-06-11 02:22:41.307734 EDT | MinReturn                1063.76
2017-06-11 02:22:41.308078 EDT | AverageEsReturn           295.468
2017-06-11 02:22:41.308419 EDT | StdEsReturn               201.166
2017-06-11 02:22:41.308695 EDT | MaxEsReturn               749.341
2017-06-11 02:22:41.309029 EDT | MinEsReturn                42.4401
2017-06-11 02:22:41.312984 EDT | AverageDiscountedReturn   256.597
2017-06-11 02:22:41.313210 EDT | AverageQLoss                2.2236
2017-06-11 02:22:41.313795 EDT | AveragePolicySurr         -30.741
2017-06-11 02:22:41.314113 EDT | AverageQ                   30.4206
2017-06-11 02:22:41.314391 EDT | AverageAbsQ                30.4431
2017-06-11 02:22:41.314766 EDT | AverageY                   30.42
2017-06-11 02:22:41.315082 EDT | AverageAbsY                30.4302
2017-06-11 02:22:41.315415 EDT | AverageAbsQYDiff            0.526539
2017-06-11 02:22:41.315773 EDT | AverageAction               0.994797
2017-06-11 02:22:41.316099 EDT | PolicyRegParamNorm         92.9099
2017-06-11 02:22:41.316418 EDT | QFunRegParamNorm          120.47
2017-06-11 02:22:41.316754 EDT | -----------------------  -----------
2017-06-11 02:22:41.317096 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #897 | Training started
2017-06-11 02:22:59.153444 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #897 | Training finished
2017-06-11 02:22:59.154483 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #897 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 02:22:59.154870 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #897 | Collecting samples for evaluation
2017-06-11 02:23:13.313831 EDT | -----------------------  -----------
2017-06-11 02:23:13.314703 EDT | Epoch                     897
2017-06-11 02:23:13.315039 EDT | Iteration                 897
2017-06-11 02:23:13.315360 EDT | AverageReturn            3126.91
2017-06-11 02:23:13.315685 EDT | StdReturn                 301.86
2017-06-11 02:23:13.316003 EDT | MaxReturn                3355.12
2017-06-11 02:23:13.316318 EDT | MinReturn                2408.04
2017-06-11 02:23:13.316636 EDT | AverageEsReturn           326.348
2017-06-11 02:23:13.316952 EDT | StdEsReturn               218.494
2017-06-11 02:23:13.317271 EDT | MaxEsReturn               632.849
2017-06-11 02:23:13.317585 EDT | MinEsReturn                46.5457
2017-06-11 02:23:13.317909 EDT | AverageDiscountedReturn   256.804
2017-06-11 02:23:13.318223 EDT | AverageQLoss                2.26533
2017-06-11 02:23:13.318535 EDT | AveragePolicySurr         -30.6725
2017-06-11 02:23:13.318852 EDT | AverageQ                   30.3473
2017-06-11 02:23:13.319163 EDT | AverageAbsQ                30.3698
2017-06-11 02:23:13.319475 EDT | AverageY                   30.349
2017-06-11 02:23:13.319790 EDT | AverageAbsY                30.3616
2017-06-11 02:23:13.320102 EDT | AverageAbsQYDiff            0.527335
2017-06-11 02:23:13.320413 EDT | AverageAction               0.993725
2017-06-11 02:23:13.320726 EDT | PolicyRegParamNorm         92.9331
2017-06-11 02:23:13.321036 EDT | QFunRegParamNorm          120.56
2017-06-11 02:23:13.321345 EDT | -----------------------  -----------
2017-06-11 02:23:13.321793 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #898 | Training started
2017-06-11 02:23:29.752397 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #898 | Training finished
2017-06-11 02:23:29.753399 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #898 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 02:23:29.753769 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #898 | Collecting samples for evaluation
2017-06-11 02:23:44.978620 EDT | -----------------------  -----------
2017-06-11 02:23:44.979351 EDT | Epoch                     898
2017-06-11 02:23:44.979681 EDT | Iteration                 898
2017-06-11 02:23:44.979872 EDT | AverageReturn            3212.3
2017-06-11 02:23:44.980056 EDT | StdReturn                 498.09
2017-06-11 02:23:44.980237 EDT | MaxReturn                3472.53
2017-06-11 02:23:44.980624 EDT | MinReturn                1728.58
2017-06-11 02:23:44.980824 EDT | AverageEsReturn           462.841
2017-06-11 02:23:44.981016 EDT | StdEsReturn               330.437
2017-06-11 02:23:44.981199 EDT | MaxEsReturn               985.64
2017-06-11 02:23:44.981494 EDT | MinEsReturn                58.7306
2017-06-11 02:23:44.981679 EDT | AverageDiscountedReturn   259.371
2017-06-11 02:23:44.981878 EDT | AverageQLoss                2.19704
2017-06-11 02:23:44.982068 EDT | AveragePolicySurr         -30.6787
2017-06-11 02:23:44.982248 EDT | AverageQ                   30.3639
2017-06-11 02:23:44.982449 EDT | AverageAbsQ                30.3916
2017-06-11 02:23:44.982731 EDT | AverageY                   30.3627
2017-06-11 02:23:44.982914 EDT | AverageAbsY                30.3764
2017-06-11 02:23:44.983103 EDT | AverageAbsQYDiff            0.536636
2017-06-11 02:23:44.983282 EDT | AverageAction               0.99428
2017-06-11 02:23:44.983515 EDT | PolicyRegParamNorm         92.9876
2017-06-11 02:23:44.983746 EDT | QFunRegParamNorm          120.617
2017-06-11 02:23:44.983927 EDT | -----------------------  -----------
2017-06-11 02:23:44.984220 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #899 | Training started
2017-06-11 02:24:01.709955 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #899 | Training finished
2017-06-11 02:24:01.711335 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #899 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 02:24:01.711732 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #899 | Collecting samples for evaluation
2017-06-11 02:24:16.256578 EDT | -----------------------  -----------
2017-06-11 02:24:16.257312 EDT | Epoch                     899
2017-06-11 02:24:16.257522 EDT | Iteration                 899
2017-06-11 02:24:16.257731 EDT | AverageReturn            1691.53
2017-06-11 02:24:16.258051 EDT | StdReturn                 778.127
2017-06-11 02:24:16.258312 EDT | MaxReturn                3135.4
2017-06-11 02:24:16.258593 EDT | MinReturn                 708.062
2017-06-11 02:24:16.258871 EDT | AverageEsReturn           375.673
2017-06-11 02:24:16.259159 EDT | StdEsReturn               228.763
2017-06-11 02:24:16.259415 EDT | MaxEsReturn               768.578
2017-06-11 02:24:16.259672 EDT | MinEsReturn                87.0535
2017-06-11 02:24:16.259916 EDT | AverageDiscountedReturn   249.111
2017-06-11 02:24:16.260158 EDT | AverageQLoss                2.14037
2017-06-11 02:24:16.260423 EDT | AveragePolicySurr         -30.6566
2017-06-11 02:24:16.260684 EDT | AverageQ                   30.3214
2017-06-11 02:24:16.260961 EDT | AverageAbsQ                30.3435
2017-06-11 02:24:16.261229 EDT | AverageY                   30.3238
2017-06-11 02:24:16.261513 EDT | AverageAbsY                30.3355
2017-06-11 02:24:16.261830 EDT | AverageAbsQYDiff            0.520469
2017-06-11 02:24:16.262118 EDT | AverageAction               0.995398
2017-06-11 02:24:16.262398 EDT | PolicyRegParamNorm         93.0188
2017-06-11 02:24:16.262601 EDT | QFunRegParamNorm          120.694
2017-06-11 02:24:16.262876 EDT | -----------------------  -----------
2017-06-11 02:24:16.263318 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #900 | Training started
2017-06-11 02:24:33.821959 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #900 | Training finished
2017-06-11 02:24:33.837814 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #900 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 02:24:33.838463 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #900 | Collecting samples for evaluation
2017-06-11 02:24:47.323860 EDT | -----------------------  -----------
2017-06-11 02:24:47.325014 EDT | Epoch                     900
2017-06-11 02:24:47.325524 EDT | Iteration                 900
2017-06-11 02:24:47.326008 EDT | AverageReturn            1243.96
2017-06-11 02:24:47.326478 EDT | StdReturn                 317.91
2017-06-11 02:24:47.326941 EDT | MaxReturn                2151.98
2017-06-11 02:24:47.327412 EDT | MinReturn                 888.449
2017-06-11 02:24:47.327881 EDT | AverageEsReturn           551.541
2017-06-11 02:24:47.328344 EDT | StdEsReturn               235.505
2017-06-11 02:24:47.328810 EDT | MaxEsReturn               994.634
2017-06-11 02:24:47.329275 EDT | MinEsReturn               304.966
2017-06-11 02:24:47.329725 EDT | AverageDiscountedReturn   258.148
2017-06-11 02:24:47.330190 EDT | AverageQLoss                2.24349
2017-06-11 02:24:47.330663 EDT | AveragePolicySurr         -30.6496
2017-06-11 02:24:47.331134 EDT | AverageQ                   30.3205
2017-06-11 02:24:47.345925 EDT | AverageAbsQ                30.3482
2017-06-11 02:24:47.346502 EDT | AverageY                   30.3216
2017-06-11 02:24:47.346973 EDT | AverageAbsY                30.3345
2017-06-11 02:24:47.347418 EDT | AverageAbsQYDiff            0.535277
2017-06-11 02:24:47.347871 EDT | AverageAction               0.994506
2017-06-11 02:24:47.348320 EDT | PolicyRegParamNorm         93.0312
2017-06-11 02:24:47.348763 EDT | QFunRegParamNorm          120.74
2017-06-11 02:24:47.349204 EDT | -----------------------  -----------
2017-06-11 02:24:47.349865 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #901 | Training started
2017-06-11 02:25:06.880295 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #901 | Training finished
2017-06-11 02:25:06.881258 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #901 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 02:25:06.881644 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #901 | Collecting samples for evaluation
2017-06-11 02:25:21.099053 EDT | -----------------------  -----------
2017-06-11 02:25:21.099997 EDT | Epoch                     901
2017-06-11 02:25:21.100351 EDT | Iteration                 901
2017-06-11 02:25:21.100688 EDT | AverageReturn            3235.29
2017-06-11 02:25:21.101054 EDT | StdReturn                 351.533
2017-06-11 02:25:21.101385 EDT | MaxReturn                3445.42
2017-06-11 02:25:21.101719 EDT | MinReturn                2135.2
2017-06-11 02:25:21.102046 EDT | AverageEsReturn           296.895
2017-06-11 02:25:21.102371 EDT | StdEsReturn               193.413
2017-06-11 02:25:21.102697 EDT | MaxEsReturn               501.797
2017-06-11 02:25:21.103033 EDT | MinEsReturn                 7.05101
2017-06-11 02:25:21.103379 EDT | AverageDiscountedReturn   247.324
2017-06-11 02:25:21.103707 EDT | AverageQLoss                2.17948
2017-06-11 02:25:21.104033 EDT | AveragePolicySurr         -30.6336
2017-06-11 02:25:21.104358 EDT | AverageQ                   30.3108
2017-06-11 02:25:21.104680 EDT | AverageAbsQ                30.3335
2017-06-11 02:25:21.105002 EDT | AverageY                   30.3106
2017-06-11 02:25:21.105324 EDT | AverageAbsY                30.3213
2017-06-11 02:25:21.105645 EDT | AverageAbsQYDiff            0.526933
2017-06-11 02:25:21.105980 EDT | AverageAction               0.99289
2017-06-11 02:25:21.106302 EDT | PolicyRegParamNorm         93.1165
2017-06-11 02:25:21.106623 EDT | QFunRegParamNorm          120.801
2017-06-11 02:25:21.106951 EDT | -----------------------  -----------
2017-06-11 02:25:21.107417 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #902 | Training started
2017-06-11 02:25:39.340341 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #902 | Training finished
2017-06-11 02:25:39.344125 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #902 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 02:25:39.344573 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #902 | Collecting samples for evaluation
2017-06-11 02:25:53.344222 EDT | -----------------------  -----------
2017-06-11 02:25:53.344582 EDT | Epoch                     902
2017-06-11 02:25:53.344856 EDT | Iteration                 902
2017-06-11 02:25:53.345122 EDT | AverageReturn            2139.91
2017-06-11 02:25:53.345384 EDT | StdReturn                 857.402
2017-06-11 02:25:53.345645 EDT | MaxReturn                3482.29
2017-06-11 02:25:53.345918 EDT | MinReturn                 762.178
2017-06-11 02:25:53.346180 EDT | AverageEsReturn           453.156
2017-06-11 02:25:53.346439 EDT | StdEsReturn               335.547
2017-06-11 02:25:53.346699 EDT | MaxEsReturn               945.687
2017-06-11 02:25:53.346959 EDT | MinEsReturn                24.7343
2017-06-11 02:25:53.347217 EDT | AverageDiscountedReturn   252.14
2017-06-11 02:25:53.347476 EDT | AverageQLoss                2.42862
2017-06-11 02:25:53.347734 EDT | AveragePolicySurr         -30.6713
2017-06-11 02:25:53.347991 EDT | AverageQ                   30.3443
2017-06-11 02:25:53.348249 EDT | AverageAbsQ                30.3643
2017-06-11 02:25:53.348507 EDT | AverageY                   30.3456
2017-06-11 02:25:53.348765 EDT | AverageAbsY                30.3557
2017-06-11 02:25:53.349023 EDT | AverageAbsQYDiff            0.538695
2017-06-11 02:25:53.349280 EDT | AverageAction               0.993761
2017-06-11 02:25:53.349538 EDT | PolicyRegParamNorm         93.1137
2017-06-11 02:25:53.349805 EDT | QFunRegParamNorm          120.909
2017-06-11 02:25:53.350130 EDT | -----------------------  -----------
2017-06-11 02:25:53.350554 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #903 | Training started
2017-06-11 02:26:09.927966 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #903 | Training finished
2017-06-11 02:26:09.929713 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #903 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 02:26:09.930360 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #903 | Collecting samples for evaluation
2017-06-11 02:26:25.075716 EDT | -----------------------  -----------
2017-06-11 02:26:25.076772 EDT | Epoch                     903
2017-06-11 02:26:25.077101 EDT | Iteration                 903
2017-06-11 02:26:25.077304 EDT | AverageReturn            1038.91
2017-06-11 02:26:25.077501 EDT | StdReturn                 675.753
2017-06-11 02:26:25.077702 EDT | MaxReturn                3107.9
2017-06-11 02:26:25.077909 EDT | MinReturn                 393.36
2017-06-11 02:26:25.078103 EDT | AverageEsReturn           332.821
2017-06-11 02:26:25.078297 EDT | StdEsReturn               267.624
2017-06-11 02:26:25.078489 EDT | MaxEsReturn               845.132
2017-06-11 02:26:25.078681 EDT | MinEsReturn                23.2425
2017-06-11 02:26:25.078877 EDT | AverageDiscountedReturn   224.542
2017-06-11 02:26:25.079068 EDT | AverageQLoss                2.21128
2017-06-11 02:26:25.079260 EDT | AveragePolicySurr         -30.6142
2017-06-11 02:26:25.079452 EDT | AverageQ                   30.2911
2017-06-11 02:26:25.079649 EDT | AverageAbsQ                30.3166
2017-06-11 02:26:25.079840 EDT | AverageY                   30.2933
2017-06-11 02:26:25.080033 EDT | AverageAbsY                30.305
2017-06-11 02:26:25.080232 EDT | AverageAbsQYDiff            0.535483
2017-06-11 02:26:25.080423 EDT | AverageAction               0.994291
2017-06-11 02:26:25.080616 EDT | PolicyRegParamNorm         93.173
2017-06-11 02:26:25.080808 EDT | QFunRegParamNorm          120.973
2017-06-11 02:26:25.080998 EDT | -----------------------  -----------
2017-06-11 02:26:25.081306 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #904 | Training started
2017-06-11 02:26:42.166097 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #904 | Training finished
2017-06-11 02:26:42.166988 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #904 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 02:26:42.167271 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #904 | Collecting samples for evaluation
2017-06-11 02:26:56.551437 EDT | -----------------------  -----------
2017-06-11 02:26:56.560554 EDT | Epoch                     904
2017-06-11 02:26:56.560830 EDT | Iteration                 904
2017-06-11 02:26:56.560996 EDT | AverageReturn             967.745
2017-06-11 02:26:56.561227 EDT | StdReturn                 284.727
2017-06-11 02:26:56.561419 EDT | MaxReturn                1688.7
2017-06-11 02:26:56.561581 EDT | MinReturn                 591.3
2017-06-11 02:26:56.561762 EDT | AverageEsReturn           321.407
2017-06-11 02:26:56.562032 EDT | StdEsReturn               236.598
2017-06-11 02:26:56.562193 EDT | MaxEsReturn               680.589
2017-06-11 02:26:56.562349 EDT | MinEsReturn                65.1252
2017-06-11 02:26:56.562505 EDT | AverageDiscountedReturn   235.344
2017-06-11 02:26:56.563555 EDT | AverageQLoss                2.52132
2017-06-11 02:26:56.563756 EDT | AveragePolicySurr         -30.5974
2017-06-11 02:26:56.564031 EDT | AverageQ                   30.2569
2017-06-11 02:26:56.564291 EDT | AverageAbsQ                30.2791
2017-06-11 02:26:56.564508 EDT | AverageY                   30.2591
2017-06-11 02:26:56.564691 EDT | AverageAbsY                30.2687
2017-06-11 02:26:56.564919 EDT | AverageAbsQYDiff            0.556613
2017-06-11 02:26:56.565156 EDT | AverageAction               0.995676
2017-06-11 02:26:56.565337 EDT | PolicyRegParamNorm         93.2112
2017-06-11 02:26:56.565516 EDT | QFunRegParamNorm          121.029
2017-06-11 02:26:56.565773 EDT | -----------------------  -----------
2017-06-11 02:26:56.566179 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #905 | Training started
2017-06-11 02:27:13.360058 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #905 | Training finished
2017-06-11 02:27:13.361130 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #905 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 02:27:13.361518 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #905 | Collecting samples for evaluation
2017-06-11 02:27:26.549984 EDT | -----------------------  -----------
2017-06-11 02:27:26.550947 EDT | Epoch                     905
2017-06-11 02:27:26.551143 EDT | Iteration                 905
2017-06-11 02:27:26.551379 EDT | AverageReturn            1339.1
2017-06-11 02:27:26.555089 EDT | StdReturn                 566.837
2017-06-11 02:27:26.555528 EDT | MaxReturn                2865.27
2017-06-11 02:27:26.555895 EDT | MinReturn                 888.834
2017-06-11 02:27:26.556251 EDT | AverageEsReturn           361.28
2017-06-11 02:27:26.556554 EDT | StdEsReturn               205.076
2017-06-11 02:27:26.556876 EDT | MaxEsReturn               791.666
2017-06-11 02:27:26.557236 EDT | MinEsReturn               124.598
2017-06-11 02:27:26.558392 EDT | AverageDiscountedReturn   228.091
2017-06-11 02:27:26.558781 EDT | AverageQLoss                2.3669
2017-06-11 02:27:26.559003 EDT | AveragePolicySurr         -30.6321
2017-06-11 02:27:26.559175 EDT | AverageQ                   30.2927
2017-06-11 02:27:26.559330 EDT | AverageAbsQ                30.3163
2017-06-11 02:27:26.559510 EDT | AverageY                   30.2932
2017-06-11 02:27:26.559740 EDT | AverageAbsY                30.3035
2017-06-11 02:27:26.559893 EDT | AverageAbsQYDiff            0.54868
2017-06-11 02:27:26.560044 EDT | AverageAction               0.994447
2017-06-11 02:27:26.560194 EDT | PolicyRegParamNorm         93.2253
2017-06-11 02:27:26.560342 EDT | QFunRegParamNorm          121.096
2017-06-11 02:27:26.560586 EDT | -----------------------  -----------
2017-06-11 02:27:26.560895 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #906 | Training started
2017-06-11 02:27:46.077227 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #906 | Training finished
2017-06-11 02:27:46.078358 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #906 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 02:27:46.078776 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #906 | Collecting samples for evaluation
2017-06-11 02:27:59.795322 EDT | -----------------------  -----------
2017-06-11 02:27:59.796318 EDT | Epoch                     906
2017-06-11 02:27:59.796766 EDT | Iteration                 906
2017-06-11 02:27:59.797120 EDT | AverageReturn            1103.39
2017-06-11 02:27:59.797544 EDT | StdReturn                 496.739
2017-06-11 02:27:59.798007 EDT | MaxReturn                2913.93
2017-06-11 02:27:59.798408 EDT | MinReturn                 432.407
2017-06-11 02:27:59.798767 EDT | AverageEsReturn           506.428
2017-06-11 02:27:59.799184 EDT | StdEsReturn               322.075
2017-06-11 02:27:59.799618 EDT | MaxEsReturn               814.529
2017-06-11 02:27:59.799995 EDT | MinEsReturn                83.8834
2017-06-11 02:27:59.800371 EDT | AverageDiscountedReturn   226.133
2017-06-11 02:27:59.800784 EDT | AverageQLoss                1.9272
2017-06-11 02:27:59.801214 EDT | AveragePolicySurr         -30.6509
2017-06-11 02:27:59.801577 EDT | AverageQ                   30.3235
2017-06-11 02:27:59.801995 EDT | AverageAbsQ                30.3456
2017-06-11 02:27:59.802420 EDT | AverageY                   30.326
2017-06-11 02:27:59.802840 EDT | AverageAbsY                30.3348
2017-06-11 02:27:59.803189 EDT | AverageAbsQYDiff            0.520508
2017-06-11 02:27:59.803610 EDT | AverageAction               0.995221
2017-06-11 02:27:59.804043 EDT | PolicyRegParamNorm         93.327
2017-06-11 02:27:59.804441 EDT | QFunRegParamNorm          121.112
2017-06-11 02:27:59.804797 EDT | -----------------------  -----------
2017-06-11 02:27:59.805373 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #907 | Training started
2017-06-11 02:28:15.502378 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #907 | Training finished
2017-06-11 02:28:15.503287 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #907 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 02:28:15.503509 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #907 | Collecting samples for evaluation
2017-06-11 02:28:29.281227 EDT | -----------------------  -----------
2017-06-11 02:28:29.283106 EDT | Epoch                     907
2017-06-11 02:28:29.283414 EDT | Iteration                 907
2017-06-11 02:28:29.283587 EDT | AverageReturn            2168.04
2017-06-11 02:28:29.283745 EDT | StdReturn                 693.072
2017-06-11 02:28:29.284061 EDT | MaxReturn                2978.06
2017-06-11 02:28:29.284428 EDT | MinReturn                1093.12
2017-06-11 02:28:29.284717 EDT | AverageEsReturn           473.284
2017-06-11 02:28:29.284879 EDT | StdEsReturn               290.048
2017-06-11 02:28:29.285040 EDT | MaxEsReturn              1032.26
2017-06-11 02:28:29.285193 EDT | MinEsReturn               153.922
2017-06-11 02:28:29.285344 EDT | AverageDiscountedReturn   240.835
2017-06-11 02:28:29.285494 EDT | AverageQLoss                2.16257
2017-06-11 02:28:29.285643 EDT | AveragePolicySurr         -30.5909
2017-06-11 02:28:29.285844 EDT | AverageQ                   30.2746
2017-06-11 02:28:29.286000 EDT | AverageAbsQ                30.2939
2017-06-11 02:28:29.286209 EDT | AverageY                   30.2754
2017-06-11 02:28:29.286384 EDT | AverageAbsY                30.2824
2017-06-11 02:28:29.286572 EDT | AverageAbsQYDiff            0.525525
2017-06-11 02:28:29.286791 EDT | AverageAction               0.995963
2017-06-11 02:28:29.287036 EDT | PolicyRegParamNorm         93.3375
2017-06-11 02:28:29.290383 EDT | QFunRegParamNorm          121.187
2017-06-11 02:28:29.291507 EDT | -----------------------  -----------
2017-06-11 02:28:29.291826 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #908 | Training started
2017-06-11 02:28:45.407625 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #908 | Training finished
2017-06-11 02:28:45.408453 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #908 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 02:28:45.408645 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #908 | Collecting samples for evaluation
2017-06-11 02:28:59.642906 EDT | -----------------------  -----------
2017-06-11 02:28:59.643893 EDT | Epoch                     908
2017-06-11 02:28:59.644278 EDT | Iteration                 908
2017-06-11 02:28:59.644709 EDT | AverageReturn            2279.29
2017-06-11 02:28:59.645015 EDT | StdReturn                 792.104
2017-06-11 02:28:59.645354 EDT | MaxReturn                3232.17
2017-06-11 02:28:59.645710 EDT | MinReturn                1287.88
2017-06-11 02:28:59.646083 EDT | AverageEsReturn           409.59
2017-06-11 02:28:59.646425 EDT | StdEsReturn               277.308
2017-06-11 02:28:59.646765 EDT | MaxEsReturn               824.875
2017-06-11 02:28:59.647140 EDT | MinEsReturn                30.9516
2017-06-11 02:28:59.647474 EDT | AverageDiscountedReturn   249.239
2017-06-11 02:28:59.647808 EDT | AverageQLoss                2.27455
2017-06-11 02:28:59.648366 EDT | AveragePolicySurr         -30.6189
2017-06-11 02:28:59.648711 EDT | AverageQ                   30.2924
2017-06-11 02:28:59.649424 EDT | AverageAbsQ                30.3126
2017-06-11 02:28:59.649851 EDT | AverageY                   30.2949
2017-06-11 02:28:59.650162 EDT | AverageAbsY                30.3013
2017-06-11 02:28:59.650492 EDT | AverageAbsQYDiff            0.542774
2017-06-11 02:28:59.650864 EDT | AverageAction               0.995647
2017-06-11 02:28:59.651175 EDT | PolicyRegParamNorm         93.3707
2017-06-11 02:28:59.651508 EDT | QFunRegParamNorm          121.236
2017-06-11 02:28:59.651888 EDT | -----------------------  -----------
2017-06-11 02:28:59.652398 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #909 | Training started
2017-06-11 02:29:16.132398 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #909 | Training finished
2017-06-11 02:29:16.134069 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #909 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 02:29:16.134744 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #909 | Collecting samples for evaluation
2017-06-11 02:29:28.817890 EDT | -----------------------  -----------
2017-06-11 02:29:28.818851 EDT | Epoch                     909
2017-06-11 02:29:28.819176 EDT | Iteration                 909
2017-06-11 02:29:28.819443 EDT | AverageReturn            1798.28
2017-06-11 02:29:28.819804 EDT | StdReturn                 726.673
2017-06-11 02:29:28.820116 EDT | MaxReturn                3166.22
2017-06-11 02:29:28.820436 EDT | MinReturn                1060.79
2017-06-11 02:29:28.820760 EDT | AverageEsReturn           362.425
2017-06-11 02:29:28.821078 EDT | StdEsReturn               282.205
2017-06-11 02:29:28.821392 EDT | MaxEsReturn               817.313
2017-06-11 02:29:28.821657 EDT | MinEsReturn                51.1033
2017-06-11 02:29:28.821997 EDT | AverageDiscountedReturn   251.624
2017-06-11 02:29:28.822302 EDT | AverageQLoss                2.39108
2017-06-11 02:29:28.822623 EDT | AveragePolicySurr         -30.6439
2017-06-11 02:29:28.822943 EDT | AverageQ                   30.3252
2017-06-11 02:29:28.823414 EDT | AverageAbsQ                30.3445
2017-06-11 02:29:28.823575 EDT | AverageY                   30.3241
2017-06-11 02:29:28.823729 EDT | AverageAbsY                30.3311
2017-06-11 02:29:28.823882 EDT | AverageAbsQYDiff            0.545323
2017-06-11 02:29:28.824407 EDT | AverageAction               0.995377
2017-06-11 02:29:28.824568 EDT | PolicyRegParamNorm         93.4135
2017-06-11 02:29:28.824722 EDT | QFunRegParamNorm          121.272
2017-06-11 02:29:28.824873 EDT | -----------------------  -----------
2017-06-11 02:29:28.825138 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #910 | Training started
2017-06-11 02:29:45.816795 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #910 | Training finished
2017-06-11 02:29:45.817667 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #910 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 02:29:45.818083 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #910 | Collecting samples for evaluation
2017-06-11 02:29:59.070195 EDT | -----------------------  -----------
2017-06-11 02:29:59.072713 EDT | Epoch                     910
2017-06-11 02:29:59.073102 EDT | Iteration                 910
2017-06-11 02:29:59.074467 EDT | AverageReturn             962.334
2017-06-11 02:29:59.076504 EDT | StdReturn                 139.667
2017-06-11 02:29:59.076884 EDT | MaxReturn                1282.1
2017-06-11 02:29:59.077243 EDT | MinReturn                 741.338
2017-06-11 02:29:59.077601 EDT | AverageEsReturn           375.264
2017-06-11 02:29:59.077967 EDT | StdEsReturn               219.668
2017-06-11 02:29:59.078997 EDT | MaxEsReturn               603.589
2017-06-11 02:29:59.080838 EDT | MinEsReturn                62.59
2017-06-11 02:29:59.081218 EDT | AverageDiscountedReturn   242.314
2017-06-11 02:29:59.081576 EDT | AverageQLoss                2.20297
2017-06-11 02:29:59.081945 EDT | AveragePolicySurr         -30.5402
2017-06-11 02:29:59.082783 EDT | AverageQ                   30.2077
2017-06-11 02:29:59.084416 EDT | AverageAbsQ                30.2313
2017-06-11 02:29:59.084890 EDT | AverageY                   30.2077
2017-06-11 02:29:59.085339 EDT | AverageAbsY                30.2187
2017-06-11 02:29:59.085789 EDT | AverageAbsQYDiff            0.53552
2017-06-11 02:29:59.086368 EDT | AverageAction               0.996086
2017-06-11 02:29:59.086821 EDT | PolicyRegParamNorm         93.4264
2017-06-11 02:29:59.087266 EDT | QFunRegParamNorm          121.377
2017-06-11 02:29:59.087709 EDT | -----------------------  -----------
2017-06-11 02:29:59.088323 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #911 | Training started
2017-06-11 02:30:14.893888 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #911 | Training finished
2017-06-11 02:30:14.894822 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #911 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 02:30:14.895208 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #911 | Collecting samples for evaluation
2017-06-11 02:30:29.943234 EDT | -----------------------  -----------
2017-06-11 02:30:29.946182 EDT | Epoch                     911
2017-06-11 02:30:29.947155 EDT | Iteration                 911
2017-06-11 02:30:29.948810 EDT | AverageReturn            1065.3
2017-06-11 02:30:29.949231 EDT | StdReturn                 212.001
2017-06-11 02:30:29.949591 EDT | MaxReturn                1810.03
2017-06-11 02:30:29.950760 EDT | MinReturn                 735.723
2017-06-11 02:30:29.951163 EDT | AverageEsReturn           473.341
2017-06-11 02:30:29.952930 EDT | StdEsReturn               191.743
2017-06-11 02:30:29.954017 EDT | MaxEsReturn               798.569
2017-06-11 02:30:29.954403 EDT | MinEsReturn               167.933
2017-06-11 02:30:29.956680 EDT | AverageDiscountedReturn   239.96
2017-06-11 02:30:29.957141 EDT | AverageQLoss                2.33489
2017-06-11 02:30:29.957591 EDT | AveragePolicySurr         -30.5767
2017-06-11 02:30:29.958044 EDT | AverageQ                   30.2485
2017-06-11 02:30:29.959228 EDT | AverageAbsQ                30.2725
2017-06-11 02:30:29.959685 EDT | AverageY                   30.2508
2017-06-11 02:30:29.961724 EDT | AverageAbsY                30.2599
2017-06-11 02:30:29.962165 EDT | AverageAbsQYDiff            0.548471
2017-06-11 02:30:29.962611 EDT | AverageAction               0.995357
2017-06-11 02:30:29.963054 EDT | PolicyRegParamNorm         93.4155
2017-06-11 02:30:29.964460 EDT | QFunRegParamNorm          121.424
2017-06-11 02:30:29.964922 EDT | -----------------------  -----------
2017-06-11 02:30:29.966983 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #912 | Training started
2017-06-11 02:30:47.118925 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #912 | Training finished
2017-06-11 02:30:47.119362 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #912 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 02:30:47.119735 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #912 | Collecting samples for evaluation
2017-06-11 02:31:00.900544 EDT | -----------------------  -----------
2017-06-11 02:31:00.901643 EDT | Epoch                     912
2017-06-11 02:31:00.902096 EDT | Iteration                 912
2017-06-11 02:31:00.902475 EDT | AverageReturn             925.565
2017-06-11 02:31:00.902824 EDT | StdReturn                 133.734
2017-06-11 02:31:00.903159 EDT | MaxReturn                1380.21
2017-06-11 02:31:00.903582 EDT | MinReturn                 769.941
2017-06-11 02:31:00.904002 EDT | AverageEsReturn           433.597
2017-06-11 02:31:00.904419 EDT | StdEsReturn               234.755
2017-06-11 02:31:00.905345 EDT | MaxEsReturn               840.464
2017-06-11 02:31:00.906276 EDT | MinEsReturn                77.7057
2017-06-11 02:31:00.907179 EDT | AverageDiscountedReturn   231.172
2017-06-11 02:31:00.908282 EDT | AverageQLoss                1.97075
2017-06-11 02:31:00.909309 EDT | AveragePolicySurr         -30.6741
2017-06-11 02:31:00.910435 EDT | AverageQ                   30.348
2017-06-11 02:31:00.911376 EDT | AverageAbsQ                30.3704
2017-06-11 02:31:00.912283 EDT | AverageY                   30.3486
2017-06-11 02:31:00.913308 EDT | AverageAbsY                30.3612
2017-06-11 02:31:00.914417 EDT | AverageAbsQYDiff            0.517367
2017-06-11 02:31:00.915509 EDT | AverageAction               0.994767
2017-06-11 02:31:00.916435 EDT | PolicyRegParamNorm         93.4317
2017-06-11 02:31:00.917570 EDT | QFunRegParamNorm          121.459
2017-06-11 02:31:00.918705 EDT | -----------------------  -----------
2017-06-11 02:31:00.919863 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #913 | Training started
2017-06-11 02:31:18.577290 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #913 | Training finished
2017-06-11 02:31:18.577548 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #913 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 02:31:18.577734 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #913 | Collecting samples for evaluation
2017-06-11 02:31:30.888136 EDT | -----------------------  -----------
2017-06-11 02:31:30.891897 EDT | Epoch                     913
2017-06-11 02:31:30.892200 EDT | Iteration                 913
2017-06-11 02:31:30.892386 EDT | AverageReturn            1059.2
2017-06-11 02:31:30.892594 EDT | StdReturn                 187.668
2017-06-11 02:31:30.892851 EDT | MaxReturn                1642.36
2017-06-11 02:31:30.893015 EDT | MinReturn                 851.528
2017-06-11 02:31:30.893298 EDT | AverageEsReturn           289.761
2017-06-11 02:31:30.893548 EDT | StdEsReturn               194.612
2017-06-11 02:31:30.893808 EDT | MaxEsReturn               575.013
2017-06-11 02:31:30.894092 EDT | MinEsReturn                56.8732
2017-06-11 02:31:30.894380 EDT | AverageDiscountedReturn   250.181
2017-06-11 02:31:30.894661 EDT | AverageQLoss                2.25234
2017-06-11 02:31:30.894859 EDT | AveragePolicySurr         -30.5897
2017-06-11 02:31:30.895012 EDT | AverageQ                   30.2589
2017-06-11 02:31:30.895163 EDT | AverageAbsQ                30.277
2017-06-11 02:31:30.895314 EDT | AverageY                   30.2602
2017-06-11 02:31:30.895463 EDT | AverageAbsY                30.2668
2017-06-11 02:31:30.895612 EDT | AverageAbsQYDiff            0.54149
2017-06-11 02:31:30.895765 EDT | AverageAction               0.994674
2017-06-11 02:31:30.896012 EDT | PolicyRegParamNorm         93.4425
2017-06-11 02:31:30.896184 EDT | QFunRegParamNorm          121.572
2017-06-11 02:31:30.896337 EDT | -----------------------  -----------
2017-06-11 02:31:30.896695 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #914 | Training started
2017-06-11 02:31:48.334250 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #914 | Training finished
2017-06-11 02:31:48.334742 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #914 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 02:31:48.335226 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #914 | Collecting samples for evaluation
2017-06-11 02:32:01.970348 EDT | -----------------------  -----------
2017-06-11 02:32:01.971145 EDT | Epoch                     914
2017-06-11 02:32:01.971664 EDT | Iteration                 914
2017-06-11 02:32:01.972003 EDT | AverageReturn            1940.45
2017-06-11 02:32:01.972328 EDT | StdReturn                 791.963
2017-06-11 02:32:01.972517 EDT | MaxReturn                2997.06
2017-06-11 02:32:01.972700 EDT | MinReturn                 651.241
2017-06-11 02:32:01.973094 EDT | AverageEsReturn           294.568
2017-06-11 02:32:01.973333 EDT | StdEsReturn               214.981
2017-06-11 02:32:01.973527 EDT | MaxEsReturn               630.133
2017-06-11 02:32:01.973725 EDT | MinEsReturn                64.5942
2017-06-11 02:32:01.974029 EDT | AverageDiscountedReturn   237.659
2017-06-11 02:32:01.974410 EDT | AverageQLoss                2.25134
2017-06-11 02:32:01.974674 EDT | AveragePolicySurr         -30.6231
2017-06-11 02:32:01.974861 EDT | AverageQ                   30.2995
2017-06-11 02:32:01.975151 EDT | AverageAbsQ                30.322
2017-06-11 02:32:01.975336 EDT | AverageY                   30.2998
2017-06-11 02:32:01.975517 EDT | AverageAbsY                30.308
2017-06-11 02:32:01.975706 EDT | AverageAbsQYDiff            0.530477
2017-06-11 02:32:01.975885 EDT | AverageAction               0.993371
2017-06-11 02:32:01.976065 EDT | PolicyRegParamNorm         93.5731
2017-06-11 02:32:01.976244 EDT | QFunRegParamNorm          121.625
2017-06-11 02:32:01.976424 EDT | -----------------------  -----------
2017-06-11 02:32:01.976781 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #915 | Training started
2017-06-11 02:32:18.732642 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #915 | Training finished
2017-06-11 02:32:18.733095 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #915 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 02:32:18.733415 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #915 | Collecting samples for evaluation
2017-06-11 02:32:34.091298 EDT | -----------------------  -----------
2017-06-11 02:32:34.092401 EDT | Epoch                     915
2017-06-11 02:32:34.092607 EDT | Iteration                 915
2017-06-11 02:32:34.092800 EDT | AverageReturn            2818.57
2017-06-11 02:32:34.093026 EDT | StdReturn                 428.319
2017-06-11 02:32:34.093245 EDT | MaxReturn                3125.96
2017-06-11 02:32:34.093437 EDT | MinReturn                1768.94
2017-06-11 02:32:34.093620 EDT | AverageEsReturn           278.648
2017-06-11 02:32:34.094038 EDT | StdEsReturn               221.462
2017-06-11 02:32:34.094217 EDT | MaxEsReturn               587.497
2017-06-11 02:32:34.094411 EDT | MinEsReturn                 7.39951
2017-06-11 02:32:34.094594 EDT | AverageDiscountedReturn   242.447
2017-06-11 02:32:34.094776 EDT | AverageQLoss                2.37649
2017-06-11 02:32:34.094954 EDT | AveragePolicySurr         -30.6561
2017-06-11 02:32:34.095133 EDT | AverageQ                   30.3006
2017-06-11 02:32:34.095312 EDT | AverageAbsQ                30.3188
2017-06-11 02:32:34.095498 EDT | AverageY                   30.3034
2017-06-11 02:32:34.095730 EDT | AverageAbsY                30.31
2017-06-11 02:32:34.095911 EDT | AverageAbsQYDiff            0.541375
2017-06-11 02:32:34.096089 EDT | AverageAction               0.993112
2017-06-11 02:32:34.096269 EDT | PolicyRegParamNorm         93.603
2017-06-11 02:32:34.096709 EDT | QFunRegParamNorm          121.666
2017-06-11 02:32:34.097054 EDT | -----------------------  -----------
2017-06-11 02:32:34.100651 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #916 | Training started
2017-06-11 02:32:51.316215 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #916 | Training finished
2017-06-11 02:32:51.317228 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #916 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 02:32:51.317643 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #916 | Collecting samples for evaluation
2017-06-11 02:33:06.313928 EDT | -----------------------  -----------
2017-06-11 02:33:06.315016 EDT | Epoch                     916
2017-06-11 02:33:06.315291 EDT | Iteration                 916
2017-06-11 02:33:06.315545 EDT | AverageReturn            2022.27
2017-06-11 02:33:06.315795 EDT | StdReturn                1304.47
2017-06-11 02:33:06.316043 EDT | MaxReturn                3518.1
2017-06-11 02:33:06.316291 EDT | MinReturn                 258.363
2017-06-11 02:33:06.316537 EDT | AverageEsReturn           707.427
2017-06-11 02:33:06.316782 EDT | StdEsReturn               254.133
2017-06-11 02:33:06.317028 EDT | MaxEsReturn              1034.03
2017-06-11 02:33:06.317273 EDT | MinEsReturn               498.228
2017-06-11 02:33:06.317519 EDT | AverageDiscountedReturn   218.072
2017-06-11 02:33:06.317778 EDT | AverageQLoss                2.13679
2017-06-11 02:33:06.318025 EDT | AveragePolicySurr         -30.6432
2017-06-11 02:33:06.318270 EDT | AverageQ                   30.3082
2017-06-11 02:33:06.318518 EDT | AverageAbsQ                30.3262
2017-06-11 02:33:06.318763 EDT | AverageY                   30.3096
2017-06-11 02:33:06.319007 EDT | AverageAbsY                30.3178
2017-06-11 02:33:06.319251 EDT | AverageAbsQYDiff            0.527105
2017-06-11 02:33:06.319504 EDT | AverageAction               0.993257
2017-06-11 02:33:06.319751 EDT | PolicyRegParamNorm         93.6553
2017-06-11 02:33:06.319996 EDT | QFunRegParamNorm          121.684
2017-06-11 02:33:06.320240 EDT | -----------------------  -----------
2017-06-11 02:33:06.320638 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #917 | Training started
2017-06-11 02:33:23.327801 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #917 | Training finished
2017-06-11 02:33:23.328811 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #917 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 02:33:23.329515 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #917 | Collecting samples for evaluation
2017-06-11 02:33:36.347198 EDT | -----------------------  -----------
2017-06-11 02:33:36.348281 EDT | Epoch                     917
2017-06-11 02:33:36.348657 EDT | Iteration                 917
2017-06-11 02:33:36.349010 EDT | AverageReturn             617.587
2017-06-11 02:33:36.349356 EDT | StdReturn                 911.323
2017-06-11 02:33:36.349708 EDT | MaxReturn                3411.26
2017-06-11 02:33:36.350057 EDT | MinReturn                 258.072
2017-06-11 02:33:36.350409 EDT | AverageEsReturn           402.486
2017-06-11 02:33:36.350760 EDT | StdEsReturn               299.553
2017-06-11 02:33:36.351107 EDT | MaxEsReturn               931.009
2017-06-11 02:33:36.351451 EDT | MinEsReturn                20.6447
2017-06-11 02:33:36.351794 EDT | AverageDiscountedReturn   162.112
2017-06-11 02:33:36.352138 EDT | AverageQLoss                2.28991
2017-06-11 02:33:36.352486 EDT | AveragePolicySurr         -30.6729
2017-06-11 02:33:36.365567 EDT | AverageQ                   30.3701
2017-06-11 02:33:36.365956 EDT | AverageAbsQ                30.3895
2017-06-11 02:33:36.366674 EDT | AverageY                   30.3687
2017-06-11 02:33:36.367028 EDT | AverageAbsY                30.3758
2017-06-11 02:33:36.367380 EDT | AverageAbsQYDiff            0.517372
2017-06-11 02:33:36.367731 EDT | AverageAction               0.993343
2017-06-11 02:33:36.368079 EDT | PolicyRegParamNorm         93.69
2017-06-11 02:33:36.368420 EDT | QFunRegParamNorm          121.721
2017-06-11 02:33:36.368767 EDT | -----------------------  -----------
2017-06-11 02:33:36.369631 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #918 | Training started
2017-06-11 02:33:54.061844 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #918 | Training finished
2017-06-11 02:33:54.062912 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #918 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 02:33:54.063364 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #918 | Collecting samples for evaluation
2017-06-11 02:34:08.739396 EDT | -----------------------  -----------
2017-06-11 02:34:08.740720 EDT | Epoch                     918
2017-06-11 02:34:08.741129 EDT | Iteration                 918
2017-06-11 02:34:08.741488 EDT | AverageReturn            2727.77
2017-06-11 02:34:08.741737 EDT | StdReturn                 800.271
2017-06-11 02:34:08.742035 EDT | MaxReturn                3565.02
2017-06-11 02:34:08.742725 EDT | MinReturn                1242.49
2017-06-11 02:34:08.743451 EDT | AverageEsReturn           355.659
2017-06-11 02:34:08.743874 EDT | StdEsReturn               250.653
2017-06-11 02:34:08.744287 EDT | MaxEsReturn               938.846
2017-06-11 02:34:08.744776 EDT | MinEsReturn                33.6291
2017-06-11 02:34:08.745192 EDT | AverageDiscountedReturn   261.513
2017-06-11 02:34:08.745666 EDT | AverageQLoss                2.52127
2017-06-11 02:34:08.746095 EDT | AveragePolicySurr         -30.7146
2017-06-11 02:34:08.746513 EDT | AverageQ                   30.3702
2017-06-11 02:34:08.746830 EDT | AverageAbsQ                30.3885
2017-06-11 02:34:08.747300 EDT | AverageY                   30.3708
2017-06-11 02:34:08.747552 EDT | AverageAbsY                30.3759
2017-06-11 02:34:08.747959 EDT | AverageAbsQYDiff            0.570488
2017-06-11 02:34:08.748377 EDT | AverageAction               0.992412
2017-06-11 02:34:08.748789 EDT | PolicyRegParamNorm         93.6808
2017-06-11 02:34:08.748999 EDT | QFunRegParamNorm          121.818
2017-06-11 02:34:08.749387 EDT | -----------------------  -----------
2017-06-11 02:34:08.749961 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #919 | Training started
2017-06-11 02:34:24.845947 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #919 | Training finished
2017-06-11 02:34:24.847159 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #919 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 02:34:24.847658 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #919 | Collecting samples for evaluation
2017-06-11 02:34:40.891591 EDT | -----------------------  -----------
2017-06-11 02:34:40.892291 EDT | Epoch                     919
2017-06-11 02:34:40.892730 EDT | Iteration                 919
2017-06-11 02:34:40.893088 EDT | AverageReturn            2125.43
2017-06-11 02:34:40.893448 EDT | StdReturn                1158.15
2017-06-11 02:34:40.893824 EDT | MaxReturn                3336.02
2017-06-11 02:34:40.894183 EDT | MinReturn                 234.301
2017-06-11 02:34:40.894542 EDT | AverageEsReturn           300.603
2017-06-11 02:34:40.894981 EDT | StdEsReturn               261.624
2017-06-11 02:34:40.895336 EDT | MaxEsReturn               787.289
2017-06-11 02:34:40.895683 EDT | MinEsReturn                37.5244
2017-06-11 02:34:40.896028 EDT | AverageDiscountedReturn   223.589
2017-06-11 02:34:40.896372 EDT | AverageQLoss                1.82264
2017-06-11 02:34:40.896715 EDT | AveragePolicySurr         -30.7252
2017-06-11 02:34:40.897071 EDT | AverageQ                   30.3879
2017-06-11 02:34:40.897416 EDT | AverageAbsQ                30.4049
2017-06-11 02:34:40.897768 EDT | AverageY                   30.3884
2017-06-11 02:34:40.898111 EDT | AverageAbsY                30.3959
2017-06-11 02:34:40.898452 EDT | AverageAbsQYDiff            0.50459
2017-06-11 02:34:40.898795 EDT | AverageAction               0.993604
2017-06-11 02:34:40.899105 EDT | PolicyRegParamNorm         93.7816
2017-06-11 02:34:40.899426 EDT | QFunRegParamNorm          121.89
2017-06-11 02:34:40.899832 EDT | -----------------------  -----------
2017-06-11 02:34:40.900409 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #920 | Training started
2017-06-11 02:34:57.964906 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #920 | Training finished
2017-06-11 02:34:57.965725 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #920 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 02:34:57.965934 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #920 | Collecting samples for evaluation
2017-06-11 02:35:12.999099 EDT | -----------------------  -----------
2017-06-11 02:35:12.999396 EDT | Epoch                     920
2017-06-11 02:35:12.999574 EDT | Iteration                 920
2017-06-11 02:35:12.999776 EDT | AverageReturn            1456.17
2017-06-11 02:35:12.999959 EDT | StdReturn                1270.48
2017-06-11 02:35:13.000321 EDT | MaxReturn                3313.22
2017-06-11 02:35:13.000778 EDT | MinReturn                 222.278
2017-06-11 02:35:13.001028 EDT | AverageEsReturn           336.766
2017-06-11 02:35:13.001215 EDT | StdEsReturn               232.893
2017-06-11 02:35:13.001397 EDT | MaxEsReturn               742.019
2017-06-11 02:35:13.001634 EDT | MinEsReturn                18.946
2017-06-11 02:35:13.001844 EDT | AverageDiscountedReturn   192.056
2017-06-11 02:35:13.002027 EDT | AverageQLoss                2.18143
2017-06-11 02:35:13.002242 EDT | AveragePolicySurr         -30.6372
2017-06-11 02:35:13.002425 EDT | AverageQ                   30.3188
2017-06-11 02:35:13.002698 EDT | AverageAbsQ                30.3453
2017-06-11 02:35:13.002890 EDT | AverageY                   30.3211
2017-06-11 02:35:13.003072 EDT | AverageAbsY                30.3289
2017-06-11 02:35:13.003251 EDT | AverageAbsQYDiff            0.536219
2017-06-11 02:35:13.003430 EDT | AverageAction               0.993921
2017-06-11 02:35:13.003610 EDT | PolicyRegParamNorm         93.8412
2017-06-11 02:35:13.003788 EDT | QFunRegParamNorm          121.98
2017-06-11 02:35:13.003977 EDT | -----------------------  -----------
2017-06-11 02:35:13.004327 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #921 | Training started
2017-06-11 02:35:30.989532 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #921 | Training finished
2017-06-11 02:35:30.990858 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #921 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 02:35:30.991671 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #921 | Collecting samples for evaluation
2017-06-11 02:35:44.690035 EDT | -----------------------  -----------
2017-06-11 02:35:44.690981 EDT | Epoch                     921
2017-06-11 02:35:44.691188 EDT | Iteration                 921
2017-06-11 02:35:44.691373 EDT | AverageReturn             410.015
2017-06-11 02:35:44.691567 EDT | StdReturn                 332.651
2017-06-11 02:35:44.691753 EDT | MaxReturn                1812.19
2017-06-11 02:35:44.691934 EDT | MinReturn                 216.737
2017-06-11 02:35:44.692568 EDT | AverageEsReturn           604.954
2017-06-11 02:35:44.697266 EDT | StdEsReturn               461.022
2017-06-11 02:35:44.697533 EDT | MaxEsReturn              1011.51
2017-06-11 02:35:44.697748 EDT | MinEsReturn                34.093
2017-06-11 02:35:44.698309 EDT | AverageDiscountedReturn   158.673
2017-06-11 02:35:44.698529 EDT | AverageQLoss                2.44651
2017-06-11 02:35:44.698725 EDT | AveragePolicySurr         -30.6696
2017-06-11 02:35:44.698910 EDT | AverageQ                   30.344
2017-06-11 02:35:44.699089 EDT | AverageAbsQ                30.3648
2017-06-11 02:35:44.699331 EDT | AverageY                   30.3431
2017-06-11 02:35:44.699511 EDT | AverageAbsY                30.3502
2017-06-11 02:35:44.699692 EDT | AverageAbsQYDiff            0.573379
2017-06-11 02:35:44.699876 EDT | AverageAction               0.996349
2017-06-11 02:35:44.700098 EDT | PolicyRegParamNorm         93.8391
2017-06-11 02:35:44.700280 EDT | QFunRegParamNorm          122.033
2017-06-11 02:35:44.700458 EDT | -----------------------  -----------
2017-06-11 02:35:44.700765 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #922 | Training started
2017-06-11 02:36:02.432939 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #922 | Training finished
2017-06-11 02:36:02.434163 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #922 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 02:36:02.434543 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #922 | Collecting samples for evaluation
2017-06-11 02:36:15.845427 EDT | -----------------------  -----------
2017-06-11 02:36:15.846468 EDT | Epoch                     922
2017-06-11 02:36:15.846820 EDT | Iteration                 922
2017-06-11 02:36:15.847141 EDT | AverageReturn            1946.41
2017-06-11 02:36:15.847463 EDT | StdReturn                 837.217
2017-06-11 02:36:15.847783 EDT | MaxReturn                3550.25
2017-06-11 02:36:15.848136 EDT | MinReturn                 811.383
2017-06-11 02:36:15.848455 EDT | AverageEsReturn           277.759
2017-06-11 02:36:15.848782 EDT | StdEsReturn               265.856
2017-06-11 02:36:15.849122 EDT | MaxEsReturn               908.366
2017-06-11 02:36:15.849443 EDT | MinEsReturn                22.5584
2017-06-11 02:36:15.849786 EDT | AverageDiscountedReturn   251.471
2017-06-11 02:36:15.850126 EDT | AverageQLoss                2.03803
2017-06-11 02:36:15.850454 EDT | AveragePolicySurr         -30.6905
2017-06-11 02:36:15.850776 EDT | AverageQ                   30.3667
2017-06-11 02:36:15.851117 EDT | AverageAbsQ                30.3848
2017-06-11 02:36:15.851448 EDT | AverageY                   30.3706
2017-06-11 02:36:15.852904 EDT | AverageAbsY                30.3764
2017-06-11 02:36:15.853248 EDT | AverageAbsQYDiff            0.544844
2017-06-11 02:36:15.853850 EDT | AverageAction               0.993965
2017-06-11 02:36:15.854215 EDT | PolicyRegParamNorm         93.8861
2017-06-11 02:36:15.856809 EDT | QFunRegParamNorm          122.084
2017-06-11 02:36:15.857115 EDT | -----------------------  -----------
2017-06-11 02:36:15.857614 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #923 | Training started
2017-06-11 02:36:33.347750 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #923 | Training finished
2017-06-11 02:36:33.348784 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #923 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 02:36:33.349164 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #923 | Collecting samples for evaluation
2017-06-11 02:36:47.089727 EDT | -----------------------  -----------
2017-06-11 02:36:47.090517 EDT | Epoch                     923
2017-06-11 02:36:47.090762 EDT | Iteration                 923
2017-06-11 02:36:47.090956 EDT | AverageReturn            1948.96
2017-06-11 02:36:47.091142 EDT | StdReturn                 672.97
2017-06-11 02:36:47.091340 EDT | MaxReturn                3463.44
2017-06-11 02:36:47.091523 EDT | MinReturn                1126.37
2017-06-11 02:36:47.091721 EDT | AverageEsReturn           414.895
2017-06-11 02:36:47.091904 EDT | StdEsReturn               317.325
2017-06-11 02:36:47.092086 EDT | MaxEsReturn              1036.34
2017-06-11 02:36:47.092266 EDT | MinEsReturn               109.858
2017-06-11 02:36:47.092454 EDT | AverageDiscountedReturn   245.605
2017-06-11 02:36:47.092634 EDT | AverageQLoss                2.04048
2017-06-11 02:36:47.092815 EDT | AveragePolicySurr         -30.7444
2017-06-11 02:36:47.092997 EDT | AverageQ                   30.4263
2017-06-11 02:36:47.093177 EDT | AverageAbsQ                30.4459
2017-06-11 02:36:47.093357 EDT | AverageY                   30.4267
2017-06-11 02:36:47.093545 EDT | AverageAbsY                30.4328
2017-06-11 02:36:47.093738 EDT | AverageAbsQYDiff            0.527329
2017-06-11 02:36:47.093920 EDT | AverageAction               0.994814
2017-06-11 02:36:47.094100 EDT | PolicyRegParamNorm         93.9454
2017-06-11 02:36:47.094279 EDT | QFunRegParamNorm          122.1
2017-06-11 02:36:47.094464 EDT | -----------------------  -----------
2017-06-11 02:36:47.094772 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #924 | Training started
2017-06-11 02:37:04.948805 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #924 | Training finished
2017-06-11 02:37:04.952274 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #924 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 02:37:04.952707 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #924 | Collecting samples for evaluation
2017-06-11 02:37:18.806906 EDT | -----------------------  -----------
2017-06-11 02:37:18.807929 EDT | Epoch                     924
2017-06-11 02:37:18.808306 EDT | Iteration                 924
2017-06-11 02:37:18.808662 EDT | AverageReturn            1181.11
2017-06-11 02:37:18.809015 EDT | StdReturn                 541.631
2017-06-11 02:37:18.809364 EDT | MaxReturn                3292.09
2017-06-11 02:37:18.809748 EDT | MinReturn                 756.904
2017-06-11 02:37:18.810098 EDT | AverageEsReturn           474.052
2017-06-11 02:37:18.810446 EDT | StdEsReturn               293.603
2017-06-11 02:37:18.810793 EDT | MaxEsReturn               816.489
2017-06-11 02:37:18.811139 EDT | MinEsReturn               119.037
2017-06-11 02:37:18.811485 EDT | AverageDiscountedReturn   243.255
2017-06-11 02:37:18.811832 EDT | AverageQLoss                1.99918
2017-06-11 02:37:18.812176 EDT | AveragePolicySurr         -30.6739
2017-06-11 02:37:18.812524 EDT | AverageQ                   30.3506
2017-06-11 02:37:18.812872 EDT | AverageAbsQ                30.3733
2017-06-11 02:37:18.813219 EDT | AverageY                   30.3511
2017-06-11 02:37:18.813565 EDT | AverageAbsY                30.3604
2017-06-11 02:37:18.822090 EDT | AverageAbsQYDiff            0.528122
2017-06-11 02:37:18.822447 EDT | AverageAction               0.995213
2017-06-11 02:37:18.822798 EDT | PolicyRegParamNorm         93.9595
2017-06-11 02:37:18.823147 EDT | QFunRegParamNorm          122.155
2017-06-11 02:37:18.823496 EDT | -----------------------  -----------
2017-06-11 02:37:18.824016 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #925 | Training started
2017-06-11 02:37:36.315052 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #925 | Training finished
2017-06-11 02:37:36.319739 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #925 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 02:37:36.320170 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #925 | Collecting samples for evaluation
2017-06-11 02:37:50.032237 EDT | -----------------------  -----------
2017-06-11 02:37:50.033264 EDT | Epoch                     925
2017-06-11 02:37:50.033670 EDT | Iteration                 925
2017-06-11 02:37:50.034064 EDT | AverageReturn            1145.51
2017-06-11 02:37:50.034451 EDT | StdReturn                 217.419
2017-06-11 02:37:50.034830 EDT | MaxReturn                1498.89
2017-06-11 02:37:50.035210 EDT | MinReturn                 475.98
2017-06-11 02:37:50.035588 EDT | AverageEsReturn           484.954
2017-06-11 02:37:50.035967 EDT | StdEsReturn               385.961
2017-06-11 02:37:50.036343 EDT | MaxEsReturn               948.871
2017-06-11 02:37:50.036721 EDT | MinEsReturn                56.5624
2017-06-11 02:37:50.037099 EDT | AverageDiscountedReturn   241.564
2017-06-11 02:37:50.037482 EDT | AverageQLoss                2.08944
2017-06-11 02:37:50.037870 EDT | AveragePolicySurr         -30.6764
2017-06-11 02:37:50.038253 EDT | AverageQ                   30.3574
2017-06-11 02:37:50.038631 EDT | AverageAbsQ                30.3806
2017-06-11 02:37:50.039007 EDT | AverageY                   30.3566
2017-06-11 02:37:50.039385 EDT | AverageAbsY                30.3663
2017-06-11 02:37:50.039762 EDT | AverageAbsQYDiff            0.535516
2017-06-11 02:37:50.040140 EDT | AverageAction               0.995713
2017-06-11 02:37:50.040518 EDT | PolicyRegParamNorm         94.0212
2017-06-11 02:37:50.040890 EDT | QFunRegParamNorm          122.19
2017-06-11 02:37:50.041268 EDT | -----------------------  -----------
2017-06-11 02:37:50.041838 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #926 | Training started
2017-06-11 02:38:07.571117 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #926 | Training finished
2017-06-11 02:38:07.572157 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #926 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 02:38:07.572692 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #926 | Collecting samples for evaluation
2017-06-11 02:38:21.732991 EDT | -----------------------  -----------
2017-06-11 02:38:21.734077 EDT | Epoch                     926
2017-06-11 02:38:21.734482 EDT | Iteration                 926
2017-06-11 02:38:21.734860 EDT | AverageReturn             822.332
2017-06-11 02:38:21.735235 EDT | StdReturn                 292.586
2017-06-11 02:38:21.735607 EDT | MaxReturn                1612.48
2017-06-11 02:38:21.735978 EDT | MinReturn                 482.206
2017-06-11 02:38:21.736348 EDT | AverageEsReturn           392.065
2017-06-11 02:38:21.736717 EDT | StdEsReturn               232.834
2017-06-11 02:38:21.737087 EDT | MaxEsReturn               753.303
2017-06-11 02:38:21.737454 EDT | MinEsReturn                19.9403
2017-06-11 02:38:21.737832 EDT | AverageDiscountedReturn   226.243
2017-06-11 02:38:21.738202 EDT | AverageQLoss                2.17796
2017-06-11 02:38:21.738570 EDT | AveragePolicySurr         -30.6785
2017-06-11 02:38:21.738938 EDT | AverageQ                   30.356
2017-06-11 02:38:21.739304 EDT | AverageAbsQ                30.3744
2017-06-11 02:38:21.739670 EDT | AverageY                   30.3571
2017-06-11 02:38:21.740037 EDT | AverageAbsY                30.3649
2017-06-11 02:38:21.740404 EDT | AverageAbsQYDiff            0.534963
2017-06-11 02:38:21.740769 EDT | AverageAction               0.996637
2017-06-11 02:38:21.741135 EDT | PolicyRegParamNorm         94.0355
2017-06-11 02:38:21.741500 EDT | QFunRegParamNorm          122.297
2017-06-11 02:38:21.741944 EDT | -----------------------  -----------
2017-06-11 02:38:21.742770 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #927 | Training started
2017-06-11 02:38:38.314472 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #927 | Training finished
2017-06-11 02:38:38.315247 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #927 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 02:38:38.315431 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #927 | Collecting samples for evaluation
2017-06-11 02:38:53.414730 EDT | -----------------------  -----------
2017-06-11 02:38:53.415811 EDT | Epoch                     927
2017-06-11 02:38:53.416213 EDT | Iteration                 927
2017-06-11 02:38:53.416646 EDT | AverageReturn            2161.44
2017-06-11 02:38:53.417093 EDT | StdReturn                 774.381
2017-06-11 02:38:53.417454 EDT | MaxReturn                3169.8
2017-06-11 02:38:53.417894 EDT | MinReturn                1189.88
2017-06-11 02:38:53.418335 EDT | AverageEsReturn           633.393
2017-06-11 02:38:53.418738 EDT | StdEsReturn               259.63
2017-06-11 02:38:53.419132 EDT | MaxEsReturn               944.172
2017-06-11 02:38:53.419557 EDT | MinEsReturn               305.297
2017-06-11 02:38:53.433893 EDT | AverageDiscountedReturn   243.654
2017-06-11 02:38:53.434371 EDT | AverageQLoss                1.91979
2017-06-11 02:38:53.434786 EDT | AveragePolicySurr         -30.7907
2017-06-11 02:38:53.435151 EDT | AverageQ                   30.4721
2017-06-11 02:38:53.435562 EDT | AverageAbsQ                30.4903
2017-06-11 02:38:53.435928 EDT | AverageY                   30.4738
2017-06-11 02:38:53.436353 EDT | AverageAbsY                30.4842
2017-06-11 02:38:53.436786 EDT | AverageAbsQYDiff            0.501785
2017-06-11 02:38:53.437162 EDT | AverageAction               0.995321
2017-06-11 02:38:53.437581 EDT | PolicyRegParamNorm         94.0442
2017-06-11 02:38:53.438052 EDT | QFunRegParamNorm          122.345
2017-06-11 02:38:53.438452 EDT | -----------------------  -----------
2017-06-11 02:38:53.438957 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #928 | Training started
2017-06-11 02:39:10.496710 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #928 | Training finished
2017-06-11 02:39:10.497731 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #928 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 02:39:10.498126 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #928 | Collecting samples for evaluation
2017-06-11 02:39:24.157827 EDT | -----------------------  -----------
2017-06-11 02:39:24.158876 EDT | Epoch                     928
2017-06-11 02:39:24.159350 EDT | Iteration                 928
2017-06-11 02:39:24.159760 EDT | AverageReturn             753.423
2017-06-11 02:39:24.160394 EDT | StdReturn                 117.677
2017-06-11 02:39:24.162017 EDT | MaxReturn                1173.43
2017-06-11 02:39:24.162441 EDT | MinReturn                 675.296
2017-06-11 02:39:24.163529 EDT | AverageEsReturn           503.235
2017-06-11 02:39:24.164013 EDT | StdEsReturn               356.409
2017-06-11 02:39:24.164779 EDT | MaxEsReturn              1054.87
2017-06-11 02:39:24.165040 EDT | MinEsReturn                24.9028
2017-06-11 02:39:24.165465 EDT | AverageDiscountedReturn   230.526
2017-06-11 02:39:24.165903 EDT | AverageQLoss                2.47807
2017-06-11 02:39:24.166439 EDT | AveragePolicySurr         -30.6017
2017-06-11 02:39:24.166927 EDT | AverageQ                   30.2808
2017-06-11 02:39:24.167356 EDT | AverageAbsQ                30.301
2017-06-11 02:39:24.167893 EDT | AverageY                   30.2825
2017-06-11 02:39:24.168350 EDT | AverageAbsY                30.2917
2017-06-11 02:39:24.168797 EDT | AverageAbsQYDiff            0.561536
2017-06-11 02:39:24.169336 EDT | AverageAction               0.995176
2017-06-11 02:39:24.169835 EDT | PolicyRegParamNorm         94.0081
2017-06-11 02:39:24.170280 EDT | QFunRegParamNorm          122.364
2017-06-11 02:39:24.170708 EDT | -----------------------  -----------
2017-06-11 02:39:24.171366 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #929 | Training started
2017-06-11 02:39:41.298815 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #929 | Training finished
2017-06-11 02:39:41.299090 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #929 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 02:39:41.299268 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #929 | Collecting samples for evaluation
2017-06-11 02:39:55.070435 EDT | -----------------------  -----------
2017-06-11 02:39:55.071420 EDT | Epoch                     929
2017-06-11 02:39:55.071798 EDT | Iteration                 929
2017-06-11 02:39:55.072153 EDT | AverageReturn             945.743
2017-06-11 02:39:55.075467 EDT | StdReturn                 485.924
2017-06-11 02:39:55.076898 EDT | MaxReturn                2811.23
2017-06-11 02:39:55.077252 EDT | MinReturn                 654.958
2017-06-11 02:39:55.077604 EDT | AverageEsReturn           496.192
2017-06-11 02:39:55.077966 EDT | StdEsReturn               260.85
2017-06-11 02:39:55.078313 EDT | MaxEsReturn               966.947
2017-06-11 02:39:55.078657 EDT | MinEsReturn                80.4665
2017-06-11 02:39:55.079002 EDT | AverageDiscountedReturn   232.375
2017-06-11 02:39:55.079344 EDT | AverageQLoss                2.04054
2017-06-11 02:39:55.079687 EDT | AveragePolicySurr         -30.7316
2017-06-11 02:39:55.080031 EDT | AverageQ                   30.423
2017-06-11 02:39:55.080374 EDT | AverageAbsQ                30.4442
2017-06-11 02:39:55.080716 EDT | AverageY                   30.4243
2017-06-11 02:39:55.081059 EDT | AverageAbsY                30.4332
2017-06-11 02:39:55.081404 EDT | AverageAbsQYDiff            0.512621
2017-06-11 02:39:55.081756 EDT | AverageAction               0.995283
2017-06-11 02:39:55.082113 EDT | PolicyRegParamNorm         94.0163
2017-06-11 02:39:55.082457 EDT | QFunRegParamNorm          122.414
2017-06-11 02:39:55.082800 EDT | -----------------------  -----------
2017-06-11 02:39:55.083577 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #930 | Training started
2017-06-11 02:40:12.821004 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #930 | Training finished
2017-06-11 02:40:12.821819 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #930 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 02:40:12.822203 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #930 | Collecting samples for evaluation
2017-06-11 02:40:27.249641 EDT | -----------------------  -----------
2017-06-11 02:40:27.296501 EDT | Epoch                     930
2017-06-11 02:40:27.296941 EDT | Iteration                 930
2017-06-11 02:40:27.297222 EDT | AverageReturn            1019.56
2017-06-11 02:40:27.297561 EDT | StdReturn                 242.994
2017-06-11 02:40:27.297848 EDT | MaxReturn                1572.24
2017-06-11 02:40:27.298106 EDT | MinReturn                 663.647
2017-06-11 02:40:27.298381 EDT | AverageEsReturn           452.423
2017-06-11 02:40:27.298863 EDT | StdEsReturn               257.489
2017-06-11 02:40:27.299119 EDT | MaxEsReturn               778.501
2017-06-11 02:40:27.304705 EDT | MinEsReturn                56.379
2017-06-11 02:40:27.304977 EDT | AverageDiscountedReturn   244.763
2017-06-11 02:40:27.305240 EDT | AverageQLoss                2.07886
2017-06-11 02:40:27.305498 EDT | AveragePolicySurr         -30.656
2017-06-11 02:40:27.305789 EDT | AverageQ                   30.3518
2017-06-11 02:40:27.306045 EDT | AverageAbsQ                30.3705
2017-06-11 02:40:27.306296 EDT | AverageY                   30.3542
2017-06-11 02:40:27.306546 EDT | AverageAbsY                30.3596
2017-06-11 02:40:27.306815 EDT | AverageAbsQYDiff            0.52334
2017-06-11 02:40:27.307067 EDT | AverageAction               0.995766
2017-06-11 02:40:27.307317 EDT | PolicyRegParamNorm         94.0562
2017-06-11 02:40:27.307639 EDT | QFunRegParamNorm          122.483
2017-06-11 02:40:27.307912 EDT | -----------------------  -----------
2017-06-11 02:40:27.308327 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #931 | Training started
2017-06-11 02:40:45.129727 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #931 | Training finished
2017-06-11 02:40:45.130573 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #931 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 02:40:45.130837 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #931 | Collecting samples for evaluation
2017-06-11 02:40:59.760182 EDT | -----------------------  -----------
2017-06-11 02:40:59.767805 EDT | Epoch                     931
2017-06-11 02:40:59.769785 EDT | Iteration                 931
2017-06-11 02:40:59.773893 EDT | AverageReturn            1531.38
2017-06-11 02:40:59.776070 EDT | StdReturn                 358.681
2017-06-11 02:40:59.778106 EDT | MaxReturn                2236.3
2017-06-11 02:40:59.779840 EDT | MinReturn                1007.19
2017-06-11 02:40:59.781977 EDT | AverageEsReturn           555.25
2017-06-11 02:40:59.783207 EDT | StdEsReturn               131.268
2017-06-11 02:40:59.784544 EDT | MaxEsReturn               739.222
2017-06-11 02:40:59.794695 EDT | MinEsReturn               326.957
2017-06-11 02:40:59.796550 EDT | AverageDiscountedReturn   248.429
2017-06-11 02:40:59.797771 EDT | AverageQLoss                2.37934
2017-06-11 02:40:59.798175 EDT | AveragePolicySurr         -30.6145
2017-06-11 02:40:59.798529 EDT | AverageQ                   30.3076
2017-06-11 02:40:59.798853 EDT | AverageAbsQ                30.327
2017-06-11 02:40:59.799200 EDT | AverageY                   30.3075
2017-06-11 02:40:59.799484 EDT | AverageAbsY                30.3155
2017-06-11 02:40:59.799736 EDT | AverageAbsQYDiff            0.538276
2017-06-11 02:40:59.799982 EDT | AverageAction               0.995594
2017-06-11 02:40:59.800229 EDT | PolicyRegParamNorm         94.1683
2017-06-11 02:40:59.800476 EDT | QFunRegParamNorm          122.51
2017-06-11 02:40:59.800733 EDT | -----------------------  -----------
2017-06-11 02:40:59.801142 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #932 | Training started
2017-06-11 02:41:17.530160 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #932 | Training finished
2017-06-11 02:41:17.530567 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #932 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 02:41:17.530926 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #932 | Collecting samples for evaluation
2017-06-11 02:41:31.457290 EDT | -----------------------  -----------
2017-06-11 02:41:31.459153 EDT | Epoch                     932
2017-06-11 02:41:31.459693 EDT | Iteration                 932
2017-06-11 02:41:31.460044 EDT | AverageReturn            1025.39
2017-06-11 02:41:31.460377 EDT | StdReturn                 152.327
2017-06-11 02:41:31.460804 EDT | MaxReturn                1376.3
2017-06-11 02:41:31.461647 EDT | MinReturn                 656.139
2017-06-11 02:41:31.462009 EDT | AverageEsReturn           350.045
2017-06-11 02:41:31.462559 EDT | StdEsReturn               177.177
2017-06-11 02:41:31.463522 EDT | MaxEsReturn               707.624
2017-06-11 02:41:31.463975 EDT | MinEsReturn                95.1603
2017-06-11 02:41:31.464422 EDT | AverageDiscountedReturn   246.084
2017-06-11 02:41:31.464859 EDT | AverageQLoss                2.35719
2017-06-11 02:41:31.465299 EDT | AveragePolicySurr         -30.6471
2017-06-11 02:41:31.465745 EDT | AverageQ                   30.323
2017-06-11 02:41:31.466183 EDT | AverageAbsQ                30.3462
2017-06-11 02:41:31.466623 EDT | AverageY                   30.3256
2017-06-11 02:41:31.467064 EDT | AverageAbsY                30.3325
2017-06-11 02:41:31.467502 EDT | AverageAbsQYDiff            0.544397
2017-06-11 02:41:31.467941 EDT | AverageAction               0.995921
2017-06-11 02:41:31.468381 EDT | PolicyRegParamNorm         94.2659
2017-06-11 02:41:31.468821 EDT | QFunRegParamNorm          122.552
2017-06-11 02:41:31.469258 EDT | -----------------------  -----------
2017-06-11 02:41:31.469829 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #933 | Training started
2017-06-11 02:41:49.591314 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #933 | Training finished
2017-06-11 02:41:49.592140 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #933 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 02:41:49.592349 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #933 | Collecting samples for evaluation
2017-06-11 02:42:03.907678 EDT | -----------------------  -----------
2017-06-11 02:42:03.909131 EDT | Epoch                     933
2017-06-11 02:42:03.909499 EDT | Iteration                 933
2017-06-11 02:42:03.909859 EDT | AverageReturn             909.145
2017-06-11 02:42:03.910254 EDT | StdReturn                 211.374
2017-06-11 02:42:03.912268 EDT | MaxReturn                1515.41
2017-06-11 02:42:03.912760 EDT | MinReturn                 582.418
2017-06-11 02:42:03.913173 EDT | AverageEsReturn           322.504
2017-06-11 02:42:03.913638 EDT | StdEsReturn               272.871
2017-06-11 02:42:03.915161 EDT | MaxEsReturn               713.351
2017-06-11 02:42:03.915580 EDT | MinEsReturn                11.4166
2017-06-11 02:42:03.917799 EDT | AverageDiscountedReturn   231.118
2017-06-11 02:42:03.918244 EDT | AverageQLoss                2.20252
2017-06-11 02:42:03.918623 EDT | AveragePolicySurr         -30.709
2017-06-11 02:42:03.918978 EDT | AverageQ                   30.3952
2017-06-11 02:42:03.919350 EDT | AverageAbsQ                30.4138
2017-06-11 02:42:03.919744 EDT | AverageY                   30.3962
2017-06-11 02:42:03.920114 EDT | AverageAbsY                30.4043
2017-06-11 02:42:03.920482 EDT | AverageAbsQYDiff            0.544359
2017-06-11 02:42:03.920847 EDT | AverageAction               0.996625
2017-06-11 02:42:03.921214 EDT | PolicyRegParamNorm         94.2671
2017-06-11 02:42:03.921739 EDT | QFunRegParamNorm          122.612
2017-06-11 02:42:03.922199 EDT | -----------------------  -----------
2017-06-11 02:42:03.922831 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #934 | Training started
2017-06-11 02:42:22.903209 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #934 | Training finished
2017-06-11 02:42:22.904208 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #934 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 02:42:22.904595 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #934 | Collecting samples for evaluation
2017-06-11 02:42:36.722030 EDT | -----------------------  ----------
2017-06-11 02:42:36.723352 EDT | Epoch                    934
2017-06-11 02:42:36.723912 EDT | Iteration                934
2017-06-11 02:42:36.724369 EDT | AverageReturn            821.732
2017-06-11 02:42:36.724821 EDT | StdReturn                 58.732
2017-06-11 02:42:36.725267 EDT | MaxReturn                964.278
2017-06-11 02:42:36.725732 EDT | MinReturn                635.253
2017-06-11 02:42:36.726180 EDT | AverageEsReturn          451.276
2017-06-11 02:42:36.726819 EDT | StdEsReturn               76.5398
2017-06-11 02:42:36.728890 EDT | MaxEsReturn              545.585
2017-06-11 02:42:36.729352 EDT | MinEsReturn              322.489
2017-06-11 02:42:36.729812 EDT | AverageDiscountedReturn  234.833
2017-06-11 02:42:36.730258 EDT | AverageQLoss               2.1994
2017-06-11 02:42:36.730704 EDT | AveragePolicySurr        -30.7059
2017-06-11 02:42:36.731149 EDT | AverageQ                  30.3922
2017-06-11 02:42:36.731596 EDT | AverageAbsQ               30.4159
2017-06-11 02:42:36.732042 EDT | AverageY                  30.393
2017-06-11 02:42:36.732488 EDT | AverageAbsY               30.4036
2017-06-11 02:42:36.732933 EDT | AverageAbsQYDiff           0.531543
2017-06-11 02:42:36.733378 EDT | AverageAction              0.995572
2017-06-11 02:42:36.733831 EDT | PolicyRegParamNorm        94.2911
2017-06-11 02:42:36.734272 EDT | QFunRegParamNorm         122.627
2017-06-11 02:42:36.734714 EDT | -----------------------  ----------
2017-06-11 02:42:36.735331 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #935 | Training started
2017-06-11 02:42:56.160917 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #935 | Training finished
2017-06-11 02:42:56.161975 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #935 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 02:42:56.162377 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #935 | Collecting samples for evaluation
2017-06-11 02:43:11.173787 EDT | -----------------------  -----------
2017-06-11 02:43:11.174828 EDT | Epoch                     935
2017-06-11 02:43:11.175104 EDT | Iteration                 935
2017-06-11 02:43:11.175355 EDT | AverageReturn             850.678
2017-06-11 02:43:11.175604 EDT | StdReturn                  69.5933
2017-06-11 02:43:11.175848 EDT | MaxReturn                1001.31
2017-06-11 02:43:11.176089 EDT | MinReturn                 659.262
2017-06-11 02:43:11.176337 EDT | AverageEsReturn           285.494
2017-06-11 02:43:11.176581 EDT | StdEsReturn               192.444
2017-06-11 02:43:11.176823 EDT | MaxEsReturn               666.277
2017-06-11 02:43:11.177063 EDT | MinEsReturn                39.7134
2017-06-11 02:43:11.177303 EDT | AverageDiscountedReturn   233.568
2017-06-11 02:43:11.177542 EDT | AverageQLoss                2.08778
2017-06-11 02:43:11.177812 EDT | AveragePolicySurr         -30.6746
2017-06-11 02:43:11.178055 EDT | AverageQ                   30.3753
2017-06-11 02:43:11.178297 EDT | AverageAbsQ                30.3927
2017-06-11 02:43:11.178539 EDT | AverageY                   30.3767
2017-06-11 02:43:11.178778 EDT | AverageAbsY                30.3827
2017-06-11 02:43:11.179018 EDT | AverageAbsQYDiff            0.527226
2017-06-11 02:43:11.179258 EDT | AverageAction               0.995576
2017-06-11 02:43:11.179499 EDT | PolicyRegParamNorm         94.4014
2017-06-11 02:43:11.179739 EDT | QFunRegParamNorm          122.663
2017-06-11 02:43:11.179979 EDT | -----------------------  -----------
2017-06-11 02:43:11.180376 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #936 | Training started
2017-06-11 02:43:28.647052 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #936 | Training finished
2017-06-11 02:43:28.647964 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #936 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 02:43:28.648264 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #936 | Collecting samples for evaluation
2017-06-11 02:43:42.380678 EDT | -----------------------  -----------
2017-06-11 02:43:42.381534 EDT | Epoch                     936
2017-06-11 02:43:42.381866 EDT | Iteration                 936
2017-06-11 02:43:42.385124 EDT | AverageReturn            1005.76
2017-06-11 02:43:42.385545 EDT | StdReturn                 100.847
2017-06-11 02:43:42.385753 EDT | MaxReturn                1338.09
2017-06-11 02:43:42.385913 EDT | MinReturn                 855.546
2017-06-11 02:43:42.386069 EDT | AverageEsReturn           293.912
2017-06-11 02:43:42.386259 EDT | StdEsReturn               196.141
2017-06-11 02:43:42.386433 EDT | MaxEsReturn               651.779
2017-06-11 02:43:42.386588 EDT | MinEsReturn                25.9597
2017-06-11 02:43:42.386789 EDT | AverageDiscountedReturn   240.173
2017-06-11 02:43:42.386982 EDT | AverageQLoss                2.26451
2017-06-11 02:43:42.387136 EDT | AveragePolicySurr         -30.6156
2017-06-11 02:43:42.387288 EDT | AverageQ                   30.2891
2017-06-11 02:43:42.387446 EDT | AverageAbsQ                30.3121
2017-06-11 02:43:42.387602 EDT | AverageY                   30.2912
2017-06-11 02:43:42.387755 EDT | AverageAbsY                30.3006
2017-06-11 02:43:42.387970 EDT | AverageAbsQYDiff            0.537807
2017-06-11 02:43:42.388154 EDT | AverageAction               0.995655
2017-06-11 02:43:42.388308 EDT | PolicyRegParamNorm         94.3741
2017-06-11 02:43:42.388516 EDT | QFunRegParamNorm          122.679
2017-06-11 02:43:42.388674 EDT | -----------------------  -----------
2017-06-11 02:43:42.388939 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #937 | Training started
2017-06-11 02:44:00.123641 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #937 | Training finished
2017-06-11 02:44:00.124399 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #937 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 02:44:00.124664 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #937 | Collecting samples for evaluation
2017-06-11 02:44:14.726968 EDT | -----------------------  -----------
2017-06-11 02:44:14.727951 EDT | Epoch                     937
2017-06-11 02:44:14.728161 EDT | Iteration                 937
2017-06-11 02:44:14.728360 EDT | AverageReturn             878.325
2017-06-11 02:44:14.728518 EDT | StdReturn                 129.684
2017-06-11 02:44:14.728679 EDT | MaxReturn                1052.97
2017-06-11 02:44:14.728835 EDT | MinReturn                 692.926
2017-06-11 02:44:14.728987 EDT | AverageEsReturn           366.973
2017-06-11 02:44:14.729162 EDT | StdEsReturn               247.171
2017-06-11 02:44:14.729323 EDT | MaxEsReturn               657.823
2017-06-11 02:44:14.729475 EDT | MinEsReturn                14.2785
2017-06-11 02:44:14.729649 EDT | AverageDiscountedReturn   242.359
2017-06-11 02:44:14.729835 EDT | AverageQLoss                2.05149
2017-06-11 02:44:14.730027 EDT | AveragePolicySurr         -30.6388
2017-06-11 02:44:14.730232 EDT | AverageQ                   30.3141
2017-06-11 02:44:14.730407 EDT | AverageAbsQ                30.3311
2017-06-11 02:44:14.730690 EDT | AverageY                   30.3155
2017-06-11 02:44:14.730986 EDT | AverageAbsY                30.3235
2017-06-11 02:44:14.731276 EDT | AverageAbsQYDiff            0.518781
2017-06-11 02:44:14.731463 EDT | AverageAction               0.99674
2017-06-11 02:44:14.731651 EDT | PolicyRegParamNorm         94.4535
2017-06-11 02:44:14.731833 EDT | QFunRegParamNorm          122.66
2017-06-11 02:44:14.732121 EDT | -----------------------  -----------
2017-06-11 02:44:14.732442 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #938 | Training started
2017-06-11 02:44:32.078934 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #938 | Training finished
2017-06-11 02:44:32.079917 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #938 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 02:44:32.080198 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #938 | Collecting samples for evaluation
2017-06-11 02:44:46.514732 EDT | -----------------------  ----------
2017-06-11 02:44:46.515642 EDT | Epoch                    938
2017-06-11 02:44:46.516037 EDT | Iteration                938
2017-06-11 02:44:46.516369 EDT | AverageReturn            650.53
2017-06-11 02:44:46.516671 EDT | StdReturn                 42.0967
2017-06-11 02:44:46.516976 EDT | MaxReturn                776.121
2017-06-11 02:44:46.517407 EDT | MinReturn                541.831
2017-06-11 02:44:46.517689 EDT | AverageEsReturn          385.995
2017-06-11 02:44:46.518031 EDT | StdEsReturn              189.416
2017-06-11 02:44:46.518333 EDT | MaxEsReturn              662.047
2017-06-11 02:44:46.518647 EDT | MinEsReturn              146.54
2017-06-11 02:44:46.518975 EDT | AverageDiscountedReturn  219.69
2017-06-11 02:44:46.519285 EDT | AverageQLoss               2.51075
2017-06-11 02:44:46.519609 EDT | AveragePolicySurr        -30.5119
2017-06-11 02:44:46.519918 EDT | AverageQ                  30.1732
2017-06-11 02:44:46.520184 EDT | AverageAbsQ               30.1942
2017-06-11 02:44:46.520476 EDT | AverageY                  30.1727
2017-06-11 02:44:46.521790 EDT | AverageAbsY               30.1796
2017-06-11 02:44:46.522100 EDT | AverageAbsQYDiff           0.551013
2017-06-11 02:44:46.522396 EDT | AverageAction              0.996286
2017-06-11 02:44:46.522571 EDT | PolicyRegParamNorm        94.4652
2017-06-11 02:44:46.523078 EDT | QFunRegParamNorm         122.743
2017-06-11 02:44:46.523389 EDT | -----------------------  ----------
2017-06-11 02:44:46.523861 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #939 | Training started
2017-06-11 02:45:02.250560 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #939 | Training finished
2017-06-11 02:45:02.534961 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #939 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 02:45:02.535341 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #939 | Collecting samples for evaluation
2017-06-11 02:45:16.376221 EDT | -----------------------  -----------
2017-06-11 02:45:16.376948 EDT | Epoch                     939
2017-06-11 02:45:16.377138 EDT | Iteration                 939
2017-06-11 02:45:16.377328 EDT | AverageReturn             961.744
2017-06-11 02:45:16.377523 EDT | StdReturn                 204.372
2017-06-11 02:45:16.377756 EDT | MaxReturn                1350.13
2017-06-11 02:45:16.377944 EDT | MinReturn                 689.817
2017-06-11 02:45:16.378126 EDT | AverageEsReturn           485.369
2017-06-11 02:45:16.378308 EDT | StdEsReturn               222.15
2017-06-11 02:45:16.378498 EDT | MaxEsReturn               843.262
2017-06-11 02:45:16.378678 EDT | MinEsReturn               242.255
2017-06-11 02:45:16.378858 EDT | AverageDiscountedReturn   244.235
2017-06-11 02:45:16.379038 EDT | AverageQLoss                2.332
2017-06-11 02:45:16.379218 EDT | AveragePolicySurr         -30.593
2017-06-11 02:45:16.379398 EDT | AverageQ                   30.2643
2017-06-11 02:45:16.379586 EDT | AverageAbsQ                30.2797
2017-06-11 02:45:16.379765 EDT | AverageY                   30.2661
2017-06-11 02:45:16.379949 EDT | AverageAbsY                30.2705
2017-06-11 02:45:16.380134 EDT | AverageAbsQYDiff            0.545194
2017-06-11 02:45:16.380312 EDT | AverageAction               0.995797
2017-06-11 02:45:16.380729 EDT | PolicyRegParamNorm         94.5664
2017-06-11 02:45:16.381090 EDT | QFunRegParamNorm          122.77
2017-06-11 02:45:16.381279 EDT | -----------------------  -----------
2017-06-11 02:45:16.381626 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #940 | Training started
2017-06-11 02:45:33.948049 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #940 | Training finished
2017-06-11 02:45:33.949744 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #940 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 02:45:33.950336 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #940 | Collecting samples for evaluation
2017-06-11 02:45:47.091613 EDT | -----------------------  -----------
2017-06-11 02:45:47.092627 EDT | Epoch                     940
2017-06-11 02:45:47.092822 EDT | Iteration                 940
2017-06-11 02:45:47.092984 EDT | AverageReturn             877.476
2017-06-11 02:45:47.093141 EDT | StdReturn                 152.402
2017-06-11 02:45:47.093292 EDT | MaxReturn                1067.86
2017-06-11 02:45:47.093444 EDT | MinReturn                 684.754
2017-06-11 02:45:47.093598 EDT | AverageEsReturn           481.053
2017-06-11 02:45:47.093835 EDT | StdEsReturn               184.398
2017-06-11 02:45:47.094158 EDT | MaxEsReturn               646.121
2017-06-11 02:45:47.094497 EDT | MinEsReturn               140.698
2017-06-11 02:45:47.095033 EDT | AverageDiscountedReturn   244.343
2017-06-11 02:45:47.095364 EDT | AverageQLoss                2.19083
2017-06-11 02:45:47.095697 EDT | AveragePolicySurr         -30.6018
2017-06-11 02:45:47.096072 EDT | AverageQ                   30.2828
2017-06-11 02:45:47.096234 EDT | AverageAbsQ                30.2987
2017-06-11 02:45:47.096390 EDT | AverageY                   30.2844
2017-06-11 02:45:47.096545 EDT | AverageAbsY                30.2895
2017-06-11 02:45:47.096696 EDT | AverageAbsQYDiff            0.539483
2017-06-11 02:45:47.096847 EDT | AverageAction               0.995458
2017-06-11 02:45:47.096998 EDT | PolicyRegParamNorm         94.614
2017-06-11 02:45:47.097149 EDT | QFunRegParamNorm          122.834
2017-06-11 02:45:47.097299 EDT | -----------------------  -----------
2017-06-11 02:45:47.097552 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #941 | Training started
2017-06-11 02:46:05.985241 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #941 | Training finished
2017-06-11 02:46:05.986015 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #941 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 02:46:05.986213 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #941 | Collecting samples for evaluation
2017-06-11 02:46:19.765517 EDT | -----------------------  -----------
2017-06-11 02:46:19.765930 EDT | Epoch                     941
2017-06-11 02:46:19.766307 EDT | Iteration                 941
2017-06-11 02:46:19.766665 EDT | AverageReturn            1047.08
2017-06-11 02:46:19.767009 EDT | StdReturn                  63.506
2017-06-11 02:46:19.767352 EDT | MaxReturn                1142.83
2017-06-11 02:46:19.767688 EDT | MinReturn                 836.295
2017-06-11 02:46:19.768026 EDT | AverageEsReturn           435.448
2017-06-11 02:46:19.768309 EDT | StdEsReturn               279.85
2017-06-11 02:46:19.768637 EDT | MaxEsReturn               949.215
2017-06-11 02:46:19.768974 EDT | MinEsReturn               125.956
2017-06-11 02:46:19.769305 EDT | AverageDiscountedReturn   260.098
2017-06-11 02:46:19.769631 EDT | AverageQLoss                2.4275
2017-06-11 02:46:19.769951 EDT | AveragePolicySurr         -30.5833
2017-06-11 02:46:19.770591 EDT | AverageQ                   30.2434
2017-06-11 02:46:19.770931 EDT | AverageAbsQ                30.2623
2017-06-11 02:46:19.771135 EDT | AverageY                   30.2449
2017-06-11 02:46:19.771329 EDT | AverageAbsY                30.2509
2017-06-11 02:46:19.771687 EDT | AverageAbsQYDiff            0.556344
2017-06-11 02:46:19.772102 EDT | AverageAction               0.996459
2017-06-11 02:46:19.775329 EDT | PolicyRegParamNorm         94.731
2017-06-11 02:46:19.776085 EDT | QFunRegParamNorm          122.841
2017-06-11 02:46:19.776506 EDT | -----------------------  -----------
2017-06-11 02:46:19.777096 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #942 | Training started
2017-06-11 02:46:36.866745 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #942 | Training finished
2017-06-11 02:46:36.873342 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #942 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 02:46:36.873650 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #942 | Collecting samples for evaluation
2017-06-11 02:46:51.792084 EDT | -----------------------  -----------
2017-06-11 02:46:51.806713 EDT | Epoch                     942
2017-06-11 02:46:51.807105 EDT | Iteration                 942
2017-06-11 02:46:51.807415 EDT | AverageReturn            2661.02
2017-06-11 02:46:51.807720 EDT | StdReturn                 809.361
2017-06-11 02:46:51.808021 EDT | MaxReturn                3369.31
2017-06-11 02:46:51.808320 EDT | MinReturn                 879.453
2017-06-11 02:46:51.808617 EDT | AverageEsReturn           630.11
2017-06-11 02:46:51.808913 EDT | StdEsReturn               313.033
2017-06-11 02:46:51.809209 EDT | MaxEsReturn              1012.28
2017-06-11 02:46:51.809505 EDT | MinEsReturn               244.976
2017-06-11 02:46:51.809810 EDT | AverageDiscountedReturn   235.521
2017-06-11 02:46:51.810117 EDT | AverageQLoss                2.21623
2017-06-11 02:46:51.810414 EDT | AveragePolicySurr         -30.5882
2017-06-11 02:46:51.810710 EDT | AverageQ                   30.2621
2017-06-11 02:46:51.811003 EDT | AverageAbsQ                30.2846
2017-06-11 02:46:51.811296 EDT | AverageY                   30.2657
2017-06-11 02:46:51.811591 EDT | AverageAbsY                30.2741
2017-06-11 02:46:51.811884 EDT | AverageAbsQYDiff            0.541563
2017-06-11 02:46:51.812179 EDT | AverageAction               0.995853
2017-06-11 02:46:51.812502 EDT | PolicyRegParamNorm         94.8944
2017-06-11 02:46:51.812797 EDT | QFunRegParamNorm          122.912
2017-06-11 02:46:51.813100 EDT | -----------------------  -----------
2017-06-11 02:46:51.813561 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #943 | Training started
2017-06-11 02:47:08.786810 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #943 | Training finished
2017-06-11 02:47:08.788824 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #943 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 02:47:08.789346 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #943 | Collecting samples for evaluation
2017-06-11 02:47:23.967734 EDT | -----------------------  -----------
2017-06-11 02:47:23.968611 EDT | Epoch                     943
2017-06-11 02:47:23.968905 EDT | Iteration                 943
2017-06-11 02:47:23.969167 EDT | AverageReturn             850.714
2017-06-11 02:47:23.969424 EDT | StdReturn                 400.385
2017-06-11 02:47:23.969681 EDT | MaxReturn                1869.19
2017-06-11 02:47:23.969949 EDT | MinReturn                 494.372
2017-06-11 02:47:23.970203 EDT | AverageEsReturn           382.454
2017-06-11 02:47:23.970455 EDT | StdEsReturn               289.637
2017-06-11 02:47:23.970708 EDT | MaxEsReturn               872.971
2017-06-11 02:47:23.970964 EDT | MinEsReturn                71.5783
2017-06-11 02:47:23.971215 EDT | AverageDiscountedReturn   225.807
2017-06-11 02:47:23.971467 EDT | AverageQLoss                2.71533
2017-06-11 02:47:23.971718 EDT | AveragePolicySurr         -30.5196
2017-06-11 02:47:23.972204 EDT | AverageQ                   30.1855
2017-06-11 02:47:23.972765 EDT | AverageAbsQ                30.202
2017-06-11 02:47:23.973984 EDT | AverageY                   30.1859
2017-06-11 02:47:23.974281 EDT | AverageAbsY                30.1925
2017-06-11 02:47:23.974550 EDT | AverageAbsQYDiff            0.566999
2017-06-11 02:47:23.974815 EDT | AverageAction               0.996073
2017-06-11 02:47:23.975083 EDT | PolicyRegParamNorm         94.9242
2017-06-11 02:47:23.975344 EDT | QFunRegParamNorm          123.027
2017-06-11 02:47:23.976933 EDT | -----------------------  -----------
2017-06-11 02:47:23.977376 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #944 | Training started
2017-06-11 02:47:41.673649 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #944 | Training finished
2017-06-11 02:47:41.683903 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #944 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 02:47:41.684300 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #944 | Collecting samples for evaluation
2017-06-11 02:47:56.323491 EDT | -----------------------  -----------
2017-06-11 02:47:56.324403 EDT | Epoch                     944
2017-06-11 02:47:56.324769 EDT | Iteration                 944
2017-06-11 02:47:56.325121 EDT | AverageReturn             752.618
2017-06-11 02:47:56.325479 EDT | StdReturn                 155.159
2017-06-11 02:47:56.325773 EDT | MaxReturn                1039.51
2017-06-11 02:47:56.326075 EDT | MinReturn                 521.39
2017-06-11 02:47:56.326414 EDT | AverageEsReturn           462.698
2017-06-11 02:47:56.326767 EDT | StdEsReturn               157.072
2017-06-11 02:47:56.327089 EDT | MaxEsReturn               712.456
2017-06-11 02:47:56.327359 EDT | MinEsReturn               238.12
2017-06-11 02:47:56.327698 EDT | AverageDiscountedReturn   223.347
2017-06-11 02:47:56.328043 EDT | AverageQLoss                2.34362
2017-06-11 02:47:56.328391 EDT | AveragePolicySurr         -30.6107
2017-06-11 02:47:56.328674 EDT | AverageQ                   30.2897
2017-06-11 02:47:56.328974 EDT | AverageAbsQ                30.3067
2017-06-11 02:47:56.329314 EDT | AverageY                   30.291
2017-06-11 02:47:56.329673 EDT | AverageAbsY                30.2956
2017-06-11 02:47:56.330002 EDT | AverageAbsQYDiff            0.535688
2017-06-11 02:47:56.330272 EDT | AverageAction               0.996909
2017-06-11 02:47:56.330608 EDT | PolicyRegParamNorm         94.9442
2017-06-11 02:47:56.330951 EDT | QFunRegParamNorm          123.092
2017-06-11 02:47:56.331296 EDT | -----------------------  -----------
2017-06-11 02:47:56.331731 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #945 | Training started
2017-06-11 02:48:14.633173 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #945 | Training finished
2017-06-11 02:48:14.634008 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #945 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 02:48:14.634357 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #945 | Collecting samples for evaluation
2017-06-11 02:48:28.560486 EDT | -----------------------  ----------
2017-06-11 02:48:28.561527 EDT | Epoch                    945
2017-06-11 02:48:28.561937 EDT | Iteration                945
2017-06-11 02:48:28.562295 EDT | AverageReturn            566.113
2017-06-11 02:48:28.562646 EDT | StdReturn                 91.4311
2017-06-11 02:48:28.563008 EDT | MaxReturn                780.776
2017-06-11 02:48:28.563354 EDT | MinReturn                389.115
2017-06-11 02:48:28.563681 EDT | AverageEsReturn          499.122
2017-06-11 02:48:28.564028 EDT | StdEsReturn              134.111
2017-06-11 02:48:28.564352 EDT | MaxEsReturn              706.073
2017-06-11 02:48:28.564675 EDT | MinEsReturn              313.38
2017-06-11 02:48:28.564996 EDT | AverageDiscountedReturn  206.558
2017-06-11 02:48:28.565317 EDT | AverageQLoss               2.08628
2017-06-11 02:48:28.565640 EDT | AveragePolicySurr        -30.6771
2017-06-11 02:48:28.566000 EDT | AverageQ                  30.3593
2017-06-11 02:48:28.566325 EDT | AverageAbsQ               30.3721
2017-06-11 02:48:28.566646 EDT | AverageY                  30.3607
2017-06-11 02:48:28.566968 EDT | AverageAbsY               30.3658
2017-06-11 02:48:28.567289 EDT | AverageAbsQYDiff           0.511636
2017-06-11 02:48:28.567624 EDT | AverageAction              0.996296
2017-06-11 02:48:28.567998 EDT | PolicyRegParamNorm        94.9576
2017-06-11 02:48:28.568367 EDT | QFunRegParamNorm         123.11
2017-06-11 02:48:28.568716 EDT | -----------------------  ----------
2017-06-11 02:48:28.569185 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #946 | Training started
2017-06-11 02:48:45.168303 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #946 | Training finished
2017-06-11 02:48:45.169067 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #946 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 02:48:45.169305 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #946 | Collecting samples for evaluation
2017-06-11 02:48:59.736307 EDT | -----------------------  -----------
2017-06-11 02:48:59.737248 EDT | Epoch                     946
2017-06-11 02:48:59.737571 EDT | Iteration                 946
2017-06-11 02:48:59.740606 EDT | AverageReturn            1164.83
2017-06-11 02:48:59.740925 EDT | StdReturn                 210.571
2017-06-11 02:48:59.741249 EDT | MaxReturn                1794.69
2017-06-11 02:48:59.741547 EDT | MinReturn                 899.366
2017-06-11 02:48:59.741854 EDT | AverageEsReturn           276.723
2017-06-11 02:48:59.742165 EDT | StdEsReturn               241.333
2017-06-11 02:48:59.742500 EDT | MaxEsReturn               780.708
2017-06-11 02:48:59.742798 EDT | MinEsReturn                14.3913
2017-06-11 02:48:59.745798 EDT | AverageDiscountedReturn   248.059
2017-06-11 02:48:59.747207 EDT | AverageQLoss                2.48321
2017-06-11 02:48:59.747539 EDT | AveragePolicySurr         -30.5908
2017-06-11 02:48:59.747836 EDT | AverageQ                   30.2832
2017-06-11 02:48:59.748128 EDT | AverageAbsQ                30.3021
2017-06-11 02:48:59.748439 EDT | AverageY                   30.2843
2017-06-11 02:48:59.748729 EDT | AverageAbsY                30.2914
2017-06-11 02:48:59.749015 EDT | AverageAbsQYDiff            0.547083
2017-06-11 02:48:59.749300 EDT | AverageAction               0.995674
2017-06-11 02:48:59.749606 EDT | PolicyRegParamNorm         94.9819
2017-06-11 02:48:59.749911 EDT | QFunRegParamNorm          123.172
2017-06-11 02:48:59.750199 EDT | -----------------------  -----------
2017-06-11 02:48:59.750667 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #947 | Training started
2017-06-11 02:49:16.894016 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #947 | Training finished
2017-06-11 02:49:16.895738 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #947 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 02:49:16.896370 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #947 | Collecting samples for evaluation
2017-06-11 02:49:31.908646 EDT | -----------------------  ----------
2017-06-11 02:49:31.909673 EDT | Epoch                    947
2017-06-11 02:49:31.910035 EDT | Iteration                947
2017-06-11 02:49:31.910372 EDT | AverageReturn            887.882
2017-06-11 02:49:31.910706 EDT | StdReturn                 65.1736
2017-06-11 02:49:31.911037 EDT | MaxReturn                996.761
2017-06-11 02:49:31.911366 EDT | MinReturn                741.627
2017-06-11 02:49:31.911694 EDT | AverageEsReturn          331.125
2017-06-11 02:49:31.912022 EDT | StdEsReturn              223.651
2017-06-11 02:49:31.912349 EDT | MaxEsReturn              696.934
2017-06-11 02:49:31.912676 EDT | MinEsReturn              119.781
2017-06-11 02:49:31.913004 EDT | AverageDiscountedReturn  245.884
2017-06-11 02:49:31.913329 EDT | AverageQLoss               2.35521
2017-06-11 02:49:31.913656 EDT | AveragePolicySurr        -30.5214
2017-06-11 02:49:31.914079 EDT | AverageQ                  30.211
2017-06-11 02:49:31.914418 EDT | AverageAbsQ               30.2301
2017-06-11 02:49:31.914745 EDT | AverageY                  30.2131
2017-06-11 02:49:31.915072 EDT | AverageAbsY               30.22
2017-06-11 02:49:31.915396 EDT | AverageAbsQYDiff           0.538081
2017-06-11 02:49:31.915758 EDT | AverageAction              0.995603
2017-06-11 02:49:31.916191 EDT | PolicyRegParamNorm        95.008
2017-06-11 02:49:31.916632 EDT | QFunRegParamNorm         123.195
2017-06-11 02:49:31.917074 EDT | -----------------------  ----------
2017-06-11 02:49:31.917688 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #948 | Training started
2017-06-11 02:49:49.864419 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #948 | Training finished
2017-06-11 02:49:49.865461 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #948 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 02:49:49.865804 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #948 | Collecting samples for evaluation
2017-06-11 02:50:03.800035 EDT | -----------------------  -----------
2017-06-11 02:50:03.800950 EDT | Epoch                     948
2017-06-11 02:50:03.801304 EDT | Iteration                 948
2017-06-11 02:50:03.801650 EDT | AverageReturn             686.817
2017-06-11 02:50:03.801996 EDT | StdReturn                 389.721
2017-06-11 02:50:03.802260 EDT | MaxReturn                1142.61
2017-06-11 02:50:03.802586 EDT | MinReturn                 118.84
2017-06-11 02:50:03.802914 EDT | AverageEsReturn           302.652
2017-06-11 02:50:03.803249 EDT | StdEsReturn               198.016
2017-06-11 02:50:03.803564 EDT | MaxEsReturn               740.583
2017-06-11 02:50:03.803841 EDT | MinEsReturn                79.1736
2017-06-11 02:50:03.804170 EDT | AverageDiscountedReturn   199.153
2017-06-11 02:50:03.804506 EDT | AverageQLoss                2.18644
2017-06-11 02:50:03.804842 EDT | AveragePolicySurr         -30.5425
2017-06-11 02:50:03.805115 EDT | AverageQ                   30.2405
2017-06-11 02:50:03.806295 EDT | AverageAbsQ                30.2609
2017-06-11 02:50:03.806621 EDT | AverageY                   30.2417
2017-06-11 02:50:03.806953 EDT | AverageAbsY                30.2501
2017-06-11 02:50:03.807284 EDT | AverageAbsQYDiff            0.525552
2017-06-11 02:50:03.807621 EDT | AverageAction               0.996352
2017-06-11 02:50:03.807923 EDT | PolicyRegParamNorm         95.0627
2017-06-11 02:50:03.808205 EDT | QFunRegParamNorm          123.229
2017-06-11 02:50:03.808532 EDT | -----------------------  -----------
2017-06-11 02:50:03.809009 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #949 | Training started
2017-06-11 02:50:20.936921 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #949 | Training finished
2017-06-11 02:50:20.937963 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #949 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 02:50:20.938610 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #949 | Collecting samples for evaluation
2017-06-11 02:50:35.251287 EDT | -----------------------  -----------
2017-06-11 02:50:35.252225 EDT | Epoch                     949
2017-06-11 02:50:35.252612 EDT | Iteration                 949
2017-06-11 02:50:35.253772 EDT | AverageReturn             864.53
2017-06-11 02:50:35.254158 EDT | StdReturn                 116.347
2017-06-11 02:50:35.257774 EDT | MaxReturn                1006.31
2017-06-11 02:50:35.258162 EDT | MinReturn                 708.772
2017-06-11 02:50:35.258527 EDT | AverageEsReturn           305.307
2017-06-11 02:50:35.258890 EDT | StdEsReturn               191.912
2017-06-11 02:50:35.259249 EDT | MaxEsReturn               699.778
2017-06-11 02:50:35.259605 EDT | MinEsReturn                56.0554
2017-06-11 02:50:35.259963 EDT | AverageDiscountedReturn   244.48
2017-06-11 02:50:35.260324 EDT | AverageQLoss                1.94818
2017-06-11 02:50:35.260682 EDT | AveragePolicySurr         -30.5128
2017-06-11 02:50:35.261770 EDT | AverageQ                   30.2077
2017-06-11 02:50:35.262152 EDT | AverageAbsQ                30.2283
2017-06-11 02:50:35.265771 EDT | AverageY                   30.2089
2017-06-11 02:50:35.266156 EDT | AverageAbsY                30.2152
2017-06-11 02:50:35.266519 EDT | AverageAbsQYDiff            0.497491
2017-06-11 02:50:35.266880 EDT | AverageAction               0.996643
2017-06-11 02:50:35.267240 EDT | PolicyRegParamNorm         95.0358
2017-06-11 02:50:35.267597 EDT | QFunRegParamNorm          123.267
2017-06-11 02:50:35.267955 EDT | -----------------------  -----------
2017-06-11 02:50:35.268485 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #950 | Training started
2017-06-11 02:50:52.619345 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #950 | Training finished
2017-06-11 02:50:52.619892 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #950 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 02:50:52.620221 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #950 | Collecting samples for evaluation
2017-06-11 02:51:07.815647 EDT | -----------------------  -----------
2017-06-11 02:51:07.825542 EDT | Epoch                     950
2017-06-11 02:51:07.826056 EDT | Iteration                 950
2017-06-11 02:51:07.826403 EDT | AverageReturn             213.972
2017-06-11 02:51:07.826767 EDT | StdReturn                  78.2137
2017-06-11 02:51:07.827189 EDT | MaxReturn                 674.155
2017-06-11 02:51:07.827564 EDT | MinReturn                 184.93
2017-06-11 02:51:07.827905 EDT | AverageEsReturn           341.319
2017-06-11 02:51:07.828168 EDT | StdEsReturn               282.178
2017-06-11 02:51:07.828508 EDT | MaxEsReturn              1030.8
2017-06-11 02:51:07.830165 EDT | MinEsReturn                66.5202
2017-06-11 02:51:07.830525 EDT | AverageDiscountedReturn   124.927
2017-06-11 02:51:07.830908 EDT | AverageQLoss                1.70855
2017-06-11 02:51:07.831307 EDT | AveragePolicySurr         -30.4889
2017-06-11 02:51:07.831648 EDT | AverageQ                   30.2093
2017-06-11 02:51:07.832001 EDT | AverageAbsQ                30.2263
2017-06-11 02:51:07.832423 EDT | AverageY                   30.2106
2017-06-11 02:51:07.832779 EDT | AverageAbsY                30.2157
2017-06-11 02:51:07.833113 EDT | AverageAbsQYDiff            0.491866
2017-06-11 02:51:07.833500 EDT | AverageAction               0.995212
2017-06-11 02:51:07.833936 EDT | PolicyRegParamNorm         95.1311
2017-06-11 02:51:07.834354 EDT | QFunRegParamNorm          123.281
2017-06-11 02:51:07.835226 EDT | -----------------------  -----------
2017-06-11 02:51:07.835734 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #951 | Training started
2017-06-11 02:51:26.524776 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #951 | Training finished
2017-06-11 02:51:26.525800 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #951 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 02:51:26.526199 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #951 | Collecting samples for evaluation
2017-06-11 02:51:43.176305 EDT | -----------------------  ----------
2017-06-11 02:51:43.177309 EDT | Epoch                    951
2017-06-11 02:51:43.177682 EDT | Iteration                951
2017-06-11 02:51:43.178053 EDT | AverageReturn            200.307
2017-06-11 02:51:43.178414 EDT | StdReturn                 63.6124
2017-06-11 02:51:43.178832 EDT | MaxReturn                455.415
2017-06-11 02:51:43.179186 EDT | MinReturn                 69.1258
2017-06-11 02:51:43.179531 EDT | AverageEsReturn          387.802
2017-06-11 02:51:43.179874 EDT | StdEsReturn              242.412
2017-06-11 02:51:43.180216 EDT | MaxEsReturn              716.701
2017-06-11 02:51:43.180554 EDT | MinEsReturn                7.46617
2017-06-11 02:51:43.180897 EDT | AverageDiscountedReturn  121.436
2017-06-11 02:51:43.181242 EDT | AverageQLoss               2.49789
2017-06-11 02:51:43.181586 EDT | AveragePolicySurr        -30.4382
2017-06-11 02:51:43.181952 EDT | AverageQ                  30.1515
2017-06-11 02:51:43.182304 EDT | AverageAbsQ               30.1658
2017-06-11 02:51:43.182658 EDT | AverageY                  30.152
2017-06-11 02:51:43.183006 EDT | AverageAbsY               30.1576
2017-06-11 02:51:43.183348 EDT | AverageAbsQYDiff           0.541361
2017-06-11 02:51:43.183788 EDT | AverageAction              0.99694
2017-06-11 02:51:43.184228 EDT | PolicyRegParamNorm        95.1488
2017-06-11 02:51:43.184667 EDT | QFunRegParamNorm         123.33
2017-06-11 02:51:43.185087 EDT | -----------------------  ----------
2017-06-11 02:51:43.185623 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #952 | Training started
2017-06-11 02:52:02.163923 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #952 | Training finished
2017-06-11 02:52:02.164672 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #952 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 02:52:02.165119 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #952 | Collecting samples for evaluation
2017-06-11 02:52:17.097337 EDT | -----------------------  -----------
2017-06-11 02:52:17.098846 EDT | Epoch                     952
2017-06-11 02:52:17.100849 EDT | Iteration                 952
2017-06-11 02:52:17.101302 EDT | AverageReturn            1179.01
2017-06-11 02:52:17.101780 EDT | StdReturn                 137.838
2017-06-11 02:52:17.102232 EDT | MaxReturn                1462.64
2017-06-11 02:52:17.103345 EDT | MinReturn                1037.93
2017-06-11 02:52:17.105223 EDT | AverageEsReturn           235.231
2017-06-11 02:52:17.105812 EDT | StdEsReturn               198.399
2017-06-11 02:52:17.107604 EDT | MaxEsReturn               654.546
2017-06-11 02:52:17.110533 EDT | MinEsReturn                15.8557
2017-06-11 02:52:17.111007 EDT | AverageDiscountedReturn   250.284
2017-06-11 02:52:17.111458 EDT | AverageQLoss                2.51657
2017-06-11 02:52:17.111908 EDT | AveragePolicySurr         -30.4667
2017-06-11 02:52:17.113846 EDT | AverageQ                   30.1781
2017-06-11 02:52:17.119375 EDT | AverageAbsQ                30.1917
2017-06-11 02:52:17.119739 EDT | AverageY                   30.18
2017-06-11 02:52:17.120850 EDT | AverageAbsY                30.1844
2017-06-11 02:52:17.121254 EDT | AverageAbsQYDiff            0.545484
2017-06-11 02:52:17.121775 EDT | AverageAction               0.995062
2017-06-11 02:52:17.122162 EDT | PolicyRegParamNorm         95.2322
2017-06-11 02:52:17.122632 EDT | QFunRegParamNorm          123.41
2017-06-11 02:52:17.123063 EDT | -----------------------  -----------
2017-06-11 02:52:17.123660 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #953 | Training started
2017-06-11 02:52:37.162272 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #953 | Training finished
2017-06-11 02:52:37.169389 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #953 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 02:52:37.170024 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #953 | Collecting samples for evaluation
2017-06-11 02:52:51.134654 EDT | -----------------------  -----------
2017-06-11 02:52:51.136350 EDT | Epoch                     953
2017-06-11 02:52:51.136682 EDT | Iteration                 953
2017-06-11 02:52:51.137011 EDT | AverageReturn            1555.76
2017-06-11 02:52:51.137322 EDT | StdReturn                 322.766
2017-06-11 02:52:51.137618 EDT | MaxReturn                2212.74
2017-06-11 02:52:51.138032 EDT | MinReturn                1078.89
2017-06-11 02:52:51.138393 EDT | AverageEsReturn           431.896
2017-06-11 02:52:51.138834 EDT | StdEsReturn               233.496
2017-06-11 02:52:51.139217 EDT | MaxEsReturn               783.147
2017-06-11 02:52:51.139566 EDT | MinEsReturn                11.0902
2017-06-11 02:52:51.139939 EDT | AverageDiscountedReturn   252.567
2017-06-11 02:52:51.140329 EDT | AverageQLoss                2.25706
2017-06-11 02:52:51.140734 EDT | AveragePolicySurr         -30.5188
2017-06-11 02:52:51.141138 EDT | AverageQ                   30.2372
2017-06-11 02:52:51.141530 EDT | AverageAbsQ                30.2505
2017-06-11 02:52:51.141914 EDT | AverageY                   30.2367
2017-06-11 02:52:51.142333 EDT | AverageAbsY                30.2395
2017-06-11 02:52:51.142731 EDT | AverageAbsQYDiff            0.52618
2017-06-11 02:52:51.143150 EDT | AverageAction               0.995574
2017-06-11 02:52:51.143619 EDT | PolicyRegParamNorm         95.3014
2017-06-11 02:52:51.144020 EDT | QFunRegParamNorm          123.454
2017-06-11 02:52:51.144398 EDT | -----------------------  -----------
2017-06-11 02:52:51.144944 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #954 | Training started
2017-06-11 02:53:09.735923 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #954 | Training finished
2017-06-11 02:53:09.736768 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #954 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 02:53:09.737113 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #954 | Collecting samples for evaluation
2017-06-11 02:53:25.682975 EDT | -----------------------  -----------
2017-06-11 02:53:25.683891 EDT | Epoch                     954
2017-06-11 02:53:25.684210 EDT | Iteration                 954
2017-06-11 02:53:25.684574 EDT | AverageReturn            2343.6
2017-06-11 02:53:25.685062 EDT | StdReturn                 888.291
2017-06-11 02:53:25.685412 EDT | MaxReturn                3150.42
2017-06-11 02:53:25.685850 EDT | MinReturn                 913.598
2017-06-11 02:53:25.686136 EDT | AverageEsReturn           251.353
2017-06-11 02:53:25.686479 EDT | StdEsReturn               191.442
2017-06-11 02:53:25.686828 EDT | MaxEsReturn               660.687
2017-06-11 02:53:25.687212 EDT | MinEsReturn                14.3972
2017-06-11 02:53:25.687545 EDT | AverageDiscountedReturn   242.794
2017-06-11 02:53:25.687892 EDT | AverageQLoss                2.12183
2017-06-11 02:53:25.688283 EDT | AveragePolicySurr         -30.4135
2017-06-11 02:53:25.688596 EDT | AverageQ                   30.0935
2017-06-11 02:53:25.689083 EDT | AverageAbsQ                30.1135
2017-06-11 02:53:25.689451 EDT | AverageY                   30.0947
2017-06-11 02:53:25.689800 EDT | AverageAbsY                30.0992
2017-06-11 02:53:25.690601 EDT | AverageAbsQYDiff            0.51855
2017-06-11 02:53:25.690963 EDT | AverageAction               0.994381
2017-06-11 02:53:25.691604 EDT | PolicyRegParamNorm         95.3441
2017-06-11 02:53:25.692025 EDT | QFunRegParamNorm          123.524
2017-06-11 02:53:25.693465 EDT | -----------------------  -----------
2017-06-11 02:53:25.706327 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #955 | Training started
2017-06-11 02:53:43.743513 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #955 | Training finished
2017-06-11 02:53:43.744655 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #955 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 02:53:43.745050 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #955 | Collecting samples for evaluation
2017-06-11 02:53:59.103199 EDT | -----------------------  -----------
2017-06-11 02:53:59.104077 EDT | Epoch                     955
2017-06-11 02:53:59.104354 EDT | Iteration                 955
2017-06-11 02:53:59.104616 EDT | AverageReturn            1092.53
2017-06-11 02:53:59.104875 EDT | StdReturn                 298.139
2017-06-11 02:53:59.105131 EDT | MaxReturn                1870.87
2017-06-11 02:53:59.105384 EDT | MinReturn                 683.062
2017-06-11 02:53:59.105639 EDT | AverageEsReturn           345.799
2017-06-11 02:53:59.105903 EDT | StdEsReturn               295.324
2017-06-11 02:53:59.106157 EDT | MaxEsReturn               911.376
2017-06-11 02:53:59.106409 EDT | MinEsReturn                10.5858
2017-06-11 02:53:59.106661 EDT | AverageDiscountedReturn   241.622
2017-06-11 02:53:59.106913 EDT | AverageQLoss                2.14237
2017-06-11 02:53:59.107165 EDT | AveragePolicySurr         -30.487
2017-06-11 02:53:59.107417 EDT | AverageQ                   30.192
2017-06-11 02:53:59.107667 EDT | AverageAbsQ                30.211
2017-06-11 02:53:59.107917 EDT | AverageY                   30.1938
2017-06-11 02:53:59.108170 EDT | AverageAbsY                30.1992
2017-06-11 02:53:59.108422 EDT | AverageAbsQYDiff            0.525473
2017-06-11 02:53:59.108672 EDT | AverageAction               0.995158
2017-06-11 02:53:59.108922 EDT | PolicyRegParamNorm         95.3346
2017-06-11 02:53:59.109173 EDT | QFunRegParamNorm          123.563
2017-06-11 02:53:59.109424 EDT | -----------------------  -----------
2017-06-11 02:53:59.109851 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #956 | Training started
2017-06-11 02:54:17.193207 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #956 | Training finished
2017-06-11 02:54:17.218398 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #956 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 02:54:17.218733 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #956 | Collecting samples for evaluation
2017-06-11 02:54:32.180168 EDT | -----------------------  -----------
2017-06-11 02:54:32.181290 EDT | Epoch                     956
2017-06-11 02:54:32.181749 EDT | Iteration                 956
2017-06-11 02:54:32.182177 EDT | AverageReturn            1351.84
2017-06-11 02:54:32.182608 EDT | StdReturn                 673.079
2017-06-11 02:54:32.182810 EDT | MaxReturn                3423.49
2017-06-11 02:54:32.183144 EDT | MinReturn                 483.201
2017-06-11 02:54:32.183545 EDT | AverageEsReturn           563.892
2017-06-11 02:54:32.183974 EDT | StdEsReturn               207.085
2017-06-11 02:54:32.184393 EDT | MaxEsReturn               806.441
2017-06-11 02:54:32.184811 EDT | MinEsReturn               247.639
2017-06-11 02:54:32.185218 EDT | AverageDiscountedReturn   244.594
2017-06-11 02:54:32.185630 EDT | AverageQLoss                1.94101
2017-06-11 02:54:32.186069 EDT | AveragePolicySurr         -30.3715
2017-06-11 02:54:32.186476 EDT | AverageQ                   30.0917
2017-06-11 02:54:32.186861 EDT | AverageAbsQ                30.1113
2017-06-11 02:54:32.187285 EDT | AverageY                   30.0929
2017-06-11 02:54:32.187703 EDT | AverageAbsY                30.1015
2017-06-11 02:54:32.188285 EDT | AverageAbsQYDiff            0.507862
2017-06-11 02:54:32.188718 EDT | AverageAction               0.996043
2017-06-11 02:54:32.189282 EDT | PolicyRegParamNorm         95.391
2017-06-11 02:54:32.189719 EDT | QFunRegParamNorm          123.589
2017-06-11 02:54:32.190140 EDT | -----------------------  -----------
2017-06-11 02:54:32.190934 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #957 | Training started
2017-06-11 02:54:51.894307 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #957 | Training finished
2017-06-11 02:54:51.895209 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #957 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 02:54:51.895561 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #957 | Collecting samples for evaluation
2017-06-11 02:55:06.714471 EDT | -----------------------  -----------
2017-06-11 02:55:06.715311 EDT | Epoch                     957
2017-06-11 02:55:06.715604 EDT | Iteration                 957
2017-06-11 02:55:06.715868 EDT | AverageReturn            1320.45
2017-06-11 02:55:06.716126 EDT | StdReturn                 699.845
2017-06-11 02:55:06.716380 EDT | MaxReturn                2845.97
2017-06-11 02:55:06.716632 EDT | MinReturn                  77.0445
2017-06-11 02:55:06.716885 EDT | AverageEsReturn           419.29
2017-06-11 02:55:06.717138 EDT | StdEsReturn               191.691
2017-06-11 02:55:06.717886 EDT | MaxEsReturn               680.215
2017-06-11 02:55:06.718173 EDT | MinEsReturn                28.41
2017-06-11 02:55:06.719261 EDT | AverageDiscountedReturn   238.781
2017-06-11 02:55:06.719687 EDT | AverageQLoss                2.55263
2017-06-11 02:55:06.720026 EDT | AveragePolicySurr         -30.4381
2017-06-11 02:55:06.720359 EDT | AverageQ                   30.1471
2017-06-11 02:55:06.720689 EDT | AverageAbsQ                30.1659
2017-06-11 02:55:06.721019 EDT | AverageY                   30.1481
2017-06-11 02:55:06.721350 EDT | AverageAbsY                30.1536
2017-06-11 02:55:06.721679 EDT | AverageAbsQYDiff            0.547251
2017-06-11 02:55:06.722017 EDT | AverageAction               0.996711
2017-06-11 02:55:06.722346 EDT | PolicyRegParamNorm         95.4975
2017-06-11 02:55:06.722681 EDT | QFunRegParamNorm          123.663
2017-06-11 02:55:06.723106 EDT | -----------------------  -----------
2017-06-11 02:55:06.723689 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #958 | Training started
2017-06-11 02:55:26.324274 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #958 | Training finished
2017-06-11 02:55:26.325249 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #958 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 02:55:26.325669 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #958 | Collecting samples for evaluation
2017-06-11 02:55:40.331764 EDT | -----------------------  -----------
2017-06-11 02:55:40.332753 EDT | Epoch                     958
2017-06-11 02:55:40.333127 EDT | Iteration                 958
2017-06-11 02:55:40.333470 EDT | AverageReturn             865.692
2017-06-11 02:55:40.333831 EDT | StdReturn                 253.599
2017-06-11 02:55:40.334170 EDT | MaxReturn                1366.16
2017-06-11 02:55:40.334504 EDT | MinReturn                  74.4513
2017-06-11 02:55:40.334837 EDT | AverageEsReturn           336.11
2017-06-11 02:55:40.335168 EDT | StdEsReturn               145.302
2017-06-11 02:55:40.335502 EDT | MaxEsReturn               510.189
2017-06-11 02:55:40.335833 EDT | MinEsReturn                21.8672
2017-06-11 02:55:40.336164 EDT | AverageDiscountedReturn   240.86
2017-06-11 02:55:40.336494 EDT | AverageQLoss                2.61227
2017-06-11 02:55:40.336825 EDT | AveragePolicySurr         -30.3641
2017-06-11 02:55:40.337156 EDT | AverageQ                   30.0725
2017-06-11 02:55:40.337486 EDT | AverageAbsQ                30.0886
2017-06-11 02:55:40.337826 EDT | AverageY                   30.0727
2017-06-11 02:55:40.338157 EDT | AverageAbsY                30.0786
2017-06-11 02:55:40.338495 EDT | AverageAbsQYDiff            0.553416
2017-06-11 02:55:40.338825 EDT | AverageAction               0.996983
2017-06-11 02:55:40.339156 EDT | PolicyRegParamNorm         95.5034
2017-06-11 02:55:40.339488 EDT | QFunRegParamNorm          123.724
2017-06-11 02:55:40.339818 EDT | -----------------------  -----------
2017-06-11 02:55:40.340293 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #959 | Training started
2017-06-11 02:55:56.168551 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #959 | Training finished
2017-06-11 02:55:56.169484 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #959 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 02:55:56.169882 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #959 | Collecting samples for evaluation
2017-06-11 02:56:10.996119 EDT | -----------------------  -----------
2017-06-11 02:56:10.997236 EDT | Epoch                     959
2017-06-11 02:56:10.997658 EDT | Iteration                 959
2017-06-11 02:56:10.997982 EDT | AverageReturn            1685.82
2017-06-11 02:56:10.998317 EDT | StdReturn                 866.349
2017-06-11 02:56:10.998606 EDT | MaxReturn                3497.51
2017-06-11 02:56:10.998946 EDT | MinReturn                  79.9881
2017-06-11 02:56:10.999269 EDT | AverageEsReturn           572.334
2017-06-11 02:56:10.999590 EDT | StdEsReturn               163.69
2017-06-11 02:56:10.999900 EDT | MaxEsReturn               734.835
2017-06-11 02:56:11.006296 EDT | MinEsReturn               291.85
2017-06-11 02:56:11.006689 EDT | AverageDiscountedReturn   228.915
2017-06-11 02:56:11.007041 EDT | AverageQLoss                2.04612
2017-06-11 02:56:11.007403 EDT | AveragePolicySurr         -30.318
2017-06-11 02:56:11.007753 EDT | AverageQ                   30.0298
2017-06-11 02:56:11.008257 EDT | AverageAbsQ                30.0487
2017-06-11 02:56:11.008618 EDT | AverageY                   30.0314
2017-06-11 02:56:11.008961 EDT | AverageAbsY                30.0388
2017-06-11 02:56:11.009404 EDT | AverageAbsQYDiff            0.50471
2017-06-11 02:56:11.009840 EDT | AverageAction               0.995698
2017-06-11 02:56:11.010253 EDT | PolicyRegParamNorm         95.5407
2017-06-11 02:56:11.010608 EDT | QFunRegParamNorm          123.748
2017-06-11 02:56:11.010954 EDT | -----------------------  -----------
2017-06-11 02:56:11.011475 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #960 | Training started
2017-06-11 02:56:28.209306 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #960 | Training finished
2017-06-11 02:56:28.209532 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #960 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 02:56:28.209872 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #960 | Collecting samples for evaluation
2017-06-11 02:56:42.509394 EDT | -----------------------  -----------
2017-06-11 02:56:42.510292 EDT | Epoch                     960
2017-06-11 02:56:42.510485 EDT | Iteration                 960
2017-06-11 02:56:42.510678 EDT | AverageReturn             812.952
2017-06-11 02:56:42.510910 EDT | StdReturn                 230.632
2017-06-11 02:56:42.512309 EDT | MaxReturn                1093.99
2017-06-11 02:56:42.512663 EDT | MinReturn                  83.4044
2017-06-11 02:56:42.513502 EDT | AverageEsReturn           271.682
2017-06-11 02:56:42.514226 EDT | StdEsReturn               151.586
2017-06-11 02:56:42.514415 EDT | MaxEsReturn               684.566
2017-06-11 02:56:42.514829 EDT | MinEsReturn                71.2545
2017-06-11 02:56:42.515048 EDT | AverageDiscountedReturn   238.034
2017-06-11 02:56:42.515264 EDT | AverageQLoss                2.13962
2017-06-11 02:56:42.515545 EDT | AveragePolicySurr         -30.2887
2017-06-11 02:56:42.515802 EDT | AverageQ                   29.9995
2017-06-11 02:56:42.515987 EDT | AverageAbsQ                30.0161
2017-06-11 02:56:42.516331 EDT | AverageY                   29.9996
2017-06-11 02:56:42.516517 EDT | AverageAbsY                30.0064
2017-06-11 02:56:42.516800 EDT | AverageAbsQYDiff            0.5101
2017-06-11 02:56:42.516985 EDT | AverageAction               0.996921
2017-06-11 02:56:42.517214 EDT | PolicyRegParamNorm         95.4895
2017-06-11 02:56:42.517398 EDT | QFunRegParamNorm          123.853
2017-06-11 02:56:42.517578 EDT | -----------------------  -----------
2017-06-11 02:56:42.517919 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #961 | Training started
2017-06-11 02:57:01.299665 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #961 | Training finished
2017-06-11 02:57:01.300659 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #961 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 02:57:01.301046 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #961 | Collecting samples for evaluation
2017-06-11 02:57:16.798450 EDT | -----------------------  -----------
2017-06-11 02:57:16.799531 EDT | Epoch                     961
2017-06-11 02:57:16.799975 EDT | Iteration                 961
2017-06-11 02:57:16.800354 EDT | AverageReturn            2788.15
2017-06-11 02:57:16.800730 EDT | StdReturn                 546.051
2017-06-11 02:57:16.801155 EDT | MaxReturn                3305.97
2017-06-11 02:57:16.801536 EDT | MinReturn                1340.41
2017-06-11 02:57:16.801881 EDT | AverageEsReturn           356.924
2017-06-11 02:57:16.802267 EDT | StdEsReturn               328.084
2017-06-11 02:57:16.802657 EDT | MaxEsReturn               861.349
2017-06-11 02:57:16.803043 EDT | MinEsReturn                30.1923
2017-06-11 02:57:16.803391 EDT | AverageDiscountedReturn   244.106
2017-06-11 02:57:16.803728 EDT | AverageQLoss                2.32577
2017-06-11 02:57:16.804120 EDT | AveragePolicySurr         -30.3133
2017-06-11 02:57:16.804505 EDT | AverageQ                   29.9903
2017-06-11 02:57:16.804933 EDT | AverageAbsQ                30.0053
2017-06-11 02:57:16.805321 EDT | AverageY                   29.992
2017-06-11 02:57:16.805746 EDT | AverageAbsY                29.9983
2017-06-11 02:57:16.806168 EDT | AverageAbsQYDiff            0.529434
2017-06-11 02:57:16.806587 EDT | AverageAction               0.993982
2017-06-11 02:57:16.806969 EDT | PolicyRegParamNorm         95.5324
2017-06-11 02:57:16.807311 EDT | QFunRegParamNorm          123.9
2017-06-11 02:57:16.807707 EDT | -----------------------  -----------
2017-06-11 02:57:16.808260 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #962 | Training started
2017-06-11 02:57:34.039752 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #962 | Training finished
2017-06-11 02:57:34.040659 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #962 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 02:57:34.040958 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #962 | Collecting samples for evaluation
2017-06-11 02:57:48.427813 EDT | -----------------------  -----------
2017-06-11 02:57:48.428703 EDT | Epoch                     962
2017-06-11 02:57:48.429049 EDT | Iteration                 962
2017-06-11 02:57:48.429376 EDT | AverageReturn            1073.93
2017-06-11 02:57:48.429710 EDT | StdReturn                 269.672
2017-06-11 02:57:48.430031 EDT | MaxReturn                1837.29
2017-06-11 02:57:48.430328 EDT | MinReturn                 716.737
2017-06-11 02:57:48.430665 EDT | AverageEsReturn           187.217
2017-06-11 02:57:48.430983 EDT | StdEsReturn               125.246
2017-06-11 02:57:48.431302 EDT | MaxEsReturn               415.216
2017-06-11 02:57:48.431613 EDT | MinEsReturn                 9.94322
2017-06-11 02:57:48.432281 EDT | AverageDiscountedReturn   246.297
2017-06-11 02:57:48.432756 EDT | AverageQLoss                1.84797
2017-06-11 02:57:48.433066 EDT | AveragePolicySurr         -30.2191
2017-06-11 02:57:48.433363 EDT | AverageQ                   29.9341
2017-06-11 02:57:48.436356 EDT | AverageAbsQ                29.954
2017-06-11 02:57:48.436527 EDT | AverageY                   29.9355
2017-06-11 02:57:48.436689 EDT | AverageAbsY                29.9455
2017-06-11 02:57:48.436931 EDT | AverageAbsQYDiff            0.505979
2017-06-11 02:57:48.437165 EDT | AverageAction               0.996852
2017-06-11 02:57:48.437332 EDT | PolicyRegParamNorm         95.5974
2017-06-11 02:57:48.437525 EDT | QFunRegParamNorm          123.967
2017-06-11 02:57:48.437730 EDT | -----------------------  -----------
2017-06-11 02:57:48.438062 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #963 | Training started
2017-06-11 02:58:06.817837 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #963 | Training finished
2017-06-11 02:58:06.819794 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #963 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 02:58:06.820202 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #963 | Collecting samples for evaluation
2017-06-11 02:58:21.275545 EDT | -----------------------  -----------
2017-06-11 02:58:21.276905 EDT | Epoch                     963
2017-06-11 02:58:21.277121 EDT | Iteration                 963
2017-06-11 02:58:21.277283 EDT | AverageReturn            3155.35
2017-06-11 02:58:21.277441 EDT | StdReturn                  22.014
2017-06-11 02:58:21.277595 EDT | MaxReturn                3202.8
2017-06-11 02:58:21.277844 EDT | MinReturn                3125.63
2017-06-11 02:58:21.278004 EDT | AverageEsReturn           414.043
2017-06-11 02:58:21.278158 EDT | StdEsReturn               310.765
2017-06-11 02:58:21.278309 EDT | MaxEsReturn               972.21
2017-06-11 02:58:21.278494 EDT | MinEsReturn                37.513
2017-06-11 02:58:21.278647 EDT | AverageDiscountedReturn   238.759
2017-06-11 02:58:21.278798 EDT | AverageQLoss                2.00929
2017-06-11 02:58:21.278949 EDT | AveragePolicySurr         -30.2678
2017-06-11 02:58:21.279099 EDT | AverageQ                   29.9818
2017-06-11 02:58:21.279249 EDT | AverageAbsQ                29.9975
2017-06-11 02:58:21.279399 EDT | AverageY                   29.9825
2017-06-11 02:58:21.279548 EDT | AverageAbsY                29.9886
2017-06-11 02:58:21.279698 EDT | AverageAbsQYDiff            0.510737
2017-06-11 02:58:21.279850 EDT | AverageAction               0.995877
2017-06-11 02:58:21.279999 EDT | PolicyRegParamNorm         95.6664
2017-06-11 02:58:21.280149 EDT | QFunRegParamNorm          124.003
2017-06-11 02:58:21.280405 EDT | -----------------------  -----------
2017-06-11 02:58:21.280674 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #964 | Training started
2017-06-11 02:58:39.268517 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #964 | Training finished
2017-06-11 02:58:39.269459 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #964 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 02:58:39.269827 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #964 | Collecting samples for evaluation
2017-06-11 02:58:53.547153 EDT | -----------------------  -----------
2017-06-11 02:58:53.548514 EDT | Epoch                     964
2017-06-11 02:58:53.548890 EDT | Iteration                 964
2017-06-11 02:58:53.549242 EDT | AverageReturn            2975.83
2017-06-11 02:58:53.549586 EDT | StdReturn                 563.126
2017-06-11 02:58:53.549940 EDT | MaxReturn                3418.04
2017-06-11 02:58:53.550482 EDT | MinReturn                1596.66
2017-06-11 02:58:53.550835 EDT | AverageEsReturn           636.058
2017-06-11 02:58:53.551238 EDT | StdEsReturn               747.745
2017-06-11 02:58:53.551583 EDT | MaxEsReturn              2117.34
2017-06-11 02:58:53.551928 EDT | MinEsReturn               102.913
2017-06-11 02:58:53.552267 EDT | AverageDiscountedReturn   238.885
2017-06-11 02:58:53.553582 EDT | AverageQLoss                2.04686
2017-06-11 02:58:53.553955 EDT | AveragePolicySurr         -30.2186
2017-06-11 02:58:53.554328 EDT | AverageQ                   29.9204
2017-06-11 02:58:53.554834 EDT | AverageAbsQ                29.9418
2017-06-11 02:58:53.555338 EDT | AverageY                   29.9202
2017-06-11 02:58:53.555673 EDT | AverageAbsY                29.9294
2017-06-11 02:58:53.556020 EDT | AverageAbsQYDiff            0.515476
2017-06-11 02:58:53.556933 EDT | AverageAction               0.996207
2017-06-11 02:58:53.557272 EDT | PolicyRegParamNorm         95.6933
2017-06-11 02:58:53.557770 EDT | QFunRegParamNorm          124.083
2017-06-11 02:58:53.558077 EDT | -----------------------  -----------
2017-06-11 02:58:53.559018 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #965 | Training started
2017-06-11 02:59:13.073564 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #965 | Training finished
2017-06-11 02:59:13.074463 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #965 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 02:59:13.074946 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #965 | Collecting samples for evaluation
2017-06-11 02:59:27.596067 EDT | -----------------------  -----------
2017-06-11 02:59:27.596647 EDT | Epoch                     965
2017-06-11 02:59:27.597092 EDT | Iteration                 965
2017-06-11 02:59:27.597397 EDT | AverageReturn            1028.27
2017-06-11 02:59:27.597846 EDT | StdReturn                 138.523
2017-06-11 02:59:27.598273 EDT | MaxReturn                1310.88
2017-06-11 02:59:27.598607 EDT | MinReturn                 796.754
2017-06-11 02:59:27.598950 EDT | AverageEsReturn           337.016
2017-06-11 02:59:27.599217 EDT | StdEsReturn               283.57
2017-06-11 02:59:27.599617 EDT | MaxEsReturn               814.835
2017-06-11 02:59:27.599955 EDT | MinEsReturn                 8.06923
2017-06-11 02:59:27.600261 EDT | AverageDiscountedReturn   236.973
2017-06-11 02:59:27.600591 EDT | AverageQLoss                1.96024
2017-06-11 02:59:27.601009 EDT | AveragePolicySurr         -30.2495
2017-06-11 02:59:27.601413 EDT | AverageQ                   29.9598
2017-06-11 02:59:27.601746 EDT | AverageAbsQ                29.9784
2017-06-11 02:59:27.601994 EDT | AverageY                   29.962
2017-06-11 02:59:27.602178 EDT | AverageAbsY                29.9721
2017-06-11 02:59:27.602361 EDT | AverageAbsQYDiff            0.507364
2017-06-11 02:59:27.602559 EDT | AverageAction               0.996977
2017-06-11 02:59:27.602743 EDT | PolicyRegParamNorm         95.749
2017-06-11 02:59:27.602924 EDT | QFunRegParamNorm          124.146
2017-06-11 02:59:27.603105 EDT | -----------------------  -----------
2017-06-11 02:59:27.603610 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #966 | Training started
2017-06-11 02:59:45.730637 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #966 | Training finished
2017-06-11 02:59:45.731653 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #966 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 02:59:45.732102 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #966 | Collecting samples for evaluation
2017-06-11 03:00:00.380895 EDT | -----------------------  -----------
2017-06-11 03:00:00.381714 EDT | Epoch                     966
2017-06-11 03:00:00.381920 EDT | Iteration                 966
2017-06-11 03:00:00.382194 EDT | AverageReturn            1008.42
2017-06-11 03:00:00.382394 EDT | StdReturn                 276.32
2017-06-11 03:00:00.382661 EDT | MaxReturn                1558.48
2017-06-11 03:00:00.382873 EDT | MinReturn                 619.285
2017-06-11 03:00:00.383077 EDT | AverageEsReturn           368.341
2017-06-11 03:00:00.383395 EDT | StdEsReturn               369.689
2017-06-11 03:00:00.383592 EDT | MaxEsReturn               868.239
2017-06-11 03:00:00.383797 EDT | MinEsReturn                16.7868
2017-06-11 03:00:00.383991 EDT | AverageDiscountedReturn   231.289
2017-06-11 03:00:00.385157 EDT | AverageQLoss                2.31338
2017-06-11 03:00:00.385358 EDT | AveragePolicySurr         -30.2398
2017-06-11 03:00:00.385740 EDT | AverageQ                   29.9399
2017-06-11 03:00:00.386027 EDT | AverageAbsQ                29.961
2017-06-11 03:00:00.386267 EDT | AverageY                   29.9423
2017-06-11 03:00:00.386481 EDT | AverageAbsY                29.9528
2017-06-11 03:00:00.386676 EDT | AverageAbsQYDiff            0.526595
2017-06-11 03:00:00.386870 EDT | AverageAction               0.996517
2017-06-11 03:00:00.387161 EDT | PolicyRegParamNorm         95.7719
2017-06-11 03:00:00.387355 EDT | QFunRegParamNorm          124.161
2017-06-11 03:00:00.387547 EDT | -----------------------  -----------
2017-06-11 03:00:00.387952 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #967 | Training started
2017-06-11 03:00:18.161554 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #967 | Training finished
2017-06-11 03:00:18.161970 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #967 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 03:00:18.162300 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #967 | Collecting samples for evaluation
2017-06-11 03:00:33.276786 EDT | -----------------------  -----------
2017-06-11 03:00:33.278002 EDT | Epoch                     967
2017-06-11 03:00:33.278414 EDT | Iteration                 967
2017-06-11 03:00:33.278795 EDT | AverageReturn             867.628
2017-06-11 03:00:33.279226 EDT | StdReturn                 149.326
2017-06-11 03:00:33.279634 EDT | MaxReturn                1279.4
2017-06-11 03:00:33.279995 EDT | MinReturn                 634.04
2017-06-11 03:00:33.280419 EDT | AverageEsReturn           406.202
2017-06-11 03:00:33.280839 EDT | StdEsReturn               300.459
2017-06-11 03:00:33.281190 EDT | MaxEsReturn               928.662
2017-06-11 03:00:33.281615 EDT | MinEsReturn                 7.69038
2017-06-11 03:00:33.282060 EDT | AverageDiscountedReturn   224.107
2017-06-11 03:00:33.282412 EDT | AverageQLoss                2.74047
2017-06-11 03:00:33.282827 EDT | AveragePolicySurr         -30.1454
2017-06-11 03:00:33.283261 EDT | AverageQ                   29.8294
2017-06-11 03:00:33.283627 EDT | AverageAbsQ                29.856
2017-06-11 03:00:33.284179 EDT | AverageY                   29.8314
2017-06-11 03:00:33.284613 EDT | AverageAbsY                29.8461
2017-06-11 03:00:33.284968 EDT | AverageAbsQYDiff            0.571395
2017-06-11 03:00:33.285384 EDT | AverageAction               0.996805
2017-06-11 03:00:33.285831 EDT | PolicyRegParamNorm         95.8011
2017-06-11 03:00:33.286194 EDT | QFunRegParamNorm          124.251
2017-06-11 03:00:33.286600 EDT | -----------------------  -----------
2017-06-11 03:00:33.287205 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #968 | Training started
2017-06-11 03:00:51.966495 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #968 | Training finished
2017-06-11 03:00:51.967707 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #968 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 03:00:51.968256 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #968 | Collecting samples for evaluation
2017-06-11 03:01:06.274028 EDT | -----------------------  -----------
2017-06-11 03:01:06.287439 EDT | Epoch                     968
2017-06-11 03:01:06.288200 EDT | Iteration                 968
2017-06-11 03:01:06.288557 EDT | AverageReturn            1331.54
2017-06-11 03:01:06.288896 EDT | StdReturn                 288.068
2017-06-11 03:01:06.289262 EDT | MaxReturn                2285.32
2017-06-11 03:01:06.289681 EDT | MinReturn                 862.296
2017-06-11 03:01:06.290052 EDT | AverageEsReturn           370.988
2017-06-11 03:01:06.290388 EDT | StdEsReturn               226.959
2017-06-11 03:01:06.290742 EDT | MaxEsReturn               638.301
2017-06-11 03:01:06.291175 EDT | MinEsReturn                22.8293
2017-06-11 03:01:06.291593 EDT | AverageDiscountedReturn   241.212
2017-06-11 03:01:06.292007 EDT | AverageQLoss                2.53232
2017-06-11 03:01:06.292432 EDT | AveragePolicySurr         -30.2286
2017-06-11 03:01:06.292777 EDT | AverageQ                   29.9347
2017-06-11 03:01:06.293111 EDT | AverageAbsQ                29.9608
2017-06-11 03:01:06.293507 EDT | AverageY                   29.9348
2017-06-11 03:01:06.293851 EDT | AverageAbsY                29.9473
2017-06-11 03:01:06.294180 EDT | AverageAbsQYDiff            0.545888
2017-06-11 03:01:06.294564 EDT | AverageAction               0.997361
2017-06-11 03:01:06.294998 EDT | PolicyRegParamNorm         95.8367
2017-06-11 03:01:06.297603 EDT | QFunRegParamNorm          124.318
2017-06-11 03:01:06.297957 EDT | -----------------------  -----------
2017-06-11 03:01:06.298531 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #969 | Training started
2017-06-11 03:01:25.152129 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #969 | Training finished
2017-06-11 03:01:25.153103 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #969 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 03:01:25.153465 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #969 | Collecting samples for evaluation
2017-06-11 03:01:39.311983 EDT | -----------------------  -----------
2017-06-11 03:01:39.312795 EDT | Epoch                     969
2017-06-11 03:01:39.313002 EDT | Iteration                 969
2017-06-11 03:01:39.313166 EDT | AverageReturn            1165.18
2017-06-11 03:01:39.313323 EDT | StdReturn                 223.509
2017-06-11 03:01:39.313476 EDT | MaxReturn                1805.76
2017-06-11 03:01:39.313759 EDT | MinReturn                 726.307
2017-06-11 03:01:39.313999 EDT | AverageEsReturn           639.583
2017-06-11 03:01:39.314185 EDT | StdEsReturn               154.939
2017-06-11 03:01:39.314367 EDT | MaxEsReturn               959.001
2017-06-11 03:01:39.314727 EDT | MinEsReturn               479.785
2017-06-11 03:01:39.315068 EDT | AverageDiscountedReturn   246.936
2017-06-11 03:01:39.315623 EDT | AverageQLoss                2.09402
2017-06-11 03:01:39.316028 EDT | AveragePolicySurr         -30.1526
2017-06-11 03:01:39.316456 EDT | AverageQ                   29.8207
2017-06-11 03:01:39.316806 EDT | AverageAbsQ                29.8408
2017-06-11 03:01:39.317122 EDT | AverageY                   29.8227
2017-06-11 03:01:39.317432 EDT | AverageAbsY                29.8326
2017-06-11 03:01:39.317763 EDT | AverageAbsQYDiff            0.519721
2017-06-11 03:01:39.318081 EDT | AverageAction               0.996879
2017-06-11 03:01:39.318400 EDT | PolicyRegParamNorm         95.8436
2017-06-11 03:01:39.318815 EDT | QFunRegParamNorm          124.355
2017-06-11 03:01:39.319208 EDT | -----------------------  -----------
2017-06-11 03:01:39.319699 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #970 | Training started
2017-06-11 03:01:57.696665 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #970 | Training finished
2017-06-11 03:01:57.697945 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #970 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 03:01:57.698468 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #970 | Collecting samples for evaluation
2017-06-11 03:02:12.349152 EDT | -----------------------  ----------
2017-06-11 03:02:12.350042 EDT | Epoch                     970
2017-06-11 03:02:12.350471 EDT | Iteration                 970
2017-06-11 03:02:12.350867 EDT | AverageReturn            1071.59
2017-06-11 03:02:12.351210 EDT | StdReturn                 276.961
2017-06-11 03:02:12.351545 EDT | MaxReturn                1994.85
2017-06-11 03:02:12.351921 EDT | MinReturn                 670.51
2017-06-11 03:02:12.352250 EDT | AverageEsReturn           233.986
2017-06-11 03:02:12.352689 EDT | StdEsReturn               230.998
2017-06-11 03:02:12.353314 EDT | MaxEsReturn               731.56
2017-06-11 03:02:12.353891 EDT | MinEsReturn                17.8058
2017-06-11 03:02:12.354316 EDT | AverageDiscountedReturn   242.845
2017-06-11 03:02:12.354753 EDT | AverageQLoss                2.43721
2017-06-11 03:02:12.355242 EDT | AveragePolicySurr         -30.0944
2017-06-11 03:02:12.355664 EDT | AverageQ                   29.7795
2017-06-11 03:02:12.356230 EDT | AverageAbsQ                29.7998
2017-06-11 03:02:12.356665 EDT | AverageY                   29.7814
2017-06-11 03:02:12.357180 EDT | AverageAbsY                29.7908
2017-06-11 03:02:12.357562 EDT | AverageAbsQYDiff            0.54452
2017-06-11 03:02:12.357999 EDT | AverageAction               0.99754
2017-06-11 03:02:12.358634 EDT | PolicyRegParamNorm         95.8825
2017-06-11 03:02:12.359074 EDT | QFunRegParamNorm          124.385
2017-06-11 03:02:12.359575 EDT | -----------------------  ----------
2017-06-11 03:02:12.360170 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #971 | Training started
2017-06-11 03:02:29.515894 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #971 | Training finished
2017-06-11 03:02:29.516628 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #971 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 03:02:29.516927 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #971 | Collecting samples for evaluation
2017-06-11 03:02:44.536333 EDT | -----------------------  -----------
2017-06-11 03:02:44.537215 EDT | Epoch                     971
2017-06-11 03:02:44.537563 EDT | Iteration                 971
2017-06-11 03:02:44.537837 EDT | AverageReturn            2054.51
2017-06-11 03:02:44.538411 EDT | StdReturn                1038.29
2017-06-11 03:02:44.538728 EDT | MaxReturn                3467.81
2017-06-11 03:02:44.539159 EDT | MinReturn                 102.802
2017-06-11 03:02:44.539441 EDT | AverageEsReturn           367.027
2017-06-11 03:02:44.539705 EDT | StdEsReturn               181.872
2017-06-11 03:02:44.539869 EDT | MaxEsReturn               547.435
2017-06-11 03:02:44.542091 EDT | MinEsReturn                86.9891
2017-06-11 03:02:44.542442 EDT | AverageDiscountedReturn   236.529
2017-06-11 03:02:44.542715 EDT | AverageQLoss                2.06631
2017-06-11 03:02:44.543042 EDT | AveragePolicySurr         -30.168
2017-06-11 03:02:44.543726 EDT | AverageQ                   29.8527
2017-06-11 03:02:44.544007 EDT | AverageAbsQ                29.8722
2017-06-11 03:02:44.544328 EDT | AverageY                   29.8541
2017-06-11 03:02:44.544596 EDT | AverageAbsY                29.8629
2017-06-11 03:02:44.544767 EDT | AverageAbsQYDiff            0.512196
2017-06-11 03:02:44.545022 EDT | AverageAction               0.997003
2017-06-11 03:02:44.545260 EDT | PolicyRegParamNorm         95.8903
2017-06-11 03:02:44.545415 EDT | QFunRegParamNorm          124.426
2017-06-11 03:02:44.545566 EDT | -----------------------  -----------
2017-06-11 03:02:44.545900 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #972 | Training started
2017-06-11 03:03:02.857043 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #972 | Training finished
2017-06-11 03:03:02.858594 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #972 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 03:03:02.859144 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #972 | Collecting samples for evaluation
2017-06-11 03:03:18.227890 EDT | -----------------------  -----------
2017-06-11 03:03:18.228449 EDT | Epoch                     972
2017-06-11 03:03:18.228786 EDT | Iteration                 972
2017-06-11 03:03:18.229157 EDT | AverageReturn             211.193
2017-06-11 03:03:18.229531 EDT | StdReturn                 434.317
2017-06-11 03:03:18.229952 EDT | MaxReturn                2237.86
2017-06-11 03:03:18.230282 EDT | MinReturn                  66.605
2017-06-11 03:03:18.230648 EDT | AverageEsReturn           154.777
2017-06-11 03:03:18.231020 EDT | StdEsReturn               186.769
2017-06-11 03:03:18.231430 EDT | MaxEsReturn               680.268
2017-06-11 03:03:18.231772 EDT | MinEsReturn                18.9812
2017-06-11 03:03:18.232141 EDT | AverageDiscountedReturn    77.1099
2017-06-11 03:03:18.232511 EDT | AverageQLoss                1.90416
2017-06-11 03:03:18.232916 EDT | AveragePolicySurr         -30.1494
2017-06-11 03:03:18.233247 EDT | AverageQ                   29.8864
2017-06-11 03:03:18.233615 EDT | AverageAbsQ                29.9077
2017-06-11 03:03:18.234010 EDT | AverageY                   29.8884
2017-06-11 03:03:18.234422 EDT | AverageAbsY                29.898
2017-06-11 03:03:18.234761 EDT | AverageAbsQYDiff            0.519725
2017-06-11 03:03:18.235130 EDT | AverageAction               0.997819
2017-06-11 03:03:18.235501 EDT | PolicyRegParamNorm         95.9335
2017-06-11 03:03:18.235889 EDT | QFunRegParamNorm          124.482
2017-06-11 03:03:18.236242 EDT | -----------------------  -----------
2017-06-11 03:03:18.236784 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #973 | Training started
2017-06-11 03:03:35.482173 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #973 | Training finished
2017-06-11 03:03:35.483055 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #973 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 03:03:35.483262 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #973 | Collecting samples for evaluation
2017-06-11 03:03:49.218126 EDT | -----------------------  -----------
2017-06-11 03:03:49.218701 EDT | Epoch                     973
2017-06-11 03:03:49.219054 EDT | Iteration                 973
2017-06-11 03:03:49.219417 EDT | AverageReturn            1076.36
2017-06-11 03:03:49.219864 EDT | StdReturn                 543.607
2017-06-11 03:03:49.220776 EDT | MaxReturn                1941.49
2017-06-11 03:03:49.221151 EDT | MinReturn                  86.3243
2017-06-11 03:03:49.222147 EDT | AverageEsReturn           277.603
2017-06-11 03:03:49.222599 EDT | StdEsReturn               307.756
2017-06-11 03:03:49.223049 EDT | MaxEsReturn              1031.24
2017-06-11 03:03:49.223496 EDT | MinEsReturn                 9.53447
2017-06-11 03:03:49.224379 EDT | AverageDiscountedReturn   211.916
2017-06-11 03:03:49.224739 EDT | AverageQLoss                1.92277
2017-06-11 03:03:49.225088 EDT | AveragePolicySurr         -30.1837
2017-06-11 03:03:49.225436 EDT | AverageQ                   29.9021
2017-06-11 03:03:49.225790 EDT | AverageAbsQ                29.9192
2017-06-11 03:03:49.226232 EDT | AverageY                   29.9029
2017-06-11 03:03:49.227797 EDT | AverageAbsY                29.9106
2017-06-11 03:03:49.228270 EDT | AverageAbsQYDiff            0.517459
2017-06-11 03:03:49.230376 EDT | AverageAction               0.99681
2017-06-11 03:03:49.230805 EDT | PolicyRegParamNorm         96.0984
2017-06-11 03:03:49.231258 EDT | QFunRegParamNorm          124.503
2017-06-11 03:03:49.231686 EDT | -----------------------  -----------
2017-06-11 03:03:49.232227 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #974 | Training started
2017-06-11 03:04:07.314193 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #974 | Training finished
2017-06-11 03:04:07.317299 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #974 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 03:04:07.317737 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #974 | Collecting samples for evaluation
2017-06-11 03:04:21.412170 EDT | -----------------------  -----------
2017-06-11 03:04:21.413260 EDT | Epoch                     974
2017-06-11 03:04:21.413615 EDT | Iteration                 974
2017-06-11 03:04:21.413973 EDT | AverageReturn            2082.72
2017-06-11 03:04:21.414411 EDT | StdReturn                1014.45
2017-06-11 03:04:21.415158 EDT | MaxReturn                2961.99
2017-06-11 03:04:21.415589 EDT | MinReturn                  80.3696
2017-06-11 03:04:21.415923 EDT | AverageEsReturn           453.644
2017-06-11 03:04:21.416248 EDT | StdEsReturn               308.195
2017-06-11 03:04:21.416615 EDT | MaxEsReturn               857.553
2017-06-11 03:04:21.416950 EDT | MinEsReturn                85.8361
2017-06-11 03:04:21.417295 EDT | AverageDiscountedReturn   212.156
2017-06-11 03:04:21.417643 EDT | AverageQLoss                2.42825
2017-06-11 03:04:21.418895 EDT | AveragePolicySurr         -30.1476
2017-06-11 03:04:21.419462 EDT | AverageQ                   29.8438
2017-06-11 03:04:21.419799 EDT | AverageAbsQ                29.8655
2017-06-11 03:04:21.419991 EDT | AverageY                   29.8448
2017-06-11 03:04:21.420548 EDT | AverageAbsY                29.854
2017-06-11 03:04:21.421150 EDT | AverageAbsQYDiff            0.552766
2017-06-11 03:04:21.421486 EDT | AverageAction               0.996701
2017-06-11 03:04:21.423022 EDT | PolicyRegParamNorm         96.1354
2017-06-11 03:04:21.423350 EDT | QFunRegParamNorm          124.562
2017-06-11 03:04:21.423689 EDT | -----------------------  -----------
2017-06-11 03:04:21.424325 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #975 | Training started
2017-06-11 03:04:39.903959 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #975 | Training finished
2017-06-11 03:04:39.908681 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #975 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 03:04:39.908987 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #975 | Collecting samples for evaluation
2017-06-11 03:04:54.341708 EDT | -----------------------  -----------
2017-06-11 03:04:54.342810 EDT | Epoch                     975
2017-06-11 03:04:54.343164 EDT | Iteration                 975
2017-06-11 03:04:54.343505 EDT | AverageReturn            1987.27
2017-06-11 03:04:54.343862 EDT | StdReturn                 929.402
2017-06-11 03:04:54.344195 EDT | MaxReturn                3249.01
2017-06-11 03:04:54.344528 EDT | MinReturn                 713.095
2017-06-11 03:04:54.344878 EDT | AverageEsReturn           393.928
2017-06-11 03:04:54.345207 EDT | StdEsReturn               348.382
2017-06-11 03:04:54.345542 EDT | MaxEsReturn              1193.5
2017-06-11 03:04:54.345874 EDT | MinEsReturn                65.1867
2017-06-11 03:04:54.346205 EDT | AverageDiscountedReturn   232.253
2017-06-11 03:04:54.346539 EDT | AverageQLoss                1.89752
2017-06-11 03:04:54.346888 EDT | AveragePolicySurr         -30.1713
2017-06-11 03:04:54.347223 EDT | AverageQ                   29.863
2017-06-11 03:04:54.347552 EDT | AverageAbsQ                29.8846
2017-06-11 03:04:54.347943 EDT | AverageY                   29.8647
2017-06-11 03:04:54.348280 EDT | AverageAbsY                29.8739
2017-06-11 03:04:54.348604 EDT | AverageAbsQYDiff            0.508467
2017-06-11 03:04:54.348938 EDT | AverageAction               0.997104
2017-06-11 03:04:54.349273 EDT | PolicyRegParamNorm         96.1999
2017-06-11 03:04:54.349589 EDT | QFunRegParamNorm          124.62
2017-06-11 03:04:54.349936 EDT | -----------------------  -----------
2017-06-11 03:04:54.350389 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #976 | Training started
2017-06-11 03:05:11.924452 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #976 | Training finished
2017-06-11 03:05:11.924944 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #976 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 03:05:11.925354 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #976 | Collecting samples for evaluation
2017-06-11 03:05:26.630958 EDT | -----------------------  -----------
2017-06-11 03:05:26.632091 EDT | Epoch                     976
2017-06-11 03:05:26.632529 EDT | Iteration                 976
2017-06-11 03:05:26.632935 EDT | AverageReturn            1943.97
2017-06-11 03:05:26.633228 EDT | StdReturn                 786.275
2017-06-11 03:05:26.633560 EDT | MaxReturn                3382.98
2017-06-11 03:05:26.633921 EDT | MinReturn                 713.833
2017-06-11 03:05:26.634261 EDT | AverageEsReturn           447.357
2017-06-11 03:05:26.634588 EDT | StdEsReturn               409.258
2017-06-11 03:05:26.634871 EDT | MaxEsReturn              1227.98
2017-06-11 03:05:26.635207 EDT | MinEsReturn                53.9272
2017-06-11 03:05:26.635600 EDT | AverageDiscountedReturn   237.193
2017-06-11 03:05:26.635957 EDT | AverageQLoss                2.40816
2017-06-11 03:05:26.636391 EDT | AveragePolicySurr         -30.1021
2017-06-11 03:05:26.636809 EDT | AverageQ                   29.7887
2017-06-11 03:05:26.637221 EDT | AverageAbsQ                29.807
2017-06-11 03:05:26.637637 EDT | AverageY                   29.7899
2017-06-11 03:05:26.638060 EDT | AverageAbsY                29.7963
2017-06-11 03:05:26.638438 EDT | AverageAbsQYDiff            0.542908
2017-06-11 03:05:26.639274 EDT | AverageAction               0.996791
2017-06-11 03:05:26.639707 EDT | PolicyRegParamNorm         96.2076
2017-06-11 03:05:26.640133 EDT | QFunRegParamNorm          124.667
2017-06-11 03:05:26.641138 EDT | -----------------------  -----------
2017-06-11 03:05:26.642546 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #977 | Training started
2017-06-11 03:05:44.293825 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #977 | Training finished
2017-06-11 03:05:44.302409 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #977 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 03:05:44.303670 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #977 | Collecting samples for evaluation
2017-06-11 03:05:58.471345 EDT | -----------------------  -----------
2017-06-11 03:05:58.472037 EDT | Epoch                     977
2017-06-11 03:05:58.472501 EDT | Iteration                 977
2017-06-11 03:05:58.472949 EDT | AverageReturn             639.445
2017-06-11 03:05:58.473399 EDT | StdReturn                 323.311
2017-06-11 03:05:58.473854 EDT | MaxReturn                1847.82
2017-06-11 03:05:58.474303 EDT | MinReturn                 392.528
2017-06-11 03:05:58.474748 EDT | AverageEsReturn           362.252
2017-06-11 03:05:58.475189 EDT | StdEsReturn               219.642
2017-06-11 03:05:58.475637 EDT | MaxEsReturn               810.293
2017-06-11 03:05:58.476075 EDT | MinEsReturn               105.524
2017-06-11 03:05:58.476516 EDT | AverageDiscountedReturn   195.673
2017-06-11 03:05:58.476955 EDT | AverageQLoss                2.39302
2017-06-11 03:05:58.477395 EDT | AveragePolicySurr         -30.0267
2017-06-11 03:05:58.477852 EDT | AverageQ                   29.7208
2017-06-11 03:05:58.478291 EDT | AverageAbsQ                29.7392
2017-06-11 03:05:58.478728 EDT | AverageY                   29.7221
2017-06-11 03:05:58.479170 EDT | AverageAbsY                29.7285
2017-06-11 03:05:58.479609 EDT | AverageAbsQYDiff            0.544228
2017-06-11 03:05:58.480047 EDT | AverageAction               0.996796
2017-06-11 03:05:58.480489 EDT | PolicyRegParamNorm         96.2272
2017-06-11 03:05:58.480923 EDT | QFunRegParamNorm          124.712
2017-06-11 03:05:58.481357 EDT | -----------------------  -----------
2017-06-11 03:05:58.481984 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #978 | Training started
2017-06-11 03:06:16.174679 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #978 | Training finished
2017-06-11 03:06:16.175619 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #978 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 03:06:16.176031 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #978 | Collecting samples for evaluation
2017-06-11 03:06:28.947111 EDT | -----------------------  -----------
2017-06-11 03:06:28.948061 EDT | Epoch                     978
2017-06-11 03:06:28.948461 EDT | Iteration                 978
2017-06-11 03:06:28.948936 EDT | AverageReturn            1463.44
2017-06-11 03:06:28.949380 EDT | StdReturn                 494.111
2017-06-11 03:06:28.949857 EDT | MaxReturn                2665.51
2017-06-11 03:06:28.950244 EDT | MinReturn                 977.017
2017-06-11 03:06:28.950612 EDT | AverageEsReturn           201.782
2017-06-11 03:06:28.950982 EDT | StdEsReturn               147.649
2017-06-11 03:06:28.951338 EDT | MaxEsReturn               452.279
2017-06-11 03:06:28.951714 EDT | MinEsReturn                16.9108
2017-06-11 03:06:28.952092 EDT | AverageDiscountedReturn   258.849
2017-06-11 03:06:28.952457 EDT | AverageQLoss                2.15776
2017-06-11 03:06:28.952823 EDT | AveragePolicySurr         -30.0589
2017-06-11 03:06:28.953187 EDT | AverageQ                   29.7713
2017-06-11 03:06:28.953551 EDT | AverageAbsQ                29.7879
2017-06-11 03:06:28.953949 EDT | AverageY                   29.7727
2017-06-11 03:06:28.954393 EDT | AverageAbsY                29.7795
2017-06-11 03:06:28.954790 EDT | AverageAbsQYDiff            0.51933
2017-06-11 03:06:28.955157 EDT | AverageAction               0.997479
2017-06-11 03:06:28.955538 EDT | PolicyRegParamNorm         96.2386
2017-06-11 03:06:28.955905 EDT | QFunRegParamNorm          124.79
2017-06-11 03:06:28.956357 EDT | -----------------------  -----------
2017-06-11 03:06:28.956877 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #979 | Training started
2017-06-11 03:06:47.810553 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #979 | Training finished
2017-06-11 03:06:47.813152 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #979 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 03:06:47.813504 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #979 | Collecting samples for evaluation
2017-06-11 03:07:01.140695 EDT | -----------------------  -----------
2017-06-11 03:07:01.141821 EDT | Epoch                     979
2017-06-11 03:07:01.142160 EDT | Iteration                 979
2017-06-11 03:07:01.142430 EDT | AverageReturn            2252.09
2017-06-11 03:07:01.142688 EDT | StdReturn                 797.682
2017-06-11 03:07:01.143067 EDT | MaxReturn                3429.46
2017-06-11 03:07:01.143347 EDT | MinReturn                 844.997
2017-06-11 03:07:01.143769 EDT | AverageEsReturn           408.769
2017-06-11 03:07:01.144068 EDT | StdEsReturn               298.895
2017-06-11 03:07:01.144354 EDT | MaxEsReturn               718.947
2017-06-11 03:07:01.144620 EDT | MinEsReturn                18.2026
2017-06-11 03:07:01.144883 EDT | AverageDiscountedReturn   243.777
2017-06-11 03:07:01.145226 EDT | AverageQLoss                2.12068
2017-06-11 03:07:01.145572 EDT | AveragePolicySurr         -30.0397
2017-06-11 03:07:01.145873 EDT | AverageQ                   29.7448
2017-06-11 03:07:01.146137 EDT | AverageAbsQ                29.7591
2017-06-11 03:07:01.146390 EDT | AverageY                   29.7473
2017-06-11 03:07:01.146882 EDT | AverageAbsY                29.7506
2017-06-11 03:07:01.147201 EDT | AverageAbsQYDiff            0.520205
2017-06-11 03:07:01.147482 EDT | AverageAction               0.996349
2017-06-11 03:07:01.148810 EDT | PolicyRegParamNorm         96.2582
2017-06-11 03:07:01.149151 EDT | QFunRegParamNorm          124.831
2017-06-11 03:07:01.149430 EDT | -----------------------  -----------
2017-06-11 03:07:01.149851 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #980 | Training started
2017-06-11 03:07:18.637215 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #980 | Training finished
2017-06-11 03:07:18.638177 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #980 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 03:07:18.638515 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #980 | Collecting samples for evaluation
2017-06-11 03:07:35.267311 EDT | -----------------------  -----------
2017-06-11 03:07:35.268180 EDT | Epoch                     980
2017-06-11 03:07:35.268507 EDT | Iteration                 980
2017-06-11 03:07:35.268814 EDT | AverageReturn            1996.42
2017-06-11 03:07:35.269482 EDT | StdReturn                1035.21
2017-06-11 03:07:35.270745 EDT | MaxReturn                3115.96
2017-06-11 03:07:35.271973 EDT | MinReturn                 456.157
2017-06-11 03:07:35.273190 EDT | AverageEsReturn           540.336
2017-06-11 03:07:35.274405 EDT | StdEsReturn               192.827
2017-06-11 03:07:35.275633 EDT | MaxEsReturn               739.646
2017-06-11 03:07:35.276839 EDT | MinEsReturn               208.507
2017-06-11 03:07:35.278045 EDT | AverageDiscountedReturn   232.017
2017-06-11 03:07:35.279279 EDT | AverageQLoss                2.3415
2017-06-11 03:07:35.280482 EDT | AveragePolicySurr         -30.0012
2017-06-11 03:07:35.282038 EDT | AverageQ                   29.7253
2017-06-11 03:07:35.283622 EDT | AverageAbsQ                29.7438
2017-06-11 03:07:35.284870 EDT | AverageY                   29.7268
2017-06-11 03:07:35.286096 EDT | AverageAbsY                29.7314
2017-06-11 03:07:35.287351 EDT | AverageAbsQYDiff            0.536494
2017-06-11 03:07:35.288860 EDT | AverageAction               0.996542
2017-06-11 03:07:35.290163 EDT | PolicyRegParamNorm         96.3364
2017-06-11 03:07:35.291409 EDT | QFunRegParamNorm          124.951
2017-06-11 03:07:35.292625 EDT | -----------------------  -----------
2017-06-11 03:07:35.294013 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #981 | Training started
2017-06-11 03:07:52.626293 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #981 | Training finished
2017-06-11 03:07:52.627137 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #981 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 03:07:52.627527 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #981 | Collecting samples for evaluation
2017-06-11 03:08:07.651587 EDT | -----------------------  -----------
2017-06-11 03:08:07.653374 EDT | Epoch                     981
2017-06-11 03:08:07.653725 EDT | Iteration                 981
2017-06-11 03:08:07.654070 EDT | AverageReturn            1159.61
2017-06-11 03:08:07.654860 EDT | StdReturn                 597.884
2017-06-11 03:08:07.655329 EDT | MaxReturn                3098.75
2017-06-11 03:08:07.655825 EDT | MinReturn                 596.429
2017-06-11 03:08:07.656239 EDT | AverageEsReturn           477.552
2017-06-11 03:08:07.656674 EDT | StdEsReturn               424.719
2017-06-11 03:08:07.657367 EDT | MaxEsReturn              1146.42
2017-06-11 03:08:07.658243 EDT | MinEsReturn                17.235
2017-06-11 03:08:07.659349 EDT | AverageDiscountedReturn   225.766
2017-06-11 03:08:07.659732 EDT | AverageQLoss                2.11649
2017-06-11 03:08:07.660159 EDT | AveragePolicySurr         -29.9669
2017-06-11 03:08:07.660596 EDT | AverageQ                   29.6885
2017-06-11 03:08:07.661113 EDT | AverageAbsQ                29.7047
2017-06-11 03:08:07.661552 EDT | AverageY                   29.6887
2017-06-11 03:08:07.662143 EDT | AverageAbsY                29.6956
2017-06-11 03:08:07.662811 EDT | AverageAbsQYDiff            0.518353
2017-06-11 03:08:07.664112 EDT | AverageAction               0.996939
2017-06-11 03:08:07.664554 EDT | PolicyRegParamNorm         96.4044
2017-06-11 03:08:07.665103 EDT | QFunRegParamNorm          125.008
2017-06-11 03:08:07.665495 EDT | -----------------------  -----------
2017-06-11 03:08:07.666069 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #982 | Training started
2017-06-11 03:08:26.117457 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #982 | Training finished
2017-06-11 03:08:26.118454 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #982 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 03:08:26.118746 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #982 | Collecting samples for evaluation
2017-06-11 03:08:42.235181 EDT | -----------------------  -----------
2017-06-11 03:08:42.235511 EDT | Epoch                     982
2017-06-11 03:08:42.235779 EDT | Iteration                 982
2017-06-11 03:08:42.236060 EDT | AverageReturn            2265.5
2017-06-11 03:08:42.236307 EDT | StdReturn                 792.458
2017-06-11 03:08:42.236554 EDT | MaxReturn                3158.82
2017-06-11 03:08:42.236820 EDT | MinReturn                 977.658
2017-06-11 03:08:42.237074 EDT | AverageEsReturn           194.915
2017-06-11 03:08:42.237335 EDT | StdEsReturn               201.302
2017-06-11 03:08:42.237599 EDT | MaxEsReturn               661.595
2017-06-11 03:08:42.238650 EDT | MinEsReturn                13.7255
2017-06-11 03:08:42.239011 EDT | AverageDiscountedReturn   236.068
2017-06-11 03:08:42.239278 EDT | AverageQLoss                2.42758
2017-06-11 03:08:42.239558 EDT | AveragePolicySurr         -29.9941
2017-06-11 03:08:42.239819 EDT | AverageQ                   29.6855
2017-06-11 03:08:42.240065 EDT | AverageAbsQ                29.706
2017-06-11 03:08:42.240249 EDT | AverageY                   29.6858
2017-06-11 03:08:42.240480 EDT | AverageAbsY                29.6956
2017-06-11 03:08:42.240669 EDT | AverageAbsQYDiff            0.533252
2017-06-11 03:08:42.240938 EDT | AverageAction               0.997432
2017-06-11 03:08:42.241119 EDT | PolicyRegParamNorm         96.4173
2017-06-11 03:08:42.241300 EDT | QFunRegParamNorm          125.012
2017-06-11 03:08:42.241534 EDT | -----------------------  -----------
2017-06-11 03:08:42.241863 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #983 | Training started
2017-06-11 03:09:01.221636 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #983 | Training finished
2017-06-11 03:09:01.237814 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #983 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 03:09:01.238223 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #983 | Collecting samples for evaluation
2017-06-11 03:09:15.591981 EDT | -----------------------  -----------
2017-06-11 03:09:15.592855 EDT | Epoch                     983
2017-06-11 03:09:15.593167 EDT | Iteration                 983
2017-06-11 03:09:15.593469 EDT | AverageReturn            2283.37
2017-06-11 03:09:15.593783 EDT | StdReturn                 758.128
2017-06-11 03:09:15.594079 EDT | MaxReturn                3379.7
2017-06-11 03:09:15.594373 EDT | MinReturn                1130.78
2017-06-11 03:09:15.594648 EDT | AverageEsReturn           272.287
2017-06-11 03:09:15.594939 EDT | StdEsReturn               252.343
2017-06-11 03:09:15.595222 EDT | MaxEsReturn               894.296
2017-06-11 03:09:15.595509 EDT | MinEsReturn                 8.39143
2017-06-11 03:09:15.595799 EDT | AverageDiscountedReturn   247.613
2017-06-11 03:09:15.596071 EDT | AverageQLoss                2.31345
2017-06-11 03:09:15.596352 EDT | AveragePolicySurr         -30.0036
2017-06-11 03:09:15.596646 EDT | AverageQ                   29.6956
2017-06-11 03:09:15.596940 EDT | AverageAbsQ                29.7143
2017-06-11 03:09:15.597235 EDT | AverageY                   29.6971
2017-06-11 03:09:15.597524 EDT | AverageAbsY                29.7046
2017-06-11 03:09:15.597825 EDT | AverageAbsQYDiff            0.546934
2017-06-11 03:09:15.598115 EDT | AverageAction               0.997682
2017-06-11 03:09:15.598406 EDT | PolicyRegParamNorm         96.4123
2017-06-11 03:09:15.598676 EDT | QFunRegParamNorm          125.081
2017-06-11 03:09:15.598968 EDT | -----------------------  -----------
2017-06-11 03:09:15.599410 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #984 | Training started
2017-06-11 03:09:34.765633 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #984 | Training finished
2017-06-11 03:09:34.766649 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #984 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 03:09:34.767033 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #984 | Collecting samples for evaluation
2017-06-11 03:09:49.472312 EDT | -----------------------  -----------
2017-06-11 03:09:49.473279 EDT | Epoch                     984
2017-06-11 03:09:49.473649 EDT | Iteration                 984
2017-06-11 03:09:49.474009 EDT | AverageReturn             661.373
2017-06-11 03:09:49.474348 EDT | StdReturn                1045.08
2017-06-11 03:09:49.474683 EDT | MaxReturn                2960.95
2017-06-11 03:09:49.475017 EDT | MinReturn                  19.2009
2017-06-11 03:09:49.475350 EDT | AverageEsReturn           244.449
2017-06-11 03:09:49.475682 EDT | StdEsReturn               206.361
2017-06-11 03:09:49.476011 EDT | MaxEsReturn               597.78
2017-06-11 03:09:49.476339 EDT | MinEsReturn                12.2908
2017-06-11 03:09:49.476669 EDT | AverageDiscountedReturn    85.5403
2017-06-11 03:09:49.477000 EDT | AverageQLoss                1.91804
2017-06-11 03:09:49.477327 EDT | AveragePolicySurr         -29.9601
2017-06-11 03:09:49.477655 EDT | AverageQ                   29.6913
2017-06-11 03:09:49.477994 EDT | AverageAbsQ                29.7091
2017-06-11 03:09:49.478321 EDT | AverageY                   29.6921
2017-06-11 03:09:49.478648 EDT | AverageAbsY                29.7034
2017-06-11 03:09:49.478976 EDT | AverageAbsQYDiff            0.513171
2017-06-11 03:09:49.479304 EDT | AverageAction               0.9973
2017-06-11 03:09:49.479631 EDT | PolicyRegParamNorm         96.4471
2017-06-11 03:09:49.479957 EDT | QFunRegParamNorm          125.071
2017-06-11 03:09:49.480284 EDT | -----------------------  -----------
2017-06-11 03:09:49.480760 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #985 | Training started
2017-06-11 03:10:06.103629 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #985 | Training finished
2017-06-11 03:10:06.104991 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #985 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 03:10:06.107304 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #985 | Collecting samples for evaluation
2017-06-11 03:10:20.981530 EDT | -----------------------  -----------
2017-06-11 03:10:20.984175 EDT | Epoch                     985
2017-06-11 03:10:20.984733 EDT | Iteration                 985
2017-06-11 03:10:20.985214 EDT | AverageReturn            1794.35
2017-06-11 03:10:20.985709 EDT | StdReturn                1154.15
2017-06-11 03:10:20.986194 EDT | MaxReturn                2966.99
2017-06-11 03:10:20.986672 EDT | MinReturn                 197.349
2017-06-11 03:10:20.987154 EDT | AverageEsReturn           256.623
2017-06-11 03:10:20.987634 EDT | StdEsReturn               340.442
2017-06-11 03:10:20.988107 EDT | MaxEsReturn              1197.41
2017-06-11 03:10:20.988586 EDT | MinEsReturn                 9.26914
2017-06-11 03:10:20.989061 EDT | AverageDiscountedReturn   204.366
2017-06-11 03:10:20.989535 EDT | AverageQLoss                2.2158
2017-06-11 03:10:20.989992 EDT | AveragePolicySurr         -29.9715
2017-06-11 03:10:20.990464 EDT | AverageQ                   29.6782
2017-06-11 03:10:20.990939 EDT | AverageAbsQ                29.6973
2017-06-11 03:10:20.991417 EDT | AverageY                   29.68
2017-06-11 03:10:20.991899 EDT | AverageAbsY                29.6891
2017-06-11 03:10:20.992372 EDT | AverageAbsQYDiff            0.537315
2017-06-11 03:10:20.992845 EDT | AverageAction               0.997619
2017-06-11 03:10:20.993324 EDT | PolicyRegParamNorm         96.4597
2017-06-11 03:10:20.993818 EDT | QFunRegParamNorm          125.104
2017-06-11 03:10:20.994289 EDT | -----------------------  -----------
2017-06-11 03:10:20.994934 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #986 | Training started
2017-06-11 03:10:38.208230 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #986 | Training finished
2017-06-11 03:10:38.209347 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #986 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 03:10:38.209743 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #986 | Collecting samples for evaluation
2017-06-11 03:10:53.662435 EDT | -----------------------  -----------
2017-06-11 03:10:53.662706 EDT | Epoch                     986
2017-06-11 03:10:53.662881 EDT | Iteration                 986
2017-06-11 03:10:53.663049 EDT | AverageReturn            1569.8
2017-06-11 03:10:53.663212 EDT | StdReturn                 647.126
2017-06-11 03:10:53.663377 EDT | MaxReturn                2833.6
2017-06-11 03:10:53.663540 EDT | MinReturn                 630.444
2017-06-11 03:10:53.663702 EDT | AverageEsReturn           236.343
2017-06-11 03:10:53.663863 EDT | StdEsReturn               175.744
2017-06-11 03:10:53.664023 EDT | MaxEsReturn               613.567
2017-06-11 03:10:53.664191 EDT | MinEsReturn                11.0585
2017-06-11 03:10:53.664362 EDT | AverageDiscountedReturn   229.67
2017-06-11 03:10:53.664566 EDT | AverageQLoss                2.33893
2017-06-11 03:10:53.664737 EDT | AveragePolicySurr         -30.0191
2017-06-11 03:10:53.664913 EDT | AverageQ                   29.703
2017-06-11 03:10:53.665149 EDT | AverageAbsQ                29.7218
2017-06-11 03:10:53.665354 EDT | AverageY                   29.7056
2017-06-11 03:10:53.665542 EDT | AverageAbsY                29.7123
2017-06-11 03:10:53.665730 EDT | AverageAbsQYDiff            0.543582
2017-06-11 03:10:53.665929 EDT | AverageAction               0.997405
2017-06-11 03:10:53.666123 EDT | PolicyRegParamNorm         96.5749
2017-06-11 03:10:53.666316 EDT | QFunRegParamNorm          125.176
2017-06-11 03:10:53.666507 EDT | -----------------------  -----------
2017-06-11 03:10:53.666818 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #987 | Training started
2017-06-11 03:11:11.379606 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #987 | Training finished
2017-06-11 03:11:11.380454 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #987 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 03:11:11.380836 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #987 | Collecting samples for evaluation
2017-06-11 03:11:26.965612 EDT | -----------------------  -----------
2017-06-11 03:11:26.966523 EDT | Epoch                     987
2017-06-11 03:11:26.966917 EDT | Iteration                 987
2017-06-11 03:11:26.967282 EDT | AverageReturn            2545.06
2017-06-11 03:11:26.967643 EDT | StdReturn                 507.748
2017-06-11 03:11:26.967966 EDT | MaxReturn                2829.07
2017-06-11 03:11:26.968312 EDT | MinReturn                 913.946
2017-06-11 03:11:26.968494 EDT | AverageEsReturn           334.527
2017-06-11 03:11:26.968871 EDT | StdEsReturn               311.153
2017-06-11 03:11:26.972228 EDT | MaxEsReturn               939.227
2017-06-11 03:11:26.974771 EDT | MinEsReturn                10.2176
2017-06-11 03:11:26.975097 EDT | AverageDiscountedReturn   230.466
2017-06-11 03:11:26.975469 EDT | AverageQLoss                2.29406
2017-06-11 03:11:26.975847 EDT | AveragePolicySurr         -29.9875
2017-06-11 03:11:26.976182 EDT | AverageQ                   29.6549
2017-06-11 03:11:26.976580 EDT | AverageAbsQ                29.6768
2017-06-11 03:11:26.976908 EDT | AverageY                   29.6552
2017-06-11 03:11:26.977228 EDT | AverageAbsY                29.668
2017-06-11 03:11:26.977551 EDT | AverageAbsQYDiff            0.539097
2017-06-11 03:11:26.977916 EDT | AverageAction               0.997321
2017-06-11 03:11:26.978178 EDT | PolicyRegParamNorm         96.6402
2017-06-11 03:11:26.978334 EDT | QFunRegParamNorm          125.242
2017-06-11 03:11:26.978488 EDT | -----------------------  -----------
2017-06-11 03:11:26.978764 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #988 | Training started
2017-06-11 03:11:44.938188 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #988 | Training finished
2017-06-11 03:11:44.946122 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #988 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 03:11:44.946565 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #988 | Collecting samples for evaluation
2017-06-11 03:11:58.582526 EDT | -----------------------  -----------
2017-06-11 03:11:58.583336 EDT | Epoch                     988
2017-06-11 03:11:58.583619 EDT | Iteration                 988
2017-06-11 03:11:58.583872 EDT | AverageReturn            2765.07
2017-06-11 03:11:58.584119 EDT | StdReturn                 330.45
2017-06-11 03:11:58.584377 EDT | MaxReturn                2934.91
2017-06-11 03:11:58.584618 EDT | MinReturn                1789.44
2017-06-11 03:11:58.584861 EDT | AverageEsReturn           592.865
2017-06-11 03:11:58.585103 EDT | StdEsReturn               360.639
2017-06-11 03:11:58.585342 EDT | MaxEsReturn              1098.46
2017-06-11 03:11:58.585582 EDT | MinEsReturn               223.11
2017-06-11 03:11:58.585836 EDT | AverageDiscountedReturn   237.484
2017-06-11 03:11:58.586078 EDT | AverageQLoss                2.21045
2017-06-11 03:11:58.586319 EDT | AveragePolicySurr         -30.0643
2017-06-11 03:11:58.586560 EDT | AverageQ                   29.716
2017-06-11 03:11:58.586800 EDT | AverageAbsQ                29.7343
2017-06-11 03:11:58.587039 EDT | AverageY                   29.7185
2017-06-11 03:11:58.587280 EDT | AverageAbsY                29.7266
2017-06-11 03:11:58.587519 EDT | AverageAbsQYDiff            0.524466
2017-06-11 03:11:58.587758 EDT | AverageAction               0.997202
2017-06-11 03:11:58.587996 EDT | PolicyRegParamNorm         96.6824
2017-06-11 03:11:58.588236 EDT | QFunRegParamNorm          125.311
2017-06-11 03:11:58.588475 EDT | -----------------------  -----------
2017-06-11 03:11:58.588854 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #989 | Training started
2017-06-11 03:12:16.216339 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #989 | Training finished
2017-06-11 03:12:16.217403 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #989 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 03:12:16.217937 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #989 | Collecting samples for evaluation
2017-06-11 03:12:31.112357 EDT | -----------------------  -----------
2017-06-11 03:12:31.113366 EDT | Epoch                     989
2017-06-11 03:12:31.113812 EDT | Iteration                 989
2017-06-11 03:12:31.114220 EDT | AverageReturn            2326.28
2017-06-11 03:12:31.114659 EDT | StdReturn                 575.817
2017-06-11 03:12:31.115055 EDT | MaxReturn                2887.77
2017-06-11 03:12:31.115440 EDT | MinReturn                1349.97
2017-06-11 03:12:31.115871 EDT | AverageEsReturn           498.13
2017-06-11 03:12:31.116359 EDT | StdEsReturn               213.3
2017-06-11 03:12:31.116789 EDT | MaxEsReturn               900.051
2017-06-11 03:12:31.117287 EDT | MinEsReturn               213.007
2017-06-11 03:12:31.117708 EDT | AverageDiscountedReturn   229.251
2017-06-11 03:12:31.118146 EDT | AverageQLoss                1.88547
2017-06-11 03:12:31.118793 EDT | AveragePolicySurr         -30.0937
2017-06-11 03:12:31.119337 EDT | AverageQ                   29.7684
2017-06-11 03:12:31.119771 EDT | AverageAbsQ                29.7924
2017-06-11 03:12:31.120401 EDT | AverageY                   29.7698
2017-06-11 03:12:31.120923 EDT | AverageAbsY                29.7813
2017-06-11 03:12:31.121361 EDT | AverageAbsQYDiff            0.50696
2017-06-11 03:12:31.121868 EDT | AverageAction               0.997188
2017-06-11 03:12:31.122249 EDT | PolicyRegParamNorm         96.7623
2017-06-11 03:12:31.122676 EDT | QFunRegParamNorm          125.386
2017-06-11 03:12:31.123154 EDT | -----------------------  -----------
2017-06-11 03:12:31.123753 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #990 | Training started
2017-06-11 03:12:48.514471 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #990 | Training finished
2017-06-11 03:12:48.515240 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #990 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 03:12:48.515437 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #990 | Collecting samples for evaluation
2017-06-11 03:13:01.892665 EDT | -----------------------  -----------
2017-06-11 03:13:01.893872 EDT | Epoch                     990
2017-06-11 03:13:01.894320 EDT | Iteration                 990
2017-06-11 03:13:01.894675 EDT | AverageReturn            1121.33
2017-06-11 03:13:01.895023 EDT | StdReturn                 362.155
2017-06-11 03:13:01.895369 EDT | MaxReturn                2268.62
2017-06-11 03:13:01.895712 EDT | MinReturn                 650.729
2017-06-11 03:13:01.896057 EDT | AverageEsReturn           608.005
2017-06-11 03:13:01.896404 EDT | StdEsReturn               419.629
2017-06-11 03:13:01.896746 EDT | MaxEsReturn              1159.32
2017-06-11 03:13:01.897085 EDT | MinEsReturn                56.3095
2017-06-11 03:13:01.897447 EDT | AverageDiscountedReturn   228.278
2017-06-11 03:13:01.897799 EDT | AverageQLoss                2.06456
2017-06-11 03:13:01.898140 EDT | AveragePolicySurr         -30.109
2017-06-11 03:13:01.898480 EDT | AverageQ                   29.7779
2017-06-11 03:13:01.899229 EDT | AverageAbsQ                29.8028
2017-06-11 03:13:01.899683 EDT | AverageY                   29.7776
2017-06-11 03:13:01.900129 EDT | AverageAbsY                29.7923
2017-06-11 03:13:01.900571 EDT | AverageAbsQYDiff            0.522237
2017-06-11 03:13:01.901016 EDT | AverageAction               0.997658
2017-06-11 03:13:01.901458 EDT | PolicyRegParamNorm         96.7976
2017-06-11 03:13:01.901911 EDT | QFunRegParamNorm          125.438
2017-06-11 03:13:01.902352 EDT | -----------------------  -----------
2017-06-11 03:13:01.902972 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #991 | Training started
2017-06-11 03:13:19.439360 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #991 | Training finished
2017-06-11 03:13:19.440591 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #991 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 03:13:19.441059 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #991 | Collecting samples for evaluation
2017-06-11 03:13:33.265325 EDT | -----------------------  -----------
2017-06-11 03:13:33.266040 EDT | Epoch                     991
2017-06-11 03:13:33.266219 EDT | Iteration                 991
2017-06-11 03:13:33.266383 EDT | AverageReturn            1036.09
2017-06-11 03:13:33.266539 EDT | StdReturn                 176.979
2017-06-11 03:13:33.266739 EDT | MaxReturn                1531.7
2017-06-11 03:13:33.266892 EDT | MinReturn                 769.365
2017-06-11 03:13:33.267050 EDT | AverageEsReturn           490.854
2017-06-11 03:13:33.267210 EDT | StdEsReturn               211.806
2017-06-11 03:13:33.267379 EDT | MaxEsReturn               801.148
2017-06-11 03:13:33.267610 EDT | MinEsReturn               169.516
2017-06-11 03:13:33.267971 EDT | AverageDiscountedReturn   226.439
2017-06-11 03:13:33.268422 EDT | AverageQLoss                2.22571
2017-06-11 03:13:33.268758 EDT | AveragePolicySurr         -30.023
2017-06-11 03:13:33.269079 EDT | AverageQ                   29.6832
2017-06-11 03:13:33.270275 EDT | AverageAbsQ                29.705
2017-06-11 03:13:33.270560 EDT | AverageY                   29.6848
2017-06-11 03:13:33.270928 EDT | AverageAbsY                29.6955
2017-06-11 03:13:33.271275 EDT | AverageAbsQYDiff            0.526318
2017-06-11 03:13:33.271464 EDT | AverageAction               0.997758
2017-06-11 03:13:33.271987 EDT | PolicyRegParamNorm         96.7988
2017-06-11 03:13:33.272307 EDT | QFunRegParamNorm          125.474
2017-06-11 03:13:33.272563 EDT | -----------------------  -----------
2017-06-11 03:13:33.272869 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #992 | Training started
2017-06-11 03:13:51.867592 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #992 | Training finished
2017-06-11 03:13:51.868565 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #992 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 03:13:51.868770 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #992 | Collecting samples for evaluation
2017-06-11 03:14:04.597455 EDT | -----------------------  -----------
2017-06-11 03:14:04.598379 EDT | Epoch                     992
2017-06-11 03:14:04.598749 EDT | Iteration                 992
2017-06-11 03:14:04.599099 EDT | AverageReturn             163.541
2017-06-11 03:14:04.599444 EDT | StdReturn                 108.519
2017-06-11 03:14:04.599785 EDT | MaxReturn                1088.66
2017-06-11 03:14:04.600130 EDT | MinReturn                 136.393
2017-06-11 03:14:04.600475 EDT | AverageEsReturn           653.537
2017-06-11 03:14:04.600821 EDT | StdEsReturn               146.004
2017-06-11 03:14:04.601164 EDT | MaxEsReturn               776.685
2017-06-11 03:14:04.601505 EDT | MinEsReturn               375.394
2017-06-11 03:14:04.601860 EDT | AverageDiscountedReturn   102.671
2017-06-11 03:14:04.602202 EDT | AverageQLoss                2.72368
2017-06-11 03:14:04.602545 EDT | AveragePolicySurr         -30.0826
2017-06-11 03:14:04.602888 EDT | AverageQ                   29.789
2017-06-11 03:14:04.603226 EDT | AverageAbsQ                29.8097
2017-06-11 03:14:04.603568 EDT | AverageY                   29.7896
2017-06-11 03:14:04.603910 EDT | AverageAbsY                29.8
2017-06-11 03:14:04.604259 EDT | AverageAbsQYDiff            0.547455
2017-06-11 03:14:04.604604 EDT | AverageAction               0.995956
2017-06-11 03:14:04.604944 EDT | PolicyRegParamNorm         96.7863
2017-06-11 03:14:04.605283 EDT | QFunRegParamNorm          125.559
2017-06-11 03:14:04.605625 EDT | -----------------------  -----------
2017-06-11 03:14:04.606112 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #993 | Training started
2017-06-11 03:14:21.906875 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #993 | Training finished
2017-06-11 03:14:21.908655 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #993 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 03:14:21.909032 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #993 | Collecting samples for evaluation
2017-06-11 03:14:36.451536 EDT | -----------------------  -----------
2017-06-11 03:14:36.452380 EDT | Epoch                     993
2017-06-11 03:14:36.452680 EDT | Iteration                 993
2017-06-11 03:14:36.452947 EDT | AverageReturn             650.351
2017-06-11 03:14:36.453206 EDT | StdReturn                 584.691
2017-06-11 03:14:36.453462 EDT | MaxReturn                2523.06
2017-06-11 03:14:36.453734 EDT | MinReturn                 141.958
2017-06-11 03:14:36.453998 EDT | AverageEsReturn           349.439
2017-06-11 03:14:36.454254 EDT | StdEsReturn               207.527
2017-06-11 03:14:36.454506 EDT | MaxEsReturn               683.39
2017-06-11 03:14:36.454758 EDT | MinEsReturn               143.958
2017-06-11 03:14:36.455016 EDT | AverageDiscountedReturn   163.866
2017-06-11 03:14:36.455278 EDT | AverageQLoss                2.30445
2017-06-11 03:14:36.455528 EDT | AveragePolicySurr         -30.0101
2017-06-11 03:14:36.455794 EDT | AverageQ                   29.7052
2017-06-11 03:14:36.456053 EDT | AverageAbsQ                29.7216
2017-06-11 03:14:36.456303 EDT | AverageY                   29.7069
2017-06-11 03:14:36.456553 EDT | AverageAbsY                29.7136
2017-06-11 03:14:36.456802 EDT | AverageAbsQYDiff            0.514327
2017-06-11 03:14:36.457056 EDT | AverageAction               0.997207
2017-06-11 03:14:36.457340 EDT | PolicyRegParamNorm         96.8776
2017-06-11 03:14:36.457594 EDT | QFunRegParamNorm          125.599
2017-06-11 03:14:36.457855 EDT | -----------------------  -----------
2017-06-11 03:14:36.458260 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #994 | Training started
2017-06-11 03:14:52.976382 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #994 | Training finished
2017-06-11 03:14:52.977405 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #994 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 03:14:52.977801 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #994 | Collecting samples for evaluation
2017-06-11 03:15:07.619659 EDT | -----------------------  -----------
2017-06-11 03:15:07.620414 EDT | Epoch                     994
2017-06-11 03:15:07.620619 EDT | Iteration                 994
2017-06-11 03:15:07.620817 EDT | AverageReturn            1070.99
2017-06-11 03:15:07.621092 EDT | StdReturn                 253.403
2017-06-11 03:15:07.621285 EDT | MaxReturn                1630.42
2017-06-11 03:15:07.621556 EDT | MinReturn                 583.08
2017-06-11 03:15:07.621980 EDT | AverageEsReturn           120.323
2017-06-11 03:15:07.622165 EDT | StdEsReturn               159.663
2017-06-11 03:15:07.624281 EDT | MaxEsReturn               597.084
2017-06-11 03:15:07.625979 EDT | MinEsReturn                 5.52152
2017-06-11 03:15:07.626266 EDT | AverageDiscountedReturn   225.682
2017-06-11 03:15:07.626573 EDT | AverageQLoss                2.03425
2017-06-11 03:15:07.626887 EDT | AveragePolicySurr         -30.0899
2017-06-11 03:15:07.627260 EDT | AverageQ                   29.7942
2017-06-11 03:15:07.627520 EDT | AverageAbsQ                29.8116
2017-06-11 03:15:07.627834 EDT | AverageY                   29.7951
2017-06-11 03:15:07.628110 EDT | AverageAbsY                29.8021
2017-06-11 03:15:07.628367 EDT | AverageAbsQYDiff            0.513586
2017-06-11 03:15:07.628648 EDT | AverageAction               0.99775
2017-06-11 03:15:07.628907 EDT | PolicyRegParamNorm         96.9164
2017-06-11 03:15:07.629129 EDT | QFunRegParamNorm          125.678
2017-06-11 03:15:07.629311 EDT | -----------------------  -----------
2017-06-11 03:15:07.629607 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #995 | Training started
2017-06-11 03:15:25.050972 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #995 | Training finished
2017-06-11 03:15:25.051509 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #995 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 03:15:25.051878 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #995 | Collecting samples for evaluation
2017-06-11 03:15:38.480813 EDT | -----------------------  -----------
2017-06-11 03:15:38.482296 EDT | Epoch                     995
2017-06-11 03:15:38.482666 EDT | Iteration                 995
2017-06-11 03:15:38.483009 EDT | AverageReturn            1549.27
2017-06-11 03:15:38.483339 EDT | StdReturn                1114.59
2017-06-11 03:15:38.483780 EDT | MaxReturn                3022.43
2017-06-11 03:15:38.484092 EDT | MinReturn                  12.7669
2017-06-11 03:15:38.484419 EDT | AverageEsReturn           350.779
2017-06-11 03:15:38.485012 EDT | StdEsReturn               295.633
2017-06-11 03:15:38.485333 EDT | MaxEsReturn               859.48
2017-06-11 03:15:38.485651 EDT | MinEsReturn                10.8405
2017-06-11 03:15:38.485988 EDT | AverageDiscountedReturn   186.015
2017-06-11 03:15:38.487199 EDT | AverageQLoss                2.26931
2017-06-11 03:15:38.487464 EDT | AveragePolicySurr         -30.0101
2017-06-11 03:15:38.487738 EDT | AverageQ                   29.7126
2017-06-11 03:15:38.488069 EDT | AverageAbsQ                29.7307
2017-06-11 03:15:38.488706 EDT | AverageY                   29.7131
2017-06-11 03:15:38.489038 EDT | AverageAbsY                29.7215
2017-06-11 03:15:38.491918 EDT | AverageAbsQYDiff            0.522466
2017-06-11 03:15:38.492104 EDT | AverageAction               0.997774
2017-06-11 03:15:38.492631 EDT | PolicyRegParamNorm         96.9934
2017-06-11 03:15:38.492917 EDT | QFunRegParamNorm          125.719
2017-06-11 03:15:38.493322 EDT | -----------------------  -----------
2017-06-11 03:15:38.493889 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #996 | Training started
2017-06-11 03:15:56.018293 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #996 | Training finished
2017-06-11 03:15:56.018742 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #996 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 03:15:56.019138 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #996 | Collecting samples for evaluation
2017-06-11 03:16:09.987413 EDT | -----------------------  -----------
2017-06-11 03:16:09.988233 EDT | Epoch                     996
2017-06-11 03:16:09.988420 EDT | Iteration                 996
2017-06-11 03:16:09.988619 EDT | AverageReturn            1413.18
2017-06-11 03:16:09.988803 EDT | StdReturn                 534.641
2017-06-11 03:16:09.988986 EDT | MaxReturn                3036.94
2017-06-11 03:16:09.989167 EDT | MinReturn                 671.28
2017-06-11 03:16:09.989347 EDT | AverageEsReturn           553.783
2017-06-11 03:16:09.989528 EDT | StdEsReturn               437.194
2017-06-11 03:16:09.989734 EDT | MaxEsReturn              1206.53
2017-06-11 03:16:09.989917 EDT | MinEsReturn                14.7414
2017-06-11 03:16:09.990098 EDT | AverageDiscountedReturn   248.741
2017-06-11 03:16:09.990277 EDT | AverageQLoss                2.27359
2017-06-11 03:16:09.990456 EDT | AveragePolicySurr         -29.8665
2017-06-11 03:16:09.990635 EDT | AverageQ                   29.5492
2017-06-11 03:16:09.990823 EDT | AverageAbsQ                29.5692
2017-06-11 03:16:09.991002 EDT | AverageY                   29.551
2017-06-11 03:16:09.991181 EDT | AverageAbsY                29.5592
2017-06-11 03:16:09.991359 EDT | AverageAbsQYDiff            0.530367
2017-06-11 03:16:09.991537 EDT | AverageAction               0.998049
2017-06-11 03:16:09.991716 EDT | PolicyRegParamNorm         96.9747
2017-06-11 03:16:09.991903 EDT | QFunRegParamNorm          125.724
2017-06-11 03:16:09.992081 EDT | -----------------------  -----------
2017-06-11 03:16:09.992375 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #997 | Training started
2017-06-11 03:16:27.908364 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #997 | Training finished
2017-06-11 03:16:27.909090 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #997 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 03:16:27.909306 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #997 | Collecting samples for evaluation
2017-06-11 03:16:42.807247 EDT | -----------------------  -----------
2017-06-11 03:16:42.808328 EDT | Epoch                     997
2017-06-11 03:16:42.808821 EDT | Iteration                 997
2017-06-11 03:16:42.809132 EDT | AverageReturn            2072.35
2017-06-11 03:16:42.809557 EDT | StdReturn                 899.224
2017-06-11 03:16:42.810013 EDT | MaxReturn                3250.81
2017-06-11 03:16:42.810474 EDT | MinReturn                 856.22
2017-06-11 03:16:42.810900 EDT | AverageEsReturn           300.959
2017-06-11 03:16:42.812773 EDT | StdEsReturn               170.836
2017-06-11 03:16:42.813436 EDT | MaxEsReturn               601.519
2017-06-11 03:16:42.815302 EDT | MinEsReturn                29.3362
2017-06-11 03:16:42.815838 EDT | AverageDiscountedReturn   248.406
2017-06-11 03:16:42.816279 EDT | AverageQLoss                2.20214
2017-06-11 03:16:42.816972 EDT | AveragePolicySurr         -30.0442
2017-06-11 03:16:42.817489 EDT | AverageQ                   29.7539
2017-06-11 03:16:42.817905 EDT | AverageAbsQ                29.7677
2017-06-11 03:16:42.818338 EDT | AverageY                   29.7529
2017-06-11 03:16:42.818952 EDT | AverageAbsY                29.7577
2017-06-11 03:16:42.819397 EDT | AverageAbsQYDiff            0.529085
2017-06-11 03:16:42.819897 EDT | AverageAction               0.998232
2017-06-11 03:16:42.820330 EDT | PolicyRegParamNorm         97.0034
2017-06-11 03:16:42.820759 EDT | QFunRegParamNorm          125.758
2017-06-11 03:16:42.821126 EDT | -----------------------  -----------
2017-06-11 03:16:42.821671 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #998 | Training started
2017-06-11 03:17:01.044103 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #998 | Training finished
2017-06-11 03:17:01.045625 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #998 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 03:17:01.046122 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #998 | Collecting samples for evaluation
2017-06-11 03:17:15.670081 EDT | -----------------------  -----------
2017-06-11 03:17:15.670988 EDT | Epoch                     998
2017-06-11 03:17:15.671360 EDT | Iteration                 998
2017-06-11 03:17:15.671713 EDT | AverageReturn            2250.93
2017-06-11 03:17:15.672062 EDT | StdReturn                 704.549
2017-06-11 03:17:15.672409 EDT | MaxReturn                2941.17
2017-06-11 03:17:15.672756 EDT | MinReturn                1115.14
2017-06-11 03:17:15.673100 EDT | AverageEsReturn           587.988
2017-06-11 03:17:15.673450 EDT | StdEsReturn               422.391
2017-06-11 03:17:15.674008 EDT | MaxEsReturn              1125.01
2017-06-11 03:17:15.674365 EDT | MinEsReturn                23.2729
2017-06-11 03:17:15.674712 EDT | AverageDiscountedReturn   239.253
2017-06-11 03:17:15.675055 EDT | AverageQLoss                1.82031
2017-06-11 03:17:15.675396 EDT | AveragePolicySurr         -30.0043
2017-06-11 03:17:15.675741 EDT | AverageQ                   29.7016
2017-06-11 03:17:15.676086 EDT | AverageAbsQ                29.7156
2017-06-11 03:17:15.676430 EDT | AverageY                   29.7043
2017-06-11 03:17:15.676774 EDT | AverageAbsY                29.7095
2017-06-11 03:17:15.677121 EDT | AverageAbsQYDiff            0.49376
2017-06-11 03:17:15.677464 EDT | AverageAction               0.997187
2017-06-11 03:17:15.677818 EDT | PolicyRegParamNorm         97.041
2017-06-11 03:17:15.678162 EDT | QFunRegParamNorm          125.841
2017-06-11 03:17:15.678505 EDT | -----------------------  -----------
2017-06-11 03:17:15.679117 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #999 | Training started
2017-06-11 03:17:33.058840 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #999 | Training finished
2017-06-11 03:17:33.059661 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #999 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 03:17:33.060039 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #999 | Collecting samples for evaluation
2017-06-11 03:17:47.314969 EDT | -----------------------  -----------
2017-06-11 03:17:47.315818 EDT | Epoch                     999
2017-06-11 03:17:47.316189 EDT | Iteration                 999
2017-06-11 03:17:47.316535 EDT | AverageReturn            2043.85
2017-06-11 03:17:47.316880 EDT | StdReturn                 872.913
2017-06-11 03:17:47.317222 EDT | MaxReturn                3107.21
2017-06-11 03:17:47.317565 EDT | MinReturn                 937.098
2017-06-11 03:17:47.317924 EDT | AverageEsReturn           373.106
2017-06-11 03:17:47.318266 EDT | StdEsReturn               276.727
2017-06-11 03:17:47.318608 EDT | MaxEsReturn               926.002
2017-06-11 03:17:47.319151 EDT | MinEsReturn               102.431
2017-06-11 03:17:47.319499 EDT | AverageDiscountedReturn   239.934
2017-06-11 03:17:47.319841 EDT | AverageQLoss                2.21076
2017-06-11 03:17:47.320745 EDT | AveragePolicySurr         -29.9582
2017-06-11 03:17:47.321091 EDT | AverageQ                   29.6603
2017-06-11 03:17:47.321435 EDT | AverageAbsQ                29.6766
2017-06-11 03:17:47.321787 EDT | AverageY                   29.661
2017-06-11 03:17:47.322129 EDT | AverageAbsY                29.6673
2017-06-11 03:17:47.322471 EDT | AverageAbsQYDiff            0.516402
2017-06-11 03:17:47.322809 EDT | AverageAction               0.997323
2017-06-11 03:17:47.323149 EDT | PolicyRegParamNorm         97.0697
2017-06-11 03:17:47.323488 EDT | QFunRegParamNorm          125.912
2017-06-11 03:17:47.323831 EDT | -----------------------  -----------
2017-06-11 03:17:47.324335 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1000 | Training started
2017-06-11 03:18:05.525319 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1000 | Training finished
2017-06-11 03:18:05.526086 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1000 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 03:18:05.526996 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1000 | Collecting samples for evaluation
2017-06-11 03:18:19.349003 EDT | -----------------------  -----------
2017-06-11 03:18:19.349785 EDT | Epoch                    1000
2017-06-11 03:18:19.349982 EDT | Iteration                1000
2017-06-11 03:18:19.350176 EDT | AverageReturn            2856.22
2017-06-11 03:18:19.350360 EDT | StdReturn                 313.221
2017-06-11 03:18:19.350644 EDT | MaxReturn                3063.74
2017-06-11 03:18:19.350842 EDT | MinReturn                1895.08
2017-06-11 03:18:19.351024 EDT | AverageEsReturn           368.667
2017-06-11 03:18:19.351359 EDT | StdEsReturn               186.983
2017-06-11 03:18:19.351536 EDT | MaxEsReturn               741.601
2017-06-11 03:18:19.351718 EDT | MinEsReturn               179.46
2017-06-11 03:18:19.351898 EDT | AverageDiscountedReturn   248.452
2017-06-11 03:18:19.352077 EDT | AverageQLoss                1.94656
2017-06-11 03:18:19.352255 EDT | AveragePolicySurr         -29.8907
2017-06-11 03:18:19.352444 EDT | AverageQ                   29.5838
2017-06-11 03:18:19.352621 EDT | AverageAbsQ                29.5995
2017-06-11 03:18:19.352799 EDT | AverageY                   29.5836
2017-06-11 03:18:19.352977 EDT | AverageAbsY                29.5915
2017-06-11 03:18:19.353154 EDT | AverageAbsQYDiff            0.514728
2017-06-11 03:18:19.355208 EDT | AverageAction               0.997414
2017-06-11 03:18:19.356421 EDT | PolicyRegParamNorm         97.0925
2017-06-11 03:18:19.360447 EDT | QFunRegParamNorm          125.969
2017-06-11 03:18:19.360640 EDT | -----------------------  -----------
2017-06-11 03:18:19.360949 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1001 | Training started
2017-06-11 03:18:37.932326 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1001 | Training finished
2017-06-11 03:18:37.933318 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1001 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 03:18:37.933546 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1001 | Collecting samples for evaluation
2017-06-11 03:18:50.864800 EDT | -----------------------  -----------
2017-06-11 03:18:50.865747 EDT | Epoch                    1001
2017-06-11 03:18:50.865933 EDT | Iteration                1001
2017-06-11 03:18:50.866096 EDT | AverageReturn            2849.71
2017-06-11 03:18:50.866482 EDT | StdReturn                 102.143
2017-06-11 03:18:50.866915 EDT | MaxReturn                2971.71
2017-06-11 03:18:50.867224 EDT | MinReturn                2583.86
2017-06-11 03:18:50.867625 EDT | AverageEsReturn           502.525
2017-06-11 03:18:50.869873 EDT | StdEsReturn               894.245
2017-06-11 03:18:50.870164 EDT | MaxEsReturn              2290.45
2017-06-11 03:18:50.871175 EDT | MinEsReturn                14.1326
2017-06-11 03:18:50.871577 EDT | AverageDiscountedReturn   243.981
2017-06-11 03:18:50.874552 EDT | AverageQLoss                1.91566
2017-06-11 03:18:50.874969 EDT | AveragePolicySurr         -29.9251
2017-06-11 03:18:50.875306 EDT | AverageQ                   29.651
2017-06-11 03:18:50.875726 EDT | AverageAbsQ                29.6717
2017-06-11 03:18:50.876125 EDT | AverageY                   29.6545
2017-06-11 03:18:50.876530 EDT | AverageAbsY                29.6632
2017-06-11 03:18:50.876763 EDT | AverageAbsQYDiff            0.507515
2017-06-11 03:18:50.877162 EDT | AverageAction               0.997505
2017-06-11 03:18:50.877548 EDT | PolicyRegParamNorm         97.11
2017-06-11 03:18:50.877916 EDT | QFunRegParamNorm          126.01
2017-06-11 03:18:50.878284 EDT | -----------------------  -----------
2017-06-11 03:18:50.878839 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1002 | Training started
2017-06-11 03:19:07.275571 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1002 | Training finished
2017-06-11 03:19:07.276418 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1002 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 03:19:07.276731 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1002 | Collecting samples for evaluation
2017-06-11 03:19:20.313594 EDT | -----------------------  -----------
2017-06-11 03:19:20.314625 EDT | Epoch                    1002
2017-06-11 03:19:20.315000 EDT | Iteration                1002
2017-06-11 03:19:20.315348 EDT | AverageReturn             975.268
2017-06-11 03:19:20.315694 EDT | StdReturn                 524.8
2017-06-11 03:19:20.316035 EDT | MaxReturn                2990.59
2017-06-11 03:19:20.319850 EDT | MinReturn                 425.705
2017-06-11 03:19:20.320213 EDT | AverageEsReturn           274.592
2017-06-11 03:19:20.320560 EDT | StdEsReturn               129.089
2017-06-11 03:19:20.320921 EDT | MaxEsReturn               535.6
2017-06-11 03:19:20.321269 EDT | MinEsReturn               112.579
2017-06-11 03:19:20.321611 EDT | AverageDiscountedReturn   235.951
2017-06-11 03:19:20.321963 EDT | AverageQLoss                2.42806
2017-06-11 03:19:20.322305 EDT | AveragePolicySurr         -29.8971
2017-06-11 03:19:20.322699 EDT | AverageQ                   29.5886
2017-06-11 03:19:20.323039 EDT | AverageAbsQ                29.6046
2017-06-11 03:19:20.323381 EDT | AverageY                   29.5896
2017-06-11 03:19:20.323723 EDT | AverageAbsY                29.5961
2017-06-11 03:19:20.324132 EDT | AverageAbsQYDiff            0.54177
2017-06-11 03:19:20.324473 EDT | AverageAction               0.997782
2017-06-11 03:19:20.324875 EDT | PolicyRegParamNorm         97.2311
2017-06-11 03:19:20.325248 EDT | QFunRegParamNorm          126.026
2017-06-11 03:19:20.325594 EDT | -----------------------  -----------
2017-06-11 03:19:20.326156 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1003 | Training started
2017-06-11 03:19:36.405734 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1003 | Training finished
2017-06-11 03:19:36.406638 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1003 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 03:19:36.407011 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1003 | Collecting samples for evaluation
2017-06-11 03:19:50.939336 EDT | -----------------------  -----------
2017-06-11 03:19:50.940378 EDT | Epoch                    1003
2017-06-11 03:19:50.940739 EDT | Iteration                1003
2017-06-11 03:19:50.941080 EDT | AverageReturn            2173.25
2017-06-11 03:19:50.941416 EDT | StdReturn                 719.485
2017-06-11 03:19:50.941761 EDT | MaxReturn                2757.81
2017-06-11 03:19:50.942096 EDT | MinReturn                 767.609
2017-06-11 03:19:50.942430 EDT | AverageEsReturn           381.193
2017-06-11 03:19:50.942761 EDT | StdEsReturn               204.388
2017-06-11 03:19:50.943096 EDT | MaxEsReturn               736.921
2017-06-11 03:19:50.943434 EDT | MinEsReturn               111.557
2017-06-11 03:19:50.943770 EDT | AverageDiscountedReturn   230.168
2017-06-11 03:19:50.944114 EDT | AverageQLoss                2.30505
2017-06-11 03:19:50.944452 EDT | AveragePolicySurr         -29.9626
2017-06-11 03:19:50.944787 EDT | AverageQ                   29.6575
2017-06-11 03:19:50.945121 EDT | AverageAbsQ                29.6752
2017-06-11 03:19:50.945454 EDT | AverageY                   29.6588
2017-06-11 03:19:50.945796 EDT | AverageAbsY                29.6632
2017-06-11 03:19:50.946133 EDT | AverageAbsQYDiff            0.542076
2017-06-11 03:19:50.946468 EDT | AverageAction               0.997277
2017-06-11 03:19:50.946804 EDT | PolicyRegParamNorm         97.2195
2017-06-11 03:19:50.947141 EDT | QFunRegParamNorm          126.074
2017-06-11 03:19:50.947473 EDT | -----------------------  -----------
2017-06-11 03:19:50.947967 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1004 | Training started
2017-06-11 03:20:07.981551 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1004 | Training finished
2017-06-11 03:20:07.982646 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1004 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 03:20:07.983168 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1004 | Collecting samples for evaluation
2017-06-11 03:20:21.899432 EDT | -----------------------  -----------
2017-06-11 03:20:21.900359 EDT | Epoch                    1004
2017-06-11 03:20:21.900728 EDT | Iteration                1004
2017-06-11 03:20:21.901078 EDT | AverageReturn            2380.56
2017-06-11 03:20:21.901636 EDT | StdReturn                 665.224
2017-06-11 03:20:21.902093 EDT | MaxReturn                2883.3
2017-06-11 03:20:21.902595 EDT | MinReturn                1048.26
2017-06-11 03:20:21.903012 EDT | AverageEsReturn           517.644
2017-06-11 03:20:21.903444 EDT | StdEsReturn               281.153
2017-06-11 03:20:21.904005 EDT | MaxEsReturn               866.962
2017-06-11 03:20:21.904425 EDT | MinEsReturn               211.126
2017-06-11 03:20:21.904919 EDT | AverageDiscountedReturn   240.879
2017-06-11 03:20:21.905300 EDT | AverageQLoss                2.20941
2017-06-11 03:20:21.905729 EDT | AveragePolicySurr         -29.8397
2017-06-11 03:20:21.906163 EDT | AverageQ                   29.5464
2017-06-11 03:20:21.906613 EDT | AverageAbsQ                29.5613
2017-06-11 03:20:21.907035 EDT | AverageY                   29.5473
2017-06-11 03:20:21.907469 EDT | AverageAbsY                29.5517
2017-06-11 03:20:21.908133 EDT | AverageAbsQYDiff            0.533655
2017-06-11 03:20:21.908734 EDT | AverageAction               0.997698
2017-06-11 03:20:21.909180 EDT | PolicyRegParamNorm         97.3419
2017-06-11 03:20:21.909683 EDT | QFunRegParamNorm          126.102
2017-06-11 03:20:21.910218 EDT | -----------------------  -----------
2017-06-11 03:20:21.911192 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1005 | Training started
2017-06-11 03:20:38.600550 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1005 | Training finished
2017-06-11 03:20:38.601388 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1005 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 03:20:38.601587 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1005 | Collecting samples for evaluation
2017-06-11 03:20:53.175264 EDT | -----------------------  -----------
2017-06-11 03:20:53.175838 EDT | Epoch                    1005
2017-06-11 03:20:53.176298 EDT | Iteration                1005
2017-06-11 03:20:53.176749 EDT | AverageReturn            1607.01
2017-06-11 03:20:53.177198 EDT | StdReturn                 690.56
2017-06-11 03:20:53.178614 EDT | MaxReturn                2979.97
2017-06-11 03:20:53.179407 EDT | MinReturn                 861.544
2017-06-11 03:20:53.179856 EDT | AverageEsReturn           312.16
2017-06-11 03:20:53.180304 EDT | StdEsReturn               173.633
2017-06-11 03:20:53.180748 EDT | MaxEsReturn               653.921
2017-06-11 03:20:53.181191 EDT | MinEsReturn               120.618
2017-06-11 03:20:53.181633 EDT | AverageDiscountedReturn   245.262
2017-06-11 03:20:53.182091 EDT | AverageQLoss                2.39924
2017-06-11 03:20:53.182533 EDT | AveragePolicySurr         -29.8606
2017-06-11 03:20:53.182975 EDT | AverageQ                   29.5691
2017-06-11 03:20:53.183415 EDT | AverageAbsQ                29.5854
2017-06-11 03:20:53.183856 EDT | AverageY                   29.5727
2017-06-11 03:20:53.184300 EDT | AverageAbsY                29.5773
2017-06-11 03:20:53.184739 EDT | AverageAbsQYDiff            0.546734
2017-06-11 03:20:53.185179 EDT | AverageAction               0.997667
2017-06-11 03:20:53.185622 EDT | PolicyRegParamNorm         97.3221
2017-06-11 03:20:53.186078 EDT | QFunRegParamNorm          126.148
2017-06-11 03:20:53.186520 EDT | -----------------------  -----------
2017-06-11 03:20:53.187132 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1006 | Training started
2017-06-11 03:21:09.674276 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1006 | Training finished
2017-06-11 03:21:09.675359 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1006 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 03:21:09.675811 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1006 | Collecting samples for evaluation
2017-06-11 03:21:23.254129 EDT | -----------------------  -----------
2017-06-11 03:21:23.254526 EDT | Epoch                    1006
2017-06-11 03:21:23.254811 EDT | Iteration                1006
2017-06-11 03:21:23.255066 EDT | AverageReturn            2665.46
2017-06-11 03:21:23.255317 EDT | StdReturn                  43.1443
2017-06-11 03:21:23.255558 EDT | MaxReturn                2711.33
2017-06-11 03:21:23.255797 EDT | MinReturn                2578.59
2017-06-11 03:21:23.256041 EDT | AverageEsReturn           382.201
2017-06-11 03:21:23.256282 EDT | StdEsReturn               488.764
2017-06-11 03:21:23.256524 EDT | MaxEsReturn              1443.21
2017-06-11 03:21:23.256775 EDT | MinEsReturn                66.3767
2017-06-11 03:21:23.257046 EDT | AverageDiscountedReturn   237.63
2017-06-11 03:21:23.257301 EDT | AverageQLoss                1.87526
2017-06-11 03:21:23.257544 EDT | AveragePolicySurr         -29.9179
2017-06-11 03:21:23.258210 EDT | AverageQ                   29.6371
2017-06-11 03:21:23.258455 EDT | AverageAbsQ                29.6509
2017-06-11 03:21:23.258695 EDT | AverageY                   29.6367
2017-06-11 03:21:23.259083 EDT | AverageAbsY                29.6413
2017-06-11 03:21:23.259327 EDT | AverageAbsQYDiff            0.512029
2017-06-11 03:21:23.259568 EDT | AverageAction               0.997704
2017-06-11 03:21:23.259808 EDT | PolicyRegParamNorm         97.3742
2017-06-11 03:21:23.260048 EDT | QFunRegParamNorm          126.186
2017-06-11 03:21:23.260288 EDT | -----------------------  -----------
2017-06-11 03:21:23.260649 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1007 | Training started
2017-06-11 03:21:42.567601 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1007 | Training finished
2017-06-11 03:21:42.568342 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1007 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 03:21:42.568715 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1007 | Collecting samples for evaluation
2017-06-11 03:21:57.497081 EDT | -----------------------  -----------
2017-06-11 03:21:57.498679 EDT | Epoch                    1007
2017-06-11 03:21:57.499306 EDT | Iteration                1007
2017-06-11 03:21:57.499626 EDT | AverageReturn            2602.96
2017-06-11 03:21:57.499963 EDT | StdReturn                 452.53
2017-06-11 03:21:57.500372 EDT | MaxReturn                2832.09
2017-06-11 03:21:57.500548 EDT | MinReturn                1181.31
2017-06-11 03:21:57.500738 EDT | AverageEsReturn           437.391
2017-06-11 03:21:57.500915 EDT | StdEsReturn               366.773
2017-06-11 03:21:57.501074 EDT | MaxEsReturn              1099.22
2017-06-11 03:21:57.501232 EDT | MinEsReturn                24.5524
2017-06-11 03:21:57.501904 EDT | AverageDiscountedReturn   239.864
2017-06-11 03:21:57.502100 EDT | AverageQLoss                2.71299
2017-06-11 03:21:57.502288 EDT | AveragePolicySurr         -29.9097
2017-06-11 03:21:57.502556 EDT | AverageQ                   29.6186
2017-06-11 03:21:57.502741 EDT | AverageAbsQ                29.6338
2017-06-11 03:21:57.503102 EDT | AverageY                   29.6219
2017-06-11 03:21:57.503429 EDT | AverageAbsY                29.6258
2017-06-11 03:21:57.503754 EDT | AverageAbsQYDiff            0.572215
2017-06-11 03:21:57.503997 EDT | AverageAction               0.99738
2017-06-11 03:21:57.504240 EDT | PolicyRegParamNorm         97.4326
2017-06-11 03:21:57.504447 EDT | QFunRegParamNorm          126.19
2017-06-11 03:21:57.504628 EDT | -----------------------  -----------
2017-06-11 03:21:57.505705 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1008 | Training started
2017-06-11 03:22:14.767115 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1008 | Training finished
2017-06-11 03:22:14.773149 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1008 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 03:22:14.773589 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1008 | Collecting samples for evaluation
2017-06-11 03:22:29.470044 EDT | -----------------------  -----------
2017-06-11 03:22:29.504964 EDT | Epoch                    1008
2017-06-11 03:22:29.508328 EDT | Iteration                1008
2017-06-11 03:22:29.513765 EDT | AverageReturn            2875.34
2017-06-11 03:22:29.514072 EDT | StdReturn                 286.699
2017-06-11 03:22:29.514347 EDT | MaxReturn                3161.84
2017-06-11 03:22:29.514617 EDT | MinReturn                2000.33
2017-06-11 03:22:29.514892 EDT | AverageEsReturn           513.317
2017-06-11 03:22:29.515156 EDT | StdEsReturn               339.318
2017-06-11 03:22:29.515419 EDT | MaxEsReturn              1054.82
2017-06-11 03:22:29.515682 EDT | MinEsReturn                 7.28818
2017-06-11 03:22:29.515944 EDT | AverageDiscountedReturn   244.637
2017-06-11 03:22:29.516204 EDT | AverageQLoss                1.87827
2017-06-11 03:22:29.516464 EDT | AveragePolicySurr         -29.9191
2017-06-11 03:22:29.516723 EDT | AverageQ                   29.6267
2017-06-11 03:22:29.516983 EDT | AverageAbsQ                29.6455
2017-06-11 03:22:29.517243 EDT | AverageY                   29.6258
2017-06-11 03:22:29.517502 EDT | AverageAbsY                29.6326
2017-06-11 03:22:29.521985 EDT | AverageAbsQYDiff            0.510924
2017-06-11 03:22:29.522572 EDT | AverageAction               0.997309
2017-06-11 03:22:29.523149 EDT | PolicyRegParamNorm         97.4321
2017-06-11 03:22:29.523692 EDT | QFunRegParamNorm          126.213
2017-06-11 03:22:29.524237 EDT | -----------------------  -----------
2017-06-11 03:22:29.524929 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1009 | Training started
2017-06-11 03:22:46.601334 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1009 | Training finished
2017-06-11 03:22:46.603188 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1009 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 03:22:46.603921 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1009 | Collecting samples for evaluation
2017-06-11 03:23:01.452740 EDT | -----------------------  -----------
2017-06-11 03:23:01.453538 EDT | Epoch                    1009
2017-06-11 03:23:01.453741 EDT | Iteration                1009
2017-06-11 03:23:01.453909 EDT | AverageReturn            1520.78
2017-06-11 03:23:01.454065 EDT | StdReturn                 589.585
2017-06-11 03:23:01.454348 EDT | MaxReturn                2749.08
2017-06-11 03:23:01.454707 EDT | MinReturn                 857.839
2017-06-11 03:23:01.455438 EDT | AverageEsReturn           384.864
2017-06-11 03:23:01.455765 EDT | StdEsReturn               199.519
2017-06-11 03:23:01.456099 EDT | MaxEsReturn               713.025
2017-06-11 03:23:01.456550 EDT | MinEsReturn               134.56
2017-06-11 03:23:01.456947 EDT | AverageDiscountedReturn   241.257
2017-06-11 03:23:01.457379 EDT | AverageQLoss                1.89892
2017-06-11 03:23:01.457722 EDT | AveragePolicySurr         -29.9031
2017-06-11 03:23:01.458040 EDT | AverageQ                   29.6193
2017-06-11 03:23:01.458450 EDT | AverageAbsQ                29.6318
2017-06-11 03:23:01.458770 EDT | AverageY                   29.6207
2017-06-11 03:23:01.459221 EDT | AverageAbsY                29.6259
2017-06-11 03:23:01.459558 EDT | AverageAbsQYDiff            0.514015
2017-06-11 03:23:01.459882 EDT | AverageAction               0.997292
2017-06-11 03:23:01.460204 EDT | PolicyRegParamNorm         97.456
2017-06-11 03:23:01.460636 EDT | QFunRegParamNorm          126.237
2017-06-11 03:23:01.460968 EDT | -----------------------  -----------
2017-06-11 03:23:01.461378 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1010 | Training started
2017-06-11 03:23:19.675280 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1010 | Training finished
2017-06-11 03:23:19.685865 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1010 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 03:23:19.686154 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1010 | Collecting samples for evaluation
2017-06-11 03:23:34.065685 EDT | -----------------------  -----------
2017-06-11 03:23:34.066587 EDT | Epoch                    1010
2017-06-11 03:23:34.066944 EDT | Iteration                1010
2017-06-11 03:23:34.067280 EDT | AverageReturn             847.964
2017-06-11 03:23:34.067615 EDT | StdReturn                 259.209
2017-06-11 03:23:34.067943 EDT | MaxReturn                1675.77
2017-06-11 03:23:34.068267 EDT | MinReturn                 484.971
2017-06-11 03:23:34.068606 EDT | AverageEsReturn           580.928
2017-06-11 03:23:34.068854 EDT | StdEsReturn               362.096
2017-06-11 03:23:34.069179 EDT | MaxEsReturn              1000.49
2017-06-11 03:23:34.069512 EDT | MinEsReturn               109.369
2017-06-11 03:23:34.069821 EDT | AverageDiscountedReturn   242.048
2017-06-11 03:23:34.070148 EDT | AverageQLoss                1.94781
2017-06-11 03:23:34.070476 EDT | AveragePolicySurr         -29.9369
2017-06-11 03:23:34.070809 EDT | AverageQ                   29.6601
2017-06-11 03:23:34.070984 EDT | AverageAbsQ                29.6762
2017-06-11 03:23:34.071211 EDT | AverageY                   29.6614
2017-06-11 03:23:34.071531 EDT | AverageAbsY                29.666
2017-06-11 03:23:34.071864 EDT | AverageAbsQYDiff            0.504883
2017-06-11 03:23:34.072134 EDT | AverageAction               0.998003
2017-06-11 03:23:34.072297 EDT | PolicyRegParamNorm         97.5201
2017-06-11 03:23:34.072620 EDT | QFunRegParamNorm          126.27
2017-06-11 03:23:34.072943 EDT | -----------------------  -----------
2017-06-11 03:23:34.073434 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1011 | Training started
2017-06-11 03:23:51.830442 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1011 | Training finished
2017-06-11 03:23:51.831545 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1011 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 03:23:51.832078 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1011 | Collecting samples for evaluation
2017-06-11 03:24:06.676284 EDT | -----------------------  -----------
2017-06-11 03:24:06.677235 EDT | Epoch                    1011
2017-06-11 03:24:06.677525 EDT | Iteration                1011
2017-06-11 03:24:06.677803 EDT | AverageReturn            2325.52
2017-06-11 03:24:06.678069 EDT | StdReturn                 524.717
2017-06-11 03:24:06.678296 EDT | MaxReturn                2624.61
2017-06-11 03:24:06.678647 EDT | MinReturn                1040.21
2017-06-11 03:24:06.678920 EDT | AverageEsReturn           539.346
2017-06-11 03:24:06.679172 EDT | StdEsReturn               366.014
2017-06-11 03:24:06.679391 EDT | MaxEsReturn              1005.66
2017-06-11 03:24:06.679558 EDT | MinEsReturn                86.2469
2017-06-11 03:24:06.679904 EDT | AverageDiscountedReturn   226.951
2017-06-11 03:24:06.680075 EDT | AverageQLoss                1.9562
2017-06-11 03:24:06.680267 EDT | AveragePolicySurr         -29.9655
2017-06-11 03:24:06.680422 EDT | AverageQ                   29.6984
2017-06-11 03:24:06.680675 EDT | AverageAbsQ                29.7113
2017-06-11 03:24:06.680880 EDT | AverageY                   29.6994
2017-06-11 03:24:06.681046 EDT | AverageAbsY                29.7027
2017-06-11 03:24:06.681201 EDT | AverageAbsQYDiff            0.495808
2017-06-11 03:24:06.681362 EDT | AverageAction               0.997013
2017-06-11 03:24:06.681662 EDT | PolicyRegParamNorm         97.5381
2017-06-11 03:24:06.681889 EDT | QFunRegParamNorm          126.289
2017-06-11 03:24:06.682074 EDT | -----------------------  -----------
2017-06-11 03:24:06.682542 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1012 | Training started
2017-06-11 03:24:23.809764 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1012 | Training finished
2017-06-11 03:24:23.810190 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1012 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 03:24:23.810553 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1012 | Collecting samples for evaluation
2017-06-11 03:24:37.524171 EDT | -----------------------  -----------
2017-06-11 03:24:37.525271 EDT | Epoch                    1012
2017-06-11 03:24:37.525747 EDT | Iteration                1012
2017-06-11 03:24:37.526192 EDT | AverageReturn            2539.76
2017-06-11 03:24:37.526637 EDT | StdReturn                  56.8718
2017-06-11 03:24:37.527083 EDT | MaxReturn                2635.74
2017-06-11 03:24:37.527524 EDT | MinReturn                2457.32
2017-06-11 03:24:37.528108 EDT | AverageEsReturn           533.74
2017-06-11 03:24:37.528550 EDT | StdEsReturn               214.143
2017-06-11 03:24:37.528991 EDT | MaxEsReturn               872.546
2017-06-11 03:24:37.529433 EDT | MinEsReturn               243.031
2017-06-11 03:24:37.529889 EDT | AverageDiscountedReturn   222.338
2017-06-11 03:24:37.530308 EDT | AverageQLoss                2.4654
2017-06-11 03:24:37.530751 EDT | AveragePolicySurr         -29.9552
2017-06-11 03:24:37.531167 EDT | AverageQ                   29.6887
2017-06-11 03:24:37.531511 EDT | AverageAbsQ                29.7041
2017-06-11 03:24:37.531953 EDT | AverageY                   29.6911
2017-06-11 03:24:37.532303 EDT | AverageAbsY                29.6961
2017-06-11 03:24:37.532666 EDT | AverageAbsQYDiff            0.525974
2017-06-11 03:24:37.533005 EDT | AverageAction               0.996783
2017-06-11 03:24:37.533360 EDT | PolicyRegParamNorm         97.5679
2017-06-11 03:24:37.533810 EDT | QFunRegParamNorm          126.381
2017-06-11 03:24:37.534160 EDT | -----------------------  -----------
2017-06-11 03:24:37.534743 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1013 | Training started
2017-06-11 03:24:55.554596 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1013 | Training finished
2017-06-11 03:24:55.555429 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1013 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 03:24:55.555778 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1013 | Collecting samples for evaluation
2017-06-11 03:25:10.498755 EDT | -----------------------  -----------
2017-06-11 03:25:10.499459 EDT | Epoch                    1013
2017-06-11 03:25:10.499840 EDT | Iteration                1013
2017-06-11 03:25:10.500152 EDT | AverageReturn            2097.09
2017-06-11 03:25:10.500591 EDT | StdReturn                 747.164
2017-06-11 03:25:10.501144 EDT | MaxReturn                2875.14
2017-06-11 03:25:10.501624 EDT | MinReturn                1025.66
2017-06-11 03:25:10.502258 EDT | AverageEsReturn           424.299
2017-06-11 03:25:10.502825 EDT | StdEsReturn               202.306
2017-06-11 03:25:10.503305 EDT | MaxEsReturn               777.706
2017-06-11 03:25:10.503729 EDT | MinEsReturn               201.12
2017-06-11 03:25:10.504159 EDT | AverageDiscountedReturn   242.849
2017-06-11 03:25:10.504619 EDT | AverageQLoss                2.11894
2017-06-11 03:25:10.505022 EDT | AveragePolicySurr         -29.9404
2017-06-11 03:25:10.505526 EDT | AverageQ                   29.6897
2017-06-11 03:25:10.506008 EDT | AverageAbsQ                29.7057
2017-06-11 03:25:10.506473 EDT | AverageY                   29.6891
2017-06-11 03:25:10.507024 EDT | AverageAbsY                29.6961
2017-06-11 03:25:10.507499 EDT | AverageAbsQYDiff            0.513842
2017-06-11 03:25:10.508006 EDT | AverageAction               0.997685
2017-06-11 03:25:10.508429 EDT | PolicyRegParamNorm         97.6041
2017-06-11 03:25:10.508979 EDT | QFunRegParamNorm          126.414
2017-06-11 03:25:10.509353 EDT | -----------------------  -----------
2017-06-11 03:25:10.509927 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1014 | Training started
2017-06-11 03:25:27.011862 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1014 | Training finished
2017-06-11 03:25:27.012167 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1014 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 03:25:27.012342 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1014 | Collecting samples for evaluation
2017-06-11 03:25:41.032198 EDT | -----------------------  -----------
2017-06-11 03:25:41.033069 EDT | Epoch                    1014
2017-06-11 03:25:41.033437 EDT | Iteration                1014
2017-06-11 03:25:41.034128 EDT | AverageReturn             795.852
2017-06-11 03:25:41.034611 EDT | StdReturn                  83.5135
2017-06-11 03:25:41.035211 EDT | MaxReturn                1091
2017-06-11 03:25:41.035632 EDT | MinReturn                 729.088
2017-06-11 03:25:41.036039 EDT | AverageEsReturn           845.865
2017-06-11 03:25:41.036404 EDT | StdEsReturn               760.706
2017-06-11 03:25:41.036744 EDT | MaxEsReturn              2158.98
2017-06-11 03:25:41.037137 EDT | MinEsReturn               319.106
2017-06-11 03:25:41.037534 EDT | AverageDiscountedReturn   246.611
2017-06-11 03:25:41.037947 EDT | AverageQLoss                1.91304
2017-06-11 03:25:41.038369 EDT | AveragePolicySurr         -29.871
2017-06-11 03:25:41.038777 EDT | AverageQ                   29.624
2017-06-11 03:25:41.039326 EDT | AverageAbsQ                29.6401
2017-06-11 03:25:41.039627 EDT | AverageY                   29.625
2017-06-11 03:25:41.039980 EDT | AverageAbsY                29.6304
2017-06-11 03:25:41.040391 EDT | AverageAbsQYDiff            0.489837
2017-06-11 03:25:41.040804 EDT | AverageAction               0.998066
2017-06-11 03:25:41.041225 EDT | PolicyRegParamNorm         97.6033
2017-06-11 03:25:41.041614 EDT | QFunRegParamNorm          126.444
2017-06-11 03:25:41.042001 EDT | -----------------------  -----------
2017-06-11 03:25:41.042517 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1015 | Training started
2017-06-11 03:25:56.666714 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1015 | Training finished
2017-06-11 03:25:56.666988 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1015 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 03:25:56.667162 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1015 | Collecting samples for evaluation
2017-06-11 03:26:10.804057 EDT | -----------------------  -----------
2017-06-11 03:26:10.805092 EDT | Epoch                    1015
2017-06-11 03:26:10.805469 EDT | Iteration                1015
2017-06-11 03:26:10.805877 EDT | AverageReturn            1427.69
2017-06-11 03:26:10.806226 EDT | StdReturn                 649.372
2017-06-11 03:26:10.806569 EDT | MaxReturn                2919.44
2017-06-11 03:26:10.806912 EDT | MinReturn                 838.979
2017-06-11 03:26:10.807259 EDT | AverageEsReturn           329.955
2017-06-11 03:26:10.807605 EDT | StdEsReturn               217.098
2017-06-11 03:26:10.808137 EDT | MaxEsReturn               673.099
2017-06-11 03:26:10.808527 EDT | MinEsReturn                79.167
2017-06-11 03:26:10.808875 EDT | AverageDiscountedReturn   255.346
2017-06-11 03:26:10.809312 EDT | AverageQLoss                1.98553
2017-06-11 03:26:10.809661 EDT | AveragePolicySurr         -29.8687
2017-06-11 03:26:10.812114 EDT | AverageQ                   29.6226
2017-06-11 03:26:10.813527 EDT | AverageAbsQ                29.6347
2017-06-11 03:26:10.813994 EDT | AverageY                   29.6234
2017-06-11 03:26:10.814443 EDT | AverageAbsY                29.628
2017-06-11 03:26:10.814891 EDT | AverageAbsQYDiff            0.494305
2017-06-11 03:26:10.815340 EDT | AverageAction               0.997098
2017-06-11 03:26:10.815710 EDT | PolicyRegParamNorm         97.706
2017-06-11 03:26:10.816069 EDT | QFunRegParamNorm          126.524
2017-06-11 03:26:10.816427 EDT | -----------------------  -----------
2017-06-11 03:26:10.816962 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1016 | Training started
2017-06-11 03:26:28.628043 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1016 | Training finished
2017-06-11 03:26:28.628311 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1016 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 03:26:28.628484 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1016 | Collecting samples for evaluation
2017-06-11 03:26:42.360371 EDT | -----------------------  -----------
2017-06-11 03:26:42.361150 EDT | Epoch                    1016
2017-06-11 03:26:42.361342 EDT | Iteration                1016
2017-06-11 03:26:42.361597 EDT | AverageReturn             842.856
2017-06-11 03:26:42.361806 EDT | StdReturn                 450.516
2017-06-11 03:26:42.361990 EDT | MaxReturn                3129.29
2017-06-11 03:26:42.362173 EDT | MinReturn                 442.046
2017-06-11 03:26:42.362354 EDT | AverageEsReturn           305.228
2017-06-11 03:26:42.362535 EDT | StdEsReturn               135.365
2017-06-11 03:26:42.362716 EDT | MaxEsReturn               611.988
2017-06-11 03:26:42.363012 EDT | MinEsReturn               181.742
2017-06-11 03:26:42.363231 EDT | AverageDiscountedReturn   240.362
2017-06-11 03:26:42.363414 EDT | AverageQLoss                2.32646
2017-06-11 03:26:42.363595 EDT | AveragePolicySurr         -29.7739
2017-06-11 03:26:42.363870 EDT | AverageQ                   29.4985
2017-06-11 03:26:42.364060 EDT | AverageAbsQ                29.5164
2017-06-11 03:26:42.364239 EDT | AverageY                   29.5014
2017-06-11 03:26:42.364417 EDT | AverageAbsY                29.5068
2017-06-11 03:26:42.364594 EDT | AverageAbsQYDiff            0.525293
2017-06-11 03:26:42.364773 EDT | AverageAction               0.997749
2017-06-11 03:26:42.365066 EDT | PolicyRegParamNorm         97.7294
2017-06-11 03:26:42.365248 EDT | QFunRegParamNorm          126.628
2017-06-11 03:26:42.365776 EDT | -----------------------  -----------
2017-06-11 03:26:42.366614 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1017 | Training started
2017-06-11 03:26:59.976936 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1017 | Training finished
2017-06-11 03:26:59.978242 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1017 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 03:26:59.978664 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1017 | Collecting samples for evaluation
2017-06-11 03:27:13.645817 EDT | -----------------------  -----------
2017-06-11 03:27:13.646792 EDT | Epoch                    1017
2017-06-11 03:27:13.647159 EDT | Iteration                1017
2017-06-11 03:27:13.647497 EDT | AverageReturn             540.636
2017-06-11 03:27:13.647829 EDT | StdReturn                  93.3266
2017-06-11 03:27:13.648166 EDT | MaxReturn                 774.265
2017-06-11 03:27:13.648495 EDT | MinReturn                 277.419
2017-06-11 03:27:13.648820 EDT | AverageEsReturn           344.555
2017-06-11 03:27:13.649146 EDT | StdEsReturn               105.205
2017-06-11 03:27:13.649468 EDT | MaxEsReturn               563.846
2017-06-11 03:27:13.649809 EDT | MinEsReturn               197.269
2017-06-11 03:27:13.650133 EDT | AverageDiscountedReturn   218.046
2017-06-11 03:27:13.650454 EDT | AverageQLoss                2.26264
2017-06-11 03:27:13.650776 EDT | AveragePolicySurr         -29.7845
2017-06-11 03:27:13.651099 EDT | AverageQ                   29.5266
2017-06-11 03:27:13.651421 EDT | AverageAbsQ                29.5399
2017-06-11 03:27:13.652227 EDT | AverageY                   29.5287
2017-06-11 03:27:13.652583 EDT | AverageAbsY                29.5327
2017-06-11 03:27:13.653610 EDT | AverageAbsQYDiff            0.520575
2017-06-11 03:27:13.654003 EDT | AverageAction               0.997954
2017-06-11 03:27:13.655194 EDT | PolicyRegParamNorm         97.7467
2017-06-11 03:27:13.655550 EDT | QFunRegParamNorm          126.706
2017-06-11 03:27:13.656731 EDT | -----------------------  -----------
2017-06-11 03:27:13.657237 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1018 | Training started
2017-06-11 03:27:30.165509 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1018 | Training finished
2017-06-11 03:27:30.166416 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1018 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 03:27:30.166727 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1018 | Collecting samples for evaluation
2017-06-11 03:27:44.351508 EDT | -----------------------  -----------
2017-06-11 03:27:44.352427 EDT | Epoch                    1018
2017-06-11 03:27:44.352766 EDT | Iteration                1018
2017-06-11 03:27:44.355583 EDT | AverageReturn            1519.16
2017-06-11 03:27:44.355986 EDT | StdReturn                 927.115
2017-06-11 03:27:44.356673 EDT | MaxReturn                3285.6
2017-06-11 03:27:44.356851 EDT | MinReturn                 717.18
2017-06-11 03:27:44.357135 EDT | AverageEsReturn           295.002
2017-06-11 03:27:44.357429 EDT | StdEsReturn               143.965
2017-06-11 03:27:44.357793 EDT | MaxEsReturn               532.695
2017-06-11 03:27:44.358172 EDT | MinEsReturn                74.4975
2017-06-11 03:27:44.358551 EDT | AverageDiscountedReturn   253.942
2017-06-11 03:27:44.358905 EDT | AverageQLoss                2.03642
2017-06-11 03:27:44.361133 EDT | AveragePolicySurr         -29.7335
2017-06-11 03:27:44.361331 EDT | AverageQ                   29.5081
2017-06-11 03:27:44.361611 EDT | AverageAbsQ                29.5224
2017-06-11 03:27:44.361922 EDT | AverageY                   29.5075
2017-06-11 03:27:44.362117 EDT | AverageAbsY                29.5126
2017-06-11 03:27:44.362351 EDT | AverageAbsQYDiff            0.492761
2017-06-11 03:27:44.362639 EDT | AverageAction               0.997377
2017-06-11 03:27:44.362913 EDT | PolicyRegParamNorm         97.7866
2017-06-11 03:27:44.363184 EDT | QFunRegParamNorm          126.704
2017-06-11 03:27:44.363460 EDT | -----------------------  -----------
2017-06-11 03:27:44.363906 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1019 | Training started
2017-06-11 03:28:02.422844 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1019 | Training finished
2017-06-11 03:28:02.423861 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1019 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 03:28:02.424251 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1019 | Collecting samples for evaluation
2017-06-11 03:28:16.892573 EDT | -----------------------  -----------
2017-06-11 03:28:16.893893 EDT | Epoch                    1019
2017-06-11 03:28:16.894259 EDT | Iteration                1019
2017-06-11 03:28:16.894576 EDT | AverageReturn             777.69
2017-06-11 03:28:16.894899 EDT | StdReturn                 161.004
2017-06-11 03:28:16.895222 EDT | MaxReturn                1034.67
2017-06-11 03:28:16.895646 EDT | MinReturn                 386.877
2017-06-11 03:28:16.896274 EDT | AverageEsReturn           546.414
2017-06-11 03:28:16.896690 EDT | StdEsReturn               257.865
2017-06-11 03:28:16.897109 EDT | MaxEsReturn               924.495
2017-06-11 03:28:16.897871 EDT | MinEsReturn               147.76
2017-06-11 03:28:16.898286 EDT | AverageDiscountedReturn   231.761
2017-06-11 03:28:16.898708 EDT | AverageQLoss                2.32411
2017-06-11 03:28:16.898902 EDT | AveragePolicySurr         -29.9362
2017-06-11 03:28:16.899089 EDT | AverageQ                   29.6952
2017-06-11 03:28:16.899365 EDT | AverageAbsQ                29.7064
2017-06-11 03:28:16.899701 EDT | AverageY                   29.6965
2017-06-11 03:28:16.900150 EDT | AverageAbsY                29.7019
2017-06-11 03:28:16.900539 EDT | AverageAbsQYDiff            0.516136
2017-06-11 03:28:16.901875 EDT | AverageAction               0.996801
2017-06-11 03:28:16.902173 EDT | PolicyRegParamNorm         97.7803
2017-06-11 03:28:16.902462 EDT | QFunRegParamNorm          126.715
2017-06-11 03:28:16.902629 EDT | -----------------------  -----------
2017-06-11 03:28:16.902915 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1020 | Training started
2017-06-11 03:28:34.851385 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1020 | Training finished
2017-06-11 03:28:34.852211 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1020 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 03:28:34.852614 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1020 | Collecting samples for evaluation
2017-06-11 03:28:48.506076 EDT | -----------------------  -----------
2017-06-11 03:28:48.506991 EDT | Epoch                    1020
2017-06-11 03:28:48.507230 EDT | Iteration                1020
2017-06-11 03:28:48.507423 EDT | AverageReturn             851.694
2017-06-11 03:28:48.507679 EDT | StdReturn                  90.1105
2017-06-11 03:28:48.507866 EDT | MaxReturn                1047.43
2017-06-11 03:28:48.508058 EDT | MinReturn                 694.266
2017-06-11 03:28:48.508276 EDT | AverageEsReturn           481.149
2017-06-11 03:28:48.508457 EDT | StdEsReturn               432.482
2017-06-11 03:28:48.508639 EDT | MaxEsReturn              1115.29
2017-06-11 03:28:48.508868 EDT | MinEsReturn                24.7832
2017-06-11 03:28:48.509525 EDT | AverageDiscountedReturn   239.944
2017-06-11 03:28:48.509915 EDT | AverageQLoss                2.10656
2017-06-11 03:28:48.510299 EDT | AveragePolicySurr         -29.686
2017-06-11 03:28:48.510535 EDT | AverageQ                   29.4829
2017-06-11 03:28:48.510719 EDT | AverageAbsQ                29.4954
2017-06-11 03:28:48.510945 EDT | AverageY                   29.4839
2017-06-11 03:28:48.511129 EDT | AverageAbsY                29.4906
2017-06-11 03:28:48.511350 EDT | AverageAbsQYDiff            0.491692
2017-06-11 03:28:48.511565 EDT | AverageAction               0.99735
2017-06-11 03:28:48.511747 EDT | PolicyRegParamNorm         97.8159
2017-06-11 03:28:48.511999 EDT | QFunRegParamNorm          126.806
2017-06-11 03:28:48.512281 EDT | -----------------------  -----------
2017-06-11 03:28:48.512696 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1021 | Training started
2017-06-11 03:29:05.879713 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1021 | Training finished
2017-06-11 03:29:05.881159 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1021 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 03:29:05.881377 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1021 | Collecting samples for evaluation
2017-06-11 03:29:20.733832 EDT | -----------------------  -----------
2017-06-11 03:29:20.734780 EDT | Epoch                    1021
2017-06-11 03:29:20.735164 EDT | Iteration                1021
2017-06-11 03:29:20.735534 EDT | AverageReturn             774.932
2017-06-11 03:29:20.736019 EDT | StdReturn                 166.414
2017-06-11 03:29:20.736382 EDT | MaxReturn                1127.73
2017-06-11 03:29:20.736850 EDT | MinReturn                  17.5278
2017-06-11 03:29:20.737426 EDT | AverageEsReturn           274.382
2017-06-11 03:29:20.737913 EDT | StdEsReturn               278.309
2017-06-11 03:29:20.738381 EDT | MaxEsReturn               682.789
2017-06-11 03:29:20.738958 EDT | MinEsReturn                17.6322
2017-06-11 03:29:20.739420 EDT | AverageDiscountedReturn   219.634
2017-06-11 03:29:20.740034 EDT | AverageQLoss                1.81395
2017-06-11 03:29:20.740417 EDT | AveragePolicySurr         -29.7174
2017-06-11 03:29:20.740787 EDT | AverageQ                   29.4714
2017-06-11 03:29:20.741352 EDT | AverageAbsQ                29.4869
2017-06-11 03:29:20.741822 EDT | AverageY                   29.4733
2017-06-11 03:29:20.742446 EDT | AverageAbsY                29.4793
2017-06-11 03:29:20.742917 EDT | AverageAbsQYDiff            0.499698
2017-06-11 03:29:20.743605 EDT | AverageAction               0.997356
2017-06-11 03:29:20.744082 EDT | PolicyRegParamNorm         97.8536
2017-06-11 03:29:20.744566 EDT | QFunRegParamNorm          126.853
2017-06-11 03:29:20.744998 EDT | -----------------------  -----------
2017-06-11 03:29:20.745542 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1022 | Training started
2017-06-11 03:29:38.983154 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1022 | Training finished
2017-06-11 03:29:38.983919 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1022 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 03:29:38.984114 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1022 | Collecting samples for evaluation
2017-06-11 03:29:52.392045 EDT | -----------------------  -----------
2017-06-11 03:29:52.393042 EDT | Epoch                    1022
2017-06-11 03:29:52.393401 EDT | Iteration                1022
2017-06-11 03:29:52.393770 EDT | AverageReturn            1707.99
2017-06-11 03:29:52.394124 EDT | StdReturn                 669.003
2017-06-11 03:29:52.394484 EDT | MaxReturn                2521.03
2017-06-11 03:29:52.394800 EDT | MinReturn                 378.788
2017-06-11 03:29:52.395133 EDT | AverageEsReturn           667.759
2017-06-11 03:29:52.395482 EDT | StdEsReturn               370.872
2017-06-11 03:29:52.395812 EDT | MaxEsReturn              1286.37
2017-06-11 03:29:52.396084 EDT | MinEsReturn               311.383
2017-06-11 03:29:52.396467 EDT | AverageDiscountedReturn   221.294
2017-06-11 03:29:52.396953 EDT | AverageQLoss                2.00347
2017-06-11 03:29:52.397354 EDT | AveragePolicySurr         -29.7436
2017-06-11 03:29:52.397788 EDT | AverageQ                   29.5011
2017-06-11 03:29:52.398216 EDT | AverageAbsQ                29.5186
2017-06-11 03:29:52.398609 EDT | AverageY                   29.5031
2017-06-11 03:29:52.399031 EDT | AverageAbsY                29.5091
2017-06-11 03:29:52.399428 EDT | AverageAbsQYDiff            0.505238
2017-06-11 03:29:52.399850 EDT | AverageAction               0.997058
2017-06-11 03:29:52.400274 EDT | PolicyRegParamNorm         97.8716
2017-06-11 03:29:52.400914 EDT | QFunRegParamNorm          126.904
2017-06-11 03:29:52.401734 EDT | -----------------------  -----------
2017-06-11 03:29:52.402352 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1023 | Training started
2017-06-11 03:30:09.276832 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1023 | Training finished
2017-06-11 03:30:09.277589 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1023 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 03:30:09.277804 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1023 | Collecting samples for evaluation
2017-06-11 03:30:24.367890 EDT | -----------------------  -----------
2017-06-11 03:30:24.391433 EDT | Epoch                    1023
2017-06-11 03:30:24.392047 EDT | Iteration                1023
2017-06-11 03:30:24.392508 EDT | AverageReturn             829.345
2017-06-11 03:30:24.392964 EDT | StdReturn                 386.757
2017-06-11 03:30:24.393417 EDT | MaxReturn                2973.85
2017-06-11 03:30:24.393875 EDT | MinReturn                 503.199
2017-06-11 03:30:24.394325 EDT | AverageEsReturn           607.518
2017-06-11 03:30:24.394772 EDT | StdEsReturn               410.099
2017-06-11 03:30:24.395219 EDT | MaxEsReturn              1322.16
2017-06-11 03:30:24.395661 EDT | MinEsReturn               145.903
2017-06-11 03:30:24.396099 EDT | AverageDiscountedReturn   241.46
2017-06-11 03:30:24.396542 EDT | AverageQLoss                2.02425
2017-06-11 03:30:24.396985 EDT | AveragePolicySurr         -29.7277
2017-06-11 03:30:24.397433 EDT | AverageQ                   29.5001
2017-06-11 03:30:24.397886 EDT | AverageAbsQ                29.5098
2017-06-11 03:30:24.398328 EDT | AverageY                   29.5022
2017-06-11 03:30:24.398776 EDT | AverageAbsY                29.505
2017-06-11 03:30:24.399195 EDT | AverageAbsQYDiff            0.496747
2017-06-11 03:30:24.399611 EDT | AverageAction               0.998548
2017-06-11 03:30:24.400053 EDT | PolicyRegParamNorm         97.9882
2017-06-11 03:30:24.400499 EDT | QFunRegParamNorm          126.958
2017-06-11 03:30:24.400948 EDT | -----------------------  -----------
2017-06-11 03:30:24.401578 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1024 | Training started
2017-06-11 03:30:42.751666 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1024 | Training finished
2017-06-11 03:30:42.765479 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1024 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 03:30:42.765870 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1024 | Collecting samples for evaluation
2017-06-11 03:30:56.792041 EDT | -----------------------  -----------
2017-06-11 03:30:56.793101 EDT | Epoch                    1024
2017-06-11 03:30:56.793474 EDT | Iteration                1024
2017-06-11 03:30:56.793837 EDT | AverageReturn             238.994
2017-06-11 03:30:56.794185 EDT | StdReturn                  21.6397
2017-06-11 03:30:56.794532 EDT | MaxReturn                 259.879
2017-06-11 03:30:56.794881 EDT | MinReturn                  92.7484
2017-06-11 03:30:56.795329 EDT | AverageEsReturn           214.88
2017-06-11 03:30:56.795778 EDT | StdEsReturn                97.7468
2017-06-11 03:30:56.796227 EDT | MaxEsReturn               355.866
2017-06-11 03:30:56.809883 EDT | MinEsReturn                32.1825
2017-06-11 03:30:56.810365 EDT | AverageDiscountedReturn   138.487
2017-06-11 03:30:56.810807 EDT | AverageQLoss                2.06735
2017-06-11 03:30:56.811144 EDT | AveragePolicySurr         -29.6489
2017-06-11 03:30:56.811549 EDT | AverageQ                   29.4137
2017-06-11 03:30:56.811889 EDT | AverageAbsQ                29.4257
2017-06-11 03:30:56.812223 EDT | AverageY                   29.4151
2017-06-11 03:30:56.812639 EDT | AverageAbsY                29.419
2017-06-11 03:30:56.813076 EDT | AverageAbsQYDiff            0.510314
2017-06-11 03:30:56.813503 EDT | AverageAction               0.998613
2017-06-11 03:30:56.813926 EDT | PolicyRegParamNorm         98.041
2017-06-11 03:30:56.814300 EDT | QFunRegParamNorm          127.037
2017-06-11 03:30:56.814840 EDT | -----------------------  -----------
2017-06-11 03:30:56.815407 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1025 | Training started
2017-06-11 03:31:13.790059 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1025 | Training finished
2017-06-11 03:31:13.790999 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1025 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 03:31:13.791287 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1025 | Collecting samples for evaluation
2017-06-11 03:31:27.081066 EDT | -----------------------  -----------
2017-06-11 03:31:27.082026 EDT | Epoch                    1025
2017-06-11 03:31:27.082303 EDT | Iteration                1025
2017-06-11 03:31:27.082513 EDT | AverageReturn             116.679
2017-06-11 03:31:27.082763 EDT | StdReturn                  69.7054
2017-06-11 03:31:27.082949 EDT | MaxReturn                 261.95
2017-06-11 03:31:27.083146 EDT | MinReturn                  70.0925
2017-06-11 03:31:27.083427 EDT | AverageEsReturn           241.701
2017-06-11 03:31:27.083699 EDT | StdEsReturn                73.9208
2017-06-11 03:31:27.083974 EDT | MaxEsReturn               304.629
2017-06-11 03:31:27.084262 EDT | MinEsReturn                22.3245
2017-06-11 03:31:27.084559 EDT | AverageDiscountedReturn    79.6606
2017-06-11 03:31:27.084855 EDT | AverageQLoss                1.79572
2017-06-11 03:31:27.085136 EDT | AveragePolicySurr         -29.6673
2017-06-11 03:31:27.085357 EDT | AverageQ                   29.4303
2017-06-11 03:31:27.085603 EDT | AverageAbsQ                29.4459
2017-06-11 03:31:27.085887 EDT | AverageY                   29.4313
2017-06-11 03:31:27.086105 EDT | AverageAbsY                29.436
2017-06-11 03:31:27.086299 EDT | AverageAbsQYDiff            0.482964
2017-06-11 03:31:27.086477 EDT | AverageAction               0.998365
2017-06-11 03:31:27.086656 EDT | PolicyRegParamNorm         98.0449
2017-06-11 03:31:27.086834 EDT | QFunRegParamNorm          127.078
2017-06-11 03:31:27.087013 EDT | -----------------------  -----------
2017-06-11 03:31:27.087395 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1026 | Training started
2017-06-11 03:31:44.995567 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1026 | Training finished
2017-06-11 03:31:44.996375 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1026 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 03:31:44.996565 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1026 | Collecting samples for evaluation
2017-06-11 03:31:59.611227 EDT | -----------------------  -----------
2017-06-11 03:31:59.611704 EDT | Epoch                    1026
2017-06-11 03:31:59.612012 EDT | Iteration                1026
2017-06-11 03:31:59.612309 EDT | AverageReturn            2538.35
2017-06-11 03:31:59.612604 EDT | StdReturn                 424.314
2017-06-11 03:31:59.612900 EDT | MaxReturn                2873.14
2017-06-11 03:31:59.613210 EDT | MinReturn                1359.78
2017-06-11 03:31:59.613513 EDT | AverageEsReturn           250.29
2017-06-11 03:31:59.613838 EDT | StdEsReturn               148.191
2017-06-11 03:31:59.614143 EDT | MaxEsReturn               600.605
2017-06-11 03:31:59.614442 EDT | MinEsReturn                 7.47128
2017-06-11 03:31:59.614739 EDT | AverageDiscountedReturn   243.525
2017-06-11 03:31:59.615037 EDT | AverageQLoss                1.79396
2017-06-11 03:31:59.615334 EDT | AveragePolicySurr         -29.7027
2017-06-11 03:31:59.615639 EDT | AverageQ                   29.4844
2017-06-11 03:31:59.615937 EDT | AverageAbsQ                29.4957
2017-06-11 03:31:59.616234 EDT | AverageY                   29.486
2017-06-11 03:31:59.617773 EDT | AverageAbsY                29.4887
2017-06-11 03:31:59.618113 EDT | AverageAbsQYDiff            0.475851
2017-06-11 03:31:59.618421 EDT | AverageAction               0.99735
2017-06-11 03:31:59.621768 EDT | PolicyRegParamNorm         98.119
2017-06-11 03:31:59.622106 EDT | QFunRegParamNorm          127.065
2017-06-11 03:31:59.622417 EDT | -----------------------  -----------
2017-06-11 03:31:59.622900 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1027 | Training started
2017-06-11 03:32:18.071344 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1027 | Training finished
2017-06-11 03:32:18.072269 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1027 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 03:32:18.072592 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1027 | Collecting samples for evaluation
2017-06-11 03:32:33.982908 EDT | -----------------------  -----------
2017-06-11 03:32:33.983915 EDT | Epoch                    1027
2017-06-11 03:32:33.984370 EDT | Iteration                1027
2017-06-11 03:32:33.984727 EDT | AverageReturn             672.348
2017-06-11 03:32:33.985155 EDT | StdReturn                 380.009
2017-06-11 03:32:33.985596 EDT | MaxReturn                1598.69
2017-06-11 03:32:33.985999 EDT | MinReturn                 195.535
2017-06-11 03:32:33.986381 EDT | AverageEsReturn           312.164
2017-06-11 03:32:33.986807 EDT | StdEsReturn               297.734
2017-06-11 03:32:33.987255 EDT | MaxEsReturn              1080.25
2017-06-11 03:32:33.987610 EDT | MinEsReturn                77.0751
2017-06-11 03:32:33.988034 EDT | AverageDiscountedReturn   189.174
2017-06-11 03:32:33.988467 EDT | AverageQLoss                2.22457
2017-06-11 03:32:33.988856 EDT | AveragePolicySurr         -29.5741
2017-06-11 03:32:33.989300 EDT | AverageQ                   29.3625
2017-06-11 03:32:33.990038 EDT | AverageAbsQ                29.3748
2017-06-11 03:32:33.990400 EDT | AverageY                   29.3623
2017-06-11 03:32:33.991066 EDT | AverageAbsY                29.3658
2017-06-11 03:32:33.991503 EDT | AverageAbsQYDiff            0.512166
2017-06-11 03:32:33.995447 EDT | AverageAction               0.997631
2017-06-11 03:32:33.995843 EDT | PolicyRegParamNorm         98.1315
2017-06-11 03:32:33.996246 EDT | QFunRegParamNorm          127.155
2017-06-11 03:32:33.996683 EDT | -----------------------  -----------
2017-06-11 03:32:33.997274 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1028 | Training started
2017-06-11 03:32:52.735031 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1028 | Training finished
2017-06-11 03:32:52.735970 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1028 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 03:32:52.736366 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1028 | Collecting samples for evaluation
2017-06-11 03:33:08.665684 EDT | -----------------------  -----------
2017-06-11 03:33:08.666609 EDT | Epoch                    1028
2017-06-11 03:33:08.666953 EDT | Iteration                1028
2017-06-11 03:33:08.667207 EDT | AverageReturn            1600.78
2017-06-11 03:33:08.667532 EDT | StdReturn                 833.437
2017-06-11 03:33:08.669539 EDT | MaxReturn                3215.83
2017-06-11 03:33:08.669863 EDT | MinReturn                 738.602
2017-06-11 03:33:08.670864 EDT | AverageEsReturn           311.677
2017-06-11 03:33:08.673576 EDT | StdEsReturn               229.705
2017-06-11 03:33:08.674221 EDT | MaxEsReturn               754.933
2017-06-11 03:33:08.674682 EDT | MinEsReturn                45.7
2017-06-11 03:33:08.675189 EDT | AverageDiscountedReturn   254.189
2017-06-11 03:33:08.675690 EDT | AverageQLoss                2.0917
2017-06-11 03:33:08.676139 EDT | AveragePolicySurr         -29.5238
2017-06-11 03:33:08.676585 EDT | AverageQ                   29.3124
2017-06-11 03:33:08.677031 EDT | AverageAbsQ                29.3241
2017-06-11 03:33:08.677727 EDT | AverageY                   29.3154
2017-06-11 03:33:08.678176 EDT | AverageAbsY                29.3194
2017-06-11 03:33:08.678630 EDT | AverageAbsQYDiff            0.499246
2017-06-11 03:33:08.679418 EDT | AverageAction               0.997275
2017-06-11 03:33:08.679874 EDT | PolicyRegParamNorm         98.1901
2017-06-11 03:33:08.680318 EDT | QFunRegParamNorm          127.195
2017-06-11 03:33:08.680874 EDT | -----------------------  -----------
2017-06-11 03:33:08.681503 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1029 | Training started
2017-06-11 03:33:27.134157 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1029 | Training finished
2017-06-11 03:33:27.135208 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1029 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 03:33:27.135668 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1029 | Collecting samples for evaluation
2017-06-11 03:33:43.444849 EDT | -----------------------  ------------
2017-06-11 03:33:43.445840 EDT | Epoch                    1029
2017-06-11 03:33:43.446128 EDT | Iteration                1029
2017-06-11 03:33:43.446387 EDT | AverageReturn               5.98474
2017-06-11 03:33:43.446663 EDT | StdReturn                   0.0452779
2017-06-11 03:33:43.446914 EDT | MaxReturn                   6.20348
2017-06-11 03:33:43.447163 EDT | MinReturn                   5.87784
2017-06-11 03:33:43.447411 EDT | AverageEsReturn            41.9838
2017-06-11 03:33:43.447679 EDT | StdEsReturn               128.409
2017-06-11 03:33:43.447927 EDT | MaxEsReturn               708.572
2017-06-11 03:33:43.448175 EDT | MinEsReturn                 5.83329
2017-06-11 03:33:43.448422 EDT | AverageDiscountedReturn     5.79897
2017-06-11 03:33:43.448686 EDT | AverageQLoss                1.93648
2017-06-11 03:33:43.448935 EDT | AveragePolicySurr         -29.5269
2017-06-11 03:33:43.449182 EDT | AverageQ                   29.3378
2017-06-11 03:33:43.449430 EDT | AverageAbsQ                29.3492
2017-06-11 03:33:43.449685 EDT | AverageY                   29.3392
2017-06-11 03:33:43.449950 EDT | AverageAbsY                29.3433
2017-06-11 03:33:43.450198 EDT | AverageAbsQYDiff            0.495967
2017-06-11 03:33:43.450451 EDT | AverageAction               0.999468
2017-06-11 03:33:43.450698 EDT | PolicyRegParamNorm         98.2244
2017-06-11 03:33:43.450969 EDT | QFunRegParamNorm          127.267
2017-06-11 03:33:43.451220 EDT | -----------------------  ------------
2017-06-11 03:33:43.451611 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1030 | Training started
2017-06-11 03:34:02.777750 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1030 | Training finished
2017-06-11 03:34:02.779267 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1030 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 03:34:02.779823 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1030 | Collecting samples for evaluation
2017-06-11 03:34:17.611388 EDT | -----------------------  -----------
2017-06-11 03:34:17.612332 EDT | Epoch                    1030
2017-06-11 03:34:17.612766 EDT | Iteration                1030
2017-06-11 03:34:17.613061 EDT | AverageReturn             607.472
2017-06-11 03:34:17.613392 EDT | StdReturn                 382.039
2017-06-11 03:34:17.613817 EDT | MaxReturn                1184.73
2017-06-11 03:34:17.614103 EDT | MinReturn                   7.46529
2017-06-11 03:34:17.614435 EDT | AverageEsReturn           119.332
2017-06-11 03:34:17.614769 EDT | StdEsReturn               225.687
2017-06-11 03:34:17.615321 EDT | MaxEsReturn               814.663
2017-06-11 03:34:17.615759 EDT | MinEsReturn                 5.76434
2017-06-11 03:34:17.616073 EDT | AverageDiscountedReturn   170.973
2017-06-11 03:34:17.616402 EDT | AverageQLoss                2.15775
2017-06-11 03:34:17.616809 EDT | AveragePolicySurr         -29.5185
2017-06-11 03:34:17.617087 EDT | AverageQ                   29.2909
2017-06-11 03:34:17.617410 EDT | AverageAbsQ                29.3033
2017-06-11 03:34:17.617760 EDT | AverageY                   29.293
2017-06-11 03:34:17.618135 EDT | AverageAbsY                29.2964
2017-06-11 03:34:17.618454 EDT | AverageAbsQYDiff            0.503408
2017-06-11 03:34:17.618785 EDT | AverageAction               0.997441
2017-06-11 03:34:17.619301 EDT | PolicyRegParamNorm         98.2663
2017-06-11 03:34:17.619631 EDT | QFunRegParamNorm          127.329
2017-06-11 03:34:17.620074 EDT | -----------------------  -----------
2017-06-11 03:34:17.620558 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1031 | Training started
2017-06-11 03:34:36.252130 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1031 | Training finished
2017-06-11 03:34:36.252791 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1031 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 03:34:36.253090 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1031 | Collecting samples for evaluation
2017-06-11 03:34:52.222143 EDT | -----------------------  -----------
2017-06-11 03:34:52.223214 EDT | Epoch                    1031
2017-06-11 03:34:52.223418 EDT | Iteration                1031
2017-06-11 03:34:52.223640 EDT | AverageReturn             768.06
2017-06-11 03:34:52.223835 EDT | StdReturn                 136.911
2017-06-11 03:34:52.224042 EDT | MaxReturn                1067.36
2017-06-11 03:34:52.224312 EDT | MinReturn                 268.207
2017-06-11 03:34:52.224495 EDT | AverageEsReturn           228.168
2017-06-11 03:34:52.224714 EDT | StdEsReturn               263.722
2017-06-11 03:34:52.225004 EDT | MaxEsReturn               741.719
2017-06-11 03:34:52.225329 EDT | MinEsReturn                 7.21433
2017-06-11 03:34:52.225645 EDT | AverageDiscountedReturn   238.454
2017-06-11 03:34:52.225925 EDT | AverageQLoss                2.05854
2017-06-11 03:34:52.226194 EDT | AveragePolicySurr         -29.4647
2017-06-11 03:34:52.226487 EDT | AverageQ                   29.2452
2017-06-11 03:34:52.226818 EDT | AverageAbsQ                29.2596
2017-06-11 03:34:52.227152 EDT | AverageY                   29.245
2017-06-11 03:34:52.227458 EDT | AverageAbsY                29.2495
2017-06-11 03:34:52.227795 EDT | AverageAbsQYDiff            0.502757
2017-06-11 03:34:52.228117 EDT | AverageAction               0.997588
2017-06-11 03:34:52.228539 EDT | PolicyRegParamNorm         98.2746
2017-06-11 03:34:52.228851 EDT | QFunRegParamNorm          127.386
2017-06-11 03:34:52.229188 EDT | -----------------------  -----------
2017-06-11 03:34:52.229765 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1032 | Training started
2017-06-11 03:35:09.806645 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1032 | Training finished
2017-06-11 03:35:09.807581 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1032 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 03:35:09.807964 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1032 | Collecting samples for evaluation
2017-06-11 03:35:24.640776 EDT | -----------------------  -----------
2017-06-11 03:35:24.641646 EDT | Epoch                    1032
2017-06-11 03:35:24.642018 EDT | Iteration                1032
2017-06-11 03:35:24.642317 EDT | AverageReturn            1031.59
2017-06-11 03:35:24.642593 EDT | StdReturn                 104.433
2017-06-11 03:35:24.642856 EDT | MaxReturn                1284.25
2017-06-11 03:35:24.643142 EDT | MinReturn                 804.16
2017-06-11 03:35:24.643477 EDT | AverageEsReturn           339.486
2017-06-11 03:35:24.643887 EDT | StdEsReturn               184.848
2017-06-11 03:35:24.644289 EDT | MaxEsReturn               648.596
2017-06-11 03:35:24.644705 EDT | MinEsReturn                55.0878
2017-06-11 03:35:24.645051 EDT | AverageDiscountedReturn   252.706
2017-06-11 03:35:24.645367 EDT | AverageQLoss                2.11444
2017-06-11 03:35:24.645713 EDT | AveragePolicySurr         -29.5304
2017-06-11 03:35:24.646302 EDT | AverageQ                   29.2991
2017-06-11 03:35:24.646692 EDT | AverageAbsQ                29.3095
2017-06-11 03:35:24.647092 EDT | AverageY                   29.2989
2017-06-11 03:35:24.647923 EDT | AverageAbsY                29.3026
2017-06-11 03:35:24.651079 EDT | AverageAbsQYDiff            0.497095
2017-06-11 03:35:24.651482 EDT | AverageAction               0.997979
2017-06-11 03:35:24.651766 EDT | PolicyRegParamNorm         98.3701
2017-06-11 03:35:24.652160 EDT | QFunRegParamNorm          127.472
2017-06-11 03:35:24.652477 EDT | -----------------------  -----------
2017-06-11 03:35:24.653029 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1033 | Training started
2017-06-11 03:35:43.111968 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1033 | Training finished
2017-06-11 03:35:43.113108 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1033 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 03:35:43.113396 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1033 | Collecting samples for evaluation
2017-06-11 03:35:58.085541 EDT | -----------------------  -----------
2017-06-11 03:35:58.086035 EDT | Epoch                    1033
2017-06-11 03:35:58.086338 EDT | Iteration                1033
2017-06-11 03:35:58.086620 EDT | AverageReturn            1070.98
2017-06-11 03:35:58.086928 EDT | StdReturn                 173.914
2017-06-11 03:35:58.087362 EDT | MaxReturn                1482.5
2017-06-11 03:35:58.087717 EDT | MinReturn                 620.608
2017-06-11 03:35:58.088533 EDT | AverageEsReturn           215.175
2017-06-11 03:35:58.088858 EDT | StdEsReturn               205.658
2017-06-11 03:35:58.089602 EDT | MaxEsReturn               705.932
2017-06-11 03:35:58.092127 EDT | MinEsReturn                 6.92886
2017-06-11 03:35:58.092372 EDT | AverageDiscountedReturn   234.847
2017-06-11 03:35:58.092560 EDT | AverageQLoss                2.27374
2017-06-11 03:35:58.092759 EDT | AveragePolicySurr         -29.4807
2017-06-11 03:35:58.092943 EDT | AverageQ                   29.2385
2017-06-11 03:35:58.093125 EDT | AverageAbsQ                29.2517
2017-06-11 03:35:58.093305 EDT | AverageY                   29.2412
2017-06-11 03:35:58.093485 EDT | AverageAbsY                29.2462
2017-06-11 03:35:58.093726 EDT | AverageAbsQYDiff            0.51524
2017-06-11 03:35:58.093916 EDT | AverageAction               0.997927
2017-06-11 03:35:58.094097 EDT | PolicyRegParamNorm         98.3976
2017-06-11 03:35:58.094412 EDT | QFunRegParamNorm          127.514
2017-06-11 03:35:58.096696 EDT | -----------------------  -----------
2017-06-11 03:35:58.097260 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1034 | Training started
2017-06-11 03:36:18.922358 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1034 | Training finished
2017-06-11 03:36:18.923264 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1034 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 03:36:18.923600 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1034 | Collecting samples for evaluation
2017-06-11 03:36:35.268198 EDT | -----------------------  -----------
2017-06-11 03:36:35.269162 EDT | Epoch                    1034
2017-06-11 03:36:35.269535 EDT | Iteration                1034
2017-06-11 03:36:35.269896 EDT | AverageReturn            1606.81
2017-06-11 03:36:35.270228 EDT | StdReturn                 640.452
2017-06-11 03:36:35.270501 EDT | MaxReturn                2880.83
2017-06-11 03:36:35.270765 EDT | MinReturn                 884.021
2017-06-11 03:36:35.271021 EDT | AverageEsReturn           514.316
2017-06-11 03:36:35.271272 EDT | StdEsReturn               126.329
2017-06-11 03:36:35.271523 EDT | MaxEsReturn               744.774
2017-06-11 03:36:35.271774 EDT | MinEsReturn               329.816
2017-06-11 03:36:35.272032 EDT | AverageDiscountedReturn   237.221
2017-06-11 03:36:35.272281 EDT | AverageQLoss                2.07502
2017-06-11 03:36:35.272555 EDT | AveragePolicySurr         -29.5025
2017-06-11 03:36:35.272799 EDT | AverageQ                   29.2702
2017-06-11 03:36:35.273039 EDT | AverageAbsQ                29.282
2017-06-11 03:36:35.273279 EDT | AverageY                   29.2722
2017-06-11 03:36:35.273518 EDT | AverageAbsY                29.2766
2017-06-11 03:36:35.313310 EDT | AverageAbsQYDiff            0.501336
2017-06-11 03:36:35.313646 EDT | AverageAction               0.997776
2017-06-11 03:36:35.313910 EDT | PolicyRegParamNorm         98.4444
2017-06-11 03:36:35.314157 EDT | QFunRegParamNorm          127.602
2017-06-11 03:36:35.314401 EDT | -----------------------  -----------
2017-06-11 03:36:35.314789 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1035 | Training started
2017-06-11 03:36:53.873178 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1035 | Training finished
2017-06-11 03:36:53.874068 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1035 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 03:36:53.874349 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1035 | Collecting samples for evaluation
2017-06-11 03:37:08.765450 EDT | -----------------------  -----------
2017-06-11 03:37:08.766509 EDT | Epoch                    1035
2017-06-11 03:37:08.766976 EDT | Iteration                1035
2017-06-11 03:37:08.767429 EDT | AverageReturn             919.943
2017-06-11 03:37:08.767812 EDT | StdReturn                 357.623
2017-06-11 03:37:08.768226 EDT | MaxReturn                1871.3
2017-06-11 03:37:08.768672 EDT | MinReturn                 574.543
2017-06-11 03:37:08.769098 EDT | AverageEsReturn           405.664
2017-06-11 03:37:08.769531 EDT | StdEsReturn               333.079
2017-06-11 03:37:08.769982 EDT | MaxEsReturn               951.06
2017-06-11 03:37:08.770418 EDT | MinEsReturn                17.1169
2017-06-11 03:37:08.770787 EDT | AverageDiscountedReturn   219.413
2017-06-11 03:37:08.771117 EDT | AverageQLoss                2.23204
2017-06-11 03:37:08.771487 EDT | AveragePolicySurr         -29.4898
2017-06-11 03:37:08.771856 EDT | AverageQ                   29.2323
2017-06-11 03:37:08.772202 EDT | AverageAbsQ                29.2491
2017-06-11 03:37:08.772581 EDT | AverageY                   29.2318
2017-06-11 03:37:08.772953 EDT | AverageAbsY                29.238
2017-06-11 03:37:08.773391 EDT | AverageAbsQYDiff            0.515483
2017-06-11 03:37:08.773836 EDT | AverageAction               0.997657
2017-06-11 03:37:08.774289 EDT | PolicyRegParamNorm         98.4706
2017-06-11 03:37:08.774674 EDT | QFunRegParamNorm          127.673
2017-06-11 03:37:08.775044 EDT | -----------------------  -----------
2017-06-11 03:37:08.775577 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1036 | Training started
2017-06-11 03:37:26.768104 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1036 | Training finished
2017-06-11 03:37:26.768504 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1036 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 03:37:26.768795 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1036 | Collecting samples for evaluation
2017-06-11 03:37:42.724120 EDT | -----------------------  -----------
2017-06-11 03:37:42.724985 EDT | Epoch                    1036
2017-06-11 03:37:42.725325 EDT | Iteration                1036
2017-06-11 03:37:42.725620 EDT | AverageReturn            1625.59
2017-06-11 03:37:42.725923 EDT | StdReturn                 706.154
2017-06-11 03:37:42.726247 EDT | MaxReturn                2918.79
2017-06-11 03:37:42.726551 EDT | MinReturn                 622.24
2017-06-11 03:37:42.726813 EDT | AverageEsReturn           522.647
2017-06-11 03:37:42.727148 EDT | StdEsReturn               485.23
2017-06-11 03:37:42.727477 EDT | MaxEsReturn              1484.98
2017-06-11 03:37:42.727797 EDT | MinEsReturn               177.289
2017-06-11 03:37:42.728116 EDT | AverageDiscountedReturn   235.605
2017-06-11 03:37:42.728428 EDT | AverageQLoss                2.31789
2017-06-11 03:37:42.728743 EDT | AveragePolicySurr         -29.4873
2017-06-11 03:37:42.729057 EDT | AverageQ                   29.2489
2017-06-11 03:37:42.729365 EDT | AverageAbsQ                29.2652
2017-06-11 03:37:42.729708 EDT | AverageY                   29.2506
2017-06-11 03:37:42.730028 EDT | AverageAbsY                29.2573
2017-06-11 03:37:42.730349 EDT | AverageAbsQYDiff            0.512483
2017-06-11 03:37:42.730661 EDT | AverageAction               0.997584
2017-06-11 03:37:42.730942 EDT | PolicyRegParamNorm         98.5247
2017-06-11 03:37:42.731199 EDT | QFunRegParamNorm          127.744
2017-06-11 03:37:42.731511 EDT | -----------------------  -----------
2017-06-11 03:37:42.731954 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1037 | Training started
2017-06-11 03:38:01.012854 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1037 | Training finished
2017-06-11 03:38:01.014629 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1037 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 03:38:01.014859 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1037 | Collecting samples for evaluation
2017-06-11 03:38:15.342099 EDT | -----------------------  -----------
2017-06-11 03:38:15.345432 EDT | Epoch                    1037
2017-06-11 03:38:15.345802 EDT | Iteration                1037
2017-06-11 03:38:15.346132 EDT | AverageReturn            1239.04
2017-06-11 03:38:15.346459 EDT | StdReturn                 402.266
2017-06-11 03:38:15.346778 EDT | MaxReturn                2698.69
2017-06-11 03:38:15.350267 EDT | MinReturn                 592.354
2017-06-11 03:38:15.350589 EDT | AverageEsReturn           364.007
2017-06-11 03:38:15.350914 EDT | StdEsReturn               208.15
2017-06-11 03:38:15.351249 EDT | MaxEsReturn               689.538
2017-06-11 03:38:15.351558 EDT | MinEsReturn               114.03
2017-06-11 03:38:15.351874 EDT | AverageDiscountedReturn   229.212
2017-06-11 03:38:15.352184 EDT | AverageQLoss                2.39389
2017-06-11 03:38:15.352462 EDT | AveragePolicySurr         -29.3768
2017-06-11 03:38:15.352717 EDT | AverageQ                   29.1121
2017-06-11 03:38:15.352970 EDT | AverageAbsQ                29.128
2017-06-11 03:38:15.353212 EDT | AverageY                   29.114
2017-06-11 03:38:15.353454 EDT | AverageAbsY                29.1226
2017-06-11 03:38:15.353701 EDT | AverageAbsQYDiff            0.534039
2017-06-11 03:38:15.353957 EDT | AverageAction               0.99812
2017-06-11 03:38:15.354201 EDT | PolicyRegParamNorm         98.5929
2017-06-11 03:38:15.354441 EDT | QFunRegParamNorm          127.802
2017-06-11 03:38:15.354760 EDT | -----------------------  -----------
2017-06-11 03:38:15.355235 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1038 | Training started
2017-06-11 03:38:33.969048 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1038 | Training finished
2017-06-11 03:38:33.981837 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1038 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 03:38:33.982542 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1038 | Collecting samples for evaluation
2017-06-11 03:38:47.608445 EDT | -----------------------  -----------
2017-06-11 03:38:47.609403 EDT | Epoch                    1038
2017-06-11 03:38:47.609837 EDT | Iteration                1038
2017-06-11 03:38:47.610389 EDT | AverageReturn             978.831
2017-06-11 03:38:47.610828 EDT | StdReturn                 167.586
2017-06-11 03:38:47.611251 EDT | MaxReturn                1283.87
2017-06-11 03:38:47.611670 EDT | MinReturn                 661.691
2017-06-11 03:38:47.612059 EDT | AverageEsReturn           480.895
2017-06-11 03:38:47.612415 EDT | StdEsReturn               529.439
2017-06-11 03:38:47.612831 EDT | MaxEsReturn              1705.29
2017-06-11 03:38:47.613200 EDT | MinEsReturn                 7.0574
2017-06-11 03:38:47.613572 EDT | AverageDiscountedReturn   238.866
2017-06-11 03:38:47.614006 EDT | AverageQLoss                2.01013
2017-06-11 03:38:47.614377 EDT | AveragePolicySurr         -29.4373
2017-06-11 03:38:47.614715 EDT | AverageQ                   29.1773
2017-06-11 03:38:47.615070 EDT | AverageAbsQ                29.1921
2017-06-11 03:38:47.615484 EDT | AverageY                   29.1771
2017-06-11 03:38:47.615848 EDT | AverageAbsY                29.1834
2017-06-11 03:38:47.616269 EDT | AverageAbsQYDiff            0.508459
2017-06-11 03:38:47.616639 EDT | AverageAction               0.998038
2017-06-11 03:38:47.617074 EDT | PolicyRegParamNorm         98.5911
2017-06-11 03:38:47.617493 EDT | QFunRegParamNorm          127.877
2017-06-11 03:38:47.617918 EDT | -----------------------  -----------
2017-06-11 03:38:47.618499 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1039 | Training started
2017-06-11 03:39:04.751905 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1039 | Training finished
2017-06-11 03:39:04.752917 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1039 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 03:39:04.753221 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1039 | Collecting samples for evaluation
2017-06-11 03:39:18.390466 EDT | -----------------------  -----------
2017-06-11 03:39:18.391385 EDT | Epoch                    1039
2017-06-11 03:39:18.391760 EDT | Iteration                1039
2017-06-11 03:39:18.392118 EDT | AverageReturn             781.364
2017-06-11 03:39:18.392468 EDT | StdReturn                 260.427
2017-06-11 03:39:18.392816 EDT | MaxReturn                1663.36
2017-06-11 03:39:18.393163 EDT | MinReturn                 594.036
2017-06-11 03:39:18.393510 EDT | AverageEsReturn           272.88
2017-06-11 03:39:18.393871 EDT | StdEsReturn               341.675
2017-06-11 03:39:18.394272 EDT | MaxEsReturn               964.843
2017-06-11 03:39:18.394588 EDT | MinEsReturn                 6.71864
2017-06-11 03:39:18.394920 EDT | AverageDiscountedReturn   221.495
2017-06-11 03:39:18.395328 EDT | AverageQLoss                2.13419
2017-06-11 03:39:18.395642 EDT | AveragePolicySurr         -29.5665
2017-06-11 03:39:18.395987 EDT | AverageQ                   29.3266
2017-06-11 03:39:18.396401 EDT | AverageAbsQ                29.3388
2017-06-11 03:39:18.396726 EDT | AverageY                   29.3285
2017-06-11 03:39:18.397060 EDT | AverageAbsY                29.3337
2017-06-11 03:39:18.397464 EDT | AverageAbsQYDiff            0.492839
2017-06-11 03:39:18.397810 EDT | AverageAction               0.998026
2017-06-11 03:39:18.398149 EDT | PolicyRegParamNorm         98.5993
2017-06-11 03:39:18.398546 EDT | QFunRegParamNorm          127.955
2017-06-11 03:39:18.398878 EDT | -----------------------  -----------
2017-06-11 03:39:18.399469 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1040 | Training started
2017-06-11 03:39:34.857669 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1040 | Training finished
2017-06-11 03:39:34.858667 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1040 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 03:39:34.859066 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1040 | Collecting samples for evaluation
2017-06-11 03:39:50.234391 EDT | -----------------------  -----------
2017-06-11 03:39:50.235224 EDT | Epoch                    1040
2017-06-11 03:39:50.235496 EDT | Iteration                1040
2017-06-11 03:39:50.235765 EDT | AverageReturn            2127
2017-06-11 03:39:50.236039 EDT | StdReturn                1058.31
2017-06-11 03:39:50.236323 EDT | MaxReturn                3228.18
2017-06-11 03:39:50.236580 EDT | MinReturn                 627.881
2017-06-11 03:39:50.236843 EDT | AverageEsReturn           411.562
2017-06-11 03:39:50.237120 EDT | StdEsReturn               374.672
2017-06-11 03:39:50.237388 EDT | MaxEsReturn              1131.06
2017-06-11 03:39:50.237639 EDT | MinEsReturn                 5.37167
2017-06-11 03:39:50.237917 EDT | AverageDiscountedReturn   244.171
2017-06-11 03:39:50.238181 EDT | AverageQLoss                1.97288
2017-06-11 03:39:50.238440 EDT | AveragePolicySurr         -29.4518
2017-06-11 03:39:50.238704 EDT | AverageQ                   29.2115
2017-06-11 03:39:50.238972 EDT | AverageAbsQ                29.2282
2017-06-11 03:39:50.239243 EDT | AverageY                   29.2132
2017-06-11 03:39:50.239494 EDT | AverageAbsY                29.2203
2017-06-11 03:39:50.239753 EDT | AverageAbsQYDiff            0.492674
2017-06-11 03:39:50.240007 EDT | AverageAction               0.997329
2017-06-11 03:39:50.240261 EDT | PolicyRegParamNorm         98.7554
2017-06-11 03:39:50.240516 EDT | QFunRegParamNorm          127.977
2017-06-11 03:39:50.240770 EDT | -----------------------  -----------
2017-06-11 03:39:50.241186 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1041 | Training started
2017-06-11 03:40:06.750197 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1041 | Training finished
2017-06-11 03:40:06.751136 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1041 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 03:40:06.751522 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1041 | Collecting samples for evaluation
2017-06-11 03:40:20.323936 EDT | -----------------------  -----------
2017-06-11 03:40:20.324798 EDT | Epoch                    1041
2017-06-11 03:40:20.325079 EDT | Iteration                1041
2017-06-11 03:40:20.325338 EDT | AverageReturn            1531.24
2017-06-11 03:40:20.325586 EDT | StdReturn                 916.61
2017-06-11 03:40:20.325878 EDT | MaxReturn                3295.27
2017-06-11 03:40:20.326135 EDT | MinReturn                 674.127
2017-06-11 03:40:20.326391 EDT | AverageEsReturn           394.014
2017-06-11 03:40:20.326647 EDT | StdEsReturn               294.299
2017-06-11 03:40:20.326904 EDT | MaxEsReturn               969.588
2017-06-11 03:40:20.327169 EDT | MinEsReturn                18.4115
2017-06-11 03:40:20.328473 EDT | AverageDiscountedReturn   246.513
2017-06-11 03:40:20.329083 EDT | AverageQLoss                2.40726
2017-06-11 03:40:20.329988 EDT | AveragePolicySurr         -29.483
2017-06-11 03:40:20.331678 EDT | AverageQ                   29.2438
2017-06-11 03:40:20.333677 EDT | AverageAbsQ                29.2589
2017-06-11 03:40:20.334418 EDT | AverageY                   29.2452
2017-06-11 03:40:20.335063 EDT | AverageAbsY                29.252
2017-06-11 03:40:20.337025 EDT | AverageAbsQYDiff            0.512814
2017-06-11 03:40:20.337755 EDT | AverageAction               0.997719
2017-06-11 03:40:20.339741 EDT | PolicyRegParamNorm         98.7966
2017-06-11 03:40:20.340449 EDT | QFunRegParamNorm          128.065
2017-06-11 03:40:20.341099 EDT | -----------------------  -----------
2017-06-11 03:40:20.342218 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1042 | Training started
2017-06-11 03:40:37.820148 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1042 | Training finished
2017-06-11 03:40:37.821080 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1042 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 03:40:37.821471 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1042 | Collecting samples for evaluation
2017-06-11 03:40:49.622285 EDT | -----------------------  -----------
2017-06-11 03:40:49.623185 EDT | Epoch                    1042
2017-06-11 03:40:49.623501 EDT | Iteration                1042
2017-06-11 03:40:49.623825 EDT | AverageReturn             992.269
2017-06-11 03:40:49.624130 EDT | StdReturn                 469.566
2017-06-11 03:40:49.624321 EDT | MaxReturn                1642.7
2017-06-11 03:40:49.624650 EDT | MinReturn                   7.45179
2017-06-11 03:40:49.624973 EDT | AverageEsReturn           368.435
2017-06-11 03:40:49.625251 EDT | StdEsReturn               276.379
2017-06-11 03:40:49.625539 EDT | MaxEsReturn               853.103
2017-06-11 03:40:49.625791 EDT | MinEsReturn                 6.62667
2017-06-11 03:40:49.625948 EDT | AverageDiscountedReturn   211.48
2017-06-11 03:40:49.626185 EDT | AverageQLoss                1.90341
2017-06-11 03:40:49.626501 EDT | AveragePolicySurr         -29.4903
2017-06-11 03:40:49.626819 EDT | AverageQ                   29.2498
2017-06-11 03:40:49.627140 EDT | AverageAbsQ                29.2658
2017-06-11 03:40:49.627481 EDT | AverageY                   29.251
2017-06-11 03:40:49.627809 EDT | AverageAbsY                29.2589
2017-06-11 03:40:49.628130 EDT | AverageAbsQYDiff            0.486536
2017-06-11 03:40:49.628426 EDT | AverageAction               0.99802
2017-06-11 03:40:49.628693 EDT | PolicyRegParamNorm         98.8091
2017-06-11 03:40:49.628985 EDT | QFunRegParamNorm          128.123
2017-06-11 03:40:49.629268 EDT | -----------------------  -----------
2017-06-11 03:40:49.629666 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1043 | Training started
2017-06-11 03:41:05.961596 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1043 | Training finished
2017-06-11 03:41:05.962439 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1043 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 03:41:05.962744 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1043 | Collecting samples for evaluation
2017-06-11 03:41:18.618153 EDT | -----------------------  -----------
2017-06-11 03:41:18.619233 EDT | Epoch                    1043
2017-06-11 03:41:18.619696 EDT | Iteration                1043
2017-06-11 03:41:18.620146 EDT | AverageReturn            1570.53
2017-06-11 03:41:18.620593 EDT | StdReturn                 651.501
2017-06-11 03:41:18.621057 EDT | MaxReturn                3003.6
2017-06-11 03:41:18.621502 EDT | MinReturn                 944.811
2017-06-11 03:41:18.621958 EDT | AverageEsReturn           263.021
2017-06-11 03:41:18.622399 EDT | StdEsReturn               402.968
2017-06-11 03:41:18.622840 EDT | MaxEsReturn              1188.14
2017-06-11 03:41:18.623281 EDT | MinEsReturn                 5.8979
2017-06-11 03:41:18.623722 EDT | AverageDiscountedReturn   243.208
2017-06-11 03:41:18.624162 EDT | AverageQLoss                2.15491
2017-06-11 03:41:18.624606 EDT | AveragePolicySurr         -29.4941
2017-06-11 03:41:18.625048 EDT | AverageQ                   29.249
2017-06-11 03:41:18.625491 EDT | AverageAbsQ                29.2666
2017-06-11 03:41:18.625947 EDT | AverageY                   29.2514
2017-06-11 03:41:18.626390 EDT | AverageAbsY                29.2613
2017-06-11 03:41:18.626833 EDT | AverageAbsQYDiff            0.513753
2017-06-11 03:41:18.627274 EDT | AverageAction               0.997818
2017-06-11 03:41:18.627717 EDT | PolicyRegParamNorm         98.822
2017-06-11 03:41:18.628158 EDT | QFunRegParamNorm          128.17
2017-06-11 03:41:18.628600 EDT | -----------------------  -----------
2017-06-11 03:41:18.629184 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1044 | Training started
2017-06-11 03:41:35.764360 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1044 | Training finished
2017-06-11 03:41:35.772971 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1044 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 03:41:35.773264 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1044 | Collecting samples for evaluation
2017-06-11 03:41:50.762111 EDT | -----------------------  -----------
2017-06-11 03:41:50.765938 EDT | Epoch                    1044
2017-06-11 03:41:50.766311 EDT | Iteration                1044
2017-06-11 03:41:50.769531 EDT | AverageReturn            2759.45
2017-06-11 03:41:50.769826 EDT | StdReturn                 707.98
2017-06-11 03:41:50.770124 EDT | MaxReturn                3204.19
2017-06-11 03:41:50.770462 EDT | MinReturn                1066.85
2017-06-11 03:41:50.770784 EDT | AverageEsReturn           221.1
2017-06-11 03:41:50.771098 EDT | StdEsReturn               207.069
2017-06-11 03:41:50.771436 EDT | MaxEsReturn               634.949
2017-06-11 03:41:50.771781 EDT | MinEsReturn                 7.16124
2017-06-11 03:41:50.772121 EDT | AverageDiscountedReturn   252.429
2017-06-11 03:41:50.772468 EDT | AverageQLoss                2.0827
2017-06-11 03:41:50.772807 EDT | AveragePolicySurr         -29.4215
2017-06-11 03:41:50.773146 EDT | AverageQ                   29.1729
2017-06-11 03:41:50.773493 EDT | AverageAbsQ                29.1875
2017-06-11 03:41:50.773849 EDT | AverageY                   29.1717
2017-06-11 03:41:50.774186 EDT | AverageAbsY                29.1795
2017-06-11 03:41:50.774525 EDT | AverageAbsQYDiff            0.501209
2017-06-11 03:41:50.774864 EDT | AverageAction               0.997762
2017-06-11 03:41:50.775207 EDT | PolicyRegParamNorm         98.8593
2017-06-11 03:41:50.775550 EDT | QFunRegParamNorm          128.216
2017-06-11 03:41:50.775888 EDT | -----------------------  -----------
2017-06-11 03:41:50.776401 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1045 | Training started
2017-06-11 03:42:06.818114 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1045 | Training finished
2017-06-11 03:42:06.820005 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1045 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 03:42:06.820220 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1045 | Collecting samples for evaluation
2017-06-11 03:42:23.062382 EDT | -----------------------  -----------
2017-06-11 03:42:23.063253 EDT | Epoch                    1045
2017-06-11 03:42:23.063811 EDT | Iteration                1045
2017-06-11 03:42:23.064150 EDT | AverageReturn               7.42472
2017-06-11 03:42:23.064487 EDT | StdReturn                   0.143543
2017-06-11 03:42:23.069512 EDT | MaxReturn                   7.65511
2017-06-11 03:42:23.069881 EDT | MinReturn                   6.02509
2017-06-11 03:42:23.070221 EDT | AverageEsReturn           193.922
2017-06-11 03:42:23.071234 EDT | StdEsReturn               228.917
2017-06-11 03:42:23.072411 EDT | MaxEsReturn               647.248
2017-06-11 03:42:23.073609 EDT | MinEsReturn                 7.11824
2017-06-11 03:42:23.075021 EDT | AverageDiscountedReturn     7.16167
2017-06-11 03:42:23.076263 EDT | AverageQLoss                1.99303
2017-06-11 03:42:23.082645 EDT | AveragePolicySurr         -29.4225
2017-06-11 03:42:23.084011 EDT | AverageQ                   29.1744
2017-06-11 03:42:23.085381 EDT | AverageAbsQ                29.1949
2017-06-11 03:42:23.086767 EDT | AverageY                   29.1766
2017-06-11 03:42:23.088178 EDT | AverageAbsY                29.1852
2017-06-11 03:42:23.089644 EDT | AverageAbsQYDiff            0.503073
2017-06-11 03:42:23.090878 EDT | AverageAction               1
2017-06-11 03:42:23.092154 EDT | PolicyRegParamNorm         98.9178
2017-06-11 03:42:23.093619 EDT | QFunRegParamNorm          128.241
2017-06-11 03:42:23.094861 EDT | -----------------------  -----------
2017-06-11 03:42:23.096653 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1046 | Training started
2017-06-11 03:42:39.909678 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1046 | Training finished
2017-06-11 03:42:39.911053 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1046 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 03:42:39.911455 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1046 | Collecting samples for evaluation
2017-06-11 03:42:53.297255 EDT | -----------------------  -----------
2017-06-11 03:42:53.298098 EDT | Epoch                    1046
2017-06-11 03:42:53.298394 EDT | Iteration                1046
2017-06-11 03:42:53.298699 EDT | AverageReturn            2214.66
2017-06-11 03:42:53.299027 EDT | StdReturn                 995.894
2017-06-11 03:42:53.299330 EDT | MaxReturn                3126.43
2017-06-11 03:42:53.299580 EDT | MinReturn                 428.436
2017-06-11 03:42:53.299830 EDT | AverageEsReturn           263.411
2017-06-11 03:42:53.300115 EDT | StdEsReturn               243.371
2017-06-11 03:42:53.300402 EDT | MaxEsReturn               619.581
2017-06-11 03:42:53.300692 EDT | MinEsReturn                 4.1346
2017-06-11 03:42:53.300948 EDT | AverageDiscountedReturn   229.903
2017-06-11 03:42:53.301201 EDT | AverageQLoss                2.28758
2017-06-11 03:42:53.301452 EDT | AveragePolicySurr         -29.4734
2017-06-11 03:42:53.301767 EDT | AverageQ                   29.2274
2017-06-11 03:42:53.302072 EDT | AverageAbsQ                29.2433
2017-06-11 03:42:53.302353 EDT | AverageY                   29.2288
2017-06-11 03:42:53.302679 EDT | AverageAbsY                29.2368
2017-06-11 03:42:53.302968 EDT | AverageAbsQYDiff            0.512297
2017-06-11 03:42:53.303273 EDT | AverageAction               0.997355
2017-06-11 03:42:53.303610 EDT | PolicyRegParamNorm         98.9494
2017-06-11 03:42:53.303933 EDT | QFunRegParamNorm          128.339
2017-06-11 03:42:53.304251 EDT | -----------------------  -----------
2017-06-11 03:42:53.304803 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1047 | Training started
2017-06-11 03:43:10.743499 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1047 | Training finished
2017-06-11 03:43:10.744860 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1047 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 03:43:10.745187 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1047 | Collecting samples for evaluation
2017-06-11 03:43:25.528714 EDT | -----------------------  -----------
2017-06-11 03:43:25.529095 EDT | Epoch                    1047
2017-06-11 03:43:25.529366 EDT | Iteration                1047
2017-06-11 03:43:25.529628 EDT | AverageReturn             804.069
2017-06-11 03:43:25.539377 EDT | StdReturn                1010.58
2017-06-11 03:43:25.539643 EDT | MaxReturn                3262.84
2017-06-11 03:43:25.539902 EDT | MinReturn                 156.73
2017-06-11 03:43:25.540158 EDT | AverageEsReturn           253.989
2017-06-11 03:43:25.540419 EDT | StdEsReturn               192.001
2017-06-11 03:43:25.540674 EDT | MaxEsReturn               680.002
2017-06-11 03:43:25.540928 EDT | MinEsReturn                11.6326
2017-06-11 03:43:25.541182 EDT | AverageDiscountedReturn   156.647
2017-06-11 03:43:25.541436 EDT | AverageQLoss                2.1733
2017-06-11 03:43:25.541688 EDT | AveragePolicySurr         -29.4962
2017-06-11 03:43:25.549678 EDT | AverageQ                   29.2395
2017-06-11 03:43:25.554518 EDT | AverageAbsQ                29.2535
2017-06-11 03:43:25.554795 EDT | AverageY                   29.2406
2017-06-11 03:43:25.555059 EDT | AverageAbsY                29.2481
2017-06-11 03:43:25.555317 EDT | AverageAbsQYDiff            0.515932
2017-06-11 03:43:25.555577 EDT | AverageAction               0.997947
2017-06-11 03:43:25.555831 EDT | PolicyRegParamNorm         98.957
2017-06-11 03:43:25.556085 EDT | QFunRegParamNorm          128.446
2017-06-11 03:43:25.556338 EDT | -----------------------  -----------
2017-06-11 03:43:25.556735 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1048 | Training started
2017-06-11 03:43:42.480576 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1048 | Training finished
2017-06-11 03:43:42.481577 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1048 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 03:43:42.481970 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1048 | Collecting samples for evaluation
2017-06-11 03:43:56.667040 EDT | -----------------------  -----------
2017-06-11 03:43:56.667659 EDT | Epoch                    1048
2017-06-11 03:43:56.668111 EDT | Iteration                1048
2017-06-11 03:43:56.668553 EDT | AverageReturn              34.9457
2017-06-11 03:43:56.668998 EDT | StdReturn                   0.67223
2017-06-11 03:43:56.669437 EDT | MaxReturn                  35.7698
2017-06-11 03:43:56.669898 EDT | MinReturn                  32.6152
2017-06-11 03:43:56.670345 EDT | AverageEsReturn           144.697
2017-06-11 03:43:56.670791 EDT | StdEsReturn               150.364
2017-06-11 03:43:56.671231 EDT | MaxEsReturn               639.173
2017-06-11 03:43:56.671674 EDT | MinEsReturn                11.318
2017-06-11 03:43:56.672113 EDT | AverageDiscountedReturn    31.1893
2017-06-11 03:43:56.672552 EDT | AverageQLoss                1.91891
2017-06-11 03:43:56.672988 EDT | AveragePolicySurr         -29.5438
2017-06-11 03:43:56.673426 EDT | AverageQ                   29.2757
2017-06-11 03:43:56.673911 EDT | AverageAbsQ                29.289
2017-06-11 03:43:56.674347 EDT | AverageY                   29.2778
2017-06-11 03:43:56.674781 EDT | AverageAbsY                29.2823
2017-06-11 03:43:56.675223 EDT | AverageAbsQYDiff            0.49173
2017-06-11 03:43:56.675657 EDT | AverageAction               0.999985
2017-06-11 03:43:56.676093 EDT | PolicyRegParamNorm         98.9403
2017-06-11 03:43:56.676535 EDT | QFunRegParamNorm          128.481
2017-06-11 03:43:56.676971 EDT | -----------------------  -----------
2017-06-11 03:43:56.677601 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1049 | Training started
2017-06-11 03:44:12.835551 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1049 | Training finished
2017-06-11 03:44:12.836653 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1049 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 03:44:12.837020 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1049 | Collecting samples for evaluation
2017-06-11 03:44:26.707009 EDT | -----------------------  -----------
2017-06-11 03:44:26.707384 EDT | Epoch                    1049
2017-06-11 03:44:26.707663 EDT | Iteration                1049
2017-06-11 03:44:26.708174 EDT | AverageReturn             852.764
2017-06-11 03:44:26.708545 EDT | StdReturn                 953.096
2017-06-11 03:44:26.708896 EDT | MaxReturn                2839.03
2017-06-11 03:44:26.709239 EDT | MinReturn                  28.992
2017-06-11 03:44:26.709608 EDT | AverageEsReturn           337.253
2017-06-11 03:44:26.710046 EDT | StdEsReturn               223.29
2017-06-11 03:44:26.710451 EDT | MaxEsReturn               623.026
2017-06-11 03:44:26.710902 EDT | MinEsReturn                35.346
2017-06-11 03:44:26.711316 EDT | AverageDiscountedReturn   130.402
2017-06-11 03:44:26.711745 EDT | AverageQLoss                2.12021
2017-06-11 03:44:26.712206 EDT | AveragePolicySurr         -29.5091
2017-06-11 03:44:26.712615 EDT | AverageQ                   29.2708
2017-06-11 03:44:26.713085 EDT | AverageAbsQ                29.2905
2017-06-11 03:44:26.713489 EDT | AverageY                   29.2733
2017-06-11 03:44:26.713958 EDT | AverageAbsY                29.2804
2017-06-11 03:44:26.714366 EDT | AverageAbsQYDiff            0.500196
2017-06-11 03:44:26.714768 EDT | AverageAction               0.997974
2017-06-11 03:44:26.715491 EDT | PolicyRegParamNorm         98.9409
2017-06-11 03:44:26.716367 EDT | QFunRegParamNorm          128.51
2017-06-11 03:44:26.716988 EDT | -----------------------  -----------
2017-06-11 03:44:26.718184 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1050 | Training started
2017-06-11 03:44:44.133465 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1050 | Training finished
2017-06-11 03:44:44.134261 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1050 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 03:44:44.134725 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1050 | Collecting samples for evaluation
2017-06-11 03:44:58.029349 EDT | -----------------------  -----------
2017-06-11 03:44:58.030452 EDT | Epoch                    1050
2017-06-11 03:44:58.030800 EDT | Iteration                1050
2017-06-11 03:44:58.031131 EDT | AverageReturn            1256.17
2017-06-11 03:44:58.031399 EDT | StdReturn                 261.259
2017-06-11 03:44:58.031598 EDT | MaxReturn                1929.75
2017-06-11 03:44:58.031794 EDT | MinReturn                 951.38
2017-06-11 03:44:58.032042 EDT | AverageEsReturn           614.31
2017-06-11 03:44:58.032332 EDT | StdEsReturn               318.56
2017-06-11 03:44:58.032527 EDT | MaxEsReturn               898.672
2017-06-11 03:44:58.032852 EDT | MinEsReturn                34.6714
2017-06-11 03:44:58.033128 EDT | AverageDiscountedReturn   237.544
2017-06-11 03:44:58.033323 EDT | AverageQLoss                2.11252
2017-06-11 03:44:58.033613 EDT | AveragePolicySurr         -29.5213
2017-06-11 03:44:58.035275 EDT | AverageQ                   29.2454
2017-06-11 03:44:58.035477 EDT | AverageAbsQ                29.2633
2017-06-11 03:44:58.035942 EDT | AverageY                   29.246
2017-06-11 03:44:58.036368 EDT | AverageAbsY                29.2558
2017-06-11 03:44:58.036738 EDT | AverageAbsQYDiff            0.51116
2017-06-11 03:44:58.037112 EDT | AverageAction               0.997765
2017-06-11 03:44:58.037496 EDT | PolicyRegParamNorm         98.9874
2017-06-11 03:44:58.037912 EDT | QFunRegParamNorm          128.552
2017-06-11 03:44:58.038288 EDT | -----------------------  -----------
2017-06-11 03:44:58.038841 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1051 | Training started
2017-06-11 03:45:14.469055 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1051 | Training finished
2017-06-11 03:45:14.469464 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1051 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 03:45:14.469831 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1051 | Collecting samples for evaluation
2017-06-11 03:45:27.489052 EDT | -----------------------  -----------
2017-06-11 03:45:27.495265 EDT | Epoch                    1051
2017-06-11 03:45:27.495642 EDT | Iteration                1051
2017-06-11 03:45:27.496204 EDT | AverageReturn            1142.27
2017-06-11 03:45:27.496817 EDT | StdReturn                 202.459
2017-06-11 03:45:27.497426 EDT | MaxReturn                1659.84
2017-06-11 03:45:27.498039 EDT | MinReturn                 661.435
2017-06-11 03:45:27.498645 EDT | AverageEsReturn           236.559
2017-06-11 03:45:27.499299 EDT | StdEsReturn               194.873
2017-06-11 03:45:27.499916 EDT | MaxEsReturn               579.424
2017-06-11 03:45:27.500520 EDT | MinEsReturn                21.2194
2017-06-11 03:45:27.501121 EDT | AverageDiscountedReturn   230.429
2017-06-11 03:45:27.501781 EDT | AverageQLoss                2.33749
2017-06-11 03:45:27.502361 EDT | AveragePolicySurr         -29.5222
2017-06-11 03:45:27.502961 EDT | AverageQ                   29.2795
2017-06-11 03:45:27.503559 EDT | AverageAbsQ                29.2972
2017-06-11 03:45:27.504157 EDT | AverageY                   29.2805
2017-06-11 03:45:27.504755 EDT | AverageAbsY                29.2887
2017-06-11 03:45:27.505348 EDT | AverageAbsQYDiff            0.520998
2017-06-11 03:45:27.505947 EDT | AverageAction               0.997867
2017-06-11 03:45:27.506548 EDT | PolicyRegParamNorm         99.0416
2017-06-11 03:45:27.507146 EDT | QFunRegParamNorm          128.605
2017-06-11 03:45:27.507862 EDT | -----------------------  -----------
2017-06-11 03:45:27.508654 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1052 | Training started
2017-06-11 03:45:44.278545 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1052 | Training finished
2017-06-11 03:45:44.278948 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1052 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 03:45:44.279313 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1052 | Collecting samples for evaluation
2017-06-11 03:45:57.486298 EDT | -----------------------  -----------
2017-06-11 03:45:57.487417 EDT | Epoch                    1052
2017-06-11 03:45:57.487885 EDT | Iteration                1052
2017-06-11 03:45:57.488335 EDT | AverageReturn             863.019
2017-06-11 03:45:57.488783 EDT | StdReturn                 242.288
2017-06-11 03:45:57.489230 EDT | MaxReturn                1497.3
2017-06-11 03:45:57.489673 EDT | MinReturn                 639.79
2017-06-11 03:45:57.490147 EDT | AverageEsReturn           310.424
2017-06-11 03:45:57.490594 EDT | StdEsReturn               266.389
2017-06-11 03:45:57.491039 EDT | MaxEsReturn               816.997
2017-06-11 03:45:57.491487 EDT | MinEsReturn                37.5399
2017-06-11 03:45:57.491931 EDT | AverageDiscountedReturn   221.547
2017-06-11 03:45:57.492368 EDT | AverageQLoss                2.28492
2017-06-11 03:45:57.492807 EDT | AveragePolicySurr         -29.4522
2017-06-11 03:45:57.493259 EDT | AverageQ                   29.2017
2017-06-11 03:45:57.493717 EDT | AverageAbsQ                29.2193
2017-06-11 03:45:57.494096 EDT | AverageY                   29.2036
2017-06-11 03:45:57.494485 EDT | AverageAbsY                29.2102
2017-06-11 03:45:57.494886 EDT | AverageAbsQYDiff            0.51747
2017-06-11 03:45:57.495271 EDT | AverageAction               0.997659
2017-06-11 03:45:57.495632 EDT | PolicyRegParamNorm         99.0539
2017-06-11 03:45:57.496025 EDT | QFunRegParamNorm          128.676
2017-06-11 03:45:57.496380 EDT | -----------------------  -----------
2017-06-11 03:45:57.496913 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1053 | Training started
2017-06-11 03:46:14.108986 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1053 | Training finished
2017-06-11 03:46:14.109882 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1053 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 03:46:14.110218 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1053 | Collecting samples for evaluation
2017-06-11 03:46:27.603183 EDT | -----------------------  -----------
2017-06-11 03:46:27.603737 EDT | Epoch                    1053
2017-06-11 03:46:27.604171 EDT | Iteration                1053
2017-06-11 03:46:27.604364 EDT | AverageReturn            1785.6
2017-06-11 03:46:27.606049 EDT | StdReturn                 803.435
2017-06-11 03:46:27.606230 EDT | MaxReturn                2992.31
2017-06-11 03:46:27.606402 EDT | MinReturn                  99.5929
2017-06-11 03:46:27.606612 EDT | AverageEsReturn           713.026
2017-06-11 03:46:27.606806 EDT | StdEsReturn               552.506
2017-06-11 03:46:27.607073 EDT | MaxEsReturn              1615.91
2017-06-11 03:46:27.607235 EDT | MinEsReturn               158.001
2017-06-11 03:46:27.607393 EDT | AverageDiscountedReturn   223.843
2017-06-11 03:46:27.607568 EDT | AverageQLoss                1.98078
2017-06-11 03:46:27.607778 EDT | AveragePolicySurr         -29.509
2017-06-11 03:46:27.607961 EDT | AverageQ                   29.2719
2017-06-11 03:46:27.608120 EDT | AverageAbsQ                29.2905
2017-06-11 03:46:27.608277 EDT | AverageY                   29.2734
2017-06-11 03:46:27.608435 EDT | AverageAbsY                29.2841
2017-06-11 03:46:27.608648 EDT | AverageAbsQYDiff            0.503395
2017-06-11 03:46:27.608813 EDT | AverageAction               0.997898
2017-06-11 03:46:27.608998 EDT | PolicyRegParamNorm         99.1575
2017-06-11 03:46:27.609182 EDT | QFunRegParamNorm          128.717
2017-06-11 03:46:27.609395 EDT | -----------------------  -----------
2017-06-11 03:46:27.609743 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1054 | Training started
2017-06-11 03:46:43.539675 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1054 | Training finished
2017-06-11 03:46:43.540425 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1054 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 03:46:43.540618 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1054 | Collecting samples for evaluation
2017-06-11 03:46:56.960073 EDT | -----------------------  -----------
2017-06-11 03:46:56.961977 EDT | Epoch                    1054
2017-06-11 03:46:56.962283 EDT | Iteration                1054
2017-06-11 03:46:56.962644 EDT | AverageReturn            1612.56
2017-06-11 03:46:56.962985 EDT | StdReturn                 741.615
2017-06-11 03:46:56.963325 EDT | MaxReturn                2601.65
2017-06-11 03:46:56.963657 EDT | MinReturn                 271.964
2017-06-11 03:46:56.963986 EDT | AverageEsReturn           387.652
2017-06-11 03:46:56.964571 EDT | StdEsReturn               428.001
2017-06-11 03:46:56.964805 EDT | MaxEsReturn              1359.05
2017-06-11 03:46:56.965287 EDT | MinEsReturn                 8.6829
2017-06-11 03:46:56.965620 EDT | AverageDiscountedReturn   210.587
2017-06-11 03:46:56.965934 EDT | AverageQLoss                1.86806
2017-06-11 03:46:56.966243 EDT | AveragePolicySurr         -29.4989
2017-06-11 03:46:56.966587 EDT | AverageQ                   29.2626
2017-06-11 03:46:56.966950 EDT | AverageAbsQ                29.2777
2017-06-11 03:46:56.967263 EDT | AverageY                   29.264
2017-06-11 03:46:56.967642 EDT | AverageAbsY                29.2697
2017-06-11 03:46:56.967971 EDT | AverageAbsQYDiff            0.486249
2017-06-11 03:46:56.968291 EDT | AverageAction               0.997831
2017-06-11 03:46:56.968611 EDT | PolicyRegParamNorm         99.2324
2017-06-11 03:46:56.968935 EDT | QFunRegParamNorm          128.774
2017-06-11 03:46:56.969232 EDT | -----------------------  -----------
2017-06-11 03:46:56.969715 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1055 | Training started
2017-06-11 03:47:13.217242 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1055 | Training finished
2017-06-11 03:47:13.218848 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1055 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 03:47:13.219401 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1055 | Collecting samples for evaluation
2017-06-11 03:47:27.862088 EDT | -----------------------  -----------
2017-06-11 03:47:27.863014 EDT | Epoch                    1055
2017-06-11 03:47:27.863303 EDT | Iteration                1055
2017-06-11 03:47:27.863626 EDT | AverageReturn            1598.69
2017-06-11 03:47:27.863949 EDT | StdReturn                 541.371
2017-06-11 03:47:27.864289 EDT | MaxReturn                2403.17
2017-06-11 03:47:27.864625 EDT | MinReturn                 731.862
2017-06-11 03:47:27.864921 EDT | AverageEsReturn           190.717
2017-06-11 03:47:27.865502 EDT | StdEsReturn               174.455
2017-06-11 03:47:27.865746 EDT | MaxEsReturn               615.298
2017-06-11 03:47:27.866489 EDT | MinEsReturn                 6.29114
2017-06-11 03:47:27.866773 EDT | AverageDiscountedReturn   209.2
2017-06-11 03:47:27.867083 EDT | AverageQLoss                2.30666
2017-06-11 03:47:27.867539 EDT | AveragePolicySurr         -29.4195
2017-06-11 03:47:27.869300 EDT | AverageQ                   29.1981
2017-06-11 03:47:27.869627 EDT | AverageAbsQ                29.2143
2017-06-11 03:47:27.870001 EDT | AverageY                   29.1993
2017-06-11 03:47:27.870322 EDT | AverageAbsY                29.2087
2017-06-11 03:47:27.870639 EDT | AverageAbsQYDiff            0.530673
2017-06-11 03:47:27.870967 EDT | AverageAction               0.997527
2017-06-11 03:47:27.871289 EDT | PolicyRegParamNorm         99.2892
2017-06-11 03:47:27.871609 EDT | QFunRegParamNorm          128.831
2017-06-11 03:47:27.871923 EDT | -----------------------  -----------
2017-06-11 03:47:27.872506 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1056 | Training started
2017-06-11 03:47:46.032158 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1056 | Training finished
2017-06-11 03:47:46.032648 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1056 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 03:47:46.033014 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1056 | Collecting samples for evaluation
2017-06-11 03:47:59.800311 EDT | -----------------------  -----------
2017-06-11 03:47:59.801264 EDT | Epoch                    1056
2017-06-11 03:47:59.801636 EDT | Iteration                1056
2017-06-11 03:47:59.801995 EDT | AverageReturn            1741.67
2017-06-11 03:47:59.802338 EDT | StdReturn                 745.531
2017-06-11 03:47:59.802693 EDT | MaxReturn                2761.32
2017-06-11 03:47:59.803040 EDT | MinReturn                 266.068
2017-06-11 03:47:59.803382 EDT | AverageEsReturn           803.267
2017-06-11 03:47:59.803726 EDT | StdEsReturn               215.776
2017-06-11 03:47:59.804071 EDT | MaxEsReturn              1147.65
2017-06-11 03:47:59.804416 EDT | MinEsReturn               564.278
2017-06-11 03:47:59.804756 EDT | AverageDiscountedReturn   222.834
2017-06-11 03:47:59.805098 EDT | AverageQLoss                2.02436
2017-06-11 03:47:59.805442 EDT | AveragePolicySurr         -29.5297
2017-06-11 03:47:59.805801 EDT | AverageQ                   29.2906
2017-06-11 03:47:59.806144 EDT | AverageAbsQ                29.3077
2017-06-11 03:47:59.806485 EDT | AverageY                   29.2921
2017-06-11 03:47:59.806829 EDT | AverageAbsY                29.3034
2017-06-11 03:47:59.807171 EDT | AverageAbsQYDiff            0.505579
2017-06-11 03:47:59.807513 EDT | AverageAction               0.996935
2017-06-11 03:47:59.807853 EDT | PolicyRegParamNorm         99.2479
2017-06-11 03:47:59.808194 EDT | QFunRegParamNorm          128.868
2017-06-11 03:47:59.808540 EDT | -----------------------  -----------
2017-06-11 03:47:59.809054 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1057 | Training started
2017-06-11 03:48:16.672298 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1057 | Training finished
2017-06-11 03:48:16.672752 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1057 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 03:48:16.673082 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1057 | Collecting samples for evaluation
2017-06-11 03:48:31.342485 EDT | -----------------------  -----------
2017-06-11 03:48:31.343426 EDT | Epoch                    1057
2017-06-11 03:48:31.343762 EDT | Iteration                1057
2017-06-11 03:48:31.344082 EDT | AverageReturn            1428.32
2017-06-11 03:48:31.344400 EDT | StdReturn                1318.64
2017-06-11 03:48:31.344716 EDT | MaxReturn                3331.2
2017-06-11 03:48:31.345031 EDT | MinReturn                 274.133
2017-06-11 03:48:31.345345 EDT | AverageEsReturn           296.738
2017-06-11 03:48:31.345659 EDT | StdEsReturn               253.518
2017-06-11 03:48:31.345984 EDT | MaxEsReturn               764.566
2017-06-11 03:48:31.346570 EDT | MinEsReturn                 7.03285
2017-06-11 03:48:31.347395 EDT | AverageDiscountedReturn   197.968
2017-06-11 03:48:31.348211 EDT | AverageQLoss                2.25216
2017-06-11 03:48:31.349026 EDT | AveragePolicySurr         -29.5213
2017-06-11 03:48:31.349860 EDT | AverageQ                   29.2689
2017-06-11 03:48:31.350698 EDT | AverageAbsQ                29.2864
2017-06-11 03:48:31.351509 EDT | AverageY                   29.2712
2017-06-11 03:48:31.352321 EDT | AverageAbsY                29.2803
2017-06-11 03:48:31.353129 EDT | AverageAbsQYDiff            0.52374
2017-06-11 03:48:31.353941 EDT | AverageAction               0.997469
2017-06-11 03:48:31.354775 EDT | PolicyRegParamNorm         99.2888
2017-06-11 03:48:31.355592 EDT | QFunRegParamNorm          128.951
2017-06-11 03:48:31.356406 EDT | -----------------------  -----------
2017-06-11 03:48:31.357382 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1058 | Training started
2017-06-11 03:48:48.591508 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1058 | Training finished
2017-06-11 03:48:48.592313 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1058 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 03:48:48.592689 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1058 | Collecting samples for evaluation
2017-06-11 03:49:03.788712 EDT | -----------------------  -----------
2017-06-11 03:49:03.789629 EDT | Epoch                    1058
2017-06-11 03:49:03.790049 EDT | Iteration                1058
2017-06-11 03:49:03.790412 EDT | AverageReturn            1703.2
2017-06-11 03:49:03.790736 EDT | StdReturn                 689.78
2017-06-11 03:49:03.791117 EDT | MaxReturn                2907.41
2017-06-11 03:49:03.791488 EDT | MinReturn                 883.979
2017-06-11 03:49:03.791866 EDT | AverageEsReturn           259.39
2017-06-11 03:49:03.792733 EDT | StdEsReturn               160.346
2017-06-11 03:49:03.793122 EDT | MaxEsReturn               541.669
2017-06-11 03:49:03.793496 EDT | MinEsReturn                77.7323
2017-06-11 03:49:03.794494 EDT | AverageDiscountedReturn   234.528
2017-06-11 03:49:03.798452 EDT | AverageQLoss                2.00645
2017-06-11 03:49:03.798941 EDT | AveragePolicySurr         -29.4267
2017-06-11 03:49:03.799944 EDT | AverageQ                   29.1707
2017-06-11 03:49:03.800415 EDT | AverageAbsQ                29.189
2017-06-11 03:49:03.800861 EDT | AverageY                   29.1697
2017-06-11 03:49:03.801274 EDT | AverageAbsY                29.1769
2017-06-11 03:49:03.801748 EDT | AverageAbsQYDiff            0.517086
2017-06-11 03:49:03.802212 EDT | AverageAction               0.998016
2017-06-11 03:49:03.802611 EDT | PolicyRegParamNorm         99.3297
2017-06-11 03:49:03.803076 EDT | QFunRegParamNorm          129.009
2017-06-11 03:49:03.804089 EDT | -----------------------  -----------
2017-06-11 03:49:03.807182 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1059 | Training started
2017-06-11 03:49:20.039552 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1059 | Training finished
2017-06-11 03:49:20.040404 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1059 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 03:49:20.040685 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1059 | Collecting samples for evaluation
2017-06-11 03:49:35.060177 EDT | -----------------------  -----------
2017-06-11 03:49:35.061274 EDT | Epoch                    1059
2017-06-11 03:49:35.061654 EDT | Iteration                1059
2017-06-11 03:49:35.062097 EDT | AverageReturn            1678.36
2017-06-11 03:49:35.062524 EDT | StdReturn                 703.598
2017-06-11 03:49:35.062941 EDT | MaxReturn                2884.74
2017-06-11 03:49:35.063359 EDT | MinReturn                 982.527
2017-06-11 03:49:35.063812 EDT | AverageEsReturn           638.425
2017-06-11 03:49:35.064252 EDT | StdEsReturn               425.274
2017-06-11 03:49:35.064694 EDT | MaxEsReturn              1304.06
2017-06-11 03:49:35.065131 EDT | MinEsReturn                62.8038
2017-06-11 03:49:35.065572 EDT | AverageDiscountedReturn   234.226
2017-06-11 03:49:35.066020 EDT | AverageQLoss                2.27241
2017-06-11 03:49:35.066459 EDT | AveragePolicySurr         -29.5185
2017-06-11 03:49:35.066898 EDT | AverageQ                   29.2557
2017-06-11 03:49:35.067337 EDT | AverageAbsQ                29.2732
2017-06-11 03:49:35.074434 EDT | AverageY                   29.2587
2017-06-11 03:49:35.075257 EDT | AverageAbsY                29.2685
2017-06-11 03:49:35.076100 EDT | AverageAbsQYDiff            0.527173
2017-06-11 03:49:35.076803 EDT | AverageAction               0.997265
2017-06-11 03:49:35.077504 EDT | PolicyRegParamNorm         99.4017
2017-06-11 03:49:35.078685 EDT | QFunRegParamNorm          129.045
2017-06-11 03:49:35.079382 EDT | -----------------------  -----------
2017-06-11 03:49:35.080383 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1060 | Training started
2017-06-11 03:49:52.949165 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1060 | Training finished
2017-06-11 03:49:52.961334 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1060 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 03:49:52.961752 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1060 | Collecting samples for evaluation
2017-06-11 03:50:06.238600 EDT | -----------------------  -----------
2017-06-11 03:50:06.239733 EDT | Epoch                    1060
2017-06-11 03:50:06.240196 EDT | Iteration                1060
2017-06-11 03:50:06.240701 EDT | AverageReturn            1833.05
2017-06-11 03:50:06.241146 EDT | StdReturn                 649.661
2017-06-11 03:50:06.241586 EDT | MaxReturn                3113
2017-06-11 03:50:06.242041 EDT | MinReturn                 975.006
2017-06-11 03:50:06.242702 EDT | AverageEsReturn           321.391
2017-06-11 03:50:06.243291 EDT | StdEsReturn               190.362
2017-06-11 03:50:06.243733 EDT | MaxEsReturn               559.649
2017-06-11 03:50:06.244172 EDT | MinEsReturn               156.058
2017-06-11 03:50:06.244737 EDT | AverageDiscountedReturn   241.708
2017-06-11 03:50:06.245331 EDT | AverageQLoss                2.03093
2017-06-11 03:50:06.245789 EDT | AveragePolicySurr         -29.5578
2017-06-11 03:50:06.246230 EDT | AverageQ                   29.2916
2017-06-11 03:50:06.246645 EDT | AverageAbsQ                29.3083
2017-06-11 03:50:06.247074 EDT | AverageY                   29.2933
2017-06-11 03:50:06.247514 EDT | AverageAbsY                29.3005
2017-06-11 03:50:06.247949 EDT | AverageAbsQYDiff            0.510049
2017-06-11 03:50:06.248385 EDT | AverageAction               0.997838
2017-06-11 03:50:06.248820 EDT | PolicyRegParamNorm         99.4575
2017-06-11 03:50:06.249256 EDT | QFunRegParamNorm          129.093
2017-06-11 03:50:06.249687 EDT | -----------------------  -----------
2017-06-11 03:50:06.250300 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1061 | Training started
2017-06-11 03:50:24.460373 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1061 | Training finished
2017-06-11 03:50:24.461127 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1061 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 03:50:24.461485 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1061 | Collecting samples for evaluation
2017-06-11 03:50:38.321988 EDT | -----------------------  -----------
2017-06-11 03:50:38.322508 EDT | Epoch                    1061
2017-06-11 03:50:38.322843 EDT | Iteration                1061
2017-06-11 03:50:38.323158 EDT | AverageReturn            1446.87
2017-06-11 03:50:38.323516 EDT | StdReturn                 887.225
2017-06-11 03:50:38.323929 EDT | MaxReturn                2876.47
2017-06-11 03:50:38.324271 EDT | MinReturn                 289.684
2017-06-11 03:50:38.324585 EDT | AverageEsReturn           791.918
2017-06-11 03:50:38.324913 EDT | StdEsReturn               392.819
2017-06-11 03:50:38.325235 EDT | MaxEsReturn              1383.25
2017-06-11 03:50:38.325586 EDT | MinEsReturn               410.609
2017-06-11 03:50:38.325919 EDT | AverageDiscountedReturn   208.316
2017-06-11 03:50:38.326249 EDT | AverageQLoss                2.20633
2017-06-11 03:50:38.326585 EDT | AveragePolicySurr         -29.5602
2017-06-11 03:50:38.326913 EDT | AverageQ                   29.3253
2017-06-11 03:50:38.327247 EDT | AverageAbsQ                29.3402
2017-06-11 03:50:38.327598 EDT | AverageY                   29.3275
2017-06-11 03:50:38.327926 EDT | AverageAbsY                29.3322
2017-06-11 03:50:38.328246 EDT | AverageAbsQYDiff            0.511516
2017-06-11 03:50:38.328556 EDT | AverageAction               0.996985
2017-06-11 03:50:38.328883 EDT | PolicyRegParamNorm         99.5843
2017-06-11 03:50:38.329214 EDT | QFunRegParamNorm          129.157
2017-06-11 03:50:38.329544 EDT | -----------------------  -----------
2017-06-11 03:50:38.330051 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1062 | Training started
2017-06-11 03:50:55.107069 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1062 | Training finished
2017-06-11 03:50:55.108448 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1062 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 03:50:55.108818 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1062 | Collecting samples for evaluation
2017-06-11 03:51:09.297457 EDT | -----------------------  -----------
2017-06-11 03:51:09.298622 EDT | Epoch                    1062
2017-06-11 03:51:09.299034 EDT | Iteration                1062
2017-06-11 03:51:09.299392 EDT | AverageReturn             403.815
2017-06-11 03:51:09.299720 EDT | StdReturn                 296.043
2017-06-11 03:51:09.300076 EDT | MaxReturn                1760.59
2017-06-11 03:51:09.300425 EDT | MinReturn                 215.732
2017-06-11 03:51:09.300736 EDT | AverageEsReturn           309.546
2017-06-11 03:51:09.301215 EDT | StdEsReturn               222.383
2017-06-11 03:51:09.301664 EDT | MaxEsReturn               882.177
2017-06-11 03:51:09.302138 EDT | MinEsReturn               120.423
2017-06-11 03:51:09.302597 EDT | AverageDiscountedReturn   163.679
2017-06-11 03:51:09.303047 EDT | AverageQLoss                2.07487
2017-06-11 03:51:09.303486 EDT | AveragePolicySurr         -29.4449
2017-06-11 03:51:09.303780 EDT | AverageQ                   29.2124
2017-06-11 03:51:09.304118 EDT | AverageAbsQ                29.225
2017-06-11 03:51:09.304476 EDT | AverageY                   29.2136
2017-06-11 03:51:09.304882 EDT | AverageAbsY                29.2213
2017-06-11 03:51:09.305304 EDT | AverageAbsQYDiff            0.502593
2017-06-11 03:51:09.305756 EDT | AverageAction               0.998394
2017-06-11 03:51:09.306170 EDT | PolicyRegParamNorm         99.5625
2017-06-11 03:51:09.306530 EDT | QFunRegParamNorm          129.189
2017-06-11 03:51:09.307000 EDT | -----------------------  -----------
2017-06-11 03:51:09.307464 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1063 | Training started
2017-06-11 03:51:25.542231 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1063 | Training finished
2017-06-11 03:51:25.543160 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1063 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 03:51:25.543665 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1063 | Collecting samples for evaluation
2017-06-11 03:51:39.169835 EDT | -----------------------  -----------
2017-06-11 03:51:39.171729 EDT | Epoch                    1063
2017-06-11 03:51:39.172321 EDT | Iteration                1063
2017-06-11 03:51:39.173387 EDT | AverageReturn             712.33
2017-06-11 03:51:39.173826 EDT | StdReturn                 498.638
2017-06-11 03:51:39.173992 EDT | MaxReturn                2670.41
2017-06-11 03:51:39.174221 EDT | MinReturn                 250.094
2017-06-11 03:51:39.174382 EDT | AverageEsReturn           348.527
2017-06-11 03:51:39.174538 EDT | StdEsReturn               173.159
2017-06-11 03:51:39.174719 EDT | MaxEsReturn               587.619
2017-06-11 03:51:39.174904 EDT | MinEsReturn                 9.11835
2017-06-11 03:51:39.175083 EDT | AverageDiscountedReturn   205.35
2017-06-11 03:51:39.175256 EDT | AverageQLoss                1.64057
2017-06-11 03:51:39.175413 EDT | AveragePolicySurr         -29.5991
2017-06-11 03:51:39.175568 EDT | AverageQ                   29.376
2017-06-11 03:51:39.175818 EDT | AverageAbsQ                29.3937
2017-06-11 03:51:39.175984 EDT | AverageY                   29.3773
2017-06-11 03:51:39.176250 EDT | AverageAbsY                29.3878
2017-06-11 03:51:39.176431 EDT | AverageAbsQYDiff            0.474274
2017-06-11 03:51:39.176621 EDT | AverageAction               0.998096
2017-06-11 03:51:39.176791 EDT | PolicyRegParamNorm         99.6207
2017-06-11 03:51:39.177009 EDT | QFunRegParamNorm          129.217
2017-06-11 03:51:39.177206 EDT | -----------------------  -----------
2017-06-11 03:51:39.177493 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1064 | Training started
2017-06-11 03:51:56.759833 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1064 | Training finished
2017-06-11 03:51:56.761163 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1064 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 03:51:56.761416 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1064 | Collecting samples for evaluation
2017-06-11 03:52:10.155612 EDT | -----------------------  -----------
2017-06-11 03:52:10.156632 EDT | Epoch                    1064
2017-06-11 03:52:10.157025 EDT | Iteration                1064
2017-06-11 03:52:10.157368 EDT | AverageReturn             704.676
2017-06-11 03:52:10.157739 EDT | StdReturn                  61.1563
2017-06-11 03:52:10.158098 EDT | MaxReturn                 926.781
2017-06-11 03:52:10.158435 EDT | MinReturn                 575.517
2017-06-11 03:52:10.158767 EDT | AverageEsReturn           236.947
2017-06-11 03:52:10.159097 EDT | StdEsReturn               140.505
2017-06-11 03:52:10.159353 EDT | MaxEsReturn               570.264
2017-06-11 03:52:10.159730 EDT | MinEsReturn                81.7589
2017-06-11 03:52:10.160129 EDT | AverageDiscountedReturn   235.481
2017-06-11 03:52:10.161886 EDT | AverageQLoss                1.89294
2017-06-11 03:52:10.162222 EDT | AveragePolicySurr         -29.4694
2017-06-11 03:52:10.162543 EDT | AverageQ                   29.2395
2017-06-11 03:52:10.162861 EDT | AverageAbsQ                29.2625
2017-06-11 03:52:10.163167 EDT | AverageY                   29.2409
2017-06-11 03:52:10.163468 EDT | AverageAbsY                29.2552
2017-06-11 03:52:10.163769 EDT | AverageAbsQYDiff            0.501095
2017-06-11 03:52:10.164069 EDT | AverageAction               0.998158
2017-06-11 03:52:10.164371 EDT | PolicyRegParamNorm         99.6387
2017-06-11 03:52:10.164662 EDT | QFunRegParamNorm          129.246
2017-06-11 03:52:10.164964 EDT | -----------------------  -----------
2017-06-11 03:52:10.165428 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1065 | Training started
2017-06-11 03:52:26.923129 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1065 | Training finished
2017-06-11 03:52:26.923916 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1065 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 03:52:26.924102 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1065 | Collecting samples for evaluation
2017-06-11 03:52:41.408614 EDT | -----------------------  -----------
2017-06-11 03:52:41.409506 EDT | Epoch                    1065
2017-06-11 03:52:41.409872 EDT | Iteration                1065
2017-06-11 03:52:41.410197 EDT | AverageReturn             233.229
2017-06-11 03:52:41.410586 EDT | StdReturn                   7.8057
2017-06-11 03:52:41.410915 EDT | MaxReturn                 256.758
2017-06-11 03:52:41.412133 EDT | MinReturn                 220.388
2017-06-11 03:52:41.412396 EDT | AverageEsReturn           272.946
2017-06-11 03:52:41.412711 EDT | StdEsReturn               135.479
2017-06-11 03:52:41.413018 EDT | MaxEsReturn               480.065
2017-06-11 03:52:41.413279 EDT | MinEsReturn                40.2672
2017-06-11 03:52:41.413691 EDT | AverageDiscountedReturn   135.638
2017-06-11 03:52:41.414093 EDT | AverageQLoss                2.15191
2017-06-11 03:52:41.414476 EDT | AveragePolicySurr         -29.399
2017-06-11 03:52:41.414915 EDT | AverageQ                   29.1959
2017-06-11 03:52:41.415245 EDT | AverageAbsQ                29.224
2017-06-11 03:52:41.415562 EDT | AverageY                   29.1978
2017-06-11 03:52:41.415907 EDT | AverageAbsY                29.2149
2017-06-11 03:52:41.416076 EDT | AverageAbsQYDiff            0.517797
2017-06-11 03:52:41.416231 EDT | AverageAction               0.998406
2017-06-11 03:52:41.416395 EDT | PolicyRegParamNorm         99.7143
2017-06-11 03:52:41.416593 EDT | QFunRegParamNorm          129.275
2017-06-11 03:52:41.416768 EDT | -----------------------  -----------
2017-06-11 03:52:41.417049 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1066 | Training started
2017-06-11 03:52:58.663324 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1066 | Training finished
2017-06-11 03:52:58.664268 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1066 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 03:52:58.664603 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1066 | Collecting samples for evaluation
2017-06-11 03:53:12.770637 EDT | -----------------------  -----------
2017-06-11 03:53:12.771637 EDT | Epoch                    1066
2017-06-11 03:53:12.772005 EDT | Iteration                1066
2017-06-11 03:53:12.772353 EDT | AverageReturn             203.313
2017-06-11 03:53:12.772695 EDT | StdReturn                   5.07663
2017-06-11 03:53:12.773827 EDT | MaxReturn                 224.065
2017-06-11 03:53:12.774181 EDT | MinReturn                 192.695
2017-06-11 03:53:12.774524 EDT | AverageEsReturn           202.457
2017-06-11 03:53:12.774874 EDT | StdEsReturn               144.228
2017-06-11 03:53:12.775215 EDT | MaxEsReturn               501.988
2017-06-11 03:53:12.775557 EDT | MinEsReturn                10.8108
2017-06-11 03:53:12.775899 EDT | AverageDiscountedReturn   124.049
2017-06-11 03:53:12.776240 EDT | AverageQLoss                2.00297
2017-06-11 03:53:12.776579 EDT | AveragePolicySurr         -29.3736
2017-06-11 03:53:12.777053 EDT | AverageQ                   29.1525
2017-06-11 03:53:12.777402 EDT | AverageAbsQ                29.1746
2017-06-11 03:53:12.779085 EDT | AverageY                   29.1529
2017-06-11 03:53:12.779435 EDT | AverageAbsY                29.1664
2017-06-11 03:53:12.779783 EDT | AverageAbsQYDiff            0.505558
2017-06-11 03:53:12.780122 EDT | AverageAction               0.9981
2017-06-11 03:53:12.780464 EDT | PolicyRegParamNorm         99.7868
2017-06-11 03:53:12.780805 EDT | QFunRegParamNorm          129.374
2017-06-11 03:53:12.781148 EDT | -----------------------  -----------
2017-06-11 03:53:12.781664 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1067 | Training started
2017-06-11 03:53:28.747735 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1067 | Training finished
2017-06-11 03:53:28.748762 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1067 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 03:53:28.749136 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1067 | Collecting samples for evaluation
2017-06-11 03:53:43.753570 EDT | -----------------------  -----------
2017-06-11 03:53:43.753864 EDT | Epoch                    1067
2017-06-11 03:53:43.754138 EDT | Iteration                1067
2017-06-11 03:53:43.754358 EDT | AverageReturn            1165.52
2017-06-11 03:53:43.754671 EDT | StdReturn                 561.639
2017-06-11 03:53:43.754956 EDT | MaxReturn                2579.53
2017-06-11 03:53:43.755262 EDT | MinReturn                 419.71
2017-06-11 03:53:43.755573 EDT | AverageEsReturn           110.719
2017-06-11 03:53:43.755888 EDT | StdEsReturn                97.7664
2017-06-11 03:53:43.756198 EDT | MaxEsReturn               259.361
2017-06-11 03:53:43.756512 EDT | MinEsReturn                 8.17601
2017-06-11 03:53:43.756828 EDT | AverageDiscountedReturn   224.683
2017-06-11 03:53:43.757100 EDT | AverageQLoss                2.03008
2017-06-11 03:53:43.757380 EDT | AveragePolicySurr         -29.3487
2017-06-11 03:53:43.758002 EDT | AverageQ                   29.1442
2017-06-11 03:53:43.758213 EDT | AverageAbsQ                29.1762
2017-06-11 03:53:43.758398 EDT | AverageY                   29.1449
2017-06-11 03:53:43.758587 EDT | AverageAbsY                29.1728
2017-06-11 03:53:43.758767 EDT | AverageAbsQYDiff            0.516211
2017-06-11 03:53:43.758979 EDT | AverageAction               0.998118
2017-06-11 03:53:43.759539 EDT | PolicyRegParamNorm         99.8665
2017-06-11 03:53:43.759731 EDT | QFunRegParamNorm          129.352
2017-06-11 03:53:43.759911 EDT | -----------------------  -----------
2017-06-11 03:53:43.760230 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1068 | Training started
2017-06-11 03:53:59.400405 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1068 | Training finished
2017-06-11 03:53:59.401303 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1068 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 03:53:59.401737 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1068 | Collecting samples for evaluation
2017-06-11 03:54:13.403766 EDT | -----------------------  -----------
2017-06-11 03:54:13.404043 EDT | Epoch                    1068
2017-06-11 03:54:13.404289 EDT | Iteration                1068
2017-06-11 03:54:13.404531 EDT | AverageReturn            1363.29
2017-06-11 03:54:13.404716 EDT | StdReturn                 235.8
2017-06-11 03:54:13.404902 EDT | MaxReturn                1821.94
2017-06-11 03:54:13.405090 EDT | MinReturn                 965.869
2017-06-11 03:54:13.405312 EDT | AverageEsReturn           220.171
2017-06-11 03:54:13.405495 EDT | StdEsReturn               126.472
2017-06-11 03:54:13.405675 EDT | MaxEsReturn               542.656
2017-06-11 03:54:13.405872 EDT | MinEsReturn                46.9504
2017-06-11 03:54:13.406061 EDT | AverageDiscountedReturn   223.772
2017-06-11 03:54:13.406241 EDT | AverageQLoss                2.04699
2017-06-11 03:54:13.406420 EDT | AveragePolicySurr         -29.3908
2017-06-11 03:54:13.406602 EDT | AverageQ                   29.1831
2017-06-11 03:54:13.406781 EDT | AverageAbsQ                29.2109
2017-06-11 03:54:13.407008 EDT | AverageY                   29.1838
2017-06-11 03:54:13.407218 EDT | AverageAbsY                29.2078
2017-06-11 03:54:13.407402 EDT | AverageAbsQYDiff            0.510188
2017-06-11 03:54:13.407673 EDT | AverageAction               0.998126
2017-06-11 03:54:13.407903 EDT | PolicyRegParamNorm         99.9533
2017-06-11 03:54:13.408093 EDT | QFunRegParamNorm          129.428
2017-06-11 03:54:13.408273 EDT | -----------------------  -----------
2017-06-11 03:54:13.408568 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1069 | Training started
2017-06-11 03:54:29.312460 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1069 | Training finished
2017-06-11 03:54:29.313244 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1069 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 03:54:29.313434 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1069 | Collecting samples for evaluation
2017-06-11 03:54:42.604364 EDT | -----------------------  -----------
2017-06-11 03:54:42.604747 EDT | Epoch                    1069
2017-06-11 03:54:42.605010 EDT | Iteration                1069
2017-06-11 03:54:42.605264 EDT | AverageReturn            1087.67
2017-06-11 03:54:42.605515 EDT | StdReturn                 502.548
2017-06-11 03:54:42.605793 EDT | MaxReturn                2517.07
2017-06-11 03:54:42.606046 EDT | MinReturn                 396.446
2017-06-11 03:54:42.606294 EDT | AverageEsReturn           338.672
2017-06-11 03:54:42.606541 EDT | StdEsReturn               101.075
2017-06-11 03:54:42.606794 EDT | MaxEsReturn               531.702
2017-06-11 03:54:42.607040 EDT | MinEsReturn               208.689
2017-06-11 03:54:42.607292 EDT | AverageDiscountedReturn   208.407
2017-06-11 03:54:42.607538 EDT | AverageQLoss                2.57551
2017-06-11 03:54:42.607785 EDT | AveragePolicySurr         -29.2577
2017-06-11 03:54:42.608031 EDT | AverageQ                   29.0431
2017-06-11 03:54:42.608277 EDT | AverageAbsQ                29.0812
2017-06-11 03:54:42.608522 EDT | AverageY                   29.0464
2017-06-11 03:54:42.608767 EDT | AverageAbsY                29.0831
2017-06-11 03:54:42.609010 EDT | AverageAbsQYDiff            0.557965
2017-06-11 03:54:42.609254 EDT | AverageAction               0.997713
2017-06-11 03:54:42.609499 EDT | PolicyRegParamNorm         99.9653
2017-06-11 03:54:42.631619 EDT | QFunRegParamNorm          129.524
2017-06-11 03:54:42.631919 EDT | -----------------------  -----------
2017-06-11 03:54:42.632372 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1070 | Training started
2017-06-11 03:54:59.356436 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1070 | Training finished
2017-06-11 03:54:59.358589 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1070 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 03:54:59.359325 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1070 | Collecting samples for evaluation
2017-06-11 03:55:12.562744 EDT | -----------------------  -----------
2017-06-11 03:55:12.563835 EDT | Epoch                    1070
2017-06-11 03:55:12.564300 EDT | Iteration                1070
2017-06-11 03:55:12.564750 EDT | AverageReturn             822.392
2017-06-11 03:55:12.565197 EDT | StdReturn                 214.23
2017-06-11 03:55:12.565639 EDT | MaxReturn                1774.25
2017-06-11 03:55:12.566439 EDT | MinReturn                 688.506
2017-06-11 03:55:12.574521 EDT | AverageEsReturn           392.62
2017-06-11 03:55:12.575811 EDT | StdEsReturn               202.552
2017-06-11 03:55:12.577038 EDT | MaxEsReturn               604.696
2017-06-11 03:55:12.578270 EDT | MinEsReturn                86.8653
2017-06-11 03:55:12.579500 EDT | AverageDiscountedReturn   227.593
2017-06-11 03:55:12.580693 EDT | AverageQLoss                2.29114
2017-06-11 03:55:12.581920 EDT | AveragePolicySurr         -29.3747
2017-06-11 03:55:12.583119 EDT | AverageQ                   29.1346
2017-06-11 03:55:12.584326 EDT | AverageAbsQ                29.1847
2017-06-11 03:55:12.585535 EDT | AverageY                   29.1353
2017-06-11 03:55:12.586782 EDT | AverageAbsY                29.174
2017-06-11 03:55:12.587994 EDT | AverageAbsQYDiff            0.530523
2017-06-11 03:55:12.589208 EDT | AverageAction               0.998262
2017-06-11 03:55:12.590300 EDT | PolicyRegParamNorm         99.9556
2017-06-11 03:55:12.591307 EDT | QFunRegParamNorm          129.586
2017-06-11 03:55:12.592525 EDT | -----------------------  -----------
2017-06-11 03:55:12.593934 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1071 | Training started
2017-06-11 03:55:28.701399 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1071 | Training finished
2017-06-11 03:55:28.702307 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1071 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 03:55:28.702523 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1071 | Collecting samples for evaluation
2017-06-11 03:55:43.074841 EDT | -----------------------  -----------
2017-06-11 03:55:43.077530 EDT | Epoch                    1071
2017-06-11 03:55:43.078192 EDT | Iteration                1071
2017-06-11 03:55:43.078595 EDT | AverageReturn            1167.5
2017-06-11 03:55:43.078951 EDT | StdReturn                 166.616
2017-06-11 03:55:43.079390 EDT | MaxReturn                1889.44
2017-06-11 03:55:43.081999 EDT | MinReturn                 981.256
2017-06-11 03:55:43.082453 EDT | AverageEsReturn           596.403
2017-06-11 03:55:43.082902 EDT | StdEsReturn               447.183
2017-06-11 03:55:43.083349 EDT | MaxEsReturn              1376.67
2017-06-11 03:55:43.083798 EDT | MinEsReturn                86.596
2017-06-11 03:55:43.084240 EDT | AverageDiscountedReturn   243.354
2017-06-11 03:55:43.084680 EDT | AverageQLoss                2.15547
2017-06-11 03:55:43.085125 EDT | AveragePolicySurr         -29.3212
2017-06-11 03:55:43.085568 EDT | AverageQ                   29.0969
2017-06-11 03:55:43.086024 EDT | AverageAbsQ                29.1299
2017-06-11 03:55:43.086462 EDT | AverageY                   29.0985
2017-06-11 03:55:43.086907 EDT | AverageAbsY                29.1276
2017-06-11 03:55:43.087346 EDT | AverageAbsQYDiff            0.520668
2017-06-11 03:55:43.087785 EDT | AverageAction               0.997618
2017-06-11 03:55:43.088223 EDT | PolicyRegParamNorm        100.065
2017-06-11 03:55:43.088661 EDT | QFunRegParamNorm          129.608
2017-06-11 03:55:43.089103 EDT | -----------------------  -----------
2017-06-11 03:55:43.089731 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1072 | Training started
2017-06-11 03:55:58.089533 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1072 | Training finished
2017-06-11 03:55:58.090386 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1072 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 03:55:58.090589 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1072 | Collecting samples for evaluation
2017-06-11 03:56:11.333922 EDT | -----------------------  -----------
2017-06-11 03:56:11.334878 EDT | Epoch                    1072
2017-06-11 03:56:11.335239 EDT | Iteration                1072
2017-06-11 03:56:11.335579 EDT | AverageReturn             831.053
2017-06-11 03:56:11.335914 EDT | StdReturn                 133.644
2017-06-11 03:56:11.336255 EDT | MaxReturn                1154.72
2017-06-11 03:56:11.336583 EDT | MinReturn                 697.751
2017-06-11 03:56:11.336911 EDT | AverageEsReturn           370.868
2017-06-11 03:56:11.337239 EDT | StdEsReturn               225.913
2017-06-11 03:56:11.337566 EDT | MaxEsReturn               636.675
2017-06-11 03:56:11.337901 EDT | MinEsReturn                94.2515
2017-06-11 03:56:11.338229 EDT | AverageDiscountedReturn   238.285
2017-06-11 03:56:11.338555 EDT | AverageQLoss                2.30405
2017-06-11 03:56:11.338882 EDT | AveragePolicySurr         -29.2731
2017-06-11 03:56:11.339208 EDT | AverageQ                   29.033
2017-06-11 03:56:11.339534 EDT | AverageAbsQ                29.063
2017-06-11 03:56:11.339858 EDT | AverageY                   29.0346
2017-06-11 03:56:11.340184 EDT | AverageAbsY                29.0536
2017-06-11 03:56:11.340508 EDT | AverageAbsQYDiff            0.543643
2017-06-11 03:56:11.340832 EDT | AverageAction               0.998842
2017-06-11 03:56:11.341157 EDT | PolicyRegParamNorm        100.082
2017-06-11 03:56:11.341480 EDT | QFunRegParamNorm          129.629
2017-06-11 03:56:11.341811 EDT | -----------------------  -----------
2017-06-11 03:56:11.342279 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1073 | Training started
2017-06-11 03:56:27.763557 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1073 | Training finished
2017-06-11 03:56:27.764123 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1073 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 03:56:27.764439 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1073 | Collecting samples for evaluation
2017-06-11 03:56:41.315773 EDT | -----------------------  -----------
2017-06-11 03:56:41.316458 EDT | Epoch                    1073
2017-06-11 03:56:41.316831 EDT | Iteration                1073
2017-06-11 03:56:41.317181 EDT | AverageReturn            1319.98
2017-06-11 03:56:41.317545 EDT | StdReturn                 531.285
2017-06-11 03:56:41.317908 EDT | MaxReturn                2693.06
2017-06-11 03:56:41.318361 EDT | MinReturn                 785.438
2017-06-11 03:56:41.318715 EDT | AverageEsReturn           423.725
2017-06-11 03:56:41.319160 EDT | StdEsReturn               150.129
2017-06-11 03:56:41.319608 EDT | MaxEsReturn               637.18
2017-06-11 03:56:41.320055 EDT | MinEsReturn               209.403
2017-06-11 03:56:41.320506 EDT | AverageDiscountedReturn   228.76
2017-06-11 03:56:41.320954 EDT | AverageQLoss                2.01915
2017-06-11 03:56:41.321404 EDT | AveragePolicySurr         -29.2692
2017-06-11 03:56:41.321868 EDT | AverageQ                   29.016
2017-06-11 03:56:41.322312 EDT | AverageAbsQ                29.0447
2017-06-11 03:56:41.322762 EDT | AverageY                   29.0154
2017-06-11 03:56:41.323212 EDT | AverageAbsY                29.0373
2017-06-11 03:56:41.323571 EDT | AverageAbsQYDiff            0.518717
2017-06-11 03:56:41.323915 EDT | AverageAction               0.998364
2017-06-11 03:56:41.324259 EDT | PolicyRegParamNorm        100.123
2017-06-11 03:56:41.324618 EDT | QFunRegParamNorm          129.646
2017-06-11 03:56:41.324962 EDT | -----------------------  -----------
2017-06-11 03:56:41.325488 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1074 | Training started
2017-06-11 03:56:59.506139 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1074 | Training finished
2017-06-11 03:56:59.506894 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1074 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 03:56:59.507073 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1074 | Collecting samples for evaluation
2017-06-11 03:57:12.532890 EDT | -----------------------  -----------
2017-06-11 03:57:12.533846 EDT | Epoch                    1074
2017-06-11 03:57:12.534204 EDT | Iteration                1074
2017-06-11 03:57:12.534536 EDT | AverageReturn            1082.07
2017-06-11 03:57:12.534856 EDT | StdReturn                 349.413
2017-06-11 03:57:12.535276 EDT | MaxReturn                1930.92
2017-06-11 03:57:12.536225 EDT | MinReturn                 634.906
2017-06-11 03:57:12.536788 EDT | AverageEsReturn           448.554
2017-06-11 03:57:12.537098 EDT | StdEsReturn               240.296
2017-06-11 03:57:12.537422 EDT | MaxEsReturn               771.402
2017-06-11 03:57:12.537753 EDT | MinEsReturn                73.6484
2017-06-11 03:57:12.538098 EDT | AverageDiscountedReturn   225.794
2017-06-11 03:57:12.538433 EDT | AverageQLoss                2.22787
2017-06-11 03:57:12.538768 EDT | AveragePolicySurr         -29.3749
2017-06-11 03:57:12.539095 EDT | AverageQ                   29.1058
2017-06-11 03:57:12.539555 EDT | AverageAbsQ                29.1353
2017-06-11 03:57:12.539961 EDT | AverageY                   29.1085
2017-06-11 03:57:12.540297 EDT | AverageAbsY                29.1292
2017-06-11 03:57:12.540620 EDT | AverageAbsQYDiff            0.51575
2017-06-11 03:57:12.540945 EDT | AverageAction               0.998134
2017-06-11 03:57:12.541258 EDT | PolicyRegParamNorm        100.138
2017-06-11 03:57:12.546602 EDT | QFunRegParamNorm          129.665
2017-06-11 03:57:12.546932 EDT | -----------------------  -----------
2017-06-11 03:57:12.547409 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1075 | Training started
2017-06-11 03:57:28.745070 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1075 | Training finished
2017-06-11 03:57:28.746257 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1075 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 03:57:28.746608 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1075 | Collecting samples for evaluation
2017-06-11 03:57:43.236317 EDT | -----------------------  -----------
2017-06-11 03:57:43.237174 EDT | Epoch                    1075
2017-06-11 03:57:43.237430 EDT | Iteration                1075
2017-06-11 03:57:43.237605 EDT | AverageReturn            1230.17
2017-06-11 03:57:43.237816 EDT | StdReturn                 521.001
2017-06-11 03:57:43.238004 EDT | MaxReturn                2537.38
2017-06-11 03:57:43.238188 EDT | MinReturn                 612.276
2017-06-11 03:57:43.238372 EDT | AverageEsReturn           425.531
2017-06-11 03:57:43.238554 EDT | StdEsReturn               298.572
2017-06-11 03:57:43.238800 EDT | MaxEsReturn               932.013
2017-06-11 03:57:43.238984 EDT | MinEsReturn                67.6319
2017-06-11 03:57:43.239165 EDT | AverageDiscountedReturn   221.669
2017-06-11 03:57:43.239345 EDT | AverageQLoss                1.98449
2017-06-11 03:57:43.239526 EDT | AveragePolicySurr         -29.2633
2017-06-11 03:57:43.239771 EDT | AverageQ                   28.9998
2017-06-11 03:57:43.239953 EDT | AverageAbsQ                29.0232
2017-06-11 03:57:43.240133 EDT | AverageY                   29.001
2017-06-11 03:57:43.240312 EDT | AverageAbsY                29.0141
2017-06-11 03:57:43.240489 EDT | AverageAbsQYDiff            0.512128
2017-06-11 03:57:43.240668 EDT | AverageAction               0.998338
2017-06-11 03:57:43.240846 EDT | PolicyRegParamNorm        100.094
2017-06-11 03:57:43.241026 EDT | QFunRegParamNorm          129.7
2017-06-11 03:57:43.241205 EDT | -----------------------  -----------
2017-06-11 03:57:43.241550 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1076 | Training started
2017-06-11 03:58:01.114203 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1076 | Training finished
2017-06-11 03:58:01.115285 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1076 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 03:58:01.115756 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1076 | Collecting samples for evaluation
2017-06-11 03:58:15.841732 EDT | -----------------------  -----------
2017-06-11 03:58:15.842500 EDT | Epoch                    1076
2017-06-11 03:58:15.842747 EDT | Iteration                1076
2017-06-11 03:58:15.842936 EDT | AverageReturn            1005.4
2017-06-11 03:58:15.843123 EDT | StdReturn                 167.897
2017-06-11 03:58:15.843531 EDT | MaxReturn                1484.12
2017-06-11 03:58:15.843876 EDT | MinReturn                 757.077
2017-06-11 03:58:15.849243 EDT | AverageEsReturn           450.797
2017-06-11 03:58:15.849800 EDT | StdEsReturn               246.267
2017-06-11 03:58:15.850004 EDT | MaxEsReturn               719.766
2017-06-11 03:58:15.850231 EDT | MinEsReturn                64.2072
2017-06-11 03:58:15.850418 EDT | AverageDiscountedReturn   217.812
2017-06-11 03:58:15.850604 EDT | AverageQLoss                2.00567
2017-06-11 03:58:15.850784 EDT | AveragePolicySurr         -29.3605
2017-06-11 03:58:15.850975 EDT | AverageQ                   29.1289
2017-06-11 03:58:15.851155 EDT | AverageAbsQ                29.15
2017-06-11 03:58:15.851335 EDT | AverageY                   29.1284
2017-06-11 03:58:15.851514 EDT | AverageAbsY                29.142
2017-06-11 03:58:15.851694 EDT | AverageAbsQYDiff            0.507717
2017-06-11 03:58:15.851920 EDT | AverageAction               0.998013
2017-06-11 03:58:15.852105 EDT | PolicyRegParamNorm        100.169
2017-06-11 03:58:15.852286 EDT | QFunRegParamNorm          129.752
2017-06-11 03:58:15.852465 EDT | -----------------------  -----------
2017-06-11 03:58:15.852768 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1077 | Training started
2017-06-11 03:58:33.069261 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1077 | Training finished
2017-06-11 03:58:33.070142 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1077 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 03:58:33.070623 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1077 | Collecting samples for evaluation
2017-06-11 03:58:46.305540 EDT | -----------------------  -----------
2017-06-11 03:58:46.324059 EDT | Epoch                    1077
2017-06-11 03:58:46.324491 EDT | Iteration                1077
2017-06-11 03:58:46.324898 EDT | AverageReturn            1604.27
2017-06-11 03:58:46.325233 EDT | StdReturn                 580.363
2017-06-11 03:58:46.325557 EDT | MaxReturn                2677.96
2017-06-11 03:58:46.325900 EDT | MinReturn                 900.645
2017-06-11 03:58:46.326373 EDT | AverageEsReturn           562.971
2017-06-11 03:58:46.326701 EDT | StdEsReturn               377.659
2017-06-11 03:58:46.327109 EDT | MaxEsReturn              1183.27
2017-06-11 03:58:46.327449 EDT | MinEsReturn                 9.52059
2017-06-11 03:58:46.327772 EDT | AverageDiscountedReturn   225.38
2017-06-11 03:58:46.328094 EDT | AverageQLoss                1.69704
2017-06-11 03:58:46.328523 EDT | AveragePolicySurr         -29.3966
2017-06-11 03:58:46.328810 EDT | AverageQ                   29.1559
2017-06-11 03:58:46.329125 EDT | AverageAbsQ                29.1754
2017-06-11 03:58:46.329602 EDT | AverageY                   29.1566
2017-06-11 03:58:46.329933 EDT | AverageAbsY                29.169
2017-06-11 03:58:46.330247 EDT | AverageAbsQYDiff            0.47615
2017-06-11 03:58:46.330559 EDT | AverageAction               0.998439
2017-06-11 03:58:46.331101 EDT | PolicyRegParamNorm        100.192
2017-06-11 03:58:46.331601 EDT | QFunRegParamNorm          129.738
2017-06-11 03:58:46.331880 EDT | -----------------------  -----------
2017-06-11 03:58:46.332378 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1078 | Training started
2017-06-11 03:59:04.612151 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1078 | Training finished
2017-06-11 03:59:04.612920 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1078 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 03:59:04.613163 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1078 | Collecting samples for evaluation
2017-06-11 03:59:18.094087 EDT | -----------------------  -----------
2017-06-11 03:59:18.099690 EDT | Epoch                    1078
2017-06-11 03:59:18.102145 EDT | Iteration                1078
2017-06-11 03:59:18.103903 EDT | AverageReturn             220.241
2017-06-11 03:59:18.105615 EDT | StdReturn                   4.7883
2017-06-11 03:59:18.106840 EDT | MaxReturn                 231.749
2017-06-11 03:59:18.108001 EDT | MinReturn                 210.696
2017-06-11 03:59:18.109156 EDT | AverageEsReturn           356.543
2017-06-11 03:59:18.110315 EDT | StdEsReturn               291.021
2017-06-11 03:59:18.111470 EDT | MaxEsReturn               999.857
2017-06-11 03:59:18.112612 EDT | MinEsReturn                10.9515
2017-06-11 03:59:18.113784 EDT | AverageDiscountedReturn   128.992
2017-06-11 03:59:18.114922 EDT | AverageQLoss                1.91609
2017-06-11 03:59:18.116071 EDT | AveragePolicySurr         -29.3024
2017-06-11 03:59:18.117244 EDT | AverageQ                   29.0752
2017-06-11 03:59:18.118391 EDT | AverageAbsQ                29.0926
2017-06-11 03:59:18.119569 EDT | AverageY                   29.0781
2017-06-11 03:59:18.120704 EDT | AverageAbsY                29.0877
2017-06-11 03:59:18.121846 EDT | AverageAbsQYDiff            0.501504
2017-06-11 03:59:18.122995 EDT | AverageAction               0.998286
2017-06-11 03:59:18.124128 EDT | PolicyRegParamNorm        100.195
2017-06-11 03:59:18.125259 EDT | QFunRegParamNorm          129.778
2017-06-11 03:59:18.126393 EDT | -----------------------  -----------
2017-06-11 03:59:18.127706 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1079 | Training started
2017-06-11 03:59:34.511229 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1079 | Training finished
2017-06-11 03:59:34.512164 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1079 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 03:59:34.512624 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1079 | Collecting samples for evaluation
2017-06-11 03:59:49.187444 EDT | -----------------------  -----------
2017-06-11 03:59:49.191695 EDT | Epoch                    1079
2017-06-11 03:59:49.192074 EDT | Iteration                1079
2017-06-11 03:59:49.192414 EDT | AverageReturn             191.21
2017-06-11 03:59:49.192749 EDT | StdReturn                   3.82812
2017-06-11 03:59:49.193084 EDT | MaxReturn                 200.407
2017-06-11 03:59:49.194936 EDT | MinReturn                 178.3
2017-06-11 03:59:49.195298 EDT | AverageEsReturn           293.908
2017-06-11 03:59:49.195636 EDT | StdEsReturn               244.072
2017-06-11 03:59:49.195970 EDT | MaxEsReturn               869.889
2017-06-11 03:59:49.196983 EDT | MinEsReturn                68.5551
2017-06-11 03:59:49.198757 EDT | AverageDiscountedReturn   118.08
2017-06-11 03:59:49.199121 EDT | AverageQLoss                2.2724
2017-06-11 03:59:49.199461 EDT | AveragePolicySurr         -29.311
2017-06-11 03:59:49.199795 EDT | AverageQ                   29.0877
2017-06-11 03:59:49.200769 EDT | AverageAbsQ                29.108
2017-06-11 03:59:49.202301 EDT | AverageY                   29.0886
2017-06-11 03:59:49.202669 EDT | AverageAbsY                29.0996
2017-06-11 03:59:49.203054 EDT | AverageAbsQYDiff            0.510759
2017-06-11 03:59:49.205198 EDT | AverageAction               0.998309
2017-06-11 03:59:49.205557 EDT | PolicyRegParamNorm        100.237
2017-06-11 03:59:49.207117 EDT | QFunRegParamNorm          129.847
2017-06-11 03:59:49.207463 EDT | -----------------------  -----------
2017-06-11 03:59:49.207925 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1080 | Training started
2017-06-11 04:00:05.331404 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1080 | Training finished
2017-06-11 04:00:05.332379 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1080 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 04:00:05.332839 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1080 | Collecting samples for evaluation
2017-06-11 04:00:19.228841 EDT | -----------------------  -----------
2017-06-11 04:00:19.230109 EDT | Epoch                    1080
2017-06-11 04:00:19.230497 EDT | Iteration                1080
2017-06-11 04:00:19.230863 EDT | AverageReturn             958.35
2017-06-11 04:00:19.231227 EDT | StdReturn                 850.637
2017-06-11 04:00:19.231587 EDT | MaxReturn                2653.66
2017-06-11 04:00:19.231947 EDT | MinReturn                 192.373
2017-06-11 04:00:19.232308 EDT | AverageEsReturn           348.28
2017-06-11 04:00:19.232666 EDT | StdEsReturn               156.096
2017-06-11 04:00:19.233028 EDT | MaxEsReturn               646.649
2017-06-11 04:00:19.233395 EDT | MinEsReturn               209.587
2017-06-11 04:00:19.233751 EDT | AverageDiscountedReturn   174.006
2017-06-11 04:00:19.234107 EDT | AverageQLoss                2.27633
2017-06-11 04:00:19.234467 EDT | AveragePolicySurr         -29.3476
2017-06-11 04:00:19.234901 EDT | AverageQ                   29.1132
2017-06-11 04:00:19.235268 EDT | AverageAbsQ                29.1333
2017-06-11 04:00:19.235688 EDT | AverageY                   29.1151
2017-06-11 04:00:19.236048 EDT | AverageAbsY                29.1254
2017-06-11 04:00:19.236405 EDT | AverageAbsQYDiff            0.527683
2017-06-11 04:00:19.236765 EDT | AverageAction               0.998262
2017-06-11 04:00:19.237111 EDT | PolicyRegParamNorm        100.254
2017-06-11 04:00:19.237382 EDT | QFunRegParamNorm          129.889
2017-06-11 04:00:19.237722 EDT | -----------------------  -----------
2017-06-11 04:00:19.238187 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1081 | Training started
2017-06-11 04:00:35.467926 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1081 | Training finished
2017-06-11 04:00:35.468938 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1081 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 04:00:35.469193 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1081 | Collecting samples for evaluation
2017-06-11 04:00:50.090072 EDT | -----------------------  -----------
2017-06-11 04:00:50.090459 EDT | Epoch                    1081
2017-06-11 04:00:50.090725 EDT | Iteration                1081
2017-06-11 04:00:50.090984 EDT | AverageReturn            1063.59
2017-06-11 04:00:50.091237 EDT | StdReturn                 232.449
2017-06-11 04:00:50.091489 EDT | MaxReturn                2025.14
2017-06-11 04:00:50.091741 EDT | MinReturn                 918.584
2017-06-11 04:00:50.091992 EDT | AverageEsReturn           304.916
2017-06-11 04:00:50.092244 EDT | StdEsReturn               162.158
2017-06-11 04:00:50.092495 EDT | MaxEsReturn               656.146
2017-06-11 04:00:50.092746 EDT | MinEsReturn               184.619
2017-06-11 04:00:50.092996 EDT | AverageDiscountedReturn   239.61
2017-06-11 04:00:50.093307 EDT | AverageQLoss                2.25302
2017-06-11 04:00:50.093667 EDT | AveragePolicySurr         -29.1807
2017-06-11 04:00:50.093984 EDT | AverageQ                   28.9754
2017-06-11 04:00:50.094524 EDT | AverageAbsQ                28.998
2017-06-11 04:00:50.094852 EDT | AverageY                   28.9769
2017-06-11 04:00:50.095175 EDT | AverageAbsY                28.9928
2017-06-11 04:00:50.095494 EDT | AverageAbsQYDiff            0.531225
2017-06-11 04:00:50.096006 EDT | AverageAction               0.998549
2017-06-11 04:00:50.096169 EDT | PolicyRegParamNorm        100.339
2017-06-11 04:00:50.096325 EDT | QFunRegParamNorm          129.901
2017-06-11 04:00:50.096657 EDT | -----------------------  -----------
2017-06-11 04:00:50.097163 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1082 | Training started
2017-06-11 04:01:09.305294 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1082 | Training finished
2017-06-11 04:01:09.306391 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1082 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 04:01:09.306755 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1082 | Collecting samples for evaluation
2017-06-11 04:01:24.293024 EDT | -----------------------  -----------
2017-06-11 04:01:24.293774 EDT | Epoch                    1082
2017-06-11 04:01:24.294021 EDT | Iteration                1082
2017-06-11 04:01:24.294193 EDT | AverageReturn            1408.22
2017-06-11 04:01:24.294487 EDT | StdReturn                 868.095
2017-06-11 04:01:24.294644 EDT | MaxReturn                2829.31
2017-06-11 04:01:24.295017 EDT | MinReturn                 639.135
2017-06-11 04:01:24.295231 EDT | AverageEsReturn           353.676
2017-06-11 04:01:24.295388 EDT | StdEsReturn               176.098
2017-06-11 04:01:24.295540 EDT | MaxEsReturn               594.919
2017-06-11 04:01:24.295689 EDT | MinEsReturn                58.9115
2017-06-11 04:01:24.296045 EDT | AverageDiscountedReturn   221.309
2017-06-11 04:01:24.296217 EDT | AverageQLoss                1.95083
2017-06-11 04:01:24.296422 EDT | AveragePolicySurr         -29.3531
2017-06-11 04:01:24.296598 EDT | AverageQ                   29.1214
2017-06-11 04:01:24.296780 EDT | AverageAbsQ                29.1431
2017-06-11 04:01:24.297095 EDT | AverageY                   29.1218
2017-06-11 04:01:24.297422 EDT | AverageAbsY                29.1333
2017-06-11 04:01:24.297763 EDT | AverageAbsQYDiff            0.510211
2017-06-11 04:01:24.298106 EDT | AverageAction               0.998337
2017-06-11 04:01:24.298430 EDT | PolicyRegParamNorm        100.351
2017-06-11 04:01:24.298726 EDT | QFunRegParamNorm          129.948
2017-06-11 04:01:24.298970 EDT | -----------------------  -----------
2017-06-11 04:01:24.299371 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1083 | Training started
2017-06-11 04:01:42.500433 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1083 | Training finished
2017-06-11 04:01:42.501455 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1083 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 04:01:42.501877 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1083 | Collecting samples for evaluation
2017-06-11 04:01:57.804520 EDT | -----------------------  -----------
2017-06-11 04:01:57.805428 EDT | Epoch                    1083
2017-06-11 04:01:57.805641 EDT | Iteration                1083
2017-06-11 04:01:57.805900 EDT | AverageReturn             978.365
2017-06-11 04:01:57.806101 EDT | StdReturn                  22.3448
2017-06-11 04:01:57.806314 EDT | MaxReturn                1025.44
2017-06-11 04:01:57.806497 EDT | MinReturn                 935.064
2017-06-11 04:01:57.807720 EDT | AverageEsReturn           567.34
2017-06-11 04:01:57.807979 EDT | StdEsReturn               169.306
2017-06-11 04:01:57.808235 EDT | MaxEsReturn               750.366
2017-06-11 04:01:57.808464 EDT | MinEsReturn               253.436
2017-06-11 04:01:57.808843 EDT | AverageDiscountedReturn   234.197
2017-06-11 04:01:57.809035 EDT | AverageQLoss                2.68989
2017-06-11 04:01:57.809220 EDT | AveragePolicySurr         -29.2833
2017-06-11 04:01:57.809511 EDT | AverageQ                   29.0663
2017-06-11 04:01:57.809701 EDT | AverageAbsQ                29.0898
2017-06-11 04:01:57.809917 EDT | AverageY                   29.0688
2017-06-11 04:01:57.810286 EDT | AverageAbsY                29.0816
2017-06-11 04:01:57.810527 EDT | AverageAbsQYDiff            0.576813
2017-06-11 04:01:57.810985 EDT | AverageAction               0.998509
2017-06-11 04:01:57.811183 EDT | PolicyRegParamNorm        100.348
2017-06-11 04:01:57.811642 EDT | QFunRegParamNorm          129.995
2017-06-11 04:01:57.811890 EDT | -----------------------  -----------
2017-06-11 04:01:57.812195 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1084 | Training started
2017-06-11 04:02:15.839482 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1084 | Training finished
2017-06-11 04:02:15.841204 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1084 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 04:02:15.841839 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1084 | Collecting samples for evaluation
2017-06-11 04:02:31.822731 EDT | -----------------------  -----------
2017-06-11 04:02:31.823480 EDT | Epoch                    1084
2017-06-11 04:02:31.823795 EDT | Iteration                1084
2017-06-11 04:02:31.824065 EDT | AverageReturn             784.665
2017-06-11 04:02:31.824345 EDT | StdReturn                 319.436
2017-06-11 04:02:31.824598 EDT | MaxReturn                2654.6
2017-06-11 04:02:31.824839 EDT | MinReturn                 671.946
2017-06-11 04:02:31.825099 EDT | AverageEsReturn           764.279
2017-06-11 04:02:31.825389 EDT | StdEsReturn               471.101
2017-06-11 04:02:31.825632 EDT | MaxEsReturn              1372.43
2017-06-11 04:02:31.825905 EDT | MinEsReturn                73.9288
2017-06-11 04:02:31.826167 EDT | AverageDiscountedReturn   213.745
2017-06-11 04:02:31.826404 EDT | AverageQLoss                2.92641
2017-06-11 04:02:31.826667 EDT | AveragePolicySurr         -29.2184
2017-06-11 04:02:31.826940 EDT | AverageQ                   28.9759
2017-06-11 04:02:31.827219 EDT | AverageAbsQ                28.9973
2017-06-11 04:02:31.827547 EDT | AverageY                   28.9757
2017-06-11 04:02:31.827823 EDT | AverageAbsY                28.9883
2017-06-11 04:02:31.828014 EDT | AverageAbsQYDiff            0.59183
2017-06-11 04:02:31.828258 EDT | AverageAction               0.998627
2017-06-11 04:02:31.828419 EDT | PolicyRegParamNorm        100.362
2017-06-11 04:02:31.828570 EDT | QFunRegParamNorm          130.067
2017-06-11 04:02:31.828737 EDT | -----------------------  -----------
2017-06-11 04:02:31.829055 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1085 | Training started
2017-06-11 04:02:48.412211 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1085 | Training finished
2017-06-11 04:02:48.413019 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1085 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 04:02:48.413224 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1085 | Collecting samples for evaluation
2017-06-11 04:03:03.394357 EDT | -----------------------  -----------
2017-06-11 04:03:03.395292 EDT | Epoch                    1085
2017-06-11 04:03:03.395658 EDT | Iteration                1085
2017-06-11 04:03:03.396005 EDT | AverageReturn             703.095
2017-06-11 04:03:03.396351 EDT | StdReturn                 638.036
2017-06-11 04:03:03.396697 EDT | MaxReturn                2358.64
2017-06-11 04:03:03.397038 EDT | MinReturn                 194.606
2017-06-11 04:03:03.397376 EDT | AverageEsReturn           448.955
2017-06-11 04:03:03.397731 EDT | StdEsReturn               282.716
2017-06-11 04:03:03.398079 EDT | MaxEsReturn               835.131
2017-06-11 04:03:03.398418 EDT | MinEsReturn               103.474
2017-06-11 04:03:03.398758 EDT | AverageDiscountedReturn   171.238
2017-06-11 04:03:03.399097 EDT | AverageQLoss                2.60236
2017-06-11 04:03:03.399735 EDT | AveragePolicySurr         -29.3707
2017-06-11 04:03:03.400095 EDT | AverageQ                   29.0968
2017-06-11 04:03:03.400438 EDT | AverageAbsQ                29.1116
2017-06-11 04:03:03.400784 EDT | AverageY                   29.0992
2017-06-11 04:03:03.401124 EDT | AverageAbsY                29.1047
2017-06-11 04:03:03.401465 EDT | AverageAbsQYDiff            0.573647
2017-06-11 04:03:03.401803 EDT | AverageAction               0.998378
2017-06-11 04:03:03.402077 EDT | PolicyRegParamNorm        100.419
2017-06-11 04:03:03.402366 EDT | QFunRegParamNorm          130.153
2017-06-11 04:03:03.402630 EDT | -----------------------  -----------
2017-06-11 04:03:03.403102 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1086 | Training started
2017-06-11 04:03:20.953341 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1086 | Training finished
2017-06-11 04:03:20.953619 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1086 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 04:03:20.953826 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1086 | Collecting samples for evaluation
2017-06-11 04:03:34.613314 EDT | -----------------------  -----------
2017-06-11 04:03:34.614158 EDT | Epoch                    1086
2017-06-11 04:03:34.614361 EDT | Iteration                1086
2017-06-11 04:03:34.614523 EDT | AverageReturn             973.411
2017-06-11 04:03:34.614679 EDT | StdReturn                 749.834
2017-06-11 04:03:34.614838 EDT | MaxReturn                3018.45
2017-06-11 04:03:34.615040 EDT | MinReturn                 207.647
2017-06-11 04:03:34.615212 EDT | AverageEsReturn           484.464
2017-06-11 04:03:34.615540 EDT | StdEsReturn               146.323
2017-06-11 04:03:34.615806 EDT | MaxEsReturn               694.274
2017-06-11 04:03:34.616000 EDT | MinEsReturn               317.033
2017-06-11 04:03:34.616182 EDT | AverageDiscountedReturn   195.269
2017-06-11 04:03:34.617081 EDT | AverageQLoss                2.20744
2017-06-11 04:03:34.617475 EDT | AveragePolicySurr         -29.3855
2017-06-11 04:03:34.617896 EDT | AverageQ                   29.132
2017-06-11 04:03:34.618094 EDT | AverageAbsQ                29.15
2017-06-11 04:03:34.618380 EDT | AverageY                   29.132
2017-06-11 04:03:34.618744 EDT | AverageAbsY                29.1416
2017-06-11 04:03:34.619026 EDT | AverageAbsQYDiff            0.516131
2017-06-11 04:03:34.619220 EDT | AverageAction               0.998221
2017-06-11 04:03:34.619401 EDT | PolicyRegParamNorm        100.425
2017-06-11 04:03:34.619680 EDT | QFunRegParamNorm          130.161
2017-06-11 04:03:34.619858 EDT | -----------------------  -----------
2017-06-11 04:03:34.620218 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1087 | Training started
2017-06-11 04:03:52.135681 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1087 | Training finished
2017-06-11 04:03:52.136082 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1087 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 04:03:52.136355 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1087 | Collecting samples for evaluation
2017-06-11 04:04:06.546405 EDT | -----------------------  -----------
2017-06-11 04:04:06.547169 EDT | Epoch                    1087
2017-06-11 04:04:06.547342 EDT | Iteration                1087
2017-06-11 04:04:06.547504 EDT | AverageReturn             963.816
2017-06-11 04:04:06.547657 EDT | StdReturn                 134.537
2017-06-11 04:04:06.547807 EDT | MaxReturn                1040.5
2017-06-11 04:04:06.547956 EDT | MinReturn                 210.592
2017-06-11 04:04:06.548120 EDT | AverageEsReturn           591.796
2017-06-11 04:04:06.548328 EDT | StdEsReturn               242.114
2017-06-11 04:04:06.548481 EDT | MaxEsReturn               757.328
2017-06-11 04:04:06.548630 EDT | MinEsReturn               127.968
2017-06-11 04:04:06.548777 EDT | AverageDiscountedReturn   232.355
2017-06-11 04:04:06.548925 EDT | AverageQLoss                1.89387
2017-06-11 04:04:06.549072 EDT | AveragePolicySurr         -29.3254
2017-06-11 04:04:06.549231 EDT | AverageQ                   29.0726
2017-06-11 04:04:06.549381 EDT | AverageAbsQ                29.0885
2017-06-11 04:04:06.549529 EDT | AverageY                   29.0761
2017-06-11 04:04:06.549675 EDT | AverageAbsY                29.0846
2017-06-11 04:04:06.549850 EDT | AverageAbsQYDiff            0.496737
2017-06-11 04:04:06.550000 EDT | AverageAction               0.998609
2017-06-11 04:04:06.550148 EDT | PolicyRegParamNorm        100.421
2017-06-11 04:04:06.550307 EDT | QFunRegParamNorm          130.179
2017-06-11 04:04:06.550456 EDT | -----------------------  -----------
2017-06-11 04:04:06.550704 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1088 | Training started
2017-06-11 04:04:24.603624 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1088 | Training finished
2017-06-11 04:04:24.604602 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1088 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 04:04:24.604970 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1088 | Collecting samples for evaluation
2017-06-11 04:04:39.547085 EDT | -----------------------  -----------
2017-06-11 04:04:39.547366 EDT | Epoch                    1088
2017-06-11 04:04:39.547587 EDT | Iteration                1088
2017-06-11 04:04:39.547785 EDT | AverageReturn             479.283
2017-06-11 04:04:39.548233 EDT | StdReturn                 617.425
2017-06-11 04:04:39.548553 EDT | MaxReturn                2652.11
2017-06-11 04:04:39.549031 EDT | MinReturn                 183.399
2017-06-11 04:04:39.549378 EDT | AverageEsReturn           340.349
2017-06-11 04:04:39.549689 EDT | StdEsReturn               235.291
2017-06-11 04:04:39.549959 EDT | MaxEsReturn               647.451
2017-06-11 04:04:39.550221 EDT | MinEsReturn                54.1707
2017-06-11 04:04:39.550513 EDT | AverageDiscountedReturn   143.247
2017-06-11 04:04:39.550787 EDT | AverageQLoss                2.30236
2017-06-11 04:04:39.551105 EDT | AveragePolicySurr         -29.3243
2017-06-11 04:04:39.552227 EDT | AverageQ                   29.0706
2017-06-11 04:04:39.552579 EDT | AverageAbsQ                29.0898
2017-06-11 04:04:39.552904 EDT | AverageY                   29.0722
2017-06-11 04:04:39.553220 EDT | AverageAbsY                29.0814
2017-06-11 04:04:39.553548 EDT | AverageAbsQYDiff            0.521988
2017-06-11 04:04:39.553940 EDT | AverageAction               0.997871
2017-06-11 04:04:39.554145 EDT | PolicyRegParamNorm        100.426
2017-06-11 04:04:39.554380 EDT | QFunRegParamNorm          130.263
2017-06-11 04:04:39.554695 EDT | -----------------------  -----------
2017-06-11 04:04:39.555178 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1089 | Training started
2017-06-11 04:04:56.101919 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1089 | Training finished
2017-06-11 04:04:56.103301 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1089 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 04:04:56.103688 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1089 | Collecting samples for evaluation
2017-06-11 04:05:11.738970 EDT | -----------------------  -----------
2017-06-11 04:05:11.739341 EDT | Epoch                    1089
2017-06-11 04:05:11.739597 EDT | Iteration                1089
2017-06-11 04:05:11.739847 EDT | AverageReturn            1135.53
2017-06-11 04:05:11.740095 EDT | StdReturn                 262.076
2017-06-11 04:05:11.740339 EDT | MaxReturn                1797.95
2017-06-11 04:05:11.740585 EDT | MinReturn                 941.342
2017-06-11 04:05:11.740829 EDT | AverageEsReturn           412.749
2017-06-11 04:05:11.741073 EDT | StdEsReturn               447.322
2017-06-11 04:05:11.741316 EDT | MaxEsReturn              1354.54
2017-06-11 04:05:11.741557 EDT | MinEsReturn                83.38
2017-06-11 04:05:11.741819 EDT | AverageDiscountedReturn   237.361
2017-06-11 04:05:11.742069 EDT | AverageQLoss                2.11795
2017-06-11 04:05:11.742317 EDT | AveragePolicySurr         -29.3883
2017-06-11 04:05:11.742563 EDT | AverageQ                   29.1471
2017-06-11 04:05:11.742812 EDT | AverageAbsQ                29.1677
2017-06-11 04:05:11.743060 EDT | AverageY                   29.1481
2017-06-11 04:05:11.743307 EDT | AverageAbsY                29.1596
2017-06-11 04:05:11.743554 EDT | AverageAbsQYDiff            0.490673
2017-06-11 04:05:11.743801 EDT | AverageAction               0.998975
2017-06-11 04:05:11.744056 EDT | PolicyRegParamNorm        100.44
2017-06-11 04:05:11.744304 EDT | QFunRegParamNorm          130.303
2017-06-11 04:05:11.744550 EDT | -----------------------  -----------
2017-06-11 04:05:11.744942 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1090 | Training started
2017-06-11 04:05:31.266114 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1090 | Training finished
2017-06-11 04:05:31.267026 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1090 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 04:05:31.267219 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1090 | Collecting samples for evaluation
2017-06-11 04:05:45.522355 EDT | -----------------------  -----------
2017-06-11 04:05:45.523234 EDT | Epoch                    1090
2017-06-11 04:05:45.524742 EDT | Iteration                1090
2017-06-11 04:05:45.525044 EDT | AverageReturn             750.854
2017-06-11 04:05:45.525304 EDT | StdReturn                 780.947
2017-06-11 04:05:45.525580 EDT | MaxReturn                2937.81
2017-06-11 04:05:45.525881 EDT | MinReturn                 204.651
2017-06-11 04:05:45.526122 EDT | AverageEsReturn           446.637
2017-06-11 04:05:45.526278 EDT | StdEsReturn               234.771
2017-06-11 04:05:45.526430 EDT | MaxEsReturn               711.488
2017-06-11 04:05:45.526580 EDT | MinEsReturn                42.5126
2017-06-11 04:05:45.526728 EDT | AverageDiscountedReturn   176.668
2017-06-11 04:05:45.526876 EDT | AverageQLoss                2.17424
2017-06-11 04:05:45.527024 EDT | AveragePolicySurr         -29.2204
2017-06-11 04:05:45.527171 EDT | AverageQ                   29.011
2017-06-11 04:05:45.527319 EDT | AverageAbsQ                29.0273
2017-06-11 04:05:45.527467 EDT | AverageY                   29.0113
2017-06-11 04:05:45.527614 EDT | AverageAbsY                29.0197
2017-06-11 04:05:45.527762 EDT | AverageAbsQYDiff            0.509503
2017-06-11 04:05:45.527909 EDT | AverageAction               0.998349
2017-06-11 04:05:45.528057 EDT | PolicyRegParamNorm        100.412
2017-06-11 04:05:45.528204 EDT | QFunRegParamNorm          130.324
2017-06-11 04:05:45.529539 EDT | -----------------------  -----------
2017-06-11 04:05:45.529939 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1091 | Training started
2017-06-11 04:06:04.251601 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1091 | Training finished
2017-06-11 04:06:04.253262 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1091 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 04:06:04.253588 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1091 | Collecting samples for evaluation
2017-06-11 04:06:18.624470 EDT | -----------------------  -----------
2017-06-11 04:06:18.625358 EDT | Epoch                    1091
2017-06-11 04:06:18.625823 EDT | Iteration                1091
2017-06-11 04:06:18.626328 EDT | AverageReturn             190.096
2017-06-11 04:06:18.626755 EDT | StdReturn                   2.45668
2017-06-11 04:06:18.627191 EDT | MaxReturn                 199.718
2017-06-11 04:06:18.627693 EDT | MinReturn                 185.649
2017-06-11 04:06:18.628116 EDT | AverageEsReturn           418.679
2017-06-11 04:06:18.628632 EDT | StdEsReturn               323.654
2017-06-11 04:06:18.629034 EDT | MaxEsReturn              1041.93
2017-06-11 04:06:18.629460 EDT | MinEsReturn                36.468
2017-06-11 04:06:18.629969 EDT | AverageDiscountedReturn   118.421
2017-06-11 04:06:18.630399 EDT | AverageQLoss                1.92508
2017-06-11 04:06:18.630832 EDT | AveragePolicySurr         -29.1891
2017-06-11 04:06:18.631317 EDT | AverageQ                   28.9725
2017-06-11 04:06:18.631725 EDT | AverageAbsQ                28.9923
2017-06-11 04:06:18.632273 EDT | AverageY                   28.9748
2017-06-11 04:06:18.632612 EDT | AverageAbsY                28.9849
2017-06-11 04:06:18.632949 EDT | AverageAbsQYDiff            0.480838
2017-06-11 04:06:18.633395 EDT | AverageAction               0.998118
2017-06-11 04:06:18.633722 EDT | PolicyRegParamNorm        100.474
2017-06-11 04:06:18.634061 EDT | QFunRegParamNorm          130.398
2017-06-11 04:06:18.634456 EDT | -----------------------  -----------
2017-06-11 04:06:18.634907 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1092 | Training started
2017-06-11 04:06:36.082538 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1092 | Training finished
2017-06-11 04:06:36.083441 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1092 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 04:06:36.083749 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1092 | Collecting samples for evaluation
2017-06-11 04:06:51.292340 EDT | -----------------------  -----------
2017-06-11 04:06:51.293361 EDT | Epoch                    1092
2017-06-11 04:06:51.293817 EDT | Iteration                1092
2017-06-11 04:06:51.294177 EDT | AverageReturn             421.792
2017-06-11 04:06:51.294602 EDT | StdReturn                 470.711
2017-06-11 04:06:51.295035 EDT | MaxReturn                2375.39
2017-06-11 04:06:51.295409 EDT | MinReturn                 206.731
2017-06-11 04:06:51.295799 EDT | AverageEsReturn           402.65
2017-06-11 04:06:51.296232 EDT | StdEsReturn               287.483
2017-06-11 04:06:51.296626 EDT | MaxEsReturn              1026.57
2017-06-11 04:06:51.296993 EDT | MinEsReturn               156.163
2017-06-11 04:06:51.297422 EDT | AverageDiscountedReturn   148.162
2017-06-11 04:06:51.297840 EDT | AverageQLoss                1.98279
2017-06-11 04:06:51.298200 EDT | AveragePolicySurr         -29.1669
2017-06-11 04:06:51.298631 EDT | AverageQ                   28.9683
2017-06-11 04:06:51.299051 EDT | AverageAbsQ                28.9873
2017-06-11 04:06:51.299401 EDT | AverageY                   28.9694
2017-06-11 04:06:51.299827 EDT | AverageAbsY                28.9813
2017-06-11 04:06:51.300252 EDT | AverageAbsQYDiff            0.482184
2017-06-11 04:06:51.300607 EDT | AverageAction               0.998195
2017-06-11 04:06:51.301021 EDT | PolicyRegParamNorm        100.565
2017-06-11 04:06:51.301454 EDT | QFunRegParamNorm          130.433
2017-06-11 04:06:51.301832 EDT | -----------------------  -----------
2017-06-11 04:06:51.302406 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1093 | Training started
2017-06-11 04:07:08.187040 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1093 | Training finished
2017-06-11 04:07:08.187812 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1093 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 04:07:08.188111 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1093 | Collecting samples for evaluation
2017-06-11 04:07:23.219420 EDT | -----------------------  -----------
2017-06-11 04:07:23.220410 EDT | Epoch                    1093
2017-06-11 04:07:23.220746 EDT | Iteration                1093
2017-06-11 04:07:23.221064 EDT | AverageReturn             183.979
2017-06-11 04:07:23.221379 EDT | StdReturn                   2.66203
2017-06-11 04:07:23.221700 EDT | MaxReturn                 192.268
2017-06-11 04:07:23.222015 EDT | MinReturn                 176.061
2017-06-11 04:07:23.222326 EDT | AverageEsReturn           317.692
2017-06-11 04:07:23.222632 EDT | StdEsReturn               124.616
2017-06-11 04:07:23.222941 EDT | MaxEsReturn               569.869
2017-06-11 04:07:23.223256 EDT | MinEsReturn               184.859
2017-06-11 04:07:23.223578 EDT | AverageDiscountedReturn   115.582
2017-06-11 04:07:23.223912 EDT | AverageQLoss                2.17866
2017-06-11 04:07:23.224219 EDT | AveragePolicySurr         -29.1855
2017-06-11 04:07:23.224528 EDT | AverageQ                   28.9786
2017-06-11 04:07:23.224833 EDT | AverageAbsQ                28.9985
2017-06-11 04:07:23.225138 EDT | AverageY                   28.9804
2017-06-11 04:07:23.225447 EDT | AverageAbsY                28.9889
2017-06-11 04:07:23.225762 EDT | AverageAbsQYDiff            0.507359
2017-06-11 04:07:23.226070 EDT | AverageAction               0.998165
2017-06-11 04:07:23.226381 EDT | PolicyRegParamNorm        100.609
2017-06-11 04:07:23.226729 EDT | QFunRegParamNorm          130.507
2017-06-11 04:07:23.227046 EDT | -----------------------  -----------
2017-06-11 04:07:23.227488 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1094 | Training started
2017-06-11 04:07:40.281842 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1094 | Training finished
2017-06-11 04:07:40.282423 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1094 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 04:07:40.282929 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1094 | Collecting samples for evaluation
2017-06-11 04:07:53.094849 EDT | -----------------------  -----------
2017-06-11 04:07:53.095680 EDT | Epoch                    1094
2017-06-11 04:07:53.096176 EDT | Iteration                1094
2017-06-11 04:07:53.096473 EDT | AverageReturn             184.167
2017-06-11 04:07:53.098692 EDT | StdReturn                  12.6238
2017-06-11 04:07:53.099293 EDT | MaxReturn                 209.845
2017-06-11 04:07:53.099461 EDT | MinReturn                 167.913
2017-06-11 04:07:53.099618 EDT | AverageEsReturn           219.602
2017-06-11 04:07:53.099772 EDT | StdEsReturn               180.113
2017-06-11 04:07:53.100023 EDT | MaxEsReturn               634.181
2017-06-11 04:07:53.100205 EDT | MinEsReturn                21.4871
2017-06-11 04:07:53.100371 EDT | AverageDiscountedReturn   115.523
2017-06-11 04:07:53.100538 EDT | AverageQLoss                2.16591
2017-06-11 04:07:53.100721 EDT | AveragePolicySurr         -29.1455
2017-06-11 04:07:53.100878 EDT | AverageQ                   28.9428
2017-06-11 04:07:53.101035 EDT | AverageAbsQ                28.9664
2017-06-11 04:07:53.101193 EDT | AverageY                   28.9444
2017-06-11 04:07:53.101349 EDT | AverageAbsY                28.9572
2017-06-11 04:07:53.101505 EDT | AverageAbsQYDiff            0.488518
2017-06-11 04:07:53.101661 EDT | AverageAction               0.998392
2017-06-11 04:07:53.101992 EDT | PolicyRegParamNorm        100.627
2017-06-11 04:07:53.102410 EDT | QFunRegParamNorm          130.563
2017-06-11 04:07:53.102812 EDT | -----------------------  -----------
2017-06-11 04:07:53.105630 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1095 | Training started
2017-06-11 04:08:10.681703 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1095 | Training finished
2017-06-11 04:08:10.682604 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1095 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 04:08:10.683416 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1095 | Collecting samples for evaluation
2017-06-11 04:08:24.399791 EDT | -----------------------  -----------
2017-06-11 04:08:24.400570 EDT | Epoch                    1095
2017-06-11 04:08:24.400773 EDT | Iteration                1095
2017-06-11 04:08:24.400973 EDT | AverageReturn            1033.85
2017-06-11 04:08:24.401221 EDT | StdReturn                 366.015
2017-06-11 04:08:24.401493 EDT | MaxReturn                1933.95
2017-06-11 04:08:24.401815 EDT | MinReturn                 416.47
2017-06-11 04:08:24.402246 EDT | AverageEsReturn           369.371
2017-06-11 04:08:24.402720 EDT | StdEsReturn               237.541
2017-06-11 04:08:24.403137 EDT | MaxEsReturn               845.668
2017-06-11 04:08:24.403606 EDT | MinEsReturn                93.1757
2017-06-11 04:08:24.404058 EDT | AverageDiscountedReturn   224.867
2017-06-11 04:08:24.404475 EDT | AverageQLoss                1.86384
2017-06-11 04:08:24.404949 EDT | AveragePolicySurr         -29.0894
2017-06-11 04:08:24.405361 EDT | AverageQ                   28.8753
2017-06-11 04:08:24.405819 EDT | AverageAbsQ                28.8928
2017-06-11 04:08:24.406178 EDT | AverageY                   28.877
2017-06-11 04:08:24.406741 EDT | AverageAbsY                28.8855
2017-06-11 04:08:24.407191 EDT | AverageAbsQYDiff            0.476486
2017-06-11 04:08:24.407388 EDT | AverageAction               0.998093
2017-06-11 04:08:24.407972 EDT | PolicyRegParamNorm        100.707
2017-06-11 04:08:24.408436 EDT | QFunRegParamNorm          130.591
2017-06-11 04:08:24.408891 EDT | -----------------------  -----------
2017-06-11 04:08:24.409503 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1096 | Training started
2017-06-11 04:08:41.380116 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1096 | Training finished
2017-06-11 04:08:41.380452 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1096 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 04:08:41.380665 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1096 | Collecting samples for evaluation
2017-06-11 04:08:55.435513 EDT | -----------------------  -----------
2017-06-11 04:08:55.436493 EDT | Epoch                    1096
2017-06-11 04:08:55.436881 EDT | Iteration                1096
2017-06-11 04:08:55.437355 EDT | AverageReturn             904.152
2017-06-11 04:08:55.437715 EDT | StdReturn                 135.921
2017-06-11 04:08:55.438054 EDT | MaxReturn                1345.2
2017-06-11 04:08:55.438410 EDT | MinReturn                 704.362
2017-06-11 04:08:55.438742 EDT | AverageEsReturn           338.489
2017-06-11 04:08:55.439102 EDT | StdEsReturn               251.658
2017-06-11 04:08:55.439456 EDT | MaxEsReturn               795.977
2017-06-11 04:08:55.439786 EDT | MinEsReturn                34.3645
2017-06-11 04:08:55.440105 EDT | AverageDiscountedReturn   229.541
2017-06-11 04:08:55.440423 EDT | AverageQLoss                1.87924
2017-06-11 04:08:55.440743 EDT | AveragePolicySurr         -29.2521
2017-06-11 04:08:55.441063 EDT | AverageQ                   29.0386
2017-06-11 04:08:55.441380 EDT | AverageAbsQ                29.0542
2017-06-11 04:08:55.441717 EDT | AverageY                   29.0381
2017-06-11 04:08:55.442046 EDT | AverageAbsY                29.0435
2017-06-11 04:08:55.442377 EDT | AverageAbsQYDiff            0.487724
2017-06-11 04:08:55.442727 EDT | AverageAction               0.997732
2017-06-11 04:08:55.443075 EDT | PolicyRegParamNorm        100.75
2017-06-11 04:08:55.443399 EDT | QFunRegParamNorm          130.614
2017-06-11 04:08:55.443718 EDT | -----------------------  -----------
2017-06-11 04:08:55.444161 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1097 | Training started
2017-06-11 04:09:10.629608 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1097 | Training finished
2017-06-11 04:09:10.630962 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1097 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 04:09:10.631344 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1097 | Collecting samples for evaluation
2017-06-11 04:09:25.583450 EDT | -----------------------  -----------
2017-06-11 04:09:25.584249 EDT | Epoch                    1097
2017-06-11 04:09:25.584431 EDT | Iteration                1097
2017-06-11 04:09:25.584601 EDT | AverageReturn            1095.66
2017-06-11 04:09:25.584900 EDT | StdReturn                 172.623
2017-06-11 04:09:25.585058 EDT | MaxReturn                1673.72
2017-06-11 04:09:25.585211 EDT | MinReturn                 942.675
2017-06-11 04:09:25.585436 EDT | AverageEsReturn           423.017
2017-06-11 04:09:25.585599 EDT | StdEsReturn               268.978
2017-06-11 04:09:25.585883 EDT | MaxEsReturn               796.368
2017-06-11 04:09:25.586039 EDT | MinEsReturn                20.8077
2017-06-11 04:09:25.586191 EDT | AverageDiscountedReturn   251.179
2017-06-11 04:09:25.586353 EDT | AverageQLoss                2.10723
2017-06-11 04:09:25.586568 EDT | AveragePolicySurr         -29.1518
2017-06-11 04:09:25.586760 EDT | AverageQ                   28.9129
2017-06-11 04:09:25.586991 EDT | AverageAbsQ                28.9317
2017-06-11 04:09:25.587143 EDT | AverageY                   28.9162
2017-06-11 04:09:25.587307 EDT | AverageAbsY                28.9258
2017-06-11 04:09:25.587499 EDT | AverageAbsQYDiff            0.506312
2017-06-11 04:09:25.587818 EDT | AverageAction               0.997848
2017-06-11 04:09:25.587973 EDT | PolicyRegParamNorm        100.759
2017-06-11 04:09:25.588179 EDT | QFunRegParamNorm          130.667
2017-06-11 04:09:25.588627 EDT | -----------------------  -----------
2017-06-11 04:09:25.588988 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1098 | Training started
2017-06-11 04:09:43.613814 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1098 | Training finished
2017-06-11 04:09:43.629769 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1098 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 04:09:43.630164 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1098 | Collecting samples for evaluation
2017-06-11 04:09:56.450634 EDT | -----------------------  -----------
2017-06-11 04:09:56.451766 EDT | Epoch                    1098
2017-06-11 04:09:56.452120 EDT | Iteration                1098
2017-06-11 04:09:56.452445 EDT | AverageReturn             229.237
2017-06-11 04:09:56.452762 EDT | StdReturn                 109.855
2017-06-11 04:09:56.453076 EDT | MaxReturn                1085.89
2017-06-11 04:09:56.453395 EDT | MinReturn                 202.351
2017-06-11 04:09:56.454087 EDT | AverageEsReturn           396.258
2017-06-11 04:09:56.454403 EDT | StdEsReturn                89.9987
2017-06-11 04:09:56.458050 EDT | MaxEsReturn               539.39
2017-06-11 04:09:56.458319 EDT | MinEsReturn               279.965
2017-06-11 04:09:56.458580 EDT | AverageDiscountedReturn   129.819
2017-06-11 04:09:56.458837 EDT | AverageQLoss                2.28577
2017-06-11 04:09:56.459090 EDT | AveragePolicySurr         -29.0892
2017-06-11 04:09:56.459343 EDT | AverageQ                   28.8841
2017-06-11 04:09:56.459595 EDT | AverageAbsQ                28.9005
2017-06-11 04:09:56.459848 EDT | AverageY                   28.8854
2017-06-11 04:09:56.460098 EDT | AverageAbsY                28.8964
2017-06-11 04:09:56.460349 EDT | AverageAbsQYDiff            0.500304
2017-06-11 04:09:56.460600 EDT | AverageAction               0.996838
2017-06-11 04:09:56.460849 EDT | PolicyRegParamNorm        100.837
2017-06-11 04:09:56.461099 EDT | QFunRegParamNorm          130.733
2017-06-11 04:09:56.461350 EDT | -----------------------  -----------
2017-06-11 04:09:56.461766 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1099 | Training started
2017-06-11 04:10:13.749663 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1099 | Training finished
2017-06-11 04:10:13.750597 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1099 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 04:10:13.751134 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1099 | Collecting samples for evaluation
2017-06-11 04:10:28.354779 EDT | -----------------------  -----------
2017-06-11 04:10:28.355654 EDT | Epoch                    1099
2017-06-11 04:10:28.356096 EDT | Iteration                1099
2017-06-11 04:10:28.356820 EDT | AverageReturn            1135.54
2017-06-11 04:10:28.357644 EDT | StdReturn                 352.964
2017-06-11 04:10:28.358081 EDT | MaxReturn                2412.94
2017-06-11 04:10:28.358512 EDT | MinReturn                 705.575
2017-06-11 04:10:28.359353 EDT | AverageEsReturn           302.654
2017-06-11 04:10:28.359791 EDT | StdEsReturn               200.775
2017-06-11 04:10:28.360209 EDT | MaxEsReturn               666.774
2017-06-11 04:10:28.360642 EDT | MinEsReturn                32.6783
2017-06-11 04:10:28.361262 EDT | AverageDiscountedReturn   239.853
2017-06-11 04:10:28.361951 EDT | AverageQLoss                2.04909
2017-06-11 04:10:28.362929 EDT | AveragePolicySurr         -29.0614
2017-06-11 04:10:28.363329 EDT | AverageQ                   28.844
2017-06-11 04:10:28.363757 EDT | AverageAbsQ                28.8608
2017-06-11 04:10:28.364169 EDT | AverageY                   28.8451
2017-06-11 04:10:28.364605 EDT | AverageAbsY                28.8542
2017-06-11 04:10:28.365047 EDT | AverageAbsQYDiff            0.49423
2017-06-11 04:10:28.365601 EDT | AverageAction               0.997039
2017-06-11 04:10:28.366057 EDT | PolicyRegParamNorm        100.911
2017-06-11 04:10:28.366850 EDT | QFunRegParamNorm          130.769
2017-06-11 04:10:28.367906 EDT | -----------------------  -----------
2017-06-11 04:10:28.368453 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1100 | Training started
2017-06-11 04:10:46.471137 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1100 | Training finished
2017-06-11 04:10:46.471386 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1100 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 04:10:46.471570 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1100 | Collecting samples for evaluation
2017-06-11 04:11:01.571136 EDT | -----------------------  -----------
2017-06-11 04:11:01.571994 EDT | Epoch                    1100
2017-06-11 04:11:01.572285 EDT | Iteration                1100
2017-06-11 04:11:01.572544 EDT | AverageReturn            1159.54
2017-06-11 04:11:01.572796 EDT | StdReturn                 388.361
2017-06-11 04:11:01.573056 EDT | MaxReturn                2913.04
2017-06-11 04:11:01.573307 EDT | MinReturn                 748.522
2017-06-11 04:11:01.573553 EDT | AverageEsReturn           387.919
2017-06-11 04:11:01.573815 EDT | StdEsReturn               271.603
2017-06-11 04:11:01.574057 EDT | MaxEsReturn               685.392
2017-06-11 04:11:01.574299 EDT | MinEsReturn                12.6332
2017-06-11 04:11:01.574539 EDT | AverageDiscountedReturn   251.277
2017-06-11 04:11:01.574780 EDT | AverageQLoss                1.60358
2017-06-11 04:11:01.575020 EDT | AveragePolicySurr         -29.0285
2017-06-11 04:11:01.575259 EDT | AverageQ                   28.8182
2017-06-11 04:11:01.575498 EDT | AverageAbsQ                28.8374
2017-06-11 04:11:01.575736 EDT | AverageY                   28.8189
2017-06-11 04:11:01.575975 EDT | AverageAbsY                28.8289
2017-06-11 04:11:01.576214 EDT | AverageAbsQYDiff            0.465939
2017-06-11 04:11:01.576453 EDT | AverageAction               0.997758
2017-06-11 04:11:01.576691 EDT | PolicyRegParamNorm        100.923
2017-06-11 04:11:01.576930 EDT | QFunRegParamNorm          130.791
2017-06-11 04:11:01.577169 EDT | -----------------------  -----------
2017-06-11 04:11:01.577553 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1101 | Training started
2017-06-11 04:11:18.129000 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1101 | Training finished
2017-06-11 04:11:18.129319 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1101 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 04:11:18.129899 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1101 | Collecting samples for evaluation
2017-06-11 04:11:32.990981 EDT | -----------------------  -----------
2017-06-11 04:11:32.991881 EDT | Epoch                    1101
2017-06-11 04:11:32.992227 EDT | Iteration                1101
2017-06-11 04:11:32.994907 EDT | AverageReturn             425.344
2017-06-11 04:11:32.995679 EDT | StdReturn                 489.115
2017-06-11 04:11:32.995997 EDT | MaxReturn                1325.32
2017-06-11 04:11:32.996306 EDT | MinReturn                   5.77978
2017-06-11 04:11:32.996571 EDT | AverageEsReturn           389.113
2017-06-11 04:11:32.996939 EDT | StdEsReturn               388.94
2017-06-11 04:11:32.997248 EDT | MaxEsReturn              1025.53
2017-06-11 04:11:32.997611 EDT | MinEsReturn                10.0946
2017-06-11 04:11:32.997958 EDT | AverageDiscountedReturn   112.064
2017-06-11 04:11:32.998289 EDT | AverageQLoss                1.85306
2017-06-11 04:11:32.998746 EDT | AveragePolicySurr         -28.9779
2017-06-11 04:11:32.999062 EDT | AverageQ                   28.775
2017-06-11 04:11:32.999250 EDT | AverageAbsQ                28.7907
2017-06-11 04:11:32.999432 EDT | AverageY                   28.7755
2017-06-11 04:11:32.999608 EDT | AverageAbsY                28.7819
2017-06-11 04:11:32.999810 EDT | AverageAbsQYDiff            0.481073
2017-06-11 04:11:32.999994 EDT | AverageAction               0.997671
2017-06-11 04:11:33.000176 EDT | PolicyRegParamNorm        100.93
2017-06-11 04:11:33.000358 EDT | QFunRegParamNorm          130.847
2017-06-11 04:11:33.000539 EDT | -----------------------  -----------
2017-06-11 04:11:33.000814 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1102 | Training started
2017-06-11 04:11:51.249942 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1102 | Training finished
2017-06-11 04:11:51.251070 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1102 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 04:11:51.251346 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1102 | Collecting samples for evaluation
2017-06-11 04:12:04.311427 EDT | -----------------------  -----------
2017-06-11 04:12:04.312579 EDT | Epoch                    1102
2017-06-11 04:12:04.313042 EDT | Iteration                1102
2017-06-11 04:12:04.313490 EDT | AverageReturn             677.45
2017-06-11 04:12:04.313917 EDT | StdReturn                  98.0746
2017-06-11 04:12:04.314311 EDT | MaxReturn                 775.068
2017-06-11 04:12:04.314754 EDT | MinReturn                 489.416
2017-06-11 04:12:04.315203 EDT | AverageEsReturn           234.384
2017-06-11 04:12:04.315649 EDT | StdEsReturn               279.837
2017-06-11 04:12:04.316091 EDT | MaxEsReturn               755.369
2017-06-11 04:12:04.316538 EDT | MinEsReturn                 5.64745
2017-06-11 04:12:04.316983 EDT | AverageDiscountedReturn   242.09
2017-06-11 04:12:04.317432 EDT | AverageQLoss                2.14642
2017-06-11 04:12:04.317888 EDT | AveragePolicySurr         -28.9405
2017-06-11 04:12:04.318338 EDT | AverageQ                   28.7495
2017-06-11 04:12:04.318789 EDT | AverageAbsQ                28.7719
2017-06-11 04:12:04.319233 EDT | AverageY                   28.7511
2017-06-11 04:12:04.319826 EDT | AverageAbsY                28.7628
2017-06-11 04:12:04.320374 EDT | AverageAbsQYDiff            0.510517
2017-06-11 04:12:04.320827 EDT | AverageAction               0.997788
2017-06-11 04:12:04.321286 EDT | PolicyRegParamNorm        100.954
2017-06-11 04:12:04.321736 EDT | QFunRegParamNorm          130.907
2017-06-11 04:12:04.322429 EDT | -----------------------  -----------
2017-06-11 04:12:04.323200 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1103 | Training started
2017-06-11 04:12:21.641034 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1103 | Training finished
2017-06-11 04:12:21.642300 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1103 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 04:12:21.642682 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1103 | Collecting samples for evaluation
2017-06-11 04:12:35.909423 EDT | -----------------------  -----------
2017-06-11 04:12:35.911107 EDT | Epoch                    1103
2017-06-11 04:12:35.911947 EDT | Iteration                1103
2017-06-11 04:12:35.914218 EDT | AverageReturn            2729.86
2017-06-11 04:12:35.914613 EDT | StdReturn                1066.29
2017-06-11 04:12:35.915565 EDT | MaxReturn                3662.83
2017-06-11 04:12:35.916028 EDT | MinReturn                1062.6
2017-06-11 04:12:35.916479 EDT | AverageEsReturn           248.967
2017-06-11 04:12:35.916928 EDT | StdEsReturn               216.955
2017-06-11 04:12:35.917886 EDT | MaxEsReturn               582.24
2017-06-11 04:12:35.918989 EDT | MinEsReturn                19.0011
2017-06-11 04:12:35.920972 EDT | AverageDiscountedReturn   274.205
2017-06-11 04:12:35.921443 EDT | AverageQLoss                2.17123
2017-06-11 04:12:35.922471 EDT | AveragePolicySurr         -28.9177
2017-06-11 04:12:35.924404 EDT | AverageQ                   28.7319
2017-06-11 04:12:35.924872 EDT | AverageAbsQ                28.7507
2017-06-11 04:12:35.925228 EDT | AverageY                   28.7332
2017-06-11 04:12:35.925573 EDT | AverageAbsY                28.7418
2017-06-11 04:12:35.925932 EDT | AverageAbsQYDiff            0.505452
2017-06-11 04:12:35.926274 EDT | AverageAction               0.997876
2017-06-11 04:12:35.926617 EDT | PolicyRegParamNorm        100.985
2017-06-11 04:12:35.926962 EDT | QFunRegParamNorm          130.938
2017-06-11 04:12:35.927308 EDT | -----------------------  -----------
2017-06-11 04:12:35.927784 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1104 | Training started
2017-06-11 04:12:54.320203 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1104 | Training finished
2017-06-11 04:12:54.321272 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1104 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 04:12:54.321738 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1104 | Collecting samples for evaluation
2017-06-11 04:13:08.562861 EDT | -----------------------  -----------
2017-06-11 04:13:08.563590 EDT | Epoch                    1104
2017-06-11 04:13:08.563933 EDT | Iteration                1104
2017-06-11 04:13:08.564278 EDT | AverageReturn            2615.75
2017-06-11 04:13:08.564687 EDT | StdReturn                 866.823
2017-06-11 04:13:08.565103 EDT | MaxReturn                3542.95
2017-06-11 04:13:08.565534 EDT | MinReturn                 475.169
2017-06-11 04:13:08.565969 EDT | AverageEsReturn           434.734
2017-06-11 04:13:08.566336 EDT | StdEsReturn               181.604
2017-06-11 04:13:08.566726 EDT | MaxEsReturn               790.386
2017-06-11 04:13:08.567124 EDT | MinEsReturn               181.65
2017-06-11 04:13:08.567514 EDT | AverageDiscountedReturn   265.459
2017-06-11 04:13:08.567938 EDT | AverageQLoss                2.07272
2017-06-11 04:13:08.568365 EDT | AveragePolicySurr         -28.9953
2017-06-11 04:13:08.568893 EDT | AverageQ                   28.7774
2017-06-11 04:13:08.569261 EDT | AverageAbsQ                28.7978
2017-06-11 04:13:08.569672 EDT | AverageY                   28.7793
2017-06-11 04:13:08.570003 EDT | AverageAbsY                28.792
2017-06-11 04:13:08.570353 EDT | AverageAbsQYDiff            0.493036
2017-06-11 04:13:08.570782 EDT | AverageAction               0.998067
2017-06-11 04:13:08.571116 EDT | PolicyRegParamNorm        100.955
2017-06-11 04:13:08.571430 EDT | QFunRegParamNorm          131.014
2017-06-11 04:13:08.571756 EDT | -----------------------  -----------
2017-06-11 04:13:08.572233 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1105 | Training started
2017-06-11 04:13:25.108944 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1105 | Training finished
2017-06-11 04:13:25.109915 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1105 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 04:13:25.110229 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1105 | Collecting samples for evaluation
2017-06-11 04:13:39.916699 EDT | -----------------------  -----------
2017-06-11 04:13:39.917653 EDT | Epoch                    1105
2017-06-11 04:13:39.918043 EDT | Iteration                1105
2017-06-11 04:13:39.918379 EDT | AverageReturn            1912.83
2017-06-11 04:13:39.918709 EDT | StdReturn                 720.523
2017-06-11 04:13:39.919035 EDT | MaxReturn                3275.03
2017-06-11 04:13:39.919361 EDT | MinReturn                 809.182
2017-06-11 04:13:39.921585 EDT | AverageEsReturn           442.412
2017-06-11 04:13:39.921952 EDT | StdEsReturn               152.993
2017-06-11 04:13:39.922284 EDT | MaxEsReturn               694.504
2017-06-11 04:13:39.922616 EDT | MinEsReturn               199.99
2017-06-11 04:13:39.922940 EDT | AverageDiscountedReturn   263.686
2017-06-11 04:13:39.923285 EDT | AverageQLoss                2.04306
2017-06-11 04:13:39.923611 EDT | AveragePolicySurr         -28.9079
2017-06-11 04:13:39.924002 EDT | AverageQ                   28.6904
2017-06-11 04:13:39.925033 EDT | AverageAbsQ                28.7143
2017-06-11 04:13:39.925806 EDT | AverageY                   28.6927
2017-06-11 04:13:39.926529 EDT | AverageAbsY                28.704
2017-06-11 04:13:39.927270 EDT | AverageAbsQYDiff            0.505166
2017-06-11 04:13:39.928064 EDT | AverageAction               0.998086
2017-06-11 04:13:39.928858 EDT | PolicyRegParamNorm        101.062
2017-06-11 04:13:39.929597 EDT | QFunRegParamNorm          131.074
2017-06-11 04:13:39.930301 EDT | -----------------------  -----------
2017-06-11 04:13:39.931138 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1106 | Training started
2017-06-11 04:13:57.873451 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1106 | Training finished
2017-06-11 04:13:57.874879 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1106 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 04:13:57.875278 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1106 | Collecting samples for evaluation
2017-06-11 04:14:11.929016 EDT | -----------------------  -----------
2017-06-11 04:14:11.929934 EDT | Epoch                    1106
2017-06-11 04:14:11.930304 EDT | Iteration                1106
2017-06-11 04:14:11.930658 EDT | AverageReturn            1669.74
2017-06-11 04:14:11.931002 EDT | StdReturn                 770.081
2017-06-11 04:14:11.931344 EDT | MaxReturn                3124.72
2017-06-11 04:14:11.931690 EDT | MinReturn                 681.186
2017-06-11 04:14:11.932031 EDT | AverageEsReturn           392.361
2017-06-11 04:14:11.932375 EDT | StdEsReturn               254.319
2017-06-11 04:14:11.932722 EDT | MaxEsReturn               816.576
2017-06-11 04:14:11.933066 EDT | MinEsReturn                 7.40906
2017-06-11 04:14:11.933417 EDT | AverageDiscountedReturn   239.393
2017-06-11 04:14:11.934090 EDT | AverageQLoss                1.98974
2017-06-11 04:14:11.934441 EDT | AveragePolicySurr         -28.96
2017-06-11 04:14:11.935140 EDT | AverageQ                   28.7449
2017-06-11 04:14:11.935490 EDT | AverageAbsQ                28.7633
2017-06-11 04:14:11.935855 EDT | AverageY                   28.7458
2017-06-11 04:14:11.937678 EDT | AverageAbsY                28.7529
2017-06-11 04:14:11.939337 EDT | AverageAbsQYDiff            0.483379
2017-06-11 04:14:11.939698 EDT | AverageAction               0.997551
2017-06-11 04:14:11.940044 EDT | PolicyRegParamNorm        101.104
2017-06-11 04:14:11.940394 EDT | QFunRegParamNorm          131.117
2017-06-11 04:14:11.940741 EDT | -----------------------  -----------
2017-06-11 04:14:11.941258 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1107 | Training started
2017-06-11 04:14:30.393882 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1107 | Training finished
2017-06-11 04:14:30.396514 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1107 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 04:14:30.396927 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1107 | Collecting samples for evaluation
2017-06-11 04:14:44.941550 EDT | -----------------------  -----------
2017-06-11 04:14:44.942326 EDT | Epoch                    1107
2017-06-11 04:14:44.942556 EDT | Iteration                1107
2017-06-11 04:14:44.942748 EDT | AverageReturn            2469.34
2017-06-11 04:14:44.942932 EDT | StdReturn                 638.838
2017-06-11 04:14:44.943114 EDT | MaxReturn                3298.28
2017-06-11 04:14:44.943294 EDT | MinReturn                1491.53
2017-06-11 04:14:44.943475 EDT | AverageEsReturn           391.573
2017-06-11 04:14:44.943732 EDT | StdEsReturn               267.359
2017-06-11 04:14:44.943912 EDT | MaxEsReturn               754.782
2017-06-11 04:14:44.944072 EDT | MinEsReturn                40.2626
2017-06-11 04:14:44.944237 EDT | AverageDiscountedReturn   250.485
2017-06-11 04:14:44.944415 EDT | AverageQLoss                1.98763
2017-06-11 04:14:44.944581 EDT | AveragePolicySurr         -28.985
2017-06-11 04:14:44.944762 EDT | AverageQ                   28.7668
2017-06-11 04:14:44.944997 EDT | AverageAbsQ                28.7845
2017-06-11 04:14:44.945156 EDT | AverageY                   28.7679
2017-06-11 04:14:44.945313 EDT | AverageAbsY                28.7752
2017-06-11 04:14:44.945470 EDT | AverageAbsQYDiff            0.497899
2017-06-11 04:14:44.945709 EDT | AverageAction               0.997317
2017-06-11 04:14:44.945869 EDT | PolicyRegParamNorm        101.139
2017-06-11 04:14:44.946021 EDT | QFunRegParamNorm          131.177
2017-06-11 04:14:44.946172 EDT | -----------------------  -----------
2017-06-11 04:14:44.946428 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1108 | Training started
2017-06-11 04:15:02.944260 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1108 | Training finished
2017-06-11 04:15:02.945096 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1108 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 04:15:02.945504 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1108 | Collecting samples for evaluation
2017-06-11 04:15:16.093843 EDT | -----------------------  -----------
2017-06-11 04:15:16.094293 EDT | Epoch                    1108
2017-06-11 04:15:16.095172 EDT | Iteration                1108
2017-06-11 04:15:16.095549 EDT | AverageReturn            1463.94
2017-06-11 04:15:16.095811 EDT | StdReturn                1085.23
2017-06-11 04:15:16.097425 EDT | MaxReturn                3561.87
2017-06-11 04:15:16.098565 EDT | MinReturn                 427.906
2017-06-11 04:15:16.098886 EDT | AverageEsReturn           345.631
2017-06-11 04:15:16.099189 EDT | StdEsReturn               213.111
2017-06-11 04:15:16.099508 EDT | MaxEsReturn               657.011
2017-06-11 04:15:16.099825 EDT | MinEsReturn                11.3627
2017-06-11 04:15:16.100139 EDT | AverageDiscountedReturn   236.904
2017-06-11 04:15:16.100419 EDT | AverageQLoss                1.73821
2017-06-11 04:15:16.100579 EDT | AveragePolicySurr         -29.0808
2017-06-11 04:15:16.100767 EDT | AverageQ                   28.8623
2017-06-11 04:15:16.101088 EDT | AverageAbsQ                28.8813
2017-06-11 04:15:16.101299 EDT | AverageY                   28.8627
2017-06-11 04:15:16.101480 EDT | AverageAbsY                28.8723
2017-06-11 04:15:16.101632 EDT | AverageAbsQYDiff            0.479953
2017-06-11 04:15:16.101794 EDT | AverageAction               0.998218
2017-06-11 04:15:16.101945 EDT | PolicyRegParamNorm        101.18
2017-06-11 04:15:16.102093 EDT | QFunRegParamNorm          131.186
2017-06-11 04:15:16.102241 EDT | -----------------------  -----------
2017-06-11 04:15:16.102500 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1109 | Training started
2017-06-11 04:15:33.145540 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1109 | Training finished
2017-06-11 04:15:33.146420 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1109 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 04:15:33.146945 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1109 | Collecting samples for evaluation
2017-06-11 04:15:47.666167 EDT | -----------------------  -----------
2017-06-11 04:15:47.666605 EDT | Epoch                    1109
2017-06-11 04:15:47.666951 EDT | Iteration                1109
2017-06-11 04:15:47.667264 EDT | AverageReturn            1150.44
2017-06-11 04:15:47.667525 EDT | StdReturn                 605.61
2017-06-11 04:15:47.667780 EDT | MaxReturn                3436.47
2017-06-11 04:15:47.668028 EDT | MinReturn                 431.472
2017-06-11 04:15:47.668277 EDT | AverageEsReturn           264.521
2017-06-11 04:15:47.668521 EDT | StdEsReturn               196.787
2017-06-11 04:15:47.668849 EDT | MaxEsReturn               650.244
2017-06-11 04:15:47.669181 EDT | MinEsReturn                 8.46023
2017-06-11 04:15:47.669509 EDT | AverageDiscountedReturn   244.245
2017-06-11 04:15:47.669800 EDT | AverageQLoss                1.58158
2017-06-11 04:15:47.670064 EDT | AveragePolicySurr         -28.9858
2017-06-11 04:15:47.670310 EDT | AverageQ                   28.7866
2017-06-11 04:15:47.670552 EDT | AverageAbsQ                28.8079
2017-06-11 04:15:47.670794 EDT | AverageY                   28.7882
2017-06-11 04:15:47.671063 EDT | AverageAbsY                28.8008
2017-06-11 04:15:47.671384 EDT | AverageAbsQYDiff            0.458407
2017-06-11 04:15:47.671726 EDT | AverageAction               0.998037
2017-06-11 04:15:47.672053 EDT | PolicyRegParamNorm        101.254
2017-06-11 04:15:47.672315 EDT | QFunRegParamNorm          131.239
2017-06-11 04:15:47.672568 EDT | -----------------------  -----------
2017-06-11 04:15:47.672967 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1110 | Training started
2017-06-11 04:16:06.469327 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1110 | Training finished
2017-06-11 04:16:06.470390 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1110 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 04:16:06.470884 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1110 | Collecting samples for evaluation
2017-06-11 04:16:21.959134 EDT | -----------------------  -----------
2017-06-11 04:16:21.960061 EDT | Epoch                    1110
2017-06-11 04:16:21.960527 EDT | Iteration                1110
2017-06-11 04:16:21.960883 EDT | AverageReturn            1256.53
2017-06-11 04:16:21.961210 EDT | StdReturn                 213.966
2017-06-11 04:16:21.961618 EDT | MaxReturn                1592.06
2017-06-11 04:16:21.962068 EDT | MinReturn                 675.103
2017-06-11 04:16:21.962449 EDT | AverageEsReturn           216.412
2017-06-11 04:16:21.962812 EDT | StdEsReturn               171.696
2017-06-11 04:16:21.963175 EDT | MaxEsReturn               450.521
2017-06-11 04:16:21.963555 EDT | MinEsReturn                 5.37979
2017-06-11 04:16:21.963909 EDT | AverageDiscountedReturn   246.613
2017-06-11 04:16:21.964257 EDT | AverageQLoss                2.20332
2017-06-11 04:16:21.964602 EDT | AveragePolicySurr         -28.8986
2017-06-11 04:16:21.964903 EDT | AverageQ                   28.6929
2017-06-11 04:16:21.965206 EDT | AverageAbsQ                28.7109
2017-06-11 04:16:21.965498 EDT | AverageY                   28.693
2017-06-11 04:16:21.965810 EDT | AverageAbsY                28.7029
2017-06-11 04:16:21.966108 EDT | AverageAbsQYDiff            0.509854
2017-06-11 04:16:21.966406 EDT | AverageAction               0.997977
2017-06-11 04:16:21.966793 EDT | PolicyRegParamNorm        101.323
2017-06-11 04:16:21.967189 EDT | QFunRegParamNorm          131.261
2017-06-11 04:16:21.967605 EDT | -----------------------  -----------
2017-06-11 04:16:21.968118 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1111 | Training started
2017-06-11 04:16:39.104132 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1111 | Training finished
2017-06-11 04:16:39.104997 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1111 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 04:16:39.105301 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1111 | Collecting samples for evaluation
2017-06-11 04:16:56.679500 EDT | -----------------------  -----------
2017-06-11 04:16:56.680496 EDT | Epoch                    1111
2017-06-11 04:16:56.683767 EDT | Iteration                1111
2017-06-11 04:16:56.684141 EDT | AverageReturn               7.43053
2017-06-11 04:16:56.685389 EDT | StdReturn                   0.120635
2017-06-11 04:16:56.685872 EDT | MaxReturn                   7.67244
2017-06-11 04:16:56.686320 EDT | MinReturn                   6.05946
2017-06-11 04:16:56.686778 EDT | AverageEsReturn           573.446
2017-06-11 04:16:56.687200 EDT | StdEsReturn               461.066
2017-06-11 04:16:56.687623 EDT | MaxEsReturn              1263.5
2017-06-11 04:16:56.688081 EDT | MinEsReturn                36.2062
2017-06-11 04:16:56.688477 EDT | AverageDiscountedReturn     7.16714
2017-06-11 04:16:56.688935 EDT | AverageQLoss                2.14866
2017-06-11 04:16:56.690222 EDT | AveragePolicySurr         -28.9287
2017-06-11 04:16:56.690429 EDT | AverageQ                   28.7264
2017-06-11 04:16:56.690628 EDT | AverageAbsQ                28.7403
2017-06-11 04:16:56.690824 EDT | AverageY                   28.7268
2017-06-11 04:16:56.691063 EDT | AverageAbsY                28.7336
2017-06-11 04:16:56.691260 EDT | AverageAbsQYDiff            0.502889
2017-06-11 04:16:56.691455 EDT | AverageAction               1
2017-06-11 04:16:56.691649 EDT | PolicyRegParamNorm        101.342
2017-06-11 04:16:56.691840 EDT | QFunRegParamNorm          131.332
2017-06-11 04:16:56.692032 EDT | -----------------------  -----------
2017-06-11 04:16:56.692347 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1112 | Training started
2017-06-11 04:17:14.583722 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1112 | Training finished
2017-06-11 04:17:14.585768 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1112 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 04:17:14.586133 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1112 | Collecting samples for evaluation
2017-06-11 04:17:31.306172 EDT | -----------------------  -----------
2017-06-11 04:17:31.307033 EDT | Epoch                    1112
2017-06-11 04:17:31.307221 EDT | Iteration                1112
2017-06-11 04:17:31.307388 EDT | AverageReturn               5.83656
2017-06-11 04:17:31.307548 EDT | StdReturn                   0.060323
2017-06-11 04:17:31.307837 EDT | MaxReturn                   6.02788
2017-06-11 04:17:31.308123 EDT | MinReturn                   5.70981
2017-06-11 04:17:31.308374 EDT | AverageEsReturn             9.4919
2017-06-11 04:17:31.308543 EDT | StdEsReturn                25.3072
2017-06-11 04:17:31.308697 EDT | MaxEsReturn               288.872
2017-06-11 04:17:31.308849 EDT | MinEsReturn                 5.44953
2017-06-11 04:17:31.309001 EDT | AverageDiscountedReturn     5.67781
2017-06-11 04:17:31.309152 EDT | AverageQLoss                2.27681
2017-06-11 04:17:31.309309 EDT | AveragePolicySurr         -28.8772
2017-06-11 04:17:31.309511 EDT | AverageQ                   28.7372
2017-06-11 04:17:31.309666 EDT | AverageAbsQ                28.7529
2017-06-11 04:17:31.309892 EDT | AverageY                   28.7383
2017-06-11 04:17:31.310068 EDT | AverageAbsY                28.7497
2017-06-11 04:17:31.310228 EDT | AverageAbsQYDiff            0.522793
2017-06-11 04:17:31.310429 EDT | AverageAction               1
2017-06-11 04:17:31.310593 EDT | PolicyRegParamNorm        101.329
2017-06-11 04:17:31.310745 EDT | QFunRegParamNorm          131.412
2017-06-11 04:17:31.310895 EDT | -----------------------  -----------
2017-06-11 04:17:31.311123 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1113 | Training started
2017-06-11 04:17:49.944466 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1113 | Training finished
2017-06-11 04:17:49.945378 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1113 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 04:17:49.945682 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1113 | Collecting samples for evaluation
2017-06-11 04:18:05.012447 EDT | -----------------------  -----------
2017-06-11 04:18:05.013455 EDT | Epoch                    1113
2017-06-11 04:18:05.013734 EDT | Iteration                1113
2017-06-11 04:18:05.014151 EDT | AverageReturn              59.2064
2017-06-11 04:18:05.014653 EDT | StdReturn                  13.2104
2017-06-11 04:18:05.015045 EDT | MaxReturn                 162.152
2017-06-11 04:18:05.015407 EDT | MinReturn                  51.3325
2017-06-11 04:18:05.015768 EDT | AverageEsReturn            35.6684
2017-06-11 04:18:05.016152 EDT | StdEsReturn                74.6067
2017-06-11 04:18:05.016519 EDT | MaxEsReturn               423.832
2017-06-11 04:18:05.016879 EDT | MinEsReturn                 2.70502
2017-06-11 04:18:05.017232 EDT | AverageDiscountedReturn    49.7239
2017-06-11 04:18:05.017566 EDT | AverageQLoss                2.54579
2017-06-11 04:18:05.017913 EDT | AveragePolicySurr         -28.8718
2017-06-11 04:18:05.018239 EDT | AverageQ                   28.6753
2017-06-11 04:18:05.018587 EDT | AverageAbsQ                28.6936
2017-06-11 04:18:05.018938 EDT | AverageY                   28.6762
2017-06-11 04:18:05.019263 EDT | AverageAbsY                28.6865
2017-06-11 04:18:05.019586 EDT | AverageAbsQYDiff            0.569937
2017-06-11 04:18:05.019939 EDT | AverageAction               0.998503
2017-06-11 04:18:05.020303 EDT | PolicyRegParamNorm        101.344
2017-06-11 04:18:05.020722 EDT | QFunRegParamNorm          131.448
2017-06-11 04:18:05.021133 EDT | -----------------------  -----------
2017-06-11 04:18:05.021677 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1114 | Training started
2017-06-11 04:18:22.621557 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1114 | Training finished
2017-06-11 04:18:22.622452 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1114 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 04:18:22.622956 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1114 | Collecting samples for evaluation
2017-06-11 04:18:37.534997 EDT | -----------------------  -----------
2017-06-11 04:18:37.535869 EDT | Epoch                    1114
2017-06-11 04:18:37.536139 EDT | Iteration                1114
2017-06-11 04:18:37.536393 EDT | AverageReturn             834.309
2017-06-11 04:18:37.536763 EDT | StdReturn                 121.156
2017-06-11 04:18:37.537096 EDT | MaxReturn                1091.91
2017-06-11 04:18:37.537425 EDT | MinReturn                 589.756
2017-06-11 04:18:37.537769 EDT | AverageEsReturn           193.504
2017-06-11 04:18:37.538099 EDT | StdEsReturn               134.813
2017-06-11 04:18:37.538424 EDT | MaxEsReturn               447.261
2017-06-11 04:18:37.538746 EDT | MinEsReturn                25.8652
2017-06-11 04:18:37.539068 EDT | AverageDiscountedReturn   227.245
2017-06-11 04:18:37.539389 EDT | AverageQLoss                2.12295
2017-06-11 04:18:37.540036 EDT | AveragePolicySurr         -28.8459
2017-06-11 04:18:37.540366 EDT | AverageQ                   28.6233
2017-06-11 04:18:37.540691 EDT | AverageAbsQ                28.6443
2017-06-11 04:18:37.541012 EDT | AverageY                   28.6258
2017-06-11 04:18:37.541332 EDT | AverageAbsY                28.6358
2017-06-11 04:18:37.541653 EDT | AverageAbsQYDiff            0.526803
2017-06-11 04:18:37.541992 EDT | AverageAction               0.998223
2017-06-11 04:18:37.542311 EDT | PolicyRegParamNorm        101.345
2017-06-11 04:18:37.542628 EDT | QFunRegParamNorm          131.49
2017-06-11 04:18:37.542943 EDT | -----------------------  -----------
2017-06-11 04:18:37.543422 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1115 | Training started
2017-06-11 04:18:55.180446 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1115 | Training finished
2017-06-11 04:18:55.193784 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1115 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 04:18:55.194213 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1115 | Collecting samples for evaluation
2017-06-11 04:19:10.246419 EDT | -----------------------  -----------
2017-06-11 04:19:10.247394 EDT | Epoch                    1115
2017-06-11 04:19:10.248891 EDT | Iteration                1115
2017-06-11 04:19:10.249258 EDT | AverageReturn             709.774
2017-06-11 04:19:10.249562 EDT | StdReturn                 144.051
2017-06-11 04:19:10.249893 EDT | MaxReturn                1110.41
2017-06-11 04:19:10.250216 EDT | MinReturn                 480.945
2017-06-11 04:19:10.250544 EDT | AverageEsReturn           256.439
2017-06-11 04:19:10.250857 EDT | StdEsReturn               231.346
2017-06-11 04:19:10.251171 EDT | MaxEsReturn               687.414
2017-06-11 04:19:10.251475 EDT | MinEsReturn                31.3356
2017-06-11 04:19:10.252510 EDT | AverageDiscountedReturn   205.605
2017-06-11 04:19:10.252847 EDT | AverageQLoss                1.96397
2017-06-11 04:19:10.253164 EDT | AveragePolicySurr         -28.8962
2017-06-11 04:19:10.253467 EDT | AverageQ                   28.6745
2017-06-11 04:19:10.254426 EDT | AverageAbsQ                28.6877
2017-06-11 04:19:10.254745 EDT | AverageY                   28.6758
2017-06-11 04:19:10.255070 EDT | AverageAbsY                28.6804
2017-06-11 04:19:10.255379 EDT | AverageAbsQYDiff            0.506832
2017-06-11 04:19:10.255695 EDT | AverageAction               0.998726
2017-06-11 04:19:10.256239 EDT | PolicyRegParamNorm        101.406
2017-06-11 04:19:10.256780 EDT | QFunRegParamNorm          131.536
2017-06-11 04:19:10.258065 EDT | -----------------------  -----------
2017-06-11 04:19:10.258623 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1116 | Training started
2017-06-11 04:19:28.666536 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1116 | Training finished
2017-06-11 04:19:28.667401 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1116 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 04:19:28.667737 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1116 | Collecting samples for evaluation
2017-06-11 04:19:42.393399 EDT | -----------------------  -----------
2017-06-11 04:19:42.393684 EDT | Epoch                    1116
2017-06-11 04:19:42.393919 EDT | Iteration                1116
2017-06-11 04:19:42.394103 EDT | AverageReturn             821.764
2017-06-11 04:19:42.394292 EDT | StdReturn                 176.096
2017-06-11 04:19:42.394454 EDT | MaxReturn                1188.72
2017-06-11 04:19:42.394614 EDT | MinReturn                 481.817
2017-06-11 04:19:42.394770 EDT | AverageEsReturn           544.309
2017-06-11 04:19:42.394927 EDT | StdEsReturn               219.91
2017-06-11 04:19:42.395083 EDT | MaxEsReturn               744.341
2017-06-11 04:19:42.395245 EDT | MinEsReturn               145.929
2017-06-11 04:19:42.395430 EDT | AverageDiscountedReturn   202.026
2017-06-11 04:19:42.395604 EDT | AverageQLoss                2.0519
2017-06-11 04:19:42.395760 EDT | AveragePolicySurr         -28.8687
2017-06-11 04:19:42.395916 EDT | AverageQ                   28.6425
2017-06-11 04:19:42.396078 EDT | AverageAbsQ                28.6587
2017-06-11 04:19:42.396258 EDT | AverageY                   28.6434
2017-06-11 04:19:42.396430 EDT | AverageAbsY                28.6513
2017-06-11 04:19:42.396592 EDT | AverageAbsQYDiff            0.502792
2017-06-11 04:19:42.396765 EDT | AverageAction               0.997519
2017-06-11 04:19:42.396928 EDT | PolicyRegParamNorm        101.428
2017-06-11 04:19:42.397109 EDT | QFunRegParamNorm          131.594
2017-06-11 04:19:42.397287 EDT | -----------------------  -----------
2017-06-11 04:19:42.397580 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1117 | Training started
2017-06-11 04:20:01.126858 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1117 | Training finished
2017-06-11 04:20:01.127842 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1117 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 04:20:01.128219 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1117 | Collecting samples for evaluation
2017-06-11 04:20:14.105339 EDT | -----------------------  -----------
2017-06-11 04:20:14.106418 EDT | Epoch                    1117
2017-06-11 04:20:14.106876 EDT | Iteration                1117
2017-06-11 04:20:14.107294 EDT | AverageReturn            1203.53
2017-06-11 04:20:14.107703 EDT | StdReturn                 369.494
2017-06-11 04:20:14.108046 EDT | MaxReturn                2318.23
2017-06-11 04:20:14.108473 EDT | MinReturn                 194.713
2017-06-11 04:20:14.108749 EDT | AverageEsReturn           193.978
2017-06-11 04:20:14.109147 EDT | StdEsReturn               226.824
2017-06-11 04:20:14.109501 EDT | MaxEsReturn               639.597
2017-06-11 04:20:14.109949 EDT | MinEsReturn                14.1649
2017-06-11 04:20:14.110322 EDT | AverageDiscountedReturn   229.165
2017-06-11 04:20:14.110663 EDT | AverageQLoss                2.07078
2017-06-11 04:20:14.111090 EDT | AveragePolicySurr         -28.8931
2017-06-11 04:20:14.111458 EDT | AverageQ                   28.7036
2017-06-11 04:20:14.111892 EDT | AverageAbsQ                28.7204
2017-06-11 04:20:14.112297 EDT | AverageY                   28.7055
2017-06-11 04:20:14.112685 EDT | AverageAbsY                28.711
2017-06-11 04:20:14.113108 EDT | AverageAbsQYDiff            0.510304
2017-06-11 04:20:14.113543 EDT | AverageAction               0.997802
2017-06-11 04:20:14.113881 EDT | PolicyRegParamNorm        101.496
2017-06-11 04:20:14.114306 EDT | QFunRegParamNorm          131.631
2017-06-11 04:20:14.114867 EDT | -----------------------  -----------
2017-06-11 04:20:14.115387 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1118 | Training started
2017-06-11 04:20:31.463321 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1118 | Training finished
2017-06-11 04:20:31.464305 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1118 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 04:20:31.464715 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1118 | Collecting samples for evaluation
2017-06-11 04:20:45.520359 EDT | -----------------------  -----------
2017-06-11 04:20:45.520794 EDT | Epoch                    1118
2017-06-11 04:20:45.520997 EDT | Iteration                1118
2017-06-11 04:20:45.521458 EDT | AverageReturn             614.502
2017-06-11 04:20:45.522743 EDT | StdReturn                 223.341
2017-06-11 04:20:45.523099 EDT | MaxReturn                 967.229
2017-06-11 04:20:45.523434 EDT | MinReturn                  12.6758
2017-06-11 04:20:45.523666 EDT | AverageEsReturn           140.781
2017-06-11 04:20:45.523860 EDT | StdEsReturn               222.096
2017-06-11 04:20:45.524043 EDT | MaxEsReturn               731.63
2017-06-11 04:20:45.524223 EDT | MinEsReturn                10.2797
2017-06-11 04:20:45.524403 EDT | AverageDiscountedReturn   200.426
2017-06-11 04:20:45.524583 EDT | AverageQLoss                2.38045
2017-06-11 04:20:45.524761 EDT | AveragePolicySurr         -28.7859
2017-06-11 04:20:45.524947 EDT | AverageQ                   28.6029
2017-06-11 04:20:45.525126 EDT | AverageAbsQ                28.6227
2017-06-11 04:20:45.525303 EDT | AverageY                   28.6039
2017-06-11 04:20:45.525480 EDT | AverageAbsY                28.6136
2017-06-11 04:20:45.525656 EDT | AverageAbsQYDiff            0.535892
2017-06-11 04:20:45.525920 EDT | AverageAction               0.998282
2017-06-11 04:20:45.526105 EDT | PolicyRegParamNorm        101.537
2017-06-11 04:20:45.526716 EDT | QFunRegParamNorm          131.615
2017-06-11 04:20:45.527097 EDT | -----------------------  -----------
2017-06-11 04:20:45.527400 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1119 | Training started
2017-06-11 04:21:00.375411 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1119 | Training finished
2017-06-11 04:21:00.376395 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1119 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 04:21:00.377174 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1119 | Collecting samples for evaluation
2017-06-11 04:21:14.073071 EDT | -----------------------  -----------
2017-06-11 04:21:14.073838 EDT | Epoch                    1119
2017-06-11 04:21:14.074025 EDT | Iteration                1119
2017-06-11 04:21:14.074359 EDT | AverageReturn             309.592
2017-06-11 04:21:14.074531 EDT | StdReturn                 505.719
2017-06-11 04:21:14.074743 EDT | MaxReturn                3439.62
2017-06-11 04:21:14.074942 EDT | MinReturn                   8.91507
2017-06-11 04:21:14.075107 EDT | AverageEsReturn           251.017
2017-06-11 04:21:14.075269 EDT | StdEsReturn               260.679
2017-06-11 04:21:14.075478 EDT | MaxEsReturn               705.494
2017-06-11 04:21:14.075641 EDT | MinEsReturn                10.3372
2017-06-11 04:21:14.075908 EDT | AverageDiscountedReturn    85.7652
2017-06-11 04:21:14.076104 EDT | AverageQLoss                2.38217
2017-06-11 04:21:14.076268 EDT | AveragePolicySurr         -28.8081
2017-06-11 04:21:14.076485 EDT | AverageQ                   28.5876
2017-06-11 04:21:14.076804 EDT | AverageAbsQ                28.6004
2017-06-11 04:21:14.077134 EDT | AverageY                   28.5895
2017-06-11 04:21:14.077336 EDT | AverageAbsY                28.5954
2017-06-11 04:21:14.077640 EDT | AverageAbsQYDiff            0.537413
2017-06-11 04:21:14.077884 EDT | AverageAction               0.998639
2017-06-11 04:21:14.078047 EDT | PolicyRegParamNorm        101.599
2017-06-11 04:21:14.078206 EDT | QFunRegParamNorm          131.652
2017-06-11 04:21:14.078417 EDT | -----------------------  -----------
2017-06-11 04:21:14.078842 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1120 | Training started
2017-06-11 04:21:29.672652 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1120 | Training finished
2017-06-11 04:21:29.673596 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1120 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 04:21:29.674016 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1120 | Collecting samples for evaluation
2017-06-11 04:21:43.880368 EDT | -----------------------  -----------
2017-06-11 04:21:43.888447 EDT | Epoch                    1120
2017-06-11 04:21:43.889337 EDT | Iteration                1120
2017-06-11 04:21:43.889808 EDT | AverageReturn            2682.93
2017-06-11 04:21:43.890260 EDT | StdReturn                 729.736
2017-06-11 04:21:43.890719 EDT | MaxReturn                3276.78
2017-06-11 04:21:43.891169 EDT | MinReturn                1077.33
2017-06-11 04:21:43.891619 EDT | AverageEsReturn           578.064
2017-06-11 04:21:43.892070 EDT | StdEsReturn               451.871
2017-06-11 04:21:43.892519 EDT | MaxEsReturn              1355.38
2017-06-11 04:21:43.897627 EDT | MinEsReturn               112.015
2017-06-11 04:21:43.898134 EDT | AverageDiscountedReturn   234.495
2017-06-11 04:21:43.899067 EDT | AverageQLoss                1.99838
2017-06-11 04:21:43.899536 EDT | AveragePolicySurr         -28.8013
2017-06-11 04:21:43.899983 EDT | AverageQ                   28.5484
2017-06-11 04:21:43.904795 EDT | AverageAbsQ                28.564
2017-06-11 04:21:43.905260 EDT | AverageY                   28.5496
2017-06-11 04:21:43.905719 EDT | AverageAbsY                28.5555
2017-06-11 04:21:43.906167 EDT | AverageAbsQYDiff            0.514484
2017-06-11 04:21:43.906617 EDT | AverageAction               0.998759
2017-06-11 04:21:43.907067 EDT | PolicyRegParamNorm        101.79
2017-06-11 04:21:43.913525 EDT | QFunRegParamNorm          131.66
2017-06-11 04:21:43.914805 EDT | -----------------------  -----------
2017-06-11 04:21:43.915652 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1121 | Training started
2017-06-11 04:22:00.899941 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1121 | Training finished
2017-06-11 04:22:00.908731 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1121 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 04:22:00.909210 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1121 | Collecting samples for evaluation
2017-06-11 04:22:14.437529 EDT | -----------------------  -----------
2017-06-11 04:22:14.438608 EDT | Epoch                    1121
2017-06-11 04:22:14.438979 EDT | Iteration                1121
2017-06-11 04:22:14.439361 EDT | AverageReturn            2127.48
2017-06-11 04:22:14.439730 EDT | StdReturn                 867.882
2017-06-11 04:22:14.440086 EDT | MaxReturn                3451.53
2017-06-11 04:22:14.440506 EDT | MinReturn                1020.88
2017-06-11 04:22:14.440861 EDT | AverageEsReturn           663.408
2017-06-11 04:22:14.441278 EDT | StdEsReturn               565.921
2017-06-11 04:22:14.441666 EDT | MaxEsReturn              1500.16
2017-06-11 04:22:14.442060 EDT | MinEsReturn                63.0368
2017-06-11 04:22:14.442488 EDT | AverageDiscountedReturn   254.19
2017-06-11 04:22:14.442903 EDT | AverageQLoss                1.72687
2017-06-11 04:22:14.443310 EDT | AveragePolicySurr         -28.9004
2017-06-11 04:22:14.443722 EDT | AverageQ                   28.6676
2017-06-11 04:22:14.444146 EDT | AverageAbsQ                28.6777
2017-06-11 04:22:14.444587 EDT | AverageY                   28.6693
2017-06-11 04:22:14.445031 EDT | AverageAbsY                28.6727
2017-06-11 04:22:14.445471 EDT | AverageAbsQYDiff            0.473642
2017-06-11 04:22:14.445915 EDT | AverageAction               0.998232
2017-06-11 04:22:14.446262 EDT | PolicyRegParamNorm        101.814
2017-06-11 04:22:14.446649 EDT | QFunRegParamNorm          131.643
2017-06-11 04:22:14.447018 EDT | -----------------------  -----------
2017-06-11 04:22:14.447619 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1122 | Training started
2017-06-11 04:22:29.502033 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1122 | Training finished
2017-06-11 04:22:29.502897 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1122 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 04:22:29.503180 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1122 | Collecting samples for evaluation
2017-06-11 04:22:43.384964 EDT | -----------------------  -----------
2017-06-11 04:22:43.386046 EDT | Epoch                    1122
2017-06-11 04:22:43.386488 EDT | Iteration                1122
2017-06-11 04:22:43.386959 EDT | AverageReturn            2773.5
2017-06-11 04:22:43.387311 EDT | StdReturn                 995.696
2017-06-11 04:22:43.387712 EDT | MaxReturn                3597.76
2017-06-11 04:22:43.390817 EDT | MinReturn                 865.361
2017-06-11 04:22:43.391022 EDT | AverageEsReturn           352.94
2017-06-11 04:22:43.391242 EDT | StdEsReturn               171.659
2017-06-11 04:22:43.392130 EDT | MaxEsReturn               712.823
2017-06-11 04:22:43.393013 EDT | MinEsReturn               120.9
2017-06-11 04:22:43.393204 EDT | AverageDiscountedReturn   261.11
2017-06-11 04:22:43.393505 EDT | AverageQLoss                1.86291
2017-06-11 04:22:43.393683 EDT | AveragePolicySurr         -28.9598
2017-06-11 04:22:43.394010 EDT | AverageQ                   28.7156
2017-06-11 04:22:43.394298 EDT | AverageAbsQ                28.7279
2017-06-11 04:22:43.394672 EDT | AverageY                   28.7161
2017-06-11 04:22:43.395069 EDT | AverageAbsY                28.721
2017-06-11 04:22:43.395472 EDT | AverageAbsQYDiff            0.477015
2017-06-11 04:22:43.395934 EDT | AverageAction               0.998129
2017-06-11 04:22:43.396319 EDT | PolicyRegParamNorm        101.89
2017-06-11 04:22:43.396784 EDT | QFunRegParamNorm          131.726
2017-06-11 04:22:43.397216 EDT | -----------------------  -----------
2017-06-11 04:22:43.397918 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1123 | Training started
2017-06-11 04:22:59.057213 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1123 | Training finished
2017-06-11 04:22:59.058226 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1123 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 04:22:59.058453 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1123 | Collecting samples for evaluation
2017-06-11 04:23:12.921636 EDT | -----------------------  -----------
2017-06-11 04:23:12.922552 EDT | Epoch                    1123
2017-06-11 04:23:12.922760 EDT | Iteration                1123
2017-06-11 04:23:12.923062 EDT | AverageReturn            1604.49
2017-06-11 04:23:12.924693 EDT | StdReturn                 707.189
2017-06-11 04:23:12.925462 EDT | MaxReturn                2677.56
2017-06-11 04:23:12.926413 EDT | MinReturn                 419.95
2017-06-11 04:23:12.926737 EDT | AverageEsReturn           305.431
2017-06-11 04:23:12.926975 EDT | StdEsReturn               194.641
2017-06-11 04:23:12.927230 EDT | MaxEsReturn               593.364
2017-06-11 04:23:12.927428 EDT | MinEsReturn                14.0549
2017-06-11 04:23:12.927651 EDT | AverageDiscountedReturn   214.422
2017-06-11 04:23:12.927852 EDT | AverageQLoss                1.88644
2017-06-11 04:23:12.928046 EDT | AveragePolicySurr         -28.8542
2017-06-11 04:23:12.928329 EDT | AverageQ                   28.6357
2017-06-11 04:23:12.928525 EDT | AverageAbsQ                28.6498
2017-06-11 04:23:12.928765 EDT | AverageY                   28.638
2017-06-11 04:23:12.929072 EDT | AverageAbsY                28.6419
2017-06-11 04:23:12.929264 EDT | AverageAbsQYDiff            0.483418
2017-06-11 04:23:12.929550 EDT | AverageAction               0.998032
2017-06-11 04:23:12.930566 EDT | PolicyRegParamNorm        101.93
2017-06-11 04:23:12.930974 EDT | QFunRegParamNorm          131.805
2017-06-11 04:23:12.931214 EDT | -----------------------  -----------
2017-06-11 04:23:12.931547 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1124 | Training started
2017-06-11 04:23:29.054595 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1124 | Training finished
2017-06-11 04:23:29.055597 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1124 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 04:23:29.055982 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1124 | Collecting samples for evaluation
2017-06-11 04:23:42.183657 EDT | -----------------------  -----------
2017-06-11 04:23:42.184683 EDT | Epoch                    1124
2017-06-11 04:23:42.185030 EDT | Iteration                1124
2017-06-11 04:23:42.185355 EDT | AverageReturn             232.777
2017-06-11 04:23:42.185708 EDT | StdReturn                 302.052
2017-06-11 04:23:42.186036 EDT | MaxReturn                1334.04
2017-06-11 04:23:42.186354 EDT | MinReturn                  14.8895
2017-06-11 04:23:42.186733 EDT | AverageEsReturn           394.589
2017-06-11 04:23:42.187016 EDT | StdEsReturn               712.466
2017-06-11 04:23:42.187351 EDT | MaxEsReturn              2131.45
2017-06-11 04:23:42.187730 EDT | MinEsReturn                18.2004
2017-06-11 04:23:42.188143 EDT | AverageDiscountedReturn    93.9183
2017-06-11 04:23:42.188567 EDT | AverageQLoss                2.11331
2017-06-11 04:23:42.188889 EDT | AveragePolicySurr         -28.935
2017-06-11 04:23:42.189213 EDT | AverageQ                   28.7279
2017-06-11 04:23:42.189535 EDT | AverageAbsQ                28.7435
2017-06-11 04:23:42.189900 EDT | AverageY                   28.7296
2017-06-11 04:23:42.192268 EDT | AverageAbsY                28.7368
2017-06-11 04:23:42.192765 EDT | AverageAbsQYDiff            0.493303
2017-06-11 04:23:42.193264 EDT | AverageAction               0.997712
2017-06-11 04:23:42.193601 EDT | PolicyRegParamNorm        101.88
2017-06-11 04:23:42.193945 EDT | QFunRegParamNorm          131.862
2017-06-11 04:23:42.194377 EDT | -----------------------  -----------
2017-06-11 04:23:42.194962 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1125 | Training started
2017-06-11 04:23:58.679812 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1125 | Training finished
2017-06-11 04:23:58.680693 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1125 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 04:23:58.681099 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1125 | Collecting samples for evaluation
2017-06-11 04:24:12.913328 EDT | -----------------------  -----------
2017-06-11 04:24:12.914428 EDT | Epoch                    1125
2017-06-11 04:24:12.914785 EDT | Iteration                1125
2017-06-11 04:24:12.915304 EDT | AverageReturn            1484.87
2017-06-11 04:24:12.915560 EDT | StdReturn                1040.7
2017-06-11 04:24:12.915857 EDT | MaxReturn                3390.71
2017-06-11 04:24:12.916110 EDT | MinReturn                 182.261
2017-06-11 04:24:12.916351 EDT | AverageEsReturn           209.241
2017-06-11 04:24:12.916601 EDT | StdEsReturn               170.09
2017-06-11 04:24:12.916909 EDT | MaxEsReturn               658.163
2017-06-11 04:24:12.917357 EDT | MinEsReturn                16.2407
2017-06-11 04:24:12.917623 EDT | AverageDiscountedReturn   234.396
2017-06-11 04:24:12.918052 EDT | AverageQLoss                1.90471
2017-06-11 04:24:12.918392 EDT | AveragePolicySurr         -28.8405
2017-06-11 04:24:12.918727 EDT | AverageQ                   28.62
2017-06-11 04:24:12.919065 EDT | AverageAbsQ                28.6355
2017-06-11 04:24:12.919924 EDT | AverageY                   28.6198
2017-06-11 04:24:12.920292 EDT | AverageAbsY                28.6252
2017-06-11 04:24:12.920636 EDT | AverageAbsQYDiff            0.478829
2017-06-11 04:24:12.920977 EDT | AverageAction               0.998241
2017-06-11 04:24:12.921317 EDT | PolicyRegParamNorm        101.898
2017-06-11 04:24:12.921656 EDT | QFunRegParamNorm          131.911
2017-06-11 04:24:12.922006 EDT | -----------------------  -----------
2017-06-11 04:24:12.922516 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1126 | Training started
2017-06-11 04:24:28.934719 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1126 | Training finished
2017-06-11 04:24:28.936595 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1126 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 04:24:28.936990 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1126 | Collecting samples for evaluation
2017-06-11 04:24:43.482460 EDT | -----------------------  -----------
2017-06-11 04:24:43.483462 EDT | Epoch                    1126
2017-06-11 04:24:43.483812 EDT | Iteration                1126
2017-06-11 04:24:43.484231 EDT | AverageReturn               9.41579
2017-06-11 04:24:43.488288 EDT | StdReturn                   0.345395
2017-06-11 04:24:43.488951 EDT | MaxReturn                  11.5453
2017-06-11 04:24:43.489645 EDT | MinReturn                   7.73391
2017-06-11 04:24:43.490687 EDT | AverageEsReturn            58.004
2017-06-11 04:24:43.491345 EDT | StdEsReturn               103.127
2017-06-11 04:24:43.491959 EDT | MaxEsReturn               404.881
2017-06-11 04:24:43.493023 EDT | MinEsReturn                 7.15254
2017-06-11 04:24:43.493835 EDT | AverageDiscountedReturn     8.96818
2017-06-11 04:24:43.494768 EDT | AverageQLoss                2.10675
2017-06-11 04:24:43.495418 EDT | AveragePolicySurr         -28.8999
2017-06-11 04:24:43.496033 EDT | AverageQ                   28.6993
2017-06-11 04:24:43.496725 EDT | AverageAbsQ                28.7177
2017-06-11 04:24:43.497385 EDT | AverageY                   28.7012
2017-06-11 04:24:43.498107 EDT | AverageAbsY                28.7065
2017-06-11 04:24:43.498889 EDT | AverageAbsQYDiff            0.502594
2017-06-11 04:24:43.499653 EDT | AverageAction               0.998538
2017-06-11 04:24:43.500297 EDT | PolicyRegParamNorm        101.932
2017-06-11 04:24:43.500902 EDT | QFunRegParamNorm          131.962
2017-06-11 04:24:43.501526 EDT | -----------------------  -----------
2017-06-11 04:24:43.502462 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1127 | Training started
2017-06-11 04:25:00.295405 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1127 | Training finished
2017-06-11 04:25:00.296549 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1127 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 04:25:00.297034 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1127 | Collecting samples for evaluation
2017-06-11 04:25:15.047038 EDT | -----------------------  -----------
2017-06-11 04:25:15.047904 EDT | Epoch                    1127
2017-06-11 04:25:15.048209 EDT | Iteration                1127
2017-06-11 04:25:15.048498 EDT | AverageReturn            2758.73
2017-06-11 04:25:15.048754 EDT | StdReturn                 768.286
2017-06-11 04:25:15.049005 EDT | MaxReturn                3297.06
2017-06-11 04:25:15.049254 EDT | MinReturn                1030.58
2017-06-11 04:25:15.049501 EDT | AverageEsReturn           219.526
2017-06-11 04:25:15.049758 EDT | StdEsReturn               246.085
2017-06-11 04:25:15.050046 EDT | MaxEsReturn               843.912
2017-06-11 04:25:15.050331 EDT | MinEsReturn                 7.2615
2017-06-11 04:25:15.050609 EDT | AverageDiscountedReturn   258.754
2017-06-11 04:25:15.050902 EDT | AverageQLoss                2.01817
2017-06-11 04:25:15.051176 EDT | AveragePolicySurr         -28.8625
2017-06-11 04:25:15.051451 EDT | AverageQ                   28.6558
2017-06-11 04:25:15.051708 EDT | AverageAbsQ                28.6705
2017-06-11 04:25:15.053121 EDT | AverageY                   28.6573
2017-06-11 04:25:15.053424 EDT | AverageAbsY                28.6628
2017-06-11 04:25:15.055219 EDT | AverageAbsQYDiff            0.501354
2017-06-11 04:25:15.055534 EDT | AverageAction               0.997819
2017-06-11 04:25:15.055797 EDT | PolicyRegParamNorm        101.915
2017-06-11 04:25:15.057304 EDT | QFunRegParamNorm          132.019
2017-06-11 04:25:15.057596 EDT | -----------------------  -----------
2017-06-11 04:25:15.059265 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1128 | Training started
2017-06-11 04:25:32.192783 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1128 | Training finished
2017-06-11 04:25:32.193583 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1128 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 04:25:32.193806 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1128 | Collecting samples for evaluation
2017-06-11 04:25:45.814606 EDT | -----------------------  -----------
2017-06-11 04:25:45.815390 EDT | Epoch                    1128
2017-06-11 04:25:45.815585 EDT | Iteration                1128
2017-06-11 04:25:45.815757 EDT | AverageReturn            1305.84
2017-06-11 04:25:45.815948 EDT | StdReturn                 930.994
2017-06-11 04:25:45.816133 EDT | MaxReturn                2986.17
2017-06-11 04:25:45.816316 EDT | MinReturn                  18.2222
2017-06-11 04:25:45.816497 EDT | AverageEsReturn           291.492
2017-06-11 04:25:45.816686 EDT | StdEsReturn               302.269
2017-06-11 04:25:45.816868 EDT | MaxEsReturn               800.337
2017-06-11 04:25:45.817129 EDT | MinEsReturn                12.3556
2017-06-11 04:25:45.817331 EDT | AverageDiscountedReturn   203.224
2017-06-11 04:25:45.817513 EDT | AverageQLoss                2.28369
2017-06-11 04:25:45.817839 EDT | AveragePolicySurr         -28.704
2017-06-11 04:25:45.818048 EDT | AverageQ                   28.5042
2017-06-11 04:25:45.818232 EDT | AverageAbsQ                28.5212
2017-06-11 04:25:45.818459 EDT | AverageY                   28.5064
2017-06-11 04:25:45.818940 EDT | AverageAbsY                28.513
2017-06-11 04:25:45.820339 EDT | AverageAbsQYDiff            0.518988
2017-06-11 04:25:45.820736 EDT | AverageAction               0.998667
2017-06-11 04:25:45.821770 EDT | PolicyRegParamNorm        101.944
2017-06-11 04:25:45.822351 EDT | QFunRegParamNorm          132.055
2017-06-11 04:25:45.822679 EDT | -----------------------  -----------
2017-06-11 04:25:45.823130 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1129 | Training started
2017-06-11 04:26:03.131650 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1129 | Training finished
2017-06-11 04:26:03.132762 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1129 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 04:26:03.133206 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1129 | Collecting samples for evaluation
2017-06-11 04:26:16.240660 EDT | -----------------------  -----------
2017-06-11 04:26:16.241513 EDT | Epoch                    1129
2017-06-11 04:26:16.241907 EDT | Iteration                1129
2017-06-11 04:26:16.242112 EDT | AverageReturn             976.2
2017-06-11 04:26:16.242337 EDT | StdReturn                 403.822
2017-06-11 04:26:16.242534 EDT | MaxReturn                2324.85
2017-06-11 04:26:16.242702 EDT | MinReturn                  89.4322
2017-06-11 04:26:16.242926 EDT | AverageEsReturn           398.727
2017-06-11 04:26:16.243088 EDT | StdEsReturn               292.152
2017-06-11 04:26:16.243240 EDT | MaxEsReturn               820.941
2017-06-11 04:26:16.243506 EDT | MinEsReturn                29.3493
2017-06-11 04:26:16.243661 EDT | AverageDiscountedReturn   217.36
2017-06-11 04:26:16.243830 EDT | AverageQLoss                2.29263
2017-06-11 04:26:16.244048 EDT | AveragePolicySurr         -28.7931
2017-06-11 04:26:16.244215 EDT | AverageQ                   28.5757
2017-06-11 04:26:16.244715 EDT | AverageAbsQ                28.5925
2017-06-11 04:26:16.244892 EDT | AverageY                   28.579
2017-06-11 04:26:16.245073 EDT | AverageAbsY                28.587
2017-06-11 04:26:16.245228 EDT | AverageAbsQYDiff            0.505356
2017-06-11 04:26:16.245401 EDT | AverageAction               0.998641
2017-06-11 04:26:16.245603 EDT | PolicyRegParamNorm        102.02
2017-06-11 04:26:16.245782 EDT | QFunRegParamNorm          132.093
2017-06-11 04:26:16.245969 EDT | -----------------------  -----------
2017-06-11 04:26:16.246362 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1130 | Training started
2017-06-11 04:26:33.137317 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1130 | Training finished
2017-06-11 04:26:33.137969 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1130 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 04:26:33.138277 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1130 | Collecting samples for evaluation
2017-06-11 04:26:47.162259 EDT | -----------------------  -----------
2017-06-11 04:26:47.162746 EDT | Epoch                    1130
2017-06-11 04:26:47.163250 EDT | Iteration                1130
2017-06-11 04:26:47.164548 EDT | AverageReturn             459.314
2017-06-11 04:26:47.164846 EDT | StdReturn                 693.453
2017-06-11 04:26:47.165172 EDT | MaxReturn                3016.79
2017-06-11 04:26:47.165770 EDT | MinReturn                  84.8735
2017-06-11 04:26:47.166168 EDT | AverageEsReturn           317.157
2017-06-11 04:26:47.166456 EDT | StdEsReturn               297.059
2017-06-11 04:26:47.166785 EDT | MaxEsReturn               905.27
2017-06-11 04:26:47.167114 EDT | MinEsReturn                81.487
2017-06-11 04:26:47.167434 EDT | AverageDiscountedReturn   119.834
2017-06-11 04:26:47.168451 EDT | AverageQLoss                2.1868
2017-06-11 04:26:47.168774 EDT | AveragePolicySurr         -28.7637
2017-06-11 04:26:47.168959 EDT | AverageQ                   28.5336
2017-06-11 04:26:47.169234 EDT | AverageAbsQ                28.55
2017-06-11 04:26:47.169716 EDT | AverageY                   28.534
2017-06-11 04:26:47.170043 EDT | AverageAbsY                28.5396
2017-06-11 04:26:47.170445 EDT | AverageAbsQYDiff            0.521377
2017-06-11 04:26:47.170671 EDT | AverageAction               0.998181
2017-06-11 04:26:47.170940 EDT | PolicyRegParamNorm        102.094
2017-06-11 04:26:47.171259 EDT | QFunRegParamNorm          132.132
2017-06-11 04:26:47.171656 EDT | -----------------------  -----------
2017-06-11 04:26:47.172371 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1131 | Training started
2017-06-11 04:27:04.900873 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1131 | Training finished
2017-06-11 04:27:04.902420 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1131 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 04:27:04.903029 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1131 | Collecting samples for evaluation
2017-06-11 04:27:18.246952 EDT | -----------------------  -----------
2017-06-11 04:27:18.251415 EDT | Epoch                    1131
2017-06-11 04:27:18.251804 EDT | Iteration                1131
2017-06-11 04:27:18.252163 EDT | AverageReturn             837.027
2017-06-11 04:27:18.252490 EDT | StdReturn                 339.322
2017-06-11 04:27:18.252813 EDT | MaxReturn                1285.88
2017-06-11 04:27:18.253129 EDT | MinReturn                  80.3734
2017-06-11 04:27:18.253441 EDT | AverageEsReturn           573.701
2017-06-11 04:27:18.253710 EDT | StdEsReturn               357.607
2017-06-11 04:27:18.253967 EDT | MaxEsReturn              1202.37
2017-06-11 04:27:18.254274 EDT | MinEsReturn               102.275
2017-06-11 04:27:18.254596 EDT | AverageDiscountedReturn   207.98
2017-06-11 04:27:18.254864 EDT | AverageQLoss                1.98583
2017-06-11 04:27:18.255167 EDT | AveragePolicySurr         -28.7188
2017-06-11 04:27:18.255600 EDT | AverageQ                   28.5015
2017-06-11 04:27:18.256017 EDT | AverageAbsQ                28.5144
2017-06-11 04:27:18.256419 EDT | AverageY                   28.5027
2017-06-11 04:27:18.256804 EDT | AverageAbsY                28.5069
2017-06-11 04:27:18.257217 EDT | AverageAbsQYDiff            0.490455
2017-06-11 04:27:18.257623 EDT | AverageAction               0.998298
2017-06-11 04:27:18.258052 EDT | PolicyRegParamNorm        102.094
2017-06-11 04:27:18.258466 EDT | QFunRegParamNorm          132.195
2017-06-11 04:27:18.258789 EDT | -----------------------  -----------
2017-06-11 04:27:18.259093 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1132 | Training started
2017-06-11 04:27:34.546960 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1132 | Training finished
2017-06-11 04:27:34.547913 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1132 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 04:27:34.548306 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1132 | Collecting samples for evaluation
2017-06-11 04:27:48.325008 EDT | -----------------------  -----------
2017-06-11 04:27:48.325552 EDT | Epoch                    1132
2017-06-11 04:27:48.326353 EDT | Iteration                1132
2017-06-11 04:27:48.326646 EDT | AverageReturn            1021.19
2017-06-11 04:27:48.327011 EDT | StdReturn                 393.095
2017-06-11 04:27:48.327391 EDT | MaxReturn                2864.77
2017-06-11 04:27:48.327729 EDT | MinReturn                 654.693
2017-06-11 04:27:48.328062 EDT | AverageEsReturn           349.016
2017-06-11 04:27:48.328382 EDT | StdEsReturn               281.287
2017-06-11 04:27:48.328695 EDT | MaxEsReturn               917.134
2017-06-11 04:27:48.329110 EDT | MinEsReturn                38.8829
2017-06-11 04:27:48.329384 EDT | AverageDiscountedReturn   243.99
2017-06-11 04:27:48.329711 EDT | AverageQLoss                1.98239
2017-06-11 04:27:48.331262 EDT | AveragePolicySurr         -28.8018
2017-06-11 04:27:48.331627 EDT | AverageQ                   28.5799
2017-06-11 04:27:48.331945 EDT | AverageAbsQ                28.5937
2017-06-11 04:27:48.332345 EDT | AverageY                   28.582
2017-06-11 04:27:48.333355 EDT | AverageAbsY                28.5869
2017-06-11 04:27:48.334042 EDT | AverageAbsQYDiff            0.492739
2017-06-11 04:27:48.334479 EDT | AverageAction               0.998475
2017-06-11 04:27:48.334798 EDT | PolicyRegParamNorm        102.134
2017-06-11 04:27:48.335230 EDT | QFunRegParamNorm          132.251
2017-06-11 04:27:48.335551 EDT | -----------------------  -----------
2017-06-11 04:27:48.336033 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1133 | Training started
2017-06-11 04:28:05.817416 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1133 | Training finished
2017-06-11 04:28:05.818177 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1133 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 04:28:05.818511 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1133 | Collecting samples for evaluation
2017-06-11 04:28:19.538435 EDT | -----------------------  -----------
2017-06-11 04:28:19.538935 EDT | Epoch                    1133
2017-06-11 04:28:19.539157 EDT | Iteration                1133
2017-06-11 04:28:19.539326 EDT | AverageReturn            1579.57
2017-06-11 04:28:19.539541 EDT | StdReturn                 830.576
2017-06-11 04:28:19.539706 EDT | MaxReturn                2905.38
2017-06-11 04:28:19.539869 EDT | MinReturn                 886.399
2017-06-11 04:28:19.540031 EDT | AverageEsReturn           307.356
2017-06-11 04:28:19.540227 EDT | StdEsReturn               219.592
2017-06-11 04:28:19.540390 EDT | MaxEsReturn               667.217
2017-06-11 04:28:19.540601 EDT | MinEsReturn                41.2262
2017-06-11 04:28:19.540778 EDT | AverageDiscountedReturn   235.1
2017-06-11 04:28:19.540942 EDT | AverageQLoss                1.9102
2017-06-11 04:28:19.541105 EDT | AveragePolicySurr         -28.7313
2017-06-11 04:28:19.541266 EDT | AverageQ                   28.507
2017-06-11 04:28:19.541425 EDT | AverageAbsQ                28.5206
2017-06-11 04:28:19.541584 EDT | AverageY                   28.5079
2017-06-11 04:28:19.541868 EDT | AverageAbsY                28.5132
2017-06-11 04:28:19.542035 EDT | AverageAbsQYDiff            0.489355
2017-06-11 04:28:19.542198 EDT | AverageAction               0.997812
2017-06-11 04:28:19.542359 EDT | PolicyRegParamNorm        102.245
2017-06-11 04:28:19.542520 EDT | QFunRegParamNorm          132.291
2017-06-11 04:28:19.542680 EDT | -----------------------  -----------
2017-06-11 04:28:19.542923 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1134 | Training started
2017-06-11 04:28:36.003032 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1134 | Training finished
2017-06-11 04:28:36.004590 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1134 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 04:28:36.004779 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1134 | Collecting samples for evaluation
2017-06-11 04:28:48.363093 EDT | -----------------------  -----------
2017-06-11 04:28:48.363543 EDT | Epoch                    1134
2017-06-11 04:28:48.363902 EDT | Iteration                1134
2017-06-11 04:28:48.364316 EDT | AverageReturn            1420.21
2017-06-11 04:28:48.364621 EDT | StdReturn                 289.778
2017-06-11 04:28:48.364957 EDT | MaxReturn                2225.56
2017-06-11 04:28:48.365336 EDT | MinReturn                1061.04
2017-06-11 04:28:48.365786 EDT | AverageEsReturn           901.083
2017-06-11 04:28:48.366123 EDT | StdEsReturn               352.398
2017-06-11 04:28:48.366473 EDT | MaxEsReturn              1443.72
2017-06-11 04:28:48.366936 EDT | MinEsReturn               542.915
2017-06-11 04:28:48.367270 EDT | AverageDiscountedReturn   232.098
2017-06-11 04:28:48.367621 EDT | AverageQLoss                1.9408
2017-06-11 04:28:48.368020 EDT | AveragePolicySurr         -28.7669
2017-06-11 04:28:48.368350 EDT | AverageQ                   28.5394
2017-06-11 04:28:48.368689 EDT | AverageAbsQ                28.5545
2017-06-11 04:28:48.369034 EDT | AverageY                   28.5393
2017-06-11 04:28:48.369406 EDT | AverageAbsY                28.5439
2017-06-11 04:28:48.369747 EDT | AverageAbsQYDiff            0.471231
2017-06-11 04:28:48.370089 EDT | AverageAction               0.998469
2017-06-11 04:28:48.370436 EDT | PolicyRegParamNorm        102.279
2017-06-11 04:28:48.370815 EDT | QFunRegParamNorm          132.32
2017-06-11 04:28:48.371155 EDT | -----------------------  -----------
2017-06-11 04:28:48.371659 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1135 | Training started
2017-06-11 04:29:05.985062 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1135 | Training finished
2017-06-11 04:29:05.985857 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1135 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 04:29:05.986246 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1135 | Collecting samples for evaluation
2017-06-11 04:29:20.802059 EDT | -----------------------  -----------
2017-06-11 04:29:20.803184 EDT | Epoch                    1135
2017-06-11 04:29:20.803684 EDT | Iteration                1135
2017-06-11 04:29:20.804110 EDT | AverageReturn              55.2951
2017-06-11 04:29:20.804545 EDT | StdReturn                   3.14514
2017-06-11 04:29:20.805169 EDT | MaxReturn                  61.577
2017-06-11 04:29:20.805604 EDT | MinReturn                  48.7569
2017-06-11 04:29:20.806118 EDT | AverageEsReturn           176.014
2017-06-11 04:29:20.806544 EDT | StdEsReturn               233.339
2017-06-11 04:29:20.806974 EDT | MaxEsReturn               740.253
2017-06-11 04:29:20.807429 EDT | MinEsReturn                17.0089
2017-06-11 04:29:20.807851 EDT | AverageDiscountedReturn    46.6028
2017-06-11 04:29:20.808280 EDT | AverageQLoss                2.16315
2017-06-11 04:29:20.808762 EDT | AveragePolicySurr         -28.7764
2017-06-11 04:29:20.809183 EDT | AverageQ                   28.5716
2017-06-11 04:29:20.809618 EDT | AverageAbsQ                28.5851
2017-06-11 04:29:20.810103 EDT | AverageY                   28.5746
2017-06-11 04:29:20.810525 EDT | AverageAbsY                28.5797
2017-06-11 04:29:20.810959 EDT | AverageAbsQYDiff            0.486724
2017-06-11 04:29:20.811432 EDT | AverageAction               0.999448
2017-06-11 04:29:20.811852 EDT | PolicyRegParamNorm        102.185
2017-06-11 04:29:20.812283 EDT | QFunRegParamNorm          132.354
2017-06-11 04:29:20.812769 EDT | -----------------------  -----------
2017-06-11 04:29:20.813349 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1136 | Training started
2017-06-11 04:29:37.654879 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1136 | Training finished
2017-06-11 04:29:37.752613 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1136 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 04:29:37.753335 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1136 | Collecting samples for evaluation
2017-06-11 04:29:51.824672 EDT | -----------------------  -----------
2017-06-11 04:29:51.825443 EDT | Epoch                    1136
2017-06-11 04:29:51.825803 EDT | Iteration                1136
2017-06-11 04:29:51.826014 EDT | AverageReturn              88.8075
2017-06-11 04:29:51.826177 EDT | StdReturn                 164.781
2017-06-11 04:29:51.826341 EDT | MaxReturn                1572.52
2017-06-11 04:29:51.826556 EDT | MinReturn                  60.297
2017-06-11 04:29:51.826878 EDT | AverageEsReturn           111.983
2017-06-11 04:29:51.828032 EDT | StdEsReturn               135.668
2017-06-11 04:29:51.829145 EDT | MaxEsReturn               536.42
2017-06-11 04:29:51.829839 EDT | MinEsReturn                 7.50302
2017-06-11 04:29:51.830170 EDT | AverageDiscountedReturn    57.97
2017-06-11 04:29:51.830327 EDT | AverageQLoss                1.80078
2017-06-11 04:29:51.830479 EDT | AveragePolicySurr         -28.7422
2017-06-11 04:29:51.830631 EDT | AverageQ                   28.5585
2017-06-11 04:29:51.830822 EDT | AverageAbsQ                28.5751
2017-06-11 04:29:51.830976 EDT | AverageY                   28.5582
2017-06-11 04:29:51.831382 EDT | AverageAbsY                28.5666
2017-06-11 04:29:51.831534 EDT | AverageAbsQYDiff            0.471257
2017-06-11 04:29:51.831683 EDT | AverageAction               0.999425
2017-06-11 04:29:51.831831 EDT | PolicyRegParamNorm        102.206
2017-06-11 04:29:51.832040 EDT | QFunRegParamNorm          132.413
2017-06-11 04:29:51.832192 EDT | -----------------------  -----------
2017-06-11 04:29:51.842427 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1137 | Training started
2017-06-11 04:30:09.287365 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1137 | Training finished
2017-06-11 04:30:09.288269 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1137 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 04:30:09.288559 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1137 | Collecting samples for evaluation
2017-06-11 04:30:22.566216 EDT | -----------------------  -----------
2017-06-11 04:30:22.567122 EDT | Epoch                    1137
2017-06-11 04:30:22.567668 EDT | Iteration                1137
2017-06-11 04:30:22.568095 EDT | AverageReturn             765.445
2017-06-11 04:30:22.571687 EDT | StdReturn                 560.677
2017-06-11 04:30:22.572921 EDT | MaxReturn                2389.97
2017-06-11 04:30:22.573910 EDT | MinReturn                  64.3077
2017-06-11 04:30:22.574286 EDT | AverageEsReturn            75.5144
2017-06-11 04:30:22.574713 EDT | StdEsReturn               144.081
2017-06-11 04:30:22.575146 EDT | MaxEsReturn               635.128
2017-06-11 04:30:22.575525 EDT | MinEsReturn                 5.75275
2017-06-11 04:30:22.575951 EDT | AverageDiscountedReturn   186.547
2017-06-11 04:30:22.576360 EDT | AverageQLoss                2.49234
2017-06-11 04:30:22.578422 EDT | AveragePolicySurr         -28.6705
2017-06-11 04:30:22.578635 EDT | AverageQ                   28.4737
2017-06-11 04:30:22.578832 EDT | AverageAbsQ                28.491
2017-06-11 04:30:22.579020 EDT | AverageY                   28.4753
2017-06-11 04:30:22.579204 EDT | AverageAbsY                28.4798
2017-06-11 04:30:22.579435 EDT | AverageAbsQYDiff            0.531257
2017-06-11 04:30:22.579620 EDT | AverageAction               0.998385
2017-06-11 04:30:22.579801 EDT | PolicyRegParamNorm        102.247
2017-06-11 04:30:22.579982 EDT | QFunRegParamNorm          132.431
2017-06-11 04:30:22.580163 EDT | -----------------------  -----------
2017-06-11 04:30:22.580464 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1138 | Training started
2017-06-11 04:30:40.390674 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1138 | Training finished
2017-06-11 04:30:40.391411 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1138 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 04:30:40.391773 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1138 | Collecting samples for evaluation
2017-06-11 04:30:53.688565 EDT | -----------------------  -----------
2017-06-11 04:30:53.690374 EDT | Epoch                    1138
2017-06-11 04:30:53.690707 EDT | Iteration                1138
2017-06-11 04:30:53.691034 EDT | AverageReturn             893.473
2017-06-11 04:30:53.691368 EDT | StdReturn                 399.004
2017-06-11 04:30:53.691706 EDT | MaxReturn                2238.67
2017-06-11 04:30:53.691966 EDT | MinReturn                 593.889
2017-06-11 04:30:53.693239 EDT | AverageEsReturn           335.34
2017-06-11 04:30:53.693589 EDT | StdEsReturn               249.556
2017-06-11 04:30:53.693934 EDT | MaxEsReturn               652.456
2017-06-11 04:30:53.694283 EDT | MinEsReturn                22.2831
2017-06-11 04:30:53.694628 EDT | AverageDiscountedReturn   219.767
2017-06-11 04:30:53.694904 EDT | AverageQLoss                2.13865
2017-06-11 04:30:53.695244 EDT | AveragePolicySurr         -28.7179
2017-06-11 04:30:53.698113 EDT | AverageQ                   28.5009
2017-06-11 04:30:53.700043 EDT | AverageAbsQ                28.5178
2017-06-11 04:30:53.700900 EDT | AverageY                   28.5021
2017-06-11 04:30:53.701268 EDT | AverageAbsY                28.5082
2017-06-11 04:30:53.701613 EDT | AverageAbsQYDiff            0.492285
2017-06-11 04:30:53.701936 EDT | AverageAction               0.998583
2017-06-11 04:30:53.702351 EDT | PolicyRegParamNorm        102.326
2017-06-11 04:30:53.702816 EDT | QFunRegParamNorm          132.498
2017-06-11 04:30:53.703261 EDT | -----------------------  -----------
2017-06-11 04:30:53.703784 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1139 | Training started
2017-06-11 04:31:11.948490 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1139 | Training finished
2017-06-11 04:31:11.949431 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1139 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 04:31:11.949635 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1139 | Collecting samples for evaluation
2017-06-11 04:31:26.373497 EDT | -----------------------  -----------
2017-06-11 04:31:26.373969 EDT | Epoch                    1139
2017-06-11 04:31:26.374320 EDT | Iteration                1139
2017-06-11 04:31:26.374670 EDT | AverageReturn            1343.71
2017-06-11 04:31:26.375015 EDT | StdReturn                 751.03
2017-06-11 04:31:26.375359 EDT | MaxReturn                3082.32
2017-06-11 04:31:26.375701 EDT | MinReturn                 622.794
2017-06-11 04:31:26.376045 EDT | AverageEsReturn           242.861
2017-06-11 04:31:26.376391 EDT | StdEsReturn               100.713
2017-06-11 04:31:26.376731 EDT | MaxEsReturn               377.657
2017-06-11 04:31:26.377073 EDT | MinEsReturn                76.0726
2017-06-11 04:31:26.377412 EDT | AverageDiscountedReturn   231.525
2017-06-11 04:31:26.377764 EDT | AverageQLoss                2.0686
2017-06-11 04:31:26.378077 EDT | AveragePolicySurr         -28.7372
2017-06-11 04:31:26.378343 EDT | AverageQ                   28.4913
2017-06-11 04:31:26.378670 EDT | AverageAbsQ                28.5075
2017-06-11 04:31:26.379503 EDT | AverageY                   28.4931
2017-06-11 04:31:26.379773 EDT | AverageAbsY                28.4984
2017-06-11 04:31:26.380024 EDT | AverageAbsQYDiff            0.492724
2017-06-11 04:31:26.380272 EDT | AverageAction               0.998158
2017-06-11 04:31:26.380517 EDT | PolicyRegParamNorm        102.365
2017-06-11 04:31:26.380759 EDT | QFunRegParamNorm          132.534
2017-06-11 04:31:26.381001 EDT | -----------------------  -----------
2017-06-11 04:31:26.381397 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1140 | Training started
2017-06-11 04:31:42.005380 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1140 | Training finished
2017-06-11 04:31:42.006270 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1140 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 04:31:42.006493 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1140 | Collecting samples for evaluation
2017-06-11 04:31:58.101427 EDT | -----------------------  -----------
2017-06-11 04:31:58.102306 EDT | Epoch                    1140
2017-06-11 04:31:58.102670 EDT | Iteration                1140
2017-06-11 04:31:58.103010 EDT | AverageReturn            2419.19
2017-06-11 04:31:58.103417 EDT | StdReturn                 855.683
2017-06-11 04:31:58.103827 EDT | MaxReturn                3171.6
2017-06-11 04:31:58.104222 EDT | MinReturn                1007.27
2017-06-11 04:31:58.104577 EDT | AverageEsReturn           406.254
2017-06-11 04:31:58.105001 EDT | StdEsReturn               264.936
2017-06-11 04:31:58.105410 EDT | MaxEsReturn               802.57
2017-06-11 04:31:58.105825 EDT | MinEsReturn               116.866
2017-06-11 04:31:58.106211 EDT | AverageDiscountedReturn   245.063
2017-06-11 04:31:58.106618 EDT | AverageQLoss                1.8182
2017-06-11 04:31:58.107018 EDT | AveragePolicySurr         -28.7238
2017-06-11 04:31:58.107444 EDT | AverageQ                   28.4725
2017-06-11 04:31:58.107854 EDT | AverageAbsQ                28.4864
2017-06-11 04:31:58.108259 EDT | AverageY                   28.4728
2017-06-11 04:31:58.108613 EDT | AverageAbsY                28.4778
2017-06-11 04:31:58.108999 EDT | AverageAbsQYDiff            0.485412
2017-06-11 04:31:58.109397 EDT | AverageAction               0.997921
2017-06-11 04:31:58.109747 EDT | PolicyRegParamNorm        102.428
2017-06-11 04:31:58.110153 EDT | QFunRegParamNorm          132.578
2017-06-11 04:31:58.110568 EDT | -----------------------  -----------
2017-06-11 04:31:58.111146 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1141 | Training started
2017-06-11 04:32:15.618657 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1141 | Training finished
2017-06-11 04:32:15.619972 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1141 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 04:32:15.620275 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1141 | Collecting samples for evaluation
2017-06-11 04:32:28.529907 EDT | -----------------------  -----------
2017-06-11 04:32:28.530849 EDT | Epoch                    1141
2017-06-11 04:32:28.531170 EDT | Iteration                1141
2017-06-11 04:32:28.531460 EDT | AverageReturn            3016.7
2017-06-11 04:32:28.531745 EDT | StdReturn                  50.1318
2017-06-11 04:32:28.532039 EDT | MaxReturn                3093.62
2017-06-11 04:32:28.532245 EDT | MinReturn                2942.68
2017-06-11 04:32:28.532495 EDT | AverageEsReturn           474.059
2017-06-11 04:32:28.532787 EDT | StdEsReturn               347.546
2017-06-11 04:32:28.533076 EDT | MaxEsReturn              1012.38
2017-06-11 04:32:28.533365 EDT | MinEsReturn               159.475
2017-06-11 04:32:28.533666 EDT | AverageDiscountedReturn   242.944
2017-06-11 04:32:28.534015 EDT | AverageQLoss                2.05769
2017-06-11 04:32:28.534347 EDT | AveragePolicySurr         -28.6999
2017-06-11 04:32:28.534700 EDT | AverageQ                   28.4733
2017-06-11 04:32:28.535066 EDT | AverageAbsQ                28.4901
2017-06-11 04:32:28.535415 EDT | AverageY                   28.4749
2017-06-11 04:32:28.535731 EDT | AverageAbsY                28.4818
2017-06-11 04:32:28.536096 EDT | AverageAbsQYDiff            0.475666
2017-06-11 04:32:28.536465 EDT | AverageAction               0.998086
2017-06-11 04:32:28.536784 EDT | PolicyRegParamNorm        102.451
2017-06-11 04:32:28.537149 EDT | QFunRegParamNorm          132.641
2017-06-11 04:32:28.537518 EDT | -----------------------  -----------
2017-06-11 04:32:28.538038 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1142 | Training started
2017-06-11 04:32:45.974590 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1142 | Training finished
2017-06-11 04:32:45.975431 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1142 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 04:32:45.975771 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1142 | Collecting samples for evaluation
2017-06-11 04:33:00.814559 EDT | -----------------------  -----------
2017-06-11 04:33:00.815338 EDT | Epoch                    1142
2017-06-11 04:33:00.815596 EDT | Iteration                1142
2017-06-11 04:33:00.815868 EDT | AverageReturn            1868.5
2017-06-11 04:33:00.816109 EDT | StdReturn                1234.49
2017-06-11 04:33:00.816311 EDT | MaxReturn                3043.26
2017-06-11 04:33:00.816530 EDT | MinReturn                 188.611
2017-06-11 04:33:00.816714 EDT | AverageEsReturn           762.085
2017-06-11 04:33:00.816948 EDT | StdEsReturn               631.793
2017-06-11 04:33:00.817130 EDT | MaxEsReturn              1814.01
2017-06-11 04:33:00.817335 EDT | MinEsReturn               141.503
2017-06-11 04:33:00.817502 EDT | AverageDiscountedReturn   206
2017-06-11 04:33:00.817677 EDT | AverageQLoss                1.42827
2017-06-11 04:33:00.817861 EDT | AveragePolicySurr         -28.7246
2017-06-11 04:33:00.818037 EDT | AverageQ                   28.5124
2017-06-11 04:33:00.818227 EDT | AverageAbsQ                28.5302
2017-06-11 04:33:00.818444 EDT | AverageY                   28.5134
2017-06-11 04:33:00.818603 EDT | AverageAbsY                28.521
2017-06-11 04:33:00.818758 EDT | AverageAbsQYDiff            0.432834
2017-06-11 04:33:00.818920 EDT | AverageAction               0.998629
2017-06-11 04:33:00.819105 EDT | PolicyRegParamNorm        102.443
2017-06-11 04:33:00.819278 EDT | QFunRegParamNorm          132.696
2017-06-11 04:33:00.819440 EDT | -----------------------  -----------
2017-06-11 04:33:00.819772 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1143 | Training started
2017-06-11 04:33:17.079892 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1143 | Training finished
2017-06-11 04:33:17.083114 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1143 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 04:33:17.083511 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1143 | Collecting samples for evaluation
2017-06-11 04:33:32.928317 EDT | -----------------------  -----------
2017-06-11 04:33:32.929751 EDT | Epoch                    1143
2017-06-11 04:33:32.930121 EDT | Iteration                1143
2017-06-11 04:33:32.930464 EDT | AverageReturn             392.686
2017-06-11 04:33:32.930807 EDT | StdReturn                 819.868
2017-06-11 04:33:32.931148 EDT | MaxReturn                2958.54
2017-06-11 04:33:32.931491 EDT | MinReturn                  67.8898
2017-06-11 04:33:32.931832 EDT | AverageEsReturn           195.848
2017-06-11 04:33:32.932173 EDT | StdEsReturn               165.022
2017-06-11 04:33:32.932567 EDT | MaxEsReturn               587.108
2017-06-11 04:33:32.933801 EDT | MinEsReturn                 6.88789
2017-06-11 04:33:32.934269 EDT | AverageDiscountedReturn    84.7271
2017-06-11 04:33:32.934627 EDT | AverageQLoss                2.34698
2017-06-11 04:33:32.934973 EDT | AveragePolicySurr         -28.6398
2017-06-11 04:33:32.935373 EDT | AverageQ                   28.4164
2017-06-11 04:33:32.935721 EDT | AverageAbsQ                28.438
2017-06-11 04:33:32.936076 EDT | AverageY                   28.4184
2017-06-11 04:33:32.936505 EDT | AverageAbsY                28.425
2017-06-11 04:33:32.936847 EDT | AverageAbsQYDiff            0.50254
2017-06-11 04:33:32.937182 EDT | AverageAction               0.998113
2017-06-11 04:33:32.937521 EDT | PolicyRegParamNorm        102.553
2017-06-11 04:33:32.937871 EDT | QFunRegParamNorm          132.793
2017-06-11 04:33:32.938216 EDT | -----------------------  -----------
2017-06-11 04:33:32.938798 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1144 | Training started
2017-06-11 04:33:49.249022 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1144 | Training finished
2017-06-11 04:33:49.250063 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1144 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 04:33:49.250421 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1144 | Collecting samples for evaluation
2017-06-11 04:34:03.070297 EDT | -----------------------  -----------
2017-06-11 04:34:03.071034 EDT | Epoch                    1144
2017-06-11 04:34:03.071232 EDT | Iteration                1144
2017-06-11 04:34:03.071449 EDT | AverageReturn            1802.49
2017-06-11 04:34:03.071630 EDT | StdReturn                1318.43
2017-06-11 04:34:03.071803 EDT | MaxReturn                3079.64
2017-06-11 04:34:03.072025 EDT | MinReturn                  78.4701
2017-06-11 04:34:03.072386 EDT | AverageEsReturn           130.526
2017-06-11 04:34:03.072684 EDT | StdEsReturn               150.241
2017-06-11 04:34:03.072971 EDT | MaxEsReturn               604.154
2017-06-11 04:34:03.073275 EDT | MinEsReturn                 7.04895
2017-06-11 04:34:03.073559 EDT | AverageDiscountedReturn   184.077
2017-06-11 04:34:03.073886 EDT | AverageQLoss                1.99598
2017-06-11 04:34:03.074189 EDT | AveragePolicySurr         -28.7038
2017-06-11 04:34:03.074494 EDT | AverageQ                   28.4996
2017-06-11 04:34:03.074811 EDT | AverageAbsQ                28.512
2017-06-11 04:34:03.075085 EDT | AverageY                   28.5006
2017-06-11 04:34:03.075442 EDT | AverageAbsY                28.5041
2017-06-11 04:34:03.075952 EDT | AverageAbsQYDiff            0.472644
2017-06-11 04:34:03.076300 EDT | AverageAction               0.997947
2017-06-11 04:34:03.076619 EDT | PolicyRegParamNorm        102.563
2017-06-11 04:34:03.076944 EDT | QFunRegParamNorm          132.825
2017-06-11 04:34:03.077273 EDT | -----------------------  -----------
2017-06-11 04:34:03.077575 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1145 | Training started
2017-06-11 04:34:19.229421 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1145 | Training finished
2017-06-11 04:34:19.234396 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1145 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 04:34:19.234800 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1145 | Collecting samples for evaluation
2017-06-11 04:34:32.338069 EDT | -----------------------  -----------
2017-06-11 04:34:32.338921 EDT | Epoch                    1145
2017-06-11 04:34:32.339365 EDT | Iteration                1145
2017-06-11 04:34:32.339710 EDT | AverageReturn            1082.84
2017-06-11 04:34:32.340036 EDT | StdReturn                 923.369
2017-06-11 04:34:32.340365 EDT | MaxReturn                2997
2017-06-11 04:34:32.340686 EDT | MinReturn                 196.336
2017-06-11 04:34:32.341127 EDT | AverageEsReturn           232.087
2017-06-11 04:34:32.341412 EDT | StdEsReturn               192.597
2017-06-11 04:34:32.341679 EDT | MaxEsReturn               646.23
2017-06-11 04:34:32.341993 EDT | MinEsReturn                77.3215
2017-06-11 04:34:32.342286 EDT | AverageDiscountedReturn   196.777
2017-06-11 04:34:32.342547 EDT | AverageQLoss                2.23313
2017-06-11 04:34:32.342883 EDT | AveragePolicySurr         -28.5761
2017-06-11 04:34:32.343038 EDT | AverageQ                   28.3634
2017-06-11 04:34:32.343202 EDT | AverageAbsQ                28.3789
2017-06-11 04:34:32.343382 EDT | AverageY                   28.3631
2017-06-11 04:34:32.343584 EDT | AverageAbsY                28.3687
2017-06-11 04:34:32.343750 EDT | AverageAbsQYDiff            0.493273
2017-06-11 04:34:32.343934 EDT | AverageAction               0.998194
2017-06-11 04:34:32.344108 EDT | PolicyRegParamNorm        102.607
2017-06-11 04:34:32.344266 EDT | QFunRegParamNorm          132.855
2017-06-11 04:34:32.344421 EDT | -----------------------  -----------
2017-06-11 04:34:32.344751 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1146 | Training started
2017-06-11 04:34:49.249478 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1146 | Training finished
2017-06-11 04:34:49.261808 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1146 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 04:34:49.262261 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1146 | Collecting samples for evaluation
2017-06-11 04:35:02.883115 EDT | -----------------------  -----------
2017-06-11 04:35:02.883960 EDT | Epoch                    1146
2017-06-11 04:35:02.884311 EDT | Iteration                1146
2017-06-11 04:35:02.884704 EDT | AverageReturn             551.638
2017-06-11 04:35:02.884870 EDT | StdReturn                 279.342
2017-06-11 04:35:02.885026 EDT | MaxReturn                2021.45
2017-06-11 04:35:02.885179 EDT | MinReturn                 201.371
2017-06-11 04:35:02.885376 EDT | AverageEsReturn           118.184
2017-06-11 04:35:02.885536 EDT | StdEsReturn               115.278
2017-06-11 04:35:02.885758 EDT | MaxEsReturn               372.131
2017-06-11 04:35:02.886053 EDT | MinEsReturn                 3.36762
2017-06-11 04:35:02.886371 EDT | AverageDiscountedReturn   200.392
2017-06-11 04:35:02.886694 EDT | AverageQLoss                2.00224
2017-06-11 04:35:02.887032 EDT | AveragePolicySurr         -28.6737
2017-06-11 04:35:02.889135 EDT | AverageQ                   28.4678
2017-06-11 04:35:02.890015 EDT | AverageAbsQ                28.4827
2017-06-11 04:35:02.890775 EDT | AverageY                   28.4695
2017-06-11 04:35:02.891042 EDT | AverageAbsY                28.4758
2017-06-11 04:35:02.891540 EDT | AverageAbsQYDiff            0.476683
2017-06-11 04:35:02.891844 EDT | AverageAction               0.998113
2017-06-11 04:35:02.892246 EDT | PolicyRegParamNorm        102.678
2017-06-11 04:35:02.893047 EDT | QFunRegParamNorm          132.909
2017-06-11 04:35:02.893217 EDT | -----------------------  -----------
2017-06-11 04:35:02.893561 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1147 | Training started
2017-06-11 04:35:20.596099 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1147 | Training finished
2017-06-11 04:35:20.596599 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1147 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 04:35:20.597377 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1147 | Collecting samples for evaluation
2017-06-11 04:35:34.372595 EDT | -----------------------  -----------
2017-06-11 04:35:34.373508 EDT | Epoch                    1147
2017-06-11 04:35:34.373837 EDT | Iteration                1147
2017-06-11 04:35:34.374105 EDT | AverageReturn            1148.01
2017-06-11 04:35:34.374438 EDT | StdReturn                 742.593
2017-06-11 04:35:34.374787 EDT | MaxReturn                3024.48
2017-06-11 04:35:34.375094 EDT | MinReturn                 418.768
2017-06-11 04:35:34.375361 EDT | AverageEsReturn           118.782
2017-06-11 04:35:34.375683 EDT | StdEsReturn               114.932
2017-06-11 04:35:34.376014 EDT | MaxEsReturn               431.334
2017-06-11 04:35:34.376336 EDT | MinEsReturn                 4.33002
2017-06-11 04:35:34.376598 EDT | AverageDiscountedReturn   221.163
2017-06-11 04:35:34.376902 EDT | AverageQLoss                1.97474
2017-06-11 04:35:34.377226 EDT | AveragePolicySurr         -28.5541
2017-06-11 04:35:34.377558 EDT | AverageQ                   28.366
2017-06-11 04:35:34.377840 EDT | AverageAbsQ                28.3844
2017-06-11 04:35:34.378110 EDT | AverageY                   28.3672
2017-06-11 04:35:34.378433 EDT | AverageAbsY                28.3735
2017-06-11 04:35:34.378763 EDT | AverageAbsQYDiff            0.488484
2017-06-11 04:35:34.379065 EDT | AverageAction               0.998085
2017-06-11 04:35:34.379322 EDT | PolicyRegParamNorm        102.678
2017-06-11 04:35:34.379641 EDT | QFunRegParamNorm          132.962
2017-06-11 04:35:34.379973 EDT | -----------------------  -----------
2017-06-11 04:35:34.380445 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1148 | Training started
2017-06-11 04:35:49.969953 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1148 | Training finished
2017-06-11 04:35:49.971121 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1148 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 04:35:49.971649 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1148 | Collecting samples for evaluation
2017-06-11 04:36:03.057315 EDT | -----------------------  -----------
2017-06-11 04:36:03.058025 EDT | Epoch                    1148
2017-06-11 04:36:03.058225 EDT | Iteration                1148
2017-06-11 04:36:03.058504 EDT | AverageReturn             198.001
2017-06-11 04:36:03.058723 EDT | StdReturn                 161.226
2017-06-11 04:36:03.058910 EDT | MaxReturn                1754.86
2017-06-11 04:36:03.059092 EDT | MinReturn                 114.765
2017-06-11 04:36:03.059364 EDT | AverageEsReturn           167.874
2017-06-11 04:36:03.059587 EDT | StdEsReturn               151.861
2017-06-11 04:36:03.059865 EDT | MaxEsReturn               457.787
2017-06-11 04:36:03.060049 EDT | MinEsReturn                 8.78057
2017-06-11 04:36:03.060232 EDT | AverageDiscountedReturn   114.501
2017-06-11 04:36:03.060502 EDT | AverageQLoss                1.58566
2017-06-11 04:36:03.060840 EDT | AveragePolicySurr         -28.6464
2017-06-11 04:36:03.061187 EDT | AverageQ                   28.4556
2017-06-11 04:36:03.061382 EDT | AverageAbsQ                28.4702
2017-06-11 04:36:03.061565 EDT | AverageY                   28.458
2017-06-11 04:36:03.061769 EDT | AverageAbsY                28.4633
2017-06-11 04:36:03.062078 EDT | AverageAbsQYDiff            0.447353
2017-06-11 04:36:03.062401 EDT | AverageAction               0.997996
2017-06-11 04:36:03.062722 EDT | PolicyRegParamNorm        102.701
2017-06-11 04:36:03.062965 EDT | QFunRegParamNorm          133.006
2017-06-11 04:36:03.063119 EDT | -----------------------  -----------
2017-06-11 04:36:03.063496 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1149 | Training started
2017-06-11 04:36:18.970973 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1149 | Training finished
2017-06-11 04:36:18.971778 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1149 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 04:36:18.972000 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1149 | Collecting samples for evaluation
2017-06-11 04:36:33.088375 EDT | -----------------------  -----------
2017-06-11 04:36:33.089409 EDT | Epoch                    1149
2017-06-11 04:36:33.089773 EDT | Iteration                1149
2017-06-11 04:36:33.090084 EDT | AverageReturn             147.752
2017-06-11 04:36:33.090415 EDT | StdReturn                  38.6603
2017-06-11 04:36:33.090742 EDT | MaxReturn                 203.457
2017-06-11 04:36:33.091073 EDT | MinReturn                 108.851
2017-06-11 04:36:33.091394 EDT | AverageEsReturn           175.823
2017-06-11 04:36:33.091717 EDT | StdEsReturn               127.155
2017-06-11 04:36:33.092024 EDT | MaxEsReturn               479.258
2017-06-11 04:36:33.093743 EDT | MinEsReturn                18.6883
2017-06-11 04:36:33.094216 EDT | AverageDiscountedReturn    98.7698
2017-06-11 04:36:33.094677 EDT | AverageQLoss                1.91805
2017-06-11 04:36:33.095063 EDT | AveragePolicySurr         -28.5954
2017-06-11 04:36:33.095443 EDT | AverageQ                   28.4091
2017-06-11 04:36:33.095798 EDT | AverageAbsQ                28.4251
2017-06-11 04:36:33.096138 EDT | AverageY                   28.4091
2017-06-11 04:36:33.096464 EDT | AverageAbsY                28.415
2017-06-11 04:36:33.096786 EDT | AverageAbsQYDiff            0.485019
2017-06-11 04:36:33.097110 EDT | AverageAction               0.998505
2017-06-11 04:36:33.097432 EDT | PolicyRegParamNorm        102.781
2017-06-11 04:36:33.097818 EDT | QFunRegParamNorm          133.056
2017-06-11 04:36:33.098203 EDT | -----------------------  -----------
2017-06-11 04:36:33.098796 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1150 | Training started
2017-06-11 04:36:48.655548 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1150 | Training finished
2017-06-11 04:36:48.790663 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1150 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 04:36:48.791139 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1150 | Collecting samples for evaluation
2017-06-11 04:37:01.809012 EDT | -----------------------  -----------
2017-06-11 04:37:01.810390 EDT | Epoch                    1150
2017-06-11 04:37:01.810830 EDT | Iteration                1150
2017-06-11 04:37:01.811232 EDT | AverageReturn             179.852
2017-06-11 04:37:01.811646 EDT | StdReturn                 175.39
2017-06-11 04:37:01.811988 EDT | MaxReturn                 752.302
2017-06-11 04:37:01.812317 EDT | MinReturn                  93.376
2017-06-11 04:37:01.812639 EDT | AverageEsReturn           251.354
2017-06-11 04:37:01.812987 EDT | StdEsReturn               155.812
2017-06-11 04:37:01.813313 EDT | MaxEsReturn               570.422
2017-06-11 04:37:01.813629 EDT | MinEsReturn               108.433
2017-06-11 04:37:01.813954 EDT | AverageDiscountedReturn    99.5221
2017-06-11 04:37:01.814336 EDT | AverageQLoss                1.9473
2017-06-11 04:37:01.814607 EDT | AveragePolicySurr         -28.4992
2017-06-11 04:37:01.814919 EDT | AverageQ                   28.2966
2017-06-11 04:37:01.815281 EDT | AverageAbsQ                28.3167
2017-06-11 04:37:01.815587 EDT | AverageY                   28.2986
2017-06-11 04:37:01.815903 EDT | AverageAbsY                28.3067
2017-06-11 04:37:01.816221 EDT | AverageAbsQYDiff            0.490283
2017-06-11 04:37:01.816527 EDT | AverageAction               0.99837
2017-06-11 04:37:01.817027 EDT | PolicyRegParamNorm        102.841
2017-06-11 04:37:01.817342 EDT | QFunRegParamNorm          133.089
2017-06-11 04:37:01.817666 EDT | -----------------------  -----------
2017-06-11 04:37:01.819325 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1151 | Training started
2017-06-11 04:37:18.303964 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1151 | Training finished
2017-06-11 04:37:18.304719 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1151 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 04:37:18.304944 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1151 | Collecting samples for evaluation
2017-06-11 04:37:31.640329 EDT | -----------------------  -----------
2017-06-11 04:37:31.641171 EDT | Epoch                    1151
2017-06-11 04:37:31.641370 EDT | Iteration                1151
2017-06-11 04:37:31.641556 EDT | AverageReturn             129.041
2017-06-11 04:37:31.643626 EDT | StdReturn                 278.327
2017-06-11 04:37:31.645128 EDT | MaxReturn                3241.87
2017-06-11 04:37:31.645643 EDT | MinReturn                  85.3699
2017-06-11 04:37:31.645827 EDT | AverageEsReturn           180.173
2017-06-11 04:37:31.646008 EDT | StdEsReturn               142.575
2017-06-11 04:37:31.646175 EDT | MaxEsReturn               451.225
2017-06-11 04:37:31.646334 EDT | MinEsReturn                10.9926
2017-06-11 04:37:31.646488 EDT | AverageDiscountedReturn    75.9802
2017-06-11 04:37:31.646660 EDT | AverageQLoss                1.80066
2017-06-11 04:37:31.647258 EDT | AveragePolicySurr         -28.5606
2017-06-11 04:37:31.647596 EDT | AverageQ                   28.3431
2017-06-11 04:37:31.647777 EDT | AverageAbsQ                28.3599
2017-06-11 04:37:31.647931 EDT | AverageY                   28.3432
2017-06-11 04:37:31.648159 EDT | AverageAbsY                28.3512
2017-06-11 04:37:31.648409 EDT | AverageAbsQYDiff            0.469969
2017-06-11 04:37:31.648661 EDT | AverageAction               0.998598
2017-06-11 04:37:31.648856 EDT | PolicyRegParamNorm        102.841
2017-06-11 04:37:31.649119 EDT | QFunRegParamNorm          133.154
2017-06-11 04:37:31.649274 EDT | -----------------------  -----------
2017-06-11 04:37:31.649590 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1152 | Training started
2017-06-11 04:37:47.542050 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1152 | Training finished
2017-06-11 04:37:47.542889 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1152 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 04:37:47.543265 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1152 | Collecting samples for evaluation
2017-06-11 04:38:01.746586 EDT | -----------------------  -----------
2017-06-11 04:38:01.748181 EDT | Epoch                    1152
2017-06-11 04:38:01.748622 EDT | Iteration                1152
2017-06-11 04:38:01.750160 EDT | AverageReturn            1205.16
2017-06-11 04:38:01.750861 EDT | StdReturn                 660.217
2017-06-11 04:38:01.751351 EDT | MaxReturn                2847.88
2017-06-11 04:38:01.752274 EDT | MinReturn                 568.121
2017-06-11 04:38:01.753158 EDT | AverageEsReturn           468.882
2017-06-11 04:38:01.753619 EDT | StdEsReturn               414.748
2017-06-11 04:38:01.754052 EDT | MaxEsReturn              1100.27
2017-06-11 04:38:01.754546 EDT | MinEsReturn                83.6274
2017-06-11 04:38:01.754952 EDT | AverageDiscountedReturn   215.77
2017-06-11 04:38:01.755369 EDT | AverageQLoss                1.92289
2017-06-11 04:38:01.755814 EDT | AveragePolicySurr         -28.6405
2017-06-11 04:38:01.756226 EDT | AverageQ                   28.4318
2017-06-11 04:38:01.756646 EDT | AverageAbsQ                28.4464
2017-06-11 04:38:01.757058 EDT | AverageY                   28.4334
2017-06-11 04:38:01.757471 EDT | AverageAbsY                28.4406
2017-06-11 04:38:01.758083 EDT | AverageAbsQYDiff            0.479856
2017-06-11 04:38:01.758501 EDT | AverageAction               0.998396
2017-06-11 04:38:01.763325 EDT | PolicyRegParamNorm        102.865
2017-06-11 04:38:01.763560 EDT | QFunRegParamNorm          133.24
2017-06-11 04:38:01.763867 EDT | -----------------------  -----------
2017-06-11 04:38:01.764217 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1153 | Training started
2017-06-11 04:38:17.599940 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1153 | Training finished
2017-06-11 04:38:17.600745 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1153 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 04:38:17.600936 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1153 | Collecting samples for evaluation
2017-06-11 04:38:32.378317 EDT | -----------------------  -----------
2017-06-11 04:38:32.379179 EDT | Epoch                    1153
2017-06-11 04:38:32.379473 EDT | Iteration                1153
2017-06-11 04:38:32.379745 EDT | AverageReturn              15.129
2017-06-11 04:38:32.380011 EDT | StdReturn                   1.36544
2017-06-11 04:38:32.380271 EDT | MaxReturn                  17.5001
2017-06-11 04:38:32.380536 EDT | MinReturn                  12.6872
2017-06-11 04:38:32.380800 EDT | AverageEsReturn           126.169
2017-06-11 04:38:32.381060 EDT | StdEsReturn               171.353
2017-06-11 04:38:32.381320 EDT | MaxEsReturn               583.726
2017-06-11 04:38:32.381580 EDT | MinEsReturn                 7.49844
2017-06-11 04:38:32.381853 EDT | AverageDiscountedReturn    14.1654
2017-06-11 04:38:32.382116 EDT | AverageQLoss                1.77329
2017-06-11 04:38:32.382377 EDT | AveragePolicySurr         -28.585
2017-06-11 04:38:32.382636 EDT | AverageQ                   28.3691
2017-06-11 04:38:32.382895 EDT | AverageAbsQ                28.3844
2017-06-11 04:38:32.383153 EDT | AverageY                   28.3705
2017-06-11 04:38:32.383412 EDT | AverageAbsY                28.375
2017-06-11 04:38:32.383670 EDT | AverageAbsQYDiff            0.471989
2017-06-11 04:38:32.383928 EDT | AverageAction               1
2017-06-11 04:38:32.384187 EDT | PolicyRegParamNorm        102.919
2017-06-11 04:38:32.384445 EDT | QFunRegParamNorm          133.305
2017-06-11 04:38:32.384703 EDT | -----------------------  -----------
2017-06-11 04:38:32.385093 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1154 | Training started
2017-06-11 04:38:50.404835 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1154 | Training finished
2017-06-11 04:38:50.408151 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1154 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 04:38:50.408375 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1154 | Collecting samples for evaluation
2017-06-11 04:39:04.472485 EDT | -----------------------  -----------
2017-06-11 04:39:04.473823 EDT | Epoch                    1154
2017-06-11 04:39:04.474279 EDT | Iteration                1154
2017-06-11 04:39:04.474697 EDT | AverageReturn            1456.57
2017-06-11 04:39:04.475963 EDT | StdReturn                1070.75
2017-06-11 04:39:04.476411 EDT | MaxReturn                2619.04
2017-06-11 04:39:04.476938 EDT | MinReturn                  82.8259
2017-06-11 04:39:04.478233 EDT | AverageEsReturn           219.775
2017-06-11 04:39:04.478641 EDT | StdEsReturn               222.25
2017-06-11 04:39:04.480098 EDT | MaxEsReturn               819.153
2017-06-11 04:39:04.480522 EDT | MinEsReturn                12.5347
2017-06-11 04:39:04.480998 EDT | AverageDiscountedReturn   168.034
2017-06-11 04:39:04.481547 EDT | AverageQLoss                1.80122
2017-06-11 04:39:04.481966 EDT | AveragePolicySurr         -28.6112
2017-06-11 04:39:04.482356 EDT | AverageQ                   28.3987
2017-06-11 04:39:04.482771 EDT | AverageAbsQ                28.4159
2017-06-11 04:39:04.483278 EDT | AverageY                   28.4009
2017-06-11 04:39:04.483750 EDT | AverageAbsY                28.4087
2017-06-11 04:39:04.484169 EDT | AverageAbsQYDiff            0.476791
2017-06-11 04:39:04.484583 EDT | AverageAction               0.99833
2017-06-11 04:39:04.485011 EDT | PolicyRegParamNorm        102.92
2017-06-11 04:39:04.486322 EDT | QFunRegParamNorm          133.316
2017-06-11 04:39:04.486718 EDT | -----------------------  -----------
2017-06-11 04:39:04.487350 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1155 | Training started
2017-06-11 04:39:20.769652 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1155 | Training finished
2017-06-11 04:39:20.770495 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1155 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 04:39:20.770684 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1155 | Collecting samples for evaluation
2017-06-11 04:39:34.080204 EDT | -----------------------  -----------
2017-06-11 04:39:34.080913 EDT | Epoch                    1155
2017-06-11 04:39:34.081266 EDT | Iteration                1155
2017-06-11 04:39:34.081492 EDT | AverageReturn            2056
2017-06-11 04:39:34.081652 EDT | StdReturn                 832.562
2017-06-11 04:39:34.081866 EDT | MaxReturn                3022.82
2017-06-11 04:39:34.082019 EDT | MinReturn                  86.2202
2017-06-11 04:39:34.082227 EDT | AverageEsReturn           264.759
2017-06-11 04:39:34.082480 EDT | StdEsReturn               231.697
2017-06-11 04:39:34.082796 EDT | MaxEsReturn               824.719
2017-06-11 04:39:34.083964 EDT | MinEsReturn                27.7733
2017-06-11 04:39:34.084297 EDT | AverageDiscountedReturn   230.153
2017-06-11 04:39:34.084632 EDT | AverageQLoss                2.00257
2017-06-11 04:39:34.084904 EDT | AveragePolicySurr         -28.5406
2017-06-11 04:39:34.085185 EDT | AverageQ                   28.3191
2017-06-11 04:39:34.085503 EDT | AverageAbsQ                28.3344
2017-06-11 04:39:34.085798 EDT | AverageY                   28.3201
2017-06-11 04:39:34.086001 EDT | AverageAbsY                28.3265
2017-06-11 04:39:34.086247 EDT | AverageAbsQYDiff            0.486731
2017-06-11 04:39:34.086484 EDT | AverageAction               0.9984
2017-06-11 04:39:34.086728 EDT | PolicyRegParamNorm        102.964
2017-06-11 04:39:34.087503 EDT | QFunRegParamNorm          133.414
2017-06-11 04:39:34.087808 EDT | -----------------------  -----------
2017-06-11 04:39:34.088296 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1156 | Training started
2017-06-11 04:39:49.629641 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1156 | Training finished
2017-06-11 04:39:49.630636 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1156 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 04:39:49.631015 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1156 | Collecting samples for evaluation
2017-06-11 04:40:03.437444 EDT | -----------------------  -----------
2017-06-11 04:40:03.438393 EDT | Epoch                    1156
2017-06-11 04:40:03.438623 EDT | Iteration                1156
2017-06-11 04:40:03.438790 EDT | AverageReturn             612.911
2017-06-11 04:40:03.438949 EDT | StdReturn                 354.901
2017-06-11 04:40:03.439158 EDT | MaxReturn                1949.65
2017-06-11 04:40:03.439313 EDT | MinReturn                 406.083
2017-06-11 04:40:03.439466 EDT | AverageEsReturn           247.499
2017-06-11 04:40:03.439617 EDT | StdEsReturn               240.614
2017-06-11 04:40:03.439768 EDT | MaxEsReturn               677.278
2017-06-11 04:40:03.439918 EDT | MinEsReturn                 5.28576
2017-06-11 04:40:03.440068 EDT | AverageDiscountedReturn   196.928
2017-06-11 04:40:03.440351 EDT | AverageQLoss                1.94765
2017-06-11 04:40:03.440519 EDT | AveragePolicySurr         -28.4607
2017-06-11 04:40:03.441261 EDT | AverageQ                   28.2617
2017-06-11 04:40:03.441865 EDT | AverageAbsQ                28.2787
2017-06-11 04:40:03.442070 EDT | AverageY                   28.2618
2017-06-11 04:40:03.442385 EDT | AverageAbsY                28.2702
2017-06-11 04:40:03.442572 EDT | AverageAbsQYDiff            0.489772
2017-06-11 04:40:03.442894 EDT | AverageAction               0.998908
2017-06-11 04:40:03.443078 EDT | PolicyRegParamNorm        103.025
2017-06-11 04:40:03.443260 EDT | QFunRegParamNorm          133.462
2017-06-11 04:40:03.443441 EDT | -----------------------  -----------
2017-06-11 04:40:03.443862 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1157 | Training started
2017-06-11 04:40:20.746691 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1157 | Training finished
2017-06-11 04:40:20.747527 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1157 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 04:40:20.747745 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1157 | Collecting samples for evaluation
2017-06-11 04:40:35.625868 EDT | -----------------------  -----------
2017-06-11 04:40:35.626784 EDT | Epoch                    1157
2017-06-11 04:40:35.627583 EDT | Iteration                1157
2017-06-11 04:40:35.628233 EDT | AverageReturn             872.19
2017-06-11 04:40:35.628529 EDT | StdReturn                 791.548
2017-06-11 04:40:35.628927 EDT | MaxReturn                3040.11
2017-06-11 04:40:35.630840 EDT | MinReturn                 399.958
2017-06-11 04:40:35.631213 EDT | AverageEsReturn           307.438
2017-06-11 04:40:35.631641 EDT | StdEsReturn               177.031
2017-06-11 04:40:35.632534 EDT | MaxEsReturn               608.69
2017-06-11 04:40:35.632881 EDT | MinEsReturn                90.0196
2017-06-11 04:40:35.633213 EDT | AverageDiscountedReturn   197.957
2017-06-11 04:40:35.633539 EDT | AverageQLoss                1.99453
2017-06-11 04:40:35.633975 EDT | AveragePolicySurr         -28.5357
2017-06-11 04:40:35.634305 EDT | AverageQ                   28.3124
2017-06-11 04:40:35.634577 EDT | AverageAbsQ                28.3278
2017-06-11 04:40:35.634968 EDT | AverageY                   28.3138
2017-06-11 04:40:35.635305 EDT | AverageAbsY                28.3221
2017-06-11 04:40:35.635634 EDT | AverageAbsQYDiff            0.48188
2017-06-11 04:40:35.635959 EDT | AverageAction               0.998765
2017-06-11 04:40:35.636292 EDT | PolicyRegParamNorm        103.063
2017-06-11 04:40:35.636567 EDT | QFunRegParamNorm          133.534
2017-06-11 04:40:35.636834 EDT | -----------------------  -----------
2017-06-11 04:40:35.648176 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1158 | Training started
2017-06-11 04:40:53.279228 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1158 | Training finished
2017-06-11 04:40:53.279701 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1158 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 04:40:53.280083 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1158 | Collecting samples for evaluation
2017-06-11 04:41:06.793643 EDT | -----------------------  -----------
2017-06-11 04:41:06.794365 EDT | Epoch                    1158
2017-06-11 04:41:06.794539 EDT | Iteration                1158
2017-06-11 04:41:06.794846 EDT | AverageReturn            1874.83
2017-06-11 04:41:06.795054 EDT | StdReturn                1200.02
2017-06-11 04:41:06.795268 EDT | MaxReturn                3186.77
2017-06-11 04:41:06.795526 EDT | MinReturn                  21.2437
2017-06-11 04:41:06.795689 EDT | AverageEsReturn           350.492
2017-06-11 04:41:06.795850 EDT | StdEsReturn               218.68
2017-06-11 04:41:06.796458 EDT | MaxEsReturn               745.453
2017-06-11 04:41:06.796713 EDT | MinEsReturn               117.212
2017-06-11 04:41:06.796972 EDT | AverageDiscountedReturn   201.774
2017-06-11 04:41:06.797170 EDT | AverageQLoss                2.17968
2017-06-11 04:41:06.797434 EDT | AveragePolicySurr         -28.4771
2017-06-11 04:41:06.797722 EDT | AverageQ                   28.2605
2017-06-11 04:41:06.797949 EDT | AverageAbsQ                28.2763
2017-06-11 04:41:06.798110 EDT | AverageY                   28.2614
2017-06-11 04:41:06.798306 EDT | AverageAbsY                28.268
2017-06-11 04:41:06.798472 EDT | AverageAbsQYDiff            0.484083
2017-06-11 04:41:06.798667 EDT | AverageAction               0.99855
2017-06-11 04:41:06.798888 EDT | PolicyRegParamNorm        103.108
2017-06-11 04:41:06.799069 EDT | QFunRegParamNorm          133.593
2017-06-11 04:41:06.799425 EDT | -----------------------  -----------
2017-06-11 04:41:06.799772 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1159 | Training started
2017-06-11 04:41:24.378368 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1159 | Training finished
2017-06-11 04:41:24.379320 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1159 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 04:41:24.379838 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1159 | Collecting samples for evaluation
2017-06-11 04:41:37.357398 EDT | -----------------------  -----------
2017-06-11 04:41:37.358429 EDT | Epoch                    1159
2017-06-11 04:41:37.358973 EDT | Iteration                1159
2017-06-11 04:41:37.359212 EDT | AverageReturn             598.791
2017-06-11 04:41:37.360726 EDT | StdReturn                 398.562
2017-06-11 04:41:37.361053 EDT | MaxReturn                2502.4
2017-06-11 04:41:37.361212 EDT | MinReturn                 415.687
2017-06-11 04:41:37.361380 EDT | AverageEsReturn           171.693
2017-06-11 04:41:37.361649 EDT | StdEsReturn               138.643
2017-06-11 04:41:37.361878 EDT | MaxEsReturn               437.781
2017-06-11 04:41:37.362122 EDT | MinEsReturn                25.7255
2017-06-11 04:41:37.362287 EDT | AverageDiscountedReturn   196.375
2017-06-11 04:41:37.362443 EDT | AverageQLoss                2.03143
2017-06-11 04:41:37.362596 EDT | AveragePolicySurr         -28.604
2017-06-11 04:41:37.362747 EDT | AverageQ                   28.3882
2017-06-11 04:41:37.364385 EDT | AverageAbsQ                28.404
2017-06-11 04:41:37.364790 EDT | AverageY                   28.3906
2017-06-11 04:41:37.365115 EDT | AverageAbsY                28.3985
2017-06-11 04:41:37.365428 EDT | AverageAbsQYDiff            0.482069
2017-06-11 04:41:37.367540 EDT | AverageAction               0.999014
2017-06-11 04:41:37.367972 EDT | PolicyRegParamNorm        103.217
2017-06-11 04:41:37.369253 EDT | QFunRegParamNorm          133.664
2017-06-11 04:41:37.369550 EDT | -----------------------  -----------
2017-06-11 04:41:37.369989 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1160 | Training started
2017-06-11 04:41:53.423407 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1160 | Training finished
2017-06-11 04:41:53.424188 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1160 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 04:41:53.424982 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1160 | Collecting samples for evaluation
2017-06-11 04:42:07.082687 EDT | -----------------------  -----------
2017-06-11 04:42:07.083680 EDT | Epoch                    1160
2017-06-11 04:42:07.084049 EDT | Iteration                1160
2017-06-11 04:42:07.084400 EDT | AverageReturn             653.638
2017-06-11 04:42:07.084742 EDT | StdReturn                 210.451
2017-06-11 04:42:07.085087 EDT | MaxReturn                1470.02
2017-06-11 04:42:07.085430 EDT | MinReturn                 432.417
2017-06-11 04:42:07.085896 EDT | AverageEsReturn           215.401
2017-06-11 04:42:07.086339 EDT | StdEsReturn               136.677
2017-06-11 04:42:07.086781 EDT | MaxEsReturn               512.295
2017-06-11 04:42:07.087135 EDT | MinEsReturn                12.5536
2017-06-11 04:42:07.088573 EDT | AverageDiscountedReturn   215.864
2017-06-11 04:42:07.089530 EDT | AverageQLoss                1.76988
2017-06-11 04:42:07.089908 EDT | AveragePolicySurr         -28.4727
2017-06-11 04:42:07.092124 EDT | AverageQ                   28.255
2017-06-11 04:42:07.092493 EDT | AverageAbsQ                28.2717
2017-06-11 04:42:07.092842 EDT | AverageY                   28.2541
2017-06-11 04:42:07.093190 EDT | AverageAbsY                28.2651
2017-06-11 04:42:07.093531 EDT | AverageAbsQYDiff            0.467365
2017-06-11 04:42:07.093885 EDT | AverageAction               0.998639
2017-06-11 04:42:07.094226 EDT | PolicyRegParamNorm        103.254
2017-06-11 04:42:07.094570 EDT | QFunRegParamNorm          133.735
2017-06-11 04:42:07.094909 EDT | -----------------------  -----------
2017-06-11 04:42:07.095422 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1161 | Training started
2017-06-11 04:42:22.779048 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1161 | Training finished
2017-06-11 04:42:22.779554 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1161 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 04:42:22.779920 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1161 | Collecting samples for evaluation
2017-06-11 04:42:36.486674 EDT | -----------------------  -----------
2017-06-11 04:42:36.488091 EDT | Epoch                    1161
2017-06-11 04:42:36.488291 EDT | Iteration                1161
2017-06-11 04:42:36.488653 EDT | AverageReturn            2603.3
2017-06-11 04:42:36.488849 EDT | StdReturn                 483.894
2017-06-11 04:42:36.489049 EDT | MaxReturn                3078.79
2017-06-11 04:42:36.489246 EDT | MinReturn                1512.43
2017-06-11 04:42:36.489440 EDT | AverageEsReturn           378.622
2017-06-11 04:42:36.489635 EDT | StdEsReturn               175.581
2017-06-11 04:42:36.489859 EDT | MaxEsReturn               651.673
2017-06-11 04:42:36.490054 EDT | MinEsReturn               118.564
2017-06-11 04:42:36.490246 EDT | AverageDiscountedReturn   234.083
2017-06-11 04:42:36.490437 EDT | AverageQLoss                1.92107
2017-06-11 04:42:36.490628 EDT | AveragePolicySurr         -28.6217
2017-06-11 04:42:36.490832 EDT | AverageQ                   28.4121
2017-06-11 04:42:36.491027 EDT | AverageAbsQ                28.4291
2017-06-11 04:42:36.491448 EDT | AverageY                   28.4147
2017-06-11 04:42:36.491643 EDT | AverageAbsY                28.4243
2017-06-11 04:42:36.491974 EDT | AverageAbsQYDiff            0.467936
2017-06-11 04:42:36.492232 EDT | AverageAction               0.998648
2017-06-11 04:42:36.492406 EDT | PolicyRegParamNorm        103.297
2017-06-11 04:42:36.492743 EDT | QFunRegParamNorm          133.763
2017-06-11 04:42:36.494735 EDT | -----------------------  -----------
2017-06-11 04:42:36.495518 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1162 | Training started
2017-06-11 04:42:53.436273 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1162 | Training finished
2017-06-11 04:42:53.436755 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1162 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 04:42:53.437075 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1162 | Collecting samples for evaluation
2017-06-11 04:43:07.280430 EDT | -----------------------  -----------
2017-06-11 04:43:07.281770 EDT | Epoch                    1162
2017-06-11 04:43:07.284016 EDT | Iteration                1162
2017-06-11 04:43:07.285757 EDT | AverageReturn            3083.65
2017-06-11 04:43:07.286244 EDT | StdReturn                 571.345
2017-06-11 04:43:07.286639 EDT | MaxReturn                3333.53
2017-06-11 04:43:07.286960 EDT | MinReturn                1281.13
2017-06-11 04:43:07.287333 EDT | AverageEsReturn           717.127
2017-06-11 04:43:07.287644 EDT | StdEsReturn               821.334
2017-06-11 04:43:07.287975 EDT | MaxEsReturn              2101.44
2017-06-11 04:43:07.288297 EDT | MinEsReturn                78.6713
2017-06-11 04:43:07.288670 EDT | AverageDiscountedReturn   247.752
2017-06-11 04:43:07.288988 EDT | AverageQLoss                2.05523
2017-06-11 04:43:07.289311 EDT | AveragePolicySurr         -28.4871
2017-06-11 04:43:07.289606 EDT | AverageQ                   28.2581
2017-06-11 04:43:07.289822 EDT | AverageAbsQ                28.2768
2017-06-11 04:43:07.289979 EDT | AverageY                   28.2574
2017-06-11 04:43:07.290133 EDT | AverageAbsY                28.2675
2017-06-11 04:43:07.290347 EDT | AverageAbsQYDiff            0.485978
2017-06-11 04:43:07.290577 EDT | AverageAction               0.998636
2017-06-11 04:43:07.290892 EDT | PolicyRegParamNorm        103.306
2017-06-11 04:43:07.291128 EDT | QFunRegParamNorm          133.812
2017-06-11 04:43:07.291442 EDT | -----------------------  -----------
2017-06-11 04:43:07.291898 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1163 | Training started
2017-06-11 04:43:23.228521 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1163 | Training finished
2017-06-11 04:43:23.228951 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1163 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 04:43:23.229306 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1163 | Collecting samples for evaluation
2017-06-11 04:43:36.986546 EDT | -----------------------  -----------
2017-06-11 04:43:36.987453 EDT | Epoch                    1163
2017-06-11 04:43:36.987634 EDT | Iteration                1163
2017-06-11 04:43:36.987792 EDT | AverageReturn            2103.53
2017-06-11 04:43:36.987946 EDT | StdReturn                1173.05
2017-06-11 04:43:36.988116 EDT | MaxReturn                3461.58
2017-06-11 04:43:36.988328 EDT | MinReturn                 697.859
2017-06-11 04:43:36.988555 EDT | AverageEsReturn           369.576
2017-06-11 04:43:36.988710 EDT | StdEsReturn               188.231
2017-06-11 04:43:36.988908 EDT | MaxEsReturn               543.853
2017-06-11 04:43:36.989058 EDT | MinEsReturn                64.635
2017-06-11 04:43:36.989207 EDT | AverageDiscountedReturn   249.209
2017-06-11 04:43:36.989402 EDT | AverageQLoss                1.89704
2017-06-11 04:43:36.989571 EDT | AveragePolicySurr         -28.4709
2017-06-11 04:43:36.989763 EDT | AverageQ                   28.272
2017-06-11 04:43:36.990062 EDT | AverageAbsQ                28.2895
2017-06-11 04:43:36.990274 EDT | AverageY                   28.2737
2017-06-11 04:43:36.990676 EDT | AverageAbsY                28.2834
2017-06-11 04:43:36.991071 EDT | AverageAbsQYDiff            0.46102
2017-06-11 04:43:36.991412 EDT | AverageAction               0.999015
2017-06-11 04:43:36.991748 EDT | PolicyRegParamNorm        103.314
2017-06-11 04:43:36.992106 EDT | QFunRegParamNorm          133.844
2017-06-11 04:43:36.992469 EDT | -----------------------  -----------
2017-06-11 04:43:36.992951 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1164 | Training started
2017-06-11 04:43:53.631338 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1164 | Training finished
2017-06-11 04:43:53.631690 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1164 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 04:43:53.631975 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1164 | Collecting samples for evaluation
2017-06-11 04:44:07.603491 EDT | -----------------------  -----------
2017-06-11 04:44:07.604492 EDT | Epoch                    1164
2017-06-11 04:44:07.606629 EDT | Iteration                1164
2017-06-11 04:44:07.606988 EDT | AverageReturn            1640.58
2017-06-11 04:44:07.608680 EDT | StdReturn                 548.145
2017-06-11 04:44:07.609054 EDT | MaxReturn                3026.61
2017-06-11 04:44:07.609399 EDT | MinReturn                 993.649
2017-06-11 04:44:07.609761 EDT | AverageEsReturn           268.394
2017-06-11 04:44:07.610121 EDT | StdEsReturn               163.383
2017-06-11 04:44:07.610467 EDT | MaxEsReturn               497.049
2017-06-11 04:44:07.610899 EDT | MinEsReturn                29.6359
2017-06-11 04:44:07.611247 EDT | AverageDiscountedReturn   240.14
2017-06-11 04:44:07.611586 EDT | AverageQLoss                1.95815
2017-06-11 04:44:07.611998 EDT | AveragePolicySurr         -28.4369
2017-06-11 04:44:07.612437 EDT | AverageQ                   28.2076
2017-06-11 04:44:07.612877 EDT | AverageAbsQ                28.2291
2017-06-11 04:44:07.613318 EDT | AverageY                   28.2092
2017-06-11 04:44:07.613666 EDT | AverageAbsY                28.2217
2017-06-11 04:44:07.614652 EDT | AverageAbsQYDiff            0.482505
2017-06-11 04:44:07.615259 EDT | AverageAction               0.998637
2017-06-11 04:44:07.615821 EDT | PolicyRegParamNorm        103.361
2017-06-11 04:44:07.616273 EDT | QFunRegParamNorm          133.89
2017-06-11 04:44:07.616716 EDT | -----------------------  -----------
2017-06-11 04:44:07.619179 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1165 | Training started
2017-06-11 04:44:24.256116 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1165 | Training finished
2017-06-11 04:44:24.256415 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1165 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 04:44:24.256589 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1165 | Collecting samples for evaluation
2017-06-11 04:44:37.847620 EDT | -----------------------  -----------
2017-06-11 04:44:37.848490 EDT | Epoch                    1165
2017-06-11 04:44:37.848787 EDT | Iteration                1165
2017-06-11 04:44:37.849051 EDT | AverageReturn            2668.61
2017-06-11 04:44:37.849302 EDT | StdReturn                 706.706
2017-06-11 04:44:37.849550 EDT | MaxReturn                3264.77
2017-06-11 04:44:37.849895 EDT | MinReturn                1403.45
2017-06-11 04:44:37.850231 EDT | AverageEsReturn           222.109
2017-06-11 04:44:37.850563 EDT | StdEsReturn               257.991
2017-06-11 04:44:37.850888 EDT | MaxEsReturn               767.229
2017-06-11 04:44:37.851220 EDT | MinEsReturn                10.7901
2017-06-11 04:44:37.852455 EDT | AverageDiscountedReturn   246.334
2017-06-11 04:44:37.852888 EDT | AverageQLoss                1.80269
2017-06-11 04:44:37.853289 EDT | AveragePolicySurr         -28.5707
2017-06-11 04:44:37.853603 EDT | AverageQ                   28.3465
2017-06-11 04:44:37.856342 EDT | AverageAbsQ                28.3634
2017-06-11 04:44:37.856822 EDT | AverageY                   28.3481
2017-06-11 04:44:37.857247 EDT | AverageAbsY                28.3564
2017-06-11 04:44:37.857575 EDT | AverageAbsQYDiff            0.470511
2017-06-11 04:44:37.857960 EDT | AverageAction               0.998476
2017-06-11 04:44:37.858238 EDT | PolicyRegParamNorm        103.37
2017-06-11 04:44:37.858555 EDT | QFunRegParamNorm          133.964
2017-06-11 04:44:37.858993 EDT | -----------------------  -----------
2017-06-11 04:44:37.859491 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1166 | Training started
2017-06-11 04:44:55.090080 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1166 | Training finished
2017-06-11 04:44:55.091048 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1166 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 04:44:55.091428 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1166 | Collecting samples for evaluation
2017-06-11 04:45:09.044642 EDT | -----------------------  -----------
2017-06-11 04:45:09.045414 EDT | Epoch                    1166
2017-06-11 04:45:09.045685 EDT | Iteration                1166
2017-06-11 04:45:09.045949 EDT | AverageReturn            1595.88
2017-06-11 04:45:09.046199 EDT | StdReturn                1359.51
2017-06-11 04:45:09.046446 EDT | MaxReturn                2947.8
2017-06-11 04:45:09.046693 EDT | MinReturn                  12.8312
2017-06-11 04:45:09.046984 EDT | AverageEsReturn           285.324
2017-06-11 04:45:09.047238 EDT | StdEsReturn               266.401
2017-06-11 04:45:09.047486 EDT | MaxEsReturn               697.659
2017-06-11 04:45:09.047733 EDT | MinEsReturn                 8.88934
2017-06-11 04:45:09.047977 EDT | AverageDiscountedReturn   139.702
2017-06-11 04:45:09.048220 EDT | AverageQLoss                2.10446
2017-06-11 04:45:09.048465 EDT | AveragePolicySurr         -28.4737
2017-06-11 04:45:09.048700 EDT | AverageQ                   28.2511
2017-06-11 04:45:09.048851 EDT | AverageAbsQ                28.2687
2017-06-11 04:45:09.049000 EDT | AverageY                   28.2526
2017-06-11 04:45:09.049148 EDT | AverageAbsY                28.2606
2017-06-11 04:45:09.049296 EDT | AverageAbsQYDiff            0.496755
2017-06-11 04:45:09.049443 EDT | AverageAction               0.998796
2017-06-11 04:45:09.049646 EDT | PolicyRegParamNorm        103.406
2017-06-11 04:45:09.049966 EDT | QFunRegParamNorm          134.032
2017-06-11 04:45:09.050121 EDT | -----------------------  -----------
2017-06-11 04:45:09.051196 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1167 | Training started
2017-06-11 04:45:26.482216 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1167 | Training finished
2017-06-11 04:45:26.483261 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1167 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 04:45:26.483663 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1167 | Collecting samples for evaluation
2017-06-11 04:45:40.663808 EDT | -----------------------  -----------
2017-06-11 04:45:40.664696 EDT | Epoch                    1167
2017-06-11 04:45:40.664950 EDT | Iteration                1167
2017-06-11 04:45:40.665141 EDT | AverageReturn            2628.28
2017-06-11 04:45:40.665327 EDT | StdReturn                 558.003
2017-06-11 04:45:40.665560 EDT | MaxReturn                2859.24
2017-06-11 04:45:40.665872 EDT | MinReturn                 868.109
2017-06-11 04:45:40.666370 EDT | AverageEsReturn           364.362
2017-06-11 04:45:40.667121 EDT | StdEsReturn               284.885
2017-06-11 04:45:40.667334 EDT | MaxEsReturn               881.641
2017-06-11 04:45:40.667528 EDT | MinEsReturn                 4.17053
2017-06-11 04:45:40.667984 EDT | AverageDiscountedReturn   230.288
2017-06-11 04:45:40.668172 EDT | AverageQLoss                2.11508
2017-06-11 04:45:40.668526 EDT | AveragePolicySurr         -28.5322
2017-06-11 04:45:40.668814 EDT | AverageQ                   28.3144
2017-06-11 04:45:40.669089 EDT | AverageAbsQ                28.334
2017-06-11 04:45:40.669272 EDT | AverageY                   28.3157
2017-06-11 04:45:40.669508 EDT | AverageAbsY                28.3237
2017-06-11 04:45:40.669720 EDT | AverageAbsQYDiff            0.500871
2017-06-11 04:45:40.669914 EDT | AverageAction               0.998777
2017-06-11 04:45:40.670095 EDT | PolicyRegParamNorm        103.461
2017-06-11 04:45:40.670414 EDT | QFunRegParamNorm          134.044
2017-06-11 04:45:40.670701 EDT | -----------------------  -----------
2017-06-11 04:45:40.671154 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1168 | Training started
2017-06-11 04:45:58.204833 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1168 | Training finished
2017-06-11 04:45:58.206103 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1168 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 04:45:58.206510 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1168 | Collecting samples for evaluation
2017-06-11 04:46:13.615330 EDT | -----------------------  -----------
2017-06-11 04:46:13.616679 EDT | Epoch                    1168
2017-06-11 04:46:13.617289 EDT | Iteration                1168
2017-06-11 04:46:13.617765 EDT | AverageReturn            2788.79
2017-06-11 04:46:13.618212 EDT | StdReturn                 564.743
2017-06-11 04:46:13.619532 EDT | MaxReturn                3057.17
2017-06-11 04:46:13.619997 EDT | MinReturn                1010.27
2017-06-11 04:46:13.622515 EDT | AverageEsReturn           616.859
2017-06-11 04:46:13.622945 EDT | StdEsReturn               689.769
2017-06-11 04:46:13.623323 EDT | MaxEsReturn              1753.53
2017-06-11 04:46:13.623690 EDT | MinEsReturn                 7.55113
2017-06-11 04:46:13.624046 EDT | AverageDiscountedReturn   236.861
2017-06-11 04:46:13.625307 EDT | AverageQLoss                1.8002
2017-06-11 04:46:13.625712 EDT | AveragePolicySurr         -28.533
2017-06-11 04:46:13.627687 EDT | AverageQ                   28.3187
2017-06-11 04:46:13.628100 EDT | AverageAbsQ                28.3314
2017-06-11 04:46:13.628541 EDT | AverageY                   28.3184
2017-06-11 04:46:13.628971 EDT | AverageAbsY                28.3247
2017-06-11 04:46:13.629866 EDT | AverageAbsQYDiff            0.471374
2017-06-11 04:46:13.631946 EDT | AverageAction               0.998142
2017-06-11 04:46:13.632410 EDT | PolicyRegParamNorm        103.45
2017-06-11 04:46:13.632854 EDT | QFunRegParamNorm          134.085
2017-06-11 04:46:13.633296 EDT | -----------------------  -----------
2017-06-11 04:46:13.634364 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1169 | Training started
2017-06-11 04:46:29.932529 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1169 | Training finished
2017-06-11 04:46:29.933575 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1169 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 04:46:29.934129 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1169 | Collecting samples for evaluation
2017-06-11 04:46:44.121394 EDT | -----------------------  -----------
2017-06-11 04:46:44.122349 EDT | Epoch                    1169
2017-06-11 04:46:44.122830 EDT | Iteration                1169
2017-06-11 04:46:44.123285 EDT | AverageReturn            2331.29
2017-06-11 04:46:44.123715 EDT | StdReturn                1176.17
2017-06-11 04:46:44.124091 EDT | MaxReturn                3262.47
2017-06-11 04:46:44.124393 EDT | MinReturn                 584.38
2017-06-11 04:46:44.124755 EDT | AverageEsReturn           298.178
2017-06-11 04:46:44.125101 EDT | StdEsReturn               200.08
2017-06-11 04:46:44.125448 EDT | MaxEsReturn               605.037
2017-06-11 04:46:44.125900 EDT | MinEsReturn                85.8037
2017-06-11 04:46:44.126352 EDT | AverageDiscountedReturn   242.659
2017-06-11 04:46:44.126786 EDT | AverageQLoss                1.96363
2017-06-11 04:46:44.127230 EDT | AveragePolicySurr         -28.5176
2017-06-11 04:46:44.127676 EDT | AverageQ                   28.2735
2017-06-11 04:46:44.128123 EDT | AverageAbsQ                28.2903
2017-06-11 04:46:44.128556 EDT | AverageY                   28.2758
2017-06-11 04:46:44.129015 EDT | AverageAbsY                28.2842
2017-06-11 04:46:44.141915 EDT | AverageAbsQYDiff            0.488054
2017-06-11 04:46:44.142347 EDT | AverageAction               0.998405
2017-06-11 04:46:44.142805 EDT | PolicyRegParamNorm        103.403
2017-06-11 04:46:44.143258 EDT | QFunRegParamNorm          134.165
2017-06-11 04:46:44.143591 EDT | -----------------------  -----------
2017-06-11 04:46:44.144065 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1170 | Training started
2017-06-11 04:47:01.377815 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1170 | Training finished
2017-06-11 04:47:01.378084 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1170 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 04:47:01.378257 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1170 | Collecting samples for evaluation
2017-06-11 04:47:14.927080 EDT | -----------------------  -----------
2017-06-11 04:47:14.929247 EDT | Epoch                    1170
2017-06-11 04:47:14.930036 EDT | Iteration                1170
2017-06-11 04:47:14.930355 EDT | AverageReturn            1898.12
2017-06-11 04:47:14.930739 EDT | StdReturn                 581.459
2017-06-11 04:47:14.931132 EDT | MaxReturn                2692
2017-06-11 04:47:14.931393 EDT | MinReturn                1151.12
2017-06-11 04:47:14.931580 EDT | AverageEsReturn           251.293
2017-06-11 04:47:14.931763 EDT | StdEsReturn               277.381
2017-06-11 04:47:14.932126 EDT | MaxEsReturn               939.841
2017-06-11 04:47:14.932306 EDT | MinEsReturn                69.7222
2017-06-11 04:47:14.932635 EDT | AverageDiscountedReturn   230.166
2017-06-11 04:47:14.932827 EDT | AverageQLoss                1.63466
2017-06-11 04:47:14.933021 EDT | AveragePolicySurr         -28.6251
2017-06-11 04:47:14.934029 EDT | AverageQ                   28.3893
2017-06-11 04:47:14.934262 EDT | AverageAbsQ                28.4028
2017-06-11 04:47:14.934454 EDT | AverageY                   28.3896
2017-06-11 04:47:14.934711 EDT | AverageAbsY                28.3943
2017-06-11 04:47:14.934889 EDT | AverageAbsQYDiff            0.463022
2017-06-11 04:47:14.935081 EDT | AverageAction               0.998003
2017-06-11 04:47:14.935262 EDT | PolicyRegParamNorm        103.441
2017-06-11 04:47:14.935491 EDT | QFunRegParamNorm          134.206
2017-06-11 04:47:14.935675 EDT | -----------------------  -----------
2017-06-11 04:47:14.936130 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1171 | Training started
2017-06-11 04:47:33.144184 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1171 | Training finished
2017-06-11 04:47:33.144678 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1171 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 04:47:33.145043 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1171 | Collecting samples for evaluation
2017-06-11 04:47:47.788513 EDT | -----------------------  -----------
2017-06-11 04:47:47.789398 EDT | Epoch                    1171
2017-06-11 04:47:47.789782 EDT | Iteration                1171
2017-06-11 04:47:47.790107 EDT | AverageReturn            2700.58
2017-06-11 04:47:47.790401 EDT | StdReturn                 355.331
2017-06-11 04:47:47.790743 EDT | MaxReturn                2909.37
2017-06-11 04:47:47.791091 EDT | MinReturn                1589.03
2017-06-11 04:47:47.791437 EDT | AverageEsReturn           454.967
2017-06-11 04:47:47.791719 EDT | StdEsReturn               476.627
2017-06-11 04:47:47.792042 EDT | MaxEsReturn              1393.49
2017-06-11 04:47:47.792381 EDT | MinEsReturn                20.5211
2017-06-11 04:47:47.792731 EDT | AverageDiscountedReturn   235.271
2017-06-11 04:47:47.793070 EDT | AverageQLoss                1.93379
2017-06-11 04:47:47.793377 EDT | AveragePolicySurr         -28.575
2017-06-11 04:47:47.793738 EDT | AverageQ                   28.3446
2017-06-11 04:47:47.794105 EDT | AverageAbsQ                28.3622
2017-06-11 04:47:47.794461 EDT | AverageY                   28.3467
2017-06-11 04:47:47.794755 EDT | AverageAbsY                28.353
2017-06-11 04:47:47.795101 EDT | AverageAbsQYDiff            0.481859
2017-06-11 04:47:47.795446 EDT | AverageAction               0.998087
2017-06-11 04:47:47.795792 EDT | PolicyRegParamNorm        103.503
2017-06-11 04:47:47.796087 EDT | QFunRegParamNorm          134.289
2017-06-11 04:47:47.796399 EDT | -----------------------  -----------
2017-06-11 04:47:47.796886 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1172 | Training started
2017-06-11 04:48:04.672306 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1172 | Training finished
2017-06-11 04:48:04.673077 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1172 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 04:48:04.673423 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1172 | Collecting samples for evaluation
2017-06-11 04:48:19.160433 EDT | -----------------------  -----------
2017-06-11 04:48:19.162000 EDT | Epoch                    1172
2017-06-11 04:48:19.163092 EDT | Iteration                1172
2017-06-11 04:48:19.165433 EDT | AverageReturn            2048.88
2017-06-11 04:48:19.165953 EDT | StdReturn                 993.958
2017-06-11 04:48:19.166341 EDT | MaxReturn                3366.15
2017-06-11 04:48:19.166680 EDT | MinReturn                 613.256
2017-06-11 04:48:19.167197 EDT | AverageEsReturn           488.716
2017-06-11 04:48:19.167541 EDT | StdEsReturn               389.736
2017-06-11 04:48:19.169338 EDT | MaxEsReturn              1110.69
2017-06-11 04:48:19.169764 EDT | MinEsReturn                50.291
2017-06-11 04:48:19.170111 EDT | AverageDiscountedReturn   240.476
2017-06-11 04:48:19.170445 EDT | AverageQLoss                2.16344
2017-06-11 04:48:19.170882 EDT | AveragePolicySurr         -28.5547
2017-06-11 04:48:19.171220 EDT | AverageQ                   28.3274
2017-06-11 04:48:19.171595 EDT | AverageAbsQ                28.3434
2017-06-11 04:48:19.171926 EDT | AverageY                   28.33
2017-06-11 04:48:19.172250 EDT | AverageAbsY                28.3347
2017-06-11 04:48:19.172575 EDT | AverageAbsQYDiff            0.489216
2017-06-11 04:48:19.173900 EDT | AverageAction               0.998246
2017-06-11 04:48:19.174793 EDT | PolicyRegParamNorm        103.527
2017-06-11 04:48:19.176621 EDT | QFunRegParamNorm          134.291
2017-06-11 04:48:19.176988 EDT | -----------------------  -----------
2017-06-11 04:48:19.177452 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1173 | Training started
2017-06-11 04:48:35.620052 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1173 | Training finished
2017-06-11 04:48:35.979420 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1173 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 04:48:35.980264 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1173 | Collecting samples for evaluation
2017-06-11 04:48:49.305435 EDT | -----------------------  -----------
2017-06-11 04:48:49.306196 EDT | Epoch                    1173
2017-06-11 04:48:49.306387 EDT | Iteration                1173
2017-06-11 04:48:49.306552 EDT | AverageReturn            1976.19
2017-06-11 04:48:49.306711 EDT | StdReturn                 857.969
2017-06-11 04:48:49.306903 EDT | MaxReturn                3197.54
2017-06-11 04:48:49.307121 EDT | MinReturn                 723.55
2017-06-11 04:48:49.307341 EDT | AverageEsReturn           470.941
2017-06-11 04:48:49.307535 EDT | StdEsReturn               204.272
2017-06-11 04:48:49.307716 EDT | MaxEsReturn               736.975
2017-06-11 04:48:49.307899 EDT | MinEsReturn               194.475
2017-06-11 04:48:49.308079 EDT | AverageDiscountedReturn   242.201
2017-06-11 04:48:49.308269 EDT | AverageQLoss                2.04387
2017-06-11 04:48:49.308449 EDT | AveragePolicySurr         -28.4505
2017-06-11 04:48:49.308751 EDT | AverageQ                   28.2188
2017-06-11 04:48:49.308955 EDT | AverageAbsQ                28.2327
2017-06-11 04:48:49.309140 EDT | AverageY                   28.2206
2017-06-11 04:48:49.309403 EDT | AverageAbsY                28.2241
2017-06-11 04:48:49.309581 EDT | AverageAbsQYDiff            0.485533
2017-06-11 04:48:49.309781 EDT | AverageAction               0.998769
2017-06-11 04:48:49.309964 EDT | PolicyRegParamNorm        103.524
2017-06-11 04:48:49.310152 EDT | QFunRegParamNorm          134.342
2017-06-11 04:48:49.310334 EDT | -----------------------  -----------
2017-06-11 04:48:49.310645 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1174 | Training started
2017-06-11 04:49:06.609672 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1174 | Training finished
2017-06-11 04:49:06.610461 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1174 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 04:49:06.610664 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1174 | Collecting samples for evaluation
2017-06-11 04:49:21.291828 EDT | -----------------------  -----------
2017-06-11 04:49:21.293552 EDT | Epoch                    1174
2017-06-11 04:49:21.294006 EDT | Iteration                1174
2017-06-11 04:49:21.294539 EDT | AverageReturn            2587.53
2017-06-11 04:49:21.294882 EDT | StdReturn                 265.279
2017-06-11 04:49:21.295241 EDT | MaxReturn                2769.54
2017-06-11 04:49:21.295668 EDT | MinReturn                1874.89
2017-06-11 04:49:21.319275 EDT | AverageEsReturn           438.185
2017-06-11 04:49:21.320326 EDT | StdEsReturn               163.025
2017-06-11 04:49:21.321454 EDT | MaxEsReturn               621.735
2017-06-11 04:49:21.323824 EDT | MinEsReturn               121.441
2017-06-11 04:49:21.324109 EDT | AverageDiscountedReturn   228.344
2017-06-11 04:49:21.324422 EDT | AverageQLoss                1.80244
2017-06-11 04:49:21.324751 EDT | AveragePolicySurr         -28.5907
2017-06-11 04:49:21.325081 EDT | AverageQ                   28.3671
2017-06-11 04:49:21.325346 EDT | AverageAbsQ                28.3825
2017-06-11 04:49:21.325599 EDT | AverageY                   28.3687
2017-06-11 04:49:21.325858 EDT | AverageAbsY                28.3761
2017-06-11 04:49:21.326102 EDT | AverageAbsQYDiff            0.46335
2017-06-11 04:49:21.326382 EDT | AverageAction               0.998434
2017-06-11 04:49:21.326711 EDT | PolicyRegParamNorm        103.554
2017-06-11 04:49:21.327042 EDT | QFunRegParamNorm          134.405
2017-06-11 04:49:21.327325 EDT | -----------------------  -----------
2017-06-11 04:49:21.327702 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1175 | Training started
2017-06-11 04:49:39.228064 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1175 | Training finished
2017-06-11 04:49:39.229020 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1175 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 04:49:39.229384 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1175 | Collecting samples for evaluation
2017-06-11 04:49:54.224227 EDT | -----------------------  -----------
2017-06-11 04:49:54.225525 EDT | Epoch                    1175
2017-06-11 04:49:54.225916 EDT | Iteration                1175
2017-06-11 04:49:54.226275 EDT | AverageReturn            1285.82
2017-06-11 04:49:54.226623 EDT | StdReturn                1032.51
2017-06-11 04:49:54.226964 EDT | MaxReturn                3312.63
2017-06-11 04:49:54.227306 EDT | MinReturn                 521.847
2017-06-11 04:49:54.227789 EDT | AverageEsReturn           355.749
2017-06-11 04:49:54.228130 EDT | StdEsReturn               411.02
2017-06-11 04:49:54.228473 EDT | MaxEsReturn              1365.52
2017-06-11 04:49:54.228816 EDT | MinEsReturn                42.6854
2017-06-11 04:49:54.229159 EDT | AverageDiscountedReturn   235.064
2017-06-11 04:49:54.229499 EDT | AverageQLoss                1.79626
2017-06-11 04:49:54.229850 EDT | AveragePolicySurr         -28.5099
2017-06-11 04:49:54.230193 EDT | AverageQ                   28.2943
2017-06-11 04:49:54.230700 EDT | AverageAbsQ                28.3098
2017-06-11 04:49:54.231043 EDT | AverageY                   28.2945
2017-06-11 04:49:54.231388 EDT | AverageAbsY                28.2991
2017-06-11 04:49:54.231730 EDT | AverageAbsQYDiff            0.457306
2017-06-11 04:49:54.232074 EDT | AverageAction               0.999075
2017-06-11 04:49:54.232414 EDT | PolicyRegParamNorm        103.617
2017-06-11 04:49:54.232755 EDT | QFunRegParamNorm          134.466
2017-06-11 04:49:54.233096 EDT | -----------------------  -----------
2017-06-11 04:49:54.233596 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1176 | Training started
2017-06-11 04:50:10.661653 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1176 | Training finished
2017-06-11 04:50:10.662783 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1176 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 04:50:10.663187 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1176 | Collecting samples for evaluation
2017-06-11 04:50:25.989775 EDT | -----------------------  -----------
2017-06-11 04:50:25.990352 EDT | Epoch                    1176
2017-06-11 04:50:25.990759 EDT | Iteration                1176
2017-06-11 04:50:25.991169 EDT | AverageReturn            1829.24
2017-06-11 04:50:25.991610 EDT | StdReturn                 803.937
2017-06-11 04:50:25.992033 EDT | MaxReturn                3038.65
2017-06-11 04:50:25.992404 EDT | MinReturn                 619.445
2017-06-11 04:50:25.992834 EDT | AverageEsReturn           407.176
2017-06-11 04:50:25.993271 EDT | StdEsReturn               260.981
2017-06-11 04:50:25.993632 EDT | MaxEsReturn               692.784
2017-06-11 04:50:25.994067 EDT | MinEsReturn                85.417
2017-06-11 04:50:25.994505 EDT | AverageDiscountedReturn   242.214
2017-06-11 04:50:25.994918 EDT | AverageQLoss                2.02604
2017-06-11 04:50:25.995294 EDT | AveragePolicySurr         -28.4999
2017-06-11 04:50:25.995711 EDT | AverageQ                   28.2641
2017-06-11 04:50:25.996146 EDT | AverageAbsQ                28.2812
2017-06-11 04:50:25.996520 EDT | AverageY                   28.2649
2017-06-11 04:50:25.996933 EDT | AverageAbsY                28.2713
2017-06-11 04:50:25.997361 EDT | AverageAbsQYDiff            0.489085
2017-06-11 04:50:25.997796 EDT | AverageAction               0.998912
2017-06-11 04:50:25.998163 EDT | PolicyRegParamNorm        103.72
2017-06-11 04:50:25.998578 EDT | QFunRegParamNorm          134.571
2017-06-11 04:50:25.999010 EDT | -----------------------  -----------
2017-06-11 04:50:25.999522 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1177 | Training started
2017-06-11 04:50:43.193881 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1177 | Training finished
2017-06-11 04:50:43.195154 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1177 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 04:50:43.195439 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1177 | Collecting samples for evaluation
2017-06-11 04:50:58.524475 EDT | -----------------------  -----------
2017-06-11 04:50:58.524866 EDT | Epoch                    1177
2017-06-11 04:50:58.525143 EDT | Iteration                1177
2017-06-11 04:50:58.525410 EDT | AverageReturn            1909.54
2017-06-11 04:50:58.525792 EDT | StdReturn                1159.92
2017-06-11 04:50:58.526884 EDT | MaxReturn                3303.98
2017-06-11 04:50:58.528062 EDT | MinReturn                 586.321
2017-06-11 04:50:58.529220 EDT | AverageEsReturn           316.037
2017-06-11 04:50:58.530382 EDT | StdEsReturn               296.872
2017-06-11 04:50:58.531561 EDT | MaxEsReturn               981.822
2017-06-11 04:50:58.532728 EDT | MinEsReturn                10.417
2017-06-11 04:50:58.533902 EDT | AverageDiscountedReturn   242.791
2017-06-11 04:50:58.535136 EDT | AverageQLoss                2.06205
2017-06-11 04:50:58.536335 EDT | AveragePolicySurr         -28.533
2017-06-11 04:50:58.537518 EDT | AverageQ                   28.3118
2017-06-11 04:50:58.538737 EDT | AverageAbsQ                28.3278
2017-06-11 04:50:58.539909 EDT | AverageY                   28.3128
2017-06-11 04:50:58.541076 EDT | AverageAbsY                28.3178
2017-06-11 04:50:58.542253 EDT | AverageAbsQYDiff            0.491157
2017-06-11 04:50:58.543432 EDT | AverageAction               0.998575
2017-06-11 04:50:58.543696 EDT | PolicyRegParamNorm        103.737
2017-06-11 04:50:58.543950 EDT | QFunRegParamNorm          134.636
2017-06-11 04:50:58.544202 EDT | -----------------------  -----------
2017-06-11 04:50:58.544610 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1178 | Training started
2017-06-11 04:51:15.286376 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1178 | Training finished
2017-06-11 04:51:15.287463 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1178 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 04:51:15.287948 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1178 | Collecting samples for evaluation
2017-06-11 04:51:28.974713 EDT | -----------------------  -----------
2017-06-11 04:51:28.975976 EDT | Epoch                    1178
2017-06-11 04:51:28.976342 EDT | Iteration                1178
2017-06-11 04:51:28.976685 EDT | AverageReturn            1986.89
2017-06-11 04:51:28.977023 EDT | StdReturn                 828.182
2017-06-11 04:51:28.977357 EDT | MaxReturn                2798.22
2017-06-11 04:51:28.977690 EDT | MinReturn                 836.369
2017-06-11 04:51:28.978027 EDT | AverageEsReturn           291.593
2017-06-11 04:51:28.978381 EDT | StdEsReturn               249.307
2017-06-11 04:51:28.978712 EDT | MaxEsReturn               915.966
2017-06-11 04:51:28.979043 EDT | MinEsReturn                69.4817
2017-06-11 04:51:28.979370 EDT | AverageDiscountedReturn   229.516
2017-06-11 04:51:28.979701 EDT | AverageQLoss                1.95225
2017-06-11 04:51:28.980027 EDT | AveragePolicySurr         -28.4838
2017-06-11 04:51:28.980358 EDT | AverageQ                   28.276
2017-06-11 04:51:28.980720 EDT | AverageAbsQ                28.2899
2017-06-11 04:51:28.981046 EDT | AverageY                   28.2775
2017-06-11 04:51:28.981371 EDT | AverageAbsY                28.2833
2017-06-11 04:51:28.981708 EDT | AverageAbsQYDiff            0.471923
2017-06-11 04:51:28.982041 EDT | AverageAction               0.997646
2017-06-11 04:51:28.982367 EDT | PolicyRegParamNorm        103.823
2017-06-11 04:51:28.982689 EDT | QFunRegParamNorm          134.652
2017-06-11 04:51:28.983008 EDT | -----------------------  -----------
2017-06-11 04:51:28.983450 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1179 | Training started
2017-06-11 04:51:47.537875 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1179 | Training finished
2017-06-11 04:51:47.538770 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1179 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 04:51:47.539049 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1179 | Collecting samples for evaluation
2017-06-11 04:52:01.790676 EDT | -----------------------  -----------
2017-06-11 04:52:01.791435 EDT | Epoch                    1179
2017-06-11 04:52:01.791661 EDT | Iteration                1179
2017-06-11 04:52:01.791854 EDT | AverageReturn            1013.22
2017-06-11 04:52:01.792042 EDT | StdReturn                 268.514
2017-06-11 04:52:01.792278 EDT | MaxReturn                1604.76
2017-06-11 04:52:01.792459 EDT | MinReturn                 278.887
2017-06-11 04:52:01.792645 EDT | AverageEsReturn           774.716
2017-06-11 04:52:01.792805 EDT | StdEsReturn               608.595
2017-06-11 04:52:01.792962 EDT | MaxEsReturn              1576.49
2017-06-11 04:52:01.793118 EDT | MinEsReturn               102.814
2017-06-11 04:52:01.793280 EDT | AverageDiscountedReturn   218.658
2017-06-11 04:52:01.793503 EDT | AverageQLoss                1.94249
2017-06-11 04:52:01.793690 EDT | AveragePolicySurr         -28.5177
2017-06-11 04:52:01.793869 EDT | AverageQ                   28.3082
2017-06-11 04:52:01.794056 EDT | AverageAbsQ                28.3197
2017-06-11 04:52:01.794213 EDT | AverageY                   28.3117
2017-06-11 04:52:01.794376 EDT | AverageAbsY                28.3155
2017-06-11 04:52:01.794560 EDT | AverageAbsQYDiff            0.468894
2017-06-11 04:52:01.794743 EDT | AverageAction               0.998443
2017-06-11 04:52:01.794902 EDT | PolicyRegParamNorm        103.839
2017-06-11 04:52:01.795058 EDT | QFunRegParamNorm          134.698
2017-06-11 04:52:01.795902 EDT | -----------------------  -----------
2017-06-11 04:52:01.796204 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1180 | Training started
2017-06-11 04:52:19.708225 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1180 | Training finished
2017-06-11 04:52:19.708986 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1180 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 04:52:19.709178 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1180 | Collecting samples for evaluation
2017-06-11 04:52:34.715627 EDT | -----------------------  -----------
2017-06-11 04:52:34.716389 EDT | Epoch                    1180
2017-06-11 04:52:34.716574 EDT | Iteration                1180
2017-06-11 04:52:34.716769 EDT | AverageReturn            1168.78
2017-06-11 04:52:34.716927 EDT | StdReturn                 691.561
2017-06-11 04:52:34.717132 EDT | MaxReturn                2323.77
2017-06-11 04:52:34.717378 EDT | MinReturn                 268.987
2017-06-11 04:52:34.717533 EDT | AverageEsReturn           461.207
2017-06-11 04:52:34.717684 EDT | StdEsReturn               594.972
2017-06-11 04:52:34.717893 EDT | MaxEsReturn              1718.21
2017-06-11 04:52:34.718167 EDT | MinEsReturn                 8.84272
2017-06-11 04:52:34.718462 EDT | AverageDiscountedReturn   200.82
2017-06-11 04:52:34.718619 EDT | AverageQLoss                1.84358
2017-06-11 04:52:34.718790 EDT | AveragePolicySurr         -28.4352
2017-06-11 04:52:34.719035 EDT | AverageQ                   28.2396
2017-06-11 04:52:34.719556 EDT | AverageAbsQ                28.2516
2017-06-11 04:52:34.719825 EDT | AverageY                   28.2394
2017-06-11 04:52:34.719999 EDT | AverageAbsY                28.2429
2017-06-11 04:52:34.720153 EDT | AverageAbsQYDiff            0.46828
2017-06-11 04:52:34.720333 EDT | AverageAction               0.997991
2017-06-11 04:52:34.720499 EDT | PolicyRegParamNorm        103.875
2017-06-11 04:52:34.720693 EDT | QFunRegParamNorm          134.75
2017-06-11 04:52:34.720854 EDT | -----------------------  -----------
2017-06-11 04:52:34.721115 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1181 | Training started
2017-06-11 04:52:51.069557 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1181 | Training finished
2017-06-11 04:52:51.071006 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1181 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 04:52:51.071337 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1181 | Collecting samples for evaluation
2017-06-11 04:53:07.267601 EDT | -----------------------  ------------
2017-06-11 04:53:07.268657 EDT | Epoch                    1181
2017-06-11 04:53:07.269129 EDT | Iteration                1181
2017-06-11 04:53:07.269533 EDT | AverageReturn               5.92226
2017-06-11 04:53:07.269875 EDT | StdReturn                   0.0626906
2017-06-11 04:53:07.270200 EDT | MaxReturn                   6.10051
2017-06-11 04:53:07.270645 EDT | MinReturn                   5.78416
2017-06-11 04:53:07.270986 EDT | AverageEsReturn            22.6061
2017-06-11 04:53:07.271322 EDT | StdEsReturn                77.9207
2017-06-11 04:53:07.271664 EDT | MaxEsReturn               568
2017-06-11 04:53:07.271992 EDT | MinEsReturn                 5.51935
2017-06-11 04:53:07.272388 EDT | AverageDiscountedReturn     5.75854
2017-06-11 04:53:07.272769 EDT | AverageQLoss                2.12791
2017-06-11 04:53:07.273101 EDT | AveragePolicySurr         -28.4134
2017-06-11 04:53:07.273472 EDT | AverageQ                   28.2581
2017-06-11 04:53:07.273891 EDT | AverageAbsQ                28.2697
2017-06-11 04:53:07.274273 EDT | AverageY                   28.2591
2017-06-11 04:53:07.274698 EDT | AverageAbsY                28.263
2017-06-11 04:53:07.275093 EDT | AverageAbsQYDiff            0.499763
2017-06-11 04:53:07.275525 EDT | AverageAction               1
2017-06-11 04:53:07.275945 EDT | PolicyRegParamNorm        103.871
2017-06-11 04:53:07.276368 EDT | QFunRegParamNorm          134.845
2017-06-11 04:53:07.284361 EDT | -----------------------  ------------
2017-06-11 04:53:07.292216 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1182 | Training started
2017-06-11 04:53:23.694433 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1182 | Training finished
2017-06-11 04:53:23.695360 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1182 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 04:53:23.695737 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1182 | Collecting samples for evaluation
2017-06-11 04:53:38.978904 EDT | -----------------------  -----------
2017-06-11 04:53:39.029871 EDT | Epoch                    1182
2017-06-11 04:53:39.033492 EDT | Iteration                1182
2017-06-11 04:53:39.033784 EDT | AverageReturn               7.42805
2017-06-11 04:53:39.034042 EDT | StdReturn                   0.134217
2017-06-11 04:53:39.034292 EDT | MaxReturn                   7.68967
2017-06-11 04:53:39.034541 EDT | MinReturn                   6.05735
2017-06-11 04:53:39.034789 EDT | AverageEsReturn            27.9898
2017-06-11 04:53:39.035032 EDT | StdEsReturn                62.9141
2017-06-11 04:53:39.035273 EDT | MaxEsReturn               381.212
2017-06-11 04:53:39.035513 EDT | MinEsReturn                 5.74212
2017-06-11 04:53:39.035752 EDT | AverageDiscountedReturn     7.165
2017-06-11 04:53:39.035992 EDT | AverageQLoss                2.50054
2017-06-11 04:53:39.036232 EDT | AveragePolicySurr         -28.2725
2017-06-11 04:53:39.036470 EDT | AverageQ                   28.0986
2017-06-11 04:53:39.036710 EDT | AverageAbsQ                28.1129
2017-06-11 04:53:39.036948 EDT | AverageY                   28.0982
2017-06-11 04:53:39.037196 EDT | AverageAbsY                28.1033
2017-06-11 04:53:39.037437 EDT | AverageAbsQYDiff            0.544825
2017-06-11 04:53:39.037676 EDT | AverageAction               1
2017-06-11 04:53:39.038944 EDT | PolicyRegParamNorm        103.91
2017-06-11 04:53:39.039197 EDT | QFunRegParamNorm          134.893
2017-06-11 04:53:39.039444 EDT | -----------------------  -----------
2017-06-11 04:53:39.039880 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1183 | Training started
2017-06-11 04:53:56.702903 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1183 | Training finished
2017-06-11 04:53:56.703206 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1183 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 04:53:56.703423 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1183 | Collecting samples for evaluation
2017-06-11 04:54:10.951870 EDT | -----------------------  -----------
2017-06-11 04:54:10.952834 EDT | Epoch                    1183
2017-06-11 04:54:10.953041 EDT | Iteration                1183
2017-06-11 04:54:10.953305 EDT | AverageReturn             179.36
2017-06-11 04:54:10.953469 EDT | StdReturn                   3.36682
2017-06-11 04:54:10.953624 EDT | MaxReturn                 188.341
2017-06-11 04:54:10.953813 EDT | MinReturn                 172.152
2017-06-11 04:54:10.954003 EDT | AverageEsReturn           144.295
2017-06-11 04:54:10.954180 EDT | StdEsReturn               133.066
2017-06-11 04:54:10.954337 EDT | MaxEsReturn               532.247
2017-06-11 04:54:10.954493 EDT | MinEsReturn                 6.90808
2017-06-11 04:54:10.954648 EDT | AverageDiscountedReturn   114.19
2017-06-11 04:54:10.954803 EDT | AverageQLoss                2.10648
2017-06-11 04:54:10.954959 EDT | AveragePolicySurr         -28.339
2017-06-11 04:54:10.955113 EDT | AverageQ                   28.1192
2017-06-11 04:54:10.955267 EDT | AverageAbsQ                28.1316
2017-06-11 04:54:10.955487 EDT | AverageY                   28.1211
2017-06-11 04:54:10.955645 EDT | AverageAbsY                28.125
2017-06-11 04:54:10.955801 EDT | AverageAbsQYDiff            0.500083
2017-06-11 04:54:10.955956 EDT | AverageAction               0.998383
2017-06-11 04:54:10.956131 EDT | PolicyRegParamNorm        103.899
2017-06-11 04:54:10.956289 EDT | QFunRegParamNorm          134.944
2017-06-11 04:54:10.956444 EDT | -----------------------  -----------
2017-06-11 04:54:10.956684 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1184 | Training started
2017-06-11 04:54:29.545672 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1184 | Training finished
2017-06-11 04:54:29.546692 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1184 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 04:54:29.547092 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1184 | Collecting samples for evaluation
2017-06-11 04:54:43.749552 EDT | -----------------------  -----------
2017-06-11 04:54:43.750463 EDT | Epoch                    1184
2017-06-11 04:54:43.750828 EDT | Iteration                1184
2017-06-11 04:54:43.751174 EDT | AverageReturn             185.276
2017-06-11 04:54:43.751519 EDT | StdReturn                   3.51972
2017-06-11 04:54:43.751860 EDT | MaxReturn                 196.172
2017-06-11 04:54:43.752196 EDT | MinReturn                 178.701
2017-06-11 04:54:43.752528 EDT | AverageEsReturn           209.745
2017-06-11 04:54:43.752861 EDT | StdEsReturn               145.771
2017-06-11 04:54:43.753191 EDT | MaxEsReturn               452.581
2017-06-11 04:54:43.753523 EDT | MinEsReturn                 5.25953
2017-06-11 04:54:43.753870 EDT | AverageDiscountedReturn   116.246
2017-06-11 04:54:43.754207 EDT | AverageQLoss                1.71144
2017-06-11 04:54:43.754541 EDT | AveragePolicySurr         -28.288
2017-06-11 04:54:43.754870 EDT | AverageQ                   28.0695
2017-06-11 04:54:43.755200 EDT | AverageAbsQ                28.0835
2017-06-11 04:54:43.755537 EDT | AverageY                   28.0711
2017-06-11 04:54:43.757128 EDT | AverageAbsY                28.0765
2017-06-11 04:54:43.759112 EDT | AverageAbsQYDiff            0.468091
2017-06-11 04:54:43.759784 EDT | AverageAction               0.998973
2017-06-11 04:54:43.760408 EDT | PolicyRegParamNorm        103.884
2017-06-11 04:54:43.762332 EDT | QFunRegParamNorm          134.971
2017-06-11 04:54:43.763005 EDT | -----------------------  -----------
2017-06-11 04:54:43.763767 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1185 | Training started
2017-06-11 04:55:00.655198 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1185 | Training finished
2017-06-11 04:55:00.656219 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1185 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 04:55:00.656614 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1185 | Collecting samples for evaluation
2017-06-11 04:55:15.803899 EDT | -----------------------  -----------
2017-06-11 04:55:15.805971 EDT | Epoch                    1185
2017-06-11 04:55:15.806785 EDT | Iteration                1185
2017-06-11 04:55:15.807364 EDT | AverageReturn            1429.87
2017-06-11 04:55:15.807787 EDT | StdReturn                 753.679
2017-06-11 04:55:15.808135 EDT | MaxReturn                2516.46
2017-06-11 04:55:15.808484 EDT | MinReturn                 192.565
2017-06-11 04:55:15.808996 EDT | AverageEsReturn           168.56
2017-06-11 04:55:15.809345 EDT | StdEsReturn               128.228
2017-06-11 04:55:15.809678 EDT | MaxEsReturn               536.727
2017-06-11 04:55:15.809979 EDT | MinEsReturn                71.7137
2017-06-11 04:55:15.810329 EDT | AverageDiscountedReturn   208.254
2017-06-11 04:55:15.810663 EDT | AverageQLoss                2.08318
2017-06-11 04:55:15.810999 EDT | AveragePolicySurr         -28.3086
2017-06-11 04:55:15.811324 EDT | AverageQ                   28.0946
2017-06-11 04:55:15.811732 EDT | AverageAbsQ                28.1061
2017-06-11 04:55:15.812077 EDT | AverageY                   28.0955
2017-06-11 04:55:15.812607 EDT | AverageAbsY                28.0988
2017-06-11 04:55:15.812948 EDT | AverageAbsQYDiff            0.491028
2017-06-11 04:55:15.813281 EDT | AverageAction               0.998618
2017-06-11 04:55:15.813607 EDT | PolicyRegParamNorm        103.961
2017-06-11 04:55:15.813815 EDT | QFunRegParamNorm          135.032
2017-06-11 04:55:15.814000 EDT | -----------------------  -----------
2017-06-11 04:55:15.814464 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1186 | Training started
2017-06-11 04:55:33.214383 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1186 | Training finished
2017-06-11 04:55:33.221481 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1186 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 04:55:33.222323 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1186 | Collecting samples for evaluation
2017-06-11 04:55:49.255446 EDT | -----------------------  -----------
2017-06-11 04:55:49.255932 EDT | Epoch                    1186
2017-06-11 04:55:49.256295 EDT | Iteration                1186
2017-06-11 04:55:49.256657 EDT | AverageReturn            2365.36
2017-06-11 04:55:49.257011 EDT | StdReturn                 833.657
2017-06-11 04:55:49.257368 EDT | MaxReturn                2929.8
2017-06-11 04:55:49.257841 EDT | MinReturn                 184.894
2017-06-11 04:55:49.258294 EDT | AverageEsReturn           319.057
2017-06-11 04:55:49.258760 EDT | StdEsReturn               248.177
2017-06-11 04:55:49.259594 EDT | MaxEsReturn               788.922
2017-06-11 04:55:49.260678 EDT | MinEsReturn                82.3167
2017-06-11 04:55:49.264124 EDT | AverageDiscountedReturn   223.382
2017-06-11 04:55:49.264590 EDT | AverageQLoss                1.94201
2017-06-11 04:55:49.265045 EDT | AveragePolicySurr         -28.2759
2017-06-11 04:55:49.265498 EDT | AverageQ                   28.0727
2017-06-11 04:55:49.265959 EDT | AverageAbsQ                28.086
2017-06-11 04:55:49.266412 EDT | AverageY                   28.0742
2017-06-11 04:55:49.266861 EDT | AverageAbsY                28.08
2017-06-11 04:55:49.267311 EDT | AverageAbsQYDiff            0.469065
2017-06-11 04:55:49.267761 EDT | AverageAction               0.998401
2017-06-11 04:55:49.268211 EDT | PolicyRegParamNorm        104.008
2017-06-11 04:55:49.268657 EDT | QFunRegParamNorm          135.081
2017-06-11 04:55:49.273794 EDT | -----------------------  -----------
2017-06-11 04:55:49.274449 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1187 | Training started
2017-06-11 04:56:06.606479 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1187 | Training finished
2017-06-11 04:56:06.607481 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1187 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 04:56:06.608009 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1187 | Collecting samples for evaluation
2017-06-11 04:56:21.676305 EDT | -----------------------  -----------
2017-06-11 04:56:21.677437 EDT | Epoch                    1187
2017-06-11 04:56:21.678103 EDT | Iteration                1187
2017-06-11 04:56:21.678909 EDT | AverageReturn            1075.95
2017-06-11 04:56:21.679375 EDT | StdReturn                1242.52
2017-06-11 04:56:21.679830 EDT | MaxReturn                2928.54
2017-06-11 04:56:21.681583 EDT | MinReturn                  87.4368
2017-06-11 04:56:21.682055 EDT | AverageEsReturn           129.257
2017-06-11 04:56:21.682508 EDT | StdEsReturn               111.447
2017-06-11 04:56:21.682958 EDT | MaxEsReturn               446.804
2017-06-11 04:56:21.683409 EDT | MinEsReturn                17.082
2017-06-11 04:56:21.683855 EDT | AverageDiscountedReturn   139.247
2017-06-11 04:56:21.684303 EDT | AverageQLoss                2.07023
2017-06-11 04:56:21.684748 EDT | AveragePolicySurr         -28.2544
2017-06-11 04:56:21.685289 EDT | AverageQ                   28.0501
2017-06-11 04:56:21.685760 EDT | AverageAbsQ                28.0657
2017-06-11 04:56:21.686218 EDT | AverageY                   28.0522
2017-06-11 04:56:21.695954 EDT | AverageAbsY                28.0573
2017-06-11 04:56:21.696427 EDT | AverageAbsQYDiff            0.492471
2017-06-11 04:56:21.696880 EDT | AverageAction               0.998674
2017-06-11 04:56:21.697327 EDT | PolicyRegParamNorm        104.082
2017-06-11 04:56:21.697780 EDT | QFunRegParamNorm          135.115
2017-06-11 04:56:21.699402 EDT | -----------------------  -----------
2017-06-11 04:56:21.701282 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1188 | Training started
2017-06-11 04:56:39.273635 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1188 | Training finished
2017-06-11 04:56:39.274567 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1188 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 04:56:39.274887 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1188 | Collecting samples for evaluation
2017-06-11 04:56:53.853019 EDT | -----------------------  -----------
2017-06-11 04:56:53.854155 EDT | Epoch                    1188
2017-06-11 04:56:53.854561 EDT | Iteration                1188
2017-06-11 04:56:53.855066 EDT | AverageReturn            2160.59
2017-06-11 04:56:53.855501 EDT | StdReturn                1126.73
2017-06-11 04:56:53.855970 EDT | MaxReturn                3313.59
2017-06-11 04:56:53.856423 EDT | MinReturn                  97.5628
2017-06-11 04:56:53.856922 EDT | AverageEsReturn           214.264
2017-06-11 04:56:53.857407 EDT | StdEsReturn               259.48
2017-06-11 04:56:53.858425 EDT | MaxEsReturn               847.766
2017-06-11 04:56:53.859167 EDT | MinEsReturn                 7.69593
2017-06-11 04:56:53.859688 EDT | AverageDiscountedReturn   236.682
2017-06-11 04:56:53.860073 EDT | AverageQLoss                2.00292
2017-06-11 04:56:53.860562 EDT | AveragePolicySurr         -28.177
2017-06-11 04:56:53.860943 EDT | AverageQ                   27.9732
2017-06-11 04:56:53.861674 EDT | AverageAbsQ                27.9891
2017-06-11 04:56:53.862081 EDT | AverageY                   27.9747
2017-06-11 04:56:53.862577 EDT | AverageAbsY                27.9813
2017-06-11 04:56:53.862962 EDT | AverageAbsQYDiff            0.499589
2017-06-11 04:56:53.863567 EDT | AverageAction               0.998463
2017-06-11 04:56:53.863957 EDT | PolicyRegParamNorm        104.106
2017-06-11 04:56:53.864417 EDT | QFunRegParamNorm          135.198
2017-06-11 04:56:53.864821 EDT | -----------------------  -----------
2017-06-11 04:56:53.865400 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1189 | Training started
2017-06-11 04:57:11.679753 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1189 | Training finished
2017-06-11 04:57:11.680512 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1189 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 04:57:11.680720 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1189 | Collecting samples for evaluation
2017-06-11 04:57:26.137064 EDT | -----------------------  -----------
2017-06-11 04:57:26.137804 EDT | Epoch                    1189
2017-06-11 04:57:26.138303 EDT | Iteration                1189
2017-06-11 04:57:26.138753 EDT | AverageReturn            2041.39
2017-06-11 04:57:26.139166 EDT | StdReturn                1190.77
2017-06-11 04:57:26.139616 EDT | MaxReturn                3439.52
2017-06-11 04:57:26.140043 EDT | MinReturn                 716.887
2017-06-11 04:57:26.140498 EDT | AverageEsReturn           296.585
2017-06-11 04:57:26.140952 EDT | StdEsReturn               273.178
2017-06-11 04:57:26.141412 EDT | MaxEsReturn               703.781
2017-06-11 04:57:26.141866 EDT | MinEsReturn                50.9557
2017-06-11 04:57:26.142192 EDT | AverageDiscountedReturn   248.7
2017-06-11 04:57:26.142589 EDT | AverageQLoss                1.95126
2017-06-11 04:57:26.142940 EDT | AveragePolicySurr         -28.2204
2017-06-11 04:57:26.143253 EDT | AverageQ                   28.0226
2017-06-11 04:57:26.143647 EDT | AverageAbsQ                28.0341
2017-06-11 04:57:26.144015 EDT | AverageY                   28.0224
2017-06-11 04:57:26.144418 EDT | AverageAbsY                28.0271
2017-06-11 04:57:26.144839 EDT | AverageAbsQYDiff            0.480138
2017-06-11 04:57:26.145271 EDT | AverageAction               0.99855
2017-06-11 04:57:26.145752 EDT | PolicyRegParamNorm        104.179
2017-06-11 04:57:26.146162 EDT | QFunRegParamNorm          135.273
2017-06-11 04:57:26.146631 EDT | -----------------------  -----------
2017-06-11 04:57:26.147226 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1190 | Training started
2017-06-11 04:57:42.761674 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1190 | Training finished
2017-06-11 04:57:42.780453 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1190 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 04:57:42.780877 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1190 | Collecting samples for evaluation
2017-06-11 04:57:58.117599 EDT | -----------------------  -----------
2017-06-11 04:57:58.118536 EDT | Epoch                    1190
2017-06-11 04:57:58.118909 EDT | Iteration                1190
2017-06-11 04:57:58.119273 EDT | AverageReturn            2628.21
2017-06-11 04:57:58.119622 EDT | StdReturn                 659.071
2017-06-11 04:57:58.119972 EDT | MaxReturn                3043.7
2017-06-11 04:57:58.120324 EDT | MinReturn                1302.51
2017-06-11 04:57:58.120673 EDT | AverageEsReturn           296.328
2017-06-11 04:57:58.121020 EDT | StdEsReturn               272.028
2017-06-11 04:57:58.121367 EDT | MaxEsReturn               945.682
2017-06-11 04:57:58.121723 EDT | MinEsReturn                64.3342
2017-06-11 04:57:58.121996 EDT | AverageDiscountedReturn   241.522
2017-06-11 04:57:58.122250 EDT | AverageQLoss                1.6871
2017-06-11 04:57:58.122502 EDT | AveragePolicySurr         -28.1527
2017-06-11 04:57:58.122752 EDT | AverageQ                   27.9705
2017-06-11 04:57:58.123009 EDT | AverageAbsQ                27.9883
2017-06-11 04:57:58.123257 EDT | AverageY                   27.9722
2017-06-11 04:57:58.123505 EDT | AverageAbsY                27.9783
2017-06-11 04:57:58.123752 EDT | AverageAbsQYDiff            0.470644
2017-06-11 04:57:58.123997 EDT | AverageAction               0.998492
2017-06-11 04:57:58.124242 EDT | PolicyRegParamNorm        104.216
2017-06-11 04:57:58.124487 EDT | QFunRegParamNorm          135.269
2017-06-11 04:57:58.124734 EDT | -----------------------  -----------
2017-06-11 04:57:58.125125 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1191 | Training started
2017-06-11 04:58:15.042256 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1191 | Training finished
2017-06-11 04:58:15.043772 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1191 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 04:58:15.044205 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1191 | Collecting samples for evaluation
2017-06-11 04:58:30.865625 EDT | -----------------------  -----------
2017-06-11 04:58:30.880749 EDT | Epoch                    1191
2017-06-11 04:58:30.881105 EDT | Iteration                1191
2017-06-11 04:58:30.881363 EDT | AverageReturn            2516.48
2017-06-11 04:58:30.881616 EDT | StdReturn                 130.825
2017-06-11 04:58:30.881877 EDT | MaxReturn                2649.46
2017-06-11 04:58:30.882125 EDT | MinReturn                2178.03
2017-06-11 04:58:30.882370 EDT | AverageEsReturn           441.329
2017-06-11 04:58:30.882619 EDT | StdEsReturn               398.832
2017-06-11 04:58:30.882862 EDT | MaxEsReturn               986.497
2017-06-11 04:58:30.883105 EDT | MinEsReturn                43.4685
2017-06-11 04:58:30.883347 EDT | AverageDiscountedReturn   215.355
2017-06-11 04:58:30.883590 EDT | AverageQLoss                2.00657
2017-06-11 04:58:30.883832 EDT | AveragePolicySurr         -28.2438
2017-06-11 04:58:30.884073 EDT | AverageQ                   28.0378
2017-06-11 04:58:30.884315 EDT | AverageAbsQ                28.0514
2017-06-11 04:58:30.884557 EDT | AverageY                   28.0383
2017-06-11 04:58:30.884798 EDT | AverageAbsY                28.0426
2017-06-11 04:58:30.885038 EDT | AverageAbsQYDiff            0.485905
2017-06-11 04:58:30.885279 EDT | AverageAction               0.998458
2017-06-11 04:58:30.885540 EDT | PolicyRegParamNorm        104.214
2017-06-11 04:58:30.918007 EDT | QFunRegParamNorm          135.307
2017-06-11 04:58:30.918292 EDT | -----------------------  -----------
2017-06-11 04:58:30.918730 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1192 | Training started
2017-06-11 04:58:49.281261 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1192 | Training finished
2017-06-11 04:58:49.281822 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1192 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 04:58:49.282246 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1192 | Collecting samples for evaluation
2017-06-11 04:59:03.351935 EDT | -----------------------  -----------
2017-06-11 04:59:03.359768 EDT | Epoch                    1192
2017-06-11 04:59:03.360094 EDT | Iteration                1192
2017-06-11 04:59:03.360390 EDT | AverageReturn            2514.75
2017-06-11 04:59:03.360679 EDT | StdReturn                 385.762
2017-06-11 04:59:03.360968 EDT | MaxReturn                2729.81
2017-06-11 04:59:03.361255 EDT | MinReturn                1324.77
2017-06-11 04:59:03.361546 EDT | AverageEsReturn           541.043
2017-06-11 04:59:03.361844 EDT | StdEsReturn               486.712
2017-06-11 04:59:03.362128 EDT | MaxEsReturn              1598.86
2017-06-11 04:59:03.362415 EDT | MinEsReturn                 7.21837
2017-06-11 04:59:03.362698 EDT | AverageDiscountedReturn   223.973
2017-06-11 04:59:03.362979 EDT | AverageQLoss                2.14979
2017-06-11 04:59:03.363262 EDT | AveragePolicySurr         -28.2129
2017-06-11 04:59:03.363544 EDT | AverageQ                   27.9966
2017-06-11 04:59:03.363827 EDT | AverageAbsQ                28.0101
2017-06-11 04:59:03.364111 EDT | AverageY                   27.9983
2017-06-11 04:59:03.364396 EDT | AverageAbsY                28.003
2017-06-11 04:59:03.364679 EDT | AverageAbsQYDiff            0.501475
2017-06-11 04:59:03.364962 EDT | AverageAction               0.99848
2017-06-11 04:59:03.365245 EDT | PolicyRegParamNorm        104.299
2017-06-11 04:59:03.365526 EDT | QFunRegParamNorm          135.39
2017-06-11 04:59:03.365824 EDT | -----------------------  -----------
2017-06-11 04:59:03.366259 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1193 | Training started
2017-06-11 04:59:21.801179 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1193 | Training finished
2017-06-11 04:59:21.801936 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1193 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 04:59:21.802129 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1193 | Collecting samples for evaluation
2017-06-11 04:59:36.515019 EDT | -----------------------  -----------
2017-06-11 04:59:36.515773 EDT | Epoch                    1193
2017-06-11 04:59:36.516017 EDT | Iteration                1193
2017-06-11 04:59:36.516299 EDT | AverageReturn            2607.1
2017-06-11 04:59:36.516500 EDT | StdReturn                 628.55
2017-06-11 04:59:36.516758 EDT | MaxReturn                3036.15
2017-06-11 04:59:36.516958 EDT | MinReturn                1155.2
2017-06-11 04:59:36.517214 EDT | AverageEsReturn           329.345
2017-06-11 04:59:36.517410 EDT | StdEsReturn               228.965
2017-06-11 04:59:36.517708 EDT | MaxEsReturn               665.789
2017-06-11 04:59:36.517905 EDT | MinEsReturn                34.4633
2017-06-11 04:59:36.518101 EDT | AverageDiscountedReturn   239.23
2017-06-11 04:59:36.518331 EDT | AverageQLoss                2.08701
2017-06-11 04:59:36.518525 EDT | AveragePolicySurr         -28.1634
2017-06-11 04:59:36.518721 EDT | AverageQ                   27.9425
2017-06-11 04:59:36.518981 EDT | AverageAbsQ                27.9556
2017-06-11 04:59:36.519174 EDT | AverageY                   27.9436
2017-06-11 04:59:36.519379 EDT | AverageAbsY                27.9469
2017-06-11 04:59:36.519571 EDT | AverageAbsQYDiff            0.49257
2017-06-11 04:59:36.519762 EDT | AverageAction               0.998805
2017-06-11 04:59:36.520716 EDT | PolicyRegParamNorm        104.333
2017-06-11 04:59:36.520922 EDT | QFunRegParamNorm          135.46
2017-06-11 04:59:36.521184 EDT | -----------------------  -----------
2017-06-11 04:59:36.521486 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1194 | Training started
2017-06-11 04:59:54.684321 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1194 | Training finished
2017-06-11 04:59:54.685242 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1194 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 04:59:54.685447 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1194 | Collecting samples for evaluation
2017-06-11 05:00:09.942936 EDT | -----------------------  -----------
2017-06-11 05:00:09.943830 EDT | Epoch                    1194
2017-06-11 05:00:09.944165 EDT | Iteration                1194
2017-06-11 05:00:09.944516 EDT | AverageReturn            1337
2017-06-11 05:00:09.944847 EDT | StdReturn                 983.658
2017-06-11 05:00:09.945171 EDT | MaxReturn                3432.51
2017-06-11 05:00:09.945507 EDT | MinReturn                 627.883
2017-06-11 05:00:09.950050 EDT | AverageEsReturn           406.023
2017-06-11 05:00:09.950361 EDT | StdEsReturn               332.501
2017-06-11 05:00:09.950696 EDT | MaxEsReturn               989.853
2017-06-11 05:00:09.950999 EDT | MinEsReturn                25.2042
2017-06-11 05:00:09.951308 EDT | AverageDiscountedReturn   241.757
2017-06-11 05:00:09.951573 EDT | AverageQLoss                2.03158
2017-06-11 05:00:09.951839 EDT | AveragePolicySurr         -28.2233
2017-06-11 05:00:09.952087 EDT | AverageQ                   28.0172
2017-06-11 05:00:09.952332 EDT | AverageAbsQ                28.0321
2017-06-11 05:00:09.952576 EDT | AverageY                   28.018
2017-06-11 05:00:09.952816 EDT | AverageAbsY                28.0224
2017-06-11 05:00:09.953056 EDT | AverageAbsQYDiff            0.482468
2017-06-11 05:00:09.953299 EDT | AverageAction               0.998865
2017-06-11 05:00:09.953537 EDT | PolicyRegParamNorm        104.366
2017-06-11 05:00:09.953791 EDT | QFunRegParamNorm          135.496
2017-06-11 05:00:09.954036 EDT | -----------------------  -----------
2017-06-11 05:00:09.954476 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1195 | Training started
2017-06-11 05:00:28.374962 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1195 | Training finished
2017-06-11 05:00:28.375464 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1195 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 05:00:28.375835 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1195 | Collecting samples for evaluation
2017-06-11 05:00:43.232329 EDT | -----------------------  -----------
2017-06-11 05:00:43.233048 EDT | Epoch                    1195
2017-06-11 05:00:43.233324 EDT | Iteration                1195
2017-06-11 05:00:43.233597 EDT | AverageReturn            1816.18
2017-06-11 05:00:43.233900 EDT | StdReturn                 904.471
2017-06-11 05:00:43.234200 EDT | MaxReturn                3099.54
2017-06-11 05:00:43.234502 EDT | MinReturn                 627.049
2017-06-11 05:00:43.234781 EDT | AverageEsReturn           403.3
2017-06-11 05:00:43.234978 EDT | StdEsReturn               172.034
2017-06-11 05:00:43.235168 EDT | MaxEsReturn               645.233
2017-06-11 05:00:43.235444 EDT | MinEsReturn                93.431
2017-06-11 05:00:43.235632 EDT | AverageDiscountedReturn   230.622
2017-06-11 05:00:43.235929 EDT | AverageQLoss                1.72371
2017-06-11 05:00:43.236129 EDT | AveragePolicySurr         -28.1985
2017-06-11 05:00:43.236294 EDT | AverageQ                   27.995
2017-06-11 05:00:43.236464 EDT | AverageAbsQ                28.0119
2017-06-11 05:00:43.236614 EDT | AverageY                   27.9963
2017-06-11 05:00:43.236796 EDT | AverageAbsY                28.0014
2017-06-11 05:00:43.236962 EDT | AverageAbsQYDiff            0.448227
2017-06-11 05:00:43.237120 EDT | AverageAction               0.998781
2017-06-11 05:00:43.237275 EDT | PolicyRegParamNorm        104.438
2017-06-11 05:00:43.237430 EDT | QFunRegParamNorm          135.55
2017-06-11 05:00:43.237616 EDT | -----------------------  -----------
2017-06-11 05:00:43.237913 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1196 | Training started
2017-06-11 05:01:03.208983 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1196 | Training finished
2017-06-11 05:01:03.210160 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1196 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 05:01:03.210554 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1196 | Collecting samples for evaluation
2017-06-11 05:01:18.315626 EDT | -----------------------  -----------
2017-06-11 05:01:18.316844 EDT | Epoch                    1196
2017-06-11 05:01:18.317349 EDT | Iteration                1196
2017-06-11 05:01:18.317831 EDT | AverageReturn            2066.06
2017-06-11 05:01:18.318289 EDT | StdReturn                 861.718
2017-06-11 05:01:18.318748 EDT | MaxReturn                2775.02
2017-06-11 05:01:18.319231 EDT | MinReturn                 196.524
2017-06-11 05:01:18.319709 EDT | AverageEsReturn           347.485
2017-06-11 05:01:18.320185 EDT | StdEsReturn               198.504
2017-06-11 05:01:18.320660 EDT | MaxEsReturn               637.582
2017-06-11 05:01:18.321134 EDT | MinEsReturn                36.6072
2017-06-11 05:01:18.321608 EDT | AverageDiscountedReturn   216.748
2017-06-11 05:01:18.322099 EDT | AverageQLoss                1.93903
2017-06-11 05:01:18.322574 EDT | AveragePolicySurr         -28.1624
2017-06-11 05:01:18.323022 EDT | AverageQ                   27.9718
2017-06-11 05:01:18.323500 EDT | AverageAbsQ                27.9866
2017-06-11 05:01:18.323978 EDT | AverageY                   27.9736
2017-06-11 05:01:18.324460 EDT | AverageAbsY                27.978
2017-06-11 05:01:18.327812 EDT | AverageAbsQYDiff            0.464458
2017-06-11 05:01:18.328743 EDT | AverageAction               0.998452
2017-06-11 05:01:18.329662 EDT | PolicyRegParamNorm        104.521
2017-06-11 05:01:18.330590 EDT | QFunRegParamNorm          135.578
2017-06-11 05:01:18.330983 EDT | -----------------------  -----------
2017-06-11 05:01:18.331548 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1197 | Training started
2017-06-11 05:01:38.593476 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1197 | Training finished
2017-06-11 05:01:38.621803 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1197 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 05:01:38.622904 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1197 | Collecting samples for evaluation
2017-06-11 05:01:53.619496 EDT | -----------------------  -----------
2017-06-11 05:01:53.620458 EDT | Epoch                    1197
2017-06-11 05:01:53.620848 EDT | Iteration                1197
2017-06-11 05:01:53.621216 EDT | AverageReturn            1782.37
2017-06-11 05:01:53.621583 EDT | StdReturn                 896.627
2017-06-11 05:01:53.621959 EDT | MaxReturn                3219.54
2017-06-11 05:01:53.622318 EDT | MinReturn                 479.973
2017-06-11 05:01:53.622673 EDT | AverageEsReturn           295.215
2017-06-11 05:01:53.623028 EDT | StdEsReturn               144.341
2017-06-11 05:01:53.623385 EDT | MaxEsReturn               623.834
2017-06-11 05:01:53.623742 EDT | MinEsReturn                87.8294
2017-06-11 05:01:53.624098 EDT | AverageDiscountedReturn   236.887
2017-06-11 05:01:53.624501 EDT | AverageQLoss                1.55355
2017-06-11 05:01:53.624870 EDT | AveragePolicySurr         -28.1159
2017-06-11 05:01:53.625368 EDT | AverageQ                   27.9171
2017-06-11 05:01:53.625824 EDT | AverageAbsQ                27.9298
2017-06-11 05:01:53.626287 EDT | AverageY                   27.918
2017-06-11 05:01:53.637918 EDT | AverageAbsY                27.922
2017-06-11 05:01:53.638363 EDT | AverageAbsQYDiff            0.442468
2017-06-11 05:01:53.638717 EDT | AverageAction               0.99915
2017-06-11 05:01:53.639066 EDT | PolicyRegParamNorm        104.535
2017-06-11 05:01:53.639414 EDT | QFunRegParamNorm          135.592
2017-06-11 05:01:53.639760 EDT | -----------------------  -----------
2017-06-11 05:01:53.640317 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1198 | Training started
2017-06-11 05:02:12.293731 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1198 | Training finished
2017-06-11 05:02:12.305793 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1198 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 05:02:12.306388 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1198 | Collecting samples for evaluation
2017-06-11 05:02:27.550343 EDT | -----------------------  -----------
2017-06-11 05:02:27.553179 EDT | Epoch                    1198
2017-06-11 05:02:27.554112 EDT | Iteration                1198
2017-06-11 05:02:27.555033 EDT | AverageReturn            1899.39
2017-06-11 05:02:27.555956 EDT | StdReturn                1000.4
2017-06-11 05:02:27.556874 EDT | MaxReturn                3503.12
2017-06-11 05:02:27.557807 EDT | MinReturn                 711.622
2017-06-11 05:02:27.558736 EDT | AverageEsReturn           403.224
2017-06-11 05:02:27.559656 EDT | StdEsReturn               283.539
2017-06-11 05:02:27.560581 EDT | MaxEsReturn               988.949
2017-06-11 05:02:27.561507 EDT | MinEsReturn                25.4924
2017-06-11 05:02:27.562687 EDT | AverageDiscountedReturn   249.779
2017-06-11 05:02:27.566083 EDT | AverageQLoss                1.74234
2017-06-11 05:02:27.566574 EDT | AveragePolicySurr         -28.0882
2017-06-11 05:02:27.567034 EDT | AverageQ                   27.9078
2017-06-11 05:02:27.567501 EDT | AverageAbsQ                27.9202
2017-06-11 05:02:27.567955 EDT | AverageY                   27.9094
2017-06-11 05:02:27.568406 EDT | AverageAbsY                27.9142
2017-06-11 05:02:27.571395 EDT | AverageAbsQYDiff            0.453869
2017-06-11 05:02:27.571885 EDT | AverageAction               0.999164
2017-06-11 05:02:27.572338 EDT | PolicyRegParamNorm        104.557
2017-06-11 05:02:27.572787 EDT | QFunRegParamNorm          135.597
2017-06-11 05:02:27.573236 EDT | -----------------------  -----------
2017-06-11 05:02:27.575221 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1199 | Training started
2017-06-11 05:02:46.126184 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1199 | Training finished
2017-06-11 05:02:46.140392 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1199 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 05:02:46.141572 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1199 | Collecting samples for evaluation
2017-06-11 05:03:02.061008 EDT | -----------------------  -----------
2017-06-11 05:03:02.061882 EDT | Epoch                    1199
2017-06-11 05:03:02.062216 EDT | Iteration                1199
2017-06-11 05:03:02.062512 EDT | AverageReturn             912.336
2017-06-11 05:03:02.062807 EDT | StdReturn                 534.818
2017-06-11 05:03:02.063100 EDT | MaxReturn                3131.4
2017-06-11 05:03:02.063390 EDT | MinReturn                 291.506
2017-06-11 05:03:02.063678 EDT | AverageEsReturn           411.439
2017-06-11 05:03:02.063979 EDT | StdEsReturn               224.685
2017-06-11 05:03:02.064270 EDT | MaxEsReturn               596.634
2017-06-11 05:03:02.064558 EDT | MinEsReturn                25.3168
2017-06-11 05:03:02.064824 EDT | AverageDiscountedReturn   213.335
2017-06-11 05:03:02.065091 EDT | AverageQLoss                1.9151
2017-06-11 05:03:02.065468 EDT | AveragePolicySurr         -28.0754
2017-06-11 05:03:02.065794 EDT | AverageQ                   27.8988
2017-06-11 05:03:02.066101 EDT | AverageAbsQ                27.9153
2017-06-11 05:03:02.066485 EDT | AverageY                   27.8998
2017-06-11 05:03:02.066784 EDT | AverageAbsY                27.9047
2017-06-11 05:03:02.067086 EDT | AverageAbsQYDiff            0.470546
2017-06-11 05:03:02.067470 EDT | AverageAction               0.998911
2017-06-11 05:03:02.067768 EDT | PolicyRegParamNorm        104.558
2017-06-11 05:03:02.068060 EDT | QFunRegParamNorm          135.669
2017-06-11 05:03:02.068438 EDT | -----------------------  -----------
2017-06-11 05:03:02.069226 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1200 | Training started
2017-06-11 05:03:18.806267 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1200 | Training finished
2017-06-11 05:03:18.808993 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1200 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 05:03:18.809307 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1200 | Collecting samples for evaluation
2017-06-11 05:03:32.723172 EDT | -----------------------  -----------
2017-06-11 05:03:32.724177 EDT | Epoch                    1200
2017-06-11 05:03:32.724979 EDT | Iteration                1200
2017-06-11 05:03:32.725601 EDT | AverageReturn             402.491
2017-06-11 05:03:32.725987 EDT | StdReturn                 490.483
2017-06-11 05:03:32.726383 EDT | MaxReturn                2381.43
2017-06-11 05:03:32.726788 EDT | MinReturn                 189.596
2017-06-11 05:03:32.727144 EDT | AverageEsReturn           313.061
2017-06-11 05:03:32.727548 EDT | StdEsReturn               285.078
2017-06-11 05:03:32.727965 EDT | MaxEsReturn              1021.12
2017-06-11 05:03:32.728386 EDT | MinEsReturn                 7.42987
2017-06-11 05:03:32.728764 EDT | AverageDiscountedReturn   142.324
2017-06-11 05:03:32.729127 EDT | AverageQLoss                2.15104
2017-06-11 05:03:32.729545 EDT | AveragePolicySurr         -28.0687
2017-06-11 05:03:32.733256 EDT | AverageQ                   27.8782
2017-06-11 05:03:32.738135 EDT | AverageAbsQ                27.8938
2017-06-11 05:03:32.738637 EDT | AverageY                   27.8778
2017-06-11 05:03:32.739080 EDT | AverageAbsY                27.8821
2017-06-11 05:03:32.739509 EDT | AverageAbsQYDiff            0.493622
2017-06-11 05:03:32.739930 EDT | AverageAction               0.998854
2017-06-11 05:03:32.740398 EDT | PolicyRegParamNorm        104.536
2017-06-11 05:03:32.740775 EDT | QFunRegParamNorm          135.7
2017-06-11 05:03:32.741186 EDT | -----------------------  -----------
2017-06-11 05:03:32.741719 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1201 | Training started
2017-06-11 05:03:51.510535 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1201 | Training finished
2017-06-11 05:03:51.511595 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1201 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 05:03:51.511866 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1201 | Collecting samples for evaluation
2017-06-11 05:04:06.079758 EDT | -----------------------  -----------
2017-06-11 05:04:06.080613 EDT | Epoch                    1201
2017-06-11 05:04:06.080975 EDT | Iteration                1201
2017-06-11 05:04:06.081297 EDT | AverageReturn            1207.58
2017-06-11 05:04:06.081565 EDT | StdReturn                1172.7
2017-06-11 05:04:06.081901 EDT | MaxReturn                2940.52
2017-06-11 05:04:06.082234 EDT | MinReturn                 110.52
2017-06-11 05:04:06.082561 EDT | AverageEsReturn           176.477
2017-06-11 05:04:06.082821 EDT | StdEsReturn               146.298
2017-06-11 05:04:06.083117 EDT | MaxEsReturn               473.449
2017-06-11 05:04:06.083441 EDT | MinEsReturn                10.2399
2017-06-11 05:04:06.083777 EDT | AverageDiscountedReturn   165.462
2017-06-11 05:04:06.084082 EDT | AverageQLoss                1.7085
2017-06-11 05:04:06.084410 EDT | AveragePolicySurr         -28.0078
2017-06-11 05:04:06.084738 EDT | AverageQ                   27.8082
2017-06-11 05:04:06.085002 EDT | AverageAbsQ                27.8246
2017-06-11 05:04:06.085318 EDT | AverageY                   27.8108
2017-06-11 05:04:06.085647 EDT | AverageAbsY                27.8177
2017-06-11 05:04:06.085973 EDT | AverageAbsQYDiff            0.45317
2017-06-11 05:04:06.086232 EDT | AverageAction               0.998259
2017-06-11 05:04:06.086560 EDT | PolicyRegParamNorm        104.554
2017-06-11 05:04:06.086893 EDT | QFunRegParamNorm          135.747
2017-06-11 05:04:06.087203 EDT | -----------------------  -----------
2017-06-11 05:04:06.087689 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1202 | Training started
2017-06-11 05:04:24.036080 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1202 | Training finished
2017-06-11 05:04:24.036863 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1202 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 05:04:24.037132 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1202 | Collecting samples for evaluation
2017-06-11 05:04:38.767002 EDT | -----------------------  -----------
2017-06-11 05:04:38.767904 EDT | Epoch                    1202
2017-06-11 05:04:38.768288 EDT | Iteration                1202
2017-06-11 05:04:38.768634 EDT | AverageReturn            1893.68
2017-06-11 05:04:38.768970 EDT | StdReturn                 754.412
2017-06-11 05:04:38.769312 EDT | MaxReturn                3191.26
2017-06-11 05:04:38.769652 EDT | MinReturn                1110.64
2017-06-11 05:04:38.770022 EDT | AverageEsReturn           333.186
2017-06-11 05:04:38.770372 EDT | StdEsReturn               188.529
2017-06-11 05:04:38.770711 EDT | MaxEsReturn               632.791
2017-06-11 05:04:38.771060 EDT | MinEsReturn                56.9749
2017-06-11 05:04:38.771402 EDT | AverageDiscountedReturn   243.332
2017-06-11 05:04:38.771737 EDT | AverageQLoss                2.05536
2017-06-11 05:04:38.772075 EDT | AveragePolicySurr         -28.0432
2017-06-11 05:04:38.772412 EDT | AverageQ                   27.8472
2017-06-11 05:04:38.772751 EDT | AverageAbsQ                27.8604
2017-06-11 05:04:38.773099 EDT | AverageY                   27.848
2017-06-11 05:04:38.773438 EDT | AverageAbsY                27.8515
2017-06-11 05:04:38.773782 EDT | AverageAbsQYDiff            0.48025
2017-06-11 05:04:38.774136 EDT | AverageAction               0.998671
2017-06-11 05:04:38.774488 EDT | PolicyRegParamNorm        104.636
2017-06-11 05:04:38.774843 EDT | QFunRegParamNorm          135.781
2017-06-11 05:04:38.775196 EDT | -----------------------  -----------
2017-06-11 05:04:38.775703 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1203 | Training started
2017-06-11 05:04:55.082829 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1203 | Training finished
2017-06-11 05:04:55.083614 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1203 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 05:04:55.083850 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1203 | Collecting samples for evaluation
2017-06-11 05:05:09.251515 EDT | -----------------------  -----------
2017-06-11 05:05:09.253142 EDT | Epoch                    1203
2017-06-11 05:05:09.253890 EDT | Iteration                1203
2017-06-11 05:05:09.254341 EDT | AverageReturn             938.051
2017-06-11 05:05:09.254889 EDT | StdReturn                 708.614
2017-06-11 05:05:09.255395 EDT | MaxReturn                3472.89
2017-06-11 05:05:09.255800 EDT | MinReturn                 494.559
2017-06-11 05:05:09.256240 EDT | AverageEsReturn           601.752
2017-06-11 05:05:09.256734 EDT | StdEsReturn               578.702
2017-06-11 05:05:09.257163 EDT | MaxEsReturn              1698.48
2017-06-11 05:05:09.257668 EDT | MinEsReturn                95.669
2017-06-11 05:05:09.258116 EDT | AverageDiscountedReturn   234.326
2017-06-11 05:05:09.258612 EDT | AverageQLoss                1.84112
2017-06-11 05:05:09.259033 EDT | AveragePolicySurr         -28.0281
2017-06-11 05:05:09.259560 EDT | AverageQ                   27.8105
2017-06-11 05:05:09.259978 EDT | AverageAbsQ                27.8225
2017-06-11 05:05:09.260414 EDT | AverageY                   27.8114
2017-06-11 05:05:09.261110 EDT | AverageAbsY                27.8146
2017-06-11 05:05:09.261992 EDT | AverageAbsQYDiff            0.450663
2017-06-11 05:05:09.262572 EDT | AverageAction               0.998871
2017-06-11 05:05:09.263535 EDT | PolicyRegParamNorm        104.719
2017-06-11 05:05:09.264095 EDT | QFunRegParamNorm          135.802
2017-06-11 05:05:09.264533 EDT | -----------------------  -----------
2017-06-11 05:05:09.265317 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1204 | Training started
2017-06-11 05:05:26.283387 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1204 | Training finished
2017-06-11 05:05:26.284202 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1204 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 05:05:26.284578 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1204 | Collecting samples for evaluation
2017-06-11 05:05:42.489415 EDT | -----------------------  ------------
2017-06-11 05:05:42.490534 EDT | Epoch                    1204
2017-06-11 05:05:42.490926 EDT | Iteration                1204
2017-06-11 05:05:42.491298 EDT | AverageReturn               5.83786
2017-06-11 05:05:42.491855 EDT | StdReturn                   0.0454553
2017-06-11 05:05:42.492282 EDT | MaxReturn                   6.00009
2017-06-11 05:05:42.492654 EDT | MinReturn                   5.7345
2017-06-11 05:05:42.493023 EDT | AverageEsReturn            91.5681
2017-06-11 05:05:42.493526 EDT | StdEsReturn               172.789
2017-06-11 05:05:42.493931 EDT | MaxEsReturn               616.453
2017-06-11 05:05:42.494354 EDT | MinEsReturn                 5.47919
2017-06-11 05:05:42.494819 EDT | AverageDiscountedReturn     5.67533
2017-06-11 05:05:42.495204 EDT | AverageQLoss                1.98478
2017-06-11 05:05:42.495871 EDT | AveragePolicySurr         -27.9323
2017-06-11 05:05:42.496246 EDT | AverageQ                   27.7496
2017-06-11 05:05:42.496570 EDT | AverageAbsQ                27.761
2017-06-11 05:05:42.496749 EDT | AverageY                   27.7516
2017-06-11 05:05:42.496922 EDT | AverageAbsY                27.7556
2017-06-11 05:05:42.497323 EDT | AverageAbsQYDiff            0.469325
2017-06-11 05:05:42.497688 EDT | AverageAction               1
2017-06-11 05:05:42.498064 EDT | PolicyRegParamNorm        104.75
2017-06-11 05:05:42.498430 EDT | QFunRegParamNorm          135.816
2017-06-11 05:05:42.499059 EDT | -----------------------  ------------
2017-06-11 05:05:42.499688 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1205 | Training started
2017-06-11 05:05:59.286422 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1205 | Training finished
2017-06-11 05:05:59.391966 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1205 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 05:05:59.392422 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1205 | Collecting samples for evaluation
2017-06-11 05:06:14.636803 EDT | -----------------------  -----------
2017-06-11 05:06:14.638100 EDT | Epoch                    1205
2017-06-11 05:06:14.638383 EDT | Iteration                1205
2017-06-11 05:06:14.638603 EDT | AverageReturn               8.58708
2017-06-11 05:06:14.638804 EDT | StdReturn                  35.5191
2017-06-11 05:06:14.639004 EDT | MaxReturn                1234.87
2017-06-11 05:06:14.639269 EDT | MinReturn                   7.31392
2017-06-11 05:06:14.639675 EDT | AverageEsReturn            20.8518
2017-06-11 05:06:14.639849 EDT | StdEsReturn                81.4475
2017-06-11 05:06:14.640028 EDT | MaxEsReturn               521.741
2017-06-11 05:06:14.640433 EDT | MinEsReturn                 3.67196
2017-06-11 05:06:14.640630 EDT | AverageDiscountedReturn     7.47468
2017-06-11 05:06:14.640866 EDT | AverageQLoss                2.49199
2017-06-11 05:06:14.641135 EDT | AveragePolicySurr         -27.7738
2017-06-11 05:06:14.641450 EDT | AverageQ                   27.6501
2017-06-11 05:06:14.641754 EDT | AverageAbsQ                27.6687
2017-06-11 05:06:14.642037 EDT | AverageY                   27.6512
2017-06-11 05:06:14.642322 EDT | AverageAbsY                27.659
2017-06-11 05:06:14.643378 EDT | AverageAbsQYDiff            0.529481
2017-06-11 05:06:14.643783 EDT | AverageAction               0.999779
2017-06-11 05:06:14.644251 EDT | PolicyRegParamNorm        104.771
2017-06-11 05:06:14.644565 EDT | QFunRegParamNorm          135.866
2017-06-11 05:06:14.644956 EDT | -----------------------  -----------
2017-06-11 05:06:14.645514 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1206 | Training started
2017-06-11 05:06:31.727964 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1206 | Training finished
2017-06-11 05:06:31.728361 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1206 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 05:06:31.728718 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1206 | Collecting samples for evaluation
2017-06-11 05:06:45.647089 EDT | -----------------------  -----------
2017-06-11 05:06:45.650123 EDT | Epoch                    1206
2017-06-11 05:06:45.650430 EDT | Iteration                1206
2017-06-11 05:06:45.650700 EDT | AverageReturn            1293.41
2017-06-11 05:06:45.650963 EDT | StdReturn                 897.078
2017-06-11 05:06:45.651225 EDT | MaxReturn                2778.41
2017-06-11 05:06:45.651484 EDT | MinReturn                 187.61
2017-06-11 05:06:45.653069 EDT | AverageEsReturn           295.648
2017-06-11 05:06:45.653367 EDT | StdEsReturn               270.063
2017-06-11 05:06:45.653637 EDT | MaxEsReturn               972.912
2017-06-11 05:06:45.655231 EDT | MinEsReturn                 5.93227
2017-06-11 05:06:45.655530 EDT | AverageDiscountedReturn   206.316
2017-06-11 05:06:45.655797 EDT | AverageQLoss                2.53209
2017-06-11 05:06:45.657376 EDT | AveragePolicySurr         -27.847
2017-06-11 05:06:45.657674 EDT | AverageQ                   27.6594
2017-06-11 05:06:45.657956 EDT | AverageAbsQ                27.6747
2017-06-11 05:06:45.659534 EDT | AverageY                   27.6611
2017-06-11 05:06:45.659833 EDT | AverageAbsY                27.6676
2017-06-11 05:06:45.660100 EDT | AverageAbsQYDiff            0.516664
2017-06-11 05:06:45.661683 EDT | AverageAction               0.998862
2017-06-11 05:06:45.661987 EDT | PolicyRegParamNorm        104.78
2017-06-11 05:06:45.662255 EDT | QFunRegParamNorm          135.916
2017-06-11 05:06:45.663842 EDT | -----------------------  -----------
2017-06-11 05:06:45.664255 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1207 | Training started
2017-06-11 05:07:03.440778 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1207 | Training finished
2017-06-11 05:07:03.441831 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1207 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 05:07:03.442213 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1207 | Collecting samples for evaluation
2017-06-11 05:07:17.032633 EDT | -----------------------  -----------
2017-06-11 05:07:17.033559 EDT | Epoch                    1207
2017-06-11 05:07:17.033920 EDT | Iteration                1207
2017-06-11 05:07:17.034221 EDT | AverageReturn            1540.84
2017-06-11 05:07:17.034525 EDT | StdReturn                 801.271
2017-06-11 05:07:17.034762 EDT | MaxReturn                3149.31
2017-06-11 05:07:17.035045 EDT | MinReturn                 266.356
2017-06-11 05:07:17.035408 EDT | AverageEsReturn           439.639
2017-06-11 05:07:17.036462 EDT | StdEsReturn               215.216
2017-06-11 05:07:17.036972 EDT | MaxEsReturn               850.438
2017-06-11 05:07:17.037378 EDT | MinEsReturn               215.06
2017-06-11 05:07:17.037721 EDT | AverageDiscountedReturn   242.986
2017-06-11 05:07:17.038201 EDT | AverageQLoss                1.58018
2017-06-11 05:07:17.039454 EDT | AveragePolicySurr         -27.8246
2017-06-11 05:07:17.040388 EDT | AverageQ                   27.5942
2017-06-11 05:07:17.040723 EDT | AverageAbsQ                27.6088
2017-06-11 05:07:17.041011 EDT | AverageY                   27.5941
2017-06-11 05:07:17.041179 EDT | AverageAbsY                27.599
2017-06-11 05:07:17.041511 EDT | AverageAbsQYDiff            0.448157
2017-06-11 05:07:17.041819 EDT | AverageAction               0.998464
2017-06-11 05:07:17.042118 EDT | PolicyRegParamNorm        104.851
2017-06-11 05:07:17.042378 EDT | QFunRegParamNorm          135.908
2017-06-11 05:07:17.042660 EDT | -----------------------  -----------
2017-06-11 05:07:17.043141 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1208 | Training started
2017-06-11 05:07:34.931891 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1208 | Training finished
2017-06-11 05:07:34.932675 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1208 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 05:07:34.933042 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1208 | Collecting samples for evaluation
2017-06-11 05:07:49.064521 EDT | -----------------------  -----------
2017-06-11 05:07:49.065442 EDT | Epoch                    1208
2017-06-11 05:07:49.065830 EDT | Iteration                1208
2017-06-11 05:07:49.066193 EDT | AverageReturn            2291.81
2017-06-11 05:07:49.066553 EDT | StdReturn                 897.437
2017-06-11 05:07:49.066911 EDT | MaxReturn                3335.14
2017-06-11 05:07:49.067268 EDT | MinReturn                 304.341
2017-06-11 05:07:49.067629 EDT | AverageEsReturn           396.003
2017-06-11 05:07:49.067984 EDT | StdEsReturn               125.278
2017-06-11 05:07:49.068341 EDT | MaxEsReturn               642.376
2017-06-11 05:07:49.068695 EDT | MinEsReturn               218.65
2017-06-11 05:07:49.069055 EDT | AverageDiscountedReturn   251.212
2017-06-11 05:07:49.069409 EDT | AverageQLoss                2.05755
2017-06-11 05:07:49.069766 EDT | AveragePolicySurr         -27.8724
2017-06-11 05:07:49.070108 EDT | AverageQ                   27.656
2017-06-11 05:07:49.070461 EDT | AverageAbsQ                27.6722
2017-06-11 05:07:49.070810 EDT | AverageY                   27.6571
2017-06-11 05:07:49.071161 EDT | AverageAbsY                27.6622
2017-06-11 05:07:49.071528 EDT | AverageAbsQYDiff            0.483418
2017-06-11 05:07:49.071886 EDT | AverageAction               0.998876
2017-06-11 05:07:49.072242 EDT | PolicyRegParamNorm        104.884
2017-06-11 05:07:49.072595 EDT | QFunRegParamNorm          135.987
2017-06-11 05:07:49.072928 EDT | -----------------------  -----------
2017-06-11 05:07:49.073429 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1209 | Training started
2017-06-11 05:08:05.875644 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1209 | Training finished
2017-06-11 05:08:05.876682 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1209 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 05:08:05.877080 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1209 | Collecting samples for evaluation
2017-06-11 05:08:19.630322 EDT | -----------------------  -----------
2017-06-11 05:08:19.632801 EDT | Epoch                    1209
2017-06-11 05:08:19.633037 EDT | Iteration                1209
2017-06-11 05:08:19.633565 EDT | AverageReturn             833.921
2017-06-11 05:08:19.635680 EDT | StdReturn                 467.674
2017-06-11 05:08:19.635874 EDT | MaxReturn                2721.91
2017-06-11 05:08:19.636064 EDT | MinReturn                 273.467
2017-06-11 05:08:19.636248 EDT | AverageEsReturn           664.191
2017-06-11 05:08:19.636438 EDT | StdEsReturn               458.38
2017-06-11 05:08:19.636621 EDT | MaxEsReturn              1519.28
2017-06-11 05:08:19.636802 EDT | MinEsReturn               332.839
2017-06-11 05:08:19.636981 EDT | AverageDiscountedReturn   225.017
2017-06-11 05:08:19.637159 EDT | AverageQLoss                1.94094
2017-06-11 05:08:19.637338 EDT | AveragePolicySurr         -27.8553
2017-06-11 05:08:19.637518 EDT | AverageQ                   27.638
2017-06-11 05:08:19.637805 EDT | AverageAbsQ                27.6514
2017-06-11 05:08:19.638054 EDT | AverageY                   27.6386
2017-06-11 05:08:19.638346 EDT | AverageAbsY                27.644
2017-06-11 05:08:19.638532 EDT | AverageAbsQYDiff            0.479026
2017-06-11 05:08:19.638712 EDT | AverageAction               0.998902
2017-06-11 05:08:19.638893 EDT | PolicyRegParamNorm        104.922
2017-06-11 05:08:19.639072 EDT | QFunRegParamNorm          136.056
2017-06-11 05:08:19.639252 EDT | -----------------------  -----------
2017-06-11 05:08:19.639546 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1210 | Training started
2017-06-11 05:08:37.346187 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1210 | Training finished
2017-06-11 05:08:37.347295 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1210 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 05:08:37.347805 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1210 | Collecting samples for evaluation
2017-06-11 05:08:51.495860 EDT | -----------------------  -----------
2017-06-11 05:08:51.499096 EDT | Epoch                    1210
2017-06-11 05:08:51.500008 EDT | Iteration                1210
2017-06-11 05:08:51.501229 EDT | AverageReturn            1273.02
2017-06-11 05:08:51.502458 EDT | StdReturn                 980.512
2017-06-11 05:08:51.503504 EDT | MaxReturn                3496.25
2017-06-11 05:08:51.504738 EDT | MinReturn                 268.345
2017-06-11 05:08:51.505908 EDT | AverageEsReturn           427.999
2017-06-11 05:08:51.507147 EDT | StdEsReturn               280.997
2017-06-11 05:08:51.508380 EDT | MaxEsReturn               864.908
2017-06-11 05:08:51.509520 EDT | MinEsReturn                34.2176
2017-06-11 05:08:51.510725 EDT | AverageDiscountedReturn   222.833
2017-06-11 05:08:51.511853 EDT | AverageQLoss                1.76014
2017-06-11 05:08:51.513016 EDT | AveragePolicySurr         -27.864
2017-06-11 05:08:51.514274 EDT | AverageQ                   27.6762
2017-06-11 05:08:51.515477 EDT | AverageAbsQ                27.6916
2017-06-11 05:08:51.518775 EDT | AverageY                   27.6764
2017-06-11 05:08:51.520015 EDT | AverageAbsY                27.6827
2017-06-11 05:08:51.521229 EDT | AverageAbsQYDiff            0.462808
2017-06-11 05:08:51.523547 EDT | AverageAction               0.998567
2017-06-11 05:08:51.526217 EDT | PolicyRegParamNorm        104.979
2017-06-11 05:08:51.527476 EDT | QFunRegParamNorm          136.112
2017-06-11 05:08:51.529174 EDT | -----------------------  -----------
2017-06-11 05:08:51.530588 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1211 | Training started
2017-06-11 05:09:09.857928 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1211 | Training finished
2017-06-11 05:09:09.860589 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1211 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 05:09:09.860867 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1211 | Collecting samples for evaluation
2017-06-11 05:09:25.014407 EDT | -----------------------  -----------
2017-06-11 05:09:25.015516 EDT | Epoch                    1211
2017-06-11 05:09:25.015993 EDT | Iteration                1211
2017-06-11 05:09:25.016447 EDT | AverageReturn            1127.57
2017-06-11 05:09:25.016901 EDT | StdReturn                 755.966
2017-06-11 05:09:25.017350 EDT | MaxReturn                2976.76
2017-06-11 05:09:25.017806 EDT | MinReturn                 518.964
2017-06-11 05:09:25.018252 EDT | AverageEsReturn           479.655
2017-06-11 05:09:25.018699 EDT | StdEsReturn               302.142
2017-06-11 05:09:25.019142 EDT | MaxEsReturn               898.124
2017-06-11 05:09:25.019586 EDT | MinEsReturn                28.2238
2017-06-11 05:09:25.020037 EDT | AverageDiscountedReturn   229.824
2017-06-11 05:09:25.021838 EDT | AverageQLoss                1.81012
2017-06-11 05:09:25.022306 EDT | AveragePolicySurr         -27.8643
2017-06-11 05:09:25.024320 EDT | AverageQ                   27.6561
2017-06-11 05:09:25.024789 EDT | AverageAbsQ                27.6707
2017-06-11 05:09:25.026760 EDT | AverageY                   27.658
2017-06-11 05:09:25.027236 EDT | AverageAbsY                27.6661
2017-06-11 05:09:25.027694 EDT | AverageAbsQYDiff            0.454128
2017-06-11 05:09:25.029679 EDT | AverageAction               0.998914
2017-06-11 05:09:25.030166 EDT | PolicyRegParamNorm        104.98
2017-06-11 05:09:25.030623 EDT | QFunRegParamNorm          136.131
2017-06-11 05:09:25.032602 EDT | -----------------------  -----------
2017-06-11 05:09:25.033245 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1212 | Training started
2017-06-11 05:09:42.773912 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1212 | Training finished
2017-06-11 05:09:42.774196 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1212 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 05:09:42.774382 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1212 | Collecting samples for evaluation
2017-06-11 05:09:57.588330 EDT | -----------------------  -----------
2017-06-11 05:09:57.589325 EDT | Epoch                    1212
2017-06-11 05:09:57.589530 EDT | Iteration                1212
2017-06-11 05:09:57.589712 EDT | AverageReturn            2623.3
2017-06-11 05:09:57.589874 EDT | StdReturn                 649.738
2017-06-11 05:09:57.590029 EDT | MaxReturn                3076.21
2017-06-11 05:09:57.590228 EDT | MinReturn                1103.54
2017-06-11 05:09:57.590389 EDT | AverageEsReturn           493.282
2017-06-11 05:09:57.590544 EDT | StdEsReturn               218.539
2017-06-11 05:09:57.590705 EDT | MaxEsReturn               771.678
2017-06-11 05:09:57.590858 EDT | MinEsReturn               182.463
2017-06-11 05:09:57.591010 EDT | AverageDiscountedReturn   240.481
2017-06-11 05:09:57.591161 EDT | AverageQLoss                1.96927
2017-06-11 05:09:57.591311 EDT | AveragePolicySurr         -27.8328
2017-06-11 05:09:57.591462 EDT | AverageQ                   27.639
2017-06-11 05:09:57.591663 EDT | AverageAbsQ                27.6557
2017-06-11 05:09:57.591818 EDT | AverageY                   27.641
2017-06-11 05:09:57.591969 EDT | AverageAbsY                27.6492
2017-06-11 05:09:57.592119 EDT | AverageAbsQYDiff            0.477884
2017-06-11 05:09:57.592270 EDT | AverageAction               0.998798
2017-06-11 05:09:57.592421 EDT | PolicyRegParamNorm        104.993
2017-06-11 05:09:57.592569 EDT | QFunRegParamNorm          136.199
2017-06-11 05:09:57.592717 EDT | -----------------------  -----------
2017-06-11 05:09:57.593002 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1213 | Training started
2017-06-11 05:10:15.402260 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1213 | Training finished
2017-06-11 05:10:15.417800 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1213 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 05:10:15.418230 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1213 | Collecting samples for evaluation
2017-06-11 05:10:29.595721 EDT | -----------------------  -----------
2017-06-11 05:10:29.596621 EDT | Epoch                    1213
2017-06-11 05:10:29.596916 EDT | Iteration                1213
2017-06-11 05:10:29.597184 EDT | AverageReturn            1989.26
2017-06-11 05:10:29.597529 EDT | StdReturn                 877.361
2017-06-11 05:10:29.597892 EDT | MaxReturn                3160.82
2017-06-11 05:10:29.598288 EDT | MinReturn                 768.967
2017-06-11 05:10:29.598553 EDT | AverageEsReturn           429.884
2017-06-11 05:10:29.598810 EDT | StdEsReturn               166.915
2017-06-11 05:10:29.599065 EDT | MaxEsReturn               734.522
2017-06-11 05:10:29.599397 EDT | MinEsReturn               230.738
2017-06-11 05:10:29.599744 EDT | AverageDiscountedReturn   246.539
2017-06-11 05:10:29.600271 EDT | AverageQLoss                1.51162
2017-06-11 05:10:29.600537 EDT | AveragePolicySurr         -27.7815
2017-06-11 05:10:29.600815 EDT | AverageQ                   27.5719
2017-06-11 05:10:29.601151 EDT | AverageAbsQ                27.5901
2017-06-11 05:10:29.601608 EDT | AverageY                   27.5725
2017-06-11 05:10:29.601901 EDT | AverageAbsY                27.5818
2017-06-11 05:10:29.602162 EDT | AverageAbsQYDiff            0.449231
2017-06-11 05:10:29.602420 EDT | AverageAction               0.998939
2017-06-11 05:10:29.602761 EDT | PolicyRegParamNorm        105.088
2017-06-11 05:10:29.603110 EDT | QFunRegParamNorm          136.226
2017-06-11 05:10:29.603490 EDT | -----------------------  -----------
2017-06-11 05:10:29.603892 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1214 | Training started
2017-06-11 05:10:46.770481 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1214 | Training finished
2017-06-11 05:10:46.771016 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1214 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 05:10:46.771421 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1214 | Collecting samples for evaluation
2017-06-11 05:11:01.382075 EDT | -----------------------  -----------
2017-06-11 05:11:01.383177 EDT | Epoch                    1214
2017-06-11 05:11:01.383632 EDT | Iteration                1214
2017-06-11 05:11:01.384075 EDT | AverageReturn             496.234
2017-06-11 05:11:01.384372 EDT | StdReturn                 338.215
2017-06-11 05:11:01.384698 EDT | MaxReturn                1653.64
2017-06-11 05:11:01.385033 EDT | MinReturn                 193.319
2017-06-11 05:11:01.385369 EDT | AverageEsReturn           346.457
2017-06-11 05:11:01.385661 EDT | StdEsReturn               267.97
2017-06-11 05:11:01.385867 EDT | MaxEsReturn               904.182
2017-06-11 05:11:01.386059 EDT | MinEsReturn                26.4827
2017-06-11 05:11:01.386243 EDT | AverageDiscountedReturn   178.454
2017-06-11 05:11:01.386540 EDT | AverageQLoss                1.93263
2017-06-11 05:11:01.386873 EDT | AveragePolicySurr         -27.8218
2017-06-11 05:11:01.387308 EDT | AverageQ                   27.6412
2017-06-11 05:11:01.387712 EDT | AverageAbsQ                27.654
2017-06-11 05:11:01.388112 EDT | AverageY                   27.6432
2017-06-11 05:11:01.388547 EDT | AverageAbsY                27.6465
2017-06-11 05:11:01.388892 EDT | AverageAbsQYDiff            0.483692
2017-06-11 05:11:01.389323 EDT | AverageAction               0.999106
2017-06-11 05:11:01.389919 EDT | PolicyRegParamNorm        105.103
2017-06-11 05:11:01.390295 EDT | QFunRegParamNorm          136.232
2017-06-11 05:11:01.390730 EDT | -----------------------  -----------
2017-06-11 05:11:01.391337 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1215 | Training started
2017-06-11 05:11:18.554558 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1215 | Training finished
2017-06-11 05:11:18.555058 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1215 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 05:11:18.555508 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1215 | Collecting samples for evaluation
2017-06-11 05:11:33.947179 EDT | -----------------------  -----------
2017-06-11 05:11:33.948767 EDT | Epoch                    1215
2017-06-11 05:11:33.949228 EDT | Iteration                1215
2017-06-11 05:11:33.949610 EDT | AverageReturn            2006.37
2017-06-11 05:11:33.949948 EDT | StdReturn                 795.689
2017-06-11 05:11:33.950390 EDT | MaxReturn                2973.88
2017-06-11 05:11:33.950735 EDT | MinReturn                 873.786
2017-06-11 05:11:33.951073 EDT | AverageEsReturn           293.338
2017-06-11 05:11:33.951405 EDT | StdEsReturn               279.872
2017-06-11 05:11:33.951823 EDT | MaxEsReturn               984.25
2017-06-11 05:11:33.952250 EDT | MinEsReturn                14.1458
2017-06-11 05:11:33.952586 EDT | AverageDiscountedReturn   229.106
2017-06-11 05:11:33.953262 EDT | AverageQLoss                1.78988
2017-06-11 05:11:33.953602 EDT | AveragePolicySurr         -27.795
2017-06-11 05:11:33.954714 EDT | AverageQ                   27.601
2017-06-11 05:11:33.955023 EDT | AverageAbsQ                27.6132
2017-06-11 05:11:33.955341 EDT | AverageY                   27.603
2017-06-11 05:11:33.955663 EDT | AverageAbsY                27.6075
2017-06-11 05:11:33.956090 EDT | AverageAbsQYDiff            0.471522
2017-06-11 05:11:33.957567 EDT | AverageAction               0.998539
2017-06-11 05:11:33.958246 EDT | PolicyRegParamNorm        105.102
2017-06-11 05:11:33.958656 EDT | QFunRegParamNorm          136.275
2017-06-11 05:11:33.958993 EDT | -----------------------  -----------
2017-06-11 05:11:33.959523 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1216 | Training started
2017-06-11 05:11:50.866824 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1216 | Training finished
2017-06-11 05:11:50.867588 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1216 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 05:11:50.867807 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1216 | Collecting samples for evaluation
2017-06-11 05:12:05.283738 EDT | -----------------------  -----------
2017-06-11 05:12:05.284672 EDT | Epoch                    1216
2017-06-11 05:12:05.284955 EDT | Iteration                1216
2017-06-11 05:12:05.285148 EDT | AverageReturn            1078.48
2017-06-11 05:12:05.285336 EDT | StdReturn                 291.867
2017-06-11 05:12:05.285648 EDT | MaxReturn                1949.3
2017-06-11 05:12:05.285865 EDT | MinReturn                 698.851
2017-06-11 05:12:05.286052 EDT | AverageEsReturn           542.299
2017-06-11 05:12:05.286234 EDT | StdEsReturn               359.366
2017-06-11 05:12:05.286415 EDT | MaxEsReturn              1198.66
2017-06-11 05:12:05.286702 EDT | MinEsReturn               181.95
2017-06-11 05:12:05.286952 EDT | AverageDiscountedReturn   212.123
2017-06-11 05:12:05.287443 EDT | AverageQLoss                1.72145
2017-06-11 05:12:05.287724 EDT | AveragePolicySurr         -27.8832
2017-06-11 05:12:05.288096 EDT | AverageQ                   27.6877
2017-06-11 05:12:05.288280 EDT | AverageAbsQ                27.7
2017-06-11 05:12:05.288467 EDT | AverageY                   27.6881
2017-06-11 05:12:05.288648 EDT | AverageAbsY                27.692
2017-06-11 05:12:05.288828 EDT | AverageAbsQYDiff            0.451012
2017-06-11 05:12:05.289007 EDT | AverageAction               0.999011
2017-06-11 05:12:05.289188 EDT | PolicyRegParamNorm        105.171
2017-06-11 05:12:05.289366 EDT | QFunRegParamNorm          136.32
2017-06-11 05:12:05.289546 EDT | -----------------------  -----------
2017-06-11 05:12:05.289841 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1217 | Training started
2017-06-11 05:12:22.572688 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1217 | Training finished
2017-06-11 05:12:22.573229 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1217 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 05:12:22.573592 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1217 | Collecting samples for evaluation
2017-06-11 05:12:35.800220 EDT | -----------------------  -----------
2017-06-11 05:12:35.801127 EDT | Epoch                    1217
2017-06-11 05:12:35.801496 EDT | Iteration                1217
2017-06-11 05:12:35.801852 EDT | AverageReturn            1661.92
2017-06-11 05:12:35.802195 EDT | StdReturn                 682.629
2017-06-11 05:12:35.802540 EDT | MaxReturn                2931.74
2017-06-11 05:12:35.802988 EDT | MinReturn                 930.33
2017-06-11 05:12:35.803439 EDT | AverageEsReturn           326.944
2017-06-11 05:12:35.803889 EDT | StdEsReturn               141.052
2017-06-11 05:12:35.804334 EDT | MaxEsReturn               574.975
2017-06-11 05:12:35.804780 EDT | MinEsReturn               127.024
2017-06-11 05:12:35.805224 EDT | AverageDiscountedReturn   233.943
2017-06-11 05:12:35.805665 EDT | AverageQLoss                2.18818
2017-06-11 05:12:35.806117 EDT | AveragePolicySurr         -27.8172
2017-06-11 05:12:35.806563 EDT | AverageQ                   27.6012
2017-06-11 05:12:35.807004 EDT | AverageAbsQ                27.6149
2017-06-11 05:12:35.807453 EDT | AverageY                   27.6025
2017-06-11 05:12:35.807895 EDT | AverageAbsY                27.6081
2017-06-11 05:12:35.808338 EDT | AverageAbsQYDiff            0.487653
2017-06-11 05:12:35.821887 EDT | AverageAction               0.998867
2017-06-11 05:12:35.822429 EDT | PolicyRegParamNorm        105.17
2017-06-11 05:12:35.822887 EDT | QFunRegParamNorm          136.364
2017-06-11 05:12:35.823339 EDT | -----------------------  -----------
2017-06-11 05:12:35.823860 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1218 | Training started
2017-06-11 05:12:55.120159 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1218 | Training finished
2017-06-11 05:12:55.181731 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1218 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 05:12:55.182101 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1218 | Collecting samples for evaluation
2017-06-11 05:13:10.656877 EDT | -----------------------  -----------
2017-06-11 05:13:10.657897 EDT | Epoch                    1218
2017-06-11 05:13:10.658261 EDT | Iteration                1218
2017-06-11 05:13:10.658619 EDT | AverageReturn            2148.42
2017-06-11 05:13:10.658920 EDT | StdReturn                 629.152
2017-06-11 05:13:10.659199 EDT | MaxReturn                3016.94
2017-06-11 05:13:10.659541 EDT | MinReturn                1129.51
2017-06-11 05:13:10.659895 EDT | AverageEsReturn           432.827
2017-06-11 05:13:10.660230 EDT | StdEsReturn               318.348
2017-06-11 05:13:10.660502 EDT | MaxEsReturn               855.787
2017-06-11 05:13:10.660824 EDT | MinEsReturn                 4.7449
2017-06-11 05:13:10.661165 EDT | AverageDiscountedReturn   239.24
2017-06-11 05:13:10.661514 EDT | AverageQLoss                2.13131
2017-06-11 05:13:10.661825 EDT | AveragePolicySurr         -27.7936
2017-06-11 05:13:10.662105 EDT | AverageQ                   27.5894
2017-06-11 05:13:10.662445 EDT | AverageAbsQ                27.603
2017-06-11 05:13:10.662800 EDT | AverageY                   27.5922
2017-06-11 05:13:10.663137 EDT | AverageAbsY                27.5975
2017-06-11 05:13:10.663408 EDT | AverageAbsQYDiff            0.471622
2017-06-11 05:13:10.663738 EDT | AverageAction               0.998601
2017-06-11 05:13:10.664080 EDT | PolicyRegParamNorm        105.103
2017-06-11 05:13:10.664428 EDT | QFunRegParamNorm          136.372
2017-06-11 05:13:10.664729 EDT | -----------------------  -----------
2017-06-11 05:13:10.665157 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1219 | Training started
2017-06-11 05:13:27.669763 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1219 | Training finished
2017-06-11 05:13:27.671023 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1219 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 05:13:27.671383 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1219 | Collecting samples for evaluation
2017-06-11 05:13:43.112545 EDT | -----------------------  -----------
2017-06-11 05:13:43.113318 EDT | Epoch                    1219
2017-06-11 05:13:43.113608 EDT | Iteration                1219
2017-06-11 05:13:43.113850 EDT | AverageReturn            3007.45
2017-06-11 05:13:43.114108 EDT | StdReturn                 184.524
2017-06-11 05:13:43.114333 EDT | MaxReturn                3115.98
2017-06-11 05:13:43.114510 EDT | MinReturn                2431.59
2017-06-11 05:13:43.114675 EDT | AverageEsReturn           504.373
2017-06-11 05:13:43.115044 EDT | StdEsReturn               323.644
2017-06-11 05:13:43.115220 EDT | MaxEsReturn               917.438
2017-06-11 05:13:43.115400 EDT | MinEsReturn                14.0544
2017-06-11 05:13:43.115561 EDT | AverageDiscountedReturn   238.897
2017-06-11 05:13:43.115818 EDT | AverageQLoss                1.75457
2017-06-11 05:13:43.116086 EDT | AveragePolicySurr         -27.7584
2017-06-11 05:13:43.116300 EDT | AverageQ                   27.5553
2017-06-11 05:13:43.116461 EDT | AverageAbsQ                27.5714
2017-06-11 05:13:43.116613 EDT | AverageY                   27.5566
2017-06-11 05:13:43.116762 EDT | AverageAbsY                27.5625
2017-06-11 05:13:43.116909 EDT | AverageAbsQYDiff            0.450244
2017-06-11 05:13:43.117096 EDT | AverageAction               0.998978
2017-06-11 05:13:43.117282 EDT | PolicyRegParamNorm        105.181
2017-06-11 05:13:43.117456 EDT | QFunRegParamNorm          136.417
2017-06-11 05:13:43.117621 EDT | -----------------------  -----------
2017-06-11 05:13:43.117975 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1220 | Training started
2017-06-11 05:14:00.309152 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1220 | Training finished
2017-06-11 05:14:00.310116 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1220 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 05:14:00.310525 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1220 | Collecting samples for evaluation
2017-06-11 05:14:15.126547 EDT | -----------------------  -----------
2017-06-11 05:14:15.127409 EDT | Epoch                    1220
2017-06-11 05:14:15.127685 EDT | Iteration                1220
2017-06-11 05:14:15.127945 EDT | AverageReturn            2638.3
2017-06-11 05:14:15.128204 EDT | StdReturn                 674.029
2017-06-11 05:14:15.128456 EDT | MaxReturn                3167.34
2017-06-11 05:14:15.128712 EDT | MinReturn                1327.99
2017-06-11 05:14:15.128963 EDT | AverageEsReturn           857.771
2017-06-11 05:14:15.129216 EDT | StdEsReturn               428.78
2017-06-11 05:14:15.129465 EDT | MaxEsReturn              1504.14
2017-06-11 05:14:15.129724 EDT | MinEsReturn               284.116
2017-06-11 05:14:15.129975 EDT | AverageDiscountedReturn   242.766
2017-06-11 05:14:15.130229 EDT | AverageQLoss                2.21253
2017-06-11 05:14:15.130478 EDT | AveragePolicySurr         -27.7611
2017-06-11 05:14:15.130727 EDT | AverageQ                   27.5593
2017-06-11 05:14:15.130976 EDT | AverageAbsQ                27.5717
2017-06-11 05:14:15.131226 EDT | AverageY                   27.5615
2017-06-11 05:14:15.131473 EDT | AverageAbsY                27.5663
2017-06-11 05:14:15.131720 EDT | AverageAbsQYDiff            0.479117
2017-06-11 05:14:15.131967 EDT | AverageAction               0.998995
2017-06-11 05:14:15.132215 EDT | PolicyRegParamNorm        105.21
2017-06-11 05:14:15.132704 EDT | QFunRegParamNorm          136.458
2017-06-11 05:14:15.133482 EDT | -----------------------  -----------
2017-06-11 05:14:15.134418 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1221 | Training started
2017-06-11 05:14:33.386200 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1221 | Training finished
2017-06-11 05:14:33.387040 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1221 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 05:14:33.387428 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1221 | Collecting samples for evaluation
2017-06-11 05:14:48.237340 EDT | -----------------------  -----------
2017-06-11 05:14:48.239188 EDT | Epoch                    1221
2017-06-11 05:14:48.239458 EDT | Iteration                1221
2017-06-11 05:14:48.239658 EDT | AverageReturn            2806.47
2017-06-11 05:14:48.239844 EDT | StdReturn                  33.4073
2017-06-11 05:14:48.240028 EDT | MaxReturn                2864.99
2017-06-11 05:14:48.240211 EDT | MinReturn                2756.24
2017-06-11 05:14:48.240394 EDT | AverageEsReturn           455.406
2017-06-11 05:14:48.240573 EDT | StdEsReturn               396.304
2017-06-11 05:14:48.240753 EDT | MaxEsReturn              1190.21
2017-06-11 05:14:48.240931 EDT | MinEsReturn                18.834
2017-06-11 05:14:48.241113 EDT | AverageDiscountedReturn   227.1
2017-06-11 05:14:48.241292 EDT | AverageQLoss                2.07211
2017-06-11 05:14:48.241471 EDT | AveragePolicySurr         -27.7789
2017-06-11 05:14:48.241649 EDT | AverageQ                   27.5737
2017-06-11 05:14:48.242078 EDT | AverageAbsQ                27.5882
2017-06-11 05:14:48.242625 EDT | AverageY                   27.5742
2017-06-11 05:14:48.243030 EDT | AverageAbsY                27.579
2017-06-11 05:14:48.243445 EDT | AverageAbsQYDiff            0.479383
2017-06-11 05:14:48.243865 EDT | AverageAction               0.998808
2017-06-11 05:14:48.244880 EDT | PolicyRegParamNorm        105.197
2017-06-11 05:14:48.245737 EDT | QFunRegParamNorm          136.501
2017-06-11 05:14:48.248306 EDT | -----------------------  -----------
2017-06-11 05:14:48.248962 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1222 | Training started
2017-06-11 05:15:08.031890 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1222 | Training finished
2017-06-11 05:15:08.032868 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1222 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 05:15:08.033402 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1222 | Collecting samples for evaluation
2017-06-11 05:15:23.175210 EDT | -----------------------  -----------
2017-06-11 05:15:23.175623 EDT | Epoch                    1222
2017-06-11 05:15:23.175897 EDT | Iteration                1222
2017-06-11 05:15:23.176163 EDT | AverageReturn            2199.43
2017-06-11 05:15:23.176423 EDT | StdReturn                 727.644
2017-06-11 05:15:23.176682 EDT | MaxReturn                3005.23
2017-06-11 05:15:23.176939 EDT | MinReturn                 586.315
2017-06-11 05:15:23.177198 EDT | AverageEsReturn           682.021
2017-06-11 05:15:23.177454 EDT | StdEsReturn               635.058
2017-06-11 05:15:23.177718 EDT | MaxEsReturn              1713.47
2017-06-11 05:15:23.177977 EDT | MinEsReturn               106.79
2017-06-11 05:15:23.178233 EDT | AverageDiscountedReturn   231.057
2017-06-11 05:15:23.178561 EDT | AverageQLoss                1.83309
2017-06-11 05:15:23.179075 EDT | AveragePolicySurr         -27.7723
2017-06-11 05:15:23.179595 EDT | AverageQ                   27.5686
2017-06-11 05:15:23.180112 EDT | AverageAbsQ                27.5851
2017-06-11 05:15:23.180628 EDT | AverageY                   27.57
2017-06-11 05:15:23.185780 EDT | AverageAbsY                27.5751
2017-06-11 05:15:23.186379 EDT | AverageAbsQYDiff            0.466725
2017-06-11 05:15:23.186915 EDT | AverageAction               0.998557
2017-06-11 05:15:23.187440 EDT | PolicyRegParamNorm        105.194
2017-06-11 05:15:23.187962 EDT | QFunRegParamNorm          136.527
2017-06-11 05:15:23.188480 EDT | -----------------------  -----------
2017-06-11 05:15:23.189138 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1223 | Training started
2017-06-11 05:15:42.714042 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1223 | Training finished
2017-06-11 05:15:42.714782 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1223 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 05:15:42.714968 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1223 | Collecting samples for evaluation
2017-06-11 05:15:58.394742 EDT | -----------------------  -----------
2017-06-11 05:15:58.395717 EDT | Epoch                    1223
2017-06-11 05:15:58.396210 EDT | Iteration                1223
2017-06-11 05:15:58.396668 EDT | AverageReturn            1442.85
2017-06-11 05:15:58.397354 EDT | StdReturn                 899.155
2017-06-11 05:15:58.397821 EDT | MaxReturn                2735.58
2017-06-11 05:15:58.399467 EDT | MinReturn                 517.574
2017-06-11 05:15:58.399923 EDT | AverageEsReturn           534.561
2017-06-11 05:15:58.400865 EDT | StdEsReturn               335.998
2017-06-11 05:15:58.401820 EDT | MaxEsReturn              1089.76
2017-06-11 05:15:58.402287 EDT | MinEsReturn               188.348
2017-06-11 05:15:58.403858 EDT | AverageDiscountedReturn   209.584
2017-06-11 05:15:58.404308 EDT | AverageQLoss                1.78142
2017-06-11 05:15:58.404776 EDT | AveragePolicySurr         -27.7438
2017-06-11 05:15:58.405575 EDT | AverageQ                   27.5378
2017-06-11 05:15:58.406488 EDT | AverageAbsQ                27.5534
2017-06-11 05:15:58.407592 EDT | AverageY                   27.5385
2017-06-11 05:15:58.408089 EDT | AverageAbsY                27.5437
2017-06-11 05:15:58.409002 EDT | AverageAbsQYDiff            0.467319
2017-06-11 05:15:58.410050 EDT | AverageAction               0.998839
2017-06-11 05:15:58.410943 EDT | PolicyRegParamNorm        105.28
2017-06-11 05:15:58.412002 EDT | QFunRegParamNorm          136.55
2017-06-11 05:15:58.412813 EDT | -----------------------  -----------
2017-06-11 05:15:58.413966 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1224 | Training started
2017-06-11 05:16:14.127123 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1224 | Training finished
2017-06-11 05:16:14.131382 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1224 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 05:16:14.132200 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1224 | Collecting samples for evaluation
2017-06-11 05:16:28.898130 EDT | -----------------------  -----------
2017-06-11 05:16:28.899010 EDT | Epoch                    1224
2017-06-11 05:16:28.899302 EDT | Iteration                1224
2017-06-11 05:16:28.899567 EDT | AverageReturn            3282.31
2017-06-11 05:16:28.899836 EDT | StdReturn                 193.348
2017-06-11 05:16:28.900092 EDT | MaxReturn                3378.26
2017-06-11 05:16:28.900347 EDT | MinReturn                2681.09
2017-06-11 05:16:28.900602 EDT | AverageEsReturn           346.863
2017-06-11 05:16:28.900882 EDT | StdEsReturn               287.633
2017-06-11 05:16:28.901136 EDT | MaxEsReturn               905.563
2017-06-11 05:16:28.901387 EDT | MinEsReturn                66.8856
2017-06-11 05:16:28.912237 EDT | AverageDiscountedReturn   246.798
2017-06-11 05:16:28.912574 EDT | AverageQLoss                1.79096
2017-06-11 05:16:28.912841 EDT | AveragePolicySurr         -27.6737
2017-06-11 05:16:28.913100 EDT | AverageQ                   27.4676
2017-06-11 05:16:28.913357 EDT | AverageAbsQ                27.4841
2017-06-11 05:16:28.913612 EDT | AverageY                   27.4706
2017-06-11 05:16:28.913877 EDT | AverageAbsY                27.4778
2017-06-11 05:16:28.914129 EDT | AverageAbsQYDiff            0.467299
2017-06-11 05:16:28.914382 EDT | AverageAction               0.999389
2017-06-11 05:16:28.914634 EDT | PolicyRegParamNorm        105.314
2017-06-11 05:16:28.914885 EDT | QFunRegParamNorm          136.527
2017-06-11 05:16:28.915136 EDT | -----------------------  -----------
2017-06-11 05:16:28.915543 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1225 | Training started
2017-06-11 05:16:46.287074 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1225 | Training finished
2017-06-11 05:16:46.301796 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1225 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 05:16:46.302422 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1225 | Collecting samples for evaluation
2017-06-11 05:17:02.945234 EDT | -----------------------  -----------
2017-06-11 05:17:02.946145 EDT | Epoch                    1225
2017-06-11 05:17:02.946373 EDT | Iteration                1225
2017-06-11 05:17:02.946636 EDT | AverageReturn            3091.08
2017-06-11 05:17:02.946900 EDT | StdReturn                 640.91
2017-06-11 05:17:02.947141 EDT | MaxReturn                3480.31
2017-06-11 05:17:02.947383 EDT | MinReturn                1454.76
2017-06-11 05:17:02.947632 EDT | AverageEsReturn           432.348
2017-06-11 05:17:02.948003 EDT | StdEsReturn               273.984
2017-06-11 05:17:02.949008 EDT | MaxEsReturn               842.503
2017-06-11 05:17:02.949291 EDT | MinEsReturn               128.971
2017-06-11 05:17:02.949595 EDT | AverageDiscountedReturn   252.018
2017-06-11 05:17:02.949945 EDT | AverageQLoss                1.65889
2017-06-11 05:17:02.950258 EDT | AveragePolicySurr         -27.7124
2017-06-11 05:17:02.950534 EDT | AverageQ                   27.5244
2017-06-11 05:17:02.950898 EDT | AverageAbsQ                27.538
2017-06-11 05:17:02.951237 EDT | AverageY                   27.523
2017-06-11 05:17:02.951539 EDT | AverageAbsY                27.5286
2017-06-11 05:17:02.951913 EDT | AverageAbsQYDiff            0.45548
2017-06-11 05:17:02.952246 EDT | AverageAction               0.999086
2017-06-11 05:17:02.952562 EDT | PolicyRegParamNorm        105.348
2017-06-11 05:17:02.952877 EDT | QFunRegParamNorm          136.588
2017-06-11 05:17:02.953301 EDT | -----------------------  -----------
2017-06-11 05:17:02.953805 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1226 | Training started
2017-06-11 05:17:20.449070 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1226 | Training finished
2017-06-11 05:17:20.449560 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1226 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 05:17:20.449943 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1226 | Collecting samples for evaluation
2017-06-11 05:17:34.140970 EDT | -----------------------  -----------
2017-06-11 05:17:34.152481 EDT | Epoch                    1226
2017-06-11 05:17:34.152979 EDT | Iteration                1226
2017-06-11 05:17:34.153348 EDT | AverageReturn            2004.65
2017-06-11 05:17:34.153723 EDT | StdReturn                 708.762
2017-06-11 05:17:34.154092 EDT | MaxReturn                2913.2
2017-06-11 05:17:34.154441 EDT | MinReturn                1201.82
2017-06-11 05:17:34.154785 EDT | AverageEsReturn           472.678
2017-06-11 05:17:34.155243 EDT | StdEsReturn               514.492
2017-06-11 05:17:34.155695 EDT | MaxEsReturn              1510.21
2017-06-11 05:17:34.156168 EDT | MinEsReturn                22.9279
2017-06-11 05:17:34.156637 EDT | AverageDiscountedReturn   234.455
2017-06-11 05:17:34.157105 EDT | AverageQLoss                1.56498
2017-06-11 05:17:34.157575 EDT | AveragePolicySurr         -27.7399
2017-06-11 05:17:34.158052 EDT | AverageQ                   27.5335
2017-06-11 05:17:34.158525 EDT | AverageAbsQ                27.5446
2017-06-11 05:17:34.158994 EDT | AverageY                   27.5351
2017-06-11 05:17:34.159460 EDT | AverageAbsY                27.5387
2017-06-11 05:17:34.159933 EDT | AverageAbsQYDiff            0.448559
2017-06-11 05:17:34.160399 EDT | AverageAction               0.998982
2017-06-11 05:17:34.160868 EDT | PolicyRegParamNorm        105.366
2017-06-11 05:17:34.161342 EDT | QFunRegParamNorm          136.597
2017-06-11 05:17:34.161819 EDT | -----------------------  -----------
2017-06-11 05:17:34.162460 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1227 | Training started
2017-06-11 05:17:53.339889 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1227 | Training finished
2017-06-11 05:17:53.340190 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1227 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 05:17:53.340422 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1227 | Collecting samples for evaluation
2017-06-11 05:18:07.230262 EDT | -----------------------  -----------
2017-06-11 05:18:07.231236 EDT | Epoch                    1227
2017-06-11 05:18:07.231615 EDT | Iteration                1227
2017-06-11 05:18:07.231978 EDT | AverageReturn            1681.35
2017-06-11 05:18:07.232333 EDT | StdReturn                 720.641
2017-06-11 05:18:07.232796 EDT | MaxReturn                3096.79
2017-06-11 05:18:07.233247 EDT | MinReturn                 609.105
2017-06-11 05:18:07.233700 EDT | AverageEsReturn           419.409
2017-06-11 05:18:07.234149 EDT | StdEsReturn               350.738
2017-06-11 05:18:07.234598 EDT | MaxEsReturn               910.804
2017-06-11 05:18:07.234948 EDT | MinEsReturn                42.8773
2017-06-11 05:18:07.235291 EDT | AverageDiscountedReturn   235.136
2017-06-11 05:18:07.235630 EDT | AverageQLoss                2.14192
2017-06-11 05:18:07.235973 EDT | AveragePolicySurr         -27.6804
2017-06-11 05:18:07.236450 EDT | AverageQ                   27.455
2017-06-11 05:18:07.236813 EDT | AverageAbsQ                27.4705
2017-06-11 05:18:07.237172 EDT | AverageY                   27.4554
2017-06-11 05:18:07.237513 EDT | AverageAbsY                27.46
2017-06-11 05:18:07.237866 EDT | AverageAbsQYDiff            0.485447
2017-06-11 05:18:07.249853 EDT | AverageAction               0.999168
2017-06-11 05:18:07.250257 EDT | PolicyRegParamNorm        105.371
2017-06-11 05:18:07.250616 EDT | QFunRegParamNorm          136.675
2017-06-11 05:18:07.250972 EDT | -----------------------  -----------
2017-06-11 05:18:07.251497 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1228 | Training started
2017-06-11 05:18:25.288193 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1228 | Training finished
2017-06-11 05:18:25.288869 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1228 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 05:18:25.289076 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1228 | Collecting samples for evaluation
2017-06-11 05:18:39.978655 EDT | -----------------------  -----------
2017-06-11 05:18:39.979755 EDT | Epoch                    1228
2017-06-11 05:18:39.980220 EDT | Iteration                1228
2017-06-11 05:18:39.980650 EDT | AverageReturn            1301.28
2017-06-11 05:18:39.981071 EDT | StdReturn                 624.985
2017-06-11 05:18:39.981463 EDT | MaxReturn                3103.13
2017-06-11 05:18:39.981889 EDT | MinReturn                 581.849
2017-06-11 05:18:39.982284 EDT | AverageEsReturn           608.577
2017-06-11 05:18:39.982627 EDT | StdEsReturn               226.381
2017-06-11 05:18:39.983024 EDT | MaxEsReturn               896.713
2017-06-11 05:18:39.983445 EDT | MinEsReturn               290.78
2017-06-11 05:18:39.983859 EDT | AverageDiscountedReturn   231.819
2017-06-11 05:18:39.984254 EDT | AverageQLoss                1.68533
2017-06-11 05:18:39.984614 EDT | AveragePolicySurr         -27.7213
2017-06-11 05:18:39.984949 EDT | AverageQ                   27.5238
2017-06-11 05:18:39.985280 EDT | AverageAbsQ                27.5331
2017-06-11 05:18:39.985610 EDT | AverageY                   27.5252
2017-06-11 05:18:39.985953 EDT | AverageAbsY                27.5288
2017-06-11 05:18:39.986359 EDT | AverageAbsQYDiff            0.449444
2017-06-11 05:18:39.986739 EDT | AverageAction               0.998823
2017-06-11 05:18:39.987082 EDT | PolicyRegParamNorm        105.436
2017-06-11 05:18:39.987806 EDT | QFunRegParamNorm          136.709
2017-06-11 05:18:39.988977 EDT | -----------------------  -----------
2017-06-11 05:18:39.990199 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1229 | Training started
2017-06-11 05:18:56.688178 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1229 | Training finished
2017-06-11 05:18:56.800614 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1229 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 05:18:56.800974 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1229 | Collecting samples for evaluation
2017-06-11 05:19:11.979800 EDT | -----------------------  -----------
2017-06-11 05:19:11.980754 EDT | Epoch                    1229
2017-06-11 05:19:11.981084 EDT | Iteration                1229
2017-06-11 05:19:11.981411 EDT | AverageReturn             983.747
2017-06-11 05:19:11.981740 EDT | StdReturn                 780.418
2017-06-11 05:19:11.982057 EDT | MaxReturn                2599.2
2017-06-11 05:19:11.982369 EDT | MinReturn                 268.14
2017-06-11 05:19:11.982689 EDT | AverageEsReturn           509.973
2017-06-11 05:19:11.982951 EDT | StdEsReturn               406.63
2017-06-11 05:19:11.983276 EDT | MaxEsReturn              1117.18
2017-06-11 05:19:11.983582 EDT | MinEsReturn               109.962
2017-06-11 05:19:11.983880 EDT | AverageDiscountedReturn   199.501
2017-06-11 05:19:11.984135 EDT | AverageQLoss                1.51209
2017-06-11 05:19:11.984382 EDT | AveragePolicySurr         -27.7004
2017-06-11 05:19:11.984659 EDT | AverageQ                   27.5081
2017-06-11 05:19:11.984964 EDT | AverageAbsQ                27.5225
2017-06-11 05:19:11.985273 EDT | AverageY                   27.5095
2017-06-11 05:19:11.985551 EDT | AverageAbsY                27.5141
2017-06-11 05:19:11.985887 EDT | AverageAbsQYDiff            0.442215
2017-06-11 05:19:11.986180 EDT | AverageAction               0.999064
2017-06-11 05:19:11.986482 EDT | PolicyRegParamNorm        105.475
2017-06-11 05:19:11.986819 EDT | QFunRegParamNorm          136.736
2017-06-11 05:19:11.987142 EDT | -----------------------  -----------
2017-06-11 05:19:11.987608 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1230 | Training started
2017-06-11 05:19:28.947339 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1230 | Training finished
2017-06-11 05:19:28.948072 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1230 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 05:19:28.948261 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1230 | Collecting samples for evaluation
2017-06-11 05:19:44.172365 EDT | -----------------------  -----------
2017-06-11 05:19:44.173737 EDT | Epoch                    1230
2017-06-11 05:19:44.176422 EDT | Iteration                1230
2017-06-11 05:19:44.177024 EDT | AverageReturn            1598.77
2017-06-11 05:19:44.177348 EDT | StdReturn                 774.278
2017-06-11 05:19:44.177519 EDT | MaxReturn                3284.97
2017-06-11 05:19:44.177675 EDT | MinReturn                 588.685
2017-06-11 05:19:44.177888 EDT | AverageEsReturn           486.356
2017-06-11 05:19:44.178063 EDT | StdEsReturn               331.009
2017-06-11 05:19:44.178251 EDT | MaxEsReturn               815.415
2017-06-11 05:19:44.178526 EDT | MinEsReturn                 8.48735
2017-06-11 05:19:44.178727 EDT | AverageDiscountedReturn   243.931
2017-06-11 05:19:44.178915 EDT | AverageQLoss                1.81224
2017-06-11 05:19:44.179100 EDT | AveragePolicySurr         -27.6916
2017-06-11 05:19:44.179256 EDT | AverageQ                   27.5076
2017-06-11 05:19:44.179496 EDT | AverageAbsQ                27.5226
2017-06-11 05:19:44.179701 EDT | AverageY                   27.5093
2017-06-11 05:19:44.179896 EDT | AverageAbsY                27.5151
2017-06-11 05:19:44.180167 EDT | AverageAbsQYDiff            0.453532
2017-06-11 05:19:44.180359 EDT | AverageAction               0.999089
2017-06-11 05:19:44.181884 EDT | PolicyRegParamNorm        105.527
2017-06-11 05:19:44.182094 EDT | QFunRegParamNorm          136.673
2017-06-11 05:19:44.182398 EDT | -----------------------  -----------
2017-06-11 05:19:44.182786 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1231 | Training started
2017-06-11 05:20:03.173266 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1231 | Training finished
2017-06-11 05:20:03.174132 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1231 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 05:20:03.174724 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1231 | Collecting samples for evaluation
2017-06-11 05:20:17.017832 EDT | -----------------------  -----------
2017-06-11 05:20:17.018269 EDT | Epoch                    1231
2017-06-11 05:20:17.018483 EDT | Iteration                1231
2017-06-11 05:20:17.018877 EDT | AverageReturn            2058.6
2017-06-11 05:20:17.019282 EDT | StdReturn                 996.382
2017-06-11 05:20:17.019722 EDT | MaxReturn                3354.35
2017-06-11 05:20:17.020055 EDT | MinReturn                 268.043
2017-06-11 05:20:17.020391 EDT | AverageEsReturn           291.166
2017-06-11 05:20:17.020830 EDT | StdEsReturn               204.5
2017-06-11 05:20:17.021167 EDT | MaxEsReturn               782.539
2017-06-11 05:20:17.021484 EDT | MinEsReturn                18.4586
2017-06-11 05:20:17.021825 EDT | AverageDiscountedReturn   242.611
2017-06-11 05:20:17.022245 EDT | AverageQLoss                1.52952
2017-06-11 05:20:17.022558 EDT | AveragePolicySurr         -27.6448
2017-06-11 05:20:17.022891 EDT | AverageQ                   27.4539
2017-06-11 05:20:17.023232 EDT | AverageAbsQ                27.4704
2017-06-11 05:20:17.023614 EDT | AverageY                   27.4546
2017-06-11 05:20:17.023893 EDT | AverageAbsY                27.4587
2017-06-11 05:20:17.024204 EDT | AverageAbsQYDiff            0.443263
2017-06-11 05:20:17.025358 EDT | AverageAction               0.999348
2017-06-11 05:20:17.025771 EDT | PolicyRegParamNorm        105.544
2017-06-11 05:20:17.026005 EDT | QFunRegParamNorm          136.706
2017-06-11 05:20:17.026176 EDT | -----------------------  -----------
2017-06-11 05:20:17.026485 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1232 | Training started
2017-06-11 05:20:34.996193 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1232 | Training finished
2017-06-11 05:20:34.997206 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1232 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 05:20:34.997494 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1232 | Collecting samples for evaluation
2017-06-11 05:20:48.825012 EDT | -----------------------  -----------
2017-06-11 05:20:48.825980 EDT | Epoch                    1232
2017-06-11 05:20:48.826338 EDT | Iteration                1232
2017-06-11 05:20:48.826637 EDT | AverageReturn            1367.41
2017-06-11 05:20:48.826920 EDT | StdReturn                1279.16
2017-06-11 05:20:48.827258 EDT | MaxReturn                3178.39
2017-06-11 05:20:48.827600 EDT | MinReturn                 233.302
2017-06-11 05:20:48.827938 EDT | AverageEsReturn           431.096
2017-06-11 05:20:48.828278 EDT | StdEsReturn               335.487
2017-06-11 05:20:48.828618 EDT | MaxEsReturn              1052.5
2017-06-11 05:20:48.828961 EDT | MinEsReturn                32.1781
2017-06-11 05:20:48.829303 EDT | AverageDiscountedReturn   197.41
2017-06-11 05:20:48.829645 EDT | AverageQLoss                2.35809
2017-06-11 05:20:48.830205 EDT | AveragePolicySurr         -27.5925
2017-06-11 05:20:48.830545 EDT | AverageQ                   27.3887
2017-06-11 05:20:48.832083 EDT | AverageAbsQ                27.4052
2017-06-11 05:20:48.832426 EDT | AverageY                   27.3929
2017-06-11 05:20:48.833020 EDT | AverageAbsY                27.3989
2017-06-11 05:20:48.833352 EDT | AverageAbsQYDiff            0.501998
2017-06-11 05:20:48.833690 EDT | AverageAction               0.999199
2017-06-11 05:20:48.834352 EDT | PolicyRegParamNorm        105.553
2017-06-11 05:20:48.835923 EDT | QFunRegParamNorm          136.774
2017-06-11 05:20:48.836541 EDT | -----------------------  -----------
2017-06-11 05:20:48.837148 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1233 | Training started
2017-06-11 05:21:05.872039 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1233 | Training finished
2017-06-11 05:21:05.872819 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1233 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 05:21:05.873010 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1233 | Collecting samples for evaluation
2017-06-11 05:21:20.487525 EDT | -----------------------  -----------
2017-06-11 05:21:20.489058 EDT | Epoch                    1233
2017-06-11 05:21:20.489360 EDT | Iteration                1233
2017-06-11 05:21:20.490859 EDT | AverageReturn             339.036
2017-06-11 05:21:20.491092 EDT | StdReturn                 199.542
2017-06-11 05:21:20.491317 EDT | MaxReturn                1117.22
2017-06-11 05:21:20.491480 EDT | MinReturn                 222.541
2017-06-11 05:21:20.491657 EDT | AverageEsReturn           277.317
2017-06-11 05:21:20.492274 EDT | StdEsReturn               248.568
2017-06-11 05:21:20.493816 EDT | MaxEsReturn               872.586
2017-06-11 05:21:20.494164 EDT | MinEsReturn                18.2879
2017-06-11 05:21:20.494488 EDT | AverageDiscountedReturn   151.424
2017-06-11 05:21:20.494823 EDT | AverageQLoss                1.9166
2017-06-11 05:21:20.495135 EDT | AveragePolicySurr         -27.6982
2017-06-11 05:21:20.495466 EDT | AverageQ                   27.4975
2017-06-11 05:21:20.495787 EDT | AverageAbsQ                27.5132
2017-06-11 05:21:20.496102 EDT | AverageY                   27.4984
2017-06-11 05:21:20.496421 EDT | AverageAbsY                27.5062
2017-06-11 05:21:20.496868 EDT | AverageAbsQYDiff            0.472633
2017-06-11 05:21:20.497157 EDT | AverageAction               0.99895
2017-06-11 05:21:20.497398 EDT | PolicyRegParamNorm        105.605
2017-06-11 05:21:20.497726 EDT | QFunRegParamNorm          136.84
2017-06-11 05:21:20.498106 EDT | -----------------------  -----------
2017-06-11 05:21:20.498575 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1234 | Training started
2017-06-11 05:21:39.104221 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1234 | Training finished
2017-06-11 05:21:39.105411 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1234 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 05:21:39.105962 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1234 | Collecting samples for evaluation
2017-06-11 05:21:52.364321 EDT | -----------------------  -----------
2017-06-11 05:21:52.365062 EDT | Epoch                    1234
2017-06-11 05:21:52.365300 EDT | Iteration                1234
2017-06-11 05:21:52.365462 EDT | AverageReturn             991.806
2017-06-11 05:21:52.365619 EDT | StdReturn                 876.503
2017-06-11 05:21:52.365794 EDT | MaxReturn                3098.57
2017-06-11 05:21:52.366799 EDT | MinReturn                 229.813
2017-06-11 05:21:52.367165 EDT | AverageEsReturn           538.018
2017-06-11 05:21:52.367588 EDT | StdEsReturn               406.311
2017-06-11 05:21:52.367864 EDT | MaxEsReturn              1299.88
2017-06-11 05:21:52.368140 EDT | MinEsReturn               194.868
2017-06-11 05:21:52.368391 EDT | AverageDiscountedReturn   192.77
2017-06-11 05:21:52.369407 EDT | AverageQLoss                1.92081
2017-06-11 05:21:52.369733 EDT | AveragePolicySurr         -27.5693
2017-06-11 05:21:52.370013 EDT | AverageQ                   27.3541
2017-06-11 05:21:52.370344 EDT | AverageAbsQ                27.3727
2017-06-11 05:21:52.370670 EDT | AverageY                   27.3552
2017-06-11 05:21:52.370987 EDT | AverageAbsY                27.3625
2017-06-11 05:21:52.371292 EDT | AverageAbsQYDiff            0.463952
2017-06-11 05:21:52.371661 EDT | AverageAction               0.99921
2017-06-11 05:21:52.371981 EDT | PolicyRegParamNorm        105.625
2017-06-11 05:21:52.372299 EDT | QFunRegParamNorm          136.913
2017-06-11 05:21:52.372608 EDT | -----------------------  -----------
2017-06-11 05:21:52.373175 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1235 | Training started
2017-06-11 05:22:11.015360 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1235 | Training finished
2017-06-11 05:22:11.016191 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1235 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 05:22:11.016709 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1235 | Collecting samples for evaluation
2017-06-11 05:22:25.802126 EDT | -----------------------  -----------
2017-06-11 05:22:25.803012 EDT | Epoch                    1235
2017-06-11 05:22:25.803248 EDT | Iteration                1235
2017-06-11 05:22:25.803450 EDT | AverageReturn             565.417
2017-06-11 05:22:25.803689 EDT | StdReturn                 455.715
2017-06-11 05:22:25.803885 EDT | MaxReturn                2457.36
2017-06-11 05:22:25.804088 EDT | MinReturn                 233.057
2017-06-11 05:22:25.804280 EDT | AverageEsReturn           144.642
2017-06-11 05:22:25.804471 EDT | StdEsReturn               209.628
2017-06-11 05:22:25.804674 EDT | MaxEsReturn               753.597
2017-06-11 05:22:25.804935 EDT | MinEsReturn                10.1997
2017-06-11 05:22:25.805794 EDT | AverageDiscountedReturn   188.23
2017-06-11 05:22:25.806003 EDT | AverageQLoss                1.71772
2017-06-11 05:22:25.806229 EDT | AveragePolicySurr         -27.5852
2017-06-11 05:22:25.806423 EDT | AverageQ                   27.4017
2017-06-11 05:22:25.806675 EDT | AverageAbsQ                27.4158
2017-06-11 05:22:25.806868 EDT | AverageY                   27.4023
2017-06-11 05:22:25.807059 EDT | AverageAbsY                27.4083
2017-06-11 05:22:25.807250 EDT | AverageAbsQYDiff            0.462152
2017-06-11 05:22:25.807600 EDT | AverageAction               0.998988
2017-06-11 05:22:25.807876 EDT | PolicyRegParamNorm        105.598
2017-06-11 05:22:25.808088 EDT | QFunRegParamNorm          136.891
2017-06-11 05:22:25.808283 EDT | -----------------------  -----------
2017-06-11 05:22:25.808787 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1236 | Training started
2017-06-11 05:22:42.930487 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1236 | Training finished
2017-06-11 05:22:42.931419 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1236 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 05:22:42.931794 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1236 | Collecting samples for evaluation
2017-06-11 05:22:58.734672 EDT | -----------------------  -----------
2017-06-11 05:22:58.735470 EDT | Epoch                    1236
2017-06-11 05:22:58.735880 EDT | Iteration                1236
2017-06-11 05:22:58.736116 EDT | AverageReturn             240.339
2017-06-11 05:22:58.736304 EDT | StdReturn                  10.6476
2017-06-11 05:22:58.736489 EDT | MaxReturn                 267.873
2017-06-11 05:22:58.736672 EDT | MinReturn                 221.658
2017-06-11 05:22:58.736872 EDT | AverageEsReturn           350.67
2017-06-11 05:22:58.737051 EDT | StdEsReturn               202.708
2017-06-11 05:22:58.737230 EDT | MaxEsReturn               768.349
2017-06-11 05:22:58.737407 EDT | MinEsReturn                31.2936
2017-06-11 05:22:58.737584 EDT | AverageDiscountedReturn   135.785
2017-06-11 05:22:58.737844 EDT | AverageQLoss                2.0059
2017-06-11 05:22:58.738135 EDT | AveragePolicySurr         -27.5287
2017-06-11 05:22:58.738439 EDT | AverageQ                   27.3342
2017-06-11 05:22:58.738823 EDT | AverageAbsQ                27.352
2017-06-11 05:22:58.739194 EDT | AverageY                   27.3352
2017-06-11 05:22:58.739560 EDT | AverageAbsY                27.3425
2017-06-11 05:22:58.739904 EDT | AverageAbsQYDiff            0.492125
2017-06-11 05:22:58.740122 EDT | AverageAction               0.998907
2017-06-11 05:22:58.740308 EDT | PolicyRegParamNorm        105.658
2017-06-11 05:22:58.740491 EDT | QFunRegParamNorm          136.933
2017-06-11 05:22:58.740670 EDT | -----------------------  -----------
2017-06-11 05:22:58.740967 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1237 | Training started
2017-06-11 05:23:16.159636 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1237 | Training finished
2017-06-11 05:23:16.160362 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1237 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 05:23:16.165763 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1237 | Collecting samples for evaluation
2017-06-11 05:23:31.146892 EDT | -----------------------  -----------
2017-06-11 05:23:31.148240 EDT | Epoch                    1237
2017-06-11 05:23:31.148691 EDT | Iteration                1237
2017-06-11 05:23:31.149376 EDT | AverageReturn              87.6
2017-06-11 05:23:31.149925 EDT | StdReturn                 362.418
2017-06-11 05:23:31.150346 EDT | MaxReturn                3074.25
2017-06-11 05:23:31.150777 EDT | MinReturn                  11.762
2017-06-11 05:23:31.151241 EDT | AverageEsReturn           193.046
2017-06-11 05:23:31.151668 EDT | StdEsReturn               209.959
2017-06-11 05:23:31.152154 EDT | MaxEsReturn               671.094
2017-06-11 05:23:31.152555 EDT | MinEsReturn                11.6362
2017-06-11 05:23:31.152981 EDT | AverageDiscountedReturn    27.4003
2017-06-11 05:23:31.153592 EDT | AverageQLoss                1.83775
2017-06-11 05:23:31.154119 EDT | AveragePolicySurr         -27.5259
2017-06-11 05:23:31.154548 EDT | AverageQ                   27.3535
2017-06-11 05:23:31.155156 EDT | AverageAbsQ                27.3682
2017-06-11 05:23:31.155592 EDT | AverageY                   27.3554
2017-06-11 05:23:31.156074 EDT | AverageAbsY                27.3621
2017-06-11 05:23:31.156498 EDT | AverageAbsQYDiff            0.469749
2017-06-11 05:23:31.156986 EDT | AverageAction               0.998661
2017-06-11 05:23:31.157393 EDT | PolicyRegParamNorm        105.715
2017-06-11 05:23:31.157827 EDT | QFunRegParamNorm          136.991
2017-06-11 05:23:31.158275 EDT | -----------------------  -----------
2017-06-11 05:23:31.158863 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1238 | Training started
2017-06-11 05:23:50.021760 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1238 | Training finished
2017-06-11 05:23:50.022725 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1238 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 05:23:50.023180 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1238 | Collecting samples for evaluation
2017-06-11 05:24:04.531205 EDT | -----------------------  -----------
2017-06-11 05:24:04.532244 EDT | Epoch                    1238
2017-06-11 05:24:04.532508 EDT | Iteration                1238
2017-06-11 05:24:04.532763 EDT | AverageReturn              34.2911
2017-06-11 05:24:04.533035 EDT | StdReturn                 210.374
2017-06-11 05:24:04.533482 EDT | MaxReturn                3181.03
2017-06-11 05:24:04.533890 EDT | MinReturn                  13.2855
2017-06-11 05:24:04.534248 EDT | AverageEsReturn           218.486
2017-06-11 05:24:04.534609 EDT | StdEsReturn               205.497
2017-06-11 05:24:04.534997 EDT | MaxEsReturn               586.034
2017-06-11 05:24:04.535355 EDT | MinEsReturn                 9.58918
2017-06-11 05:24:04.535718 EDT | AverageDiscountedReturn    16.5798
2017-06-11 05:24:04.536086 EDT | AverageQLoss                1.84727
2017-06-11 05:24:04.536419 EDT | AveragePolicySurr         -27.541
2017-06-11 05:24:04.536804 EDT | AverageQ                   27.3544
2017-06-11 05:24:04.537237 EDT | AverageAbsQ                27.367
2017-06-11 05:24:04.537626 EDT | AverageY                   27.3553
2017-06-11 05:24:04.538067 EDT | AverageAbsY                27.3612
2017-06-11 05:24:04.538443 EDT | AverageAbsQYDiff            0.47374
2017-06-11 05:24:04.538879 EDT | AverageAction               0.999738
2017-06-11 05:24:04.539316 EDT | PolicyRegParamNorm        105.696
2017-06-11 05:24:04.539748 EDT | QFunRegParamNorm          137.024
2017-06-11 05:24:04.540169 EDT | -----------------------  -----------
2017-06-11 05:24:04.540778 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1239 | Training started
2017-06-11 05:24:22.693005 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1239 | Training finished
2017-06-11 05:24:22.693848 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1239 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 05:24:22.694269 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1239 | Collecting samples for evaluation
2017-06-11 05:24:36.433626 EDT | -----------------------  -----------
2017-06-11 05:24:36.435475 EDT | Epoch                    1239
2017-06-11 05:24:36.435688 EDT | Iteration                1239
2017-06-11 05:24:36.435931 EDT | AverageReturn             251.451
2017-06-11 05:24:36.436102 EDT | StdReturn                 710.801
2017-06-11 05:24:36.436268 EDT | MaxReturn                3298.43
2017-06-11 05:24:36.436548 EDT | MinReturn                  13.6906
2017-06-11 05:24:36.436719 EDT | AverageEsReturn           342.849
2017-06-11 05:24:36.436884 EDT | StdEsReturn               498.929
2017-06-11 05:24:36.437047 EDT | MaxEsReturn              1538.76
2017-06-11 05:24:36.437314 EDT | MinEsReturn                11.0088
2017-06-11 05:24:36.437494 EDT | AverageDiscountedReturn    48.0438
2017-06-11 05:24:36.437658 EDT | AverageQLoss                2.05123
2017-06-11 05:24:36.437831 EDT | AveragePolicySurr         -27.4991
2017-06-11 05:24:36.437992 EDT | AverageQ                   27.3295
2017-06-11 05:24:36.438151 EDT | AverageAbsQ                27.3441
2017-06-11 05:24:36.438311 EDT | AverageY                   27.3315
2017-06-11 05:24:36.438580 EDT | AverageAbsY                27.3392
2017-06-11 05:24:36.438746 EDT | AverageAbsQYDiff            0.494326
2017-06-11 05:24:36.438907 EDT | AverageAction               0.999082
2017-06-11 05:24:36.439066 EDT | PolicyRegParamNorm        105.705
2017-06-11 05:24:36.439225 EDT | QFunRegParamNorm          137.027
2017-06-11 05:24:36.439463 EDT | -----------------------  -----------
2017-06-11 05:24:36.439792 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1240 | Training started
2017-06-11 05:24:53.909920 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1240 | Training finished
2017-06-11 05:24:53.910563 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1240 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 05:24:53.910786 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1240 | Collecting samples for evaluation
2017-06-11 05:25:08.140572 EDT | -----------------------  -----------
2017-06-11 05:25:08.143551 EDT | Epoch                    1240
2017-06-11 05:25:08.143917 EDT | Iteration                1240
2017-06-11 05:25:08.144248 EDT | AverageReturn            2778.29
2017-06-11 05:25:08.144514 EDT | StdReturn                 889.774
2017-06-11 05:25:08.144829 EDT | MaxReturn                3425.11
2017-06-11 05:25:08.145162 EDT | MinReturn                 640.039
2017-06-11 05:25:08.145492 EDT | AverageEsReturn           349.06
2017-06-11 05:25:08.145775 EDT | StdEsReturn               258.562
2017-06-11 05:25:08.146055 EDT | MaxEsReturn               870.949
2017-06-11 05:25:08.146380 EDT | MinEsReturn                13.8301
2017-06-11 05:25:08.150996 EDT | AverageDiscountedReturn   252.959
2017-06-11 05:25:08.151373 EDT | AverageQLoss                1.94209
2017-06-11 05:25:08.151740 EDT | AveragePolicySurr         -27.4684
2017-06-11 05:25:08.152091 EDT | AverageQ                   27.2678
2017-06-11 05:25:08.152438 EDT | AverageAbsQ                27.2849
2017-06-11 05:25:08.152785 EDT | AverageY                   27.2693
2017-06-11 05:25:08.153128 EDT | AverageAbsY                27.2781
2017-06-11 05:25:08.153493 EDT | AverageAbsQYDiff            0.48474
2017-06-11 05:25:08.153853 EDT | AverageAction               0.999034
2017-06-11 05:25:08.154195 EDT | PolicyRegParamNorm        105.692
2017-06-11 05:25:08.154553 EDT | QFunRegParamNorm          137.041
2017-06-11 05:25:08.154907 EDT | -----------------------  -----------
2017-06-11 05:25:08.155414 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1241 | Training started
2017-06-11 05:25:25.669273 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1241 | Training finished
2017-06-11 05:25:25.669599 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1241 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 05:25:25.669859 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1241 | Collecting samples for evaluation
2017-06-11 05:25:41.333086 EDT | -----------------------  -----------
2017-06-11 05:25:41.336250 EDT | Epoch                    1241
2017-06-11 05:25:41.336659 EDT | Iteration                1241
2017-06-11 05:25:41.336961 EDT | AverageReturn            3215.72
2017-06-11 05:25:41.337349 EDT | StdReturn                  85.5985
2017-06-11 05:25:41.337687 EDT | MaxReturn                3309.06
2017-06-11 05:25:41.338025 EDT | MinReturn                2981.68
2017-06-11 05:25:41.338345 EDT | AverageEsReturn           498.806
2017-06-11 05:25:41.338640 EDT | StdEsReturn               384.546
2017-06-11 05:25:41.338830 EDT | MaxEsReturn              1192.33
2017-06-11 05:25:41.339154 EDT | MinEsReturn               104.996
2017-06-11 05:25:41.339465 EDT | AverageDiscountedReturn   253.805
2017-06-11 05:25:41.342012 EDT | AverageQLoss                2.02124
2017-06-11 05:25:41.342839 EDT | AveragePolicySurr         -27.4662
2017-06-11 05:25:41.345374 EDT | AverageQ                   27.2528
2017-06-11 05:25:41.345768 EDT | AverageAbsQ                27.2719
2017-06-11 05:25:41.346104 EDT | AverageY                   27.2534
2017-06-11 05:25:41.346374 EDT | AverageAbsY                27.2618
2017-06-11 05:25:41.346535 EDT | AverageAbsQYDiff            0.485099
2017-06-11 05:25:41.346689 EDT | AverageAction               0.999196
2017-06-11 05:25:41.346838 EDT | PolicyRegParamNorm        105.764
2017-06-11 05:25:41.346987 EDT | QFunRegParamNorm          137.075
2017-06-11 05:25:41.347135 EDT | -----------------------  -----------
2017-06-11 05:25:41.347389 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1242 | Training started
2017-06-11 05:25:59.955135 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1242 | Training finished
2017-06-11 05:25:59.958610 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1242 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 05:25:59.958905 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1242 | Collecting samples for evaluation
2017-06-11 05:26:13.374660 EDT | -----------------------  -----------
2017-06-11 05:26:13.375442 EDT | Epoch                    1242
2017-06-11 05:26:13.378172 EDT | Iteration                1242
2017-06-11 05:26:13.378385 EDT | AverageReturn            1317.71
2017-06-11 05:26:13.378575 EDT | StdReturn                 929.873
2017-06-11 05:26:13.378768 EDT | MaxReturn                3599.02
2017-06-11 05:26:13.378950 EDT | MinReturn                 726.184
2017-06-11 05:26:13.379167 EDT | AverageEsReturn           476.789
2017-06-11 05:26:13.379479 EDT | StdEsReturn               275.793
2017-06-11 05:26:13.379691 EDT | MaxEsReturn               820.752
2017-06-11 05:26:13.379880 EDT | MinEsReturn                43.0764
2017-06-11 05:26:13.380062 EDT | AverageDiscountedReturn   254.101
2017-06-11 05:26:13.380335 EDT | AverageQLoss                1.67694
2017-06-11 05:26:13.380518 EDT | AveragePolicySurr         -27.4555
2017-06-11 05:26:13.380739 EDT | AverageQ                   27.2662
2017-06-11 05:26:13.381076 EDT | AverageAbsQ                27.2829
2017-06-11 05:26:13.382169 EDT | AverageY                   27.2664
2017-06-11 05:26:13.383087 EDT | AverageAbsY                27.2748
2017-06-11 05:26:13.384298 EDT | AverageAbsQYDiff            0.4623
2017-06-11 05:26:13.384650 EDT | AverageAction               0.999268
2017-06-11 05:26:13.384840 EDT | PolicyRegParamNorm        105.745
2017-06-11 05:26:13.385047 EDT | QFunRegParamNorm          137.127
2017-06-11 05:26:13.385237 EDT | -----------------------  -----------
2017-06-11 05:26:13.385541 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1243 | Training started
2017-06-11 05:26:31.302027 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1243 | Training finished
2017-06-11 05:26:31.304215 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1243 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 05:26:31.305419 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1243 | Collecting samples for evaluation
2017-06-11 05:26:45.619444 EDT | -----------------------  -----------
2017-06-11 05:26:45.620602 EDT | Epoch                    1243
2017-06-11 05:26:45.621080 EDT | Iteration                1243
2017-06-11 05:26:45.621429 EDT | AverageReturn            3140.81
2017-06-11 05:26:45.621775 EDT | StdReturn                  49.6389
2017-06-11 05:26:45.622122 EDT | MaxReturn                3214.69
2017-06-11 05:26:45.622485 EDT | MinReturn                3083.76
2017-06-11 05:26:45.622832 EDT | AverageEsReturn           460.181
2017-06-11 05:26:45.623176 EDT | StdEsReturn               415.215
2017-06-11 05:26:45.623519 EDT | MaxEsReturn              1287.4
2017-06-11 05:26:45.623864 EDT | MinEsReturn               134.529
2017-06-11 05:26:45.624201 EDT | AverageDiscountedReturn   252.565
2017-06-11 05:26:45.624544 EDT | AverageQLoss                2.00049
2017-06-11 05:26:45.624886 EDT | AveragePolicySurr         -27.4338
2017-06-11 05:26:45.625229 EDT | AverageQ                   27.2315
2017-06-11 05:26:45.625571 EDT | AverageAbsQ                27.2491
2017-06-11 05:26:45.625922 EDT | AverageY                   27.2325
2017-06-11 05:26:45.626265 EDT | AverageAbsY                27.2429
2017-06-11 05:26:45.626608 EDT | AverageAbsQYDiff            0.474293
2017-06-11 05:26:45.626948 EDT | AverageAction               0.999479
2017-06-11 05:26:45.627291 EDT | PolicyRegParamNorm        105.864
2017-06-11 05:26:45.627631 EDT | QFunRegParamNorm          137.194
2017-06-11 05:26:45.627969 EDT | -----------------------  -----------
2017-06-11 05:26:45.631752 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1244 | Training started
2017-06-11 05:27:04.690789 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1244 | Training finished
2017-06-11 05:27:04.691586 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1244 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 05:27:04.691815 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1244 | Collecting samples for evaluation
2017-06-11 05:27:18.623157 EDT | -----------------------  -----------
2017-06-11 05:27:18.626810 EDT | Epoch                    1244
2017-06-11 05:27:18.627115 EDT | Iteration                1244
2017-06-11 05:27:18.627291 EDT | AverageReturn            2094.48
2017-06-11 05:27:18.627463 EDT | StdReturn                 791.606
2017-06-11 05:27:18.627747 EDT | MaxReturn                2986.45
2017-06-11 05:27:18.628041 EDT | MinReturn                1087.64
2017-06-11 05:27:18.628297 EDT | AverageEsReturn           577.749
2017-06-11 05:27:18.628463 EDT | StdEsReturn               501.322
2017-06-11 05:27:18.628627 EDT | MaxEsReturn              1568.91
2017-06-11 05:27:18.628787 EDT | MinEsReturn               204.887
2017-06-11 05:27:18.628947 EDT | AverageDiscountedReturn   236.198
2017-06-11 05:27:18.629151 EDT | AverageQLoss                1.87425
2017-06-11 05:27:18.629312 EDT | AveragePolicySurr         -27.4387
2017-06-11 05:27:18.629515 EDT | AverageQ                   27.2442
2017-06-11 05:27:18.629677 EDT | AverageAbsQ                27.2584
2017-06-11 05:27:18.629921 EDT | AverageY                   27.2445
2017-06-11 05:27:18.630082 EDT | AverageAbsY                27.2506
2017-06-11 05:27:18.630304 EDT | AverageAbsQYDiff            0.470903
2017-06-11 05:27:18.630467 EDT | AverageAction               0.999294
2017-06-11 05:27:18.630705 EDT | PolicyRegParamNorm        105.893
2017-06-11 05:27:18.630906 EDT | QFunRegParamNorm          137.215
2017-06-11 05:27:18.631069 EDT | -----------------------  -----------
2017-06-11 05:27:18.631343 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1245 | Training started
2017-06-11 05:27:37.098210 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1245 | Training finished
2017-06-11 05:27:37.098849 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1245 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 05:27:37.099389 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1245 | Collecting samples for evaluation
2017-06-11 05:27:52.757315 EDT | -----------------------  -----------
2017-06-11 05:27:52.759509 EDT | Epoch                    1245
2017-06-11 05:27:52.759807 EDT | Iteration                1245
2017-06-11 05:27:52.760134 EDT | AverageReturn            2268.66
2017-06-11 05:27:52.760453 EDT | StdReturn                1002.31
2017-06-11 05:27:52.760720 EDT | MaxReturn                3188.04
2017-06-11 05:27:52.761032 EDT | MinReturn                 238.541
2017-06-11 05:27:52.761369 EDT | AverageEsReturn           338.313
2017-06-11 05:27:52.761691 EDT | StdEsReturn               188.19
2017-06-11 05:27:52.762019 EDT | MaxEsReturn               647.25
2017-06-11 05:27:52.762460 EDT | MinEsReturn               146.01
2017-06-11 05:27:52.762722 EDT | AverageDiscountedReturn   234.034
2017-06-11 05:27:52.763037 EDT | AverageQLoss                1.86324
2017-06-11 05:27:52.763352 EDT | AveragePolicySurr         -27.3663
2017-06-11 05:27:52.763618 EDT | AverageQ                   27.1648
2017-06-11 05:27:52.763912 EDT | AverageAbsQ                27.1827
2017-06-11 05:27:52.764259 EDT | AverageY                   27.1667
2017-06-11 05:27:52.764595 EDT | AverageAbsY                27.1745
2017-06-11 05:27:52.764931 EDT | AverageAbsQYDiff            0.458594
2017-06-11 05:27:52.765270 EDT | AverageAction               0.999118
2017-06-11 05:27:52.765610 EDT | PolicyRegParamNorm        105.887
2017-06-11 05:27:52.765967 EDT | QFunRegParamNorm          137.281
2017-06-11 05:27:52.766310 EDT | -----------------------  -----------
2017-06-11 05:27:52.766822 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1246 | Training started
2017-06-11 05:28:10.093641 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1246 | Training finished
2017-06-11 05:28:10.094766 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1246 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 05:28:10.095323 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1246 | Collecting samples for evaluation
2017-06-11 05:28:25.666802 EDT | -----------------------  -----------
2017-06-11 05:28:25.667381 EDT | Epoch                    1246
2017-06-11 05:28:25.667748 EDT | Iteration                1246
2017-06-11 05:28:25.668108 EDT | AverageReturn            1855.56
2017-06-11 05:28:25.668468 EDT | StdReturn                1035.13
2017-06-11 05:28:25.668826 EDT | MaxReturn                3482.38
2017-06-11 05:28:25.669180 EDT | MinReturn                 744.985
2017-06-11 05:28:25.669533 EDT | AverageEsReturn           444.823
2017-06-11 05:28:25.669899 EDT | StdEsReturn               229.718
2017-06-11 05:28:25.670256 EDT | MaxEsReturn               854.542
2017-06-11 05:28:25.670611 EDT | MinEsReturn                12.3581
2017-06-11 05:28:25.673746 EDT | AverageDiscountedReturn   251.935
2017-06-11 05:28:25.676310 EDT | AverageQLoss                1.87301
2017-06-11 05:28:25.676775 EDT | AveragePolicySurr         -27.4225
2017-06-11 05:28:25.677222 EDT | AverageQ                   27.2229
2017-06-11 05:28:25.677814 EDT | AverageAbsQ                27.2386
2017-06-11 05:28:25.678484 EDT | AverageY                   27.2246
2017-06-11 05:28:25.678894 EDT | AverageAbsY                27.2301
2017-06-11 05:28:25.679360 EDT | AverageAbsQYDiff            0.468837
2017-06-11 05:28:25.679791 EDT | AverageAction               0.999304
2017-06-11 05:28:25.680207 EDT | PolicyRegParamNorm        105.886
2017-06-11 05:28:25.680555 EDT | QFunRegParamNorm          137.361
2017-06-11 05:28:25.680969 EDT | -----------------------  -----------
2017-06-11 05:28:25.681565 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1247 | Training started
2017-06-11 05:28:43.843269 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1247 | Training finished
2017-06-11 05:28:43.844131 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1247 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 05:28:43.844419 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1247 | Collecting samples for evaluation
2017-06-11 05:28:59.422018 EDT | -----------------------  -----------
2017-06-11 05:28:59.424163 EDT | Epoch                    1247
2017-06-11 05:28:59.424451 EDT | Iteration                1247
2017-06-11 05:28:59.424718 EDT | AverageReturn             387.112
2017-06-11 05:28:59.424987 EDT | StdReturn                 281.385
2017-06-11 05:28:59.425241 EDT | MaxReturn                1089.98
2017-06-11 05:28:59.425499 EDT | MinReturn                   8.97367
2017-06-11 05:28:59.425755 EDT | AverageEsReturn           598.258
2017-06-11 05:28:59.426012 EDT | StdEsReturn               319.23
2017-06-11 05:28:59.426261 EDT | MaxEsReturn               904.614
2017-06-11 05:28:59.426503 EDT | MinEsReturn                62.1747
2017-06-11 05:28:59.426743 EDT | AverageDiscountedReturn   135.165
2017-06-11 05:28:59.427093 EDT | AverageQLoss                1.48271
2017-06-11 05:28:59.427346 EDT | AveragePolicySurr         -27.4408
2017-06-11 05:28:59.427619 EDT | AverageQ                   27.2688
2017-06-11 05:28:59.427896 EDT | AverageAbsQ                27.2838
2017-06-11 05:28:59.428161 EDT | AverageY                   27.2713
2017-06-11 05:28:59.428406 EDT | AverageAbsY                27.278
2017-06-11 05:28:59.428647 EDT | AverageAbsQYDiff            0.434622
2017-06-11 05:28:59.428894 EDT | AverageAction               0.999407
2017-06-11 05:28:59.429136 EDT | PolicyRegParamNorm        105.893
2017-06-11 05:28:59.429397 EDT | QFunRegParamNorm          137.403
2017-06-11 05:28:59.429639 EDT | -----------------------  -----------
2017-06-11 05:28:59.430033 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1248 | Training started
2017-06-11 05:29:17.127038 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1248 | Training finished
2017-06-11 05:29:17.127925 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1248 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 05:29:17.128258 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1248 | Collecting samples for evaluation
2017-06-11 05:29:33.000494 EDT | -----------------------  ------------
2017-06-11 05:29:33.002029 EDT | Epoch                    1248
2017-06-11 05:29:33.002666 EDT | Iteration                1248
2017-06-11 05:29:33.002863 EDT | AverageReturn               5.98293
2017-06-11 05:29:33.004209 EDT | StdReturn                   0.0912286
2017-06-11 05:29:33.004720 EDT | MaxReturn                   6.24945
2017-06-11 05:29:33.004909 EDT | MinReturn                   5.7861
2017-06-11 05:29:33.005378 EDT | AverageEsReturn            81.514
2017-06-11 05:29:33.005563 EDT | StdEsReturn               127.469
2017-06-11 05:29:33.005756 EDT | MaxEsReturn               475.465
2017-06-11 05:29:33.006239 EDT | MinEsReturn                 5.88725
2017-06-11 05:29:33.006465 EDT | AverageDiscountedReturn     5.81586
2017-06-11 05:29:33.006684 EDT | AverageQLoss                1.97021
2017-06-11 05:29:33.006867 EDT | AveragePolicySurr         -27.3333
2017-06-11 05:29:33.007077 EDT | AverageQ                   27.1773
2017-06-11 05:29:33.007260 EDT | AverageAbsQ                27.1935
2017-06-11 05:29:33.007440 EDT | AverageY                   27.1766
2017-06-11 05:29:33.007622 EDT | AverageAbsY                27.1823
2017-06-11 05:29:33.007802 EDT | AverageAbsQYDiff            0.481258
2017-06-11 05:29:33.007981 EDT | AverageAction               0.999222
2017-06-11 05:29:33.008335 EDT | PolicyRegParamNorm        105.948
2017-06-11 05:29:33.008521 EDT | QFunRegParamNorm          137.471
2017-06-11 05:29:33.008703 EDT | -----------------------  ------------
2017-06-11 05:29:33.009037 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1249 | Training started
2017-06-11 05:29:51.731076 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1249 | Training finished
2017-06-11 05:29:51.732009 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1249 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 05:29:51.732271 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1249 | Collecting samples for evaluation
2017-06-11 05:30:06.191174 EDT | -----------------------  -----------
2017-06-11 05:30:06.192821 EDT | Epoch                    1249
2017-06-11 05:30:06.193131 EDT | Iteration                1249
2017-06-11 05:30:06.193480 EDT | AverageReturn            1793.69
2017-06-11 05:30:06.193842 EDT | StdReturn                1310.09
2017-06-11 05:30:06.194193 EDT | MaxReturn                3259.32
2017-06-11 05:30:06.194541 EDT | MinReturn                  12.8205
2017-06-11 05:30:06.194867 EDT | AverageEsReturn            70.7957
2017-06-11 05:30:06.195214 EDT | StdEsReturn               141.284
2017-06-11 05:30:06.195564 EDT | MaxEsReturn               657.488
2017-06-11 05:30:06.196148 EDT | MinEsReturn                 5.83347
2017-06-11 05:30:06.198001 EDT | AverageDiscountedReturn   181.633
2017-06-11 05:30:06.198365 EDT | AverageQLoss                2.38508
2017-06-11 05:30:06.198712 EDT | AveragePolicySurr         -27.2657
2017-06-11 05:30:06.199045 EDT | AverageQ                   27.1055
2017-06-11 05:30:06.199396 EDT | AverageAbsQ                27.1227
2017-06-11 05:30:06.199737 EDT | AverageY                   27.1078
2017-06-11 05:30:06.200075 EDT | AverageAbsY                27.1137
2017-06-11 05:30:06.200419 EDT | AverageAbsQYDiff            0.518406
2017-06-11 05:30:06.200775 EDT | AverageAction               0.999202
2017-06-11 05:30:06.201118 EDT | PolicyRegParamNorm        105.889
2017-06-11 05:30:06.201458 EDT | QFunRegParamNorm          137.477
2017-06-11 05:30:06.201811 EDT | -----------------------  -----------
2017-06-11 05:30:06.202460 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1250 | Training started
2017-06-11 05:30:25.221448 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1250 | Training finished
2017-06-11 05:30:25.221989 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1250 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 05:30:25.222449 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1250 | Collecting samples for evaluation
2017-06-11 05:30:39.581109 EDT | -----------------------  -----------
2017-06-11 05:30:39.581776 EDT | Epoch                    1250
2017-06-11 05:30:39.581991 EDT | Iteration                1250
2017-06-11 05:30:39.582182 EDT | AverageReturn            1056.14
2017-06-11 05:30:39.582439 EDT | StdReturn                 842.356
2017-06-11 05:30:39.582623 EDT | MaxReturn                3596.07
2017-06-11 05:30:39.582806 EDT | MinReturn                 371.266
2017-06-11 05:30:39.583094 EDT | AverageEsReturn           284.08
2017-06-11 05:30:39.583287 EDT | StdEsReturn               207.786
2017-06-11 05:30:39.583473 EDT | MaxEsReturn               696.552
2017-06-11 05:30:39.583791 EDT | MinEsReturn                 8.57304
2017-06-11 05:30:39.584057 EDT | AverageDiscountedReturn   229.005
2017-06-11 05:30:39.584442 EDT | AverageQLoss                2.18253
2017-06-11 05:30:39.584630 EDT | AveragePolicySurr         -27.2571
2017-06-11 05:30:39.584887 EDT | AverageQ                   27.072
2017-06-11 05:30:39.585779 EDT | AverageAbsQ                27.0905
2017-06-11 05:30:39.586192 EDT | AverageY                   27.073
2017-06-11 05:30:39.586466 EDT | AverageAbsY                27.0818
2017-06-11 05:30:39.586915 EDT | AverageAbsQYDiff            0.493326
2017-06-11 05:30:39.587200 EDT | AverageAction               0.999448
2017-06-11 05:30:39.587432 EDT | PolicyRegParamNorm        105.814
2017-06-11 05:30:39.587623 EDT | QFunRegParamNorm          137.506
2017-06-11 05:30:39.587804 EDT | -----------------------  -----------
2017-06-11 05:30:39.588101 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1251 | Training started
2017-06-11 05:30:57.594748 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1251 | Training finished
2017-06-11 05:30:57.598765 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1251 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 05:30:57.599235 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1251 | Collecting samples for evaluation
2017-06-11 05:31:12.154734 EDT | -----------------------  -----------
2017-06-11 05:31:12.156070 EDT | Epoch                    1251
2017-06-11 05:31:12.156474 EDT | Iteration                1251
2017-06-11 05:31:12.157683 EDT | AverageReturn            2075.12
2017-06-11 05:31:12.158062 EDT | StdReturn                 890.443
2017-06-11 05:31:12.159810 EDT | MaxReturn                2927.6
2017-06-11 05:31:12.160184 EDT | MinReturn                 299.601
2017-06-11 05:31:12.164062 EDT | AverageEsReturn           378.612
2017-06-11 05:31:12.164428 EDT | StdEsReturn               252.554
2017-06-11 05:31:12.164790 EDT | MaxEsReturn               873.521
2017-06-11 05:31:12.165183 EDT | MinEsReturn               123.309
2017-06-11 05:31:12.165544 EDT | AverageDiscountedReturn   223.134
2017-06-11 05:31:12.165914 EDT | AverageQLoss                1.98796
2017-06-11 05:31:12.166261 EDT | AveragePolicySurr         -27.2052
2017-06-11 05:31:12.166793 EDT | AverageQ                   27.0139
2017-06-11 05:31:12.171620 EDT | AverageAbsQ                27.027
2017-06-11 05:31:12.171989 EDT | AverageY                   27.0153
2017-06-11 05:31:12.172479 EDT | AverageAbsY                27.0194
2017-06-11 05:31:12.172843 EDT | AverageAbsQYDiff            0.476839
2017-06-11 05:31:12.173202 EDT | AverageAction               0.99934
2017-06-11 05:31:12.175124 EDT | PolicyRegParamNorm        105.845
2017-06-11 05:31:12.175441 EDT | QFunRegParamNorm          137.554
2017-06-11 05:31:12.175803 EDT | -----------------------  -----------
2017-06-11 05:31:12.176332 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1252 | Training started
2017-06-11 05:31:30.933042 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1252 | Training finished
2017-06-11 05:31:30.933746 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1252 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 05:31:30.933966 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1252 | Collecting samples for evaluation
2017-06-11 05:31:47.030125 EDT | -----------------------  -----------
2017-06-11 05:31:47.031019 EDT | Epoch                    1252
2017-06-11 05:31:47.031332 EDT | Iteration                1252
2017-06-11 05:31:47.031630 EDT | AverageReturn             413.424
2017-06-11 05:31:47.031924 EDT | StdReturn                 212.583
2017-06-11 05:31:47.032214 EDT | MaxReturn                1304.68
2017-06-11 05:31:47.032504 EDT | MinReturn                 254.172
2017-06-11 05:31:47.032794 EDT | AverageEsReturn           317.085
2017-06-11 05:31:47.033082 EDT | StdEsReturn               242.371
2017-06-11 05:31:47.033373 EDT | MaxEsReturn               695.479
2017-06-11 05:31:47.033661 EDT | MinEsReturn                21.5466
2017-06-11 05:31:47.033961 EDT | AverageDiscountedReturn   170.937
2017-06-11 05:31:47.034250 EDT | AverageQLoss                1.82264
2017-06-11 05:31:47.034538 EDT | AveragePolicySurr         -27.2622
2017-06-11 05:31:47.034826 EDT | AverageQ                   27.0709
2017-06-11 05:31:47.035114 EDT | AverageAbsQ                27.0906
2017-06-11 05:31:47.035400 EDT | AverageY                   27.0707
2017-06-11 05:31:47.035689 EDT | AverageAbsY                27.0805
2017-06-11 05:31:47.035977 EDT | AverageAbsQYDiff            0.458451
2017-06-11 05:31:47.036263 EDT | AverageAction               0.999415
2017-06-11 05:31:47.036549 EDT | PolicyRegParamNorm        105.791
2017-06-11 05:31:47.036836 EDT | QFunRegParamNorm          137.572
2017-06-11 05:31:47.037123 EDT | -----------------------  -----------
2017-06-11 05:31:47.037559 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1253 | Training started
2017-06-11 05:32:06.715684 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1253 | Training finished
2017-06-11 05:32:06.716264 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1253 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 05:32:06.716446 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1253 | Collecting samples for evaluation
2017-06-11 05:32:21.913347 EDT | -----------------------  -----------
2017-06-11 05:32:21.914529 EDT | Epoch                    1253
2017-06-11 05:32:21.915002 EDT | Iteration                1253
2017-06-11 05:32:21.915447 EDT | AverageReturn            1147.3
2017-06-11 05:32:21.915894 EDT | StdReturn                 848.991
2017-06-11 05:32:21.916350 EDT | MaxReturn                2870.14
2017-06-11 05:32:21.916797 EDT | MinReturn                 308.712
2017-06-11 05:32:21.917241 EDT | AverageEsReturn           209.712
2017-06-11 05:32:21.917683 EDT | StdEsReturn               126.033
2017-06-11 05:32:21.918143 EDT | MaxEsReturn               383.307
2017-06-11 05:32:21.918583 EDT | MinEsReturn                64.8302
2017-06-11 05:32:21.919021 EDT | AverageDiscountedReturn   209.806
2017-06-11 05:32:21.920455 EDT | AverageQLoss                1.79769
2017-06-11 05:32:21.920922 EDT | AveragePolicySurr         -27.2398
2017-06-11 05:32:21.921369 EDT | AverageQ                   27.0579
2017-06-11 05:32:21.921987 EDT | AverageAbsQ                27.0734
2017-06-11 05:32:21.922422 EDT | AverageY                   27.0613
2017-06-11 05:32:21.922767 EDT | AverageAbsY                27.0679
2017-06-11 05:32:21.923108 EDT | AverageAbsQYDiff            0.452341
2017-06-11 05:32:21.923447 EDT | AverageAction               0.999405
2017-06-11 05:32:21.923786 EDT | PolicyRegParamNorm        105.844
2017-06-11 05:32:21.924127 EDT | QFunRegParamNorm          137.607
2017-06-11 05:32:21.924464 EDT | -----------------------  -----------
2017-06-11 05:32:21.924978 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1254 | Training started
2017-06-11 05:32:39.849213 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1254 | Training finished
2017-06-11 05:32:39.926322 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1254 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 05:32:39.926822 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1254 | Collecting samples for evaluation
2017-06-11 05:32:55.197921 EDT | -----------------------  -----------
2017-06-11 05:32:55.198891 EDT | Epoch                    1254
2017-06-11 05:32:55.199059 EDT | Iteration                1254
2017-06-11 05:32:55.199217 EDT | AverageReturn             753.404
2017-06-11 05:32:55.199373 EDT | StdReturn                 570.451
2017-06-11 05:32:55.199529 EDT | MaxReturn                2491.97
2017-06-11 05:32:55.199680 EDT | MinReturn                 276.326
2017-06-11 05:32:55.199830 EDT | AverageEsReturn           556.015
2017-06-11 05:32:55.199980 EDT | StdEsReturn               244.054
2017-06-11 05:32:55.200136 EDT | MaxEsReturn               906.763
2017-06-11 05:32:55.200320 EDT | MinEsReturn               275.422
2017-06-11 05:32:55.200516 EDT | AverageDiscountedReturn   205.399
2017-06-11 05:32:55.200669 EDT | AverageQLoss                1.57393
2017-06-11 05:32:55.200821 EDT | AveragePolicySurr         -27.2289
2017-06-11 05:32:55.200972 EDT | AverageQ                   27.0376
2017-06-11 05:32:55.201122 EDT | AverageAbsQ                27.0547
2017-06-11 05:32:55.201386 EDT | AverageY                   27.0392
2017-06-11 05:32:55.201650 EDT | AverageAbsY                27.0475
2017-06-11 05:32:55.201821 EDT | AverageAbsQYDiff            0.445598
2017-06-11 05:32:55.201973 EDT | AverageAction               0.999409
2017-06-11 05:32:55.202124 EDT | PolicyRegParamNorm        105.859
2017-06-11 05:32:55.202344 EDT | QFunRegParamNorm          137.6
2017-06-11 05:32:55.202516 EDT | -----------------------  -----------
2017-06-11 05:32:55.203779 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1255 | Training started
2017-06-11 05:33:12.625051 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1255 | Training finished
2017-06-11 05:33:12.625654 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1255 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 05:33:12.625877 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1255 | Collecting samples for evaluation
2017-06-11 05:33:28.743299 EDT | -----------------------  -----------
2017-06-11 05:33:28.744300 EDT | Epoch                    1255
2017-06-11 05:33:28.744687 EDT | Iteration                1255
2017-06-11 05:33:28.745066 EDT | AverageReturn            1976.02
2017-06-11 05:33:28.745431 EDT | StdReturn                1120.93
2017-06-11 05:33:28.745818 EDT | MaxReturn                3253.42
2017-06-11 05:33:28.746201 EDT | MinReturn                 333.26
2017-06-11 05:33:28.746559 EDT | AverageEsReturn           343.94
2017-06-11 05:33:28.747043 EDT | StdEsReturn               236.167
2017-06-11 05:33:28.747516 EDT | MaxEsReturn               762.227
2017-06-11 05:33:28.747962 EDT | MinEsReturn                72.538
2017-06-11 05:33:28.748428 EDT | AverageDiscountedReturn   235.853
2017-06-11 05:33:28.748872 EDT | AverageQLoss                1.97216
2017-06-11 05:33:28.749326 EDT | AveragePolicySurr         -27.1291
2017-06-11 05:33:28.749785 EDT | AverageQ                   26.9644
2017-06-11 05:33:28.750227 EDT | AverageAbsQ                26.9788
2017-06-11 05:33:28.751206 EDT | AverageY                   26.9657
2017-06-11 05:33:28.751690 EDT | AverageAbsY                26.9722
2017-06-11 05:33:28.752427 EDT | AverageAbsQYDiff            0.464601
2017-06-11 05:33:28.752868 EDT | AverageAction               0.99962
2017-06-11 05:33:28.753310 EDT | PolicyRegParamNorm        105.911
2017-06-11 05:33:28.756100 EDT | QFunRegParamNorm          137.617
2017-06-11 05:33:28.756464 EDT | -----------------------  -----------
2017-06-11 05:33:28.757096 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1256 | Training started
2017-06-11 05:33:46.558032 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1256 | Training finished
2017-06-11 05:33:46.559176 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1256 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 05:33:46.559583 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1256 | Collecting samples for evaluation
2017-06-11 05:34:00.718088 EDT | -----------------------  -----------
2017-06-11 05:34:00.719797 EDT | Epoch                    1256
2017-06-11 05:34:00.720562 EDT | Iteration                1256
2017-06-11 05:34:00.721529 EDT | AverageReturn            1192.53
2017-06-11 05:34:00.722467 EDT | StdReturn                 826.171
2017-06-11 05:34:00.724685 EDT | MaxReturn                3030.98
2017-06-11 05:34:00.725624 EDT | MinReturn                 300.381
2017-06-11 05:34:00.726538 EDT | AverageEsReturn           434.945
2017-06-11 05:34:00.727433 EDT | StdEsReturn               385.079
2017-06-11 05:34:00.728313 EDT | MaxEsReturn              1092.92
2017-06-11 05:34:00.729228 EDT | MinEsReturn                42.3289
2017-06-11 05:34:00.730133 EDT | AverageDiscountedReturn   219.293
2017-06-11 05:34:00.731014 EDT | AverageQLoss                1.72923
2017-06-11 05:34:00.731879 EDT | AveragePolicySurr         -27.1417
2017-06-11 05:34:00.732773 EDT | AverageQ                   26.9428
2017-06-11 05:34:00.733653 EDT | AverageAbsQ                26.961
2017-06-11 05:34:00.734736 EDT | AverageY                   26.9447
2017-06-11 05:34:00.735657 EDT | AverageAbsY                26.9511
2017-06-11 05:34:00.736519 EDT | AverageAbsQYDiff            0.452441
2017-06-11 05:34:00.737594 EDT | AverageAction               0.99944
2017-06-11 05:34:00.738529 EDT | PolicyRegParamNorm        105.903
2017-06-11 05:34:00.739450 EDT | QFunRegParamNorm          137.647
2017-06-11 05:34:00.740350 EDT | -----------------------  -----------
2017-06-11 05:34:00.741365 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1257 | Training started
2017-06-11 05:34:19.699057 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1257 | Training finished
2017-06-11 05:34:19.700001 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1257 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 05:34:19.700311 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1257 | Collecting samples for evaluation
2017-06-11 05:34:34.807448 EDT | -----------------------  -----------
2017-06-11 05:34:34.808064 EDT | Epoch                    1257
2017-06-11 05:34:34.808347 EDT | Iteration                1257
2017-06-11 05:34:34.808608 EDT | AverageReturn            2086.39
2017-06-11 05:34:34.808870 EDT | StdReturn                 894.507
2017-06-11 05:34:34.809131 EDT | MaxReturn                3143.82
2017-06-11 05:34:34.809384 EDT | MinReturn                 820.941
2017-06-11 05:34:34.809636 EDT | AverageEsReturn           381.054
2017-06-11 05:34:34.809900 EDT | StdEsReturn               168.643
2017-06-11 05:34:34.810151 EDT | MaxEsReturn               634.229
2017-06-11 05:34:34.810401 EDT | MinEsReturn               123.43
2017-06-11 05:34:34.810656 EDT | AverageDiscountedReturn   242.146
2017-06-11 05:34:34.810906 EDT | AverageQLoss                1.91365
2017-06-11 05:34:34.811510 EDT | AveragePolicySurr         -27.135
2017-06-11 05:34:34.811787 EDT | AverageQ                   26.9547
2017-06-11 05:34:34.812047 EDT | AverageAbsQ                26.9742
2017-06-11 05:34:34.812316 EDT | AverageY                   26.9558
2017-06-11 05:34:34.812566 EDT | AverageAbsY                26.9627
2017-06-11 05:34:34.812817 EDT | AverageAbsQYDiff            0.46159
2017-06-11 05:34:34.813572 EDT | AverageAction               0.999574
2017-06-11 05:34:34.814376 EDT | PolicyRegParamNorm        105.928
2017-06-11 05:34:34.815144 EDT | QFunRegParamNorm          137.691
2017-06-11 05:34:34.815921 EDT | -----------------------  -----------
2017-06-11 05:34:34.816889 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1258 | Training started
2017-06-11 05:34:51.511646 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1258 | Training finished
2017-06-11 05:34:51.512315 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1258 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 05:34:51.512594 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1258 | Collecting samples for evaluation
2017-06-11 05:35:05.649489 EDT | -----------------------  -----------
2017-06-11 05:35:05.650437 EDT | Epoch                    1258
2017-06-11 05:35:05.650931 EDT | Iteration                1258
2017-06-11 05:35:05.651381 EDT | AverageReturn            1813.11
2017-06-11 05:35:05.651825 EDT | StdReturn                 540.677
2017-06-11 05:35:05.652270 EDT | MaxReturn                2629.35
2017-06-11 05:35:05.652719 EDT | MinReturn                1018.43
2017-06-11 05:35:05.653160 EDT | AverageEsReturn          1058.67
2017-06-11 05:35:05.653602 EDT | StdEsReturn               560.961
2017-06-11 05:35:05.654068 EDT | MaxEsReturn              1829.21
2017-06-11 05:35:05.654508 EDT | MinEsReturn               509.95
2017-06-11 05:35:05.654952 EDT | AverageDiscountedReturn   224.92
2017-06-11 05:35:05.655432 EDT | AverageQLoss                1.976
2017-06-11 05:35:05.655880 EDT | AveragePolicySurr         -27.0784
2017-06-11 05:35:05.656327 EDT | AverageQ                   26.9065
2017-06-11 05:35:05.656765 EDT | AverageAbsQ                26.921
2017-06-11 05:35:05.657208 EDT | AverageY                   26.9092
2017-06-11 05:35:05.657561 EDT | AverageAbsY                26.9161
2017-06-11 05:35:05.657931 EDT | AverageAbsQYDiff            0.452331
2017-06-11 05:35:05.658366 EDT | AverageAction               0.999213
2017-06-11 05:35:05.658809 EDT | PolicyRegParamNorm        105.946
2017-06-11 05:35:05.659248 EDT | QFunRegParamNorm          137.754
2017-06-11 05:35:05.659682 EDT | -----------------------  -----------
2017-06-11 05:35:05.660300 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1259 | Training started
2017-06-11 05:35:22.321729 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1259 | Training finished
2017-06-11 05:35:22.322659 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1259 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 05:35:22.323061 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1259 | Collecting samples for evaluation
2017-06-11 05:35:36.510641 EDT | -----------------------  -----------
2017-06-11 05:35:36.512181 EDT | Epoch                    1259
2017-06-11 05:35:36.512646 EDT | Iteration                1259
2017-06-11 05:35:36.512982 EDT | AverageReturn            1522.96
2017-06-11 05:35:36.513310 EDT | StdReturn                 670.838
2017-06-11 05:35:36.513548 EDT | MaxReturn                2477.36
2017-06-11 05:35:36.513852 EDT | MinReturn                 589.49
2017-06-11 05:35:36.514271 EDT | AverageEsReturn           535.203
2017-06-11 05:35:36.514762 EDT | StdEsReturn               410.699
2017-06-11 05:35:36.515172 EDT | MaxEsReturn              1232.78
2017-06-11 05:35:36.515605 EDT | MinEsReturn               201.917
2017-06-11 05:35:36.516254 EDT | AverageDiscountedReturn   211.623
2017-06-11 05:35:36.516962 EDT | AverageQLoss                1.90575
2017-06-11 05:35:36.517399 EDT | AveragePolicySurr         -27.1822
2017-06-11 05:35:36.517904 EDT | AverageQ                   27.0067
2017-06-11 05:35:36.518339 EDT | AverageAbsQ                27.0241
2017-06-11 05:35:36.518846 EDT | AverageY                   27.0074
2017-06-11 05:35:36.519275 EDT | AverageAbsY                27.0144
2017-06-11 05:35:36.519779 EDT | AverageAbsQYDiff            0.46572
2017-06-11 05:35:36.520209 EDT | AverageAction               0.999363
2017-06-11 05:35:36.520715 EDT | PolicyRegParamNorm        106.06
2017-06-11 05:35:36.521145 EDT | QFunRegParamNorm          137.816
2017-06-11 05:35:36.521929 EDT | -----------------------  -----------
2017-06-11 05:35:36.522803 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1260 | Training started
2017-06-11 05:35:53.833527 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1260 | Training finished
2017-06-11 05:35:53.834364 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1260 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 05:35:53.834583 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1260 | Collecting samples for evaluation
2017-06-11 05:36:08.148028 EDT | -----------------------  -----------
2017-06-11 05:36:08.149206 EDT | Epoch                    1260
2017-06-11 05:36:08.149541 EDT | Iteration                1260
2017-06-11 05:36:08.149912 EDT | AverageReturn            1502.57
2017-06-11 05:36:08.150258 EDT | StdReturn                 698.904
2017-06-11 05:36:08.150602 EDT | MaxReturn                2845.91
2017-06-11 05:36:08.150930 EDT | MinReturn                 679.733
2017-06-11 05:36:08.151254 EDT | AverageEsReturn           359.421
2017-06-11 05:36:08.151600 EDT | StdEsReturn               254.793
2017-06-11 05:36:08.151941 EDT | MaxEsReturn               721.344
2017-06-11 05:36:08.152281 EDT | MinEsReturn                28.1624
2017-06-11 05:36:08.152625 EDT | AverageDiscountedReturn   232.191
2017-06-11 05:36:08.152962 EDT | AverageQLoss                1.94004
2017-06-11 05:36:08.153291 EDT | AveragePolicySurr         -27.1474
2017-06-11 05:36:08.153587 EDT | AverageQ                   26.9514
2017-06-11 05:36:08.153802 EDT | AverageAbsQ                26.9737
2017-06-11 05:36:08.154152 EDT | AverageY                   26.9519
2017-06-11 05:36:08.154337 EDT | AverageAbsY                26.9628
2017-06-11 05:36:08.154630 EDT | AverageAbsQYDiff            0.467898
2017-06-11 05:36:08.154974 EDT | AverageAction               0.999267
2017-06-11 05:36:08.157073 EDT | PolicyRegParamNorm        106.083
2017-06-11 05:36:08.161363 EDT | QFunRegParamNorm          137.85
2017-06-11 05:36:08.161605 EDT | -----------------------  -----------
2017-06-11 05:36:08.163788 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1261 | Training started
2017-06-11 05:36:27.589760 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1261 | Training finished
2017-06-11 05:36:27.590816 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1261 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 05:36:27.605951 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1261 | Collecting samples for evaluation
2017-06-11 05:36:42.061973 EDT | -----------------------  -----------
2017-06-11 05:36:42.062767 EDT | Epoch                    1261
2017-06-11 05:36:42.063104 EDT | Iteration                1261
2017-06-11 05:36:42.063440 EDT | AverageReturn             781.625
2017-06-11 05:36:42.063776 EDT | StdReturn                 587.338
2017-06-11 05:36:42.064095 EDT | MaxReturn                2065.76
2017-06-11 05:36:42.064281 EDT | MinReturn                  19.1234
2017-06-11 05:36:42.064445 EDT | AverageEsReturn           253.393
2017-06-11 05:36:42.064611 EDT | StdEsReturn               226.408
2017-06-11 05:36:42.064796 EDT | MaxEsReturn               662.915
2017-06-11 05:36:42.064999 EDT | MinEsReturn                13.2714
2017-06-11 05:36:42.065174 EDT | AverageDiscountedReturn   173.237
2017-06-11 05:36:42.065333 EDT | AverageQLoss                2.05138
2017-06-11 05:36:42.065492 EDT | AveragePolicySurr         -27.0132
2017-06-11 05:36:42.065656 EDT | AverageQ                   26.828
2017-06-11 05:36:42.065853 EDT | AverageAbsQ                26.8423
2017-06-11 05:36:42.066013 EDT | AverageY                   26.8283
2017-06-11 05:36:42.066172 EDT | AverageAbsY                26.8346
2017-06-11 05:36:42.066330 EDT | AverageAbsQYDiff            0.474259
2017-06-11 05:36:42.066557 EDT | AverageAction               0.999092
2017-06-11 05:36:42.066735 EDT | PolicyRegParamNorm        106.125
2017-06-11 05:36:42.066937 EDT | QFunRegParamNorm          137.908
2017-06-11 05:36:42.067118 EDT | -----------------------  -----------
2017-06-11 05:36:42.067397 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1262 | Training started
2017-06-11 05:36:58.896297 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1262 | Training finished
2017-06-11 05:36:58.897298 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1262 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 05:36:58.897685 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1262 | Collecting samples for evaluation
2017-06-11 05:37:15.530199 EDT | -----------------------  -----------
2017-06-11 05:37:15.534130 EDT | Epoch                    1262
2017-06-11 05:37:15.535572 EDT | Iteration                1262
2017-06-11 05:37:15.536183 EDT | AverageReturn            1364.99
2017-06-11 05:37:15.536532 EDT | StdReturn                 879.121
2017-06-11 05:37:15.537420 EDT | MaxReturn                3385.44
2017-06-11 05:37:15.537755 EDT | MinReturn                 313.835
2017-06-11 05:37:15.538044 EDT | AverageEsReturn           292.238
2017-06-11 05:37:15.538363 EDT | StdEsReturn               358.112
2017-06-11 05:37:15.538681 EDT | MaxEsReturn              1269.95
2017-06-11 05:37:15.538951 EDT | MinEsReturn                10.3853
2017-06-11 05:37:15.539286 EDT | AverageDiscountedReturn   242.27
2017-06-11 05:37:15.539613 EDT | AverageQLoss                1.77658
2017-06-11 05:37:15.539933 EDT | AveragePolicySurr         -27.0061
2017-06-11 05:37:15.546651 EDT | AverageQ                   26.8157
2017-06-11 05:37:15.547008 EDT | AverageAbsQ                26.8346
2017-06-11 05:37:15.548686 EDT | AverageY                   26.8181
2017-06-11 05:37:15.549040 EDT | AverageAbsY                26.8252
2017-06-11 05:37:15.549317 EDT | AverageAbsQYDiff            0.473973
2017-06-11 05:37:15.549596 EDT | AverageAction               0.999379
2017-06-11 05:37:15.549924 EDT | PolicyRegParamNorm        106.161
2017-06-11 05:37:15.550249 EDT | QFunRegParamNorm          137.968
2017-06-11 05:37:15.550564 EDT | -----------------------  -----------
2017-06-11 05:37:15.551049 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1263 | Training started
2017-06-11 05:37:34.151830 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1263 | Training finished
2017-06-11 05:37:34.152758 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1263 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 05:37:34.153125 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1263 | Collecting samples for evaluation
2017-06-11 05:37:48.201449 EDT | -----------------------  -----------
2017-06-11 05:37:48.202415 EDT | Epoch                    1263
2017-06-11 05:37:48.202777 EDT | Iteration                1263
2017-06-11 05:37:48.203092 EDT | AverageReturn             517.021
2017-06-11 05:37:48.203410 EDT | StdReturn                 217.375
2017-06-11 05:37:48.203752 EDT | MaxReturn                1439.42
2017-06-11 05:37:48.204095 EDT | MinReturn                 187.164
2017-06-11 05:37:48.204416 EDT | AverageEsReturn           342.04
2017-06-11 05:37:48.204733 EDT | StdEsReturn               209.314
2017-06-11 05:37:48.205096 EDT | MaxEsReturn               775.241
2017-06-11 05:37:48.205420 EDT | MinEsReturn                13.2982
2017-06-11 05:37:48.205764 EDT | AverageDiscountedReturn   197.696
2017-06-11 05:37:48.206084 EDT | AverageQLoss                1.95138
2017-06-11 05:37:48.206409 EDT | AveragePolicySurr         -27.0587
2017-06-11 05:37:48.206721 EDT | AverageQ                   26.8921
2017-06-11 05:37:48.207047 EDT | AverageAbsQ                26.905
2017-06-11 05:37:48.207251 EDT | AverageY                   26.8942
2017-06-11 05:37:48.207926 EDT | AverageAbsY                26.8999
2017-06-11 05:37:48.208191 EDT | AverageAbsQYDiff            0.486936
2017-06-11 05:37:48.208594 EDT | AverageAction               0.999287
2017-06-11 05:37:48.208842 EDT | PolicyRegParamNorm        106.15
2017-06-11 05:37:48.209164 EDT | QFunRegParamNorm          138.062
2017-06-11 05:37:48.209441 EDT | -----------------------  -----------
2017-06-11 05:37:48.209776 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1264 | Training started
2017-06-11 05:38:06.401583 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1264 | Training finished
2017-06-11 05:38:06.403463 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1264 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 05:38:06.403746 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1264 | Collecting samples for evaluation
2017-06-11 05:38:21.038286 EDT | -----------------------  -----------
2017-06-11 05:38:21.039132 EDT | Epoch                    1264
2017-06-11 05:38:21.039330 EDT | Iteration                1264
2017-06-11 05:38:21.042269 EDT | AverageReturn            1189.81
2017-06-11 05:38:21.043622 EDT | StdReturn                 629.792
2017-06-11 05:38:21.043830 EDT | MaxReturn                2670.23
2017-06-11 05:38:21.044027 EDT | MinReturn                 450.584
2017-06-11 05:38:21.044212 EDT | AverageEsReturn           276.35
2017-06-11 05:38:21.044453 EDT | StdEsReturn               210.563
2017-06-11 05:38:21.044730 EDT | MaxEsReturn               676.865
2017-06-11 05:38:21.044912 EDT | MinEsReturn                30.6126
2017-06-11 05:38:21.045111 EDT | AverageDiscountedReturn   228.855
2017-06-11 05:38:21.045288 EDT | AverageQLoss                2.45518
2017-06-11 05:38:21.045614 EDT | AveragePolicySurr         -26.9676
2017-06-11 05:38:21.045814 EDT | AverageQ                   26.8341
2017-06-11 05:38:21.045996 EDT | AverageAbsQ                26.8499
2017-06-11 05:38:21.046207 EDT | AverageY                   26.8361
2017-06-11 05:38:21.046389 EDT | AverageAbsY                26.8431
2017-06-11 05:38:21.046568 EDT | AverageAbsQYDiff            0.531313
2017-06-11 05:38:21.046803 EDT | AverageAction               0.999567
2017-06-11 05:38:21.046985 EDT | PolicyRegParamNorm        106.202
2017-06-11 05:38:21.047173 EDT | QFunRegParamNorm          138.084
2017-06-11 05:38:21.047352 EDT | -----------------------  -----------
2017-06-11 05:38:21.047666 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1265 | Training started
2017-06-11 05:38:40.206925 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1265 | Training finished
2017-06-11 05:38:40.207902 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1265 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 05:38:40.208323 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1265 | Collecting samples for evaluation
2017-06-11 05:38:54.421458 EDT | -----------------------  -----------
2017-06-11 05:38:54.422208 EDT | Epoch                    1265
2017-06-11 05:38:54.422402 EDT | Iteration                1265
2017-06-11 05:38:54.422565 EDT | AverageReturn            1761.82
2017-06-11 05:38:54.422783 EDT | StdReturn                 727.589
2017-06-11 05:38:54.422940 EDT | MaxReturn                2969.34
2017-06-11 05:38:54.423095 EDT | MinReturn                 623.737
2017-06-11 05:38:54.423248 EDT | AverageEsReturn           319.46
2017-06-11 05:38:54.423400 EDT | StdEsReturn               230.285
2017-06-11 05:38:54.423550 EDT | MaxEsReturn               617.197
2017-06-11 05:38:54.423708 EDT | MinEsReturn                15.2811
2017-06-11 05:38:54.423863 EDT | AverageDiscountedReturn   243.63
2017-06-11 05:38:54.424581 EDT | AverageQLoss                2.02092
2017-06-11 05:38:54.424747 EDT | AveragePolicySurr         -26.9251
2017-06-11 05:38:54.424909 EDT | AverageQ                   26.7315
2017-06-11 05:38:54.425065 EDT | AverageAbsQ                26.7525
2017-06-11 05:38:54.425217 EDT | AverageY                   26.7335
2017-06-11 05:38:54.425367 EDT | AverageAbsY                26.7426
2017-06-11 05:38:54.425518 EDT | AverageAbsQYDiff            0.494349
2017-06-11 05:38:54.425668 EDT | AverageAction               0.999126
2017-06-11 05:38:54.425844 EDT | PolicyRegParamNorm        106.241
2017-06-11 05:38:54.425997 EDT | QFunRegParamNorm          138.096
2017-06-11 05:38:54.426147 EDT | -----------------------  -----------
2017-06-11 05:38:54.426406 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1266 | Training started
2017-06-11 05:39:11.197194 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1266 | Training finished
2017-06-11 05:39:11.205849 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1266 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 05:39:11.206214 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1266 | Collecting samples for evaluation
2017-06-11 05:39:25.953622 EDT | -----------------------  -----------
2017-06-11 05:39:25.954359 EDT | Epoch                    1266
2017-06-11 05:39:25.954819 EDT | Iteration                1266
2017-06-11 05:39:25.955274 EDT | AverageReturn            1116.4
2017-06-11 05:39:25.955724 EDT | StdReturn                 806.185
2017-06-11 05:39:25.956175 EDT | MaxReturn                3170.59
2017-06-11 05:39:25.956639 EDT | MinReturn                 478.035
2017-06-11 05:39:25.957852 EDT | AverageEsReturn           506.504
2017-06-11 05:39:25.958321 EDT | StdEsReturn               182.211
2017-06-11 05:39:25.958769 EDT | MaxEsReturn               779.251
2017-06-11 05:39:25.959217 EDT | MinEsReturn               239.148
2017-06-11 05:39:25.959664 EDT | AverageDiscountedReturn   234.969
2017-06-11 05:39:25.960111 EDT | AverageQLoss                2.04056
2017-06-11 05:39:25.960559 EDT | AveragePolicySurr         -26.9252
2017-06-11 05:39:25.961001 EDT | AverageQ                   26.73
2017-06-11 05:39:25.961444 EDT | AverageAbsQ                26.7474
2017-06-11 05:39:25.961899 EDT | AverageY                   26.7313
2017-06-11 05:39:25.962342 EDT | AverageAbsY                26.7415
2017-06-11 05:39:25.962786 EDT | AverageAbsQYDiff            0.488528
2017-06-11 05:39:25.963227 EDT | AverageAction               0.999264
2017-06-11 05:39:25.963665 EDT | PolicyRegParamNorm        106.279
2017-06-11 05:39:25.964106 EDT | QFunRegParamNorm          138.107
2017-06-11 05:39:25.964542 EDT | -----------------------  -----------
2017-06-11 05:39:25.965170 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1267 | Training started
2017-06-11 05:39:43.466313 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1267 | Training finished
2017-06-11 05:39:43.467287 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1267 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 05:39:43.467675 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1267 | Collecting samples for evaluation
2017-06-11 05:39:57.838633 EDT | -----------------------  -----------
2017-06-11 05:39:57.839639 EDT | Epoch                    1267
2017-06-11 05:39:57.840032 EDT | Iteration                1267
2017-06-11 05:39:57.840441 EDT | AverageReturn             977.917
2017-06-11 05:39:57.841471 EDT | StdReturn                 514.639
2017-06-11 05:39:57.842787 EDT | MaxReturn                2668.13
2017-06-11 05:39:57.844085 EDT | MinReturn                 321.173
2017-06-11 05:39:57.845434 EDT | AverageEsReturn           383.664
2017-06-11 05:39:57.846987 EDT | StdEsReturn               160.072
2017-06-11 05:39:57.848331 EDT | MaxEsReturn               655.154
2017-06-11 05:39:57.849661 EDT | MinEsReturn               198.603
2017-06-11 05:39:57.851000 EDT | AverageDiscountedReturn   222.4
2017-06-11 05:39:57.852540 EDT | AverageQLoss                2.06721
2017-06-11 05:39:57.853941 EDT | AveragePolicySurr         -26.9185
2017-06-11 05:39:57.855372 EDT | AverageQ                   26.7223
2017-06-11 05:39:57.856681 EDT | AverageAbsQ                26.7404
2017-06-11 05:39:57.858077 EDT | AverageY                   26.7233
2017-06-11 05:39:57.859531 EDT | AverageAbsY                26.7312
2017-06-11 05:39:57.860860 EDT | AverageAbsQYDiff            0.481601
2017-06-11 05:39:57.862392 EDT | AverageAction               0.999596
2017-06-11 05:39:57.864072 EDT | PolicyRegParamNorm        106.298
2017-06-11 05:39:57.865507 EDT | QFunRegParamNorm          138.184
2017-06-11 05:39:57.866925 EDT | -----------------------  -----------
2017-06-11 05:39:57.868555 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1268 | Training started
2017-06-11 05:40:15.117530 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1268 | Training finished
2017-06-11 05:40:15.118353 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1268 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 05:40:15.119090 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1268 | Collecting samples for evaluation
2017-06-11 05:40:28.551120 EDT | -----------------------  -----------
2017-06-11 05:40:28.551848 EDT | Epoch                    1268
2017-06-11 05:40:28.552076 EDT | Iteration                1268
2017-06-11 05:40:28.552235 EDT | AverageReturn            1754.14
2017-06-11 05:40:28.552388 EDT | StdReturn                 776.824
2017-06-11 05:40:28.552619 EDT | MaxReturn                2907.3
2017-06-11 05:40:28.552773 EDT | MinReturn                 492.422
2017-06-11 05:40:28.553007 EDT | AverageEsReturn           317.45
2017-06-11 05:40:28.553290 EDT | StdEsReturn               210.305
2017-06-11 05:40:28.553561 EDT | MaxEsReturn               664.997
2017-06-11 05:40:28.554017 EDT | MinEsReturn                22.2879
2017-06-11 05:40:28.554419 EDT | AverageDiscountedReturn   237.646
2017-06-11 05:40:28.554744 EDT | AverageQLoss                1.63223
2017-06-11 05:40:28.554937 EDT | AveragePolicySurr         -26.9613
2017-06-11 05:40:28.555353 EDT | AverageQ                   26.7713
2017-06-11 05:40:28.555602 EDT | AverageAbsQ                26.7909
2017-06-11 05:40:28.555763 EDT | AverageY                   26.7739
2017-06-11 05:40:28.555923 EDT | AverageAbsY                26.7847
2017-06-11 05:40:28.557945 EDT | AverageAbsQYDiff            0.470304
2017-06-11 05:40:28.558718 EDT | AverageAction               0.999164
2017-06-11 05:40:28.558901 EDT | PolicyRegParamNorm        106.341
2017-06-11 05:40:28.559347 EDT | QFunRegParamNorm          138.228
2017-06-11 05:40:28.559541 EDT | -----------------------  -----------
2017-06-11 05:40:28.559906 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1269 | Training started
2017-06-11 05:40:46.215119 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1269 | Training finished
2017-06-11 05:40:46.215655 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1269 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 05:40:46.216086 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1269 | Collecting samples for evaluation
2017-06-11 05:41:00.639974 EDT | -----------------------  -----------
2017-06-11 05:41:00.640846 EDT | Epoch                    1269
2017-06-11 05:41:00.641106 EDT | Iteration                1269
2017-06-11 05:41:00.641297 EDT | AverageReturn             639.401
2017-06-11 05:41:00.641563 EDT | StdReturn                 165.264
2017-06-11 05:41:00.641765 EDT | MaxReturn                1072.27
2017-06-11 05:41:00.641949 EDT | MinReturn                 258.251
2017-06-11 05:41:00.642167 EDT | AverageEsReturn           317.211
2017-06-11 05:41:00.642349 EDT | StdEsReturn               132.256
2017-06-11 05:41:00.642529 EDT | MaxEsReturn               476.752
2017-06-11 05:41:00.642714 EDT | MinEsReturn                22.4764
2017-06-11 05:41:00.642962 EDT | AverageDiscountedReturn   224.672
2017-06-11 05:41:00.643145 EDT | AverageQLoss                1.62334
2017-06-11 05:41:00.643416 EDT | AveragePolicySurr         -26.9001
2017-06-11 05:41:00.643593 EDT | AverageQ                   26.7045
2017-06-11 05:41:00.643774 EDT | AverageAbsQ                26.7248
2017-06-11 05:41:00.643991 EDT | AverageY                   26.7067
2017-06-11 05:41:00.644223 EDT | AverageAbsY                26.717
2017-06-11 05:41:00.644422 EDT | AverageAbsQYDiff            0.464688
2017-06-11 05:41:00.644638 EDT | AverageAction               0.999423
2017-06-11 05:41:00.644820 EDT | PolicyRegParamNorm        106.401
2017-06-11 05:41:00.645039 EDT | QFunRegParamNorm          138.268
2017-06-11 05:41:00.645219 EDT | -----------------------  -----------
2017-06-11 05:41:00.645535 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1270 | Training started
2017-06-11 05:41:18.671981 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1270 | Training finished
2017-06-11 05:41:18.673476 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1270 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 05:41:18.673906 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1270 | Collecting samples for evaluation
2017-06-11 05:41:33.695793 EDT | -----------------------  -----------
2017-06-11 05:41:33.696884 EDT | Epoch                    1270
2017-06-11 05:41:33.697347 EDT | Iteration                1270
2017-06-11 05:41:33.697802 EDT | AverageReturn            2231.37
2017-06-11 05:41:33.698249 EDT | StdReturn                 934.486
2017-06-11 05:41:33.698695 EDT | MaxReturn                2984.96
2017-06-11 05:41:33.699139 EDT | MinReturn                 463.19
2017-06-11 05:41:33.699586 EDT | AverageEsReturn           297.039
2017-06-11 05:41:33.700029 EDT | StdEsReturn               164.116
2017-06-11 05:41:33.700469 EDT | MaxEsReturn               500.988
2017-06-11 05:41:33.700913 EDT | MinEsReturn                19.5694
2017-06-11 05:41:33.701352 EDT | AverageDiscountedReturn   236.482
2017-06-11 05:41:33.701792 EDT | AverageQLoss                1.60713
2017-06-11 05:41:33.702137 EDT | AveragePolicySurr         -26.9562
2017-06-11 05:41:33.702468 EDT | AverageQ                   26.7583
2017-06-11 05:41:33.702806 EDT | AverageAbsQ                26.7782
2017-06-11 05:41:33.703133 EDT | AverageY                   26.7604
2017-06-11 05:41:33.703460 EDT | AverageAbsY                26.7703
2017-06-11 05:41:33.703784 EDT | AverageAbsQYDiff            0.459893
2017-06-11 05:41:33.717806 EDT | AverageAction               0.999321
2017-06-11 05:41:33.718267 EDT | PolicyRegParamNorm        106.407
2017-06-11 05:41:33.718715 EDT | QFunRegParamNorm          138.29
2017-06-11 05:41:33.719155 EDT | -----------------------  -----------
2017-06-11 05:41:33.719755 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1271 | Training started
2017-06-11 05:41:50.547020 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1271 | Training finished
2017-06-11 05:41:50.547767 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1271 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 05:41:50.547963 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1271 | Collecting samples for evaluation
2017-06-11 05:42:05.441417 EDT | -----------------------  -----------
2017-06-11 05:42:05.443484 EDT | Epoch                    1271
2017-06-11 05:42:05.444010 EDT | Iteration                1271
2017-06-11 05:42:05.444843 EDT | AverageReturn            1253.26
2017-06-11 05:42:05.445684 EDT | StdReturn                 706.286
2017-06-11 05:42:05.446540 EDT | MaxReturn                3322
2017-06-11 05:42:05.447374 EDT | MinReturn                 517.435
2017-06-11 05:42:05.448204 EDT | AverageEsReturn           336.002
2017-06-11 05:42:05.449040 EDT | StdEsReturn               183.865
2017-06-11 05:42:05.449879 EDT | MaxEsReturn               764.715
2017-06-11 05:42:05.450722 EDT | MinEsReturn               158.458
2017-06-11 05:42:05.451559 EDT | AverageDiscountedReturn   251.017
2017-06-11 05:42:05.452397 EDT | AverageQLoss                1.89203
2017-06-11 05:42:05.453235 EDT | AveragePolicySurr         -27.0026
2017-06-11 05:42:05.454073 EDT | AverageQ                   26.7986
2017-06-11 05:42:05.454915 EDT | AverageAbsQ                26.8182
2017-06-11 05:42:05.455755 EDT | AverageY                   26.8
2017-06-11 05:42:05.456600 EDT | AverageAbsY                26.8084
2017-06-11 05:42:05.457441 EDT | AverageAbsQYDiff            0.470651
2017-06-11 05:42:05.458303 EDT | AverageAction               0.999375
2017-06-11 05:42:05.459153 EDT | PolicyRegParamNorm        106.455
2017-06-11 05:42:05.459993 EDT | QFunRegParamNorm          138.343
2017-06-11 05:42:05.460832 EDT | -----------------------  -----------
2017-06-11 05:42:05.461851 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1272 | Training started
2017-06-11 05:42:24.608075 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1272 | Training finished
2017-06-11 05:42:24.609010 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1272 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 05:42:24.609393 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1272 | Collecting samples for evaluation
2017-06-11 05:42:38.367681 EDT | -----------------------  -----------
2017-06-11 05:42:38.368684 EDT | Epoch                    1272
2017-06-11 05:42:38.369166 EDT | Iteration                1272
2017-06-11 05:42:38.369614 EDT | AverageReturn             655.149
2017-06-11 05:42:38.370082 EDT | StdReturn                 394.795
2017-06-11 05:42:38.370526 EDT | MaxReturn                1959.03
2017-06-11 05:42:38.370969 EDT | MinReturn                 222.443
2017-06-11 05:42:38.371414 EDT | AverageEsReturn           345.021
2017-06-11 05:42:38.371858 EDT | StdEsReturn               405.709
2017-06-11 05:42:38.372299 EDT | MaxEsReturn              1392.16
2017-06-11 05:42:38.372742 EDT | MinEsReturn                 9.0639
2017-06-11 05:42:38.373182 EDT | AverageDiscountedReturn   195.018
2017-06-11 05:42:38.373626 EDT | AverageQLoss                2.06963
2017-06-11 05:42:38.374079 EDT | AveragePolicySurr         -26.9693
2017-06-11 05:42:38.374519 EDT | AverageQ                   26.7663
2017-06-11 05:42:38.374960 EDT | AverageAbsQ                26.7875
2017-06-11 05:42:38.375376 EDT | AverageY                   26.7681
2017-06-11 05:42:38.375739 EDT | AverageAbsY                26.7788
2017-06-11 05:42:38.376176 EDT | AverageAbsQYDiff            0.475383
2017-06-11 05:42:38.376615 EDT | AverageAction               0.999452
2017-06-11 05:42:38.377056 EDT | PolicyRegParamNorm        106.492
2017-06-11 05:42:38.377496 EDT | QFunRegParamNorm          138.395
2017-06-11 05:42:38.377949 EDT | -----------------------  -----------
2017-06-11 05:42:38.378563 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1273 | Training started
2017-06-11 05:42:57.013727 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1273 | Training finished
2017-06-11 05:42:57.014471 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1273 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 05:42:57.015277 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1273 | Collecting samples for evaluation
2017-06-11 05:43:11.587000 EDT | -----------------------  -----------
2017-06-11 05:43:11.587964 EDT | Epoch                    1273
2017-06-11 05:43:11.588336 EDT | Iteration                1273
2017-06-11 05:43:11.588686 EDT | AverageReturn            3270.5
2017-06-11 05:43:11.589030 EDT | StdReturn                  75.0922
2017-06-11 05:43:11.589372 EDT | MaxReturn                3407.23
2017-06-11 05:43:11.589724 EDT | MinReturn                3170.96
2017-06-11 05:43:11.590061 EDT | AverageEsReturn           283.592
2017-06-11 05:43:11.590404 EDT | StdEsReturn               489.646
2017-06-11 05:43:11.590746 EDT | MaxEsReturn              1685.89
2017-06-11 05:43:11.591090 EDT | MinEsReturn                 7.35185
2017-06-11 05:43:11.591432 EDT | AverageDiscountedReturn   261.953
2017-06-11 05:43:11.591776 EDT | AverageQLoss                1.90187
2017-06-11 05:43:11.592117 EDT | AveragePolicySurr         -26.9716
2017-06-11 05:43:11.592455 EDT | AverageQ                   26.7629
2017-06-11 05:43:11.592797 EDT | AverageAbsQ                26.7818
2017-06-11 05:43:11.593141 EDT | AverageY                   26.7633
2017-06-11 05:43:11.593485 EDT | AverageAbsY                26.7741
2017-06-11 05:43:11.593839 EDT | AverageAbsQYDiff            0.467881
2017-06-11 05:43:11.594179 EDT | AverageAction               0.998921
2017-06-11 05:43:11.594530 EDT | PolicyRegParamNorm        106.515
2017-06-11 05:43:11.594873 EDT | QFunRegParamNorm          138.419
2017-06-11 05:43:11.595216 EDT | -----------------------  -----------
2017-06-11 05:43:11.595717 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1274 | Training started
2017-06-11 05:43:29.742751 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1274 | Training finished
2017-06-11 05:43:29.743644 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1274 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 05:43:29.743989 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1274 | Collecting samples for evaluation
2017-06-11 05:43:45.796544 EDT | -----------------------  -----------
2017-06-11 05:43:45.797236 EDT | Epoch                    1274
2017-06-11 05:43:45.797744 EDT | Iteration                1274
2017-06-11 05:43:45.798168 EDT | AverageReturn            1601.24
2017-06-11 05:43:45.798930 EDT | StdReturn                1016.34
2017-06-11 05:43:45.799631 EDT | MaxReturn                3513.23
2017-06-11 05:43:45.800086 EDT | MinReturn                 819.672
2017-06-11 05:43:45.800510 EDT | AverageEsReturn           709.02
2017-06-11 05:43:45.801171 EDT | StdEsReturn               886.595
2017-06-11 05:43:45.801737 EDT | MaxEsReturn              2183.12
2017-06-11 05:43:45.802150 EDT | MinEsReturn                14.4437
2017-06-11 05:43:45.802571 EDT | AverageDiscountedReturn   262.949
2017-06-11 05:43:45.803013 EDT | AverageQLoss                2.08325
2017-06-11 05:43:45.805492 EDT | AveragePolicySurr         -27.0671
2017-06-11 05:43:45.805981 EDT | AverageQ                   26.8674
2017-06-11 05:43:45.811574 EDT | AverageAbsQ                26.8846
2017-06-11 05:43:45.811833 EDT | AverageY                   26.8699
2017-06-11 05:43:45.812028 EDT | AverageAbsY                26.8773
2017-06-11 05:43:45.812246 EDT | AverageAbsQYDiff            0.474905
2017-06-11 05:43:45.812538 EDT | AverageAction               0.999328
2017-06-11 05:43:45.812724 EDT | PolicyRegParamNorm        106.561
2017-06-11 05:43:45.812909 EDT | QFunRegParamNorm          138.444
2017-06-11 05:43:45.813138 EDT | -----------------------  -----------
2017-06-11 05:43:45.813463 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1275 | Training started
2017-06-11 05:44:02.646732 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1275 | Training finished
2017-06-11 05:44:02.647655 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1275 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 05:44:02.647982 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1275 | Collecting samples for evaluation
2017-06-11 05:44:18.267629 EDT | -----------------------  -----------
2017-06-11 05:44:18.268211 EDT | Epoch                    1275
2017-06-11 05:44:18.268548 EDT | Iteration                1275
2017-06-11 05:44:18.268882 EDT | AverageReturn            2710.18
2017-06-11 05:44:18.269221 EDT | StdReturn                 673.876
2017-06-11 05:44:18.269623 EDT | MaxReturn                3191.34
2017-06-11 05:44:18.270046 EDT | MinReturn                1118.31
2017-06-11 05:44:18.270406 EDT | AverageEsReturn           414.918
2017-06-11 05:44:18.270776 EDT | StdEsReturn               316.011
2017-06-11 05:44:18.271143 EDT | MaxEsReturn               955.308
2017-06-11 05:44:18.271505 EDT | MinEsReturn                93.328
2017-06-11 05:44:18.271898 EDT | AverageDiscountedReturn   255.705
2017-06-11 05:44:18.272133 EDT | AverageQLoss                1.65161
2017-06-11 05:44:18.272321 EDT | AveragePolicySurr         -27.0636
2017-06-11 05:44:18.272503 EDT | AverageQ                   26.8676
2017-06-11 05:44:18.272683 EDT | AverageAbsQ                26.8861
2017-06-11 05:44:18.272931 EDT | AverageY                   26.8689
2017-06-11 05:44:18.273111 EDT | AverageAbsY                26.8793
2017-06-11 05:44:18.273298 EDT | AverageAbsQYDiff            0.453853
2017-06-11 05:44:18.273480 EDT | AverageAction               0.999452
2017-06-11 05:44:18.273705 EDT | PolicyRegParamNorm        106.63
2017-06-11 05:44:18.273893 EDT | QFunRegParamNorm          138.506
2017-06-11 05:44:18.274074 EDT | -----------------------  -----------
2017-06-11 05:44:18.274382 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1276 | Training started
2017-06-11 05:44:36.242024 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1276 | Training finished
2017-06-11 05:44:36.243102 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1276 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 05:44:36.243612 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1276 | Collecting samples for evaluation
2017-06-11 05:44:50.702584 EDT | -----------------------  -----------
2017-06-11 05:44:50.703751 EDT | Epoch                    1276
2017-06-11 05:44:50.704048 EDT | Iteration                1276
2017-06-11 05:44:50.704505 EDT | AverageReturn            1567.61
2017-06-11 05:44:50.704780 EDT | StdReturn                1058.52
2017-06-11 05:44:50.705066 EDT | MaxReturn                3266.9
2017-06-11 05:44:50.705331 EDT | MinReturn                 579.521
2017-06-11 05:44:50.705615 EDT | AverageEsReturn           516.913
2017-06-11 05:44:50.705886 EDT | StdEsReturn               272.999
2017-06-11 05:44:50.706165 EDT | MaxEsReturn               921.078
2017-06-11 05:44:50.706832 EDT | MinEsReturn                25.1076
2017-06-11 05:44:50.707702 EDT | AverageDiscountedReturn   249.327
2017-06-11 05:44:50.708873 EDT | AverageQLoss                1.65229
2017-06-11 05:44:50.709085 EDT | AveragePolicySurr         -27.0568
2017-06-11 05:44:50.709751 EDT | AverageQ                   26.8502
2017-06-11 05:44:50.710063 EDT | AverageAbsQ                26.8657
2017-06-11 05:44:50.710251 EDT | AverageY                   26.8505
2017-06-11 05:44:50.710437 EDT | AverageAbsY                26.8577
2017-06-11 05:44:50.710620 EDT | AverageAbsQYDiff            0.450067
2017-06-11 05:44:50.710802 EDT | AverageAction               0.999015
2017-06-11 05:44:50.710998 EDT | PolicyRegParamNorm        106.667
2017-06-11 05:44:50.711223 EDT | QFunRegParamNorm          138.513
2017-06-11 05:44:50.711406 EDT | -----------------------  -----------
2017-06-11 05:44:50.711680 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1277 | Training started
2017-06-11 05:45:09.786609 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1277 | Training finished
2017-06-11 05:45:09.787701 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1277 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 05:45:09.788223 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1277 | Collecting samples for evaluation
2017-06-11 05:45:23.608704 EDT | -----------------------  -----------
2017-06-11 05:45:23.609612 EDT | Epoch                    1277
2017-06-11 05:45:23.609823 EDT | Iteration                1277
2017-06-11 05:45:23.609987 EDT | AverageReturn             691.727
2017-06-11 05:45:23.610150 EDT | StdReturn                 228.591
2017-06-11 05:45:23.610309 EDT | MaxReturn                1730.48
2017-06-11 05:45:23.610463 EDT | MinReturn                 463.738
2017-06-11 05:45:23.610614 EDT | AverageEsReturn           399.032
2017-06-11 05:45:23.610765 EDT | StdEsReturn               293.785
2017-06-11 05:45:23.610915 EDT | MaxEsReturn              1063.79
2017-06-11 05:45:23.611064 EDT | MinEsReturn               139.727
2017-06-11 05:45:23.611311 EDT | AverageDiscountedReturn   228.999
2017-06-11 05:45:23.611475 EDT | AverageQLoss                1.75758
2017-06-11 05:45:23.611625 EDT | AveragePolicySurr         -26.9576
2017-06-11 05:45:23.611775 EDT | AverageQ                   26.7436
2017-06-11 05:45:23.611923 EDT | AverageAbsQ                26.7603
2017-06-11 05:45:23.612095 EDT | AverageY                   26.7454
2017-06-11 05:45:23.612316 EDT | AverageAbsY                26.7528
2017-06-11 05:45:23.612479 EDT | AverageAbsQYDiff            0.459656
2017-06-11 05:45:23.612631 EDT | AverageAction               0.999386
2017-06-11 05:45:23.612781 EDT | PolicyRegParamNorm        106.663
2017-06-11 05:45:23.612930 EDT | QFunRegParamNorm          138.587
2017-06-11 05:45:23.613079 EDT | -----------------------  -----------
2017-06-11 05:45:23.613565 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1278 | Training started
2017-06-11 05:45:42.282609 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1278 | Training finished
2017-06-11 05:45:42.283732 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1278 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 05:45:42.284024 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1278 | Collecting samples for evaluation
2017-06-11 05:45:57.381110 EDT | -----------------------  -----------
2017-06-11 05:45:57.382047 EDT | Epoch                    1278
2017-06-11 05:45:57.382403 EDT | Iteration                1278
2017-06-11 05:45:57.382743 EDT | AverageReturn             542.337
2017-06-11 05:45:57.383080 EDT | StdReturn                 135.196
2017-06-11 05:45:57.383416 EDT | MaxReturn                1017.34
2017-06-11 05:45:57.383749 EDT | MinReturn                 460.695
2017-06-11 05:45:57.384135 EDT | AverageEsReturn           332.809
2017-06-11 05:45:57.384570 EDT | StdEsReturn               123.365
2017-06-11 05:45:57.385009 EDT | MaxEsReturn               557.216
2017-06-11 05:45:57.385448 EDT | MinEsReturn               162.77
2017-06-11 05:45:57.385896 EDT | AverageDiscountedReturn   209.797
2017-06-11 05:45:57.386339 EDT | AverageQLoss                1.2749
2017-06-11 05:45:57.386779 EDT | AveragePolicySurr         -27.043
2017-06-11 05:45:57.387220 EDT | AverageQ                   26.8457
2017-06-11 05:45:57.387657 EDT | AverageAbsQ                26.8625
2017-06-11 05:45:57.388096 EDT | AverageY                   26.8471
2017-06-11 05:45:57.388533 EDT | AverageAbsY                26.8543
2017-06-11 05:45:57.388971 EDT | AverageAbsQYDiff            0.429072
2017-06-11 05:45:57.389407 EDT | AverageAction               0.998918
2017-06-11 05:45:57.389862 EDT | PolicyRegParamNorm        106.663
2017-06-11 05:45:57.390302 EDT | QFunRegParamNorm          138.608
2017-06-11 05:45:57.390742 EDT | -----------------------  -----------
2017-06-11 05:45:57.391338 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1279 | Training started
2017-06-11 05:46:15.567810 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1279 | Training finished
2017-06-11 05:46:15.569043 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1279 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 05:46:15.569581 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1279 | Collecting samples for evaluation
2017-06-11 05:46:30.771975 EDT | -----------------------  -----------
2017-06-11 05:46:30.774646 EDT | Epoch                    1279
2017-06-11 05:46:30.774889 EDT | Iteration                1279
2017-06-11 05:46:30.775053 EDT | AverageReturn            1234.71
2017-06-11 05:46:30.775234 EDT | StdReturn                 829.955
2017-06-11 05:46:30.775395 EDT | MaxReturn                3142
2017-06-11 05:46:30.775553 EDT | MinReturn                 468.886
2017-06-11 05:46:30.775711 EDT | AverageEsReturn           388.316
2017-06-11 05:46:30.775863 EDT | StdEsReturn               159.456
2017-06-11 05:46:30.776031 EDT | MaxEsReturn               571.111
2017-06-11 05:46:30.776204 EDT | MinEsReturn                62.8858
2017-06-11 05:46:30.776355 EDT | AverageDiscountedReturn   230.639
2017-06-11 05:46:30.776532 EDT | AverageQLoss                1.80702
2017-06-11 05:46:30.776682 EDT | AveragePolicySurr         -27.0572
2017-06-11 05:46:30.776850 EDT | AverageQ                   26.8672
2017-06-11 05:46:30.777010 EDT | AverageAbsQ                26.8841
2017-06-11 05:46:30.777160 EDT | AverageY                   26.8678
2017-06-11 05:46:30.777308 EDT | AverageAbsY                26.874
2017-06-11 05:46:30.777503 EDT | AverageAbsQYDiff            0.468135
2017-06-11 05:46:30.777663 EDT | AverageAction               0.998866
2017-06-11 05:46:30.779405 EDT | PolicyRegParamNorm        106.796
2017-06-11 05:46:30.779870 EDT | QFunRegParamNorm          138.68
2017-06-11 05:46:30.780025 EDT | -----------------------  -----------
2017-06-11 05:46:30.780285 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1280 | Training started
2017-06-11 05:46:47.353052 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1280 | Training finished
2017-06-11 05:46:47.367948 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1280 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 05:46:47.368344 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1280 | Collecting samples for evaluation
2017-06-11 05:47:01.632321 EDT | -----------------------  -----------
2017-06-11 05:47:01.633485 EDT | Epoch                    1280
2017-06-11 05:47:01.633968 EDT | Iteration                1280
2017-06-11 05:47:01.634417 EDT | AverageReturn            1547.58
2017-06-11 05:47:01.634867 EDT | StdReturn                 576.438
2017-06-11 05:47:01.635314 EDT | MaxReturn                2965.29
2017-06-11 05:47:01.635758 EDT | MinReturn                 887.299
2017-06-11 05:47:01.636202 EDT | AverageEsReturn           390.77
2017-06-11 05:47:01.636647 EDT | StdEsReturn               157.589
2017-06-11 05:47:01.637091 EDT | MaxEsReturn               584.278
2017-06-11 05:47:01.637535 EDT | MinEsReturn                77.7429
2017-06-11 05:47:01.637990 EDT | AverageDiscountedReturn   245.5
2017-06-11 05:47:01.638433 EDT | AverageQLoss                2.05298
2017-06-11 05:47:01.638878 EDT | AveragePolicySurr         -26.9931
2017-06-11 05:47:01.639334 EDT | AverageQ                   26.8112
2017-06-11 05:47:01.639777 EDT | AverageAbsQ                26.8259
2017-06-11 05:47:01.640223 EDT | AverageY                   26.8122
2017-06-11 05:47:01.640671 EDT | AverageAbsY                26.8196
2017-06-11 05:47:01.641121 EDT | AverageAbsQYDiff            0.478621
2017-06-11 05:47:01.641568 EDT | AverageAction               0.999106
2017-06-11 05:47:01.642020 EDT | PolicyRegParamNorm        106.809
2017-06-11 05:47:01.642461 EDT | QFunRegParamNorm          138.723
2017-06-11 05:47:01.642904 EDT | -----------------------  -----------
2017-06-11 05:47:01.643523 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1281 | Training started
2017-06-11 05:47:20.085849 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1281 | Training finished
2017-06-11 05:47:20.086765 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1281 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 05:47:20.087134 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1281 | Collecting samples for evaluation
2017-06-11 05:47:33.347088 EDT | -----------------------  -----------
2017-06-11 05:47:33.350221 EDT | Epoch                    1281
2017-06-11 05:47:33.350624 EDT | Iteration                1281
2017-06-11 05:47:33.350978 EDT | AverageReturn            1224.47
2017-06-11 05:47:33.351328 EDT | StdReturn                 397.993
2017-06-11 05:47:33.351687 EDT | MaxReturn                2463.73
2017-06-11 05:47:33.352033 EDT | MinReturn                 709.372
2017-06-11 05:47:33.352372 EDT | AverageEsReturn           431.059
2017-06-11 05:47:33.352715 EDT | StdEsReturn               208.335
2017-06-11 05:47:33.353035 EDT | MaxEsReturn               679.104
2017-06-11 05:47:33.353311 EDT | MinEsReturn                98.6336
2017-06-11 05:47:33.353605 EDT | AverageDiscountedReturn   230.247
2017-06-11 05:47:33.354231 EDT | AverageQLoss                1.92124
2017-06-11 05:47:33.355832 EDT | AveragePolicySurr         -26.941
2017-06-11 05:47:33.356189 EDT | AverageQ                   26.7515
2017-06-11 05:47:33.356535 EDT | AverageAbsQ                26.7655
2017-06-11 05:47:33.356878 EDT | AverageY                   26.7554
2017-06-11 05:47:33.357220 EDT | AverageAbsY                26.7607
2017-06-11 05:47:33.359301 EDT | AverageAbsQYDiff            0.475964
2017-06-11 05:47:33.359641 EDT | AverageAction               0.999015
2017-06-11 05:47:33.360293 EDT | PolicyRegParamNorm        106.873
2017-06-11 05:47:33.360652 EDT | QFunRegParamNorm          138.823
2017-06-11 05:47:33.361000 EDT | -----------------------  -----------
2017-06-11 05:47:33.361524 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1282 | Training started
2017-06-11 05:47:51.418031 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1282 | Training finished
2017-06-11 05:47:51.418897 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1282 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 05:47:51.419205 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1282 | Collecting samples for evaluation
2017-06-11 05:48:06.092395 EDT | -----------------------  -----------
2017-06-11 05:48:06.093861 EDT | Epoch                    1282
2017-06-11 05:48:06.094718 EDT | Iteration                1282
2017-06-11 05:48:06.095204 EDT | AverageReturn            2732.04
2017-06-11 05:48:06.095694 EDT | StdReturn                 521.595
2017-06-11 05:48:06.096174 EDT | MaxReturn                3084.31
2017-06-11 05:48:06.097506 EDT | MinReturn                1327.77
2017-06-11 05:48:06.101953 EDT | AverageEsReturn           391.634
2017-06-11 05:48:06.102317 EDT | StdEsReturn               326.039
2017-06-11 05:48:06.102687 EDT | MaxEsReturn              1005.73
2017-06-11 05:48:06.103129 EDT | MinEsReturn                36.9604
2017-06-11 05:48:06.103504 EDT | AverageDiscountedReturn   251.184
2017-06-11 05:48:06.103744 EDT | AverageQLoss                1.6965
2017-06-11 05:48:06.104106 EDT | AveragePolicySurr         -27.0247
2017-06-11 05:48:06.104389 EDT | AverageQ                   26.8239
2017-06-11 05:48:06.104753 EDT | AverageAbsQ                26.8393
2017-06-11 05:48:06.105185 EDT | AverageY                   26.8231
2017-06-11 05:48:06.105560 EDT | AverageAbsY                26.8288
2017-06-11 05:48:06.105896 EDT | AverageAbsQYDiff            0.458014
2017-06-11 05:48:06.106238 EDT | AverageAction               0.998991
2017-06-11 05:48:06.106576 EDT | PolicyRegParamNorm        106.867
2017-06-11 05:48:06.106925 EDT | QFunRegParamNorm          138.85
2017-06-11 05:48:06.109773 EDT | -----------------------  -----------
2017-06-11 05:48:06.110610 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1283 | Training started
2017-06-11 05:48:22.313826 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1283 | Training finished
2017-06-11 05:48:22.314738 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1283 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 05:48:22.315130 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1283 | Collecting samples for evaluation
2017-06-11 05:48:36.337014 EDT | -----------------------  -----------
2017-06-11 05:48:36.337855 EDT | Epoch                    1283
2017-06-11 05:48:36.338049 EDT | Iteration                1283
2017-06-11 05:48:36.338546 EDT | AverageReturn             668.16
2017-06-11 05:48:36.338885 EDT | StdReturn                 721.35
2017-06-11 05:48:36.339217 EDT | MaxReturn                3553.58
2017-06-11 05:48:36.339421 EDT | MinReturn                 302.143
2017-06-11 05:48:36.339608 EDT | AverageEsReturn           332.083
2017-06-11 05:48:36.339898 EDT | StdEsReturn               149.312
2017-06-11 05:48:36.340083 EDT | MaxEsReturn               571.223
2017-06-11 05:48:36.340265 EDT | MinEsReturn               104.558
2017-06-11 05:48:36.341547 EDT | AverageDiscountedReturn   195.604
2017-06-11 05:48:36.341759 EDT | AverageQLoss                1.85068
2017-06-11 05:48:36.341948 EDT | AveragePolicySurr         -27.0767
2017-06-11 05:48:36.342185 EDT | AverageQ                   26.8769
2017-06-11 05:48:36.342395 EDT | AverageAbsQ                26.8948
2017-06-11 05:48:36.342670 EDT | AverageY                   26.8798
2017-06-11 05:48:36.342920 EDT | AverageAbsY                26.8872
2017-06-11 05:48:36.343167 EDT | AverageAbsQYDiff            0.471412
2017-06-11 05:48:36.343414 EDT | AverageAction               0.999011
2017-06-11 05:48:36.343658 EDT | PolicyRegParamNorm        106.887
2017-06-11 05:48:36.343977 EDT | QFunRegParamNorm          138.92
2017-06-11 05:48:36.344253 EDT | -----------------------  -----------
2017-06-11 05:48:36.344535 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1284 | Training started
2017-06-11 05:48:53.058431 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1284 | Training finished
2017-06-11 05:48:53.059202 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1284 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 05:48:53.059393 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1284 | Collecting samples for evaluation
2017-06-11 05:49:07.512054 EDT | -----------------------  -----------
2017-06-11 05:49:07.513064 EDT | Epoch                    1284
2017-06-11 05:49:07.513496 EDT | Iteration                1284
2017-06-11 05:49:07.513933 EDT | AverageReturn             297.392
2017-06-11 05:49:07.514308 EDT | StdReturn                  42.402
2017-06-11 05:49:07.514668 EDT | MaxReturn                 586.175
2017-06-11 05:49:07.515048 EDT | MinReturn                 279.774
2017-06-11 05:49:07.515389 EDT | AverageEsReturn           300.34
2017-06-11 05:49:07.515718 EDT | StdEsReturn               182.416
2017-06-11 05:49:07.516128 EDT | MaxEsReturn               610.239
2017-06-11 05:49:07.516540 EDT | MinEsReturn                60.4211
2017-06-11 05:49:07.516954 EDT | AverageDiscountedReturn   158.205
2017-06-11 05:49:07.517389 EDT | AverageQLoss                1.65692
2017-06-11 05:49:07.517821 EDT | AveragePolicySurr         -27.1081
2017-06-11 05:49:07.518234 EDT | AverageQ                   26.9021
2017-06-11 05:49:07.518584 EDT | AverageAbsQ                26.9184
2017-06-11 05:49:07.518946 EDT | AverageY                   26.9023
2017-06-11 05:49:07.519362 EDT | AverageAbsY                26.9099
2017-06-11 05:49:07.519755 EDT | AverageAbsQYDiff            0.448798
2017-06-11 05:49:07.520238 EDT | AverageAction               0.999326
2017-06-11 05:49:07.520619 EDT | PolicyRegParamNorm        106.947
2017-06-11 05:49:07.521035 EDT | QFunRegParamNorm          138.942
2017-06-11 05:49:07.521506 EDT | -----------------------  -----------
2017-06-11 05:49:07.522446 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1285 | Training started
2017-06-11 05:49:24.996326 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1285 | Training finished
2017-06-11 05:49:24.996850 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1285 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 05:49:24.997251 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1285 | Collecting samples for evaluation
2017-06-11 05:49:38.699841 EDT | -----------------------  -----------
2017-06-11 05:49:38.700627 EDT | Epoch                    1285
2017-06-11 05:49:38.700904 EDT | Iteration                1285
2017-06-11 05:49:38.701165 EDT | AverageReturn             604.554
2017-06-11 05:49:38.701425 EDT | StdReturn                 190.921
2017-06-11 05:49:38.701883 EDT | MaxReturn                1205.99
2017-06-11 05:49:38.702220 EDT | MinReturn                 473.572
2017-06-11 05:49:38.702553 EDT | AverageEsReturn           408.39
2017-06-11 05:49:38.702883 EDT | StdEsReturn               282.147
2017-06-11 05:49:38.703212 EDT | MaxEsReturn               766.497
2017-06-11 05:49:38.703540 EDT | MinEsReturn                65.9446
2017-06-11 05:49:38.703868 EDT | AverageDiscountedReturn   212.636
2017-06-11 05:49:38.704201 EDT | AverageQLoss                1.37679
2017-06-11 05:49:38.704532 EDT | AveragePolicySurr         -27.0389
2017-06-11 05:49:38.704862 EDT | AverageQ                   26.8399
2017-06-11 05:49:38.705193 EDT | AverageAbsQ                26.8559
2017-06-11 05:49:38.706136 EDT | AverageY                   26.841
2017-06-11 05:49:38.706496 EDT | AverageAbsY                26.8483
2017-06-11 05:49:38.706831 EDT | AverageAbsQYDiff            0.431842
2017-06-11 05:49:38.707162 EDT | AverageAction               0.999308
2017-06-11 05:49:38.707492 EDT | PolicyRegParamNorm        106.986
2017-06-11 05:49:38.707818 EDT | QFunRegParamNorm          138.949
2017-06-11 05:49:38.708142 EDT | -----------------------  -----------
2017-06-11 05:49:38.708604 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1286 | Training started
2017-06-11 05:49:55.742315 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1286 | Training finished
2017-06-11 05:49:55.744199 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1286 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 05:49:55.744909 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1286 | Collecting samples for evaluation
2017-06-11 05:50:08.862847 EDT | -----------------------  -----------
2017-06-11 05:50:08.863762 EDT | Epoch                    1286
2017-06-11 05:50:08.864150 EDT | Iteration                1286
2017-06-11 05:50:08.864499 EDT | AverageReturn             816.41
2017-06-11 05:50:08.864847 EDT | StdReturn                 349.317
2017-06-11 05:50:08.865209 EDT | MaxReturn                1762.24
2017-06-11 05:50:08.865555 EDT | MinReturn                 454.474
2017-06-11 05:50:08.865906 EDT | AverageEsReturn           476.688
2017-06-11 05:50:08.866266 EDT | StdEsReturn               297.704
2017-06-11 05:50:08.866609 EDT | MaxEsReturn               935.686
2017-06-11 05:50:08.866952 EDT | MinEsReturn                16.1724
2017-06-11 05:50:08.867310 EDT | AverageDiscountedReturn   219.019
2017-06-11 05:50:08.867654 EDT | AverageQLoss                1.83375
2017-06-11 05:50:08.867996 EDT | AveragePolicySurr         -27.0148
2017-06-11 05:50:08.868542 EDT | AverageQ                   26.8195
2017-06-11 05:50:08.868871 EDT | AverageAbsQ                26.8368
2017-06-11 05:50:08.869217 EDT | AverageY                   26.8208
2017-06-11 05:50:08.869585 EDT | AverageAbsY                26.8297
2017-06-11 05:50:08.869938 EDT | AverageAbsQYDiff            0.464094
2017-06-11 05:50:08.870279 EDT | AverageAction               0.999096
2017-06-11 05:50:08.870646 EDT | PolicyRegParamNorm        106.995
2017-06-11 05:50:08.870997 EDT | QFunRegParamNorm          138.987
2017-06-11 05:50:08.871336 EDT | -----------------------  -----------
2017-06-11 05:50:08.871854 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1287 | Training started
2017-06-11 05:50:25.914627 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1287 | Training finished
2017-06-11 05:50:25.916069 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1287 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 05:50:25.916568 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1287 | Collecting samples for evaluation
2017-06-11 05:50:40.594850 EDT | -----------------------  -----------
2017-06-11 05:50:40.595602 EDT | Epoch                    1287
2017-06-11 05:50:40.595804 EDT | Iteration                1287
2017-06-11 05:50:40.596007 EDT | AverageReturn            1166.89
2017-06-11 05:50:40.596176 EDT | StdReturn                1257.49
2017-06-11 05:50:40.596428 EDT | MaxReturn                3245.37
2017-06-11 05:50:40.596590 EDT | MinReturn                 255.303
2017-06-11 05:50:40.596852 EDT | AverageEsReturn           643.407
2017-06-11 05:50:40.597018 EDT | StdEsReturn               240.651
2017-06-11 05:50:40.597176 EDT | MaxEsReturn               967.135
2017-06-11 05:50:40.597336 EDT | MinEsReturn               274.256
2017-06-11 05:50:40.597552 EDT | AverageDiscountedReturn   189.306
2017-06-11 05:50:40.597767 EDT | AverageQLoss                1.73825
2017-06-11 05:50:40.597927 EDT | AveragePolicySurr         -27.0422
2017-06-11 05:50:40.598142 EDT | AverageQ                   26.8429
2017-06-11 05:50:40.598301 EDT | AverageAbsQ                26.8573
2017-06-11 05:50:40.598514 EDT | AverageY                   26.8447
2017-06-11 05:50:40.598714 EDT | AverageAbsY                26.8519
2017-06-11 05:50:40.598873 EDT | AverageAbsQYDiff            0.462291
2017-06-11 05:50:40.599030 EDT | AverageAction               0.999366
2017-06-11 05:50:40.599185 EDT | PolicyRegParamNorm        106.91
2017-06-11 05:50:40.599340 EDT | QFunRegParamNorm          139.065
2017-06-11 05:50:40.599521 EDT | -----------------------  -----------
2017-06-11 05:50:40.599783 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1288 | Training started
2017-06-11 05:50:57.479746 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1288 | Training finished
2017-06-11 05:50:57.480718 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1288 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 05:50:57.481078 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1288 | Collecting samples for evaluation
2017-06-11 05:51:12.668919 EDT | -----------------------  -----------
2017-06-11 05:51:12.670044 EDT | Epoch                    1288
2017-06-11 05:51:12.670515 EDT | Iteration                1288
2017-06-11 05:51:12.670964 EDT | AverageReturn             255.401
2017-06-11 05:51:12.671408 EDT | StdReturn                  29.0218
2017-06-11 05:51:12.671851 EDT | MaxReturn                 533.909
2017-06-11 05:51:12.672293 EDT | MinReturn                 240.46
2017-06-11 05:51:12.672737 EDT | AverageEsReturn           228.738
2017-06-11 05:51:12.673183 EDT | StdEsReturn                76.0593
2017-06-11 05:51:12.686373 EDT | MaxEsReturn               292.771
2017-06-11 05:51:12.687192 EDT | MinEsReturn                23.9959
2017-06-11 05:51:12.687821 EDT | AverageDiscountedReturn   144.247
2017-06-11 05:51:12.688439 EDT | AverageQLoss                1.62998
2017-06-11 05:51:12.689053 EDT | AveragePolicySurr         -27.1
2017-06-11 05:51:12.689656 EDT | AverageQ                   26.9125
2017-06-11 05:51:12.690278 EDT | AverageAbsQ                26.924
2017-06-11 05:51:12.690889 EDT | AverageY                   26.9127
2017-06-11 05:51:12.691669 EDT | AverageAbsY                26.9173
2017-06-11 05:51:12.692496 EDT | AverageAbsQYDiff            0.449642
2017-06-11 05:51:12.693332 EDT | AverageAction               0.998976
2017-06-11 05:51:12.694179 EDT | PolicyRegParamNorm        106.883
2017-06-11 05:51:12.695006 EDT | QFunRegParamNorm          139.099
2017-06-11 05:51:12.695839 EDT | -----------------------  -----------
2017-06-11 05:51:12.696836 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1289 | Training started
2017-06-11 05:51:31.016510 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1289 | Training finished
2017-06-11 05:51:31.016930 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1289 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 05:51:31.017276 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1289 | Collecting samples for evaluation
2017-06-11 05:51:45.384891 EDT | -----------------------  -----------
2017-06-11 05:51:45.392559 EDT | Epoch                    1289
2017-06-11 05:51:45.393054 EDT | Iteration                1289
2017-06-11 05:51:45.393630 EDT | AverageReturn             279.094
2017-06-11 05:51:45.393890 EDT | StdReturn                   7.42017
2017-06-11 05:51:45.394048 EDT | MaxReturn                 297.06
2017-06-11 05:51:45.394287 EDT | MinReturn                 266.966
2017-06-11 05:51:45.394443 EDT | AverageEsReturn           330.884
2017-06-11 05:51:45.394595 EDT | StdEsReturn                90.9937
2017-06-11 05:51:45.394746 EDT | MaxEsReturn               510.516
2017-06-11 05:51:45.394896 EDT | MinEsReturn               197.871
2017-06-11 05:51:45.395070 EDT | AverageDiscountedReturn   153.241
2017-06-11 05:51:45.395227 EDT | AverageQLoss                1.75338
2017-06-11 05:51:45.395378 EDT | AveragePolicySurr         -27.0969
2017-06-11 05:51:45.395527 EDT | AverageQ                   26.8911
2017-06-11 05:51:45.395676 EDT | AverageAbsQ                26.9092
2017-06-11 05:51:45.395825 EDT | AverageY                   26.8927
2017-06-11 05:51:45.395972 EDT | AverageAbsY                26.8987
2017-06-11 05:51:45.396121 EDT | AverageAbsQYDiff            0.460256
2017-06-11 05:51:45.396268 EDT | AverageAction               0.999584
2017-06-11 05:51:45.396416 EDT | PolicyRegParamNorm        106.882
2017-06-11 05:51:45.396564 EDT | QFunRegParamNorm          139.147
2017-06-11 05:51:45.396712 EDT | -----------------------  -----------
2017-06-11 05:51:45.396964 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1290 | Training started
2017-06-11 05:52:03.134187 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1290 | Training finished
2017-06-11 05:52:03.134580 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1290 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 05:52:03.134852 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1290 | Collecting samples for evaluation
2017-06-11 05:52:17.679375 EDT | -----------------------  -----------
2017-06-11 05:52:17.680501 EDT | Epoch                    1290
2017-06-11 05:52:17.680783 EDT | Iteration                1290
2017-06-11 05:52:17.681055 EDT | AverageReturn             942.062
2017-06-11 05:52:17.681313 EDT | StdReturn                 397.478
2017-06-11 05:52:17.681544 EDT | MaxReturn                2187.11
2017-06-11 05:52:17.681829 EDT | MinReturn                 528.023
2017-06-11 05:52:17.682018 EDT | AverageEsReturn           280.003
2017-06-11 05:52:17.682205 EDT | StdEsReturn               197.137
2017-06-11 05:52:17.682394 EDT | MaxEsReturn               679.8
2017-06-11 05:52:17.682615 EDT | MinEsReturn                85.7941
2017-06-11 05:52:17.682987 EDT | AverageDiscountedReturn   248.143
2017-06-11 05:52:17.683185 EDT | AverageQLoss                1.65185
2017-06-11 05:52:17.684346 EDT | AveragePolicySurr         -27.108
2017-06-11 05:52:17.684543 EDT | AverageQ                   26.9017
2017-06-11 05:52:17.684729 EDT | AverageAbsQ                26.9147
2017-06-11 05:52:17.684948 EDT | AverageY                   26.9023
2017-06-11 05:52:17.685134 EDT | AverageAbsY                26.9063
2017-06-11 05:52:17.685316 EDT | AverageAbsQYDiff            0.445106
2017-06-11 05:52:17.685506 EDT | AverageAction               0.999584
2017-06-11 05:52:17.685703 EDT | PolicyRegParamNorm        106.905
2017-06-11 05:52:17.685906 EDT | QFunRegParamNorm          139.158
2017-06-11 05:52:17.686088 EDT | -----------------------  -----------
2017-06-11 05:52:17.686379 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1291 | Training started
2017-06-11 05:52:35.666866 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1291 | Training finished
2017-06-11 05:52:35.668137 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1291 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 05:52:35.668355 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1291 | Collecting samples for evaluation
2017-06-11 05:52:50.360227 EDT | -----------------------  -----------
2017-06-11 05:52:50.361364 EDT | Epoch                    1291
2017-06-11 05:52:50.361903 EDT | Iteration                1291
2017-06-11 05:52:50.362324 EDT | AverageReturn            2024.84
2017-06-11 05:52:50.362764 EDT | StdReturn                 760.632
2017-06-11 05:52:50.363260 EDT | MaxReturn                3505.19
2017-06-11 05:52:50.363680 EDT | MinReturn                 859.256
2017-06-11 05:52:50.364115 EDT | AverageEsReturn           240.626
2017-06-11 05:52:50.364604 EDT | StdEsReturn               191.997
2017-06-11 05:52:50.365027 EDT | MaxEsReturn               600.174
2017-06-11 05:52:50.365463 EDT | MinEsReturn                14.0877
2017-06-11 05:52:50.365945 EDT | AverageDiscountedReturn   264.775
2017-06-11 05:52:50.366374 EDT | AverageQLoss                1.83765
2017-06-11 05:52:50.366810 EDT | AveragePolicySurr         -27.1413
2017-06-11 05:52:50.367306 EDT | AverageQ                   26.9057
2017-06-11 05:52:50.367739 EDT | AverageAbsQ                26.9242
2017-06-11 05:52:50.368241 EDT | AverageY                   26.9079
2017-06-11 05:52:50.368669 EDT | AverageAbsY                26.9153
2017-06-11 05:52:50.369215 EDT | AverageAbsQYDiff            0.469876
2017-06-11 05:52:50.369648 EDT | AverageAction               0.999352
2017-06-11 05:52:50.370326 EDT | PolicyRegParamNorm        106.941
2017-06-11 05:52:50.370759 EDT | QFunRegParamNorm          139.188
2017-06-11 05:52:50.371194 EDT | -----------------------  -----------
2017-06-11 05:52:50.371765 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1292 | Training started
2017-06-11 05:53:07.609225 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1292 | Training finished
2017-06-11 05:53:07.610001 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1292 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 05:53:07.610193 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1292 | Collecting samples for evaluation
2017-06-11 05:53:21.511342 EDT | -----------------------  -----------
2017-06-11 05:53:21.513454 EDT | Epoch                    1292
2017-06-11 05:53:21.513777 EDT | Iteration                1292
2017-06-11 05:53:21.514029 EDT | AverageReturn            1859.55
2017-06-11 05:53:21.514306 EDT | StdReturn                 611.859
2017-06-11 05:53:21.514561 EDT | MaxReturn                3316.08
2017-06-11 05:53:21.514811 EDT | MinReturn                 823.355
2017-06-11 05:53:21.515068 EDT | AverageEsReturn           424.452
2017-06-11 05:53:21.515317 EDT | StdEsReturn               438.009
2017-06-11 05:53:21.515563 EDT | MaxEsReturn              1184.18
2017-06-11 05:53:21.515809 EDT | MinEsReturn                10.2424
2017-06-11 05:53:21.516055 EDT | AverageDiscountedReturn   265.418
2017-06-11 05:53:21.516300 EDT | AverageQLoss                1.72366
2017-06-11 05:53:21.516548 EDT | AveragePolicySurr         -27.1373
2017-06-11 05:53:21.516795 EDT | AverageQ                   26.9216
2017-06-11 05:53:21.517071 EDT | AverageAbsQ                26.9379
2017-06-11 05:53:21.517392 EDT | AverageY                   26.9215
2017-06-11 05:53:21.518672 EDT | AverageAbsY                26.929
2017-06-11 05:53:21.519197 EDT | AverageAbsQYDiff            0.459512
2017-06-11 05:53:21.519648 EDT | AverageAction               0.99902
2017-06-11 05:53:21.519999 EDT | PolicyRegParamNorm        107.035
2017-06-11 05:53:21.520344 EDT | QFunRegParamNorm          139.206
2017-06-11 05:53:21.520689 EDT | -----------------------  -----------
2017-06-11 05:53:21.521261 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1293 | Training started
2017-06-11 05:53:39.131025 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1293 | Training finished
2017-06-11 05:53:39.131852 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1293 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 05:53:39.132404 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1293 | Collecting samples for evaluation
2017-06-11 05:53:52.769874 EDT | -----------------------  -----------
2017-06-11 05:53:52.771244 EDT | Epoch                    1293
2017-06-11 05:53:52.771457 EDT | Iteration                1293
2017-06-11 05:53:52.771661 EDT | AverageReturn            1221.93
2017-06-11 05:53:52.771857 EDT | StdReturn                 701.176
2017-06-11 05:53:52.772118 EDT | MaxReturn                2949.13
2017-06-11 05:53:52.772402 EDT | MinReturn                 551.974
2017-06-11 05:53:52.772588 EDT | AverageEsReturn           447.713
2017-06-11 05:53:52.772827 EDT | StdEsReturn               375.513
2017-06-11 05:53:52.773011 EDT | MaxEsReturn               850.415
2017-06-11 05:53:52.773187 EDT | MinEsReturn                 6.01222
2017-06-11 05:53:52.773350 EDT | AverageDiscountedReturn   247.661
2017-06-11 05:53:52.773509 EDT | AverageQLoss                1.85261
2017-06-11 05:53:52.773665 EDT | AveragePolicySurr         -27.1127
2017-06-11 05:53:52.773849 EDT | AverageQ                   26.9228
2017-06-11 05:53:52.774029 EDT | AverageAbsQ                26.9371
2017-06-11 05:53:52.774187 EDT | AverageY                   26.924
2017-06-11 05:53:52.774350 EDT | AverageAbsY                26.9301
2017-06-11 05:53:52.774526 EDT | AverageAbsQYDiff            0.47148
2017-06-11 05:53:52.774742 EDT | AverageAction               0.999188
2017-06-11 05:53:52.775031 EDT | PolicyRegParamNorm        107.126
2017-06-11 05:53:52.775288 EDT | QFunRegParamNorm          139.232
2017-06-11 05:53:52.775576 EDT | -----------------------  -----------
2017-06-11 05:53:52.776007 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1294 | Training started
2017-06-11 05:54:09.919930 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1294 | Training finished
2017-06-11 05:54:09.920896 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1294 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 05:54:09.921295 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1294 | Collecting samples for evaluation
2017-06-11 05:54:23.759560 EDT | -----------------------  -----------
2017-06-11 05:54:23.760526 EDT | Epoch                    1294
2017-06-11 05:54:23.760905 EDT | Iteration                1294
2017-06-11 05:54:23.761252 EDT | AverageReturn            2979.08
2017-06-11 05:54:23.761587 EDT | StdReturn                  56.3768
2017-06-11 05:54:23.761939 EDT | MaxReturn                3078.36
2017-06-11 05:54:23.762383 EDT | MinReturn                2901.43
2017-06-11 05:54:23.762803 EDT | AverageEsReturn           619.733
2017-06-11 05:54:23.763153 EDT | StdEsReturn               299.11
2017-06-11 05:54:23.763508 EDT | MaxEsReturn               956.949
2017-06-11 05:54:23.763944 EDT | MinEsReturn                29.0212
2017-06-11 05:54:23.764384 EDT | AverageDiscountedReturn   243.401
2017-06-11 05:54:23.764827 EDT | AverageQLoss                1.50121
2017-06-11 05:54:23.765175 EDT | AveragePolicySurr         -27.1779
2017-06-11 05:54:23.765513 EDT | AverageQ                   26.9736
2017-06-11 05:54:23.781797 EDT | AverageAbsQ                26.9877
2017-06-11 05:54:23.782204 EDT | AverageY                   26.9759
2017-06-11 05:54:23.782654 EDT | AverageAbsY                26.9817
2017-06-11 05:54:23.783104 EDT | AverageAbsQYDiff            0.435355
2017-06-11 05:54:23.783546 EDT | AverageAction               0.999117
2017-06-11 05:54:23.783996 EDT | PolicyRegParamNorm        107.177
2017-06-11 05:54:23.784438 EDT | QFunRegParamNorm          139.305
2017-06-11 05:54:23.784879 EDT | -----------------------  -----------
2017-06-11 05:54:23.785494 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1295 | Training started
2017-06-11 05:54:41.709312 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1295 | Training finished
2017-06-11 05:54:41.709581 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1295 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 05:54:41.709891 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1295 | Collecting samples for evaluation
2017-06-11 05:54:54.908346 EDT | -----------------------  -----------
2017-06-11 05:54:54.909228 EDT | Epoch                    1295
2017-06-11 05:54:54.909606 EDT | Iteration                1295
2017-06-11 05:54:54.909942 EDT | AverageReturn            1255.9
2017-06-11 05:54:54.910146 EDT | StdReturn                 680.754
2017-06-11 05:54:54.910387 EDT | MaxReturn                2792.5
2017-06-11 05:54:54.910748 EDT | MinReturn                 457.801
2017-06-11 05:54:54.911096 EDT | AverageEsReturn           515.186
2017-06-11 05:54:54.911422 EDT | StdEsReturn               325.794
2017-06-11 05:54:54.914285 EDT | MaxEsReturn              1052.03
2017-06-11 05:54:54.915188 EDT | MinEsReturn                16.2489
2017-06-11 05:54:54.915463 EDT | AverageDiscountedReturn   245.976
2017-06-11 05:54:54.915769 EDT | AverageQLoss                1.63888
2017-06-11 05:54:54.916093 EDT | AveragePolicySurr         -27.2573
2017-06-11 05:54:54.916398 EDT | AverageQ                   27.0491
2017-06-11 05:54:54.916655 EDT | AverageAbsQ                27.0625
2017-06-11 05:54:54.916925 EDT | AverageY                   27.0504
2017-06-11 05:54:54.917280 EDT | AverageAbsY                27.0559
2017-06-11 05:54:54.917640 EDT | AverageAbsQYDiff            0.454311
2017-06-11 05:54:54.918084 EDT | AverageAction               0.999289
2017-06-11 05:54:54.918585 EDT | PolicyRegParamNorm        107.177
2017-06-11 05:54:54.918920 EDT | QFunRegParamNorm          139.344
2017-06-11 05:54:54.919261 EDT | -----------------------  -----------
2017-06-11 05:54:54.919714 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1296 | Training started
2017-06-11 05:55:11.342475 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1296 | Training finished
2017-06-11 05:55:11.343367 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1296 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 05:55:11.343659 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1296 | Collecting samples for evaluation
2017-06-11 05:55:27.167944 EDT | -----------------------  -----------
2017-06-11 05:55:27.169005 EDT | Epoch                    1296
2017-06-11 05:55:27.169392 EDT | Iteration                1296
2017-06-11 05:55:27.169833 EDT | AverageReturn               7.35712
2017-06-11 05:55:27.170450 EDT | StdReturn                   0.203393
2017-06-11 05:55:27.170854 EDT | MaxReturn                   7.68545
2017-06-11 05:55:27.171292 EDT | MinReturn                   5.9642
2017-06-11 05:55:27.172008 EDT | AverageEsReturn           367.301
2017-06-11 05:55:27.172450 EDT | StdEsReturn               583.257
2017-06-11 05:55:27.175237 EDT | MaxEsReturn              1848.49
2017-06-11 05:55:27.176290 EDT | MinEsReturn                 7.12828
2017-06-11 05:55:27.177423 EDT | AverageDiscountedReturn     7.09862
2017-06-11 05:55:27.178604 EDT | AverageQLoss                1.70742
2017-06-11 05:55:27.179743 EDT | AveragePolicySurr         -27.1761
2017-06-11 05:55:27.181043 EDT | AverageQ                   26.9825
2017-06-11 05:55:27.183581 EDT | AverageAbsQ                26.9927
2017-06-11 05:55:27.184617 EDT | AverageY                   26.9845
2017-06-11 05:55:27.185988 EDT | AverageAbsY                26.9866
2017-06-11 05:55:27.188016 EDT | AverageAbsQYDiff            0.449133
2017-06-11 05:55:27.189226 EDT | AverageAction               0.999598
2017-06-11 05:55:27.190422 EDT | PolicyRegParamNorm        107.227
2017-06-11 05:55:27.191628 EDT | QFunRegParamNorm          139.371
2017-06-11 05:55:27.192820 EDT | -----------------------  -----------
2017-06-11 05:55:27.194339 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1297 | Training started
2017-06-11 05:55:44.825553 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1297 | Training finished
2017-06-11 05:55:44.874063 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1297 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 05:55:44.874723 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1297 | Collecting samples for evaluation
2017-06-11 05:56:01.318916 EDT | -----------------------  -----------
2017-06-11 05:56:01.319792 EDT | Epoch                    1297
2017-06-11 05:56:01.320147 EDT | Iteration                1297
2017-06-11 05:56:01.320465 EDT | AverageReturn               7.4094
2017-06-11 05:56:01.320753 EDT | StdReturn                   0.179895
2017-06-11 05:56:01.321011 EDT | MaxReturn                   7.67318
2017-06-11 05:56:01.321274 EDT | MinReturn                   6.03872
2017-06-11 05:56:01.321593 EDT | AverageEsReturn           118.696
2017-06-11 05:56:01.321914 EDT | StdEsReturn               228.478
2017-06-11 05:56:01.322173 EDT | MaxEsReturn               795.232
2017-06-11 05:56:01.324787 EDT | MinEsReturn                 4.36268
2017-06-11 05:56:01.325101 EDT | AverageDiscountedReturn     7.14753
2017-06-11 05:56:01.325377 EDT | AverageQLoss                2.0551
2017-06-11 05:56:01.325673 EDT | AveragePolicySurr         -27.1191
2017-06-11 05:56:01.326009 EDT | AverageQ                   26.9567
2017-06-11 05:56:01.326307 EDT | AverageAbsQ                26.9706
2017-06-11 05:56:01.326587 EDT | AverageY                   26.9575
2017-06-11 05:56:01.326872 EDT | AverageAbsY                26.9616
2017-06-11 05:56:01.327141 EDT | AverageAbsQYDiff            0.471621
2017-06-11 05:56:01.327435 EDT | AverageAction               0.999969
2017-06-11 05:56:01.327747 EDT | PolicyRegParamNorm        107.258
2017-06-11 05:56:01.328024 EDT | QFunRegParamNorm          139.408
2017-06-11 05:56:01.328345 EDT | -----------------------  -----------
2017-06-11 05:56:01.328799 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1298 | Training started
2017-06-11 05:56:20.766653 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1298 | Training finished
2017-06-11 05:56:20.767456 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1298 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 05:56:20.767670 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1298 | Collecting samples for evaluation
2017-06-11 05:56:35.599443 EDT | -----------------------  -----------
2017-06-11 05:56:35.600378 EDT | Epoch                    1298
2017-06-11 05:56:35.600683 EDT | Iteration                1298
2017-06-11 05:56:35.600873 EDT | AverageReturn               7.40518
2017-06-11 05:56:35.601088 EDT | StdReturn                   0.156503
2017-06-11 05:56:35.601287 EDT | MaxReturn                   7.67668
2017-06-11 05:56:35.601485 EDT | MinReturn                   6.06313
2017-06-11 05:56:35.601690 EDT | AverageEsReturn            27.6742
2017-06-11 05:56:35.601907 EDT | StdEsReturn               118.646
2017-06-11 05:56:35.602102 EDT | MaxEsReturn               915.02
2017-06-11 05:56:35.602294 EDT | MinEsReturn                 5.6877
2017-06-11 05:56:35.602486 EDT | AverageDiscountedReturn     7.14336
2017-06-11 05:56:35.602691 EDT | AverageQLoss                1.84557
2017-06-11 05:56:35.602974 EDT | AveragePolicySurr         -27.0107
2017-06-11 05:56:35.603172 EDT | AverageQ                   26.8809
2017-06-11 05:56:35.603367 EDT | AverageAbsQ                26.8959
2017-06-11 05:56:35.603769 EDT | AverageY                   26.8821
2017-06-11 05:56:35.603974 EDT | AverageAbsY                26.8886
2017-06-11 05:56:35.604236 EDT | AverageAbsQYDiff            0.478275
2017-06-11 05:56:35.604434 EDT | AverageAction               0.999939
2017-06-11 05:56:35.604629 EDT | PolicyRegParamNorm        107.285
2017-06-11 05:56:35.604834 EDT | QFunRegParamNorm          139.424
2017-06-11 05:56:35.605125 EDT | -----------------------  -----------
2017-06-11 05:56:35.605534 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1299 | Training started
2017-06-11 05:56:54.071130 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1299 | Training finished
2017-06-11 05:56:54.072042 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1299 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 05:56:54.072240 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1299 | Collecting samples for evaluation
2017-06-11 05:57:10.355955 EDT | -----------------------  -----------
2017-06-11 05:57:10.357295 EDT | Epoch                    1299
2017-06-11 05:57:10.357734 EDT | Iteration                1299
2017-06-11 05:57:10.358161 EDT | AverageReturn               9.50365
2017-06-11 05:57:10.358601 EDT | StdReturn                   0.787802
2017-06-11 05:57:10.359027 EDT | MaxReturn                  11.0902
2017-06-11 05:57:10.359424 EDT | MinReturn                   7.44921
2017-06-11 05:57:10.359859 EDT | AverageEsReturn            20.5666
2017-06-11 05:57:10.360291 EDT | StdEsReturn                49.2188
2017-06-11 05:57:10.360659 EDT | MaxEsReturn               318.051
2017-06-11 05:57:10.361083 EDT | MinEsReturn                 5.20037
2017-06-11 05:57:10.361516 EDT | AverageDiscountedReturn     9.08197
2017-06-11 05:57:10.361929 EDT | AverageQLoss                2.14333
2017-06-11 05:57:10.362353 EDT | AveragePolicySurr         -26.971
2017-06-11 05:57:10.362788 EDT | AverageQ                   26.8211
2017-06-11 05:57:10.363211 EDT | AverageAbsQ                26.8351
2017-06-11 05:57:10.363606 EDT | AverageY                   26.8217
2017-06-11 05:57:10.364168 EDT | AverageAbsY                26.8264
2017-06-11 05:57:10.365794 EDT | AverageAbsQYDiff            0.508076
2017-06-11 05:57:10.366180 EDT | AverageAction               1
2017-06-11 05:57:10.366618 EDT | PolicyRegParamNorm        107.303
2017-06-11 05:57:10.367806 EDT | QFunRegParamNorm          139.44
2017-06-11 05:57:10.368706 EDT | -----------------------  -----------
2017-06-11 05:57:10.369291 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1300 | Training started
2017-06-11 05:57:27.966573 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1300 | Training finished
2017-06-11 05:57:27.967556 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1300 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 05:57:27.967926 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1300 | Collecting samples for evaluation
2017-06-11 05:57:42.540041 EDT | -----------------------  -----------
2017-06-11 05:57:42.541345 EDT | Epoch                    1300
2017-06-11 05:57:42.541840 EDT | Iteration                1300
2017-06-11 05:57:42.542291 EDT | AverageReturn            1736.1
2017-06-11 05:57:42.542743 EDT | StdReturn                1275.14
2017-06-11 05:57:42.543208 EDT | MaxReturn                3491.51
2017-06-11 05:57:42.543659 EDT | MinReturn                 537.41
2017-06-11 05:57:42.544110 EDT | AverageEsReturn           247.81
2017-06-11 05:57:42.544577 EDT | StdEsReturn               341.608
2017-06-11 05:57:42.545025 EDT | MaxEsReturn              1222.28
2017-06-11 05:57:42.545470 EDT | MinEsReturn                 8.38102
2017-06-11 05:57:42.545947 EDT | AverageDiscountedReturn   236.101
2017-06-11 05:57:42.546394 EDT | AverageQLoss                1.68681
2017-06-11 05:57:42.546854 EDT | AveragePolicySurr         -27.05
2017-06-11 05:57:42.547301 EDT | AverageQ                   26.848
2017-06-11 05:57:42.547752 EDT | AverageAbsQ                26.8644
2017-06-11 05:57:42.548243 EDT | AverageY                   26.8501
2017-06-11 05:57:42.548693 EDT | AverageAbsY                26.8568
2017-06-11 05:57:42.549628 EDT | AverageAbsQYDiff            0.48845
2017-06-11 05:57:42.550100 EDT | AverageAction               0.999236
2017-06-11 05:57:42.550547 EDT | PolicyRegParamNorm        107.399
2017-06-11 05:57:42.550995 EDT | QFunRegParamNorm          139.505
2017-06-11 05:57:42.551437 EDT | -----------------------  -----------
2017-06-11 05:57:42.552061 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1301 | Training started
2017-06-11 05:57:59.599230 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1301 | Training finished
2017-06-11 05:57:59.600236 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1301 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 05:57:59.600638 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1301 | Collecting samples for evaluation
2017-06-11 05:58:13.612777 EDT | -----------------------  -----------
2017-06-11 05:58:13.614532 EDT | Epoch                    1301
2017-06-11 05:58:13.614833 EDT | Iteration                1301
2017-06-11 05:58:13.615109 EDT | AverageReturn            1052.42
2017-06-11 05:58:13.615391 EDT | StdReturn                 585.251
2017-06-11 05:58:13.615682 EDT | MaxReturn                2406.88
2017-06-11 05:58:13.615962 EDT | MinReturn                 301.863
2017-06-11 05:58:13.616225 EDT | AverageEsReturn           405.186
2017-06-11 05:58:13.616480 EDT | StdEsReturn               328.602
2017-06-11 05:58:13.616732 EDT | MaxEsReturn               937.062
2017-06-11 05:58:13.617008 EDT | MinEsReturn                18.5382
2017-06-11 05:58:13.617294 EDT | AverageDiscountedReturn   208.449
2017-06-11 05:58:13.618059 EDT | AverageQLoss                1.92232
2017-06-11 05:58:13.618846 EDT | AveragePolicySurr         -27.1657
2017-06-11 05:58:13.619623 EDT | AverageQ                   26.9351
2017-06-11 05:58:13.620410 EDT | AverageAbsQ                26.9474
2017-06-11 05:58:13.621352 EDT | AverageY                   26.937
2017-06-11 05:58:13.622210 EDT | AverageAbsY                26.9419
2017-06-11 05:58:13.623058 EDT | AverageAbsQYDiff            0.491068
2017-06-11 05:58:13.623871 EDT | AverageAction               0.998883
2017-06-11 05:58:13.624689 EDT | PolicyRegParamNorm        107.434
2017-06-11 05:58:13.625545 EDT | QFunRegParamNorm          139.578
2017-06-11 05:58:13.626357 EDT | -----------------------  -----------
2017-06-11 05:58:13.627282 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1302 | Training started
2017-06-11 05:58:31.471058 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1302 | Training finished
2017-06-11 05:58:31.472990 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1302 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 05:58:31.473421 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1302 | Collecting samples for evaluation
2017-06-11 05:58:46.033163 EDT | -----------------------  -----------
2017-06-11 05:58:46.033430 EDT | Epoch                    1302
2017-06-11 05:58:46.033620 EDT | Iteration                1302
2017-06-11 05:58:46.033819 EDT | AverageReturn             932.098
2017-06-11 05:58:46.033975 EDT | StdReturn                 516.87
2017-06-11 05:58:46.034129 EDT | MaxReturn                2733.38
2017-06-11 05:58:46.034280 EDT | MinReturn                 655.873
2017-06-11 05:58:46.034431 EDT | AverageEsReturn           375.879
2017-06-11 05:58:46.034580 EDT | StdEsReturn               147.98
2017-06-11 05:58:46.034773 EDT | MaxEsReturn               554.526
2017-06-11 05:58:46.034926 EDT | MinEsReturn               175.182
2017-06-11 05:58:46.035078 EDT | AverageDiscountedReturn   219.325
2017-06-11 05:58:46.035288 EDT | AverageQLoss                1.88777
2017-06-11 05:58:46.035441 EDT | AveragePolicySurr         -27.1961
2017-06-11 05:58:46.035592 EDT | AverageQ                   26.9922
2017-06-11 05:58:46.035741 EDT | AverageAbsQ                27.005
2017-06-11 05:58:46.035904 EDT | AverageY                   26.9942
2017-06-11 05:58:46.036055 EDT | AverageAbsY                26.9995
2017-06-11 05:58:46.036204 EDT | AverageAbsQYDiff            0.469534
2017-06-11 05:58:46.036354 EDT | AverageAction               0.999247
2017-06-11 05:58:46.036505 EDT | PolicyRegParamNorm        107.432
2017-06-11 05:58:46.036750 EDT | QFunRegParamNorm          139.626
2017-06-11 05:58:46.036916 EDT | -----------------------  -----------
2017-06-11 05:58:46.037175 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1303 | Training started
2017-06-11 05:59:03.089368 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1303 | Training finished
2017-06-11 05:59:03.090491 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1303 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 05:59:03.091006 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1303 | Collecting samples for evaluation
2017-06-11 05:59:18.355531 EDT | -----------------------  -----------
2017-06-11 05:59:18.356090 EDT | Epoch                    1303
2017-06-11 05:59:18.356475 EDT | Iteration                1303
2017-06-11 05:59:18.356827 EDT | AverageReturn             752.076
2017-06-11 05:59:18.357234 EDT | StdReturn                 320.467
2017-06-11 05:59:18.357597 EDT | MaxReturn                1511.78
2017-06-11 05:59:18.358248 EDT | MinReturn                 468.646
2017-06-11 05:59:18.358635 EDT | AverageEsReturn           479.058
2017-06-11 05:59:18.359334 EDT | StdEsReturn               182.141
2017-06-11 05:59:18.359781 EDT | MaxEsReturn               882.027
2017-06-11 05:59:18.360116 EDT | MinEsReturn               326.216
2017-06-11 05:59:18.360487 EDT | AverageDiscountedReturn   226.281
2017-06-11 05:59:18.361091 EDT | AverageQLoss                1.69586
2017-06-11 05:59:18.361482 EDT | AveragePolicySurr         -27.2154
2017-06-11 05:59:18.361836 EDT | AverageQ                   26.9979
2017-06-11 05:59:18.362356 EDT | AverageAbsQ                27.0096
2017-06-11 05:59:18.362737 EDT | AverageY                   27.0007
2017-06-11 05:59:18.363451 EDT | AverageAbsY                27.0037
2017-06-11 05:59:18.365765 EDT | AverageAbsQYDiff            0.473702
2017-06-11 05:59:18.366291 EDT | AverageAction               0.998864
2017-06-11 05:59:18.366623 EDT | PolicyRegParamNorm        107.392
2017-06-11 05:59:18.367181 EDT | QFunRegParamNorm          139.718
2017-06-11 05:59:18.367531 EDT | -----------------------  -----------
2017-06-11 05:59:18.368008 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1304 | Training started
2017-06-11 05:59:35.697958 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1304 | Training finished
2017-06-11 05:59:35.698981 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1304 | Trained qf 1000 steps, policy 1000 steps
2017-06-11 05:59:35.699393 EDT | [reproducibility_ML/DDPG/Hopper/Reverse_Reward_Scale_Tune/Reward_Scale_0.1_Experiment_1] epoch #1304 | Collecting samples for evaluation
