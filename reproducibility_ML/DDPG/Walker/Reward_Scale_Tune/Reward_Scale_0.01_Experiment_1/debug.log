2017-07-02 15:45:54.208846 EDT | [reproducibility_ML/DDPG/Walker/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] observation space: Box(17,)
2017-07-02 15:45:54.209112 EDT | [reproducibility_ML/DDPG/Walker/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] action space: Box(6,)
2017-07-02 15:45:54.328664 EDT | [reproducibility_ML/DDPG/Walker/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] Populating workers...
2017-07-02 15:45:54.329270 EDT | [reproducibility_ML/DDPG/Walker/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] Populated
2017-07-02 15:45:55.018641 EDT | [reproducibility_ML/DDPG/Walker/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #0 | Training started
2017-07-02 15:45:56.010380 EDT | [reproducibility_ML/DDPG/Walker/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #0 | Training finished
2017-07-02 15:45:56.010685 EDT | [reproducibility_ML/DDPG/Walker/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #0 | Trained qf 0 steps, policy 0 steps
2017-07-02 15:45:56.010948 EDT | [reproducibility_ML/DDPG/Walker/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #1 | Training started
2017-07-02 15:45:56.992071 EDT | [reproducibility_ML/DDPG/Walker/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #1 | Training finished
2017-07-02 15:45:56.992609 EDT | [reproducibility_ML/DDPG/Walker/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #1 | Trained qf 0 steps, policy 0 steps
2017-07-02 15:45:56.992780 EDT | [reproducibility_ML/DDPG/Walker/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #2 | Training started
2017-07-02 15:45:57.955503 EDT | [reproducibility_ML/DDPG/Walker/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #2 | Training finished
2017-07-02 15:45:57.955781 EDT | [reproducibility_ML/DDPG/Walker/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #2 | Trained qf 0 steps, policy 0 steps
2017-07-02 15:45:57.955974 EDT | [reproducibility_ML/DDPG/Walker/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #3 | Training started
2017-07-02 15:45:58.929099 EDT | [reproducibility_ML/DDPG/Walker/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #3 | Training finished
2017-07-02 15:45:58.929405 EDT | [reproducibility_ML/DDPG/Walker/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #3 | Trained qf 0 steps, policy 0 steps
2017-07-02 15:45:58.929683 EDT | [reproducibility_ML/DDPG/Walker/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #4 | Training started
2017-07-02 15:45:59.895080 EDT | [reproducibility_ML/DDPG/Walker/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #4 | Training finished
2017-07-02 15:45:59.895318 EDT | [reproducibility_ML/DDPG/Walker/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #4 | Trained qf 0 steps, policy 0 steps
2017-07-02 15:45:59.895497 EDT | [reproducibility_ML/DDPG/Walker/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #5 | Training started
2017-07-02 15:46:00.877382 EDT | [reproducibility_ML/DDPG/Walker/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #5 | Training finished
2017-07-02 15:46:00.877713 EDT | [reproducibility_ML/DDPG/Walker/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #5 | Trained qf 0 steps, policy 0 steps
2017-07-02 15:46:00.877971 EDT | [reproducibility_ML/DDPG/Walker/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #6 | Training started
2017-07-02 15:46:01.842629 EDT | [reproducibility_ML/DDPG/Walker/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #6 | Training finished
2017-07-02 15:46:01.843015 EDT | [reproducibility_ML/DDPG/Walker/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #6 | Trained qf 0 steps, policy 0 steps
2017-07-02 15:46:01.843349 EDT | [reproducibility_ML/DDPG/Walker/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #7 | Training started
2017-07-02 15:46:02.820668 EDT | [reproducibility_ML/DDPG/Walker/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #7 | Training finished
2017-07-02 15:46:02.820974 EDT | [reproducibility_ML/DDPG/Walker/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #7 | Trained qf 0 steps, policy 0 steps
2017-07-02 15:46:02.821231 EDT | [reproducibility_ML/DDPG/Walker/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #8 | Training started
2017-07-02 15:46:03.781607 EDT | [reproducibility_ML/DDPG/Walker/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #8 | Training finished
2017-07-02 15:46:03.782132 EDT | [reproducibility_ML/DDPG/Walker/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #8 | Trained qf 0 steps, policy 0 steps
2017-07-02 15:46:03.782367 EDT | [reproducibility_ML/DDPG/Walker/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #9 | Training started
2017-07-02 15:46:04.794819 EDT | [reproducibility_ML/DDPG/Walker/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #9 | Training finished
2017-07-02 15:46:04.795037 EDT | [reproducibility_ML/DDPG/Walker/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #9 | Trained qf 1 steps, policy 1 steps
2017-07-02 15:46:04.795196 EDT | [reproducibility_ML/DDPG/Walker/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #9 | Collecting samples for evaluation
2017-07-02 15:46:14.650458 EDT | -----------------------  -----------
2017-07-02 15:46:14.650662 EDT | Epoch                      9
2017-07-02 15:46:14.650782 EDT | Iteration                  9
2017-07-02 15:46:14.650895 EDT | AverageReturn             -8.2401
2017-07-02 15:46:14.651019 EDT | StdReturn                  0.0369942
2017-07-02 15:46:14.651169 EDT | MaxReturn                 -8.12564
2017-07-02 15:46:14.651283 EDT | MinReturn                 -8.34984
2017-07-02 15:46:14.651435 EDT | AverageEsReturn           -9.77427
2017-07-02 15:46:14.651582 EDT | StdEsReturn                3.20779
2017-07-02 15:46:14.651718 EDT | MaxEsReturn                0.103882
2017-07-02 15:46:14.651870 EDT | MinEsReturn              -17.1833
2017-07-02 15:46:14.652024 EDT | AverageDiscountedReturn   -7.63801
2017-07-02 15:46:14.652227 EDT | AverageQLoss               9.40548
2017-07-02 15:46:14.652366 EDT | AveragePolicySurr         -0.99524
2017-07-02 15:46:14.652476 EDT | AverageQ                   0.427413
2017-07-02 15:46:14.652594 EDT | AverageAbsQ                0.74927
2017-07-02 15:46:14.652740 EDT | AverageY                   3.07394
2017-07-02 15:46:14.652853 EDT | AverageAbsY                3.07503
2017-07-02 15:46:14.652962 EDT | AverageAbsQYDiff           2.88517
2017-07-02 15:46:14.653105 EDT | AverageAction              0.564236
2017-07-02 15:46:14.653242 EDT | PolicyRegParamNorm        11.7813
2017-07-02 15:46:14.653352 EDT | QFunRegParamNorm          11.5833
2017-07-02 15:46:14.653537 EDT | -----------------------  -----------
2017-07-02 15:46:14.653839 EDT | [reproducibility_ML/DDPG/Walker/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #10 | Training started
2017-07-02 15:46:24.715149 EDT | [reproducibility_ML/DDPG/Walker/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #10 | Training finished
2017-07-02 15:46:24.715657 EDT | [reproducibility_ML/DDPG/Walker/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #10 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 15:46:24.715838 EDT | [reproducibility_ML/DDPG/Walker/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #10 | Collecting samples for evaluation
2017-07-02 15:46:33.791831 EDT | -----------------------  -----------
2017-07-02 15:46:33.792341 EDT | Epoch                     10
2017-07-02 15:46:33.792576 EDT | Iteration                 10
2017-07-02 15:46:33.792751 EDT | AverageReturn             -8.32089
2017-07-02 15:46:33.792886 EDT | StdReturn                  0.0829979
2017-07-02 15:46:33.793050 EDT | MaxReturn                 -8.07936
2017-07-02 15:46:33.793161 EDT | MinReturn                 -8.50993
2017-07-02 15:46:33.793269 EDT | AverageEsReturn           -7.72889
2017-07-02 15:46:33.793423 EDT | StdEsReturn                1.78912
2017-07-02 15:46:33.793610 EDT | MaxEsReturn                0.158504
2017-07-02 15:46:33.793856 EDT | MinEsReturn              -18.4578
2017-07-02 15:46:33.794045 EDT | AverageDiscountedReturn   -8.03223
2017-07-02 15:46:33.794352 EDT | AverageQLoss               0.356317
2017-07-02 15:46:33.794573 EDT | AveragePolicySurr         -2.5222
2017-07-02 15:46:33.794822 EDT | AverageQ                   1.67796
2017-07-02 15:46:33.795071 EDT | AverageAbsQ                1.68378
2017-07-02 15:46:33.795309 EDT | AverageY                   1.68898
2017-07-02 15:46:33.795554 EDT | AverageAbsY                1.69187
2017-07-02 15:46:33.795793 EDT | AverageAbsQYDiff           0.382636
2017-07-02 15:46:33.796042 EDT | AverageAction              0.999226
2017-07-02 15:46:33.796269 EDT | PolicyRegParamNorm        12.507
2017-07-02 15:46:33.796387 EDT | QFunRegParamNorm          11.8604
2017-07-02 15:46:33.796498 EDT | -----------------------  -----------
2017-07-02 15:46:33.796690 EDT | [reproducibility_ML/DDPG/Walker/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #11 | Training started
2017-07-02 15:46:43.915458 EDT | [reproducibility_ML/DDPG/Walker/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #11 | Training finished
2017-07-02 15:46:43.915998 EDT | [reproducibility_ML/DDPG/Walker/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #11 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 15:46:43.916172 EDT | [reproducibility_ML/DDPG/Walker/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #11 | Collecting samples for evaluation
2017-07-02 15:46:52.826512 EDT | -----------------------  -----------
2017-07-02 15:46:52.826733 EDT | Epoch                     11
2017-07-02 15:46:52.826899 EDT | Iteration                 11
2017-07-02 15:46:52.827035 EDT | AverageReturn             -8.09208
2017-07-02 15:46:52.827152 EDT | StdReturn                  0.064625
2017-07-02 15:46:52.827272 EDT | MaxReturn                 -7.94093
2017-07-02 15:46:52.827422 EDT | MinReturn                 -8.25671
2017-07-02 15:46:52.827557 EDT | AverageEsReturn           -7.32214
2017-07-02 15:46:52.827715 EDT | StdEsReturn                1.7767
2017-07-02 15:46:52.827908 EDT | MaxEsReturn                0.3865
2017-07-02 15:46:52.828024 EDT | MinEsReturn              -12.6641
2017-07-02 15:46:52.828204 EDT | AverageDiscountedReturn   -7.81482
2017-07-02 15:46:52.828319 EDT | AverageQLoss               0.0565806
2017-07-02 15:46:52.828436 EDT | AveragePolicySurr         -1.72587
2017-07-02 15:46:52.828615 EDT | AverageQ                   1.25052
2017-07-02 15:46:52.828729 EDT | AverageAbsQ                1.26558
2017-07-02 15:46:52.828848 EDT | AverageY                   1.25491
2017-07-02 15:46:52.828986 EDT | AverageAbsY                1.258
2017-07-02 15:46:52.829131 EDT | AverageAbsQYDiff           0.172059
2017-07-02 15:46:52.829320 EDT | AverageAction              0.999998
2017-07-02 15:46:52.829447 EDT | PolicyRegParamNorm        12.6887
2017-07-02 15:46:52.829631 EDT | QFunRegParamNorm          11.9832
2017-07-02 15:46:52.829772 EDT | -----------------------  -----------
2017-07-02 15:46:52.829971 EDT | [reproducibility_ML/DDPG/Walker/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #12 | Training started
2017-07-02 15:47:03.072720 EDT | [reproducibility_ML/DDPG/Walker/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #12 | Training finished
2017-07-02 15:47:03.073243 EDT | [reproducibility_ML/DDPG/Walker/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #12 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 15:47:03.073524 EDT | [reproducibility_ML/DDPG/Walker/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #12 | Collecting samples for evaluation
2017-07-02 15:47:11.961586 EDT | -----------------------  -----------
2017-07-02 15:47:11.975113 EDT | Epoch                     12
2017-07-02 15:47:11.975432 EDT | Iteration                 12
2017-07-02 15:47:11.975569 EDT | AverageReturn             -8.09349
2017-07-02 15:47:11.975784 EDT | StdReturn                  0.0638401
2017-07-02 15:47:11.976020 EDT | MaxReturn                 -7.94162
2017-07-02 15:47:11.976221 EDT | MinReturn                 -8.24663
2017-07-02 15:47:11.976354 EDT | AverageEsReturn           -7.38009
2017-07-02 15:47:11.976554 EDT | StdEsReturn                1.84258
2017-07-02 15:47:11.976772 EDT | MaxEsReturn               -3.94954
2017-07-02 15:47:11.977007 EDT | MinEsReturn              -15.1885
2017-07-02 15:47:11.977216 EDT | AverageDiscountedReturn   -7.81619
2017-07-02 15:47:11.977460 EDT | AverageQLoss               0.0329817
2017-07-02 15:47:11.977716 EDT | AveragePolicySurr         -1.67524
2017-07-02 15:47:11.977952 EDT | AverageQ                   1.31965
2017-07-02 15:47:11.978168 EDT | AverageAbsQ                1.33811
2017-07-02 15:47:11.978403 EDT | AverageY                   1.32188
2017-07-02 15:47:11.978604 EDT | AverageAbsY                1.32678
2017-07-02 15:47:11.978846 EDT | AverageAbsQYDiff           0.136908
2017-07-02 15:47:11.981569 EDT | AverageAction              0.999999
2017-07-02 15:47:11.981694 EDT | PolicyRegParamNorm        12.6977
2017-07-02 15:47:11.981811 EDT | QFunRegParamNorm          12.1596
2017-07-02 15:47:11.982005 EDT | -----------------------  -----------
2017-07-02 15:47:11.982212 EDT | [reproducibility_ML/DDPG/Walker/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #13 | Training started
2017-07-02 15:47:22.089718 EDT | [reproducibility_ML/DDPG/Walker/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #13 | Training finished
2017-07-02 15:47:22.089913 EDT | [reproducibility_ML/DDPG/Walker/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #13 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 15:47:22.090053 EDT | [reproducibility_ML/DDPG/Walker/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #13 | Collecting samples for evaluation
2017-07-02 15:47:31.343842 EDT | -----------------------  -----------
2017-07-02 15:47:31.344401 EDT | Epoch                     13
2017-07-02 15:47:31.344656 EDT | Iteration                 13
2017-07-02 15:47:31.344892 EDT | AverageReturn            -15.0981
2017-07-02 15:47:31.345136 EDT | StdReturn                  0.169511
2017-07-02 15:47:31.345377 EDT | MaxReturn                -14.6745
2017-07-02 15:47:31.345625 EDT | MinReturn                -15.5339
2017-07-02 15:47:31.345848 EDT | AverageEsReturn           -9.20454
2017-07-02 15:47:31.346077 EDT | StdEsReturn                3.25643
2017-07-02 15:47:31.346196 EDT | MaxEsReturn               -3.68901
2017-07-02 15:47:31.346320 EDT | MinEsReturn              -15.2141
2017-07-02 15:47:31.346549 EDT | AverageDiscountedReturn  -14.1564
2017-07-02 15:47:31.346695 EDT | AverageQLoss               0.0221074
2017-07-02 15:47:31.346925 EDT | AveragePolicySurr         -1.5152
2017-07-02 15:47:31.347150 EDT | AverageQ                   1.16738
2017-07-02 15:47:31.347268 EDT | AverageAbsQ                1.20634
2017-07-02 15:47:31.347377 EDT | AverageY                   1.1683
2017-07-02 15:47:31.347492 EDT | AverageAbsY                1.20188
2017-07-02 15:47:31.347716 EDT | AverageAbsQYDiff           0.113719
2017-07-02 15:47:31.347899 EDT | AverageAction              0.999997
2017-07-02 15:47:31.348128 EDT | PolicyRegParamNorm        12.9969
2017-07-02 15:47:31.348329 EDT | QFunRegParamNorm          12.3404
2017-07-02 15:47:31.348569 EDT | -----------------------  -----------
2017-07-02 15:47:31.348900 EDT | [reproducibility_ML/DDPG/Walker/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #14 | Training started
2017-07-02 15:47:41.442588 EDT | [reproducibility_ML/DDPG/Walker/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #14 | Training finished
2017-07-02 15:47:41.443484 EDT | [reproducibility_ML/DDPG/Walker/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #14 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 15:47:41.443743 EDT | [reproducibility_ML/DDPG/Walker/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #14 | Collecting samples for evaluation
2017-07-02 15:47:50.622429 EDT | -----------------------  -----------
2017-07-02 15:47:50.622618 EDT | Epoch                     14
2017-07-02 15:47:50.622739 EDT | Iteration                 14
2017-07-02 15:47:50.622851 EDT | AverageReturn            103.543
2017-07-02 15:47:50.623035 EDT | StdReturn                 14.395
2017-07-02 15:47:50.623157 EDT | MaxReturn                133.211
2017-07-02 15:47:50.623280 EDT | MinReturn                 70.4546
2017-07-02 15:47:50.623466 EDT | AverageEsReturn           -9.09161
2017-07-02 15:47:50.623672 EDT | StdEsReturn               18.5244
2017-07-02 15:47:50.623851 EDT | MaxEsReturn               89.278
2017-07-02 15:47:50.624038 EDT | MinEsReturn              -15.3495
2017-07-02 15:47:50.624227 EDT | AverageDiscountedReturn   64.0702
2017-07-02 15:47:50.624412 EDT | AverageQLoss               0.0181391
2017-07-02 15:47:50.624616 EDT | AveragePolicySurr         -1.55522
2017-07-02 15:47:50.624781 EDT | AverageQ                   1.19981
2017-07-02 15:47:50.624959 EDT | AverageAbsQ                1.23122
2017-07-02 15:47:50.625075 EDT | AverageY                   1.20081
2017-07-02 15:47:50.625246 EDT | AverageAbsY                1.22774
2017-07-02 15:47:50.625388 EDT | AverageAbsQYDiff           0.102619
2017-07-02 15:47:50.625518 EDT | AverageAction              0.890987
2017-07-02 15:47:50.625665 EDT | PolicyRegParamNorm        13.2672
2017-07-02 15:47:50.625899 EDT | QFunRegParamNorm          12.4732
2017-07-02 15:47:50.626136 EDT | -----------------------  -----------
2017-07-02 15:47:50.626451 EDT | [reproducibility_ML/DDPG/Walker/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #15 | Training started
2017-07-02 15:48:00.737821 EDT | [reproducibility_ML/DDPG/Walker/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #15 | Training finished
2017-07-02 15:48:00.738025 EDT | [reproducibility_ML/DDPG/Walker/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #15 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 15:48:00.738217 EDT | [reproducibility_ML/DDPG/Walker/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #15 | Collecting samples for evaluation
2017-07-02 15:48:10.074443 EDT | -----------------------  -----------
2017-07-02 15:48:10.074967 EDT | Epoch                     15
2017-07-02 15:48:10.075165 EDT | Iteration                 15
2017-07-02 15:48:10.075323 EDT | AverageReturn            -12.6405
2017-07-02 15:48:10.075501 EDT | StdReturn                  0.832946
2017-07-02 15:48:10.075702 EDT | MaxReturn                 -9.80373
2017-07-02 15:48:10.075896 EDT | MinReturn                -14.2445
2017-07-02 15:48:10.076078 EDT | AverageEsReturn           34.7226
2017-07-02 15:48:10.076193 EDT | StdEsReturn               44.9135
2017-07-02 15:48:10.076328 EDT | MaxEsReturn              203.437
2017-07-02 15:48:10.076437 EDT | MinEsReturn               -0.648243
2017-07-02 15:48:10.076587 EDT | AverageDiscountedReturn  -11.2721
2017-07-02 15:48:10.076773 EDT | AverageQLoss               0.0179945
2017-07-02 15:48:10.076900 EDT | AveragePolicySurr         -1.68525
2017-07-02 15:48:10.077069 EDT | AverageQ                   1.30001
2017-07-02 15:48:10.077215 EDT | AverageAbsQ                1.31616
2017-07-02 15:48:10.077425 EDT | AverageY                   1.30119
2017-07-02 15:48:10.077637 EDT | AverageAbsY                1.31389
2017-07-02 15:48:10.077748 EDT | AverageAbsQYDiff           0.0984767
2017-07-02 15:48:10.077933 EDT | AverageAction              0.966864
2017-07-02 15:48:10.078069 EDT | PolicyRegParamNorm        14.4661
2017-07-02 15:48:10.078206 EDT | QFunRegParamNorm          12.6879
2017-07-02 15:48:10.078365 EDT | -----------------------  -----------
2017-07-02 15:48:10.078561 EDT | [reproducibility_ML/DDPG/Walker/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #16 | Training started
2017-07-02 15:48:20.239255 EDT | [reproducibility_ML/DDPG/Walker/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #16 | Training finished
2017-07-02 15:48:20.239877 EDT | [reproducibility_ML/DDPG/Walker/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #16 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 15:48:20.240148 EDT | [reproducibility_ML/DDPG/Walker/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #16 | Collecting samples for evaluation
2017-07-02 15:48:29.620100 EDT | -----------------------  -----------
2017-07-02 15:48:29.620350 EDT | Epoch                     16
2017-07-02 15:48:29.620610 EDT | Iteration                 16
2017-07-02 15:48:29.620838 EDT | AverageReturn            -22.9098
2017-07-02 15:48:29.621048 EDT | StdReturn                  3.10932
2017-07-02 15:48:29.621292 EDT | MaxReturn                -13.349
2017-07-02 15:48:29.621541 EDT | MinReturn                -30.0774
2017-07-02 15:48:29.621786 EDT | AverageEsReturn           -9.71214
2017-07-02 15:48:29.622004 EDT | StdEsReturn               12.2017
2017-07-02 15:48:29.622237 EDT | MaxEsReturn               40.9792
2017-07-02 15:48:29.622481 EDT | MinEsReturn              -34.3062
2017-07-02 15:48:29.622702 EDT | AverageDiscountedReturn  -10.8387
2017-07-02 15:48:29.622939 EDT | AverageQLoss               0.0188702
2017-07-02 15:48:29.623183 EDT | AveragePolicySurr         -1.72744
2017-07-02 15:48:29.623408 EDT | AverageQ                   1.36369
2017-07-02 15:48:29.623615 EDT | AverageAbsQ                1.37438
2017-07-02 15:48:29.623858 EDT | AverageY                   1.36481
2017-07-02 15:48:29.624094 EDT | AverageAbsY                1.37258
2017-07-02 15:48:29.624325 EDT | AverageAbsQYDiff           0.0976153
2017-07-02 15:48:29.624568 EDT | AverageAction              0.941499
2017-07-02 15:48:29.624783 EDT | PolicyRegParamNorm        15.4453
2017-07-02 15:48:29.625024 EDT | QFunRegParamNorm          12.8853
2017-07-02 15:48:29.625230 EDT | -----------------------  -----------
2017-07-02 15:48:29.626181 EDT | [reproducibility_ML/DDPG/Walker/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #17 | Training started
2017-07-02 15:48:39.638351 EDT | [reproducibility_ML/DDPG/Walker/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #17 | Training finished
2017-07-02 15:48:39.638968 EDT | [reproducibility_ML/DDPG/Walker/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #17 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 15:48:39.639174 EDT | [reproducibility_ML/DDPG/Walker/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #17 | Collecting samples for evaluation
2017-07-02 15:48:48.631311 EDT | -----------------------  -----------
2017-07-02 15:48:48.631610 EDT | Epoch                     17
2017-07-02 15:48:48.631805 EDT | Iteration                 17
2017-07-02 15:48:48.631949 EDT | AverageReturn            -41.3921
2017-07-02 15:48:48.632143 EDT | StdReturn                  3.52155
2017-07-02 15:48:48.632266 EDT | MaxReturn                -35.1169
2017-07-02 15:48:48.632377 EDT | MinReturn                -48.1731
2017-07-02 15:48:48.632544 EDT | AverageEsReturn          -20.919
2017-07-02 15:48:48.632698 EDT | StdEsReturn               10.8429
2017-07-02 15:48:48.632812 EDT | MaxEsReturn               -3.95549
2017-07-02 15:48:48.632954 EDT | MinEsReturn              -42.4995
2017-07-02 15:48:48.633114 EDT | AverageDiscountedReturn  -17.4795
2017-07-02 15:48:48.633297 EDT | AverageQLoss               0.015151
2017-07-02 15:48:48.633431 EDT | AveragePolicySurr         -1.72131
2017-07-02 15:48:48.633608 EDT | AverageQ                   1.42779
2017-07-02 15:48:48.633725 EDT | AverageAbsQ                1.43378
2017-07-02 15:48:48.633832 EDT | AverageY                   1.4286
2017-07-02 15:48:48.633992 EDT | AverageAbsY                1.43196
2017-07-02 15:48:48.634167 EDT | AverageAbsQYDiff           0.0880972
2017-07-02 15:48:48.634301 EDT | AverageAction              0.9328
2017-07-02 15:48:48.634457 EDT | PolicyRegParamNorm        15.9259
2017-07-02 15:48:48.634612 EDT | QFunRegParamNorm          13.1009
2017-07-02 15:48:48.634732 EDT | -----------------------  -----------
2017-07-02 15:48:48.634943 EDT | [reproducibility_ML/DDPG/Walker/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #18 | Training started
2017-07-02 15:48:58.659806 EDT | [reproducibility_ML/DDPG/Walker/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #18 | Training finished
2017-07-02 15:48:58.660303 EDT | [reproducibility_ML/DDPG/Walker/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #18 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 15:48:58.660535 EDT | [reproducibility_ML/DDPG/Walker/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #18 | Collecting samples for evaluation
2017-07-02 15:49:08.011566 EDT | -----------------------  -----------
2017-07-02 15:49:08.012179 EDT | Epoch                     18
2017-07-02 15:49:08.012436 EDT | Iteration                 18
2017-07-02 15:49:08.012670 EDT | AverageReturn            -43.8971
2017-07-02 15:49:08.012916 EDT | StdReturn                  2.1428
2017-07-02 15:49:08.013151 EDT | MaxReturn                -36.2152
2017-07-02 15:49:08.013387 EDT | MinReturn                -47.8259
2017-07-02 15:49:08.013640 EDT | AverageEsReturn          -29.5074
2017-07-02 15:49:08.013871 EDT | StdEsReturn               14.6312
2017-07-02 15:49:08.014095 EDT | MaxEsReturn                3.03627
2017-07-02 15:49:08.014215 EDT | MinEsReturn              -44.329
2017-07-02 15:49:08.014361 EDT | AverageDiscountedReturn  -16.7215
2017-07-02 15:49:08.014474 EDT | AverageQLoss               0.0139153
2017-07-02 15:49:08.014584 EDT | AveragePolicySurr         -1.76264
2017-07-02 15:49:08.014733 EDT | AverageQ                   1.47781
2017-07-02 15:49:08.014963 EDT | AverageAbsQ                1.48409
2017-07-02 15:49:08.015175 EDT | AverageY                   1.47848
2017-07-02 15:49:08.015408 EDT | AverageAbsY                1.48208
2017-07-02 15:49:08.015636 EDT | AverageAbsQYDiff           0.0797511
2017-07-02 15:49:08.015879 EDT | AverageAction              0.959293
2017-07-02 15:49:08.016110 EDT | PolicyRegParamNorm        16.2978
2017-07-02 15:49:08.016346 EDT | QFunRegParamNorm          13.3672
2017-07-02 15:49:08.016581 EDT | -----------------------  -----------
2017-07-02 15:49:08.016910 EDT | [reproducibility_ML/DDPG/Walker/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #19 | Training started
2017-07-02 15:49:18.128021 EDT | [reproducibility_ML/DDPG/Walker/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #19 | Training finished
2017-07-02 15:49:18.128287 EDT | [reproducibility_ML/DDPG/Walker/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #19 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 15:49:18.128544 EDT | [reproducibility_ML/DDPG/Walker/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #19 | Collecting samples for evaluation
2017-07-02 15:49:27.421018 EDT | -----------------------  ------------
2017-07-02 15:49:27.422020 EDT | Epoch                      19
2017-07-02 15:49:27.422280 EDT | Iteration                  19
2017-07-02 15:49:27.422517 EDT | AverageReturn             987.906
2017-07-02 15:49:27.422747 EDT | StdReturn                   6.56087
2017-07-02 15:49:27.422983 EDT | MaxReturn                1000.81
2017-07-02 15:49:27.423129 EDT | MinReturn                 979.156
2017-07-02 15:49:27.423256 EDT | AverageEsReturn            -6.83356
2017-07-02 15:49:27.423464 EDT | StdEsReturn                65.1024
2017-07-02 15:49:27.423602 EDT | MaxEsReturn               169.726
2017-07-02 15:49:27.423745 EDT | MinEsReturn               -55.7057
2017-07-02 15:49:27.423974 EDT | AverageDiscountedReturn    68.9305
2017-07-02 15:49:27.424177 EDT | AverageQLoss                0.0137927
2017-07-02 15:49:27.424402 EDT | AveragePolicySurr          -1.79313
2017-07-02 15:49:27.424629 EDT | AverageQ                    1.51905
2017-07-02 15:49:27.424836 EDT | AverageAbsQ                 1.5255
2017-07-02 15:49:27.425081 EDT | AverageY                    1.51983
2017-07-02 15:49:27.425312 EDT | AverageAbsY                 1.52375
2017-07-02 15:49:27.425745 EDT | AverageAbsQYDiff            0.0777662
2017-07-02 15:49:27.425954 EDT | AverageAction               0.859091
2017-07-02 15:49:27.426187 EDT | PolicyRegParamNorm         16.6402
2017-07-02 15:49:27.426412 EDT | QFunRegParamNorm           13.7156
2017-07-02 15:49:27.426566 EDT | -----------------------  ------------
2017-07-02 15:49:27.426769 EDT | [reproducibility_ML/DDPG/Walker/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #20 | Training started
2017-07-02 15:49:37.487328 EDT | [reproducibility_ML/DDPG/Walker/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #20 | Training finished
2017-07-02 15:49:37.487961 EDT | [reproducibility_ML/DDPG/Walker/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #20 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 15:49:37.488148 EDT | [reproducibility_ML/DDPG/Walker/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #20 | Collecting samples for evaluation
2017-07-02 15:49:47.089946 EDT | -----------------------  -----------
2017-07-02 15:49:47.090148 EDT | Epoch                     20
2017-07-02 15:49:47.090267 EDT | Iteration                 20
2017-07-02 15:49:47.090381 EDT | AverageReturn            969.69
2017-07-02 15:49:47.090492 EDT | StdReturn                  6.5669
2017-07-02 15:49:47.090673 EDT | MaxReturn                976.935
2017-07-02 15:49:47.090792 EDT | MinReturn                957.246
2017-07-02 15:49:47.090922 EDT | AverageEsReturn           -9.56858
2017-07-02 15:49:47.091099 EDT | StdEsReturn               31.4755
2017-07-02 15:49:47.091293 EDT | MaxEsReturn               61.0847
2017-07-02 15:49:47.091412 EDT | MinEsReturn              -44.9486
2017-07-02 15:49:47.091566 EDT | AverageDiscountedReturn   65.2106
2017-07-02 15:49:47.091685 EDT | AverageQLoss               0.0110903
2017-07-02 15:49:47.091862 EDT | AveragePolicySurr         -1.80373
2017-07-02 15:49:47.092032 EDT | AverageQ                   1.54367
2017-07-02 15:49:47.092221 EDT | AverageAbsQ                1.55082
2017-07-02 15:49:47.092363 EDT | AverageY                   1.54412
2017-07-02 15:49:47.092473 EDT | AverageAbsY                1.54922
2017-07-02 15:49:47.092620 EDT | AverageAbsQYDiff           0.0703818
2017-07-02 15:49:47.092731 EDT | AverageAction              0.851417
2017-07-02 15:49:47.092839 EDT | PolicyRegParamNorm        17.1015
2017-07-02 15:49:47.092968 EDT | QFunRegParamNorm          14.0216
2017-07-02 15:49:47.093117 EDT | -----------------------  -----------
2017-07-02 15:49:47.093293 EDT | [reproducibility_ML/DDPG/Walker/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #21 | Training started
2017-07-02 15:49:57.310056 EDT | [reproducibility_ML/DDPG/Walker/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #21 | Training finished
2017-07-02 15:49:57.310704 EDT | [reproducibility_ML/DDPG/Walker/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #21 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 15:49:57.310896 EDT | [reproducibility_ML/DDPG/Walker/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #21 | Collecting samples for evaluation
2017-07-02 15:50:06.561407 EDT | -----------------------  -----------
2017-07-02 15:50:06.562043 EDT | Epoch                     21
2017-07-02 15:50:06.562184 EDT | Iteration                 21
2017-07-02 15:50:06.562361 EDT | AverageReturn             77.1161
2017-07-02 15:50:06.562533 EDT | StdReturn                 53.5662
2017-07-02 15:50:06.562708 EDT | MaxReturn                189.994
2017-07-02 15:50:06.562827 EDT | MinReturn                 -9.61189
2017-07-02 15:50:06.562945 EDT | AverageEsReturn          -12.1732
2017-07-02 15:50:06.563078 EDT | StdEsReturn               36.8896
2017-07-02 15:50:06.563191 EDT | MaxEsReturn               62.2532
2017-07-02 15:50:06.563303 EDT | MinEsReturn              -87.6266
2017-07-02 15:50:06.563422 EDT | AverageDiscountedReturn   29.4511
2017-07-02 15:50:06.563592 EDT | AverageQLoss               0.0133165
2017-07-02 15:50:06.563744 EDT | AveragePolicySurr         -1.81057
2017-07-02 15:50:06.563858 EDT | AverageQ                   1.55452
2017-07-02 15:50:06.563971 EDT | AverageAbsQ                1.562
2017-07-02 15:50:06.564083 EDT | AverageY                   1.55517
2017-07-02 15:50:06.564212 EDT | AverageAbsY                1.56046
2017-07-02 15:50:06.564324 EDT | AverageAbsQYDiff           0.0732311
2017-07-02 15:50:06.564434 EDT | AverageAction              0.896093
2017-07-02 15:50:06.564615 EDT | PolicyRegParamNorm        17.6107
2017-07-02 15:50:06.564736 EDT | QFunRegParamNorm          14.4363
2017-07-02 15:50:06.564871 EDT | -----------------------  -----------
2017-07-02 15:50:06.565057 EDT | [reproducibility_ML/DDPG/Walker/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #22 | Training started
2017-07-02 15:50:16.622743 EDT | [reproducibility_ML/DDPG/Walker/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #22 | Training finished
2017-07-02 15:50:16.622919 EDT | [reproducibility_ML/DDPG/Walker/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #22 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 15:50:16.623200 EDT | [reproducibility_ML/DDPG/Walker/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #22 | Collecting samples for evaluation
2017-07-02 15:50:25.719925 EDT | -----------------------  -----------
2017-07-02 15:50:25.720187 EDT | Epoch                     22
2017-07-02 15:50:25.720327 EDT | Iteration                 22
2017-07-02 15:50:25.720439 EDT | AverageReturn            -20.7535
2017-07-02 15:50:25.720577 EDT | StdReturn                 10.6936
2017-07-02 15:50:25.720739 EDT | MaxReturn                 -2.35321
2017-07-02 15:50:25.720846 EDT | MinReturn                -42.1547
2017-07-02 15:50:25.720979 EDT | AverageEsReturn          -26.3936
2017-07-02 15:50:25.721111 EDT | StdEsReturn               14.753
2017-07-02 15:50:25.721298 EDT | MaxEsReturn                3.94049
2017-07-02 15:50:25.721426 EDT | MinEsReturn              -50.2529
2017-07-02 15:50:25.721578 EDT | AverageDiscountedReturn   -9.78079
2017-07-02 15:50:25.721761 EDT | AverageQLoss               0.0129184
2017-07-02 15:50:25.721943 EDT | AveragePolicySurr         -1.85287
2017-07-02 15:50:25.722059 EDT | AverageQ                   1.58958
2017-07-02 15:50:25.722203 EDT | AverageAbsQ                1.59506
2017-07-02 15:50:25.722319 EDT | AverageY                   1.59029
2017-07-02 15:50:25.722436 EDT | AverageAbsY                1.59418
2017-07-02 15:50:25.722653 EDT | AverageAbsQYDiff           0.0712904
2017-07-02 15:50:25.722864 EDT | AverageAction              0.965979
2017-07-02 15:50:25.723032 EDT | PolicyRegParamNorm        18.0912
2017-07-02 15:50:25.723154 EDT | QFunRegParamNorm          14.8356
2017-07-02 15:50:25.723312 EDT | -----------------------  -----------
2017-07-02 15:50:25.723497 EDT | [reproducibility_ML/DDPG/Walker/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #23 | Training started
2017-07-02 15:50:35.800055 EDT | [reproducibility_ML/DDPG/Walker/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #23 | Training finished
2017-07-02 15:50:35.800541 EDT | [reproducibility_ML/DDPG/Walker/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #23 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 15:50:35.800715 EDT | [reproducibility_ML/DDPG/Walker/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #23 | Collecting samples for evaluation
2017-07-02 15:50:44.958418 EDT | -----------------------  -----------
2017-07-02 15:50:44.958953 EDT | Epoch                     23
2017-07-02 15:50:44.959212 EDT | Iteration                 23
2017-07-02 15:50:44.959417 EDT | AverageReturn            -23.6981
2017-07-02 15:50:44.959659 EDT | StdReturn                  3.32252
2017-07-02 15:50:44.959889 EDT | MaxReturn                -14.9884
2017-07-02 15:50:44.960117 EDT | MinReturn                -31.5174
2017-07-02 15:50:44.960298 EDT | AverageEsReturn          -15.6691
2017-07-02 15:50:44.960529 EDT | StdEsReturn               20.216
2017-07-02 15:50:44.960666 EDT | MaxEsReturn               29.6223
2017-07-02 15:50:44.960779 EDT | MinEsReturn              -43.9843
2017-07-02 15:50:44.960888 EDT | AverageDiscountedReturn  -11.0398
2017-07-02 15:50:44.960995 EDT | AverageQLoss               0.0147191
2017-07-02 15:50:44.961130 EDT | AveragePolicySurr         -1.85167
2017-07-02 15:50:44.961353 EDT | AverageQ                   1.61185
2017-07-02 15:50:44.961529 EDT | AverageAbsQ                1.61764
2017-07-02 15:50:44.961761 EDT | AverageY                   1.61245
2017-07-02 15:50:44.961968 EDT | AverageAbsY                1.61636
2017-07-02 15:50:44.962210 EDT | AverageAbsQYDiff           0.0756668
2017-07-02 15:50:44.962439 EDT | AverageAction              0.95534
2017-07-02 15:50:44.962672 EDT | PolicyRegParamNorm        18.79
2017-07-02 15:50:44.962842 EDT | QFunRegParamNorm          15.2787
2017-07-02 15:50:44.963066 EDT | -----------------------  -----------
2017-07-02 15:50:44.963371 EDT | [reproducibility_ML/DDPG/Walker/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #24 | Training started
2017-07-02 15:50:54.922542 EDT | [reproducibility_ML/DDPG/Walker/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #24 | Training finished
2017-07-02 15:50:54.922955 EDT | [reproducibility_ML/DDPG/Walker/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #24 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 15:50:54.923180 EDT | [reproducibility_ML/DDPG/Walker/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #24 | Collecting samples for evaluation
2017-07-02 15:51:03.962460 EDT | -----------------------  -----------
2017-07-02 15:51:03.962942 EDT | Epoch                     24
2017-07-02 15:51:03.963101 EDT | Iteration                 24
2017-07-02 15:51:03.963330 EDT | AverageReturn            -29.9744
2017-07-02 15:51:03.963573 EDT | StdReturn                  2.69294
2017-07-02 15:51:03.963731 EDT | MaxReturn                -24.6639
2017-07-02 15:51:03.963902 EDT | MinReturn                -35.765
2017-07-02 15:51:03.964143 EDT | AverageEsReturn          -28.5928
2017-07-02 15:51:03.964350 EDT | StdEsReturn               11.6379
2017-07-02 15:51:03.964568 EDT | MaxEsReturn               -3.47142
2017-07-02 15:51:03.964809 EDT | MinEsReturn              -48.4818
2017-07-02 15:51:03.965014 EDT | AverageDiscountedReturn  -13.6108
2017-07-02 15:51:03.965258 EDT | AverageQLoss               0.013528
2017-07-02 15:51:03.965469 EDT | AveragePolicySurr         -1.83814
2017-07-02 15:51:03.965734 EDT | AverageQ                   1.6195
2017-07-02 15:51:03.965955 EDT | AverageAbsQ                1.62451
2017-07-02 15:51:03.966189 EDT | AverageY                   1.61993
2017-07-02 15:51:03.966426 EDT | AverageAbsY                1.62332
2017-07-02 15:51:03.966634 EDT | AverageAbsQYDiff           0.0719493
2017-07-02 15:51:03.966875 EDT | AverageAction              0.971091
2017-07-02 15:51:03.967099 EDT | PolicyRegParamNorm        19.2263
2017-07-02 15:51:03.967342 EDT | QFunRegParamNorm          15.7385
2017-07-02 15:51:03.967512 EDT | -----------------------  -----------
2017-07-02 15:51:03.967721 EDT | [reproducibility_ML/DDPG/Walker/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #25 | Training started
2017-07-02 15:51:13.923182 EDT | [reproducibility_ML/DDPG/Walker/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #25 | Training finished
2017-07-02 15:51:13.923762 EDT | [reproducibility_ML/DDPG/Walker/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #25 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 15:51:13.924040 EDT | [reproducibility_ML/DDPG/Walker/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #25 | Collecting samples for evaluation
2017-07-02 15:51:22.600638 EDT | -----------------------  -----------
2017-07-02 15:51:22.600887 EDT | Epoch                     25
2017-07-02 15:51:22.601007 EDT | Iteration                 25
2017-07-02 15:51:22.601180 EDT | AverageReturn            -20.5747
2017-07-02 15:51:22.601386 EDT | StdReturn                 13.9286
2017-07-02 15:51:22.601514 EDT | MaxReturn                 37.8083
2017-07-02 15:51:22.601719 EDT | MinReturn                -62.3574
2017-07-02 15:51:22.601927 EDT | AverageEsReturn          -24.9808
2017-07-02 15:51:22.602042 EDT | StdEsReturn               16.9441
2017-07-02 15:51:22.602185 EDT | MaxEsReturn                3.56066
2017-07-02 15:51:22.602381 EDT | MinEsReturn              -50.9228
2017-07-02 15:51:22.602552 EDT | AverageDiscountedReturn   -7.12421
2017-07-02 15:51:22.602758 EDT | AverageQLoss               0.0124069
2017-07-02 15:51:22.602907 EDT | AveragePolicySurr         -1.83391
2017-07-02 15:51:22.603070 EDT | AverageQ                   1.6231
2017-07-02 15:51:22.603186 EDT | AverageAbsQ                1.62775
2017-07-02 15:51:22.603337 EDT | AverageY                   1.62392
2017-07-02 15:51:22.603465 EDT | AverageAbsY                1.62709
2017-07-02 15:51:22.603614 EDT | AverageAbsQYDiff           0.0687933
2017-07-02 15:51:22.603778 EDT | AverageAction              0.955981
2017-07-02 15:51:22.603889 EDT | PolicyRegParamNorm        19.7963
2017-07-02 15:51:22.604033 EDT | QFunRegParamNorm          16.1781
2017-07-02 15:51:22.604153 EDT | -----------------------  -----------
2017-07-02 15:51:22.604377 EDT | [reproducibility_ML/DDPG/Walker/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #26 | Training started
2017-07-02 15:51:32.695979 EDT | [reproducibility_ML/DDPG/Walker/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #26 | Training finished
2017-07-02 15:51:32.696564 EDT | [reproducibility_ML/DDPG/Walker/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #26 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 15:51:32.696774 EDT | [reproducibility_ML/DDPG/Walker/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #26 | Collecting samples for evaluation
2017-07-02 15:51:41.343025 EDT | -----------------------  -----------
2017-07-02 15:51:41.343651 EDT | Epoch                     26
2017-07-02 15:51:41.343873 EDT | Iteration                 26
2017-07-02 15:51:41.344069 EDT | AverageReturn             98.9052
2017-07-02 15:51:41.344290 EDT | StdReturn                136.306
2017-07-02 15:51:41.344454 EDT | MaxReturn                514.301
2017-07-02 15:51:41.344593 EDT | MinReturn                -26.8978
2017-07-02 15:51:41.344735 EDT | AverageEsReturn           -6.18562
2017-07-02 15:51:41.344846 EDT | StdEsReturn               24.8363
2017-07-02 15:51:41.345007 EDT | MaxEsReturn               43.278
2017-07-02 15:51:41.345121 EDT | MinEsReturn              -45.4062
2017-07-02 15:51:41.345228 EDT | AverageDiscountedReturn   39.8527
2017-07-02 15:51:41.345370 EDT | AverageQLoss               0.0126013
2017-07-02 15:51:41.345478 EDT | AveragePolicySurr         -1.84011
2017-07-02 15:51:41.345706 EDT | AverageQ                   1.63781
2017-07-02 15:51:41.345917 EDT | AverageAbsQ                1.64252
2017-07-02 15:51:41.346033 EDT | AverageY                   1.63835
2017-07-02 15:51:41.346169 EDT | AverageAbsY                1.64172
2017-07-02 15:51:41.346351 EDT | AverageAbsQYDiff           0.0696007
2017-07-02 15:51:41.346470 EDT | AverageAction              0.962701
2017-07-02 15:51:41.346653 EDT | PolicyRegParamNorm        20.5189
2017-07-02 15:51:41.346849 EDT | QFunRegParamNorm          16.5891
2017-07-02 15:51:41.347053 EDT | -----------------------  -----------
2017-07-02 15:51:41.347267 EDT | [reproducibility_ML/DDPG/Walker/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #27 | Training started
2017-07-02 15:51:51.334997 EDT | [reproducibility_ML/DDPG/Walker/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #27 | Training finished
2017-07-02 15:51:51.335302 EDT | [reproducibility_ML/DDPG/Walker/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #27 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 15:51:51.335653 EDT | [reproducibility_ML/DDPG/Walker/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #27 | Collecting samples for evaluation
2017-07-02 15:51:59.993184 EDT | -----------------------  -----------
2017-07-02 15:51:59.993664 EDT | Epoch                     27
2017-07-02 15:51:59.993853 EDT | Iteration                 27
2017-07-02 15:51:59.994016 EDT | AverageReturn            177.3
2017-07-02 15:51:59.994182 EDT | StdReturn                220.831
2017-07-02 15:51:59.994303 EDT | MaxReturn                680.6
2017-07-02 15:51:59.994511 EDT | MinReturn                -22.3867
2017-07-02 15:51:59.994677 EDT | AverageEsReturn           29.8973
2017-07-02 15:51:59.994807 EDT | StdEsReturn               35.9041
2017-07-02 15:51:59.994941 EDT | MaxEsReturn               89.6742
2017-07-02 15:51:59.995052 EDT | MinEsReturn              -12.306
2017-07-02 15:51:59.995247 EDT | AverageDiscountedReturn   40.6342
2017-07-02 15:51:59.995373 EDT | AverageQLoss               0.0137529
2017-07-02 15:51:59.995509 EDT | AveragePolicySurr         -1.84885
2017-07-02 15:51:59.995693 EDT | AverageQ                   1.66024
2017-07-02 15:51:59.995905 EDT | AverageAbsQ                1.66589
2017-07-02 15:51:59.996109 EDT | AverageY                   1.66086
2017-07-02 15:51:59.996589 EDT | AverageAbsY                1.66512
2017-07-02 15:51:59.996755 EDT | AverageAbsQYDiff           0.0707587
2017-07-02 15:51:59.996930 EDT | AverageAction              0.963957
2017-07-02 15:51:59.997142 EDT | PolicyRegParamNorm        20.9028
2017-07-02 15:51:59.997344 EDT | QFunRegParamNorm          17.0088
2017-07-02 15:51:59.997586 EDT | -----------------------  -----------
2017-07-02 15:51:59.997919 EDT | [reproducibility_ML/DDPG/Walker/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #28 | Training started
2017-07-02 15:52:10.013743 EDT | [reproducibility_ML/DDPG/Walker/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #28 | Training finished
2017-07-02 15:52:10.014285 EDT | [reproducibility_ML/DDPG/Walker/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #28 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 15:52:10.014483 EDT | [reproducibility_ML/DDPG/Walker/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #28 | Collecting samples for evaluation
2017-07-02 15:52:18.896978 EDT | -----------------------  -----------
2017-07-02 15:52:18.897214 EDT | Epoch                     28
2017-07-02 15:52:18.897435 EDT | Iteration                 28
2017-07-02 15:52:18.897630 EDT | AverageReturn            777.98
2017-07-02 15:52:18.897794 EDT | StdReturn                152.83
2017-07-02 15:52:18.897921 EDT | MaxReturn                942.14
2017-07-02 15:52:18.898033 EDT | MinReturn                452.432
2017-07-02 15:52:18.898160 EDT | AverageEsReturn           11.1627
2017-07-02 15:52:18.898279 EDT | StdEsReturn                0
2017-07-02 15:52:18.898415 EDT | MaxEsReturn               11.1627
2017-07-02 15:52:18.898547 EDT | MinEsReturn               11.1627
2017-07-02 15:52:18.898657 EDT | AverageDiscountedReturn   87.0091
2017-07-02 15:52:18.898789 EDT | AverageQLoss               0.0159991
2017-07-02 15:52:18.899023 EDT | AveragePolicySurr         -1.83962
2017-07-02 15:52:18.899265 EDT | AverageQ                   1.66325
2017-07-02 15:52:18.899470 EDT | AverageAbsQ                1.66938
2017-07-02 15:52:18.899677 EDT | AverageY                   1.66376
2017-07-02 15:52:18.899884 EDT | AverageAbsY                1.66823
2017-07-02 15:52:18.900025 EDT | AverageAbsQYDiff           0.0744465
2017-07-02 15:52:18.900186 EDT | AverageAction              0.948068
2017-07-02 15:52:18.900320 EDT | PolicyRegParamNorm        21.345
2017-07-02 15:52:18.900430 EDT | QFunRegParamNorm          17.4686
2017-07-02 15:52:18.900539 EDT | -----------------------  -----------
2017-07-02 15:52:18.900722 EDT | [reproducibility_ML/DDPG/Walker/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #29 | Training started
2017-07-02 15:52:28.982386 EDT | [reproducibility_ML/DDPG/Walker/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #29 | Training finished
2017-07-02 15:52:28.982779 EDT | [reproducibility_ML/DDPG/Walker/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #29 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 15:52:28.983002 EDT | [reproducibility_ML/DDPG/Walker/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #29 | Collecting samples for evaluation
2017-07-02 15:52:37.592838 EDT | -----------------------  -----------
2017-07-02 15:52:37.593453 EDT | Epoch                     29
2017-07-02 15:52:37.593722 EDT | Iteration                 29
2017-07-02 15:52:37.593968 EDT | AverageReturn            209.618
2017-07-02 15:52:37.594214 EDT | StdReturn                173.544
2017-07-02 15:52:37.594430 EDT | MaxReturn                709.309
2017-07-02 15:52:37.594574 EDT | MinReturn                -37.3374
2017-07-02 15:52:37.594790 EDT | AverageEsReturn          385.089
2017-07-02 15:52:37.595034 EDT | StdEsReturn              307.48
2017-07-02 15:52:37.595268 EDT | MaxEsReturn              800.081
2017-07-02 15:52:37.595504 EDT | MinEsReturn              -24.1378
2017-07-02 15:52:37.595728 EDT | AverageDiscountedReturn   55.2219
2017-07-02 15:52:37.595958 EDT | AverageQLoss               0.0148072
2017-07-02 15:52:37.596079 EDT | AveragePolicySurr         -1.88444
2017-07-02 15:52:37.596247 EDT | AverageQ                   1.69692
2017-07-02 15:52:37.596476 EDT | AverageAbsQ                1.70359
2017-07-02 15:52:37.596701 EDT | AverageY                   1.69771
2017-07-02 15:52:37.596936 EDT | AverageAbsY                1.70278
2017-07-02 15:52:37.597115 EDT | AverageAbsQYDiff           0.0712826
2017-07-02 15:52:37.597339 EDT | AverageAction              0.955332
2017-07-02 15:52:37.597547 EDT | PolicyRegParamNorm        21.73
2017-07-02 15:52:37.597786 EDT | QFunRegParamNorm          17.865
2017-07-02 15:52:37.597967 EDT | -----------------------  -----------
2017-07-02 15:52:37.598146 EDT | [reproducibility_ML/DDPG/Walker/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #30 | Training started
2017-07-02 15:52:47.707182 EDT | [reproducibility_ML/DDPG/Walker/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #30 | Training finished
2017-07-02 15:52:47.707670 EDT | [reproducibility_ML/DDPG/Walker/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #30 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 15:52:47.707887 EDT | [reproducibility_ML/DDPG/Walker/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #30 | Collecting samples for evaluation
2017-07-02 15:52:56.262964 EDT | -----------------------  -----------
2017-07-02 15:52:56.263163 EDT | Epoch                     30
2017-07-02 15:52:56.263369 EDT | Iteration                 30
2017-07-02 15:52:56.263600 EDT | AverageReturn            157.479
2017-07-02 15:52:56.263826 EDT | StdReturn                 64.5087
2017-07-02 15:52:56.264057 EDT | MaxReturn                294.659
2017-07-02 15:52:56.264283 EDT | MinReturn                 18.6633
2017-07-02 15:52:56.264516 EDT | AverageEsReturn           85.5114
2017-07-02 15:52:56.264737 EDT | StdEsReturn               90.9437
2017-07-02 15:52:56.264973 EDT | MaxEsReturn              249.818
2017-07-02 15:52:56.265133 EDT | MinEsReturn              -36.1153
2017-07-02 15:52:56.265365 EDT | AverageDiscountedReturn   77.4678
2017-07-02 15:52:56.265623 EDT | AverageQLoss               0.014599
2017-07-02 15:52:56.265741 EDT | AveragePolicySurr         -1.89679
2017-07-02 15:52:56.265859 EDT | AverageQ                   1.72258
2017-07-02 15:52:56.265988 EDT | AverageAbsQ                1.72904
2017-07-02 15:52:56.266099 EDT | AverageY                   1.72315
2017-07-02 15:52:56.266208 EDT | AverageAbsY                1.72836
2017-07-02 15:52:56.266315 EDT | AverageAbsQYDiff           0.0698072
2017-07-02 15:52:56.266423 EDT | AverageAction              0.958266
2017-07-02 15:52:56.266530 EDT | PolicyRegParamNorm        21.9912
2017-07-02 15:52:56.266636 EDT | QFunRegParamNorm          18.1857
2017-07-02 15:52:56.266743 EDT | -----------------------  -----------
2017-07-02 15:52:56.266918 EDT | [reproducibility_ML/DDPG/Walker/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #31 | Training started
2017-07-02 15:53:06.353545 EDT | [reproducibility_ML/DDPG/Walker/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #31 | Training finished
2017-07-02 15:53:06.354094 EDT | [reproducibility_ML/DDPG/Walker/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #31 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 15:53:06.354305 EDT | [reproducibility_ML/DDPG/Walker/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #31 | Collecting samples for evaluation
2017-07-02 15:53:14.817803 EDT | -----------------------  ------------
2017-07-02 15:53:14.818416 EDT | Epoch                      31
2017-07-02 15:53:14.818628 EDT | Iteration                  31
2017-07-02 15:53:14.818807 EDT | AverageReturn               9.07902
2017-07-02 15:53:14.819047 EDT | StdReturn                  62.7556
2017-07-02 15:53:14.819274 EDT | MaxReturn                 163.416
2017-07-02 15:53:14.819507 EDT | MinReturn                -101.678
2017-07-02 15:53:14.819682 EDT | AverageEsReturn            61.7782
2017-07-02 15:53:14.819866 EDT | StdEsReturn               111.814
2017-07-02 15:53:14.820087 EDT | MaxEsReturn               279.571
2017-07-02 15:53:14.820315 EDT | MinEsReturn               -26.8942
2017-07-02 15:53:14.820435 EDT | AverageDiscountedReturn    18.94
2017-07-02 15:53:14.820548 EDT | AverageQLoss                0.0157938
2017-07-02 15:53:14.820658 EDT | AveragePolicySurr          -1.91259
2017-07-02 15:53:14.820805 EDT | AverageQ                    1.74321
2017-07-02 15:53:14.820917 EDT | AverageAbsQ                 1.75071
2017-07-02 15:53:14.821101 EDT | AverageY                    1.74385
2017-07-02 15:53:14.821322 EDT | AverageAbsY                 1.74968
2017-07-02 15:53:14.821614 EDT | AverageAbsQYDiff            0.0714013
2017-07-02 15:53:14.821848 EDT | AverageAction               0.94142
2017-07-02 15:53:14.822046 EDT | PolicyRegParamNorm         22.3789
2017-07-02 15:53:14.822277 EDT | QFunRegParamNorm           18.5446
2017-07-02 15:53:14.822512 EDT | -----------------------  ------------
2017-07-02 15:53:14.822842 EDT | [reproducibility_ML/DDPG/Walker/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #32 | Training started
2017-07-02 15:53:24.925943 EDT | [reproducibility_ML/DDPG/Walker/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #32 | Training finished
2017-07-02 15:53:24.926181 EDT | [reproducibility_ML/DDPG/Walker/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #32 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 15:53:24.926472 EDT | [reproducibility_ML/DDPG/Walker/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #32 | Collecting samples for evaluation
2017-07-02 15:53:33.520439 EDT | -----------------------  ------------
2017-07-02 15:53:33.521080 EDT | Epoch                      32
2017-07-02 15:53:33.521311 EDT | Iteration                  32
2017-07-02 15:53:33.521438 EDT | AverageReturn              47.7263
2017-07-02 15:53:33.521630 EDT | StdReturn                 115.905
2017-07-02 15:53:33.521845 EDT | MaxReturn                 478.352
2017-07-02 15:53:33.522051 EDT | MinReturn                -126.313
2017-07-02 15:53:33.522183 EDT | AverageEsReturn           -15.4798
2017-07-02 15:53:33.522347 EDT | StdEsReturn                69.1395
2017-07-02 15:53:33.522469 EDT | MaxEsReturn               137.759
2017-07-02 15:53:33.522586 EDT | MinEsReturn              -111.953
2017-07-02 15:53:33.522752 EDT | AverageDiscountedReturn    27.9149
2017-07-02 15:53:33.522951 EDT | AverageQLoss                0.0166693
2017-07-02 15:53:33.523102 EDT | AveragePolicySurr          -1.94314
2017-07-02 15:53:33.523220 EDT | AverageQ                    1.77075
2017-07-02 15:53:33.523369 EDT | AverageAbsQ                 1.77736
2017-07-02 15:53:33.523520 EDT | AverageY                    1.77144
2017-07-02 15:53:33.523644 EDT | AverageAbsY                 1.77629
2017-07-02 15:53:33.523761 EDT | AverageAbsQYDiff            0.0726489
2017-07-02 15:53:33.523875 EDT | AverageAction               0.946773
2017-07-02 15:53:33.523994 EDT | PolicyRegParamNorm         22.6668
2017-07-02 15:53:33.524114 EDT | QFunRegParamNorm           18.9233
2017-07-02 15:53:33.524228 EDT | -----------------------  ------------
2017-07-02 15:53:33.524441 EDT | [reproducibility_ML/DDPG/Walker/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #33 | Training started
2017-07-02 15:53:43.634116 EDT | [reproducibility_ML/DDPG/Walker/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #33 | Training finished
2017-07-02 15:53:43.642904 EDT | [reproducibility_ML/DDPG/Walker/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #33 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 15:53:43.643200 EDT | [reproducibility_ML/DDPG/Walker/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #33 | Collecting samples for evaluation
2017-07-02 15:53:52.706622 EDT | -----------------------  ------------
2017-07-02 15:53:52.707134 EDT | Epoch                      33
2017-07-02 15:53:52.707357 EDT | Iteration                  33
2017-07-02 15:53:52.707577 EDT | AverageReturn             497.154
2017-07-02 15:53:52.707722 EDT | StdReturn                 297.681
2017-07-02 15:53:52.707872 EDT | MaxReturn                1100.4
2017-07-02 15:53:52.708081 EDT | MinReturn                 -25.8493
2017-07-02 15:53:52.708253 EDT | AverageEsReturn           185.244
2017-07-02 15:53:52.708421 EDT | StdEsReturn               171.854
2017-07-02 15:53:52.708578 EDT | MaxEsReturn               357.098
2017-07-02 15:53:52.708721 EDT | MinEsReturn                13.3903
2017-07-02 15:53:52.708836 EDT | AverageDiscountedReturn    88.7214
2017-07-02 15:53:52.708975 EDT | AverageQLoss                0.016121
2017-07-02 15:53:52.709107 EDT | AveragePolicySurr          -1.94795
2017-07-02 15:53:52.709305 EDT | AverageQ                    1.7868
2017-07-02 15:53:52.709460 EDT | AverageAbsQ                 1.79326
2017-07-02 15:53:52.709646 EDT | AverageY                    1.78724
2017-07-02 15:53:52.709847 EDT | AverageAbsY                 1.7919
2017-07-02 15:53:52.709993 EDT | AverageAbsQYDiff            0.0735813
2017-07-02 15:53:52.710129 EDT | AverageAction               0.938017
2017-07-02 15:53:52.710297 EDT | PolicyRegParamNorm         22.9277
2017-07-02 15:53:52.710417 EDT | QFunRegParamNorm           19.2956
2017-07-02 15:53:52.710613 EDT | -----------------------  ------------
2017-07-02 15:53:52.710900 EDT | [reproducibility_ML/DDPG/Walker/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #34 | Training started
2017-07-02 15:54:02.755394 EDT | [reproducibility_ML/DDPG/Walker/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #34 | Training finished
2017-07-02 15:54:02.756039 EDT | [reproducibility_ML/DDPG/Walker/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #34 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 15:54:02.756274 EDT | [reproducibility_ML/DDPG/Walker/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #34 | Collecting samples for evaluation
2017-07-02 15:54:11.461302 EDT | -----------------------  -----------
2017-07-02 15:54:11.461652 EDT | Epoch                     34
2017-07-02 15:54:11.461896 EDT | Iteration                 34
2017-07-02 15:54:11.462117 EDT | AverageReturn            170.674
2017-07-02 15:54:11.462358 EDT | StdReturn                 76.7311
2017-07-02 15:54:11.462540 EDT | MaxReturn                410.774
2017-07-02 15:54:11.462671 EDT | MinReturn                -12.7099
2017-07-02 15:54:11.462780 EDT | AverageEsReturn           37.8306
2017-07-02 15:54:11.462888 EDT | StdEsReturn               49.0327
2017-07-02 15:54:11.462995 EDT | MaxEsReturn               99.2498
2017-07-02 15:54:11.463100 EDT | MinEsReturn              -34.8891
2017-07-02 15:54:11.463206 EDT | AverageDiscountedReturn   84.3038
2017-07-02 15:54:11.463388 EDT | AverageQLoss               0.0170255
2017-07-02 15:54:11.463615 EDT | AveragePolicySurr         -1.99493
2017-07-02 15:54:11.463811 EDT | AverageQ                   1.82113
2017-07-02 15:54:11.464048 EDT | AverageAbsQ                1.8272
2017-07-02 15:54:11.464239 EDT | AverageY                   1.82188
2017-07-02 15:54:11.464480 EDT | AverageAbsY                1.82624
2017-07-02 15:54:11.464718 EDT | AverageAbsQYDiff           0.0730409
2017-07-02 15:54:11.464956 EDT | AverageAction              0.95356
2017-07-02 15:54:11.465191 EDT | PolicyRegParamNorm        23.2347
2017-07-02 15:54:11.465409 EDT | QFunRegParamNorm          19.7007
2017-07-02 15:54:11.465628 EDT | -----------------------  -----------
2017-07-02 15:54:11.465942 EDT | [reproducibility_ML/DDPG/Walker/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #35 | Training started
2017-07-02 15:54:21.408629 EDT | [reproducibility_ML/DDPG/Walker/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #35 | Training finished
2017-07-02 15:54:21.409156 EDT | [reproducibility_ML/DDPG/Walker/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #35 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 15:54:21.409344 EDT | [reproducibility_ML/DDPG/Walker/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #35 | Collecting samples for evaluation
2017-07-02 15:54:30.192983 EDT | -----------------------  -----------
2017-07-02 15:54:30.193504 EDT | Epoch                     35
2017-07-02 15:54:30.193721 EDT | Iteration                 35
2017-07-02 15:54:30.193868 EDT | AverageReturn            172.927
2017-07-02 15:54:30.194019 EDT | StdReturn                187.233
2017-07-02 15:54:30.194136 EDT | MaxReturn                920.486
2017-07-02 15:54:30.194309 EDT | MinReturn                -92.1335
2017-07-02 15:54:30.194525 EDT | AverageEsReturn           23.1239
2017-07-02 15:54:30.194726 EDT | StdEsReturn               83.3149
2017-07-02 15:54:30.194907 EDT | MaxEsReturn              227.668
2017-07-02 15:54:30.195105 EDT | MinEsReturn              -58.6202
2017-07-02 15:54:30.195297 EDT | AverageDiscountedReturn   64.3251
2017-07-02 15:54:30.195438 EDT | AverageQLoss               0.0180288
2017-07-02 15:54:30.195607 EDT | AveragePolicySurr         -2.01757
2017-07-02 15:54:30.195736 EDT | AverageQ                   1.85587
2017-07-02 15:54:30.195846 EDT | AverageAbsQ                1.86189
2017-07-02 15:54:30.195982 EDT | AverageY                   1.85656
2017-07-02 15:54:30.196109 EDT | AverageAbsY                1.86093
2017-07-02 15:54:30.196217 EDT | AverageAbsQYDiff           0.0775815
2017-07-02 15:54:30.196358 EDT | AverageAction              0.91404
2017-07-02 15:54:30.196516 EDT | PolicyRegParamNorm        23.6287
2017-07-02 15:54:30.196672 EDT | QFunRegParamNorm          20.1057
2017-07-02 15:54:30.196783 EDT | -----------------------  -----------
2017-07-02 15:54:30.196993 EDT | [reproducibility_ML/DDPG/Walker/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #36 | Training started
2017-07-02 15:54:40.285806 EDT | [reproducibility_ML/DDPG/Walker/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #36 | Training finished
2017-07-02 15:54:40.286436 EDT | [reproducibility_ML/DDPG/Walker/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #36 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 15:54:40.286581 EDT | [reproducibility_ML/DDPG/Walker/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #36 | Collecting samples for evaluation
2017-07-02 15:54:48.996121 EDT | -----------------------  -----------
2017-07-02 15:54:48.996429 EDT | Epoch                     36
2017-07-02 15:54:48.996661 EDT | Iteration                 36
2017-07-02 15:54:48.996911 EDT | AverageReturn             -8.5059
2017-07-02 15:54:48.997128 EDT | StdReturn                  2.64332
2017-07-02 15:54:48.997303 EDT | MaxReturn                 -4.39515
2017-07-02 15:54:48.997568 EDT | MinReturn                -40.1278
2017-07-02 15:54:48.997855 EDT | AverageEsReturn          161.787
2017-07-02 15:54:48.998116 EDT | StdEsReturn              109.268
2017-07-02 15:54:48.998345 EDT | MaxEsReturn              340.194
2017-07-02 15:54:48.998591 EDT | MinEsReturn               25.1704
2017-07-02 15:54:48.998840 EDT | AverageDiscountedReturn   -5.61098
2017-07-02 15:54:48.999085 EDT | AverageQLoss               0.0191463
2017-07-02 15:54:48.999330 EDT | AveragePolicySurr         -2.05654
2017-07-02 15:54:48.999552 EDT | AverageQ                   1.88999
2017-07-02 15:54:48.999795 EDT | AverageAbsQ                1.89599
2017-07-02 15:54:49.000025 EDT | AverageY                   1.89056
2017-07-02 15:54:49.000254 EDT | AverageAbsY                1.89465
2017-07-02 15:54:49.000495 EDT | AverageAbsQYDiff           0.0784349
2017-07-02 15:54:49.000691 EDT | AverageAction              0.956752
2017-07-02 15:54:49.000895 EDT | PolicyRegParamNorm        23.936
2017-07-02 15:54:49.001145 EDT | QFunRegParamNorm          20.527
2017-07-02 15:54:49.001355 EDT | -----------------------  -----------
2017-07-02 15:54:49.001703 EDT | [reproducibility_ML/DDPG/Walker/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #37 | Training started
2017-07-02 15:54:59.105219 EDT | [reproducibility_ML/DDPG/Walker/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #37 | Training finished
2017-07-02 15:54:59.105757 EDT | [reproducibility_ML/DDPG/Walker/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #37 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 15:54:59.105991 EDT | [reproducibility_ML/DDPG/Walker/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #37 | Collecting samples for evaluation
2017-07-02 15:55:07.772110 EDT | -----------------------  ------------
2017-07-02 15:55:07.772695 EDT | Epoch                      37
2017-07-02 15:55:07.772940 EDT | Iteration                  37
2017-07-02 15:55:07.773165 EDT | AverageReturn             135.17
2017-07-02 15:55:07.773407 EDT | StdReturn                 204.578
2017-07-02 15:55:07.773661 EDT | MaxReturn                 851.657
2017-07-02 15:55:07.773898 EDT | MinReturn                -107.082
2017-07-02 15:55:07.774130 EDT | AverageEsReturn            10.8251
2017-07-02 15:55:07.774248 EDT | StdEsReturn                16.4523
2017-07-02 15:55:07.774360 EDT | MaxEsReturn                30.5294
2017-07-02 15:55:07.774471 EDT | MinEsReturn                -9.74247
2017-07-02 15:55:07.774579 EDT | AverageDiscountedReturn    20.6112
2017-07-02 15:55:07.774685 EDT | AverageQLoss                0.0198808
2017-07-02 15:55:07.774804 EDT | AveragePolicySurr          -2.08058
2017-07-02 15:55:07.774919 EDT | AverageQ                    1.91772
2017-07-02 15:55:07.775097 EDT | AverageAbsQ                 1.92349
2017-07-02 15:55:07.775437 EDT | AverageY                    1.91837
2017-07-02 15:55:07.775654 EDT | AverageAbsY                 1.92252
2017-07-02 15:55:07.775787 EDT | AverageAbsQYDiff            0.078797
2017-07-02 15:55:07.775950 EDT | AverageAction               0.928194
2017-07-02 15:55:07.776163 EDT | PolicyRegParamNorm         24.1749
2017-07-02 15:55:07.776396 EDT | QFunRegParamNorm           20.8703
2017-07-02 15:55:07.776619 EDT | -----------------------  ------------
2017-07-02 15:55:07.776955 EDT | [reproducibility_ML/DDPG/Walker/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #38 | Training started
2017-07-02 15:55:18.015523 EDT | [reproducibility_ML/DDPG/Walker/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #38 | Training finished
2017-07-02 15:55:18.015694 EDT | [reproducibility_ML/DDPG/Walker/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #38 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 15:55:18.016050 EDT | [reproducibility_ML/DDPG/Walker/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #38 | Collecting samples for evaluation
2017-07-02 15:55:27.155475 EDT | -----------------------  -----------
2017-07-02 15:55:27.155670 EDT | Epoch                     38
2017-07-02 15:55:27.155790 EDT | Iteration                 38
2017-07-02 15:55:27.155902 EDT | AverageReturn            -13.2803
2017-07-02 15:55:27.156012 EDT | StdReturn                 46.6208
2017-07-02 15:55:27.156151 EDT | MaxReturn                382.414
2017-07-02 15:55:27.156263 EDT | MinReturn                -82.6046
2017-07-02 15:55:27.156372 EDT | AverageEsReturn           55.6779
2017-07-02 15:55:27.156480 EDT | StdEsReturn              215.234
2017-07-02 15:55:27.156587 EDT | MaxEsReturn              793.734
2017-07-02 15:55:27.156704 EDT | MinEsReturn              -39.1072
2017-07-02 15:55:27.156830 EDT | AverageDiscountedReturn   -1.84601
2017-07-02 15:55:27.156939 EDT | AverageQLoss               0.0219724
2017-07-02 15:55:27.157048 EDT | AveragePolicySurr         -2.09869
2017-07-02 15:55:27.157155 EDT | AverageQ                   1.9385
2017-07-02 15:55:27.157262 EDT | AverageAbsQ                1.94442
2017-07-02 15:55:27.157369 EDT | AverageY                   1.93902
2017-07-02 15:55:27.157475 EDT | AverageAbsY                1.94292
2017-07-02 15:55:27.157625 EDT | AverageAbsQYDiff           0.0791249
2017-07-02 15:55:27.157790 EDT | AverageAction              0.951504
2017-07-02 15:55:27.157934 EDT | PolicyRegParamNorm        24.4857
2017-07-02 15:55:27.158110 EDT | QFunRegParamNorm          21.2139
2017-07-02 15:55:27.158255 EDT | -----------------------  -----------
2017-07-02 15:55:27.158441 EDT | [reproducibility_ML/DDPG/Walker/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #39 | Training started
2017-07-02 15:55:37.190715 EDT | [reproducibility_ML/DDPG/Walker/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #39 | Training finished
2017-07-02 15:55:37.202073 EDT | [reproducibility_ML/DDPG/Walker/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #39 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 15:55:37.202274 EDT | [reproducibility_ML/DDPG/Walker/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #39 | Collecting samples for evaluation
2017-07-02 15:55:45.852357 EDT | -----------------------  ------------
2017-07-02 15:55:45.852939 EDT | Epoch                      39
2017-07-02 15:55:45.853091 EDT | Iteration                  39
2017-07-02 15:55:45.853225 EDT | AverageReturn              45.4743
2017-07-02 15:55:45.853401 EDT | StdReturn                 152.833
2017-07-02 15:55:45.853601 EDT | MaxReturn                 879.606
2017-07-02 15:55:45.853743 EDT | MinReturn                -100.585
2017-07-02 15:55:45.853888 EDT | AverageEsReturn            46.3849
2017-07-02 15:55:45.854079 EDT | StdEsReturn                97.5237
2017-07-02 15:55:45.854200 EDT | MaxEsReturn               234.81
2017-07-02 15:55:45.854364 EDT | MinEsReturn               -30.4739
2017-07-02 15:55:45.854575 EDT | AverageDiscountedReturn    21.08
2017-07-02 15:55:45.854790 EDT | AverageQLoss                0.0211792
2017-07-02 15:55:45.854990 EDT | AveragePolicySurr          -2.13719
2017-07-02 15:55:45.855179 EDT | AverageQ                    1.97284
2017-07-02 15:55:45.855340 EDT | AverageAbsQ                 1.97749
2017-07-02 15:55:45.855498 EDT | AverageY                    1.97363
2017-07-02 15:55:45.855639 EDT | AverageAbsY                 1.97675
2017-07-02 15:55:45.855759 EDT | AverageAbsQYDiff            0.0785522
2017-07-02 15:55:45.855907 EDT | AverageAction               0.956915
2017-07-02 15:55:45.856019 EDT | PolicyRegParamNorm         24.7467
2017-07-02 15:55:45.856125 EDT | QFunRegParamNorm           21.5434
2017-07-02 15:55:45.856231 EDT | -----------------------  ------------
2017-07-02 15:55:45.856480 EDT | [reproducibility_ML/DDPG/Walker/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #40 | Training started
2017-07-02 15:55:55.894488 EDT | [reproducibility_ML/DDPG/Walker/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #40 | Training finished
2017-07-02 15:55:55.894779 EDT | [reproducibility_ML/DDPG/Walker/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #40 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 15:55:55.895020 EDT | [reproducibility_ML/DDPG/Walker/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #40 | Collecting samples for evaluation
2017-07-02 15:56:04.361575 EDT | -----------------------  -----------
2017-07-02 15:56:04.362091 EDT | Epoch                     40
2017-07-02 15:56:04.362300 EDT | Iteration                 40
2017-07-02 15:56:04.362507 EDT | AverageReturn              3.77812
2017-07-02 15:56:04.362683 EDT | StdReturn                  4.3594
2017-07-02 15:56:04.362822 EDT | MaxReturn                 29.1494
2017-07-02 15:56:04.362935 EDT | MinReturn                 -4.59995
2017-07-02 15:56:04.363065 EDT | AverageEsReturn           37.4114
2017-07-02 15:56:04.363205 EDT | StdEsReturn               95.2024
2017-07-02 15:56:04.363348 EDT | MaxEsReturn              237.762
2017-07-02 15:56:04.363489 EDT | MinEsReturn              -74.6347
2017-07-02 15:56:04.363637 EDT | AverageDiscountedReturn    2.66398
2017-07-02 15:56:04.363749 EDT | AverageQLoss               0.01807
2017-07-02 15:56:04.363857 EDT | AveragePolicySurr         -2.15016
2017-07-02 15:56:04.364013 EDT | AverageQ                   1.99488
2017-07-02 15:56:04.364197 EDT | AverageAbsQ                1.99958
2017-07-02 15:56:04.364338 EDT | AverageY                   1.99551
2017-07-02 15:56:04.364470 EDT | AverageAbsY                1.9986
2017-07-02 15:56:04.364579 EDT | AverageAbsQYDiff           0.0763893
2017-07-02 15:56:04.364724 EDT | AverageAction              0.952308
2017-07-02 15:56:04.364864 EDT | PolicyRegParamNorm        24.9897
2017-07-02 15:56:04.364988 EDT | QFunRegParamNorm          21.8338
2017-07-02 15:56:04.365097 EDT | -----------------------  -----------
2017-07-02 15:56:04.365333 EDT | [reproducibility_ML/DDPG/Walker/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #41 | Training started
2017-07-02 15:56:14.482170 EDT | [reproducibility_ML/DDPG/Walker/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #41 | Training finished
2017-07-02 15:56:14.482695 EDT | [reproducibility_ML/DDPG/Walker/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #41 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 15:56:14.482834 EDT | [reproducibility_ML/DDPG/Walker/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #41 | Collecting samples for evaluation
2017-07-02 15:56:22.977383 EDT | -----------------------  ------------
2017-07-02 15:56:22.977724 EDT | Epoch                      41
2017-07-02 15:56:22.977854 EDT | Iteration                  41
2017-07-02 15:56:22.978018 EDT | AverageReturn             168.721
2017-07-02 15:56:22.978176 EDT | StdReturn                 138.86
2017-07-02 15:56:22.978345 EDT | MaxReturn                 749.231
2017-07-02 15:56:22.978472 EDT | MinReturn                -105.523
2017-07-02 15:56:22.978626 EDT | AverageEsReturn            13.1418
2017-07-02 15:56:22.978739 EDT | StdEsReturn                32.3666
2017-07-02 15:56:22.978846 EDT | MaxEsReturn                91.3003
2017-07-02 15:56:22.978968 EDT | MinEsReturn               -34.9859
2017-07-02 15:56:22.979099 EDT | AverageDiscountedReturn    76.5551
2017-07-02 15:56:22.979228 EDT | AverageQLoss                0.0193505
2017-07-02 15:56:22.979356 EDT | AveragePolicySurr          -2.16833
2017-07-02 15:56:22.979465 EDT | AverageQ                    2.01512
2017-07-02 15:56:22.979573 EDT | AverageAbsQ                 2.02022
2017-07-02 15:56:22.979707 EDT | AverageY                    2.01563
2017-07-02 15:56:22.979837 EDT | AverageAbsY                 2.01919
2017-07-02 15:56:22.979948 EDT | AverageAbsQYDiff            0.077897
2017-07-02 15:56:22.980086 EDT | AverageAction               0.958765
2017-07-02 15:56:22.980218 EDT | PolicyRegParamNorm         25.302
2017-07-02 15:56:22.980360 EDT | QFunRegParamNorm           22.1328
2017-07-02 15:56:22.980476 EDT | -----------------------  ------------
2017-07-02 15:56:22.980665 EDT | [reproducibility_ML/DDPG/Walker/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #42 | Training started
2017-07-02 15:56:33.105051 EDT | [reproducibility_ML/DDPG/Walker/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #42 | Training finished
2017-07-02 15:56:33.105798 EDT | [reproducibility_ML/DDPG/Walker/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #42 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 15:56:33.105951 EDT | [reproducibility_ML/DDPG/Walker/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #42 | Collecting samples for evaluation
2017-07-02 15:56:42.438803 EDT | -----------------------  ------------
2017-07-02 15:56:42.439281 EDT | Epoch                      42
2017-07-02 15:56:42.439444 EDT | Iteration                  42
2017-07-02 15:56:42.439672 EDT | AverageReturn              91.0503
2017-07-02 15:56:42.439916 EDT | StdReturn                 243.402
2017-07-02 15:56:42.440144 EDT | MaxReturn                 992.469
2017-07-02 15:56:42.440362 EDT | MinReturn                -173.142
2017-07-02 15:56:42.440582 EDT | AverageEsReturn             7.57732
2017-07-02 15:56:42.440819 EDT | StdEsReturn                59.229
2017-07-02 15:56:42.441060 EDT | MaxEsReturn               208.297
2017-07-02 15:56:42.441297 EDT | MinEsReturn               -67.898
2017-07-02 15:56:42.441543 EDT | AverageDiscountedReturn    22.6976
2017-07-02 15:56:42.441769 EDT | AverageQLoss                0.019079
2017-07-02 15:56:42.441998 EDT | AveragePolicySurr          -2.18903
2017-07-02 15:56:42.442219 EDT | AverageQ                    2.03883
2017-07-02 15:56:42.442449 EDT | AverageAbsQ                 2.04392
2017-07-02 15:56:42.442692 EDT | AverageY                    2.03949
2017-07-02 15:56:42.442860 EDT | AverageAbsY                 2.04265
2017-07-02 15:56:42.442974 EDT | AverageAbsQYDiff            0.0766268
2017-07-02 15:56:42.443083 EDT | AverageAction               0.936207
2017-07-02 15:56:42.443191 EDT | PolicyRegParamNorm         25.6785
2017-07-02 15:56:42.443297 EDT | QFunRegParamNorm           22.444
2017-07-02 15:56:42.443403 EDT | -----------------------  ------------
2017-07-02 15:56:42.443586 EDT | [reproducibility_ML/DDPG/Walker/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #43 | Training started
2017-07-02 15:56:52.551140 EDT | [reproducibility_ML/DDPG/Walker/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #43 | Training finished
2017-07-02 15:56:52.551347 EDT | [reproducibility_ML/DDPG/Walker/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #43 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 15:56:52.551568 EDT | [reproducibility_ML/DDPG/Walker/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #43 | Collecting samples for evaluation
2017-07-02 15:57:01.133758 EDT | -----------------------  ------------
2017-07-02 15:57:01.134278 EDT | Epoch                      43
2017-07-02 15:57:01.134527 EDT | Iteration                  43
2017-07-02 15:57:01.134661 EDT | AverageReturn              69.3324
2017-07-02 15:57:01.134840 EDT | StdReturn                 123.57
2017-07-02 15:57:01.135071 EDT | MaxReturn                 442.777
2017-07-02 15:57:01.135306 EDT | MinReturn                -135.046
2017-07-02 15:57:01.135532 EDT | AverageEsReturn           138.275
2017-07-02 15:57:01.135659 EDT | StdEsReturn               169.858
2017-07-02 15:57:01.135770 EDT | MaxEsReturn               411.866
2017-07-02 15:57:01.135878 EDT | MinEsReturn                -0.957073
2017-07-02 15:57:01.135995 EDT | AverageDiscountedReturn    27.45
2017-07-02 15:57:01.136135 EDT | AverageQLoss                0.0233007
2017-07-02 15:57:01.136243 EDT | AveragePolicySurr          -2.21251
2017-07-02 15:57:01.136348 EDT | AverageQ                    2.06367
2017-07-02 15:57:01.136499 EDT | AverageAbsQ                 2.06788
2017-07-02 15:57:01.136608 EDT | AverageY                    2.06458
2017-07-02 15:57:01.136727 EDT | AverageAbsY                 2.06705
2017-07-02 15:57:01.136939 EDT | AverageAbsQYDiff            0.0796623
2017-07-02 15:57:01.137116 EDT | AverageAction               0.956455
2017-07-02 15:57:01.137323 EDT | PolicyRegParamNorm         26.0169
2017-07-02 15:57:01.137911 EDT | QFunRegParamNorm           22.7357
2017-07-02 15:57:01.138081 EDT | -----------------------  ------------
2017-07-02 15:57:01.138322 EDT | [reproducibility_ML/DDPG/Walker/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #44 | Training started
2017-07-02 15:57:11.135752 EDT | [reproducibility_ML/DDPG/Walker/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #44 | Training finished
2017-07-02 15:57:11.136395 EDT | [reproducibility_ML/DDPG/Walker/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #44 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 15:57:11.136650 EDT | [reproducibility_ML/DDPG/Walker/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #44 | Collecting samples for evaluation
2017-07-02 15:57:19.941844 EDT | -----------------------  -----------
2017-07-02 15:57:19.942048 EDT | Epoch                     44
2017-07-02 15:57:19.942283 EDT | Iteration                 44
2017-07-02 15:57:19.942439 EDT | AverageReturn            250.647
2017-07-02 15:57:19.942584 EDT | StdReturn                227.471
2017-07-02 15:57:19.942696 EDT | MaxReturn                910.774
2017-07-02 15:57:19.942811 EDT | MinReturn                -12.971
2017-07-02 15:57:19.943040 EDT | AverageEsReturn           95.4746
2017-07-02 15:57:19.943249 EDT | StdEsReturn              122.662
2017-07-02 15:57:19.943486 EDT | MaxEsReturn              331.959
2017-07-02 15:57:19.943719 EDT | MinEsReturn              -45.6642
2017-07-02 15:57:19.943948 EDT | AverageDiscountedReturn   71.3109
2017-07-02 15:57:19.944169 EDT | AverageQLoss               0.0216444
2017-07-02 15:57:19.944288 EDT | AveragePolicySurr         -2.22474
2017-07-02 15:57:19.944403 EDT | AverageQ                   2.08251
2017-07-02 15:57:19.944627 EDT | AverageAbsQ                2.08648
2017-07-02 15:57:19.944807 EDT | AverageY                   2.08304
2017-07-02 15:57:19.944921 EDT | AverageAbsY                2.08512
2017-07-02 15:57:19.945090 EDT | AverageAbsQYDiff           0.0778142
2017-07-02 15:57:19.945204 EDT | AverageAction              0.948452
2017-07-02 15:57:19.945426 EDT | PolicyRegParamNorm        26.4663
2017-07-02 15:57:19.945751 EDT | QFunRegParamNorm          23.0507
2017-07-02 15:57:19.945977 EDT | -----------------------  -----------
2017-07-02 15:57:19.946217 EDT | [reproducibility_ML/DDPG/Walker/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #45 | Training started
2017-07-02 15:57:29.986622 EDT | [reproducibility_ML/DDPG/Walker/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #45 | Training finished
2017-07-02 15:57:29.987199 EDT | [reproducibility_ML/DDPG/Walker/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #45 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 15:57:29.987457 EDT | [reproducibility_ML/DDPG/Walker/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #45 | Collecting samples for evaluation
2017-07-02 15:57:38.886717 EDT | -----------------------  -----------
2017-07-02 15:57:38.887337 EDT | Epoch                     45
2017-07-02 15:57:38.887539 EDT | Iteration                 45
2017-07-02 15:57:38.887660 EDT | AverageReturn            311.793
2017-07-02 15:57:38.887782 EDT | StdReturn                270.866
2017-07-02 15:57:38.888011 EDT | MaxReturn                903.922
2017-07-02 15:57:38.888211 EDT | MinReturn                -52.0453
2017-07-02 15:57:38.888443 EDT | AverageEsReturn           44.2954
2017-07-02 15:57:38.888661 EDT | StdEsReturn               78.5299
2017-07-02 15:57:38.888886 EDT | MaxEsReturn              193.121
2017-07-02 15:57:38.889124 EDT | MinEsReturn              -28.4333
2017-07-02 15:57:38.889351 EDT | AverageDiscountedReturn   66.9198
2017-07-02 15:57:38.889600 EDT | AverageQLoss               0.0229904
2017-07-02 15:57:38.889824 EDT | AveragePolicySurr         -2.25118
2017-07-02 15:57:38.890027 EDT | AverageQ                   2.10567
2017-07-02 15:57:38.890253 EDT | AverageAbsQ                2.10972
2017-07-02 15:57:38.890454 EDT | AverageY                   2.10616
2017-07-02 15:57:38.890693 EDT | AverageAbsY                2.10832
2017-07-02 15:57:38.890923 EDT | AverageAbsQYDiff           0.0798491
2017-07-02 15:57:38.891151 EDT | AverageAction              0.92603
2017-07-02 15:57:38.891727 EDT | PolicyRegParamNorm        26.679
2017-07-02 15:57:38.891969 EDT | QFunRegParamNorm          23.3931
2017-07-02 15:57:38.892201 EDT | -----------------------  -----------
2017-07-02 15:57:38.892901 EDT | [reproducibility_ML/DDPG/Walker/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #46 | Training started
2017-07-02 15:57:48.867752 EDT | [reproducibility_ML/DDPG/Walker/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #46 | Training finished
2017-07-02 15:57:48.868030 EDT | [reproducibility_ML/DDPG/Walker/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #46 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 15:57:48.868239 EDT | [reproducibility_ML/DDPG/Walker/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #46 | Collecting samples for evaluation
2017-07-02 15:57:58.072590 EDT | -----------------------  -----------
2017-07-02 15:57:58.073167 EDT | Epoch                     46
2017-07-02 15:57:58.073366 EDT | Iteration                 46
2017-07-02 15:57:58.073578 EDT | AverageReturn            238.896
2017-07-02 15:57:58.073788 EDT | StdReturn                196.317
2017-07-02 15:57:58.073934 EDT | MaxReturn                944.75
2017-07-02 15:57:58.074096 EDT | MinReturn                105.841
2017-07-02 15:57:58.074221 EDT | AverageEsReturn          255.872
2017-07-02 15:57:58.074407 EDT | StdEsReturn              199.794
2017-07-02 15:57:58.074539 EDT | MaxEsReturn              508.735
2017-07-02 15:57:58.074650 EDT | MinEsReturn               20.2537
2017-07-02 15:57:58.074788 EDT | AverageDiscountedReturn   78.2193
2017-07-02 15:57:58.074904 EDT | AverageQLoss               0.0206727
2017-07-02 15:57:58.075027 EDT | AveragePolicySurr         -2.26962
2017-07-02 15:57:58.075137 EDT | AverageQ                   2.12917
2017-07-02 15:57:58.075259 EDT | AverageAbsQ                2.13288
2017-07-02 15:57:58.075386 EDT | AverageY                   2.12975
2017-07-02 15:57:58.075510 EDT | AverageAbsY                2.13181
2017-07-02 15:57:58.075716 EDT | AverageAbsQYDiff           0.0774379
2017-07-02 15:57:58.075956 EDT | AverageAction              0.936872
2017-07-02 15:57:58.076176 EDT | PolicyRegParamNorm        26.934
2017-07-02 15:57:58.076349 EDT | QFunRegParamNorm          23.6914
2017-07-02 15:57:58.076549 EDT | -----------------------  -----------
2017-07-02 15:57:58.076728 EDT | [reproducibility_ML/DDPG/Walker/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #47 | Training started
2017-07-02 15:58:08.110552 EDT | [reproducibility_ML/DDPG/Walker/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #47 | Training finished
2017-07-02 15:58:08.111125 EDT | [reproducibility_ML/DDPG/Walker/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #47 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 15:58:08.111289 EDT | [reproducibility_ML/DDPG/Walker/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #47 | Collecting samples for evaluation
2017-07-02 15:58:16.642339 EDT | -----------------------  ------------
2017-07-02 15:58:16.642679 EDT | Epoch                      47
2017-07-02 15:58:16.642907 EDT | Iteration                  47
2017-07-02 15:58:16.643163 EDT | AverageReturn             -32.4311
2017-07-02 15:58:16.643354 EDT | StdReturn                 107.601
2017-07-02 15:58:16.643679 EDT | MaxReturn                 255.161
2017-07-02 15:58:16.643949 EDT | MinReturn                -305.613
2017-07-02 15:58:16.644200 EDT | AverageEsReturn           102.787
2017-07-02 15:58:16.644367 EDT | StdEsReturn                68.3715
2017-07-02 15:58:16.644498 EDT | MaxEsReturn               190.664
2017-07-02 15:58:16.644615 EDT | MinEsReturn                -6.9897
2017-07-02 15:58:16.644729 EDT | AverageDiscountedReturn     1.78543
2017-07-02 15:58:16.644843 EDT | AverageQLoss                0.0216493
2017-07-02 15:58:16.644956 EDT | AveragePolicySurr          -2.29007
2017-07-02 15:58:16.645068 EDT | AverageQ                    2.1454
2017-07-02 15:58:16.645181 EDT | AverageAbsQ                 2.14933
2017-07-02 15:58:16.645292 EDT | AverageY                    2.14596
2017-07-02 15:58:16.645403 EDT | AverageAbsY                 2.14816
2017-07-02 15:58:16.645521 EDT | AverageAbsQYDiff            0.077754
2017-07-02 15:58:16.645633 EDT | AverageAction               0.960869
2017-07-02 15:58:16.645745 EDT | PolicyRegParamNorm         27.2069
2017-07-02 15:58:16.645857 EDT | QFunRegParamNorm           24.0087
2017-07-02 15:58:16.645968 EDT | -----------------------  ------------
2017-07-02 15:58:16.646148 EDT | [reproducibility_ML/DDPG/Walker/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #48 | Training started
2017-07-02 15:58:26.720596 EDT | [reproducibility_ML/DDPG/Walker/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #48 | Training finished
2017-07-02 15:58:26.720893 EDT | [reproducibility_ML/DDPG/Walker/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #48 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 15:58:26.721137 EDT | [reproducibility_ML/DDPG/Walker/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #48 | Collecting samples for evaluation
2017-07-02 15:58:36.466427 EDT | -----------------------  -----------
2017-07-02 15:58:36.466904 EDT | Epoch                     48
2017-07-02 15:58:36.467155 EDT | Iteration                 48
2017-07-02 15:58:36.467388 EDT | AverageReturn            400.493
2017-07-02 15:58:36.467626 EDT | StdReturn                336.331
2017-07-02 15:58:36.467808 EDT | MaxReturn                882.597
2017-07-02 15:58:36.467979 EDT | MinReturn                -27.2984
2017-07-02 15:58:36.468105 EDT | AverageEsReturn          132.155
2017-07-02 15:58:36.468236 EDT | StdEsReturn              189.277
2017-07-02 15:58:36.468356 EDT | MaxEsReturn              449.187
2017-07-02 15:58:36.468467 EDT | MinEsReturn              -35.7034
2017-07-02 15:58:36.468576 EDT | AverageDiscountedReturn   65.8675
2017-07-02 15:58:36.468721 EDT | AverageQLoss               0.0218017
2017-07-02 15:58:36.468831 EDT | AveragePolicySurr         -2.29967
2017-07-02 15:58:36.468940 EDT | AverageQ                   2.16344
2017-07-02 15:58:36.469049 EDT | AverageAbsQ                2.16779
2017-07-02 15:58:36.469177 EDT | AverageY                   2.16396
2017-07-02 15:58:36.469300 EDT | AverageAbsY                2.16659
2017-07-02 15:58:36.469425 EDT | AverageAbsQYDiff           0.0786986
2017-07-02 15:58:36.469613 EDT | AverageAction              0.934493
2017-07-02 15:58:36.469801 EDT | PolicyRegParamNorm        27.4924
2017-07-02 15:58:36.469984 EDT | QFunRegParamNorm          24.3488
2017-07-02 15:58:36.470175 EDT | -----------------------  -----------
2017-07-02 15:58:36.470453 EDT | [reproducibility_ML/DDPG/Walker/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #49 | Training started
2017-07-02 15:58:46.593345 EDT | [reproducibility_ML/DDPG/Walker/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #49 | Training finished
2017-07-02 15:58:46.593999 EDT | [reproducibility_ML/DDPG/Walker/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #49 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 15:58:46.594233 EDT | [reproducibility_ML/DDPG/Walker/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #49 | Collecting samples for evaluation
2017-07-02 15:58:55.876901 EDT | -----------------------  -----------
2017-07-02 15:58:55.877530 EDT | Epoch                     49
2017-07-02 15:58:55.877771 EDT | Iteration                 49
2017-07-02 15:58:55.877945 EDT | AverageReturn            491.867
2017-07-02 15:58:55.878172 EDT | StdReturn                260.955
2017-07-02 15:58:55.878373 EDT | MaxReturn                925.215
2017-07-02 15:58:55.878613 EDT | MinReturn                 62.0228
2017-07-02 15:58:55.878839 EDT | AverageEsReturn          114.412
2017-07-02 15:58:55.879063 EDT | StdEsReturn              107.89
2017-07-02 15:58:55.879285 EDT | MaxEsReturn              281.724
2017-07-02 15:58:55.879458 EDT | MinEsReturn                5.57251
2017-07-02 15:58:55.879692 EDT | AverageDiscountedReturn   76.7635
2017-07-02 15:58:55.879923 EDT | AverageQLoss               0.0210797
2017-07-02 15:58:55.880145 EDT | AveragePolicySurr         -2.32369
2017-07-02 15:58:55.880378 EDT | AverageQ                   2.18676
2017-07-02 15:58:55.880598 EDT | AverageAbsQ                2.19074
2017-07-02 15:58:55.880773 EDT | AverageY                   2.18749
2017-07-02 15:58:55.881006 EDT | AverageAbsY                2.18996
2017-07-02 15:58:55.881228 EDT | AverageAbsQYDiff           0.0767247
2017-07-02 15:58:55.881450 EDT | AverageAction              0.94773
2017-07-02 15:58:55.881582 EDT | PolicyRegParamNorm        27.7612
2017-07-02 15:58:55.881810 EDT | QFunRegParamNorm          24.6178
2017-07-02 15:58:55.881975 EDT | -----------------------  -----------
2017-07-02 15:58:55.882202 EDT | [reproducibility_ML/DDPG/Walker/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #50 | Training started
2017-07-02 15:59:05.891223 EDT | [reproducibility_ML/DDPG/Walker/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #50 | Training finished
2017-07-02 15:59:05.891790 EDT | [reproducibility_ML/DDPG/Walker/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #50 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 15:59:05.891944 EDT | [reproducibility_ML/DDPG/Walker/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #50 | Collecting samples for evaluation
2017-07-02 15:59:14.871874 EDT | -----------------------  -----------
2017-07-02 15:59:14.872186 EDT | Epoch                     50
2017-07-02 15:59:14.872439 EDT | Iteration                 50
2017-07-02 15:59:14.872682 EDT | AverageReturn            294.878
2017-07-02 15:59:14.872928 EDT | StdReturn                328.085
2017-07-02 15:59:14.873066 EDT | MaxReturn                951.146
2017-07-02 15:59:14.873186 EDT | MinReturn                -30.1534
2017-07-02 15:59:14.873364 EDT | AverageEsReturn          191.622
2017-07-02 15:59:14.873617 EDT | StdEsReturn               99.9293
2017-07-02 15:59:14.873844 EDT | MaxEsReturn              324.349
2017-07-02 15:59:14.874077 EDT | MinEsReturn               58.8012
2017-07-02 15:59:14.874286 EDT | AverageDiscountedReturn   61.1849
2017-07-02 15:59:14.874526 EDT | AverageQLoss               0.0227117
2017-07-02 15:59:14.874811 EDT | AveragePolicySurr         -2.32082
2017-07-02 15:59:14.875042 EDT | AverageQ                   2.19078
2017-07-02 15:59:14.875257 EDT | AverageAbsQ                2.19514
2017-07-02 15:59:14.875491 EDT | AverageY                   2.19144
2017-07-02 15:59:14.875653 EDT | AverageAbsY                2.19409
2017-07-02 15:59:14.875788 EDT | AverageAbsQYDiff           0.0786354
2017-07-02 15:59:14.875906 EDT | AverageAction              0.912053
2017-07-02 15:59:14.876113 EDT | PolicyRegParamNorm        28.019
2017-07-02 15:59:14.876329 EDT | QFunRegParamNorm          24.9296
2017-07-02 15:59:14.876563 EDT | -----------------------  -----------
2017-07-02 15:59:14.876859 EDT | [reproducibility_ML/DDPG/Walker/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #51 | Training started
2017-07-02 15:59:24.874271 EDT | [reproducibility_ML/DDPG/Walker/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #51 | Training finished
2017-07-02 15:59:24.874865 EDT | [reproducibility_ML/DDPG/Walker/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #51 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 15:59:24.875361 EDT | [reproducibility_ML/DDPG/Walker/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #51 | Collecting samples for evaluation
2017-07-02 15:59:33.554641 EDT | -----------------------  -----------
2017-07-02 15:59:33.555135 EDT | Epoch                     51
2017-07-02 15:59:33.555317 EDT | Iteration                 51
2017-07-02 15:59:33.555470 EDT | AverageReturn            115.948
2017-07-02 15:59:33.555621 EDT | StdReturn                126.23
2017-07-02 15:59:33.555771 EDT | MaxReturn                457.802
2017-07-02 15:59:33.555895 EDT | MinReturn                -36.0827
2017-07-02 15:59:33.556045 EDT | AverageEsReturn          143.199
2017-07-02 15:59:33.556212 EDT | StdEsReturn               99.0976
2017-07-02 15:59:33.556361 EDT | MaxEsReturn              334.662
2017-07-02 15:59:33.556470 EDT | MinEsReturn               67.4434
2017-07-02 15:59:33.556588 EDT | AverageDiscountedReturn   45.8117
2017-07-02 15:59:33.556761 EDT | AverageQLoss               0.0238832
2017-07-02 15:59:33.556894 EDT | AveragePolicySurr         -2.34205
2017-07-02 15:59:33.557004 EDT | AverageQ                   2.20646
2017-07-02 15:59:33.557130 EDT | AverageAbsQ                2.21095
2017-07-02 15:59:33.557301 EDT | AverageY                   2.2068
2017-07-02 15:59:33.557409 EDT | AverageAbsY                2.20967
2017-07-02 15:59:33.557558 EDT | AverageAbsQYDiff           0.0792089
2017-07-02 15:59:33.557678 EDT | AverageAction              0.955644
2017-07-02 15:59:33.557813 EDT | PolicyRegParamNorm        28.3716
2017-07-02 15:59:33.557925 EDT | QFunRegParamNorm          25.2777
2017-07-02 15:59:33.558068 EDT | -----------------------  -----------
2017-07-02 15:59:33.558245 EDT | [reproducibility_ML/DDPG/Walker/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #52 | Training started
2017-07-02 15:59:43.747242 EDT | [reproducibility_ML/DDPG/Walker/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #52 | Training finished
2017-07-02 15:59:43.747739 EDT | [reproducibility_ML/DDPG/Walker/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #52 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 15:59:43.747917 EDT | [reproducibility_ML/DDPG/Walker/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #52 | Collecting samples for evaluation
2017-07-02 15:59:52.515778 EDT | -----------------------  -----------
2017-07-02 15:59:52.516032 EDT | Epoch                     52
2017-07-02 15:59:52.516177 EDT | Iteration                 52
2017-07-02 15:59:52.516379 EDT | AverageReturn            129.252
2017-07-02 15:59:52.516604 EDT | StdReturn                122.724
2017-07-02 15:59:52.516832 EDT | MaxReturn                395.009
2017-07-02 15:59:52.517007 EDT | MinReturn                -31.6977
2017-07-02 15:59:52.517234 EDT | AverageEsReturn          175.158
2017-07-02 15:59:52.517471 EDT | StdEsReturn               92.1372
2017-07-02 15:59:52.517729 EDT | MaxEsReturn              297.5
2017-07-02 15:59:52.517963 EDT | MinEsReturn                6.16875
2017-07-02 15:59:52.518263 EDT | AverageDiscountedReturn   53.4336
2017-07-02 15:59:52.518564 EDT | AverageQLoss               0.023975
2017-07-02 15:59:52.518825 EDT | AveragePolicySurr         -2.37717
2017-07-02 15:59:52.519058 EDT | AverageQ                   2.24475
2017-07-02 15:59:52.519288 EDT | AverageAbsQ                2.24922
2017-07-02 15:59:52.519526 EDT | AverageY                   2.24536
2017-07-02 15:59:52.519692 EDT | AverageAbsY                2.2482
2017-07-02 15:59:52.519927 EDT | AverageAbsQYDiff           0.0800759
2017-07-02 15:59:52.520094 EDT | AverageAction              0.95534
2017-07-02 15:59:52.520217 EDT | PolicyRegParamNorm        28.6296
2017-07-02 15:59:52.520465 EDT | QFunRegParamNorm          25.6229
2017-07-02 15:59:52.520703 EDT | -----------------------  -----------
2017-07-02 15:59:52.521005 EDT | [reproducibility_ML/DDPG/Walker/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #53 | Training started
2017-07-02 16:00:02.547051 EDT | [reproducibility_ML/DDPG/Walker/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #53 | Training finished
2017-07-02 16:00:02.547606 EDT | [reproducibility_ML/DDPG/Walker/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #53 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 16:00:02.547779 EDT | [reproducibility_ML/DDPG/Walker/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #53 | Collecting samples for evaluation
2017-07-02 16:00:11.059539 EDT | -----------------------  -----------
2017-07-02 16:00:11.060150 EDT | Epoch                     53
2017-07-02 16:00:11.060357 EDT | Iteration                 53
2017-07-02 16:00:11.060487 EDT | AverageReturn            125.619
2017-07-02 16:00:11.060629 EDT | StdReturn                105.648
2017-07-02 16:00:11.060747 EDT | MaxReturn                500.771
2017-07-02 16:00:11.060898 EDT | MinReturn                -46.1078
2017-07-02 16:00:11.061087 EDT | AverageEsReturn           90.3643
2017-07-02 16:00:11.061217 EDT | StdEsReturn               97.2241
2017-07-02 16:00:11.061333 EDT | MaxEsReturn              212.221
2017-07-02 16:00:11.061449 EDT | MinEsReturn              -27.3348
2017-07-02 16:00:11.061762 EDT | AverageDiscountedReturn   45.5679
2017-07-02 16:00:11.062022 EDT | AverageQLoss               0.0230501
2017-07-02 16:00:11.062186 EDT | AveragePolicySurr         -2.37802
2017-07-02 16:00:11.062322 EDT | AverageQ                   2.25065
2017-07-02 16:00:11.062438 EDT | AverageAbsQ                2.25486
2017-07-02 16:00:11.062553 EDT | AverageY                   2.2513
2017-07-02 16:00:11.062686 EDT | AverageAbsY                2.25409
2017-07-02 16:00:11.062813 EDT | AverageAbsQYDiff           0.0788592
2017-07-02 16:00:11.062927 EDT | AverageAction              0.960156
2017-07-02 16:00:11.063040 EDT | PolicyRegParamNorm        28.9012
2017-07-02 16:00:11.063193 EDT | QFunRegParamNorm          25.8828
2017-07-02 16:00:11.063320 EDT | -----------------------  -----------
2017-07-02 16:00:11.063560 EDT | [reproducibility_ML/DDPG/Walker/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #54 | Training started
2017-07-02 16:00:21.336746 EDT | [reproducibility_ML/DDPG/Walker/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #54 | Training finished
2017-07-02 16:00:21.337131 EDT | [reproducibility_ML/DDPG/Walker/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #54 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 16:00:21.337742 EDT | [reproducibility_ML/DDPG/Walker/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #54 | Collecting samples for evaluation
2017-07-02 16:00:30.142320 EDT | -----------------------  -----------
2017-07-02 16:00:30.142716 EDT | Epoch                     54
2017-07-02 16:00:30.142946 EDT | Iteration                 54
2017-07-02 16:00:30.143184 EDT | AverageReturn            183.325
2017-07-02 16:00:30.143475 EDT | StdReturn                 62.4418
2017-07-02 16:00:30.143703 EDT | MaxReturn                419.935
2017-07-02 16:00:30.143940 EDT | MinReturn                 47.981
2017-07-02 16:00:30.144303 EDT | AverageEsReturn           27.7629
2017-07-02 16:00:30.144530 EDT | StdEsReturn               82.091
2017-07-02 16:00:30.144765 EDT | MaxEsReturn              212.497
2017-07-02 16:00:30.145157 EDT | MinEsReturn              -77.3113
2017-07-02 16:00:30.145277 EDT | AverageDiscountedReturn   93.8324
2017-07-02 16:00:30.145432 EDT | AverageQLoss               0.0272807
2017-07-02 16:00:30.145621 EDT | AveragePolicySurr         -2.38091
2017-07-02 16:00:30.145788 EDT | AverageQ                   2.25763
2017-07-02 16:00:30.145899 EDT | AverageAbsQ                2.26188
2017-07-02 16:00:30.146045 EDT | AverageY                   2.25809
2017-07-02 16:00:30.146155 EDT | AverageAbsY                2.26065
2017-07-02 16:00:30.146344 EDT | AverageAbsQYDiff           0.0815324
2017-07-02 16:00:30.146569 EDT | AverageAction              0.956933
2017-07-02 16:00:30.146796 EDT | PolicyRegParamNorm        29.1505
2017-07-02 16:00:30.147022 EDT | QFunRegParamNorm          26.1758
2017-07-02 16:00:30.147166 EDT | -----------------------  -----------
2017-07-02 16:00:30.147356 EDT | [reproducibility_ML/DDPG/Walker/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #55 | Training started
2017-07-02 16:00:40.130133 EDT | [reproducibility_ML/DDPG/Walker/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #55 | Training finished
2017-07-02 16:00:40.130650 EDT | [reproducibility_ML/DDPG/Walker/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #55 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 16:00:40.130793 EDT | [reproducibility_ML/DDPG/Walker/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #55 | Collecting samples for evaluation
2017-07-02 16:00:50.034426 EDT | -----------------------  -----------
2017-07-02 16:00:50.035204 EDT | Epoch                     55
2017-07-02 16:00:50.035412 EDT | Iteration                 55
2017-07-02 16:00:50.035554 EDT | AverageReturn            496.677
2017-07-02 16:00:50.035734 EDT | StdReturn                364.201
2017-07-02 16:00:50.035889 EDT | MaxReturn                942.95
2017-07-02 16:00:50.036111 EDT | MinReturn                 84.8307
2017-07-02 16:00:50.036309 EDT | AverageEsReturn          131.182
2017-07-02 16:00:50.036425 EDT | StdEsReturn               90.0855
2017-07-02 16:00:50.036606 EDT | MaxEsReturn              273.533
2017-07-02 16:00:50.036746 EDT | MinEsReturn                5.60776
2017-07-02 16:00:50.036856 EDT | AverageDiscountedReturn   74.0616
2017-07-02 16:00:50.037022 EDT | AverageQLoss               0.0241198
2017-07-02 16:00:50.037225 EDT | AveragePolicySurr         -2.38712
2017-07-02 16:00:50.037367 EDT | AverageQ                   2.26186
2017-07-02 16:00:50.037476 EDT | AverageAbsQ                2.26616
2017-07-02 16:00:50.037600 EDT | AverageY                   2.2623
2017-07-02 16:00:50.037705 EDT | AverageAbsY                2.2651
2017-07-02 16:00:50.037813 EDT | AverageAbsQYDiff           0.0794588
2017-07-02 16:00:50.037924 EDT | AverageAction              0.893982
2017-07-02 16:00:50.038119 EDT | PolicyRegParamNorm        29.4027
2017-07-02 16:00:50.038239 EDT | QFunRegParamNorm          26.465
2017-07-02 16:00:50.038376 EDT | -----------------------  -----------
2017-07-02 16:00:50.038665 EDT | [reproducibility_ML/DDPG/Walker/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #56 | Training started
2017-07-02 16:01:00.115843 EDT | [reproducibility_ML/DDPG/Walker/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #56 | Training finished
2017-07-02 16:01:00.116227 EDT | [reproducibility_ML/DDPG/Walker/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #56 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 16:01:00.116488 EDT | [reproducibility_ML/DDPG/Walker/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #56 | Collecting samples for evaluation
2017-07-02 16:01:09.220107 EDT | -----------------------  -----------
2017-07-02 16:01:09.220582 EDT | Epoch                     56
2017-07-02 16:01:09.220824 EDT | Iteration                 56
2017-07-02 16:01:09.221003 EDT | AverageReturn            263.813
2017-07-02 16:01:09.221119 EDT | StdReturn                305.513
2017-07-02 16:01:09.221230 EDT | MaxReturn                980.18
2017-07-02 16:01:09.221424 EDT | MinReturn                -14.1361
2017-07-02 16:01:09.221735 EDT | AverageEsReturn           70.4609
2017-07-02 16:01:09.221890 EDT | StdEsReturn               64.8967
2017-07-02 16:01:09.222027 EDT | MaxEsReturn              203.733
2017-07-02 16:01:09.222160 EDT | MinEsReturn              -10.7541
2017-07-02 16:01:09.222336 EDT | AverageDiscountedReturn   71.4234
2017-07-02 16:01:09.222483 EDT | AverageQLoss               0.0252214
2017-07-02 16:01:09.222624 EDT | AveragePolicySurr         -2.40068
2017-07-02 16:01:09.222778 EDT | AverageQ                   2.27477
2017-07-02 16:01:09.222918 EDT | AverageAbsQ                2.2788
2017-07-02 16:01:09.223107 EDT | AverageY                   2.27543
2017-07-02 16:01:09.223313 EDT | AverageAbsY                2.27791
2017-07-02 16:01:09.223447 EDT | AverageAbsQYDiff           0.0799906
2017-07-02 16:01:09.223563 EDT | AverageAction              0.903075
2017-07-02 16:01:09.223688 EDT | PolicyRegParamNorm        29.5971
2017-07-02 16:01:09.223910 EDT | QFunRegParamNorm          26.7616
2017-07-02 16:01:09.224134 EDT | -----------------------  -----------
2017-07-02 16:01:09.224346 EDT | [reproducibility_ML/DDPG/Walker/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #57 | Training started
2017-07-02 16:01:19.373375 EDT | [reproducibility_ML/DDPG/Walker/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #57 | Training finished
2017-07-02 16:01:19.374238 EDT | [reproducibility_ML/DDPG/Walker/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #57 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 16:01:19.374483 EDT | [reproducibility_ML/DDPG/Walker/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #57 | Collecting samples for evaluation
2017-07-02 16:01:29.223916 EDT | -----------------------  -----------
2017-07-02 16:01:29.224148 EDT | Epoch                     57
2017-07-02 16:01:29.224373 EDT | Iteration                 57
2017-07-02 16:01:29.224583 EDT | AverageReturn            368.045
2017-07-02 16:01:29.224720 EDT | StdReturn                345.459
2017-07-02 16:01:29.224838 EDT | MaxReturn                957.299
2017-07-02 16:01:29.225038 EDT | MinReturn                 20.999
2017-07-02 16:01:29.225254 EDT | AverageEsReturn           74.5293
2017-07-02 16:01:29.225446 EDT | StdEsReturn               82.4541
2017-07-02 16:01:29.225700 EDT | MaxEsReturn              240.996
2017-07-02 16:01:29.225958 EDT | MinEsReturn                1.87543
2017-07-02 16:01:29.226245 EDT | AverageDiscountedReturn   87.847
2017-07-02 16:01:29.226387 EDT | AverageQLoss               0.0276301
2017-07-02 16:01:29.226520 EDT | AveragePolicySurr         -2.42803
2017-07-02 16:01:29.226673 EDT | AverageQ                   2.2975
2017-07-02 16:01:29.226806 EDT | AverageAbsQ                2.30184
2017-07-02 16:01:29.226931 EDT | AverageY                   2.29799
2017-07-02 16:01:29.227071 EDT | AverageAbsY                2.3008
2017-07-02 16:01:29.227194 EDT | AverageAbsQYDiff           0.0820719
2017-07-02 16:01:29.227337 EDT | AverageAction              0.889144
2017-07-02 16:01:29.227475 EDT | PolicyRegParamNorm        29.8607
2017-07-02 16:01:29.227606 EDT | QFunRegParamNorm          27.0468
2017-07-02 16:01:29.227736 EDT | -----------------------  -----------
2017-07-02 16:01:29.227940 EDT | [reproducibility_ML/DDPG/Walker/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #58 | Training started
2017-07-02 16:01:39.381935 EDT | [reproducibility_ML/DDPG/Walker/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #58 | Training finished
2017-07-02 16:01:39.382487 EDT | [reproducibility_ML/DDPG/Walker/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #58 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 16:01:39.382766 EDT | [reproducibility_ML/DDPG/Walker/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #58 | Collecting samples for evaluation
2017-07-02 16:01:47.871665 EDT | -----------------------  ------------
2017-07-02 16:01:47.872152 EDT | Epoch                      58
2017-07-02 16:01:47.872414 EDT | Iteration                  58
2017-07-02 16:01:47.872654 EDT | AverageReturn              94.9305
2017-07-02 16:01:47.872890 EDT | StdReturn                  82.8586
2017-07-02 16:01:47.873081 EDT | MaxReturn                 344.482
2017-07-02 16:01:47.873317 EDT | MinReturn                -120.205
2017-07-02 16:01:47.873439 EDT | AverageEsReturn            77.8191
2017-07-02 16:01:47.873630 EDT | StdEsReturn                79.2913
2017-07-02 16:01:47.873836 EDT | MaxEsReturn               235.93
2017-07-02 16:01:47.874021 EDT | MinEsReturn                -8.5523
2017-07-02 16:01:47.874253 EDT | AverageDiscountedReturn    53.0184
2017-07-02 16:01:47.874472 EDT | AverageQLoss                0.0251783
2017-07-02 16:01:47.874720 EDT | AveragePolicySurr          -2.43988
2017-07-02 16:01:47.874938 EDT | AverageQ                    2.31064
2017-07-02 16:01:47.875131 EDT | AverageAbsQ                 2.31478
2017-07-02 16:01:47.875358 EDT | AverageY                    2.31121
2017-07-02 16:01:47.875608 EDT | AverageAbsY                 2.31358
2017-07-02 16:01:47.875845 EDT | AverageAbsQYDiff            0.0823666
2017-07-02 16:01:47.876081 EDT | AverageAction               0.954699
2017-07-02 16:01:47.876311 EDT | PolicyRegParamNorm         30.1026
2017-07-02 16:01:47.876501 EDT | QFunRegParamNorm           27.3594
2017-07-02 16:01:47.876706 EDT | -----------------------  ------------
2017-07-02 16:01:47.877040 EDT | [reproducibility_ML/DDPG/Walker/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #59 | Training started
2017-07-02 16:01:57.931019 EDT | [reproducibility_ML/DDPG/Walker/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #59 | Training finished
2017-07-02 16:01:57.931242 EDT | [reproducibility_ML/DDPG/Walker/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #59 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 16:01:57.931485 EDT | [reproducibility_ML/DDPG/Walker/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #59 | Collecting samples for evaluation
