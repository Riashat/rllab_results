2017-07-02 12:28:18.591564 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] observation space: Box(4,)
2017-07-02 12:28:18.591826 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] action space: Box(1,)
2017-07-02 12:28:18.718893 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] Populating workers...
2017-07-02 12:28:18.719131 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] Populated
2017-07-02 12:28:19.452169 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #0 | Training started
2017-07-02 12:28:20.151899 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #0 | Training finished
2017-07-02 12:28:20.152066 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #0 | Trained qf 0 steps, policy 0 steps
2017-07-02 12:28:20.152203 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #1 | Training started
2017-07-02 12:28:20.874929 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #1 | Training finished
2017-07-02 12:28:20.875429 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #1 | Trained qf 0 steps, policy 0 steps
2017-07-02 12:28:20.875678 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #2 | Training started
2017-07-02 12:28:21.572181 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #2 | Training finished
2017-07-02 12:28:21.572352 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #2 | Trained qf 0 steps, policy 0 steps
2017-07-02 12:28:21.572608 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #3 | Training started
2017-07-02 12:28:22.313166 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #3 | Training finished
2017-07-02 12:28:22.313455 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #3 | Trained qf 0 steps, policy 0 steps
2017-07-02 12:28:22.313718 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #4 | Training started
2017-07-02 12:28:23.037790 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #4 | Training finished
2017-07-02 12:28:23.038095 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #4 | Trained qf 0 steps, policy 0 steps
2017-07-02 12:28:23.038242 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #5 | Training started
2017-07-02 12:28:23.760143 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #5 | Training finished
2017-07-02 12:28:23.760450 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #5 | Trained qf 0 steps, policy 0 steps
2017-07-02 12:28:23.760681 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #6 | Training started
2017-07-02 12:28:24.502674 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #6 | Training finished
2017-07-02 12:28:24.502944 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #6 | Trained qf 0 steps, policy 0 steps
2017-07-02 12:28:24.503133 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #7 | Training started
2017-07-02 12:28:25.277959 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #7 | Training finished
2017-07-02 12:28:25.278243 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #7 | Trained qf 0 steps, policy 0 steps
2017-07-02 12:28:25.278436 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #8 | Training started
2017-07-02 12:28:26.005260 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #8 | Training finished
2017-07-02 12:28:26.005559 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #8 | Trained qf 0 steps, policy 0 steps
2017-07-02 12:28:26.005818 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #9 | Training started
2017-07-02 12:28:26.828223 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #9 | Training finished
2017-07-02 12:28:26.828426 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #9 | Trained qf 1 steps, policy 1 steps
2017-07-02 12:28:26.828582 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #9 | Collecting samples for evaluation
2017-07-02 12:28:33.338768 EDT | -----------------------  -----------
2017-07-02 12:28:33.339359 EDT | Epoch                     9
2017-07-02 12:28:33.339606 EDT | Iteration                 9
2017-07-02 12:28:33.339840 EDT | AverageReturn            11.9261
2017-07-02 12:28:33.340069 EDT | StdReturn                 0.829592
2017-07-02 12:28:33.340281 EDT | MaxReturn                14
2017-07-02 12:28:33.340518 EDT | MinReturn                11
2017-07-02 12:28:33.340731 EDT | AverageEsReturn           5.12615
2017-07-02 12:28:33.340937 EDT | StdEsReturn               2.20709
2017-07-02 12:28:33.341168 EDT | MaxEsReturn              22
2017-07-02 12:28:33.341381 EDT | MinEsReturn               3
2017-07-02 12:28:33.341639 EDT | AverageDiscountedReturn  11.2926
2017-07-02 12:28:33.341850 EDT | AverageQLoss              0.00836065
2017-07-02 12:28:33.342078 EDT | AveragePolicySurr        -0.00298938
2017-07-02 12:28:33.342290 EDT | AverageQ                 -0.0217179
2017-07-02 12:28:33.342524 EDT | AverageAbsQ               0.0245312
2017-07-02 12:28:33.342729 EDT | AverageY                 -0.0118877
2017-07-02 12:28:33.342857 EDT | AverageAbsY               0.0552279
2017-07-02 12:28:33.342968 EDT | AverageAbsQYDiff          0.0632452
2017-07-02 12:28:33.343131 EDT | AverageAction             0.00399111
2017-07-02 12:28:33.343241 EDT | PolicyRegParamNorm       10.4335
2017-07-02 12:28:33.343342 EDT | QFunRegParamNorm         10.5002
2017-07-02 12:28:33.343442 EDT | -----------------------  -----------
2017-07-02 12:28:33.343727 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #10 | Training started
2017-07-02 12:28:42.953773 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #10 | Training finished
2017-07-02 12:28:42.954011 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #10 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 12:28:42.954131 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #10 | Collecting samples for evaluation
2017-07-02 12:28:51.330170 EDT | -----------------------  ------------
2017-07-02 12:28:51.330433 EDT | Epoch                    10
2017-07-02 12:28:51.330664 EDT | Iteration                10
2017-07-02 12:28:51.330870 EDT | AverageReturn             2.38095
2017-07-02 12:28:51.331102 EDT | StdReturn                 0.485621
2017-07-02 12:28:51.331324 EDT | MaxReturn                 3
2017-07-02 12:28:51.331543 EDT | MinReturn                 2
2017-07-02 12:28:51.331711 EDT | AverageEsReturn           2.83853
2017-07-02 12:28:51.331940 EDT | StdEsReturn               0.740943
2017-07-02 12:28:51.332110 EDT | MaxEsReturn              11
2017-07-02 12:28:51.332332 EDT | MinEsReturn               2
2017-07-02 12:28:51.332550 EDT | AverageDiscountedReturn   2.36337
2017-07-02 12:28:51.332775 EDT | AverageQLoss              0.000791829
2017-07-02 12:28:51.332924 EDT | AveragePolicySurr        -0.0738366
2017-07-02 12:28:51.333148 EDT | AverageQ                  0.0242053
2017-07-02 12:28:51.333276 EDT | AverageAbsQ               0.0403645
2017-07-02 12:28:51.333509 EDT | AverageY                  0.0242719
2017-07-02 12:28:51.333725 EDT | AverageAbsY               0.0392525
2017-07-02 12:28:51.333837 EDT | AverageAbsQYDiff          0.0152137
2017-07-02 12:28:51.333939 EDT | AverageAction             0.999973
2017-07-02 12:28:51.334078 EDT | PolicyRegParamNorm       11.2939
2017-07-02 12:28:51.334295 EDT | QFunRegParamNorm         10.755
2017-07-02 12:28:51.334485 EDT | -----------------------  ------------
2017-07-02 12:28:51.334777 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #11 | Training started
2017-07-02 12:29:01.096793 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #11 | Training finished
2017-07-02 12:29:01.097332 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #11 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 12:29:01.097554 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #11 | Collecting samples for evaluation
2017-07-02 12:29:09.390770 EDT | -----------------------  ------------
2017-07-02 12:29:09.391298 EDT | Epoch                    11
2017-07-02 12:29:09.391461 EDT | Iteration                11
2017-07-02 12:29:09.391604 EDT | AverageReturn             2.37643
2017-07-02 12:29:09.391961 EDT | StdReturn                 0.484489
2017-07-02 12:29:09.392281 EDT | MaxReturn                 3
2017-07-02 12:29:09.392667 EDT | MinReturn                 2
2017-07-02 12:29:09.392893 EDT | AverageEsReturn           2.80112
2017-07-02 12:29:09.393126 EDT | StdEsReturn               0.498961
2017-07-02 12:29:09.393316 EDT | MaxEsReturn               5
2017-07-02 12:29:09.393566 EDT | MinEsReturn               2
2017-07-02 12:29:09.393768 EDT | AverageDiscountedReturn   2.35893
2017-07-02 12:29:09.393949 EDT | AverageQLoss              0.000458669
2017-07-02 12:29:09.394179 EDT | AveragePolicySurr        -0.0987653
2017-07-02 12:29:09.394393 EDT | AverageQ                  0.0594769
2017-07-02 12:29:09.394622 EDT | AverageAbsQ               0.060938
2017-07-02 12:29:09.394846 EDT | AverageY                  0.0594161
2017-07-02 12:29:09.394995 EDT | AverageAbsY               0.0594161
2017-07-02 12:29:09.395227 EDT | AverageAbsQYDiff          0.0110953
2017-07-02 12:29:09.395442 EDT | AverageAction             0.999997
2017-07-02 12:29:09.395664 EDT | PolicyRegParamNorm       11.4327
2017-07-02 12:29:09.395891 EDT | QFunRegParamNorm         10.8882
2017-07-02 12:29:09.396080 EDT | -----------------------  ------------
2017-07-02 12:29:09.396419 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #12 | Training started
2017-07-02 12:29:19.298213 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #12 | Training finished
2017-07-02 12:29:19.298456 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #12 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 12:29:19.298622 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #12 | Collecting samples for evaluation
2017-07-02 12:29:27.321978 EDT | -----------------------  ------------
2017-07-02 12:29:27.322557 EDT | Epoch                    12
2017-07-02 12:29:27.322736 EDT | Iteration                12
2017-07-02 12:29:27.322853 EDT | AverageReturn             2.39234
2017-07-02 12:29:27.322995 EDT | StdReturn                 0.488273
2017-07-02 12:29:27.323134 EDT | MaxReturn                 3
2017-07-02 12:29:27.323282 EDT | MinReturn                 2
2017-07-02 12:29:27.323387 EDT | AverageEsReturn           2.80392
2017-07-02 12:29:27.323489 EDT | StdEsReturn               0.594735
2017-07-02 12:29:27.323589 EDT | MaxEsReturn               7
2017-07-02 12:29:27.323759 EDT | MinEsReturn               2
2017-07-02 12:29:27.323956 EDT | AverageDiscountedReturn   2.37454
2017-07-02 12:29:27.324082 EDT | AverageQLoss              6.83662e-05
2017-07-02 12:29:27.324187 EDT | AveragePolicySurr        -0.060654
2017-07-02 12:29:27.324355 EDT | AverageQ                  0.0541505
2017-07-02 12:29:27.324457 EDT | AverageAbsQ               0.0545083
2017-07-02 12:29:27.324557 EDT | AverageY                  0.0541349
2017-07-02 12:29:27.324721 EDT | AverageAbsY               0.0541349
2017-07-02 12:29:27.324887 EDT | AverageAbsQYDiff          0.00530849
2017-07-02 12:29:27.324989 EDT | AverageAction             0.999994
2017-07-02 12:29:27.325089 EDT | PolicyRegParamNorm       11.3887
2017-07-02 12:29:27.325188 EDT | QFunRegParamNorm         11.05
2017-07-02 12:29:27.325321 EDT | -----------------------  ------------
2017-07-02 12:29:27.325605 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #13 | Training started
2017-07-02 12:29:37.168241 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #13 | Training finished
2017-07-02 12:29:37.168747 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #13 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 12:29:37.169011 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #13 | Collecting samples for evaluation
2017-07-02 12:29:44.612603 EDT | -----------------------  ------------
2017-07-02 12:29:44.612787 EDT | Epoch                    13
2017-07-02 12:29:44.612919 EDT | Iteration                13
2017-07-02 12:29:44.613028 EDT | AverageReturn             4.26621
2017-07-02 12:29:44.613131 EDT | StdReturn                 0.441976
2017-07-02 12:29:44.613234 EDT | MaxReturn                 5
2017-07-02 12:29:44.613396 EDT | MinReturn                 4
2017-07-02 12:29:44.613518 EDT | AverageEsReturn           3.44828
2017-07-02 12:29:44.613659 EDT | StdEsReturn               2.31168
2017-07-02 12:29:44.613762 EDT | MaxEsReturn              23
2017-07-02 12:29:44.613888 EDT | MinEsReturn               2
2017-07-02 12:29:44.613998 EDT | AverageDiscountedReturn   4.19612
2017-07-02 12:29:44.614176 EDT | AverageQLoss              4.11146e-05
2017-07-02 12:29:44.614366 EDT | AveragePolicySurr        -0.0545625
2017-07-02 12:29:44.614512 EDT | AverageQ                  0.0488911
2017-07-02 12:29:44.614614 EDT | AverageAbsQ               0.0490031
2017-07-02 12:29:44.614739 EDT | AverageY                  0.0488878
2017-07-02 12:29:44.614840 EDT | AverageAbsY               0.0488878
2017-07-02 12:29:44.614961 EDT | AverageAbsQYDiff          0.00415375
2017-07-02 12:29:44.615064 EDT | AverageAction             0.883323
2017-07-02 12:29:44.615166 EDT | PolicyRegParamNorm       11.8783
2017-07-02 12:29:44.615267 EDT | QFunRegParamNorm         11.2953
2017-07-02 12:29:44.615367 EDT | -----------------------  ------------
2017-07-02 12:29:44.615530 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #14 | Training started
2017-07-02 12:29:54.266306 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #14 | Training finished
2017-07-02 12:29:54.266865 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #14 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 12:29:54.267165 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #14 | Collecting samples for evaluation
2017-07-02 12:30:00.209135 EDT | -----------------------  ------------
2017-07-02 12:30:00.209751 EDT | Epoch                    14
2017-07-02 12:30:00.209997 EDT | Iteration                14
2017-07-02 12:30:00.210223 EDT | AverageReturn            29.9284
2017-07-02 12:30:00.210449 EDT | StdReturn                 0.792277
2017-07-02 12:30:00.210669 EDT | MaxReturn                32
2017-07-02 12:30:00.210876 EDT | MinReturn                29
2017-07-02 12:30:00.211098 EDT | AverageEsReturn          15.5625
2017-07-02 12:30:00.211221 EDT | StdEsReturn              14.1641
2017-07-02 12:30:00.211402 EDT | MaxEsReturn              91
2017-07-02 12:30:00.211518 EDT | MinEsReturn               3
2017-07-02 12:30:00.211742 EDT | AverageDiscountedReturn  25.9743
2017-07-02 12:30:00.211965 EDT | AverageQLoss              7.74431e-05
2017-07-02 12:30:00.212143 EDT | AveragePolicySurr        -0.0798724
2017-07-02 12:30:00.212352 EDT | AverageQ                  0.0562022
2017-07-02 12:30:00.212580 EDT | AverageAbsQ               0.0564921
2017-07-02 12:30:00.212794 EDT | AverageY                  0.0562168
2017-07-02 12:30:00.213023 EDT | AverageAbsY               0.0562173
2017-07-02 12:30:00.213248 EDT | AverageAbsQYDiff          0.0058189
2017-07-02 12:30:00.213470 EDT | AverageAction             0.760984
2017-07-02 12:30:00.213697 EDT | PolicyRegParamNorm       14.0178
2017-07-02 12:30:00.213873 EDT | QFunRegParamNorm         11.5299
2017-07-02 12:30:00.214094 EDT | -----------------------  ------------
2017-07-02 12:30:00.214396 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #15 | Training started
2017-07-02 12:30:09.820732 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #15 | Training finished
2017-07-02 12:30:09.821319 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #15 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 12:30:09.821591 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #15 | Collecting samples for evaluation
2017-07-02 12:30:15.764975 EDT | -----------------------  ------------
2017-07-02 12:30:15.765155 EDT | Epoch                    15
2017-07-02 12:30:15.765270 EDT | Iteration                15
2017-07-02 12:30:15.765390 EDT | AverageReturn            44.808
2017-07-02 12:30:15.765580 EDT | StdReturn                 1.01495
2017-07-02 12:30:15.765752 EDT | MaxReturn                47
2017-07-02 12:30:15.765935 EDT | MinReturn                43
2017-07-02 12:30:15.766103 EDT | AverageEsReturn          23.6429
2017-07-02 12:30:15.766278 EDT | StdEsReturn              14.0557
2017-07-02 12:30:15.766451 EDT | MaxEsReturn              56
2017-07-02 12:30:15.766614 EDT | MinEsReturn               3
2017-07-02 12:30:15.766794 EDT | AverageDiscountedReturn  36.2553
2017-07-02 12:30:15.766897 EDT | AverageQLoss              6.03577e-05
2017-07-02 12:30:15.766999 EDT | AveragePolicySurr        -0.0923081
2017-07-02 12:30:15.767132 EDT | AverageQ                  0.0677381
2017-07-02 12:30:15.767248 EDT | AverageAbsQ               0.067847
2017-07-02 12:30:15.767375 EDT | AverageY                  0.0677355
2017-07-02 12:30:15.767490 EDT | AverageAbsY               0.0677355
2017-07-02 12:30:15.767630 EDT | AverageAbsQYDiff          0.00515315
2017-07-02 12:30:15.767733 EDT | AverageAction             0.0439798
2017-07-02 12:30:15.767853 EDT | PolicyRegParamNorm       15.4696
2017-07-02 12:30:15.767956 EDT | QFunRegParamNorm         11.7939
2017-07-02 12:30:15.768056 EDT | -----------------------  ------------
2017-07-02 12:30:15.768219 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #16 | Training started
2017-07-02 12:30:25.908188 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #16 | Training finished
2017-07-02 12:30:25.908398 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #16 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 12:30:25.908577 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #16 | Collecting samples for evaluation
2017-07-02 12:30:31.790246 EDT | -----------------------  ------------
2017-07-02 12:30:31.790825 EDT | Epoch                    16
2017-07-02 12:30:31.791068 EDT | Iteration                16
2017-07-02 12:30:31.791304 EDT | AverageReturn            63.9172
2017-07-02 12:30:31.791532 EDT | StdReturn                 0.916667
2017-07-02 12:30:31.791756 EDT | MaxReturn                66
2017-07-02 12:30:31.791995 EDT | MinReturn                62
2017-07-02 12:30:31.792222 EDT | AverageEsReturn          26.973
2017-07-02 12:30:31.792437 EDT | StdEsReturn              16.3715
2017-07-02 12:30:31.792665 EDT | MaxEsReturn              55
2017-07-02 12:30:31.792884 EDT | MinEsReturn               4
2017-07-02 12:30:31.793114 EDT | AverageDiscountedReturn  47.3944
2017-07-02 12:30:31.793349 EDT | AverageQLoss              6.48304e-05
2017-07-02 12:30:31.793589 EDT | AveragePolicySurr        -0.100462
2017-07-02 12:30:31.793817 EDT | AverageQ                  0.0760463
2017-07-02 12:30:31.793974 EDT | AverageAbsQ               0.0761925
2017-07-02 12:30:31.794200 EDT | AverageY                  0.0760468
2017-07-02 12:30:31.794405 EDT | AverageAbsY               0.0760468
2017-07-02 12:30:31.794619 EDT | AverageAbsQYDiff          0.00520429
2017-07-02 12:30:31.794845 EDT | AverageAction             0.378517
2017-07-02 12:30:31.794977 EDT | PolicyRegParamNorm       16.4018
2017-07-02 12:30:31.795163 EDT | QFunRegParamNorm         12.1043
2017-07-02 12:30:31.795370 EDT | -----------------------  ------------
2017-07-02 12:30:31.795676 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #17 | Training started
2017-07-02 12:30:41.265750 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #17 | Training finished
2017-07-02 12:30:41.266390 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #17 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 12:30:41.266596 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #17 | Collecting samples for evaluation
2017-07-02 12:30:47.145295 EDT | -----------------------  ------------
2017-07-02 12:30:47.145535 EDT | Epoch                    17
2017-07-02 12:30:47.145690 EDT | Iteration                17
2017-07-02 12:30:47.145872 EDT | AverageReturn            50.934
2017-07-02 12:30:47.146068 EDT | StdReturn                 2.07981
2017-07-02 12:30:47.146235 EDT | MaxReturn                57
2017-07-02 12:30:47.146408 EDT | MinReturn                45
2017-07-02 12:30:47.146567 EDT | AverageEsReturn          20.9375
2017-07-02 12:30:47.146677 EDT | StdEsReturn              16.8008
2017-07-02 12:30:47.146802 EDT | MaxEsReturn              60
2017-07-02 12:30:47.146904 EDT | MinEsReturn               3
2017-07-02 12:30:47.147022 EDT | AverageDiscountedReturn  40.0516
2017-07-02 12:30:47.147123 EDT | AverageQLoss              7.12172e-05
2017-07-02 12:30:47.147241 EDT | AveragePolicySurr        -0.110294
2017-07-02 12:30:47.147342 EDT | AverageQ                  0.0857696
2017-07-02 12:30:47.147443 EDT | AverageAbsQ               0.0859127
2017-07-02 12:30:47.147543 EDT | AverageY                  0.0857775
2017-07-02 12:30:47.147681 EDT | AverageAbsY               0.0857775
2017-07-02 12:30:47.147791 EDT | AverageAbsQYDiff          0.00516405
2017-07-02 12:30:47.147893 EDT | AverageAction             0.446933
2017-07-02 12:30:47.147993 EDT | PolicyRegParamNorm       16.9543
2017-07-02 12:30:47.148092 EDT | QFunRegParamNorm         12.4593
2017-07-02 12:30:47.148190 EDT | -----------------------  ------------
2017-07-02 12:30:47.148350 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #18 | Training started
2017-07-02 12:30:56.648680 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #18 | Training finished
2017-07-02 12:30:56.648936 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #18 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 12:30:56.649179 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #18 | Collecting samples for evaluation
2017-07-02 12:31:02.472592 EDT | -----------------------  ------------
2017-07-02 12:31:02.473103 EDT | Epoch                    18
2017-07-02 12:31:02.473231 EDT | Iteration                18
2017-07-02 12:31:02.473371 EDT | AverageReturn            53.957
2017-07-02 12:31:02.473598 EDT | StdReturn                 1.70964
2017-07-02 12:31:02.473880 EDT | MaxReturn                58
2017-07-02 12:31:02.474053 EDT | MinReturn                50
2017-07-02 12:31:02.474185 EDT | AverageEsReturn          30.1212
2017-07-02 12:31:02.474307 EDT | StdEsReturn              17.1248
2017-07-02 12:31:02.474422 EDT | MaxEsReturn              67
2017-07-02 12:31:02.474551 EDT | MinEsReturn               5
2017-07-02 12:31:02.474668 EDT | AverageDiscountedReturn  41.8496
2017-07-02 12:31:02.474802 EDT | AverageQLoss              7.42999e-05
2017-07-02 12:31:02.474919 EDT | AveragePolicySurr        -0.1214
2017-07-02 12:31:02.475048 EDT | AverageQ                  0.0950877
2017-07-02 12:31:02.475166 EDT | AverageAbsQ               0.0952236
2017-07-02 12:31:02.475308 EDT | AverageY                  0.0951078
2017-07-02 12:31:02.475412 EDT | AverageAbsY               0.0951159
2017-07-02 12:31:02.475527 EDT | AverageAbsQYDiff          0.00519587
2017-07-02 12:31:02.475664 EDT | AverageAction             0.155978
2017-07-02 12:31:02.475803 EDT | PolicyRegParamNorm       17.3883
2017-07-02 12:31:02.475946 EDT | QFunRegParamNorm         12.8554
2017-07-02 12:31:02.476073 EDT | -----------------------  ------------
2017-07-02 12:31:02.476364 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #19 | Training started
2017-07-02 12:31:12.122866 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #19 | Training finished
2017-07-02 12:31:12.123494 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #19 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 12:31:12.123727 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #19 | Collecting samples for evaluation
2017-07-02 12:31:17.896223 EDT | -----------------------  ------------
2017-07-02 12:31:17.896543 EDT | Epoch                    19
2017-07-02 12:31:17.896774 EDT | Iteration                19
2017-07-02 12:31:17.896954 EDT | AverageReturn            57.7356
2017-07-02 12:31:17.897183 EDT | StdReturn                 1.7351
2017-07-02 12:31:17.897342 EDT | MaxReturn                63
2017-07-02 12:31:17.897458 EDT | MinReturn                54
2017-07-02 12:31:17.897609 EDT | AverageEsReturn          20.6122
2017-07-02 12:31:17.897733 EDT | StdEsReturn              14.2411
2017-07-02 12:31:17.897843 EDT | MaxEsReturn              56
2017-07-02 12:31:17.897949 EDT | MinEsReturn               3
2017-07-02 12:31:17.898055 EDT | AverageDiscountedReturn  44.0164
2017-07-02 12:31:17.898235 EDT | AverageQLoss              9.01243e-05
2017-07-02 12:31:17.898452 EDT | AveragePolicySurr        -0.132925
2017-07-02 12:31:17.898574 EDT | AverageQ                  0.105864
2017-07-02 12:31:17.898774 EDT | AverageAbsQ               0.106038
2017-07-02 12:31:17.898998 EDT | AverageY                  0.105867
2017-07-02 12:31:17.899174 EDT | AverageAbsY               0.105877
2017-07-02 12:31:17.899413 EDT | AverageAbsQYDiff          0.00570632
2017-07-02 12:31:17.899640 EDT | AverageAction             0.252232
2017-07-02 12:31:17.899875 EDT | PolicyRegParamNorm       17.9004
2017-07-02 12:31:17.900098 EDT | QFunRegParamNorm         13.2681
2017-07-02 12:31:17.900283 EDT | -----------------------  ------------
2017-07-02 12:31:17.900599 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #20 | Training started
2017-07-02 12:31:27.613719 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #20 | Training finished
2017-07-02 12:31:27.613914 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #20 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 12:31:27.614099 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #20 | Collecting samples for evaluation
2017-07-02 12:31:33.364835 EDT | -----------------------  -----------
2017-07-02 12:31:33.365366 EDT | Epoch                    20
2017-07-02 12:31:33.365624 EDT | Iteration                20
2017-07-02 12:31:33.365739 EDT | AverageReturn            77.0231
2017-07-02 12:31:33.365846 EDT | StdReturn                 5.63706
2017-07-02 12:31:33.365950 EDT | MaxReturn                95
2017-07-02 12:31:33.366051 EDT | MinReturn                65
2017-07-02 12:31:33.366157 EDT | AverageEsReturn          26.0526
2017-07-02 12:31:33.366282 EDT | StdEsReturn              18.7854
2017-07-02 12:31:33.366408 EDT | MaxEsReturn              68
2017-07-02 12:31:33.366514 EDT | MinEsReturn               3
2017-07-02 12:31:33.366619 EDT | AverageDiscountedReturn  53.815
2017-07-02 12:31:33.366730 EDT | AverageQLoss              0.00010655
2017-07-02 12:31:33.366872 EDT | AveragePolicySurr        -0.14359
2017-07-02 12:31:33.366978 EDT | AverageQ                  0.116033
2017-07-02 12:31:33.367084 EDT | AverageAbsQ               0.116247
2017-07-02 12:31:33.367190 EDT | AverageY                  0.116046
2017-07-02 12:31:33.367339 EDT | AverageAbsY               0.11605
2017-07-02 12:31:33.367446 EDT | AverageAbsQYDiff          0.00610284
2017-07-02 12:31:33.367551 EDT | AverageAction             0.55341
2017-07-02 12:31:33.367655 EDT | PolicyRegParamNorm       18.5606
2017-07-02 12:31:33.367759 EDT | QFunRegParamNorm         13.6932
2017-07-02 12:31:33.367882 EDT | -----------------------  -----------
2017-07-02 12:31:33.368052 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #21 | Training started
2017-07-02 12:31:43.076519 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #21 | Training finished
2017-07-02 12:31:43.077074 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #21 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 12:31:43.077208 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #21 | Collecting samples for evaluation
2017-07-02 12:31:48.839002 EDT | -----------------------  -----------
2017-07-02 12:31:48.839309 EDT | Epoch                    21
2017-07-02 12:31:48.839646 EDT | Iteration                21
2017-07-02 12:31:48.839838 EDT | AverageReturn            60.5361
2017-07-02 12:31:48.839948 EDT | StdReturn                 1.51157
2017-07-02 12:31:48.840052 EDT | MaxReturn                64
2017-07-02 12:31:48.840153 EDT | MinReturn                57
2017-07-02 12:31:48.840254 EDT | AverageEsReturn          20.8333
2017-07-02 12:31:48.840401 EDT | StdEsReturn              16.0745
2017-07-02 12:31:48.840539 EDT | MaxEsReturn              66
2017-07-02 12:31:48.840663 EDT | MinEsReturn               3
2017-07-02 12:31:48.840772 EDT | AverageDiscountedReturn  45.5721
2017-07-02 12:31:48.840883 EDT | AverageQLoss              0.00011532
2017-07-02 12:31:48.841012 EDT | AveragePolicySurr        -0.152333
2017-07-02 12:31:48.841139 EDT | AverageQ                  0.124889
2017-07-02 12:31:48.841265 EDT | AverageAbsQ               0.12506
2017-07-02 12:31:48.841391 EDT | AverageY                  0.124906
2017-07-02 12:31:48.841553 EDT | AverageAbsY               0.124907
2017-07-02 12:31:48.841673 EDT | AverageAbsQYDiff          0.00607713
2017-07-02 12:31:48.841782 EDT | AverageAction             0.504975
2017-07-02 12:31:48.841889 EDT | PolicyRegParamNorm       18.9345
2017-07-02 12:31:48.841995 EDT | QFunRegParamNorm         14.0682
2017-07-02 12:31:48.842101 EDT | -----------------------  -----------
2017-07-02 12:31:48.842269 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #22 | Training started
2017-07-02 12:31:58.493116 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #22 | Training finished
2017-07-02 12:31:58.493341 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #22 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 12:31:58.493458 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #22 | Collecting samples for evaluation
2017-07-02 12:32:04.220378 EDT | -----------------------  ------------
2017-07-02 12:32:04.220888 EDT | Epoch                    22
2017-07-02 12:32:04.221117 EDT | Iteration                22
2017-07-02 12:32:04.221257 EDT | AverageReturn            59.2012
2017-07-02 12:32:04.221394 EDT | StdReturn                 1.03535
2017-07-02 12:32:04.221584 EDT | MaxReturn                62
2017-07-02 12:32:04.221695 EDT | MinReturn                57
2017-07-02 12:32:04.221830 EDT | AverageEsReturn          19.7255
2017-07-02 12:32:04.221934 EDT | StdEsReturn              16.4889
2017-07-02 12:32:04.222037 EDT | MaxEsReturn              62
2017-07-02 12:32:04.222175 EDT | MinEsReturn               3
2017-07-02 12:32:04.222299 EDT | AverageDiscountedReturn  44.8403
2017-07-02 12:32:04.222423 EDT | AverageQLoss              0.000132912
2017-07-02 12:32:04.222554 EDT | AveragePolicySurr        -0.163003
2017-07-02 12:32:04.222674 EDT | AverageQ                  0.134628
2017-07-02 12:32:04.222793 EDT | AverageAbsQ               0.134822
2017-07-02 12:32:04.222895 EDT | AverageY                  0.13464
2017-07-02 12:32:04.222996 EDT | AverageAbsY               0.13464
2017-07-02 12:32:04.223095 EDT | AverageAbsQYDiff          0.00636718
2017-07-02 12:32:04.223268 EDT | AverageAction             0.414314
2017-07-02 12:32:04.223372 EDT | PolicyRegParamNorm       19.3587
2017-07-02 12:32:04.223536 EDT | QFunRegParamNorm         14.5226
2017-07-02 12:32:04.223674 EDT | -----------------------  ------------
2017-07-02 12:32:04.223851 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #23 | Training started
2017-07-02 12:32:13.780282 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #23 | Training finished
2017-07-02 12:32:13.780809 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #23 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 12:32:13.780944 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #23 | Collecting samples for evaluation
2017-07-02 12:32:19.628993 EDT | -----------------------  -----------
2017-07-02 12:32:19.629321 EDT | Epoch                    23
2017-07-02 12:32:19.629573 EDT | Iteration                23
2017-07-02 12:32:19.629789 EDT | AverageReturn            79.0079
2017-07-02 12:32:19.630029 EDT | StdReturn                 4.14025
2017-07-02 12:32:19.630248 EDT | MaxReturn                90
2017-07-02 12:32:19.630417 EDT | MinReturn                69
2017-07-02 12:32:19.630537 EDT | AverageEsReturn          20.5417
2017-07-02 12:32:19.630649 EDT | StdEsReturn              14.1656
2017-07-02 12:32:19.630758 EDT | MaxEsReturn              56
2017-07-02 12:32:19.630883 EDT | MinEsReturn               3
2017-07-02 12:32:19.630992 EDT | AverageDiscountedReturn  54.76
2017-07-02 12:32:19.631099 EDT | AverageQLoss              0.00014001
2017-07-02 12:32:19.631217 EDT | AveragePolicySurr        -0.173628
2017-07-02 12:32:19.631367 EDT | AverageQ                  0.143606
2017-07-02 12:32:19.631479 EDT | AverageAbsQ               0.143815
2017-07-02 12:32:19.631604 EDT | AverageY                  0.143608
2017-07-02 12:32:19.631716 EDT | AverageAbsY               0.143621
2017-07-02 12:32:19.631821 EDT | AverageAbsQYDiff          0.00637793
2017-07-02 12:32:19.631935 EDT | AverageAction             0.48441
2017-07-02 12:32:19.632042 EDT | PolicyRegParamNorm       19.7466
2017-07-02 12:32:19.632219 EDT | QFunRegParamNorm         15.0053
2017-07-02 12:32:19.632385 EDT | -----------------------  -----------
2017-07-02 12:32:19.632643 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #24 | Training started
2017-07-02 12:32:29.186607 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #24 | Training finished
2017-07-02 12:32:29.186902 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #24 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 12:32:29.187295 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #24 | Collecting samples for evaluation
2017-07-02 12:32:35.009707 EDT | -----------------------  --------------
2017-07-02 12:32:35.010286 EDT | Epoch                      24
2017-07-02 12:32:35.010487 EDT | Iteration                  24
2017-07-02 12:32:35.010689 EDT | AverageReturn             102.153
2017-07-02 12:32:35.010891 EDT | StdReturn                 208.284
2017-07-02 12:32:35.011016 EDT | MaxReturn                1000
2017-07-02 12:32:35.011121 EDT | MinReturn                  45
2017-07-02 12:32:35.011222 EDT | AverageEsReturn            24.3
2017-07-02 12:32:35.011323 EDT | StdEsReturn                18.6269
2017-07-02 12:32:35.011439 EDT | MaxEsReturn                80
2017-07-02 12:32:35.011599 EDT | MinEsReturn                 3
2017-07-02 12:32:35.011700 EDT | AverageDiscountedReturn    44.663
2017-07-02 12:32:35.011798 EDT | AverageQLoss                0.000164246
2017-07-02 12:32:35.011895 EDT | AveragePolicySurr          -0.183711
2017-07-02 12:32:35.012004 EDT | AverageQ                    0.153093
2017-07-02 12:32:35.012157 EDT | AverageAbsQ                 0.153393
2017-07-02 12:32:35.012259 EDT | AverageY                    0.153102
2017-07-02 12:32:35.012359 EDT | AverageAbsY                 0.153162
2017-07-02 12:32:35.012460 EDT | AverageAbsQYDiff            0.00685616
2017-07-02 12:32:35.012560 EDT | AverageAction               0.522325
2017-07-02 12:32:35.012659 EDT | PolicyRegParamNorm         19.984
2017-07-02 12:32:35.012758 EDT | QFunRegParamNorm           15.526
2017-07-02 12:32:35.012858 EDT | -----------------------  --------------
2017-07-02 12:32:35.013019 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #25 | Training started
2017-07-02 12:32:44.590742 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #25 | Training finished
2017-07-02 12:32:44.591290 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #25 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 12:32:44.591618 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #25 | Collecting samples for evaluation
2017-07-02 12:32:50.437473 EDT | -----------------------  ------------
2017-07-02 12:32:50.437798 EDT | Epoch                    25
2017-07-02 12:32:50.438042 EDT | Iteration                25
2017-07-02 12:32:50.438272 EDT | AverageReturn            47.8565
2017-07-02 12:32:50.438492 EDT | StdReturn                 2.42958
2017-07-02 12:32:50.438720 EDT | MaxReturn                57
2017-07-02 12:32:50.438947 EDT | MinReturn                44
2017-07-02 12:32:50.439215 EDT | AverageEsReturn          18.4074
2017-07-02 12:32:50.439389 EDT | StdEsReturn              14.9189
2017-07-02 12:32:50.439513 EDT | MaxEsReturn              66
2017-07-02 12:32:50.439642 EDT | MinEsReturn               4
2017-07-02 12:32:50.439768 EDT | AverageDiscountedReturn  38.1636
2017-07-02 12:32:50.439877 EDT | AverageQLoss              0.000179633
2017-07-02 12:32:50.439985 EDT | AveragePolicySurr        -0.192959
2017-07-02 12:32:50.440139 EDT | AverageQ                  0.16211
2017-07-02 12:32:50.440248 EDT | AverageAbsQ               0.162495
2017-07-02 12:32:50.440354 EDT | AverageY                  0.162129
2017-07-02 12:32:50.440460 EDT | AverageAbsY               0.162301
2017-07-02 12:32:50.440566 EDT | AverageAbsQYDiff          0.0071677
2017-07-02 12:32:50.440671 EDT | AverageAction             0.387115
2017-07-02 12:32:50.440776 EDT | PolicyRegParamNorm       20.2805
2017-07-02 12:32:50.440881 EDT | QFunRegParamNorm         16.0502
2017-07-02 12:32:50.441051 EDT | -----------------------  ------------
2017-07-02 12:32:50.441241 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #26 | Training started
2017-07-02 12:33:00.020607 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #26 | Training finished
2017-07-02 12:33:00.020834 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #26 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 12:33:00.021019 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #26 | Collecting samples for evaluation
2017-07-02 12:33:05.904299 EDT | -----------------------  ------------
2017-07-02 12:33:05.904781 EDT | Epoch                     26
2017-07-02 12:33:05.904995 EDT | Iteration                 26
2017-07-02 12:33:05.905163 EDT | AverageReturn             41.4711
2017-07-02 12:33:05.905354 EDT | StdReturn                  0.656492
2017-07-02 12:33:05.905519 EDT | MaxReturn                 43
2017-07-02 12:33:05.905649 EDT | MinReturn                 39
2017-07-02 12:33:05.905770 EDT | AverageEsReturn           18.7857
2017-07-02 12:33:05.905877 EDT | StdEsReturn               20.0256
2017-07-02 12:33:05.905977 EDT | MaxEsReturn              125
2017-07-02 12:33:05.906135 EDT | MinEsReturn                3
2017-07-02 12:33:05.906287 EDT | AverageDiscountedReturn   34.0832
2017-07-02 12:33:05.906406 EDT | AverageQLoss               0.00020186
2017-07-02 12:33:05.906581 EDT | AveragePolicySurr         -0.203386
2017-07-02 12:33:05.906741 EDT | AverageQ                   0.170723
2017-07-02 12:33:05.906875 EDT | AverageAbsQ                0.171285
2017-07-02 12:33:05.906980 EDT | AverageY                   0.170731
2017-07-02 12:33:05.907094 EDT | AverageAbsY                0.171095
2017-07-02 12:33:05.907194 EDT | AverageAbsQYDiff           0.00753559
2017-07-02 12:33:05.907350 EDT | AverageAction              0.415323
2017-07-02 12:33:05.907455 EDT | PolicyRegParamNorm        20.589
2017-07-02 12:33:05.907555 EDT | QFunRegParamNorm          16.4791
2017-07-02 12:33:05.907692 EDT | -----------------------  ------------
2017-07-02 12:33:05.907856 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #27 | Training started
2017-07-02 12:33:15.489013 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #27 | Training finished
2017-07-02 12:33:15.489620 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #27 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 12:33:15.489870 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #27 | Collecting samples for evaluation
2017-07-02 12:33:21.349147 EDT | -----------------------  -----------
2017-07-02 12:33:21.349330 EDT | Epoch                    27
2017-07-02 12:33:21.349484 EDT | Iteration                27
2017-07-02 12:33:21.349635 EDT | AverageReturn            39.1328
2017-07-02 12:33:21.349753 EDT | StdReturn                 0.402552
2017-07-02 12:33:21.349896 EDT | MaxReturn                40
2017-07-02 12:33:21.350004 EDT | MinReturn                38
2017-07-02 12:33:21.350103 EDT | AverageEsReturn          16.4
2017-07-02 12:33:21.350201 EDT | StdEsReturn              14.5685
2017-07-02 12:33:21.350347 EDT | MaxEsReturn              61
2017-07-02 12:33:21.350484 EDT | MinEsReturn               3
2017-07-02 12:33:21.350668 EDT | AverageDiscountedReturn  32.5167
2017-07-02 12:33:21.350811 EDT | AverageQLoss              0.00021353
2017-07-02 12:33:21.350924 EDT | AveragePolicySurr        -0.215027
2017-07-02 12:33:21.351047 EDT | AverageQ                  0.180401
2017-07-02 12:33:21.351145 EDT | AverageAbsQ               0.180876
2017-07-02 12:33:21.351252 EDT | AverageY                  0.180421
2017-07-02 12:33:21.351362 EDT | AverageAbsY               0.18066
2017-07-02 12:33:21.351487 EDT | AverageAbsQYDiff          0.00761107
2017-07-02 12:33:21.351624 EDT | AverageAction             0.295915
2017-07-02 12:33:21.351724 EDT | PolicyRegParamNorm       20.8814
2017-07-02 12:33:21.351823 EDT | QFunRegParamNorm         16.9726
2017-07-02 12:33:21.351960 EDT | -----------------------  -----------
2017-07-02 12:33:21.352160 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #28 | Training started
2017-07-02 12:33:30.952663 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #28 | Training finished
2017-07-02 12:33:30.952926 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #28 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 12:33:30.953254 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #28 | Collecting samples for evaluation
2017-07-02 12:33:36.830305 EDT | -----------------------  ------------
2017-07-02 12:33:36.830876 EDT | Epoch                    28
2017-07-02 12:33:36.831106 EDT | Iteration                28
2017-07-02 12:33:36.831338 EDT | AverageReturn            38.6178
2017-07-02 12:33:36.831459 EDT | StdReturn                 0.763952
2017-07-02 12:33:36.831571 EDT | MaxReturn                40
2017-07-02 12:33:36.831677 EDT | MinReturn                37
2017-07-02 12:33:36.831780 EDT | AverageEsReturn          16.3443
2017-07-02 12:33:36.831882 EDT | StdEsReturn              12.9816
2017-07-02 12:33:36.831996 EDT | MaxEsReturn              53
2017-07-02 12:33:36.832224 EDT | MinEsReturn               3
2017-07-02 12:33:36.832454 EDT | AverageDiscountedReturn  32.165
2017-07-02 12:33:36.832664 EDT | AverageQLoss              0.000241552
2017-07-02 12:33:36.832893 EDT | AveragePolicySurr        -0.226837
2017-07-02 12:33:36.833097 EDT | AverageQ                  0.191979
2017-07-02 12:33:36.833326 EDT | AverageAbsQ               0.192415
2017-07-02 12:33:36.833909 EDT | AverageY                  0.191984
2017-07-02 12:33:36.834038 EDT | AverageAbsY               0.192178
2017-07-02 12:33:36.834145 EDT | AverageAbsQYDiff          0.00773082
2017-07-02 12:33:36.834249 EDT | AverageAction             0.429347
2017-07-02 12:33:36.834350 EDT | PolicyRegParamNorm       21.1976
2017-07-02 12:33:36.834491 EDT | QFunRegParamNorm         17.3536
2017-07-02 12:33:36.834595 EDT | -----------------------  ------------
2017-07-02 12:33:36.834755 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #29 | Training started
2017-07-02 12:33:46.434969 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #29 | Training finished
2017-07-02 12:33:46.435750 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #29 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 12:33:46.435951 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #29 | Collecting samples for evaluation
2017-07-02 12:33:52.323687 EDT | -----------------------  -----------
2017-07-02 12:33:52.324207 EDT | Epoch                    29
2017-07-02 12:33:52.324353 EDT | Iteration                29
2017-07-02 12:33:52.324582 EDT | AverageReturn            36.0252
2017-07-02 12:33:52.324800 EDT | StdReturn                 0.383208
2017-07-02 12:33:52.325025 EDT | MaxReturn                37
2017-07-02 12:33:52.325255 EDT | MinReturn                35
2017-07-02 12:33:52.325474 EDT | AverageEsReturn          21.7021
2017-07-02 12:33:52.325711 EDT | StdEsReturn              16.9215
2017-07-02 12:33:52.325921 EDT | MaxEsReturn              84
2017-07-02 12:33:52.326058 EDT | MinEsReturn               3
2017-07-02 12:33:52.326171 EDT | AverageDiscountedReturn  30.3758
2017-07-02 12:33:52.326305 EDT | AverageQLoss              0.00029381
2017-07-02 12:33:52.326477 EDT | AveragePolicySurr        -0.236766
2017-07-02 12:33:52.326695 EDT | AverageQ                  0.200462
2017-07-02 12:33:52.326877 EDT | AverageAbsQ               0.201018
2017-07-02 12:33:52.326979 EDT | AverageY                  0.200497
2017-07-02 12:33:52.327115 EDT | AverageAbsY               0.200772
2017-07-02 12:33:52.327215 EDT | AverageAbsQYDiff          0.00868487
2017-07-02 12:33:52.327387 EDT | AverageAction             0.318239
2017-07-02 12:33:52.327614 EDT | PolicyRegParamNorm       21.4715
2017-07-02 12:33:52.327833 EDT | QFunRegParamNorm         17.7751
2017-07-02 12:33:52.328050 EDT | -----------------------  -----------
2017-07-02 12:33:52.328354 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #30 | Training started
2017-07-02 12:34:02.033640 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #30 | Training finished
2017-07-02 12:34:02.034228 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #30 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 12:34:02.034365 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #30 | Collecting samples for evaluation
2017-07-02 12:34:07.853799 EDT | -----------------------  ------------
2017-07-02 12:34:07.854101 EDT | Epoch                    30
2017-07-02 12:34:07.854318 EDT | Iteration                30
2017-07-02 12:34:07.854470 EDT | AverageReturn            34.7128
2017-07-02 12:34:07.854626 EDT | StdReturn                 0.452454
2017-07-02 12:34:07.854767 EDT | MaxReturn                35
2017-07-02 12:34:07.854987 EDT | MinReturn                34
2017-07-02 12:34:07.855200 EDT | AverageEsReturn          13.7222
2017-07-02 12:34:07.855417 EDT | StdEsReturn              11.7393
2017-07-02 12:34:07.855650 EDT | MaxEsReturn              47
2017-07-02 12:34:07.855871 EDT | MinEsReturn               3
2017-07-02 12:34:07.856094 EDT | AverageDiscountedReturn  29.4512
2017-07-02 12:34:07.856306 EDT | AverageQLoss              0.000318625
2017-07-02 12:34:07.856513 EDT | AveragePolicySurr        -0.247079
2017-07-02 12:34:07.856734 EDT | AverageQ                  0.209984
2017-07-02 12:34:07.856931 EDT | AverageAbsQ               0.210535
2017-07-02 12:34:07.857147 EDT | AverageY                  0.210023
2017-07-02 12:34:07.857361 EDT | AverageAbsY               0.21028
2017-07-02 12:34:07.857638 EDT | AverageAbsQYDiff          0.0087538
2017-07-02 12:34:07.857785 EDT | AverageAction             0.188683
2017-07-02 12:34:07.858004 EDT | PolicyRegParamNorm       21.6624
2017-07-02 12:34:07.858167 EDT | QFunRegParamNorm         18.2584
2017-07-02 12:34:07.858288 EDT | -----------------------  ------------
2017-07-02 12:34:07.858467 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #31 | Training started
2017-07-02 12:34:17.725514 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #31 | Training finished
2017-07-02 12:34:17.726114 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #31 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 12:34:17.726386 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #31 | Collecting samples for evaluation
2017-07-02 12:34:23.562289 EDT | -----------------------  -----------
2017-07-02 12:34:23.562495 EDT | Epoch                    31
2017-07-02 12:34:23.562703 EDT | Iteration                31
2017-07-02 12:34:23.562900 EDT | AverageReturn            34.1399
2017-07-02 12:34:23.563064 EDT | StdReturn                 0.366064
2017-07-02 12:34:23.563237 EDT | MaxReturn                35
2017-07-02 12:34:23.563374 EDT | MinReturn                33
2017-07-02 12:34:23.563501 EDT | AverageEsReturn          15.2576
2017-07-02 12:34:23.563607 EDT | StdEsReturn              12.3672
2017-07-02 12:34:23.563707 EDT | MaxEsReturn              49
2017-07-02 12:34:23.563807 EDT | MinEsReturn               3
2017-07-02 12:34:23.563907 EDT | AverageDiscountedReturn  29.0441
2017-07-02 12:34:23.564006 EDT | AverageQLoss              0.00031649
2017-07-02 12:34:23.564126 EDT | AveragePolicySurr        -0.255402
2017-07-02 12:34:23.564227 EDT | AverageQ                  0.218126
2017-07-02 12:34:23.564327 EDT | AverageAbsQ               0.218618
2017-07-02 12:34:23.564424 EDT | AverageY                  0.218139
2017-07-02 12:34:23.564524 EDT | AverageAbsY               0.218311
2017-07-02 12:34:23.564627 EDT | AverageAbsQYDiff          0.00876988
2017-07-02 12:34:23.564755 EDT | AverageAction             0.2741
2017-07-02 12:34:23.564856 EDT | PolicyRegParamNorm       21.8948
2017-07-02 12:34:23.564988 EDT | QFunRegParamNorm         18.6077
2017-07-02 12:34:23.565097 EDT | -----------------------  -----------
2017-07-02 12:34:23.565261 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #32 | Training started
2017-07-02 12:34:33.390792 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #32 | Training finished
2017-07-02 12:34:33.391319 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #32 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 12:34:33.391532 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #32 | Collecting samples for evaluation
2017-07-02 12:34:39.208713 EDT | -----------------------  ------------
2017-07-02 12:34:39.208997 EDT | Epoch                    32
2017-07-02 12:34:39.209158 EDT | Iteration                32
2017-07-02 12:34:39.209318 EDT | AverageReturn            34.5586
2017-07-02 12:34:39.209549 EDT | StdReturn                 0.496552
2017-07-02 12:34:39.209753 EDT | MaxReturn                35
2017-07-02 12:34:39.209944 EDT | MinReturn                34
2017-07-02 12:34:39.210085 EDT | AverageEsReturn          12.2099
2017-07-02 12:34:39.210227 EDT | StdEsReturn               9.77237
2017-07-02 12:34:39.210383 EDT | MaxEsReturn              45
2017-07-02 12:34:39.210532 EDT | MinEsReturn               3
2017-07-02 12:34:39.210650 EDT | AverageDiscountedReturn  29.3416
2017-07-02 12:34:39.210822 EDT | AverageQLoss              0.000348247
2017-07-02 12:34:39.210976 EDT | AveragePolicySurr        -0.265622
2017-07-02 12:34:39.211080 EDT | AverageQ                  0.226491
2017-07-02 12:34:39.211205 EDT | AverageAbsQ               0.227029
2017-07-02 12:34:39.211393 EDT | AverageY                  0.226512
2017-07-02 12:34:39.211539 EDT | AverageAbsY               0.226632
2017-07-02 12:34:39.211641 EDT | AverageAbsQYDiff          0.00905852
2017-07-02 12:34:39.211762 EDT | AverageAction             0.388951
2017-07-02 12:34:39.211877 EDT | PolicyRegParamNorm       22.2202
2017-07-02 12:34:39.212006 EDT | QFunRegParamNorm         18.999
2017-07-02 12:34:39.212156 EDT | -----------------------  ------------
2017-07-02 12:34:39.212351 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #33 | Training started
2017-07-02 12:34:49.127029 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #33 | Training finished
2017-07-02 12:34:49.136596 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #33 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 12:34:49.136857 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #33 | Collecting samples for evaluation
2017-07-02 12:34:54.852001 EDT | -----------------------  ------------
2017-07-02 12:34:54.852194 EDT | Epoch                    33
2017-07-02 12:34:54.852339 EDT | Iteration                33
2017-07-02 12:34:54.852469 EDT | AverageReturn            34.8815
2017-07-02 12:34:54.852611 EDT | StdReturn                 0.373197
2017-07-02 12:34:54.852742 EDT | MaxReturn                36
2017-07-02 12:34:54.852868 EDT | MinReturn                34
2017-07-02 12:34:54.852991 EDT | AverageEsReturn          12.119
2017-07-02 12:34:54.853129 EDT | StdEsReturn               9.58223
2017-07-02 12:34:54.853268 EDT | MaxEsReturn              39
2017-07-02 12:34:54.853398 EDT | MinEsReturn               3
2017-07-02 12:34:54.853597 EDT | AverageDiscountedReturn  29.5709
2017-07-02 12:34:54.853781 EDT | AverageQLoss              0.000345082
2017-07-02 12:34:54.853963 EDT | AveragePolicySurr        -0.274504
2017-07-02 12:34:54.854067 EDT | AverageQ                  0.236021
2017-07-02 12:34:54.854169 EDT | AverageAbsQ               0.236558
2017-07-02 12:34:54.854269 EDT | AverageY                  0.236036
2017-07-02 12:34:54.854415 EDT | AverageAbsY               0.236185
2017-07-02 12:34:54.854597 EDT | AverageAbsQYDiff          0.00897393
2017-07-02 12:34:54.854701 EDT | AverageAction             0.250121
2017-07-02 12:34:54.854802 EDT | PolicyRegParamNorm       22.5217
2017-07-02 12:34:54.854913 EDT | QFunRegParamNorm         19.4021
2017-07-02 12:34:54.855017 EDT | -----------------------  ------------
2017-07-02 12:34:54.855179 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #34 | Training started
2017-07-02 12:35:04.476920 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #34 | Training finished
2017-07-02 12:35:04.477533 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #34 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 12:35:04.477786 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #34 | Collecting samples for evaluation
2017-07-02 12:35:10.454521 EDT | -----------------------  -----------
2017-07-02 12:35:10.455024 EDT | Epoch                    34
2017-07-02 12:35:10.455246 EDT | Iteration                34
2017-07-02 12:35:10.455460 EDT | AverageReturn            34.3219
2017-07-02 12:35:10.455685 EDT | StdReturn                 0.467212
2017-07-02 12:35:10.455917 EDT | MaxReturn                35
2017-07-02 12:35:10.456116 EDT | MinReturn                34
2017-07-02 12:35:10.456348 EDT | AverageEsReturn          13.6438
2017-07-02 12:35:10.456573 EDT | StdEsReturn              10.7453
2017-07-02 12:35:10.456771 EDT | MaxEsReturn              46
2017-07-02 12:35:10.457003 EDT | MinEsReturn               3
2017-07-02 12:35:10.457219 EDT | AverageDiscountedReturn  29.1734
2017-07-02 12:35:10.457328 EDT | AverageQLoss              0.00038329
2017-07-02 12:35:10.457462 EDT | AveragePolicySurr        -0.283041
2017-07-02 12:35:10.457589 EDT | AverageQ                  0.244256
2017-07-02 12:35:10.457818 EDT | AverageAbsQ               0.244902
2017-07-02 12:35:10.458047 EDT | AverageY                  0.244296
2017-07-02 12:35:10.458219 EDT | AverageAbsY               0.244475
2017-07-02 12:35:10.458433 EDT | AverageAbsQYDiff          0.00922232
2017-07-02 12:35:10.458661 EDT | AverageAction             0.295552
2017-07-02 12:35:10.458882 EDT | PolicyRegParamNorm       22.7137
2017-07-02 12:35:10.459111 EDT | QFunRegParamNorm         19.7756
2017-07-02 12:35:10.459328 EDT | -----------------------  -----------
2017-07-02 12:35:10.459649 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #35 | Training started
2017-07-02 12:35:20.383398 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #35 | Training finished
2017-07-02 12:35:20.384005 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #35 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 12:35:20.384258 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #35 | Collecting samples for evaluation
2017-07-02 12:35:26.562710 EDT | -----------------------  ------------
2017-07-02 12:35:26.562949 EDT | Epoch                    35
2017-07-02 12:35:26.563142 EDT | Iteration                35
2017-07-02 12:35:26.563339 EDT | AverageReturn            34.9477
2017-07-02 12:35:26.563473 EDT | StdReturn                 0.324472
2017-07-02 12:35:26.563577 EDT | MaxReturn                36
2017-07-02 12:35:26.563679 EDT | MinReturn                34
2017-07-02 12:35:26.563779 EDT | AverageEsReturn          12.4074
2017-07-02 12:35:26.563898 EDT | StdEsReturn               9.5501
2017-07-02 12:35:26.563998 EDT | MaxEsReturn              51
2017-07-02 12:35:26.564131 EDT | MinEsReturn               3
2017-07-02 12:35:26.564233 EDT | AverageDiscountedReturn  29.6179
2017-07-02 12:35:26.564368 EDT | AverageQLoss              0.000456155
2017-07-02 12:35:26.564494 EDT | AveragePolicySurr        -0.293633
2017-07-02 12:35:26.564596 EDT | AverageQ                  0.252385
2017-07-02 12:35:26.564704 EDT | AverageAbsQ               0.25301
2017-07-02 12:35:26.564804 EDT | AverageY                  0.252423
2017-07-02 12:35:26.564904 EDT | AverageAbsY               0.252621
2017-07-02 12:35:26.565003 EDT | AverageAbsQYDiff          0.0102537
2017-07-02 12:35:26.565102 EDT | AverageAction             0.291336
2017-07-02 12:35:26.565202 EDT | PolicyRegParamNorm       23.0196
2017-07-02 12:35:26.565301 EDT | QFunRegParamNorm         20.1437
2017-07-02 12:35:26.565400 EDT | -----------------------  ------------
2017-07-02 12:35:26.565737 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #36 | Training started
2017-07-02 12:35:36.253641 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #36 | Training finished
2017-07-02 12:35:36.254269 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #36 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 12:35:36.254510 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #36 | Collecting samples for evaluation
2017-07-02 12:35:42.270181 EDT | -----------------------  ------------
2017-07-02 12:35:42.270695 EDT | Epoch                    36
2017-07-02 12:35:42.270896 EDT | Iteration                36
2017-07-02 12:35:42.271051 EDT | AverageReturn            33.0033
2017-07-02 12:35:42.271162 EDT | StdReturn                 0.0573536
2017-07-02 12:35:42.271265 EDT | MaxReturn                34
2017-07-02 12:35:42.271366 EDT | MinReturn                33
2017-07-02 12:35:42.271497 EDT | AverageEsReturn          11.7647
2017-07-02 12:35:42.271624 EDT | StdEsReturn               9.46902
2017-07-02 12:35:42.271726 EDT | MaxEsReturn              47
2017-07-02 12:35:42.271912 EDT | MinEsReturn               2
2017-07-02 12:35:42.272118 EDT | AverageDiscountedReturn  28.2293
2017-07-02 12:35:42.272229 EDT | AverageQLoss              0.000552524
2017-07-02 12:35:42.272332 EDT | AveragePolicySurr        -0.303746
2017-07-02 12:35:42.272433 EDT | AverageQ                  0.261362
2017-07-02 12:35:42.272631 EDT | AverageAbsQ               0.262157
2017-07-02 12:35:42.272767 EDT | AverageY                  0.261378
2017-07-02 12:35:42.272871 EDT | AverageAbsY               0.261698
2017-07-02 12:35:42.272977 EDT | AverageAbsQYDiff          0.0108529
2017-07-02 12:35:42.273077 EDT | AverageAction             0.375311
2017-07-02 12:35:42.273235 EDT | PolicyRegParamNorm       23.2155
2017-07-02 12:35:42.273376 EDT | QFunRegParamNorm         20.4313
2017-07-02 12:35:42.273484 EDT | -----------------------  ------------
2017-07-02 12:35:42.273737 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #37 | Training started
2017-07-02 12:35:52.004633 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #37 | Training finished
2017-07-02 12:35:52.004994 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #37 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 12:35:52.005243 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #37 | Collecting samples for evaluation
2017-07-02 12:35:57.914068 EDT | -----------------------  -----------
2017-07-02 12:35:57.914254 EDT | Epoch                    37
2017-07-02 12:35:57.914367 EDT | Iteration                37
2017-07-02 12:35:57.914473 EDT | AverageReturn            33.2625
2017-07-02 12:35:57.914624 EDT | StdReturn                 0.43997
2017-07-02 12:35:57.914755 EDT | MaxReturn                34
2017-07-02 12:35:57.914879 EDT | MinReturn                33
2017-07-02 12:35:57.914988 EDT | AverageEsReturn          12.0854
2017-07-02 12:35:57.915103 EDT | StdEsReturn              10.3855
2017-07-02 12:35:57.915209 EDT | MaxEsReturn              48
2017-07-02 12:35:57.915340 EDT | MinEsReturn               2
2017-07-02 12:35:57.915447 EDT | AverageDiscountedReturn  28.4153
2017-07-02 12:35:57.915573 EDT | AverageQLoss              0.00054288
2017-07-02 12:35:57.915704 EDT | AveragePolicySurr        -0.313153
2017-07-02 12:35:57.915826 EDT | AverageQ                  0.270448
2017-07-02 12:35:57.915933 EDT | AverageAbsQ               0.27134
2017-07-02 12:35:57.916045 EDT | AverageY                  0.270498
2017-07-02 12:35:57.916158 EDT | AverageAbsY               0.270852
2017-07-02 12:35:57.916265 EDT | AverageAbsQYDiff          0.0110653
2017-07-02 12:35:57.916371 EDT | AverageAction             0.330094
2017-07-02 12:35:57.916476 EDT | PolicyRegParamNorm       23.5092
2017-07-02 12:35:57.916582 EDT | QFunRegParamNorm         20.7109
2017-07-02 12:35:57.916757 EDT | -----------------------  -----------
2017-07-02 12:35:57.916930 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #38 | Training started
2017-07-02 12:36:07.641573 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #38 | Training finished
2017-07-02 12:36:07.642192 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #38 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 12:36:07.642339 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #38 | Collecting samples for evaluation
2017-07-02 12:36:13.515543 EDT | -----------------------  ------------
2017-07-02 12:36:13.515865 EDT | Epoch                    38
2017-07-02 12:36:13.516069 EDT | Iteration                38
2017-07-02 12:36:13.516262 EDT | AverageReturn            32.823
2017-07-02 12:36:13.516455 EDT | StdReturn                 0.38171
2017-07-02 12:36:13.516641 EDT | MaxReturn                33
2017-07-02 12:36:13.516768 EDT | MinReturn                32
2017-07-02 12:36:13.516889 EDT | AverageEsReturn          12.7821
2017-07-02 12:36:13.516994 EDT | StdEsReturn              10.4607
2017-07-02 12:36:13.517115 EDT | MaxEsReturn              47
2017-07-02 12:36:13.517215 EDT | MinEsReturn               3
2017-07-02 12:36:13.517315 EDT | AverageDiscountedReturn  28.0986
2017-07-02 12:36:13.517465 EDT | AverageQLoss              0.000636639
2017-07-02 12:36:13.517601 EDT | AveragePolicySurr        -0.322129
2017-07-02 12:36:13.517709 EDT | AverageQ                  0.279216
2017-07-02 12:36:13.517812 EDT | AverageAbsQ               0.280096
2017-07-02 12:36:13.517916 EDT | AverageY                  0.279237
2017-07-02 12:36:13.518098 EDT | AverageAbsY               0.279538
2017-07-02 12:36:13.518202 EDT | AverageAbsQYDiff          0.0117191
2017-07-02 12:36:13.518302 EDT | AverageAction             0.291372
2017-07-02 12:36:13.518401 EDT | PolicyRegParamNorm       23.7196
2017-07-02 12:36:13.518501 EDT | QFunRegParamNorm         21.039
2017-07-02 12:36:13.518646 EDT | -----------------------  ------------
2017-07-02 12:36:13.518811 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #39 | Training started
2017-07-02 12:36:23.292380 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #39 | Training finished
2017-07-02 12:36:23.292918 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #39 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 12:36:23.293050 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #39 | Collecting samples for evaluation
2017-07-02 12:36:29.197439 EDT | -----------------------  ------------
2017-07-02 12:36:29.197755 EDT | Epoch                    39
2017-07-02 12:36:29.197894 EDT | Iteration                39
2017-07-02 12:36:29.198020 EDT | AverageReturn            36.7831
2017-07-02 12:36:29.198135 EDT | StdReturn                 0.959094
2017-07-02 12:36:29.198266 EDT | MaxReturn                39
2017-07-02 12:36:29.198418 EDT | MinReturn                35
2017-07-02 12:36:29.198522 EDT | AverageEsReturn          15.1692
2017-07-02 12:36:29.198734 EDT | StdEsReturn              10.7311
2017-07-02 12:36:29.198905 EDT | MaxEsReturn              40
2017-07-02 12:36:29.199026 EDT | MinEsReturn               3
2017-07-02 12:36:29.199207 EDT | AverageDiscountedReturn  30.9014
2017-07-02 12:36:29.199386 EDT | AverageQLoss              0.000632931
2017-07-02 12:36:29.199599 EDT | AveragePolicySurr        -0.331524
2017-07-02 12:36:29.199760 EDT | AverageQ                  0.286129
2017-07-02 12:36:29.199884 EDT | AverageAbsQ               0.287137
2017-07-02 12:36:29.200079 EDT | AverageY                  0.286157
2017-07-02 12:36:29.200230 EDT | AverageAbsY               0.286478
2017-07-02 12:36:29.200432 EDT | AverageAbsQYDiff          0.0117201
2017-07-02 12:36:29.200600 EDT | AverageAction             0.47096
2017-07-02 12:36:29.200773 EDT | PolicyRegParamNorm       24.0271
2017-07-02 12:36:29.200969 EDT | QFunRegParamNorm         21.288
2017-07-02 12:36:29.201157 EDT | -----------------------  ------------
2017-07-02 12:36:29.201359 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #40 | Training started
2017-07-02 12:36:38.939094 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #40 | Training finished
2017-07-02 12:36:38.939616 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #40 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 12:36:38.939888 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #40 | Collecting samples for evaluation
2017-07-02 12:36:44.841706 EDT | -----------------------  ------------
2017-07-02 12:36:44.841957 EDT | Epoch                    40
2017-07-02 12:36:44.842079 EDT | Iteration                40
2017-07-02 12:36:44.842223 EDT | AverageReturn            38.9183
2017-07-02 12:36:44.842427 EDT | StdReturn                 1.00443
2017-07-02 12:36:44.842560 EDT | MaxReturn                42
2017-07-02 12:36:44.842754 EDT | MinReturn                37
2017-07-02 12:36:44.842891 EDT | AverageEsReturn          16.4677
2017-07-02 12:36:44.842995 EDT | StdEsReturn              14.1041
2017-07-02 12:36:44.843105 EDT | MaxEsReturn              79
2017-07-02 12:36:44.843270 EDT | MinEsReturn               3
2017-07-02 12:36:44.843379 EDT | AverageDiscountedReturn  32.3681
2017-07-02 12:36:44.843512 EDT | AverageQLoss              0.000719823
2017-07-02 12:36:44.843620 EDT | AveragePolicySurr        -0.341484
2017-07-02 12:36:44.843766 EDT | AverageQ                  0.295969
2017-07-02 12:36:44.843869 EDT | AverageAbsQ               0.297112
2017-07-02 12:36:44.843988 EDT | AverageY                  0.295998
2017-07-02 12:36:44.844089 EDT | AverageAbsY               0.29652
2017-07-02 12:36:44.844212 EDT | AverageAbsQYDiff          0.0124455
2017-07-02 12:36:44.844350 EDT | AverageAction             0.325767
2017-07-02 12:36:44.844453 EDT | PolicyRegParamNorm       24.3753
2017-07-02 12:36:44.844568 EDT | QFunRegParamNorm         21.566
2017-07-02 12:36:44.844690 EDT | -----------------------  ------------
2017-07-02 12:36:44.844854 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #41 | Training started
2017-07-02 12:36:54.501427 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #41 | Training finished
2017-07-02 12:36:54.501985 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #41 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 12:36:54.502141 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #41 | Collecting samples for evaluation
2017-07-02 12:37:00.390960 EDT | -----------------------  ------------
2017-07-02 12:37:00.391448 EDT | Epoch                    41
2017-07-02 12:37:00.391658 EDT | Iteration                41
2017-07-02 12:37:00.391828 EDT | AverageReturn            40.8367
2017-07-02 12:37:00.392009 EDT | StdReturn                 1.4505
2017-07-02 12:37:00.392160 EDT | MaxReturn                44
2017-07-02 12:37:00.392264 EDT | MinReturn                39
2017-07-02 12:37:00.392409 EDT | AverageEsReturn          14.4493
2017-07-02 12:37:00.392610 EDT | StdEsReturn              12.5866
2017-07-02 12:37:00.392755 EDT | MaxEsReturn              46
2017-07-02 12:37:00.392942 EDT | MinEsReturn               3
2017-07-02 12:37:00.393054 EDT | AverageDiscountedReturn  33.656
2017-07-02 12:37:00.393173 EDT | AverageQLoss              0.000681262
2017-07-02 12:37:00.393291 EDT | AveragePolicySurr        -0.348837
2017-07-02 12:37:00.393480 EDT | AverageQ                  0.302807
2017-07-02 12:37:00.393701 EDT | AverageAbsQ               0.303835
2017-07-02 12:37:00.393909 EDT | AverageY                  0.302831
2017-07-02 12:37:00.394134 EDT | AverageAbsY               0.303237
2017-07-02 12:37:00.394311 EDT | AverageAbsQYDiff          0.0120539
2017-07-02 12:37:00.394415 EDT | AverageAction             0.202772
2017-07-02 12:37:00.394516 EDT | PolicyRegParamNorm       24.6428
2017-07-02 12:37:00.394657 EDT | QFunRegParamNorm         21.8742
2017-07-02 12:37:00.394776 EDT | -----------------------  ------------
2017-07-02 12:37:00.395081 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #42 | Training started
2017-07-02 12:37:09.863033 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #42 | Training finished
2017-07-02 12:37:09.863665 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #42 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 12:37:09.863926 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #42 | Collecting samples for evaluation
2017-07-02 12:37:15.765779 EDT | -----------------------  -------------
2017-07-02 12:37:15.766032 EDT | Epoch                     42
2017-07-02 12:37:15.766246 EDT | Iteration                 42
2017-07-02 12:37:15.766371 EDT | AverageReturn             98.6863
2017-07-02 12:37:15.766474 EDT | StdReturn                  2.45341
2017-07-02 12:37:15.766596 EDT | MaxReturn                105
2017-07-02 12:37:15.766718 EDT | MinReturn                 94
2017-07-02 12:37:15.766928 EDT | AverageEsReturn           14.2941
2017-07-02 12:37:15.767076 EDT | StdEsReturn               14.0943
2017-07-02 12:37:15.767183 EDT | MaxEsReturn               75
2017-07-02 12:37:15.767385 EDT | MinEsReturn                3
2017-07-02 12:37:15.767577 EDT | AverageDiscountedReturn   62.899
2017-07-02 12:37:15.767764 EDT | AverageQLoss               0.000719578
2017-07-02 12:37:15.767939 EDT | AveragePolicySurr         -0.356789
2017-07-02 12:37:15.768074 EDT | AverageQ                   0.310524
2017-07-02 12:37:15.768206 EDT | AverageAbsQ                0.311671
2017-07-02 12:37:15.768333 EDT | AverageY                   0.310551
2017-07-02 12:37:15.768469 EDT | AverageAbsY                0.310943
2017-07-02 12:37:15.768630 EDT | AverageAbsQYDiff           0.0122046
2017-07-02 12:37:15.768825 EDT | AverageAction              0.139625
2017-07-02 12:37:15.768962 EDT | PolicyRegParamNorm        25.037
2017-07-02 12:37:15.769112 EDT | QFunRegParamNorm          22.1018
2017-07-02 12:37:15.769216 EDT | -----------------------  -------------
2017-07-02 12:37:15.769407 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #43 | Training started
2017-07-02 12:37:25.350680 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #43 | Training finished
2017-07-02 12:37:25.351174 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #43 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 12:37:25.351357 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #43 | Collecting samples for evaluation
2017-07-02 12:37:31.227759 EDT | -----------------------  -------------
2017-07-02 12:37:31.228494 EDT | Epoch                     43
2017-07-02 12:37:31.228733 EDT | Iteration                 43
2017-07-02 12:37:31.228918 EDT | AverageReturn            137.877
2017-07-02 12:37:31.229147 EDT | StdReturn                 22.0913
2017-07-02 12:37:31.229369 EDT | MaxReturn                151
2017-07-02 12:37:31.229611 EDT | MinReturn                 47
2017-07-02 12:37:31.229905 EDT | AverageEsReturn           15.1765
2017-07-02 12:37:31.230200 EDT | StdEsReturn               13.8457
2017-07-02 12:37:31.230495 EDT | MaxEsReturn               80
2017-07-02 12:37:31.230789 EDT | MinEsReturn                3
2017-07-02 12:37:31.231089 EDT | AverageDiscountedReturn   74.1517
2017-07-02 12:37:31.231384 EDT | AverageQLoss               0.000815314
2017-07-02 12:37:31.231662 EDT | AveragePolicySurr         -0.365722
2017-07-02 12:37:31.231854 EDT | AverageQ                   0.319565
2017-07-02 12:37:31.232064 EDT | AverageAbsQ                0.320818
2017-07-02 12:37:31.232277 EDT | AverageY                   0.319578
2017-07-02 12:37:31.232467 EDT | AverageAbsY                0.320092
2017-07-02 12:37:31.232688 EDT | AverageAbsQYDiff           0.0130551
2017-07-02 12:37:31.232904 EDT | AverageAction              0.378393
2017-07-02 12:37:31.233130 EDT | PolicyRegParamNorm        25.4208
2017-07-02 12:37:31.233292 EDT | QFunRegParamNorm          22.3997
2017-07-02 12:37:31.233515 EDT | -----------------------  -------------
2017-07-02 12:37:31.233770 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #44 | Training started
2017-07-02 12:37:40.798124 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #44 | Training finished
2017-07-02 12:37:40.798628 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #44 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 12:37:40.799147 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #44 | Collecting samples for evaluation
2017-07-02 12:37:46.722729 EDT | -----------------------  -------------
2017-07-02 12:37:46.722964 EDT | Epoch                     44
2017-07-02 12:37:46.723090 EDT | Iteration                 44
2017-07-02 12:37:46.723200 EDT | AverageReturn            203.64
2017-07-02 12:37:46.723303 EDT | StdReturn                 38.9357
2017-07-02 12:37:46.723451 EDT | MaxReturn                244
2017-07-02 12:37:46.723615 EDT | MinReturn                115
2017-07-02 12:37:46.723729 EDT | AverageEsReturn           14.5507
2017-07-02 12:37:46.723847 EDT | StdEsReturn               14.3875
2017-07-02 12:37:46.723996 EDT | MaxEsReturn               81
2017-07-02 12:37:46.724099 EDT | MinEsReturn                3
2017-07-02 12:37:46.724197 EDT | AverageDiscountedReturn   85.8767
2017-07-02 12:37:46.724295 EDT | AverageQLoss               0.000802855
2017-07-02 12:37:46.724414 EDT | AveragePolicySurr         -0.373289
2017-07-02 12:37:46.724625 EDT | AverageQ                   0.326265
2017-07-02 12:37:46.724826 EDT | AverageAbsQ                0.32739
2017-07-02 12:37:46.725024 EDT | AverageY                   0.326295
2017-07-02 12:37:46.725213 EDT | AverageAbsY                0.32669
2017-07-02 12:37:46.725320 EDT | AverageAbsQYDiff           0.0127509
2017-07-02 12:37:46.725423 EDT | AverageAction              0.200203
2017-07-02 12:37:46.726148 EDT | PolicyRegParamNorm        25.6131
2017-07-02 12:37:46.726325 EDT | QFunRegParamNorm          22.6254
2017-07-02 12:37:46.726433 EDT | -----------------------  -------------
2017-07-02 12:37:46.726670 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #45 | Training started
2017-07-02 12:37:56.274325 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #45 | Training finished
2017-07-02 12:37:56.274847 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #45 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 12:37:56.274992 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #45 | Collecting samples for evaluation
2017-07-02 12:38:01.966566 EDT | -----------------------  --------------
2017-07-02 12:38:01.967161 EDT | Epoch                      45
2017-07-02 12:38:01.967410 EDT | Iteration                  45
2017-07-02 12:38:01.967634 EDT | AverageReturn            1000
2017-07-02 12:38:01.967854 EDT | StdReturn                   0
2017-07-02 12:38:01.968067 EDT | MaxReturn                1000
2017-07-02 12:38:01.968293 EDT | MinReturn                1000
2017-07-02 12:38:01.968516 EDT | AverageEsReturn            19.2308
2017-07-02 12:38:01.968728 EDT | StdEsReturn                13.9802
2017-07-02 12:38:01.968953 EDT | MaxEsReturn                55
2017-07-02 12:38:01.969172 EDT | MinEsReturn                 2
2017-07-02 12:38:01.969368 EDT | AverageDiscountedReturn    99.9957
2017-07-02 12:38:01.969617 EDT | AverageQLoss                0.000783941
2017-07-02 12:38:01.969832 EDT | AveragePolicySurr          -0.381369
2017-07-02 12:38:01.970041 EDT | AverageQ                    0.33412
2017-07-02 12:38:01.970244 EDT | AverageAbsQ                 0.33523
2017-07-02 12:38:01.970426 EDT | AverageY                    0.334144
2017-07-02 12:38:01.970583 EDT | AverageAbsY                 0.334627
2017-07-02 12:38:01.970800 EDT | AverageAbsQYDiff            0.0129519
2017-07-02 12:38:01.970983 EDT | AverageAction               0.0950048
2017-07-02 12:38:01.971087 EDT | PolicyRegParamNorm         25.9221
2017-07-02 12:38:01.971187 EDT | QFunRegParamNorm           22.934
2017-07-02 12:38:01.971320 EDT | -----------------------  --------------
2017-07-02 12:38:01.971617 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #46 | Training started
2017-07-02 12:38:11.509374 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #46 | Training finished
2017-07-02 12:38:11.510146 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #46 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 12:38:11.510314 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #46 | Collecting samples for evaluation
2017-07-02 12:38:17.241480 EDT | -----------------------  --------------
2017-07-02 12:38:17.241802 EDT | Epoch                      46
2017-07-02 12:38:17.242027 EDT | Iteration                  46
2017-07-02 12:38:17.242246 EDT | AverageReturn            1000
2017-07-02 12:38:17.242483 EDT | StdReturn                   0
2017-07-02 12:38:17.242665 EDT | MaxReturn                1000
2017-07-02 12:38:17.242903 EDT | MinReturn                1000
2017-07-02 12:38:17.243107 EDT | AverageEsReturn            18.4717
2017-07-02 12:38:17.243344 EDT | StdEsReturn                20.3902
2017-07-02 12:38:17.243572 EDT | MaxEsReturn                93
2017-07-02 12:38:17.243741 EDT | MinEsReturn                 2
2017-07-02 12:38:17.243977 EDT | AverageDiscountedReturn    99.9957
2017-07-02 12:38:17.244159 EDT | AverageQLoss                0.000938166
2017-07-02 12:38:17.244392 EDT | AveragePolicySurr          -0.387895
2017-07-02 12:38:17.244622 EDT | AverageQ                    0.339317
2017-07-02 12:38:17.244766 EDT | AverageAbsQ                 0.340672
2017-07-02 12:38:17.245003 EDT | AverageY                    0.33933
2017-07-02 12:38:17.245218 EDT | AverageAbsY                 0.339905
2017-07-02 12:38:17.245432 EDT | AverageAbsQYDiff            0.0139349
2017-07-02 12:38:17.245815 EDT | AverageAction               0.0865948
2017-07-02 12:38:17.246134 EDT | PolicyRegParamNorm         26.1951
2017-07-02 12:38:17.246345 EDT | QFunRegParamNorm           23.1408
2017-07-02 12:38:17.246485 EDT | -----------------------  --------------
2017-07-02 12:38:17.246821 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #47 | Training started
2017-07-02 12:38:26.773213 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #47 | Training finished
2017-07-02 12:38:26.781950 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #47 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 12:38:26.782182 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #47 | Collecting samples for evaluation
2017-07-02 12:38:32.557152 EDT | -----------------------  --------------
2017-07-02 12:38:32.557675 EDT | Epoch                      47
2017-07-02 12:38:32.557861 EDT | Iteration                  47
2017-07-02 12:38:32.557991 EDT | AverageReturn            1000
2017-07-02 12:38:32.558107 EDT | StdReturn                   0
2017-07-02 12:38:32.558244 EDT | MaxReturn                1000
2017-07-02 12:38:32.558379 EDT | MinReturn                1000
2017-07-02 12:38:32.558538 EDT | AverageEsReturn            20.7872
2017-07-02 12:38:32.558655 EDT | StdEsReturn                15.9106
2017-07-02 12:38:32.558756 EDT | MaxEsReturn                83
2017-07-02 12:38:32.558920 EDT | MinEsReturn                 3
2017-07-02 12:38:32.559024 EDT | AverageDiscountedReturn    99.9957
2017-07-02 12:38:32.559125 EDT | AverageQLoss                0.000819919
2017-07-02 12:38:32.559257 EDT | AveragePolicySurr          -0.397589
2017-07-02 12:38:32.559386 EDT | AverageQ                    0.348838
2017-07-02 12:38:32.559548 EDT | AverageAbsQ                 0.350176
2017-07-02 12:38:32.559723 EDT | AverageY                    0.348866
2017-07-02 12:38:32.559898 EDT | AverageAbsY                 0.349395
2017-07-02 12:38:32.560073 EDT | AverageAbsQYDiff            0.0127814
2017-07-02 12:38:32.560276 EDT | AverageAction               0.16999
2017-07-02 12:38:32.560470 EDT | PolicyRegParamNorm         26.4639
2017-07-02 12:38:32.560651 EDT | QFunRegParamNorm           23.4301
2017-07-02 12:38:32.560789 EDT | -----------------------  --------------
2017-07-02 12:38:32.561004 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #48 | Training started
2017-07-02 12:38:42.142477 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #48 | Training finished
2017-07-02 12:38:42.143195 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #48 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 12:38:42.143422 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #48 | Collecting samples for evaluation
2017-07-02 12:38:47.870864 EDT | -----------------------  -------------
2017-07-02 12:38:47.871049 EDT | Epoch                      48
2017-07-02 12:38:47.871161 EDT | Iteration                  48
2017-07-02 12:38:47.871281 EDT | AverageReturn            1000
2017-07-02 12:38:47.871383 EDT | StdReturn                   0
2017-07-02 12:38:47.871484 EDT | MaxReturn                1000
2017-07-02 12:38:47.871583 EDT | MinReturn                1000
2017-07-02 12:38:47.871682 EDT | AverageEsReturn            30.4118
2017-07-02 12:38:47.871792 EDT | StdEsReturn                25.5448
2017-07-02 12:38:47.871917 EDT | MaxEsReturn               103
2017-07-02 12:38:47.872021 EDT | MinEsReturn                 3
2017-07-02 12:38:47.872122 EDT | AverageDiscountedReturn    99.9957
2017-07-02 12:38:47.872266 EDT | AverageQLoss                0.00104521
2017-07-02 12:38:47.872371 EDT | AveragePolicySurr          -0.405381
2017-07-02 12:38:47.872471 EDT | AverageQ                    0.355067
2017-07-02 12:38:47.872570 EDT | AverageAbsQ                 0.356571
2017-07-02 12:38:47.872670 EDT | AverageY                    0.355088
2017-07-02 12:38:47.872784 EDT | AverageAbsY                 0.355642
2017-07-02 12:38:47.872884 EDT | AverageAbsQYDiff            0.0147732
2017-07-02 12:38:47.872982 EDT | AverageAction               0.445103
2017-07-02 12:38:47.873080 EDT | PolicyRegParamNorm         26.6894
2017-07-02 12:38:47.873200 EDT | QFunRegParamNorm           23.6736
2017-07-02 12:38:47.873300 EDT | -----------------------  -------------
2017-07-02 12:38:47.873461 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #49 | Training started
2017-07-02 12:38:57.487936 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #49 | Training finished
2017-07-02 12:38:57.488564 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #49 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 12:38:57.488764 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #49 | Collecting samples for evaluation
2017-07-02 12:39:03.137108 EDT | -----------------------  --------------
2017-07-02 12:39:03.137363 EDT | Epoch                      49
2017-07-02 12:39:03.137568 EDT | Iteration                  49
2017-07-02 12:39:03.137743 EDT | AverageReturn            1000
2017-07-02 12:39:03.138084 EDT | StdReturn                   0
2017-07-02 12:39:03.138284 EDT | MaxReturn                1000
2017-07-02 12:39:03.138437 EDT | MinReturn                1000
2017-07-02 12:39:03.138577 EDT | AverageEsReturn            27.027
2017-07-02 12:39:03.138733 EDT | StdEsReturn                29.3814
2017-07-02 12:39:03.138866 EDT | MaxEsReturn               135
2017-07-02 12:39:03.138991 EDT | MinEsReturn                 3
2017-07-02 12:39:03.139116 EDT | AverageDiscountedReturn    99.9957
2017-07-02 12:39:03.139265 EDT | AverageQLoss                0.000900285
2017-07-02 12:39:03.139410 EDT | AveragePolicySurr          -0.415066
2017-07-02 12:39:03.139585 EDT | AverageQ                    0.364648
2017-07-02 12:39:03.139690 EDT | AverageAbsQ                 0.366055
2017-07-02 12:39:03.139825 EDT | AverageY                    0.364684
2017-07-02 12:39:03.139976 EDT | AverageAbsY                 0.36526
2017-07-02 12:39:03.140131 EDT | AverageAbsQYDiff            0.0136566
2017-07-02 12:39:03.140236 EDT | AverageAction               0.462074
2017-07-02 12:39:03.140361 EDT | PolicyRegParamNorm         26.863
2017-07-02 12:39:03.140561 EDT | QFunRegParamNorm           23.9736
2017-07-02 12:39:03.140687 EDT | -----------------------  --------------
2017-07-02 12:39:03.140876 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #50 | Training started
2017-07-02 12:39:12.923310 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #50 | Training finished
2017-07-02 12:39:12.924453 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #50 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 12:39:12.924698 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #50 | Collecting samples for evaluation
2017-07-02 12:39:18.523304 EDT | -----------------------  --------------
2017-07-02 12:39:18.523486 EDT | Epoch                      50
2017-07-02 12:39:18.523623 EDT | Iteration                  50
2017-07-02 12:39:18.523758 EDT | AverageReturn            1000
2017-07-02 12:39:18.523863 EDT | StdReturn                   0
2017-07-02 12:39:18.523983 EDT | MaxReturn                1000
2017-07-02 12:39:18.524088 EDT | MinReturn                1000
2017-07-02 12:39:18.524190 EDT | AverageEsReturn            22.4
2017-07-02 12:39:18.524290 EDT | StdEsReturn                26.6545
2017-07-02 12:39:18.524444 EDT | MaxEsReturn               143
2017-07-02 12:39:18.524547 EDT | MinEsReturn                 5
2017-07-02 12:39:18.524647 EDT | AverageDiscountedReturn    99.9957
2017-07-02 12:39:18.524747 EDT | AverageQLoss                0.000894124
2017-07-02 12:39:18.524846 EDT | AveragePolicySurr          -0.423332
2017-07-02 12:39:18.524966 EDT | AverageQ                    0.373181
2017-07-02 12:39:18.525069 EDT | AverageAbsQ                 0.374535
2017-07-02 12:39:18.525169 EDT | AverageY                    0.373205
2017-07-02 12:39:18.525267 EDT | AverageAbsY                 0.373675
2017-07-02 12:39:18.525365 EDT | AverageAbsQYDiff            0.0136043
2017-07-02 12:39:18.525463 EDT | AverageAction               0.480527
2017-07-02 12:39:18.525665 EDT | PolicyRegParamNorm         27.0525
2017-07-02 12:39:18.525879 EDT | QFunRegParamNorm           24.1243
2017-07-02 12:39:18.526107 EDT | -----------------------  --------------
2017-07-02 12:39:18.526397 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #51 | Training started
2017-07-02 12:39:28.202694 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #51 | Training finished
2017-07-02 12:39:28.203272 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #51 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 12:39:28.203524 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #51 | Collecting samples for evaluation
2017-07-02 12:39:33.918604 EDT | -----------------------  --------------
2017-07-02 12:39:33.918803 EDT | Epoch                      51
2017-07-02 12:39:33.918916 EDT | Iteration                  51
2017-07-02 12:39:33.919021 EDT | AverageReturn            1000
2017-07-02 12:39:33.919125 EDT | StdReturn                   0
2017-07-02 12:39:33.919271 EDT | MaxReturn                1000
2017-07-02 12:39:33.919376 EDT | MinReturn                1000
2017-07-02 12:39:33.919478 EDT | AverageEsReturn            22.1818
2017-07-02 12:39:33.919580 EDT | StdEsReturn                18.6368
2017-07-02 12:39:33.919682 EDT | MaxEsReturn                72
2017-07-02 12:39:33.919821 EDT | MinEsReturn                 3
2017-07-02 12:39:33.919949 EDT | AverageDiscountedReturn    99.9957
2017-07-02 12:39:33.920052 EDT | AverageQLoss                0.000905027
2017-07-02 12:39:33.920154 EDT | AveragePolicySurr          -0.432597
2017-07-02 12:39:33.920256 EDT | AverageQ                    0.380842
2017-07-02 12:39:33.920363 EDT | AverageAbsQ                 0.382309
2017-07-02 12:39:33.920506 EDT | AverageY                    0.380866
2017-07-02 12:39:33.920613 EDT | AverageAbsY                 0.381492
2017-07-02 12:39:33.920717 EDT | AverageAbsQYDiff            0.0135608
2017-07-02 12:39:33.920818 EDT | AverageAction               0.381199
2017-07-02 12:39:33.920919 EDT | PolicyRegParamNorm         27.2978
2017-07-02 12:39:33.921019 EDT | QFunRegParamNorm           24.3484
2017-07-02 12:39:33.921118 EDT | -----------------------  --------------
2017-07-02 12:39:33.921304 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #52 | Training started
2017-07-02 12:39:43.591805 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #52 | Training finished
2017-07-02 12:39:43.592443 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #52 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 12:39:43.592687 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #52 | Collecting samples for evaluation
2017-07-02 12:39:49.357332 EDT | -----------------------  -------------
2017-07-02 12:39:49.357567 EDT | Epoch                      52
2017-07-02 12:39:49.357689 EDT | Iteration                  52
2017-07-02 12:39:49.357824 EDT | AverageReturn            1000
2017-07-02 12:39:49.357939 EDT | StdReturn                   0
2017-07-02 12:39:49.358076 EDT | MaxReturn                1000
2017-07-02 12:39:49.358200 EDT | MinReturn                1000
2017-07-02 12:39:49.358327 EDT | AverageEsReturn            17.3051
2017-07-02 12:39:49.358497 EDT | StdEsReturn                12.103
2017-07-02 12:39:49.358682 EDT | MaxEsReturn                55
2017-07-02 12:39:49.358866 EDT | MinEsReturn                 3
2017-07-02 12:39:49.359034 EDT | AverageDiscountedReturn    99.9957
2017-07-02 12:39:49.359145 EDT | AverageQLoss                0.00105574
2017-07-02 12:39:49.359296 EDT | AveragePolicySurr          -0.441554
2017-07-02 12:39:49.359401 EDT | AverageQ                    0.389059
2017-07-02 12:39:49.359592 EDT | AverageAbsQ                 0.390549
2017-07-02 12:39:49.359777 EDT | AverageY                    0.389088
2017-07-02 12:39:49.359904 EDT | AverageAbsY                 0.389703
2017-07-02 12:39:49.360007 EDT | AverageAbsQYDiff            0.013969
2017-07-02 12:39:49.360107 EDT | AverageAction               0.524651
2017-07-02 12:39:49.360224 EDT | PolicyRegParamNorm         27.5701
2017-07-02 12:39:49.360338 EDT | QFunRegParamNorm           24.5796
2017-07-02 12:39:49.360460 EDT | -----------------------  -------------
2017-07-02 12:39:49.360715 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #53 | Training started
2017-07-02 12:39:58.820504 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #53 | Training finished
2017-07-02 12:39:58.821012 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #53 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 12:39:58.821158 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #53 | Collecting samples for evaluation
2017-07-02 12:40:04.633282 EDT | -----------------------  -------------
2017-07-02 12:40:04.633520 EDT | Epoch                      53
2017-07-02 12:40:04.633642 EDT | Iteration                  53
2017-07-02 12:40:04.633798 EDT | AverageReturn            1000
2017-07-02 12:40:04.633983 EDT | StdReturn                   0
2017-07-02 12:40:04.634186 EDT | MaxReturn                1000
2017-07-02 12:40:04.634348 EDT | MinReturn                1000
2017-07-02 12:40:04.634531 EDT | AverageEsReturn            17.2414
2017-07-02 12:40:04.634638 EDT | StdEsReturn                13.2916
2017-07-02 12:40:04.634803 EDT | MaxEsReturn                58
2017-07-02 12:40:04.634924 EDT | MinEsReturn                 3
2017-07-02 12:40:04.635071 EDT | AverageDiscountedReturn    99.9957
2017-07-02 12:40:04.635240 EDT | AverageQLoss                0.00107638
2017-07-02 12:40:04.635398 EDT | AveragePolicySurr          -0.45287
2017-07-02 12:40:04.635520 EDT | AverageQ                    0.399754
2017-07-02 12:40:04.635721 EDT | AverageAbsQ                 0.401241
2017-07-02 12:40:04.635887 EDT | AverageY                    0.399798
2017-07-02 12:40:04.635989 EDT | AverageAbsY                 0.400378
2017-07-02 12:40:04.636094 EDT | AverageAbsQYDiff            0.0145597
2017-07-02 12:40:04.636243 EDT | AverageAction               0.503579
2017-07-02 12:40:04.636368 EDT | PolicyRegParamNorm         27.8858
2017-07-02 12:40:04.636471 EDT | QFunRegParamNorm           24.7806
2017-07-02 12:40:04.636616 EDT | -----------------------  -------------
2017-07-02 12:40:04.636802 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #54 | Training started
2017-07-02 12:40:14.031462 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #54 | Training finished
2017-07-02 12:40:14.032025 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #54 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 12:40:14.032153 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #54 | Collecting samples for evaluation
2017-07-02 12:40:20.025189 EDT | -----------------------  -------------
2017-07-02 12:40:20.025530 EDT | Epoch                      54
2017-07-02 12:40:20.025732 EDT | Iteration                  54
2017-07-02 12:40:20.025930 EDT | AverageReturn            1000
2017-07-02 12:40:20.026140 EDT | StdReturn                   0
2017-07-02 12:40:20.026335 EDT | MaxReturn                1000
2017-07-02 12:40:20.026484 EDT | MinReturn                1000
2017-07-02 12:40:20.026668 EDT | AverageEsReturn            15.1364
2017-07-02 12:40:20.026787 EDT | StdEsReturn                13.9283
2017-07-02 12:40:20.026905 EDT | MaxEsReturn                96
2017-07-02 12:40:20.027015 EDT | MinEsReturn                 3
2017-07-02 12:40:20.027120 EDT | AverageDiscountedReturn    99.9957
2017-07-02 12:40:20.027313 EDT | AverageQLoss                0.00101381
2017-07-02 12:40:20.027418 EDT | AveragePolicySurr          -0.462166
2017-07-02 12:40:20.027519 EDT | AverageQ                    0.409114
2017-07-02 12:40:20.027619 EDT | AverageAbsQ                 0.410318
2017-07-02 12:40:20.027720 EDT | AverageY                    0.409148
2017-07-02 12:40:20.027842 EDT | AverageAbsY                 0.409818
2017-07-02 12:40:20.027992 EDT | AverageAbsQYDiff            0.0141545
2017-07-02 12:40:20.028113 EDT | AverageAction               0.573069
2017-07-02 12:40:20.028240 EDT | PolicyRegParamNorm         28.0375
2017-07-02 12:40:20.028343 EDT | QFunRegParamNorm           25.0801
2017-07-02 12:40:20.028468 EDT | -----------------------  -------------
2017-07-02 12:40:20.028775 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #55 | Training started
2017-07-02 12:40:29.848023 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #55 | Training finished
2017-07-02 12:40:29.848553 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #55 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 12:40:29.848709 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #55 | Collecting samples for evaluation
2017-07-02 12:40:35.585935 EDT | -----------------------  -------------
2017-07-02 12:40:35.586189 EDT | Epoch                      55
2017-07-02 12:40:35.586373 EDT | Iteration                  55
2017-07-02 12:40:35.586598 EDT | AverageReturn            1000
2017-07-02 12:40:35.586778 EDT | StdReturn                   0
2017-07-02 12:40:35.586917 EDT | MaxReturn                1000
2017-07-02 12:40:35.587035 EDT | MinReturn                1000
2017-07-02 12:40:35.587164 EDT | AverageEsReturn            22.2727
2017-07-02 12:40:35.587331 EDT | StdEsReturn                17.2342
2017-07-02 12:40:35.587545 EDT | MaxEsReturn                71
2017-07-02 12:40:35.587770 EDT | MinEsReturn                 3
2017-07-02 12:40:35.587964 EDT | AverageDiscountedReturn    99.9957
2017-07-02 12:40:35.588193 EDT | AverageQLoss                0.00130291
2017-07-02 12:40:35.588422 EDT | AveragePolicySurr          -0.472327
2017-07-02 12:40:35.588644 EDT | AverageQ                    0.41617
2017-07-02 12:40:35.588870 EDT | AverageAbsQ                 0.417631
2017-07-02 12:40:35.589082 EDT | AverageY                    0.41619
2017-07-02 12:40:35.589302 EDT | AverageAbsY                 0.416917
2017-07-02 12:40:35.589612 EDT | AverageAbsQYDiff            0.0156674
2017-07-02 12:40:35.589756 EDT | AverageAction               0.536469
2017-07-02 12:40:35.589867 EDT | PolicyRegParamNorm         28.2384
2017-07-02 12:40:35.589970 EDT | QFunRegParamNorm           25.2955
2017-07-02 12:40:35.590131 EDT | -----------------------  -------------
2017-07-02 12:40:35.590369 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #56 | Training started
2017-07-02 12:40:45.167861 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #56 | Training finished
2017-07-02 12:40:45.168584 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #56 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 12:40:45.168843 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #56 | Collecting samples for evaluation
2017-07-02 12:40:50.848188 EDT | -----------------------  -------------
2017-07-02 12:40:50.848419 EDT | Epoch                      56
2017-07-02 12:40:50.848563 EDT | Iteration                  56
2017-07-02 12:40:50.848742 EDT | AverageReturn            1000
2017-07-02 12:40:50.848869 EDT | StdReturn                   0
2017-07-02 12:40:50.849042 EDT | MaxReturn                1000
2017-07-02 12:40:50.849157 EDT | MinReturn                1000
2017-07-02 12:40:50.849301 EDT | AverageEsReturn            22.4222
2017-07-02 12:40:50.849456 EDT | StdEsReturn                16.4418
2017-07-02 12:40:50.849603 EDT | MaxEsReturn                72
2017-07-02 12:40:50.849712 EDT | MinEsReturn                 3
2017-07-02 12:40:50.849819 EDT | AverageDiscountedReturn    99.9957
2017-07-02 12:40:50.849929 EDT | AverageQLoss                0.00133014
2017-07-02 12:40:50.850062 EDT | AveragePolicySurr          -0.481465
2017-07-02 12:40:50.850226 EDT | AverageQ                    0.425607
2017-07-02 12:40:50.850335 EDT | AverageAbsQ                 0.427145
2017-07-02 12:40:50.850466 EDT | AverageY                    0.425657
2017-07-02 12:40:50.850599 EDT | AverageAbsY                 0.426329
2017-07-02 12:40:50.850710 EDT | AverageAbsQYDiff            0.0158318
2017-07-02 12:40:50.850816 EDT | AverageAction               0.507854
2017-07-02 12:40:50.850922 EDT | PolicyRegParamNorm         28.3609
2017-07-02 12:40:50.851064 EDT | QFunRegParamNorm           25.4965
2017-07-02 12:40:50.851230 EDT | -----------------------  -------------
2017-07-02 12:40:50.851406 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #57 | Training started
2017-07-02 12:41:00.532510 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #57 | Training finished
2017-07-02 12:41:00.533104 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #57 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 12:41:00.533451 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #57 | Collecting samples for evaluation
2017-07-02 12:41:06.251586 EDT | -----------------------  -------------
2017-07-02 12:41:06.251908 EDT | Epoch                      57
2017-07-02 12:41:06.252150 EDT | Iteration                  57
2017-07-02 12:41:06.252345 EDT | AverageReturn            1000
2017-07-02 12:41:06.252567 EDT | StdReturn                   0
2017-07-02 12:41:06.252797 EDT | MaxReturn                1000
2017-07-02 12:41:06.252998 EDT | MinReturn                1000
2017-07-02 12:41:06.253107 EDT | AverageEsReturn            13.0128
2017-07-02 12:41:06.253212 EDT | StdEsReturn                 9.97496
2017-07-02 12:41:06.253314 EDT | MaxEsReturn                52
2017-07-02 12:41:06.253424 EDT | MinEsReturn                 3
2017-07-02 12:41:06.253672 EDT | AverageDiscountedReturn    99.9957
2017-07-02 12:41:06.253887 EDT | AverageQLoss                0.00115354
2017-07-02 12:41:06.254121 EDT | AveragePolicySurr          -0.491215
2017-07-02 12:41:06.254325 EDT | AverageQ                    0.434707
2017-07-02 12:41:06.254545 EDT | AverageAbsQ                 0.436317
2017-07-02 12:41:06.254776 EDT | AverageY                    0.434758
2017-07-02 12:41:06.255008 EDT | AverageAbsY                 0.435458
2017-07-02 12:41:06.255239 EDT | AverageAbsQYDiff            0.0146893
2017-07-02 12:41:06.255457 EDT | AverageAction               0.515985
2017-07-02 12:41:06.255691 EDT | PolicyRegParamNorm         28.4694
2017-07-02 12:41:06.255892 EDT | QFunRegParamNorm           25.678
2017-07-02 12:41:06.256111 EDT | -----------------------  -------------
2017-07-02 12:41:06.256454 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #58 | Training started
2017-07-02 12:41:15.824957 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #58 | Training finished
2017-07-02 12:41:15.825806 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #58 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 12:41:15.826020 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #58 | Collecting samples for evaluation
2017-07-02 12:41:21.508022 EDT | -----------------------  -------------
2017-07-02 12:41:21.508246 EDT | Epoch                      58
2017-07-02 12:41:21.508360 EDT | Iteration                  58
2017-07-02 12:41:21.508465 EDT | AverageReturn            1000
2017-07-02 12:41:21.508568 EDT | StdReturn                   0
2017-07-02 12:41:21.508677 EDT | MaxReturn                1000
2017-07-02 12:41:21.508848 EDT | MinReturn                1000
2017-07-02 12:41:21.509012 EDT | AverageEsReturn            18.3704
2017-07-02 12:41:21.509260 EDT | StdEsReturn                12.8903
2017-07-02 12:41:21.509510 EDT | MaxEsReturn                53
2017-07-02 12:41:21.509778 EDT | MinEsReturn                 4
2017-07-02 12:41:21.510006 EDT | AverageDiscountedReturn    99.9957
2017-07-02 12:41:21.510235 EDT | AverageQLoss                0.00128843
2017-07-02 12:41:21.510487 EDT | AveragePolicySurr          -0.49872
2017-07-02 12:41:21.510782 EDT | AverageQ                    0.442043
2017-07-02 12:41:21.511043 EDT | AverageAbsQ                 0.443855
2017-07-02 12:41:21.511294 EDT | AverageY                    0.4421
2017-07-02 12:41:21.511529 EDT | AverageAbsY                 0.442808
2017-07-02 12:41:21.511765 EDT | AverageAbsQYDiff            0.0156928
2017-07-02 12:41:21.511998 EDT | AverageAction               0.513947
2017-07-02 12:41:21.512227 EDT | PolicyRegParamNorm         28.7052
2017-07-02 12:41:21.512454 EDT | QFunRegParamNorm           25.8558
2017-07-02 12:41:21.512722 EDT | -----------------------  -------------
2017-07-02 12:41:21.513043 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #59 | Training started
2017-07-02 12:41:31.035344 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #59 | Training finished
2017-07-02 12:41:31.035917 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #59 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 12:41:31.036088 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #59 | Collecting samples for evaluation
2017-07-02 12:41:36.738815 EDT | -----------------------  -------------
2017-07-02 12:41:36.739068 EDT | Epoch                      59
2017-07-02 12:41:36.739263 EDT | Iteration                  59
2017-07-02 12:41:36.739395 EDT | AverageReturn            1000
2017-07-02 12:41:36.739524 EDT | StdReturn                   0
2017-07-02 12:41:36.739667 EDT | MaxReturn                1000
2017-07-02 12:41:36.739793 EDT | MinReturn                1000
2017-07-02 12:41:36.739942 EDT | AverageEsReturn            19.8039
2017-07-02 12:41:36.740068 EDT | StdEsReturn                18.0457
2017-07-02 12:41:36.740243 EDT | MaxEsReturn                89
2017-07-02 12:41:36.740443 EDT | MinEsReturn                 3
2017-07-02 12:41:36.740564 EDT | AverageDiscountedReturn    99.9957
2017-07-02 12:41:36.740696 EDT | AverageQLoss                0.00131586
2017-07-02 12:41:36.740800 EDT | AveragePolicySurr          -0.509619
2017-07-02 12:41:36.740900 EDT | AverageQ                    0.45291
2017-07-02 12:41:36.741000 EDT | AverageAbsQ                 0.454755
2017-07-02 12:41:36.741130 EDT | AverageY                    0.452955
2017-07-02 12:41:36.741279 EDT | AverageAbsY                 0.453653
2017-07-02 12:41:36.741381 EDT | AverageAbsQYDiff            0.0155763
2017-07-02 12:41:36.741524 EDT | AverageAction               0.569567
2017-07-02 12:41:36.741643 EDT | PolicyRegParamNorm         28.8892
2017-07-02 12:41:36.741765 EDT | QFunRegParamNorm           26.0621
2017-07-02 12:41:36.741863 EDT | -----------------------  -------------
2017-07-02 12:41:36.742066 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #60 | Training started
2017-07-02 12:41:46.278527 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #60 | Training finished
2017-07-02 12:41:46.279028 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #60 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 12:41:46.279293 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #60 | Collecting samples for evaluation
2017-07-02 12:41:51.947510 EDT | -----------------------  -------------
2017-07-02 12:41:51.947722 EDT | Epoch                      60
2017-07-02 12:41:51.947875 EDT | Iteration                  60
2017-07-02 12:41:51.947982 EDT | AverageReturn            1000
2017-07-02 12:41:51.948104 EDT | StdReturn                   0
2017-07-02 12:41:51.948257 EDT | MaxReturn                1000
2017-07-02 12:41:51.948437 EDT | MinReturn                1000
2017-07-02 12:41:51.948662 EDT | AverageEsReturn            20.3878
2017-07-02 12:41:51.948871 EDT | StdEsReturn                16.3568
2017-07-02 12:41:51.949013 EDT | MaxEsReturn                80
2017-07-02 12:41:51.949238 EDT | MinEsReturn                 2
2017-07-02 12:41:51.949457 EDT | AverageDiscountedReturn    99.9957
2017-07-02 12:41:51.949677 EDT | AverageQLoss                0.00145469
2017-07-02 12:41:51.949864 EDT | AveragePolicySurr          -0.519624
2017-07-02 12:41:51.950087 EDT | AverageQ                    0.461747
2017-07-02 12:41:51.950309 EDT | AverageAbsQ                 0.463547
2017-07-02 12:41:51.950532 EDT | AverageY                    0.461741
2017-07-02 12:41:51.950732 EDT | AverageAbsY                 0.462402
2017-07-02 12:41:51.950877 EDT | AverageAbsQYDiff            0.0166469
2017-07-02 12:41:51.951055 EDT | AverageAction               0.575575
2017-07-02 12:41:51.951277 EDT | PolicyRegParamNorm         29.0192
2017-07-02 12:41:51.951487 EDT | QFunRegParamNorm           26.2637
2017-07-02 12:41:51.951724 EDT | -----------------------  -------------
2017-07-02 12:41:51.952046 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #61 | Training started
2017-07-02 12:42:01.517072 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #61 | Training finished
2017-07-02 12:42:01.517639 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #61 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 12:42:01.517918 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #61 | Collecting samples for evaluation
2017-07-02 12:42:07.183871 EDT | -----------------------  -------------
2017-07-02 12:42:07.184242 EDT | Epoch                      61
2017-07-02 12:42:07.184453 EDT | Iteration                  61
2017-07-02 12:42:07.184646 EDT | AverageReturn            1000
2017-07-02 12:42:07.184762 EDT | StdReturn                   0
2017-07-02 12:42:07.184871 EDT | MaxReturn                1000
2017-07-02 12:42:07.184979 EDT | MinReturn                1000
2017-07-02 12:42:07.185086 EDT | AverageEsReturn            13.5753
2017-07-02 12:42:07.185192 EDT | StdEsReturn                12.0387
2017-07-02 12:42:07.185298 EDT | MaxEsReturn                77
2017-07-02 12:42:07.185404 EDT | MinEsReturn                 3
2017-07-02 12:42:07.185526 EDT | AverageDiscountedReturn    99.9957
2017-07-02 12:42:07.185692 EDT | AverageQLoss                0.00136731
2017-07-02 12:42:07.185912 EDT | AveragePolicySurr          -0.528531
2017-07-02 12:42:07.186124 EDT | AverageQ                    0.471168
2017-07-02 12:42:07.186352 EDT | AverageAbsQ                 0.473129
2017-07-02 12:42:07.186573 EDT | AverageY                    0.471187
2017-07-02 12:42:07.186774 EDT | AverageAbsY                 0.471993
2017-07-02 12:42:07.186955 EDT | AverageAbsQYDiff            0.0160815
2017-07-02 12:42:07.187093 EDT | AverageAction               0.608903
2017-07-02 12:42:07.187198 EDT | PolicyRegParamNorm         29.2591
2017-07-02 12:42:07.187338 EDT | QFunRegParamNorm           26.4633
2017-07-02 12:42:07.187479 EDT | -----------------------  -------------
2017-07-02 12:42:07.187663 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #62 | Training started
2017-07-02 12:42:16.850181 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #62 | Training finished
2017-07-02 12:42:16.850663 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #62 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 12:42:16.850824 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #62 | Collecting samples for evaluation
2017-07-02 12:42:22.564688 EDT | -----------------------  -------------
2017-07-02 12:42:22.564899 EDT | Epoch                      62
2017-07-02 12:42:22.565100 EDT | Iteration                  62
2017-07-02 12:42:22.565268 EDT | AverageReturn            1000
2017-07-02 12:42:22.565384 EDT | StdReturn                   0
2017-07-02 12:42:22.565501 EDT | MaxReturn                1000
2017-07-02 12:42:22.565644 EDT | MinReturn                1000
2017-07-02 12:42:22.565797 EDT | AverageEsReturn            21.5217
2017-07-02 12:42:22.566022 EDT | StdEsReturn                15.3109
2017-07-02 12:42:22.566236 EDT | MaxEsReturn                64
2017-07-02 12:42:22.566424 EDT | MinEsReturn                 4
2017-07-02 12:42:22.566651 EDT | AverageDiscountedReturn    99.9957
2017-07-02 12:42:22.566870 EDT | AverageQLoss                0.00171683
2017-07-02 12:42:22.566996 EDT | AveragePolicySurr          -0.536935
2017-07-02 12:42:22.567149 EDT | AverageQ                    0.479946
2017-07-02 12:42:22.567279 EDT | AverageAbsQ                 0.482193
2017-07-02 12:42:22.567405 EDT | AverageY                    0.479969
2017-07-02 12:42:22.567541 EDT | AverageAbsY                 0.480765
2017-07-02 12:42:22.567648 EDT | AverageAbsQYDiff            0.0179559
2017-07-02 12:42:22.567757 EDT | AverageAction               0.59477
2017-07-02 12:42:22.567860 EDT | PolicyRegParamNorm         29.404
2017-07-02 12:42:22.567961 EDT | QFunRegParamNorm           26.6071
2017-07-02 12:42:22.568078 EDT | -----------------------  -------------
2017-07-02 12:42:22.568267 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #63 | Training started
2017-07-02 12:42:32.208463 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #63 | Training finished
2017-07-02 12:42:32.209171 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #63 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 12:42:32.209332 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #63 | Collecting samples for evaluation
2017-07-02 12:42:37.934305 EDT | -----------------------  -------------
2017-07-02 12:42:37.934568 EDT | Epoch                      63
2017-07-02 12:42:37.934782 EDT | Iteration                  63
2017-07-02 12:42:37.935010 EDT | AverageReturn            1000
2017-07-02 12:42:37.935175 EDT | StdReturn                   0
2017-07-02 12:42:37.935398 EDT | MaxReturn                1000
2017-07-02 12:42:37.935597 EDT | MinReturn                1000
2017-07-02 12:42:37.935743 EDT | AverageEsReturn            15.873
2017-07-02 12:42:37.935852 EDT | StdEsReturn                10.6062
2017-07-02 12:42:37.935956 EDT | MaxEsReturn                45
2017-07-02 12:42:37.936124 EDT | MinEsReturn                 3
2017-07-02 12:42:37.936322 EDT | AverageDiscountedReturn    99.9957
2017-07-02 12:42:37.936515 EDT | AverageQLoss                0.00152711
2017-07-02 12:42:37.936734 EDT | AveragePolicySurr          -0.545802
2017-07-02 12:42:37.936951 EDT | AverageQ                    0.486894
2017-07-02 12:42:37.937155 EDT | AverageAbsQ                 0.488704
2017-07-02 12:42:37.937379 EDT | AverageY                    0.486886
2017-07-02 12:42:37.937668 EDT | AverageAbsY                 0.487552
2017-07-02 12:42:37.937906 EDT | AverageAbsQYDiff            0.0167566
2017-07-02 12:42:37.938135 EDT | AverageAction               0.571933
2017-07-02 12:42:37.938363 EDT | PolicyRegParamNorm         29.5703
2017-07-02 12:42:37.938567 EDT | QFunRegParamNorm           26.7759
2017-07-02 12:42:37.938790 EDT | -----------------------  -------------
2017-07-02 12:42:37.939113 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #64 | Training started
2017-07-02 12:42:47.531479 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #64 | Training finished
2017-07-02 12:42:47.532041 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #64 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 12:42:47.532238 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #64 | Collecting samples for evaluation
2017-07-02 12:42:53.270656 EDT | -----------------------  -------------
2017-07-02 12:42:53.270926 EDT | Epoch                      64
2017-07-02 12:42:53.271124 EDT | Iteration                  64
2017-07-02 12:42:53.271329 EDT | AverageReturn            1000
2017-07-02 12:42:53.271451 EDT | StdReturn                   0
2017-07-02 12:42:53.271573 EDT | MaxReturn                1000
2017-07-02 12:42:53.271765 EDT | MinReturn                1000
2017-07-02 12:42:53.271873 EDT | AverageEsReturn            16.371
2017-07-02 12:42:53.272000 EDT | StdEsReturn                13.3878
2017-07-02 12:42:53.272169 EDT | MaxEsReturn                72
2017-07-02 12:42:53.272372 EDT | MinEsReturn                 3
2017-07-02 12:42:53.272523 EDT | AverageDiscountedReturn    99.9957
2017-07-02 12:42:53.272747 EDT | AverageQLoss                0.00157585
2017-07-02 12:42:53.272972 EDT | AveragePolicySurr          -0.556249
2017-07-02 12:42:53.273143 EDT | AverageQ                    0.495635
2017-07-02 12:42:53.273340 EDT | AverageAbsQ                 0.497748
2017-07-02 12:42:53.273600 EDT | AverageY                    0.49568
2017-07-02 12:42:53.273785 EDT | AverageAbsY                 0.496507
2017-07-02 12:42:53.273891 EDT | AverageAbsQYDiff            0.0172885
2017-07-02 12:42:53.273993 EDT | AverageAction               0.563887
2017-07-02 12:42:53.274113 EDT | PolicyRegParamNorm         29.8082
2017-07-02 12:42:53.274316 EDT | QFunRegParamNorm           26.9827
2017-07-02 12:42:53.274528 EDT | -----------------------  -------------
2017-07-02 12:42:53.274853 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #65 | Training started
2017-07-02 12:43:02.682870 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #65 | Training finished
2017-07-02 12:43:02.683504 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #65 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 12:43:02.683706 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #65 | Collecting samples for evaluation
2017-07-02 12:43:08.376015 EDT | -----------------------  -------------
2017-07-02 12:43:08.376253 EDT | Epoch                      65
2017-07-02 12:43:08.376364 EDT | Iteration                  65
2017-07-02 12:43:08.376540 EDT | AverageReturn            1000
2017-07-02 12:43:08.376818 EDT | StdReturn                   0
2017-07-02 12:43:08.376999 EDT | MaxReturn                1000
2017-07-02 12:43:08.377208 EDT | MinReturn                1000
2017-07-02 12:43:08.377336 EDT | AverageEsReturn            14.1571
2017-07-02 12:43:08.377461 EDT | StdEsReturn                12.887
2017-07-02 12:43:08.377647 EDT | MaxEsReturn                96
2017-07-02 12:43:08.377774 EDT | MinEsReturn                 3
2017-07-02 12:43:08.377923 EDT | AverageDiscountedReturn    99.9957
2017-07-02 12:43:08.378061 EDT | AverageQLoss                0.00160136
2017-07-02 12:43:08.378201 EDT | AveragePolicySurr          -0.56646
2017-07-02 12:43:08.378313 EDT | AverageQ                    0.505706
2017-07-02 12:43:08.378432 EDT | AverageAbsQ                 0.507756
2017-07-02 12:43:08.378584 EDT | AverageY                    0.505755
2017-07-02 12:43:08.378693 EDT | AverageAbsY                 0.506766
2017-07-02 12:43:08.378812 EDT | AverageAbsQYDiff            0.017395
2017-07-02 12:43:08.379085 EDT | AverageAction               0.547486
2017-07-02 12:43:08.379279 EDT | PolicyRegParamNorm         29.9217
2017-07-02 12:43:08.379470 EDT | QFunRegParamNorm           27.199
2017-07-02 12:43:08.379686 EDT | -----------------------  -------------
2017-07-02 12:43:08.379991 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #66 | Training started
2017-07-02 12:43:17.916618 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #66 | Training finished
2017-07-02 12:43:17.917188 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #66 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 12:43:17.917442 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #66 | Collecting samples for evaluation
2017-07-02 12:43:23.660120 EDT | -----------------------  -------------
2017-07-02 12:43:23.660391 EDT | Epoch                      66
2017-07-02 12:43:23.660510 EDT | Iteration                  66
2017-07-02 12:43:23.660633 EDT | AverageReturn            1000
2017-07-02 12:43:23.660761 EDT | StdReturn                   0
2017-07-02 12:43:23.660870 EDT | MaxReturn                1000
2017-07-02 12:43:23.661006 EDT | MinReturn                1000
2017-07-02 12:43:23.661114 EDT | AverageEsReturn            18.2182
2017-07-02 12:43:23.661253 EDT | StdEsReturn                16.3248
2017-07-02 12:43:23.661360 EDT | MaxEsReturn                91
2017-07-02 12:43:23.661473 EDT | MinEsReturn                 3
2017-07-02 12:43:23.661669 EDT | AverageDiscountedReturn    99.9957
2017-07-02 12:43:23.661856 EDT | AverageQLoss                0.00194124
2017-07-02 12:43:23.662072 EDT | AveragePolicySurr          -0.575154
2017-07-02 12:43:23.662291 EDT | AverageQ                    0.511867
2017-07-02 12:43:23.662501 EDT | AverageAbsQ                 0.514422
2017-07-02 12:43:23.662719 EDT | AverageY                    0.511906
2017-07-02 12:43:23.662848 EDT | AverageAbsY                 0.513429
2017-07-02 12:43:23.662982 EDT | AverageAbsQYDiff            0.0191987
2017-07-02 12:43:23.663130 EDT | AverageAction               0.600182
2017-07-02 12:43:23.663251 EDT | PolicyRegParamNorm         30.1418
2017-07-02 12:43:23.663358 EDT | QFunRegParamNorm           27.4167
2017-07-02 12:43:23.663464 EDT | -----------------------  -------------
2017-07-02 12:43:23.663634 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #67 | Training started
2017-07-02 12:43:33.282833 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #67 | Training finished
2017-07-02 12:43:33.283420 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #67 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 12:43:33.283601 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #67 | Collecting samples for evaluation
2017-07-02 12:43:38.967287 EDT | -----------------------  -------------
2017-07-02 12:43:38.967695 EDT | Epoch                      67
2017-07-02 12:43:38.967950 EDT | Iteration                  67
2017-07-02 12:43:38.968202 EDT | AverageReturn            1000
2017-07-02 12:43:38.968375 EDT | StdReturn                   0
2017-07-02 12:43:38.968519 EDT | MaxReturn                1000
2017-07-02 12:43:38.968623 EDT | MinReturn                1000
2017-07-02 12:43:38.968771 EDT | AverageEsReturn            12.9231
2017-07-02 12:43:38.968981 EDT | StdEsReturn                 9.86027
2017-07-02 12:43:38.969123 EDT | MaxEsReturn                46
2017-07-02 12:43:38.969252 EDT | MinEsReturn                 3
2017-07-02 12:43:38.969421 EDT | AverageDiscountedReturn    99.9957
2017-07-02 12:43:38.969694 EDT | AverageQLoss                0.00188018
2017-07-02 12:43:38.969825 EDT | AveragePolicySurr          -0.58564
2017-07-02 12:43:38.969979 EDT | AverageQ                    0.522217
2017-07-02 12:43:38.970109 EDT | AverageAbsQ                 0.525118
2017-07-02 12:43:38.970221 EDT | AverageY                    0.522252
2017-07-02 12:43:38.970355 EDT | AverageAbsY                 0.523714
2017-07-02 12:43:38.970490 EDT | AverageAbsQYDiff            0.018891
2017-07-02 12:43:38.970626 EDT | AverageAction               0.522998
2017-07-02 12:43:38.970735 EDT | PolicyRegParamNorm         30.268
2017-07-02 12:43:38.970865 EDT | QFunRegParamNorm           27.63
2017-07-02 12:43:38.970972 EDT | -----------------------  -------------
2017-07-02 12:43:38.971147 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #68 | Training started
2017-07-02 12:43:48.550138 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #68 | Training finished
2017-07-02 12:43:48.550371 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #68 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 12:43:48.550577 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #68 | Collecting samples for evaluation
2017-07-02 12:43:54.255058 EDT | -----------------------  -------------
2017-07-02 12:43:54.255572 EDT | Epoch                      68
2017-07-02 12:43:54.255717 EDT | Iteration                  68
2017-07-02 12:43:54.255930 EDT | AverageReturn            1000
2017-07-02 12:43:54.256053 EDT | StdReturn                   0
2017-07-02 12:43:54.256167 EDT | MaxReturn                1000
2017-07-02 12:43:54.256347 EDT | MinReturn                1000
2017-07-02 12:43:54.256455 EDT | AverageEsReturn            14.2143
2017-07-02 12:43:54.256598 EDT | StdEsReturn                10.9765
2017-07-02 12:43:54.256706 EDT | MaxEsReturn                49
2017-07-02 12:43:54.256847 EDT | MinEsReturn                 3
2017-07-02 12:43:54.256950 EDT | AverageDiscountedReturn    99.9957
2017-07-02 12:43:54.257083 EDT | AverageQLoss                0.00190868
2017-07-02 12:43:54.257260 EDT | AveragePolicySurr          -0.597333
2017-07-02 12:43:54.257449 EDT | AverageQ                    0.533143
2017-07-02 12:43:54.257668 EDT | AverageAbsQ                 0.535763
2017-07-02 12:43:54.257837 EDT | AverageY                    0.533171
2017-07-02 12:43:54.258020 EDT | AverageAbsY                 0.534469
2017-07-02 12:43:54.258176 EDT | AverageAbsQYDiff            0.0188727
2017-07-02 12:43:54.258281 EDT | AverageAction               0.455882
2017-07-02 12:43:54.258382 EDT | PolicyRegParamNorm         30.4531
2017-07-02 12:43:54.258484 EDT | QFunRegParamNorm           27.7576
2017-07-02 12:43:54.258584 EDT | -----------------------  -------------
2017-07-02 12:43:54.258792 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #69 | Training started
2017-07-02 12:44:03.833511 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #69 | Training finished
2017-07-02 12:44:03.834320 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #69 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 12:44:03.834490 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #69 | Collecting samples for evaluation
2017-07-02 12:44:09.594151 EDT | -----------------------  -------------
2017-07-02 12:44:09.594462 EDT | Epoch                      69
2017-07-02 12:44:09.594681 EDT | Iteration                  69
2017-07-02 12:44:09.594911 EDT | AverageReturn            1000
2017-07-02 12:44:09.595063 EDT | StdReturn                   0
2017-07-02 12:44:09.595261 EDT | MaxReturn                1000
2017-07-02 12:44:09.595489 EDT | MinReturn                1000
2017-07-02 12:44:09.595689 EDT | AverageEsReturn            18.2
2017-07-02 12:44:09.595918 EDT | StdEsReturn                17.4057
2017-07-02 12:44:09.596145 EDT | MaxEsReturn                76
2017-07-02 12:44:09.596259 EDT | MinEsReturn                 3
2017-07-02 12:44:09.596363 EDT | AverageDiscountedReturn    99.9957
2017-07-02 12:44:09.596616 EDT | AverageQLoss                0.00206312
2017-07-02 12:44:09.596916 EDT | AveragePolicySurr          -0.608359
2017-07-02 12:44:09.597203 EDT | AverageQ                    0.545625
2017-07-02 12:44:09.597454 EDT | AverageAbsQ                 0.547901
2017-07-02 12:44:09.597705 EDT | AverageY                    0.545655
2017-07-02 12:44:09.597926 EDT | AverageAbsY                 0.546645
2017-07-02 12:44:09.598062 EDT | AverageAbsQYDiff            0.0195162
2017-07-02 12:44:09.598292 EDT | AverageAction               0.560269
2017-07-02 12:44:09.598502 EDT | PolicyRegParamNorm         30.5723
2017-07-02 12:44:09.598611 EDT | QFunRegParamNorm           27.9388
2017-07-02 12:44:09.598714 EDT | -----------------------  -------------
2017-07-02 12:44:09.598932 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #70 | Training started
2017-07-02 12:44:19.095804 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #70 | Training finished
2017-07-02 12:44:19.096014 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #70 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 12:44:19.096249 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #70 | Collecting samples for evaluation
2017-07-02 12:44:24.868977 EDT | -----------------------  -------------
2017-07-02 12:44:24.869469 EDT | Epoch                      70
2017-07-02 12:44:24.869717 EDT | Iteration                  70
2017-07-02 12:44:24.869946 EDT | AverageReturn            1000
2017-07-02 12:44:24.870162 EDT | StdReturn                   0
2017-07-02 12:44:24.870385 EDT | MaxReturn                1000
2017-07-02 12:44:24.870620 EDT | MinReturn                1000
2017-07-02 12:44:24.870838 EDT | AverageEsReturn            18.9434
2017-07-02 12:44:24.871060 EDT | StdEsReturn                19.1079
2017-07-02 12:44:24.871278 EDT | MaxEsReturn               113
2017-07-02 12:44:24.871487 EDT | MinEsReturn                 3
2017-07-02 12:44:24.871703 EDT | AverageDiscountedReturn    99.9957
2017-07-02 12:44:24.871908 EDT | AverageQLoss                0.00197889
2017-07-02 12:44:24.872123 EDT | AveragePolicySurr          -0.62012
2017-07-02 12:44:24.872353 EDT | AverageQ                    0.553035
2017-07-02 12:44:24.872575 EDT | AverageAbsQ                 0.555405
2017-07-02 12:44:24.872797 EDT | AverageY                    0.553079
2017-07-02 12:44:24.873009 EDT | AverageAbsY                 0.553945
2017-07-02 12:44:24.873134 EDT | AverageAbsQYDiff            0.0190057
2017-07-02 12:44:24.873239 EDT | AverageAction               0.509237
2017-07-02 12:44:24.873342 EDT | PolicyRegParamNorm         30.7289
2017-07-02 12:44:24.873757 EDT | QFunRegParamNorm           28.0397
2017-07-02 12:44:24.873981 EDT | -----------------------  -------------
2017-07-02 12:44:24.874308 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #71 | Training started
2017-07-02 12:44:34.277736 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #71 | Training finished
2017-07-02 12:44:34.278245 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #71 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 12:44:34.278392 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #71 | Collecting samples for evaluation
2017-07-02 12:44:40.049432 EDT | -----------------------  -------------
2017-07-02 12:44:40.049719 EDT | Epoch                      71
2017-07-02 12:44:40.049871 EDT | Iteration                  71
2017-07-02 12:44:40.050045 EDT | AverageReturn            1000
2017-07-02 12:44:40.050201 EDT | StdReturn                   0
2017-07-02 12:44:40.050314 EDT | MaxReturn                1000
2017-07-02 12:44:40.050489 EDT | MinReturn                1000
2017-07-02 12:44:40.050681 EDT | AverageEsReturn            15.2308
2017-07-02 12:44:40.050881 EDT | StdEsReturn                16.8155
2017-07-02 12:44:40.051087 EDT | MaxEsReturn               106
2017-07-02 12:44:40.051288 EDT | MinEsReturn                 3
2017-07-02 12:44:40.051467 EDT | AverageDiscountedReturn    99.9957
2017-07-02 12:44:40.051610 EDT | AverageQLoss                0.00206301
2017-07-02 12:44:40.051726 EDT | AveragePolicySurr          -0.633226
2017-07-02 12:44:40.051857 EDT | AverageQ                    0.564644
2017-07-02 12:44:40.052038 EDT | AverageAbsQ                 0.566962
2017-07-02 12:44:40.052164 EDT | AverageY                    0.564697
2017-07-02 12:44:40.052361 EDT | AverageAbsY                 0.565422
2017-07-02 12:44:40.052555 EDT | AverageAbsQYDiff            0.0200126
2017-07-02 12:44:40.052744 EDT | AverageAction               0.491234
2017-07-02 12:44:40.052908 EDT | PolicyRegParamNorm         30.8608
2017-07-02 12:44:40.053102 EDT | QFunRegParamNorm           28.1869
2017-07-02 12:44:40.053290 EDT | -----------------------  -------------
2017-07-02 12:44:40.053613 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #72 | Training started
2017-07-02 12:44:49.768360 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #72 | Training finished
2017-07-02 12:44:49.768654 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #72 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 12:44:49.768892 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #72 | Collecting samples for evaluation
2017-07-02 12:44:55.404513 EDT | -----------------------  -------------
2017-07-02 12:44:55.405034 EDT | Epoch                      72
2017-07-02 12:44:55.405291 EDT | Iteration                  72
2017-07-02 12:44:55.405517 EDT | AverageReturn            1000
2017-07-02 12:44:55.405749 EDT | StdReturn                   0
2017-07-02 12:44:55.405972 EDT | MaxReturn                1000
2017-07-02 12:44:55.406192 EDT | MinReturn                1000
2017-07-02 12:44:55.406413 EDT | AverageEsReturn            16.8814
2017-07-02 12:44:55.406618 EDT | StdEsReturn                14.5603
2017-07-02 12:44:55.406811 EDT | MaxEsReturn                68
2017-07-02 12:44:55.407026 EDT | MinEsReturn                 3
2017-07-02 12:44:55.407213 EDT | AverageDiscountedReturn    99.9957
2017-07-02 12:44:55.407444 EDT | AverageQLoss                0.00239509
2017-07-02 12:44:55.407664 EDT | AveragePolicySurr          -0.648421
2017-07-02 12:44:55.407881 EDT | AverageQ                    0.579226
2017-07-02 12:44:55.408091 EDT | AverageAbsQ                 0.581491
2017-07-02 12:44:55.408255 EDT | AverageY                    0.579239
2017-07-02 12:44:55.408471 EDT | AverageAbsY                 0.579881
2017-07-02 12:44:55.408642 EDT | AverageAbsQYDiff            0.0212795
2017-07-02 12:44:55.408854 EDT | AverageAction               0.452545
2017-07-02 12:44:55.409071 EDT | PolicyRegParamNorm         30.9559
2017-07-02 12:44:55.409288 EDT | QFunRegParamNorm           28.3332
2017-07-02 12:44:55.409481 EDT | -----------------------  -------------
2017-07-02 12:44:55.409737 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #73 | Training started
2017-07-02 12:45:05.080744 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #73 | Training finished
2017-07-02 12:45:05.081253 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #73 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 12:45:05.081395 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #73 | Collecting samples for evaluation
2017-07-02 12:45:10.632501 EDT | -----------------------  -------------
2017-07-02 12:45:10.632707 EDT | Epoch                      73
2017-07-02 12:45:10.632864 EDT | Iteration                  73
2017-07-02 12:45:10.633012 EDT | AverageReturn            1000
2017-07-02 12:45:10.633143 EDT | StdReturn                   0
2017-07-02 12:45:10.633249 EDT | MaxReturn                1000
2017-07-02 12:45:10.633360 EDT | MinReturn                1000
2017-07-02 12:45:10.633518 EDT | AverageEsReturn            16.7333
2017-07-02 12:45:10.633668 EDT | StdEsReturn                17.9238
2017-07-02 12:45:10.633771 EDT | MaxEsReturn                99
2017-07-02 12:45:10.633873 EDT | MinEsReturn                 3
2017-07-02 12:45:10.633996 EDT | AverageDiscountedReturn    99.9957
2017-07-02 12:45:10.634205 EDT | AverageQLoss                0.00248107
2017-07-02 12:45:10.634380 EDT | AveragePolicySurr          -0.662032
2017-07-02 12:45:10.634554 EDT | AverageQ                    0.591332
2017-07-02 12:45:10.634659 EDT | AverageAbsQ                 0.593586
2017-07-02 12:45:10.634788 EDT | AverageY                    0.591359
2017-07-02 12:45:10.634889 EDT | AverageAbsY                 0.592053
2017-07-02 12:45:10.634991 EDT | AverageAbsQYDiff            0.0212206
2017-07-02 12:45:10.635131 EDT | AverageAction               0.440875
2017-07-02 12:45:10.635232 EDT | PolicyRegParamNorm         31.1711
2017-07-02 12:45:10.635352 EDT | QFunRegParamNorm           28.4999
2017-07-02 12:45:10.635460 EDT | -----------------------  -------------
2017-07-02 12:45:10.635635 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #74 | Training started
2017-07-02 12:45:20.690477 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #74 | Training finished
2017-07-02 12:45:20.690763 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #74 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 12:45:20.690881 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #74 | Collecting samples for evaluation
2017-07-02 12:45:26.570654 EDT | -----------------------  -------------
2017-07-02 12:45:26.571175 EDT | Epoch                      74
2017-07-02 12:45:26.571327 EDT | Iteration                  74
2017-07-02 12:45:26.571539 EDT | AverageReturn            1000
2017-07-02 12:45:26.571752 EDT | StdReturn                   0
2017-07-02 12:45:26.571930 EDT | MaxReturn                1000
2017-07-02 12:45:26.572062 EDT | MinReturn                1000
2017-07-02 12:45:26.572212 EDT | AverageEsReturn            14.5224
2017-07-02 12:45:26.572327 EDT | StdEsReturn                14.0621
2017-07-02 12:45:26.572526 EDT | MaxEsReturn                68
2017-07-02 12:45:26.572722 EDT | MinEsReturn                 3
2017-07-02 12:45:26.572850 EDT | AverageDiscountedReturn    99.9957
2017-07-02 12:45:26.572973 EDT | AverageQLoss                0.00239248
2017-07-02 12:45:26.573083 EDT | AveragePolicySurr          -0.682565
2017-07-02 12:45:26.573185 EDT | AverageQ                    0.60694
2017-07-02 12:45:26.573285 EDT | AverageAbsQ                 0.609325
2017-07-02 12:45:26.573441 EDT | AverageY                    0.607075
2017-07-02 12:45:26.573587 EDT | AverageAbsY                 0.607663
2017-07-02 12:45:26.573688 EDT | AverageAbsQYDiff            0.0208944
2017-07-02 12:45:26.573787 EDT | AverageAction               0.337692
2017-07-02 12:45:26.573886 EDT | PolicyRegParamNorm         31.3028
2017-07-02 12:45:26.574001 EDT | QFunRegParamNorm           28.6389
2017-07-02 12:45:26.574101 EDT | -----------------------  -------------
2017-07-02 12:45:26.574328 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #75 | Training started
2017-07-02 12:45:36.259730 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #75 | Training finished
2017-07-02 12:45:36.260287 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #75 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 12:45:36.260528 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #75 | Collecting samples for evaluation
2017-07-02 12:45:41.955106 EDT | -----------------------  -------------
2017-07-02 12:45:41.955305 EDT | Epoch                      75
2017-07-02 12:45:41.955459 EDT | Iteration                  75
2017-07-02 12:45:41.955567 EDT | AverageReturn            1000
2017-07-02 12:45:41.955705 EDT | StdReturn                   0
2017-07-02 12:45:41.955812 EDT | MaxReturn                1000
2017-07-02 12:45:41.955920 EDT | MinReturn                1000
2017-07-02 12:45:41.956114 EDT | AverageEsReturn            19.3774
2017-07-02 12:45:41.956244 EDT | StdEsReturn                21.9556
2017-07-02 12:45:41.956385 EDT | MaxEsReturn               108
2017-07-02 12:45:41.956492 EDT | MinEsReturn                 3
2017-07-02 12:45:41.956606 EDT | AverageDiscountedReturn    99.9957
2017-07-02 12:45:41.956763 EDT | AverageQLoss                0.00243894
2017-07-02 12:45:41.956891 EDT | AveragePolicySurr          -0.703648
2017-07-02 12:45:41.957033 EDT | AverageQ                    0.625849
2017-07-02 12:45:41.957175 EDT | AverageAbsQ                 0.627733
2017-07-02 12:45:41.957294 EDT | AverageY                    0.625872
2017-07-02 12:45:41.958801 EDT | AverageAbsY                 0.626307
2017-07-02 12:45:41.959005 EDT | AverageAbsQYDiff            0.0212111
2017-07-02 12:45:41.959129 EDT | AverageAction               0.417018
2017-07-02 12:45:41.959299 EDT | PolicyRegParamNorm         31.3537
2017-07-02 12:45:41.959420 EDT | QFunRegParamNorm           28.7534
2017-07-02 12:45:41.959601 EDT | -----------------------  -------------
2017-07-02 12:45:41.959809 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #76 | Training started
2017-07-02 12:45:51.543737 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #76 | Training finished
2017-07-02 12:45:51.544023 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #76 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 12:45:51.544262 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #76 | Collecting samples for evaluation
2017-07-02 12:45:57.211683 EDT | -----------------------  -------------
2017-07-02 12:45:57.224727 EDT | Epoch                      76
2017-07-02 12:45:57.224999 EDT | Iteration                  76
2017-07-02 12:45:57.225134 EDT | AverageReturn            1000
2017-07-02 12:45:57.225247 EDT | StdReturn                   0
2017-07-02 12:45:57.225353 EDT | MaxReturn                1000
2017-07-02 12:45:57.225512 EDT | MinReturn                1000
2017-07-02 12:45:57.225727 EDT | AverageEsReturn            16.5902
2017-07-02 12:45:57.225901 EDT | StdEsReturn                15.5988
2017-07-02 12:45:57.226006 EDT | MaxEsReturn                63
2017-07-02 12:45:57.226139 EDT | MinEsReturn                 3
2017-07-02 12:45:57.226256 EDT | AverageDiscountedReturn    99.9957
2017-07-02 12:45:57.226406 EDT | AverageQLoss                0.00270508
2017-07-02 12:45:57.226511 EDT | AveragePolicySurr          -0.724546
2017-07-02 12:45:57.226639 EDT | AverageQ                    0.643633
2017-07-02 12:45:57.226817 EDT | AverageAbsQ                 0.645818
2017-07-02 12:45:57.226984 EDT | AverageY                    0.643649
2017-07-02 12:45:57.227088 EDT | AverageAbsY                 0.644343
2017-07-02 12:45:57.227190 EDT | AverageAbsQYDiff            0.0235123
2017-07-02 12:45:57.227291 EDT | AverageAction               0.45158
2017-07-02 12:45:57.227425 EDT | PolicyRegParamNorm         31.4155
2017-07-02 12:45:57.227533 EDT | QFunRegParamNorm           28.9882
2017-07-02 12:45:57.227632 EDT | -----------------------  -------------
2017-07-02 12:45:57.227824 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #77 | Training started
2017-07-02 12:46:06.765970 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #77 | Training finished
2017-07-02 12:46:06.766498 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #77 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 12:46:06.766650 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #77 | Collecting samples for evaluation
2017-07-02 12:46:12.498522 EDT | -----------------------  -------------
2017-07-02 12:46:12.498712 EDT | Epoch                      77
2017-07-02 12:46:12.498863 EDT | Iteration                  77
2017-07-02 12:46:12.498969 EDT | AverageReturn            1000
2017-07-02 12:46:12.499084 EDT | StdReturn                   0
2017-07-02 12:46:12.499244 EDT | MaxReturn                1000
2017-07-02 12:46:12.499379 EDT | MinReturn                1000
2017-07-02 12:46:12.499502 EDT | AverageEsReturn            18.2778
2017-07-02 12:46:12.499642 EDT | StdEsReturn                15.8154
2017-07-02 12:46:12.499874 EDT | MaxEsReturn                70
2017-07-02 12:46:12.500106 EDT | MinEsReturn                 3
2017-07-02 12:46:12.500334 EDT | AverageDiscountedReturn    99.9957
2017-07-02 12:46:12.500561 EDT | AverageQLoss                0.00320976
2017-07-02 12:46:12.500781 EDT | AveragePolicySurr          -0.752451
2017-07-02 12:46:12.500981 EDT | AverageQ                    0.666701
2017-07-02 12:46:12.501206 EDT | AverageAbsQ                 0.669008
2017-07-02 12:46:12.501404 EDT | AverageY                    0.666825
2017-07-02 12:46:12.501692 EDT | AverageAbsY                 0.667461
2017-07-02 12:46:12.501907 EDT | AverageAbsQYDiff            0.0241366
2017-07-02 12:46:12.502128 EDT | AverageAction               0.40641
2017-07-02 12:46:12.502357 EDT | PolicyRegParamNorm         31.544
2017-07-02 12:46:12.502590 EDT | QFunRegParamNorm           29.1433
2017-07-02 12:46:12.502811 EDT | -----------------------  -------------
2017-07-02 12:46:12.503134 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #78 | Training started
2017-07-02 12:46:22.002383 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #78 | Training finished
2017-07-02 12:46:22.002688 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #78 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 12:46:22.002923 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #78 | Collecting samples for evaluation
2017-07-02 12:46:27.711383 EDT | -----------------------  -------------
2017-07-02 12:46:27.711985 EDT | Epoch                      78
2017-07-02 12:46:27.712220 EDT | Iteration                  78
2017-07-02 12:46:27.712421 EDT | AverageReturn            1000
2017-07-02 12:46:27.712570 EDT | StdReturn                   0
2017-07-02 12:46:27.712684 EDT | MaxReturn                1000
2017-07-02 12:46:27.712881 EDT | MinReturn                1000
2017-07-02 12:46:27.713040 EDT | AverageEsReturn            21.1458
2017-07-02 12:46:27.713172 EDT | StdEsReturn                23.066
2017-07-02 12:46:27.713286 EDT | MaxEsReturn               131
2017-07-02 12:46:27.713468 EDT | MinEsReturn                 3
2017-07-02 12:46:27.713654 EDT | AverageDiscountedReturn    99.9957
2017-07-02 12:46:27.713840 EDT | AverageQLoss                0.00312258
2017-07-02 12:46:27.714047 EDT | AveragePolicySurr          -0.778679
2017-07-02 12:46:27.714172 EDT | AverageQ                    0.68911
2017-07-02 12:46:27.714275 EDT | AverageAbsQ                 0.69142
2017-07-02 12:46:27.714445 EDT | AverageY                    0.689168
2017-07-02 12:46:27.714565 EDT | AverageAbsY                 0.689534
2017-07-02 12:46:27.714710 EDT | AverageAbsQYDiff            0.0244914
2017-07-02 12:46:27.714859 EDT | AverageAction               0.384889
2017-07-02 12:46:27.715039 EDT | PolicyRegParamNorm         31.6381
2017-07-02 12:46:27.715219 EDT | QFunRegParamNorm           29.3176
2017-07-02 12:46:27.715331 EDT | -----------------------  -------------
2017-07-02 12:46:27.715529 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #79 | Training started
2017-07-02 12:46:37.243407 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #79 | Training finished
2017-07-02 12:46:37.243997 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #79 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 12:46:37.244252 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #79 | Collecting samples for evaluation
2017-07-02 12:46:42.874456 EDT | -----------------------  ------------
2017-07-02 12:46:42.874714 EDT | Epoch                      79
2017-07-02 12:46:42.874834 EDT | Iteration                  79
2017-07-02 12:46:42.875012 EDT | AverageReturn            1000
2017-07-02 12:46:42.875122 EDT | StdReturn                   0
2017-07-02 12:46:42.875306 EDT | MaxReturn                1000
2017-07-02 12:46:42.875521 EDT | MinReturn                1000
2017-07-02 12:46:42.875701 EDT | AverageEsReturn            16.3279
2017-07-02 12:46:42.875924 EDT | StdEsReturn                16.7251
2017-07-02 12:46:42.876132 EDT | MaxEsReturn                74
2017-07-02 12:46:42.876368 EDT | MinEsReturn                 2
2017-07-02 12:46:42.876595 EDT | AverageDiscountedReturn    99.9957
2017-07-02 12:46:42.876815 EDT | AverageQLoss                0.0035877
2017-07-02 12:46:42.877035 EDT | AveragePolicySurr          -0.804857
2017-07-02 12:46:42.877252 EDT | AverageQ                    0.713432
2017-07-02 12:46:42.877429 EDT | AverageAbsQ                 0.715856
2017-07-02 12:46:42.877562 EDT | AverageY                    0.713503
2017-07-02 12:46:42.877666 EDT | AverageAbsY                 0.713976
2017-07-02 12:46:42.877768 EDT | AverageAbsQYDiff            0.0260039
2017-07-02 12:46:42.877869 EDT | AverageAction               0.367013
2017-07-02 12:46:42.877969 EDT | PolicyRegParamNorm         31.7504
2017-07-02 12:46:42.878070 EDT | QFunRegParamNorm           29.4634
2017-07-02 12:46:42.878196 EDT | -----------------------  ------------
2017-07-02 12:46:42.878364 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #80 | Training started
2017-07-02 12:46:52.452467 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #80 | Training finished
2017-07-02 12:46:52.452753 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #80 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 12:46:52.452939 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #80 | Collecting samples for evaluation
2017-07-02 12:46:58.101063 EDT | -----------------------  -------------
2017-07-02 12:46:58.101707 EDT | Epoch                      80
2017-07-02 12:46:58.101951 EDT | Iteration                  80
2017-07-02 12:46:58.102187 EDT | AverageReturn            1000
2017-07-02 12:46:58.102528 EDT | StdReturn                   0
2017-07-02 12:46:58.102759 EDT | MaxReturn                1000
2017-07-02 12:46:58.102991 EDT | MinReturn                1000
2017-07-02 12:46:58.103231 EDT | AverageEsReturn            24.3171
2017-07-02 12:46:58.103458 EDT | StdEsReturn                21.6563
2017-07-02 12:46:58.103687 EDT | MaxEsReturn                84
2017-07-02 12:46:58.103901 EDT | MinEsReturn                 3
2017-07-02 12:46:58.104135 EDT | AverageDiscountedReturn    99.9957
2017-07-02 12:46:58.104352 EDT | AverageQLoss                0.00343076
2017-07-02 12:46:58.104545 EDT | AveragePolicySurr          -0.836479
2017-07-02 12:46:58.104769 EDT | AverageQ                    0.741311
2017-07-02 12:46:58.104924 EDT | AverageAbsQ                 0.743769
2017-07-02 12:46:58.105152 EDT | AverageY                    0.741411
2017-07-02 12:46:58.105375 EDT | AverageAbsY                 0.742203
2017-07-02 12:46:58.105575 EDT | AverageAbsQYDiff            0.0249553
2017-07-02 12:46:58.105809 EDT | AverageAction               0.517188
2017-07-02 12:46:58.105977 EDT | PolicyRegParamNorm         31.8399
2017-07-02 12:46:58.106083 EDT | QFunRegParamNorm           29.7128
2017-07-02 12:46:58.106224 EDT | -----------------------  -------------
2017-07-02 12:46:58.106551 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #81 | Training started
2017-07-02 12:47:07.747220 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #81 | Training finished
2017-07-02 12:47:07.747848 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #81 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 12:47:07.748112 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #81 | Collecting samples for evaluation
2017-07-02 12:47:13.351495 EDT | -----------------------  -------------
2017-07-02 12:47:13.351699 EDT | Epoch                      81
2017-07-02 12:47:13.351845 EDT | Iteration                  81
2017-07-02 12:47:13.351985 EDT | AverageReturn            1000
2017-07-02 12:47:13.352128 EDT | StdReturn                   0
2017-07-02 12:47:13.352266 EDT | MaxReturn                1000
2017-07-02 12:47:13.352468 EDT | MinReturn                1000
2017-07-02 12:47:13.352606 EDT | AverageEsReturn            20.1667
2017-07-02 12:47:13.352774 EDT | StdEsReturn                22.8193
2017-07-02 12:47:13.352973 EDT | MaxEsReturn               119
2017-07-02 12:47:13.353105 EDT | MinEsReturn                 3
2017-07-02 12:47:13.353230 EDT | AverageDiscountedReturn    99.9957
2017-07-02 12:47:13.353349 EDT | AverageQLoss                0.00396225
2017-07-02 12:47:13.353580 EDT | AveragePolicySurr          -0.868378
2017-07-02 12:47:13.353790 EDT | AverageQ                    0.768591
2017-07-02 12:47:13.354015 EDT | AverageAbsQ                 0.771053
2017-07-02 12:47:13.354190 EDT | AverageY                    0.768719
2017-07-02 12:47:13.354296 EDT | AverageAbsY                 0.769393
2017-07-02 12:47:13.354421 EDT | AverageAbsQYDiff            0.0272242
2017-07-02 12:47:13.354550 EDT | AverageAction               0.00574927
2017-07-02 12:47:13.354725 EDT | PolicyRegParamNorm         31.9375
2017-07-02 12:47:13.354829 EDT | QFunRegParamNorm           29.9156
2017-07-02 12:47:13.354929 EDT | -----------------------  -------------
2017-07-02 12:47:13.355122 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #82 | Training started
2017-07-02 12:47:22.978933 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #82 | Training finished
2017-07-02 12:47:22.979226 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #82 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 12:47:22.979480 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #82 | Collecting samples for evaluation
2017-07-02 12:47:28.662345 EDT | -----------------------  -------------
2017-07-02 12:47:28.662945 EDT | Epoch                      82
2017-07-02 12:47:28.663162 EDT | Iteration                  82
2017-07-02 12:47:28.663359 EDT | AverageReturn            1000
2017-07-02 12:47:28.663480 EDT | StdReturn                   0
2017-07-02 12:47:28.663597 EDT | MaxReturn                1000
2017-07-02 12:47:28.663735 EDT | MinReturn                1000
2017-07-02 12:47:28.663838 EDT | AverageEsReturn            22.8
2017-07-02 12:47:28.663947 EDT | StdEsReturn                21.9541
2017-07-02 12:47:28.664077 EDT | MaxEsReturn                89
2017-07-02 12:47:28.664189 EDT | MinEsReturn                 3
2017-07-02 12:47:28.664310 EDT | AverageDiscountedReturn    99.9957
2017-07-02 12:47:28.664415 EDT | AverageQLoss                0.00441825
2017-07-02 12:47:28.664562 EDT | AveragePolicySurr          -0.903327
2017-07-02 12:47:28.664664 EDT | AverageQ                    0.798587
2017-07-02 12:47:28.664786 EDT | AverageAbsQ                 0.80149
2017-07-02 12:47:28.664889 EDT | AverageY                    0.798681
2017-07-02 12:47:28.665031 EDT | AverageAbsY                 0.799415
2017-07-02 12:47:28.665134 EDT | AverageAbsQYDiff            0.0284653
2017-07-02 12:47:28.665261 EDT | AverageAction               0.393149
2017-07-02 12:47:28.665364 EDT | PolicyRegParamNorm         32.0629
2017-07-02 12:47:28.665477 EDT | QFunRegParamNorm           30.1762
2017-07-02 12:47:28.665646 EDT | -----------------------  -------------
2017-07-02 12:47:28.665844 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #83 | Training started
2017-07-02 12:47:38.342843 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #83 | Training finished
2017-07-02 12:47:38.343455 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #83 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 12:47:38.343619 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #83 | Collecting samples for evaluation
2017-07-02 12:47:43.968247 EDT | -----------------------  -------------
2017-07-02 12:47:43.968511 EDT | Epoch                      83
2017-07-02 12:47:43.968680 EDT | Iteration                  83
2017-07-02 12:47:43.968843 EDT | AverageReturn            1000
2017-07-02 12:47:43.969003 EDT | StdReturn                   0
2017-07-02 12:47:43.969162 EDT | MaxReturn                1000
2017-07-02 12:47:43.969320 EDT | MinReturn                1000
2017-07-02 12:47:43.969479 EDT | AverageEsReturn            20.6531
2017-07-02 12:47:43.969649 EDT | StdEsReturn                22.5339
2017-07-02 12:47:43.969807 EDT | MaxEsReturn               123
2017-07-02 12:47:43.969965 EDT | MinEsReturn                 3
2017-07-02 12:47:43.970124 EDT | AverageDiscountedReturn    99.9957
2017-07-02 12:47:43.970281 EDT | AverageQLoss                0.00451986
2017-07-02 12:47:43.970439 EDT | AveragePolicySurr          -0.936863
2017-07-02 12:47:43.970596 EDT | AverageQ                    0.827609
2017-07-02 12:47:43.970753 EDT | AverageAbsQ                 0.830104
2017-07-02 12:47:43.970910 EDT | AverageY                    0.827741
2017-07-02 12:47:43.971066 EDT | AverageAbsY                 0.828125
2017-07-02 12:47:43.971223 EDT | AverageAbsQYDiff            0.0285479
2017-07-02 12:47:43.971380 EDT | AverageAction               0.250729
2017-07-02 12:47:43.971536 EDT | PolicyRegParamNorm         32.1916
2017-07-02 12:47:43.971693 EDT | QFunRegParamNorm           30.3536
2017-07-02 12:47:43.971848 EDT | -----------------------  -------------
2017-07-02 12:47:43.972090 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #84 | Training started
2017-07-02 12:47:53.690229 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #84 | Training finished
2017-07-02 12:47:53.690452 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #84 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 12:47:53.690577 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #84 | Collecting samples for evaluation
2017-07-02 12:47:59.242396 EDT | -----------------------  -------------
2017-07-02 12:47:59.242880 EDT | Epoch                      84
2017-07-02 12:47:59.243114 EDT | Iteration                  84
2017-07-02 12:47:59.243343 EDT | AverageReturn            1000
2017-07-02 12:47:59.243562 EDT | StdReturn                   0
2017-07-02 12:47:59.243787 EDT | MaxReturn                1000
2017-07-02 12:47:59.243990 EDT | MinReturn                1000
2017-07-02 12:47:59.244208 EDT | AverageEsReturn            18.5577
2017-07-02 12:47:59.244326 EDT | StdEsReturn                22.3283
2017-07-02 12:47:59.244540 EDT | MaxEsReturn               122
2017-07-02 12:47:59.244763 EDT | MinEsReturn                 3
2017-07-02 12:47:59.244923 EDT | AverageDiscountedReturn    99.9957
2017-07-02 12:47:59.245031 EDT | AverageQLoss                0.00485643
2017-07-02 12:47:59.245203 EDT | AveragePolicySurr          -0.964897
2017-07-02 12:47:59.245310 EDT | AverageQ                    0.853399
2017-07-02 12:47:59.245412 EDT | AverageAbsQ                 0.856326
2017-07-02 12:47:59.245592 EDT | AverageY                    0.853516
2017-07-02 12:47:59.245818 EDT | AverageAbsY                 0.854093
2017-07-02 12:47:59.246086 EDT | AverageAbsQYDiff            0.0296454
2017-07-02 12:47:59.246317 EDT | AverageAction               0.402783
2017-07-02 12:47:59.246508 EDT | PolicyRegParamNorm         32.3279
2017-07-02 12:47:59.246712 EDT | QFunRegParamNorm           30.6125
2017-07-02 12:47:59.246950 EDT | -----------------------  -------------
2017-07-02 12:47:59.247272 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #85 | Training started
2017-07-02 12:48:09.168734 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #85 | Training finished
2017-07-02 12:48:09.169328 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #85 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 12:48:09.169604 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #85 | Collecting samples for evaluation
2017-07-02 12:48:14.960785 EDT | -----------------------  ------------
2017-07-02 12:48:14.961100 EDT | Epoch                      85
2017-07-02 12:48:14.961342 EDT | Iteration                  85
2017-07-02 12:48:14.961548 EDT | AverageReturn            1000
2017-07-02 12:48:14.961777 EDT | StdReturn                   0
2017-07-02 12:48:14.961983 EDT | MaxReturn                1000
2017-07-02 12:48:14.962297 EDT | MinReturn                1000
2017-07-02 12:48:14.962484 EDT | AverageEsReturn            18.6731
2017-07-02 12:48:14.962701 EDT | StdEsReturn                21.8911
2017-07-02 12:48:14.962905 EDT | MaxEsReturn               102
2017-07-02 12:48:14.963142 EDT | MinEsReturn                 3
2017-07-02 12:48:14.963316 EDT | AverageDiscountedReturn    99.9957
2017-07-02 12:48:14.963543 EDT | AverageQLoss                0.0045489
2017-07-02 12:48:14.963747 EDT | AveragePolicySurr          -1.00366
2017-07-02 12:48:14.963968 EDT | AverageQ                    0.889929
2017-07-02 12:48:14.964195 EDT | AverageAbsQ                 0.89278
2017-07-02 12:48:14.964402 EDT | AverageY                    0.890009
2017-07-02 12:48:14.964613 EDT | AverageAbsY                 0.890668
2017-07-02 12:48:14.964817 EDT | AverageAbsQYDiff            0.0293965
2017-07-02 12:48:14.965053 EDT | AverageAction               0.198406
2017-07-02 12:48:14.965242 EDT | PolicyRegParamNorm         32.3689
2017-07-02 12:48:14.965460 EDT | QFunRegParamNorm           30.8028
2017-07-02 12:48:14.965676 EDT | -----------------------  ------------
2017-07-02 12:48:14.966001 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #86 | Training started
2017-07-02 12:48:24.701442 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #86 | Training finished
2017-07-02 12:48:24.701760 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #86 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 12:48:24.701997 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #86 | Collecting samples for evaluation
2017-07-02 12:48:30.290007 EDT | -----------------------  -------------
2017-07-02 12:48:30.290610 EDT | Epoch                      86
2017-07-02 12:48:30.290867 EDT | Iteration                  86
2017-07-02 12:48:30.291104 EDT | AverageReturn            1000
2017-07-02 12:48:30.291329 EDT | StdReturn                   0
2017-07-02 12:48:30.291550 EDT | MaxReturn                1000
2017-07-02 12:48:30.291775 EDT | MinReturn                1000
2017-07-02 12:48:30.291955 EDT | AverageEsReturn            17.6842
2017-07-02 12:48:30.292175 EDT | StdEsReturn                18.363
2017-07-02 12:48:30.292396 EDT | MaxEsReturn                75
2017-07-02 12:48:30.292613 EDT | MinEsReturn                 3
2017-07-02 12:48:30.292821 EDT | AverageDiscountedReturn    99.9957
2017-07-02 12:48:30.293035 EDT | AverageQLoss                0.00510861
2017-07-02 12:48:30.293265 EDT | AveragePolicySurr          -1.03541
2017-07-02 12:48:30.293460 EDT | AverageQ                    0.91809
2017-07-02 12:48:30.293707 EDT | AverageAbsQ                 0.920921
2017-07-02 12:48:30.293922 EDT | AverageY                    0.918191
2017-07-02 12:48:30.294152 EDT | AverageAbsY                 0.919022
2017-07-02 12:48:30.294306 EDT | AverageAbsQYDiff            0.0305638
2017-07-02 12:48:30.294529 EDT | AverageAction               0.0135259
2017-07-02 12:48:30.294741 EDT | PolicyRegParamNorm         32.5092
2017-07-02 12:48:30.294970 EDT | QFunRegParamNorm           31.0256
2017-07-02 12:48:30.295151 EDT | -----------------------  -------------
2017-07-02 12:48:30.295485 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #87 | Training started
2017-07-02 12:48:39.883956 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #87 | Training finished
2017-07-02 12:48:39.884809 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #87 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 12:48:39.885018 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #87 | Collecting samples for evaluation
2017-07-02 12:48:45.547805 EDT | -----------------------  -------------
2017-07-02 12:48:45.548010 EDT | Epoch                      87
2017-07-02 12:48:45.548238 EDT | Iteration                  87
2017-07-02 12:48:45.548425 EDT | AverageReturn            1000
2017-07-02 12:48:45.548654 EDT | StdReturn                   0
2017-07-02 12:48:45.548854 EDT | MaxReturn                1000
2017-07-02 12:48:45.549080 EDT | MinReturn                1000
2017-07-02 12:48:45.549311 EDT | AverageEsReturn            20.4314
2017-07-02 12:48:45.549549 EDT | StdEsReturn                19.6481
2017-07-02 12:48:45.549769 EDT | MaxEsReturn                76
2017-07-02 12:48:45.549961 EDT | MinEsReturn                 3
2017-07-02 12:48:45.550185 EDT | AverageDiscountedReturn    99.9957
2017-07-02 12:48:45.550321 EDT | AverageQLoss                0.00540789
2017-07-02 12:48:45.550435 EDT | AveragePolicySurr          -1.07194
2017-07-02 12:48:45.550602 EDT | AverageQ                    0.95117
2017-07-02 12:48:45.550730 EDT | AverageAbsQ                 0.954405
2017-07-02 12:48:45.550853 EDT | AverageY                    0.951329
2017-07-02 12:48:45.550962 EDT | AverageAbsY                 0.952239
2017-07-02 12:48:45.551098 EDT | AverageAbsQYDiff            0.0315596
2017-07-02 12:48:45.551206 EDT | AverageAction               0.303354
2017-07-02 12:48:45.551313 EDT | PolicyRegParamNorm         32.6276
2017-07-02 12:48:45.551418 EDT | QFunRegParamNorm           31.2506
2017-07-02 12:48:45.551524 EDT | -----------------------  -------------
2017-07-02 12:48:45.551748 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #88 | Training started
2017-07-02 12:48:55.172771 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #88 | Training finished
2017-07-02 12:48:55.173285 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #88 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 12:48:55.173485 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #88 | Collecting samples for evaluation
2017-07-02 12:49:00.905547 EDT | -----------------------  -------------
2017-07-02 12:49:00.905867 EDT | Epoch                      88
2017-07-02 12:49:00.906095 EDT | Iteration                  88
2017-07-02 12:49:00.906301 EDT | AverageReturn            1000
2017-07-02 12:49:00.906426 EDT | StdReturn                   0
2017-07-02 12:49:00.906608 EDT | MaxReturn                1000
2017-07-02 12:49:00.906809 EDT | MinReturn                1000
2017-07-02 12:49:00.906956 EDT | AverageEsReturn            23.4884
2017-07-02 12:49:00.907067 EDT | StdEsReturn                33.6268
2017-07-02 12:49:00.907212 EDT | MaxEsReturn               204
2017-07-02 12:49:00.907336 EDT | MinEsReturn                 3
2017-07-02 12:49:00.907469 EDT | AverageDiscountedReturn    99.9957
2017-07-02 12:49:00.907583 EDT | AverageQLoss                0.00636519
2017-07-02 12:49:00.907701 EDT | AveragePolicySurr          -1.10035
2017-07-02 12:49:00.907847 EDT | AverageQ                    0.978364
2017-07-02 12:49:00.907956 EDT | AverageAbsQ                 0.981867
2017-07-02 12:49:00.908064 EDT | AverageY                    0.978536
2017-07-02 12:49:00.908170 EDT | AverageAbsY                 0.979601
2017-07-02 12:49:00.908369 EDT | AverageAbsQYDiff            0.0339542
2017-07-02 12:49:00.908522 EDT | AverageAction               0.384251
2017-07-02 12:49:00.908631 EDT | PolicyRegParamNorm         32.7548
2017-07-02 12:49:00.908738 EDT | QFunRegParamNorm           31.5269
2017-07-02 12:49:00.908844 EDT | -----------------------  -------------
2017-07-02 12:49:00.909015 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #89 | Training started
2017-07-02 12:49:10.439251 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #89 | Training finished
2017-07-02 12:49:10.439781 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #89 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 12:49:10.439994 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #89 | Collecting samples for evaluation
2017-07-02 12:49:16.182082 EDT | -----------------------  -------------
2017-07-02 12:49:16.182401 EDT | Epoch                      89
2017-07-02 12:49:16.182720 EDT | Iteration                  89
2017-07-02 12:49:16.183066 EDT | AverageReturn            1000
2017-07-02 12:49:16.183329 EDT | StdReturn                   0
2017-07-02 12:49:16.183644 EDT | MaxReturn                1000
2017-07-02 12:49:16.183943 EDT | MinReturn                1000
2017-07-02 12:49:16.184159 EDT | AverageEsReturn            31.8387
2017-07-02 12:49:16.184321 EDT | StdEsReturn                28.6358
2017-07-02 12:49:16.184541 EDT | MaxEsReturn               134
2017-07-02 12:49:16.184777 EDT | MinEsReturn                 3
2017-07-02 12:49:16.184963 EDT | AverageDiscountedReturn    99.9957
2017-07-02 12:49:16.185158 EDT | AverageQLoss                0.00588785
2017-07-02 12:49:16.185377 EDT | AveragePolicySurr          -1.1276
2017-07-02 12:49:16.185621 EDT | AverageQ                    1.00412
2017-07-02 12:49:16.185857 EDT | AverageAbsQ                 1.00746
2017-07-02 12:49:16.186090 EDT | AverageY                    1.00419
2017-07-02 12:49:16.186302 EDT | AverageAbsY                 1.00546
2017-07-02 12:49:16.186436 EDT | AverageAbsQYDiff            0.0324544
2017-07-02 12:49:16.186666 EDT | AverageAction               0.0162758
2017-07-02 12:49:16.186892 EDT | PolicyRegParamNorm         32.8784
2017-07-02 12:49:16.187092 EDT | QFunRegParamNorm           31.7434
2017-07-02 12:49:16.187329 EDT | -----------------------  -------------
2017-07-02 12:49:16.187627 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #90 | Training started
2017-07-02 12:49:25.871855 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #90 | Training finished
2017-07-02 12:49:25.872484 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #90 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 12:49:25.872739 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #90 | Collecting samples for evaluation
2017-07-02 12:49:31.515852 EDT | -----------------------  ------------
2017-07-02 12:49:31.516181 EDT | Epoch                      90
2017-07-02 12:49:31.516400 EDT | Iteration                  90
2017-07-02 12:49:31.516622 EDT | AverageReturn            1000
2017-07-02 12:49:31.516854 EDT | StdReturn                   0
2017-07-02 12:49:31.517024 EDT | MaxReturn                1000
2017-07-02 12:49:31.517256 EDT | MinReturn                1000
2017-07-02 12:49:31.517501 EDT | AverageEsReturn            18.8
2017-07-02 12:49:31.517732 EDT | StdEsReturn                21.3652
2017-07-02 12:49:31.517961 EDT | MaxEsReturn                91
2017-07-02 12:49:31.518166 EDT | MinEsReturn                 3
2017-07-02 12:49:31.518398 EDT | AverageDiscountedReturn    99.9957
2017-07-02 12:49:31.518601 EDT | AverageQLoss                0.0062694
2017-07-02 12:49:31.518709 EDT | AveragePolicySurr          -1.15643
2017-07-02 12:49:31.518932 EDT | AverageQ                    1.02891
2017-07-02 12:49:31.519162 EDT | AverageAbsQ                 1.03249
2017-07-02 12:49:31.519298 EDT | AverageY                    1.02906
2017-07-02 12:49:31.519413 EDT | AverageAbsY                 1.03031
2017-07-02 12:49:31.519639 EDT | AverageAbsQYDiff            0.0333511
2017-07-02 12:49:31.519864 EDT | AverageAction               0.483824
2017-07-02 12:49:31.519993 EDT | PolicyRegParamNorm         32.9886
2017-07-02 12:49:31.520119 EDT | QFunRegParamNorm           31.8698
2017-07-02 12:49:31.520234 EDT | -----------------------  ------------
2017-07-02 12:49:31.520564 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #91 | Training started
2017-07-02 12:49:41.436933 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #91 | Training finished
2017-07-02 12:49:41.439589 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #91 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 12:49:41.439798 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #91 | Collecting samples for evaluation
2017-07-02 12:49:47.029736 EDT | -----------------------  -------------
2017-07-02 12:49:47.029980 EDT | Epoch                      91
2017-07-02 12:49:47.030101 EDT | Iteration                  91
2017-07-02 12:49:47.030242 EDT | AverageReturn            1000
2017-07-02 12:49:47.030418 EDT | StdReturn                   0
2017-07-02 12:49:47.030540 EDT | MaxReturn                1000
2017-07-02 12:49:47.030770 EDT | MinReturn                1000
2017-07-02 12:49:47.030999 EDT | AverageEsReturn            26.3636
2017-07-02 12:49:47.031216 EDT | StdEsReturn                37.957
2017-07-02 12:49:47.031431 EDT | MaxEsReturn               174
2017-07-02 12:49:47.031627 EDT | MinEsReturn                 3
2017-07-02 12:49:47.031808 EDT | AverageDiscountedReturn    99.9957
2017-07-02 12:49:47.031919 EDT | AverageQLoss                0.00733634
2017-07-02 12:49:47.032064 EDT | AveragePolicySurr          -1.18465
2017-07-02 12:49:47.032177 EDT | AverageQ                    1.05887
2017-07-02 12:49:47.032303 EDT | AverageAbsQ                 1.06262
2017-07-02 12:49:47.032494 EDT | AverageY                    1.05899
2017-07-02 12:49:47.032632 EDT | AverageAbsY                 1.06
2017-07-02 12:49:47.032734 EDT | AverageAbsQYDiff            0.0348989
2017-07-02 12:49:47.032882 EDT | AverageAction               0.32883
2017-07-02 12:49:47.033010 EDT | PolicyRegParamNorm         33.0663
2017-07-02 12:49:47.033112 EDT | QFunRegParamNorm           32.1033
2017-07-02 12:49:47.033280 EDT | -----------------------  -------------
2017-07-02 12:49:47.033524 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #92 | Training started
2017-07-02 12:49:56.865858 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #92 | Training finished
2017-07-02 12:49:56.866351 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #92 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 12:49:56.866569 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #92 | Collecting samples for evaluation
2017-07-02 12:50:02.531624 EDT | -----------------------  -------------
2017-07-02 12:50:02.531896 EDT | Epoch                      92
2017-07-02 12:50:02.532090 EDT | Iteration                  92
2017-07-02 12:50:02.532253 EDT | AverageReturn            1000
2017-07-02 12:50:02.532431 EDT | StdReturn                   0
2017-07-02 12:50:02.532592 EDT | MaxReturn                1000
2017-07-02 12:50:02.532762 EDT | MinReturn                1000
2017-07-02 12:50:02.532920 EDT | AverageEsReturn            16.0328
2017-07-02 12:50:02.534334 EDT | StdEsReturn                14.4676
2017-07-02 12:50:02.534478 EDT | MaxEsReturn                61
2017-07-02 12:50:02.534703 EDT | MinEsReturn                 3
2017-07-02 12:50:02.534868 EDT | AverageDiscountedReturn    99.9957
2017-07-02 12:50:02.534981 EDT | AverageQLoss                0.00645829
2017-07-02 12:50:02.535136 EDT | AveragePolicySurr          -1.20619
2017-07-02 12:50:02.535368 EDT | AverageQ                    1.08203
2017-07-02 12:50:02.535597 EDT | AverageAbsQ                 1.08536
2017-07-02 12:50:02.535814 EDT | AverageY                    1.08214
2017-07-02 12:50:02.536045 EDT | AverageAbsY                 1.08333
2017-07-02 12:50:02.536242 EDT | AverageAbsQYDiff            0.0329298
2017-07-02 12:50:02.536472 EDT | AverageAction               0.590676
2017-07-02 12:50:02.536696 EDT | PolicyRegParamNorm         33.145
2017-07-02 12:50:02.536930 EDT | QFunRegParamNorm           32.3068
2017-07-02 12:50:02.537143 EDT | -----------------------  -------------
2017-07-02 12:50:02.537315 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #93 | Training started
2017-07-02 12:50:12.327584 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #93 | Training finished
2017-07-02 12:50:12.328187 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #93 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 12:50:12.328342 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #93 | Collecting samples for evaluation
2017-07-02 12:50:18.074547 EDT | -----------------------  -------------
2017-07-02 12:50:18.074768 EDT | Epoch                      93
2017-07-02 12:50:18.074883 EDT | Iteration                  93
2017-07-02 12:50:18.075024 EDT | AverageReturn            1000
2017-07-02 12:50:18.075200 EDT | StdReturn                   0
2017-07-02 12:50:18.075365 EDT | MaxReturn                1000
2017-07-02 12:50:18.075532 EDT | MinReturn                1000
2017-07-02 12:50:18.075642 EDT | AverageEsReturn            19.0556
2017-07-02 12:50:18.075786 EDT | StdEsReturn                16.6638
2017-07-02 12:50:18.075890 EDT | MaxEsReturn                76
2017-07-02 12:50:18.076066 EDT | MinEsReturn                 3
2017-07-02 12:50:18.076170 EDT | AverageDiscountedReturn    99.9957
2017-07-02 12:50:18.076308 EDT | AverageQLoss                0.00784729
2017-07-02 12:50:18.076474 EDT | AveragePolicySurr          -1.2268
2017-07-02 12:50:18.076669 EDT | AverageQ                    1.09656
2017-07-02 12:50:18.076850 EDT | AverageAbsQ                 1.10103
2017-07-02 12:50:18.076954 EDT | AverageY                    1.09677
2017-07-02 12:50:18.077056 EDT | AverageAbsY                 1.09844
2017-07-02 12:50:18.077156 EDT | AverageAbsQYDiff            0.0361362
2017-07-02 12:50:18.077305 EDT | AverageAction               0.554787
2017-07-02 12:50:18.077418 EDT | PolicyRegParamNorm         33.2972
2017-07-02 12:50:18.077753 EDT | QFunRegParamNorm           32.4875
2017-07-02 12:50:18.077926 EDT | -----------------------  -------------
2017-07-02 12:50:18.078128 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #94 | Training started
2017-07-02 12:50:28.304304 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #94 | Training finished
2017-07-02 12:50:28.304846 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #94 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 12:50:28.305073 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #94 | Collecting samples for evaluation
2017-07-02 12:50:33.962798 EDT | -----------------------  -------------
2017-07-02 12:50:33.963310 EDT | Epoch                      94
2017-07-02 12:50:33.963558 EDT | Iteration                  94
2017-07-02 12:50:33.963759 EDT | AverageReturn            1000
2017-07-02 12:50:33.963999 EDT | StdReturn                   0
2017-07-02 12:50:33.964213 EDT | MaxReturn                1000
2017-07-02 12:50:33.964453 EDT | MinReturn                1000
2017-07-02 12:50:33.964669 EDT | AverageEsReturn            21.6889
2017-07-02 12:50:33.964909 EDT | StdEsReturn                22.6145
2017-07-02 12:50:33.965126 EDT | MaxEsReturn                85
2017-07-02 12:50:33.965279 EDT | MinEsReturn                 3
2017-07-02 12:50:33.965532 EDT | AverageDiscountedReturn    99.9957
2017-07-02 12:50:33.965730 EDT | AverageQLoss                0.00803042
2017-07-02 12:50:33.965839 EDT | AveragePolicySurr          -1.25049
2017-07-02 12:50:33.965952 EDT | AverageQ                    1.12582
2017-07-02 12:50:33.966061 EDT | AverageAbsQ                 1.12956
2017-07-02 12:50:33.966162 EDT | AverageY                    1.12599
2017-07-02 12:50:33.966263 EDT | AverageAbsY                 1.12713
2017-07-02 12:50:33.966364 EDT | AverageAbsQYDiff            0.0358455
2017-07-02 12:50:33.966463 EDT | AverageAction               0.0180064
2017-07-02 12:50:33.966611 EDT | PolicyRegParamNorm         33.3956
2017-07-02 12:50:33.966844 EDT | QFunRegParamNorm           32.6404
2017-07-02 12:50:33.967065 EDT | -----------------------  -------------
2017-07-02 12:50:33.967399 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #95 | Training started
2017-07-02 12:50:43.615757 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #95 | Training finished
2017-07-02 12:50:43.616380 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #95 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 12:50:43.616602 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #95 | Collecting samples for evaluation
2017-07-02 12:50:49.413184 EDT | -----------------------  -------------
2017-07-02 12:50:49.413521 EDT | Epoch                      95
2017-07-02 12:50:49.413834 EDT | Iteration                  95
2017-07-02 12:50:49.414111 EDT | AverageReturn            1000
2017-07-02 12:50:49.414243 EDT | StdReturn                   0
2017-07-02 12:50:49.414374 EDT | MaxReturn                1000
2017-07-02 12:50:49.414501 EDT | MinReturn                1000
2017-07-02 12:50:49.414687 EDT | AverageEsReturn            21.3617
2017-07-02 12:50:49.414907 EDT | StdEsReturn                22.1959
2017-07-02 12:50:49.415098 EDT | MaxEsReturn               109
2017-07-02 12:50:49.415335 EDT | MinEsReturn                 3
2017-07-02 12:50:49.415505 EDT | AverageDiscountedReturn    99.9957
2017-07-02 12:50:49.415737 EDT | AverageQLoss                0.00766177
2017-07-02 12:50:49.415967 EDT | AveragePolicySurr          -1.26823
2017-07-02 12:50:49.416187 EDT | AverageQ                    1.14005
2017-07-02 12:50:49.416405 EDT | AverageAbsQ                 1.1438
2017-07-02 12:50:49.416565 EDT | AverageY                    1.14011
2017-07-02 12:50:49.416779 EDT | AverageAbsY                 1.14122
2017-07-02 12:50:49.416970 EDT | AverageAbsQYDiff            0.0352824
2017-07-02 12:50:49.417076 EDT | AverageAction               0.0198357
2017-07-02 12:50:49.417175 EDT | PolicyRegParamNorm         33.5538
2017-07-02 12:50:49.417273 EDT | QFunRegParamNorm           32.757
2017-07-02 12:50:49.417370 EDT | -----------------------  -------------
2017-07-02 12:50:49.417564 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #96 | Training started
2017-07-02 12:50:58.962556 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #96 | Training finished
2017-07-02 12:50:58.963106 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #96 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 12:50:58.963289 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #96 | Collecting samples for evaluation
2017-07-02 12:51:04.712956 EDT | -----------------------  -------------
2017-07-02 12:51:04.713699 EDT | Epoch                      96
2017-07-02 12:51:04.713910 EDT | Iteration                  96
2017-07-02 12:51:04.714124 EDT | AverageReturn            1000
2017-07-02 12:51:04.714272 EDT | StdReturn                   0
2017-07-02 12:51:04.714403 EDT | MaxReturn                1000
2017-07-02 12:51:04.714604 EDT | MinReturn                1000
2017-07-02 12:51:04.714817 EDT | AverageEsReturn            18.25
2017-07-02 12:51:04.715037 EDT | StdEsReturn                17.9585
2017-07-02 12:51:04.715258 EDT | MaxEsReturn               106
2017-07-02 12:51:04.715483 EDT | MinEsReturn                 3
2017-07-02 12:51:04.715669 EDT | AverageDiscountedReturn    99.9957
2017-07-02 12:51:04.715851 EDT | AverageQLoss                0.00830412
2017-07-02 12:51:04.715980 EDT | AveragePolicySurr          -1.28723
2017-07-02 12:51:04.716205 EDT | AverageQ                    1.15739
2017-07-02 12:51:04.716420 EDT | AverageAbsQ                 1.16125
2017-07-02 12:51:04.716683 EDT | AverageY                    1.15756
2017-07-02 12:51:04.716925 EDT | AverageAbsY                 1.15839
2017-07-02 12:51:04.717165 EDT | AverageAbsQYDiff            0.0359666
2017-07-02 12:51:04.717365 EDT | AverageAction               0.0169298
2017-07-02 12:51:04.717621 EDT | PolicyRegParamNorm         33.6024
2017-07-02 12:51:04.717858 EDT | QFunRegParamNorm           32.9941
2017-07-02 12:51:04.717985 EDT | -----------------------  -------------
2017-07-02 12:51:04.718305 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #97 | Training started
2017-07-02 12:51:14.266584 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #97 | Training finished
2017-07-02 12:51:14.267132 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #97 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 12:51:14.267301 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #97 | Collecting samples for evaluation
2017-07-02 12:51:19.979507 EDT | -----------------------  ------------
2017-07-02 12:51:19.979719 EDT | Epoch                      97
2017-07-02 12:51:19.979887 EDT | Iteration                  97
2017-07-02 12:51:19.980044 EDT | AverageReturn            1000
2017-07-02 12:51:19.980151 EDT | StdReturn                   0
2017-07-02 12:51:19.980254 EDT | MaxReturn                1000
2017-07-02 12:51:19.980375 EDT | MinReturn                1000
2017-07-02 12:51:19.980529 EDT | AverageEsReturn            17.3273
2017-07-02 12:51:19.980635 EDT | StdEsReturn                16.82
2017-07-02 12:51:19.980755 EDT | MaxEsReturn                72
2017-07-02 12:51:19.980876 EDT | MinEsReturn                 3
2017-07-02 12:51:19.981008 EDT | AverageDiscountedReturn    99.9957
2017-07-02 12:51:19.981113 EDT | AverageQLoss                0.0089113
2017-07-02 12:51:19.981214 EDT | AveragePolicySurr          -1.30819
2017-07-02 12:51:19.981315 EDT | AverageQ                    1.17356
2017-07-02 12:51:19.981416 EDT | AverageAbsQ                 1.17744
2017-07-02 12:51:19.981584 EDT | AverageY                    1.17357
2017-07-02 12:51:19.981742 EDT | AverageAbsY                 1.17457
2017-07-02 12:51:19.981956 EDT | AverageAbsQYDiff            0.0375615
2017-07-02 12:51:19.982167 EDT | AverageAction               0.0479286
2017-07-02 12:51:19.982383 EDT | PolicyRegParamNorm         33.7269
2017-07-02 12:51:19.982602 EDT | QFunRegParamNorm           33.1489
2017-07-02 12:51:19.982822 EDT | -----------------------  ------------
2017-07-02 12:51:19.983138 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #98 | Training started
2017-07-02 12:51:29.563880 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #98 | Training finished
2017-07-02 12:51:29.564470 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #98 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 12:51:29.564611 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #98 | Collecting samples for evaluation
2017-07-02 12:51:35.333855 EDT | -----------------------  ------------
2017-07-02 12:51:35.334396 EDT | Epoch                      98
2017-07-02 12:51:35.334529 EDT | Iteration                  98
2017-07-02 12:51:35.334637 EDT | AverageReturn            1000
2017-07-02 12:51:35.334742 EDT | StdReturn                   0
2017-07-02 12:51:35.334858 EDT | MaxReturn                1000
2017-07-02 12:51:35.334977 EDT | MinReturn                1000
2017-07-02 12:51:35.335085 EDT | AverageEsReturn            23.7857
2017-07-02 12:51:35.335207 EDT | StdEsReturn                22.6048
2017-07-02 12:51:35.335309 EDT | MaxEsReturn                81
2017-07-02 12:51:35.335424 EDT | MinEsReturn                 3
2017-07-02 12:51:35.335638 EDT | AverageDiscountedReturn    99.9957
2017-07-02 12:51:35.335855 EDT | AverageQLoss                0.0081161
2017-07-02 12:51:35.336077 EDT | AveragePolicySurr          -1.32282
2017-07-02 12:51:35.336299 EDT | AverageQ                    1.19609
2017-07-02 12:51:35.336519 EDT | AverageAbsQ                 1.19973
2017-07-02 12:51:35.336726 EDT | AverageY                    1.19632
2017-07-02 12:51:35.336928 EDT | AverageAbsY                 1.19714
2017-07-02 12:51:35.337130 EDT | AverageAbsQYDiff            0.0357889
2017-07-02 12:51:35.337353 EDT | AverageAction               0.0234165
2017-07-02 12:51:35.337598 EDT | PolicyRegParamNorm         33.7788
2017-07-02 12:51:35.337785 EDT | QFunRegParamNorm           33.3196
2017-07-02 12:51:35.337891 EDT | -----------------------  ------------
2017-07-02 12:51:35.338145 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #99 | Training started
2017-07-02 12:51:44.965711 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #99 | Training finished
2017-07-02 12:51:44.966248 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #99 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 12:51:44.966437 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #99 | Collecting samples for evaluation
2017-07-02 12:51:50.629133 EDT | -----------------------  -------------
2017-07-02 12:51:50.629324 EDT | Epoch                      99
2017-07-02 12:51:50.629515 EDT | Iteration                  99
2017-07-02 12:51:50.629846 EDT | AverageReturn            1000
2017-07-02 12:51:50.630075 EDT | StdReturn                   0
2017-07-02 12:51:50.630312 EDT | MaxReturn                1000
2017-07-02 12:51:50.630527 EDT | MinReturn                1000
2017-07-02 12:51:50.630765 EDT | AverageEsReturn            16.3594
2017-07-02 12:51:50.630994 EDT | StdEsReturn                17.9708
2017-07-02 12:51:50.631151 EDT | MaxEsReturn                70
2017-07-02 12:51:50.631388 EDT | MinEsReturn                 3
2017-07-02 12:51:50.631623 EDT | AverageDiscountedReturn    99.9957
2017-07-02 12:51:50.631808 EDT | AverageQLoss                0.00810066
2017-07-02 12:51:50.631951 EDT | AveragePolicySurr          -1.34072
2017-07-02 12:51:50.632055 EDT | AverageQ                    1.21512
2017-07-02 12:51:50.632274 EDT | AverageAbsQ                 1.21837
2017-07-02 12:51:50.632509 EDT | AverageY                    1.21519
2017-07-02 12:51:50.632762 EDT | AverageAbsY                 1.21603
2017-07-02 12:51:50.633001 EDT | AverageAbsQYDiff            0.0349028
2017-07-02 12:51:50.633220 EDT | AverageAction               0.152672
2017-07-02 12:51:50.633456 EDT | PolicyRegParamNorm         33.8963
2017-07-02 12:51:50.633685 EDT | QFunRegParamNorm           33.4254
2017-07-02 12:51:50.633924 EDT | -----------------------  -------------
2017-07-02 12:51:50.634251 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #100 | Training started
2017-07-02 12:52:00.200891 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #100 | Training finished
2017-07-02 12:52:00.201537 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #100 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 12:52:00.201710 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #100 | Collecting samples for evaluation
2017-07-02 12:52:05.852073 EDT | -----------------------  -------------
2017-07-02 12:52:05.852635 EDT | Epoch                     100
2017-07-02 12:52:05.852787 EDT | Iteration                 100
2017-07-02 12:52:05.852934 EDT | AverageReturn            1000
2017-07-02 12:52:05.853041 EDT | StdReturn                   0
2017-07-02 12:52:05.853199 EDT | MaxReturn                1000
2017-07-02 12:52:05.853328 EDT | MinReturn                1000
2017-07-02 12:52:05.853431 EDT | AverageEsReturn            22.2667
2017-07-02 12:52:05.853617 EDT | StdEsReturn                23.3889
2017-07-02 12:52:05.853772 EDT | MaxEsReturn                81
2017-07-02 12:52:05.853948 EDT | MinEsReturn                 3
2017-07-02 12:52:05.854137 EDT | AverageDiscountedReturn    99.9957
2017-07-02 12:52:05.854323 EDT | AverageQLoss                0.00783422
2017-07-02 12:52:05.854525 EDT | AveragePolicySurr          -1.35091
2017-07-02 12:52:05.854651 EDT | AverageQ                    1.2238
2017-07-02 12:52:05.854777 EDT | AverageAbsQ                 1.22719
2017-07-02 12:52:05.854909 EDT | AverageY                    1.22395
2017-07-02 12:52:05.855077 EDT | AverageAbsY                 1.22485
2017-07-02 12:52:05.855257 EDT | AverageAbsQYDiff            0.0347327
2017-07-02 12:52:05.855422 EDT | AverageAction               0.0180051
2017-07-02 12:52:05.855527 EDT | PolicyRegParamNorm         33.9134
2017-07-02 12:52:05.855684 EDT | QFunRegParamNorm           33.6451
2017-07-02 12:52:05.855793 EDT | -----------------------  -------------
2017-07-02 12:52:05.855991 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #101 | Training started
2017-07-02 12:52:15.384623 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #101 | Training finished
2017-07-02 12:52:15.385183 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #101 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 12:52:15.385398 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #101 | Collecting samples for evaluation
2017-07-02 12:52:21.100840 EDT | -----------------------  -------------
2017-07-02 12:52:21.101076 EDT | Epoch                     101
2017-07-02 12:52:21.101226 EDT | Iteration                 101
2017-07-02 12:52:21.101397 EDT | AverageReturn            1000
2017-07-02 12:52:21.101535 EDT | StdReturn                   0
2017-07-02 12:52:21.101685 EDT | MaxReturn                1000
2017-07-02 12:52:21.101814 EDT | MinReturn                1000
2017-07-02 12:52:21.101981 EDT | AverageEsReturn            16.129
2017-07-02 12:52:21.102092 EDT | StdEsReturn                22.4941
2017-07-02 12:52:21.102195 EDT | MaxEsReturn               113
2017-07-02 12:52:21.102332 EDT | MinEsReturn                 3
2017-07-02 12:52:21.102459 EDT | AverageDiscountedReturn    99.9957
2017-07-02 12:52:21.102607 EDT | AverageQLoss                0.00913713
2017-07-02 12:52:21.102741 EDT | AveragePolicySurr          -1.36508
2017-07-02 12:52:21.102843 EDT | AverageQ                    1.23335
2017-07-02 12:52:21.102943 EDT | AverageAbsQ                 1.23747
2017-07-02 12:52:21.103082 EDT | AverageY                    1.23341
2017-07-02 12:52:21.103251 EDT | AverageAbsY                 1.23461
2017-07-02 12:52:21.103359 EDT | AverageAbsQYDiff            0.037328
2017-07-02 12:52:21.103526 EDT | AverageAction               0.0151283
2017-07-02 12:52:21.103702 EDT | PolicyRegParamNorm         33.9865
2017-07-02 12:52:21.103863 EDT | QFunRegParamNorm           33.8537
2017-07-02 12:52:21.104048 EDT | -----------------------  -------------
2017-07-02 12:52:21.104330 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #102 | Training started
2017-07-02 12:52:30.618306 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #102 | Training finished
2017-07-02 12:52:30.618821 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #102 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 12:52:30.618969 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #102 | Collecting samples for evaluation
2017-07-02 12:52:36.267662 EDT | -----------------------  -------------
2017-07-02 12:52:36.268179 EDT | Epoch                     102
2017-07-02 12:52:36.268403 EDT | Iteration                 102
2017-07-02 12:52:36.268577 EDT | AverageReturn            1000
2017-07-02 12:52:36.268722 EDT | StdReturn                   0
2017-07-02 12:52:36.268831 EDT | MaxReturn                1000
2017-07-02 12:52:36.269020 EDT | MinReturn                1000
2017-07-02 12:52:36.269190 EDT | AverageEsReturn            20.8333
2017-07-02 12:52:36.269348 EDT | StdEsReturn                32.6945
2017-07-02 12:52:36.269453 EDT | MaxEsReturn               187
2017-07-02 12:52:36.269639 EDT | MinEsReturn                 3
2017-07-02 12:52:36.269811 EDT | AverageDiscountedReturn    99.9957
2017-07-02 12:52:36.269975 EDT | AverageQLoss                0.00959221
2017-07-02 12:52:36.270136 EDT | AveragePolicySurr          -1.38419
2017-07-02 12:52:36.270298 EDT | AverageQ                    1.24771
2017-07-02 12:52:36.270460 EDT | AverageAbsQ                 1.25174
2017-07-02 12:52:36.270566 EDT | AverageY                    1.2478
2017-07-02 12:52:36.270761 EDT | AverageAbsY                 1.24907
2017-07-02 12:52:36.270956 EDT | AverageAbsQYDiff            0.0373003
2017-07-02 12:52:36.271069 EDT | AverageAction               0.0161433
2017-07-02 12:52:36.271214 EDT | PolicyRegParamNorm         34.1344
2017-07-02 12:52:36.271328 EDT | QFunRegParamNorm           34.0278
2017-07-02 12:52:36.271430 EDT | -----------------------  -------------
2017-07-02 12:52:36.271630 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #103 | Training started
2017-07-02 12:52:45.900573 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #103 | Training finished
2017-07-02 12:52:45.901084 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #103 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 12:52:45.901270 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #103 | Collecting samples for evaluation
2017-07-02 12:52:51.646054 EDT | -----------------------  -------------
2017-07-02 12:52:51.646259 EDT | Epoch                     103
2017-07-02 12:52:51.646382 EDT | Iteration                 103
2017-07-02 12:52:51.646489 EDT | AverageReturn            1000
2017-07-02 12:52:51.646594 EDT | StdReturn                   0
2017-07-02 12:52:51.646710 EDT | MaxReturn                1000
2017-07-02 12:52:51.646941 EDT | MinReturn                1000
2017-07-02 12:52:51.647172 EDT | AverageEsReturn            15.871
2017-07-02 12:52:51.647318 EDT | StdEsReturn                15.0145
2017-07-02 12:52:51.647423 EDT | MaxEsReturn                64
2017-07-02 12:52:51.647593 EDT | MinEsReturn                 3
2017-07-02 12:52:51.647697 EDT | AverageDiscountedReturn    99.9957
2017-07-02 12:52:51.647798 EDT | AverageQLoss                0.00840511
2017-07-02 12:52:51.647907 EDT | AveragePolicySurr          -1.39984
2017-07-02 12:52:51.648005 EDT | AverageQ                    1.26861
2017-07-02 12:52:51.648120 EDT | AverageAbsQ                 1.27261
2017-07-02 12:52:51.648330 EDT | AverageY                    1.26884
2017-07-02 12:52:51.648551 EDT | AverageAbsY                 1.26996
2017-07-02 12:52:51.648749 EDT | AverageAbsQYDiff            0.0362729
2017-07-02 12:52:51.648892 EDT | AverageAction               0.0173374
2017-07-02 12:52:51.648992 EDT | PolicyRegParamNorm         34.1857
2017-07-02 12:52:51.649091 EDT | QFunRegParamNorm           34.1802
2017-07-02 12:52:51.649212 EDT | -----------------------  -------------
2017-07-02 12:52:51.649417 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #104 | Training started
2017-07-02 12:53:01.293823 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #104 | Training finished
2017-07-02 12:53:01.315239 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #104 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 12:53:01.315519 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #104 | Collecting samples for evaluation
2017-07-02 12:53:06.985262 EDT | -----------------------  -------------
2017-07-02 12:53:06.985889 EDT | Epoch                     104
2017-07-02 12:53:06.986029 EDT | Iteration                 104
2017-07-02 12:53:06.986168 EDT | AverageReturn            1000
2017-07-02 12:53:06.986277 EDT | StdReturn                   0
2017-07-02 12:53:06.986382 EDT | MaxReturn                1000
2017-07-02 12:53:06.986485 EDT | MinReturn                1000
2017-07-02 12:53:06.986601 EDT | AverageEsReturn            15.9048
2017-07-02 12:53:06.986735 EDT | StdEsReturn                16.3471
2017-07-02 12:53:06.986862 EDT | MaxEsReturn                63
2017-07-02 12:53:06.986964 EDT | MinEsReturn                 3
2017-07-02 12:53:06.987065 EDT | AverageDiscountedReturn    99.9957
2017-07-02 12:53:06.987193 EDT | AverageQLoss                0.00975171
2017-07-02 12:53:06.987294 EDT | AveragePolicySurr          -1.41163
2017-07-02 12:53:06.987393 EDT | AverageQ                    1.27878
2017-07-02 12:53:06.987493 EDT | AverageAbsQ                 1.28306
2017-07-02 12:53:06.987593 EDT | AverageY                    1.27883
2017-07-02 12:53:06.987741 EDT | AverageAbsY                 1.27989
2017-07-02 12:53:06.987844 EDT | AverageAbsQYDiff            0.0382041
2017-07-02 12:53:06.987945 EDT | AverageAction               0.0206447
2017-07-02 12:53:06.988045 EDT | PolicyRegParamNorm         34.3586
2017-07-02 12:53:06.988190 EDT | QFunRegParamNorm           34.3681
2017-07-02 12:53:06.988294 EDT | -----------------------  -------------
2017-07-02 12:53:06.988469 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #105 | Training started
2017-07-02 12:53:16.632122 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #105 | Training finished
2017-07-02 12:53:16.632671 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #105 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 12:53:16.632861 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #105 | Collecting samples for evaluation
2017-07-02 12:53:22.405448 EDT | -----------------------  -------------
2017-07-02 12:53:22.405731 EDT | Epoch                     105
2017-07-02 12:53:22.405851 EDT | Iteration                 105
2017-07-02 12:53:22.405963 EDT | AverageReturn            1000
2017-07-02 12:53:22.406114 EDT | StdReturn                   0
2017-07-02 12:53:22.406279 EDT | MaxReturn                1000
2017-07-02 12:53:22.406447 EDT | MinReturn                1000
2017-07-02 12:53:22.406655 EDT | AverageEsReturn            12.9487
2017-07-02 12:53:22.406844 EDT | StdEsReturn                16.6686
2017-07-02 12:53:22.406970 EDT | MaxEsReturn               100
2017-07-02 12:53:22.407187 EDT | MinEsReturn                 3
2017-07-02 12:53:22.407410 EDT | AverageDiscountedReturn    99.9957
2017-07-02 12:53:22.407595 EDT | AverageQLoss                0.00934629
2017-07-02 12:53:22.407823 EDT | AveragePolicySurr          -1.42452
2017-07-02 12:53:22.408055 EDT | AverageQ                    1.28941
2017-07-02 12:53:22.408278 EDT | AverageAbsQ                 1.2932
2017-07-02 12:53:22.408499 EDT | AverageY                    1.28949
2017-07-02 12:53:22.408702 EDT | AverageAbsY                 1.29032
2017-07-02 12:53:22.408924 EDT | AverageAbsQYDiff            0.0365648
2017-07-02 12:53:22.409137 EDT | AverageAction               0.0153432
2017-07-02 12:53:22.409364 EDT | PolicyRegParamNorm         34.411
2017-07-02 12:53:22.409609 EDT | QFunRegParamNorm           34.6036
2017-07-02 12:53:22.409834 EDT | -----------------------  -------------
2017-07-02 12:53:22.410152 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #106 | Training started
2017-07-02 12:53:31.908338 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #106 | Training finished
2017-07-02 12:53:31.908875 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #106 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 12:53:31.909156 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #106 | Collecting samples for evaluation
2017-07-02 12:53:37.703698 EDT | -----------------------  ------------
2017-07-02 12:53:37.704191 EDT | Epoch                     106
2017-07-02 12:53:37.704376 EDT | Iteration                 106
2017-07-02 12:53:37.704614 EDT | AverageReturn            1000
2017-07-02 12:53:37.704847 EDT | StdReturn                   0
2017-07-02 12:53:37.704980 EDT | MaxReturn                1000
2017-07-02 12:53:37.705144 EDT | MinReturn                1000
2017-07-02 12:53:37.705262 EDT | AverageEsReturn            14.0563
2017-07-02 12:53:37.705372 EDT | StdEsReturn                14.7876
2017-07-02 12:53:37.705606 EDT | MaxEsReturn                62
2017-07-02 12:53:37.705810 EDT | MinEsReturn                 3
2017-07-02 12:53:37.706020 EDT | AverageDiscountedReturn    99.9957
2017-07-02 12:53:37.706241 EDT | AverageQLoss                0.0100096
2017-07-02 12:53:37.706455 EDT | AveragePolicySurr          -1.43923
2017-07-02 12:53:37.706693 EDT | AverageQ                    1.30433
2017-07-02 12:53:37.706920 EDT | AverageAbsQ                 1.30832
2017-07-02 12:53:37.707145 EDT | AverageY                    1.30442
2017-07-02 12:53:37.707355 EDT | AverageAbsY                 1.30501
2017-07-02 12:53:37.707585 EDT | AverageAbsQYDiff            0.0386342
2017-07-02 12:53:37.707800 EDT | AverageAction               0.0289947
2017-07-02 12:53:37.707918 EDT | PolicyRegParamNorm         34.5154
2017-07-02 12:53:37.708022 EDT | QFunRegParamNorm           34.7587
2017-07-02 12:53:37.708155 EDT | -----------------------  ------------
2017-07-02 12:53:37.708447 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #107 | Training started
2017-07-02 12:53:47.187954 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #107 | Training finished
2017-07-02 12:53:47.188571 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #107 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 12:53:47.188730 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #107 | Collecting samples for evaluation
2017-07-02 12:53:53.034138 EDT | -----------------------  ------------
2017-07-02 12:53:53.034632 EDT | Epoch                     107
2017-07-02 12:53:53.034792 EDT | Iteration                 107
2017-07-02 12:53:53.034969 EDT | AverageReturn            1000
2017-07-02 12:53:53.035079 EDT | StdReturn                   0
2017-07-02 12:53:53.035198 EDT | MaxReturn                1000
2017-07-02 12:53:53.035309 EDT | MinReturn                1000
2017-07-02 12:53:53.035408 EDT | AverageEsReturn            15.6875
2017-07-02 12:53:53.035507 EDT | StdEsReturn                19.4799
2017-07-02 12:53:53.035605 EDT | MaxEsReturn               114
2017-07-02 12:53:53.035733 EDT | MinEsReturn                 3
2017-07-02 12:53:53.035879 EDT | AverageDiscountedReturn    99.9957
2017-07-02 12:53:53.036069 EDT | AverageQLoss                0.0096867
2017-07-02 12:53:53.036273 EDT | AveragePolicySurr          -1.44687
2017-07-02 12:53:53.036446 EDT | AverageQ                    1.3128
2017-07-02 12:53:53.036597 EDT | AverageAbsQ                 1.31721
2017-07-02 12:53:53.036701 EDT | AverageY                    1.31287
2017-07-02 12:53:53.036802 EDT | AverageAbsY                 1.31406
2017-07-02 12:53:53.036928 EDT | AverageAbsQYDiff            0.0378041
2017-07-02 12:53:53.037030 EDT | AverageAction               0.0354315
2017-07-02 12:53:53.037156 EDT | PolicyRegParamNorm         34.584
2017-07-02 12:53:53.037339 EDT | QFunRegParamNorm           34.9112
2017-07-02 12:53:53.037452 EDT | -----------------------  ------------
2017-07-02 12:53:53.037697 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #108 | Training started
2017-07-02 12:54:02.531995 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #108 | Training finished
2017-07-02 12:54:02.532621 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #108 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 12:54:02.532846 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #108 | Collecting samples for evaluation
2017-07-02 12:54:08.330102 EDT | -----------------------  -------------
2017-07-02 12:54:08.330350 EDT | Epoch                     108
2017-07-02 12:54:08.330488 EDT | Iteration                 108
2017-07-02 12:54:08.330635 EDT | AverageReturn            1000
2017-07-02 12:54:08.330812 EDT | StdReturn                   0
2017-07-02 12:54:08.331011 EDT | MaxReturn                1000
2017-07-02 12:54:08.331165 EDT | MinReturn                1000
2017-07-02 12:54:08.331266 EDT | AverageEsReturn            17.8393
2017-07-02 12:54:08.331431 EDT | StdEsReturn                29.6237
2017-07-02 12:54:08.331570 EDT | MaxEsReturn               176
2017-07-02 12:54:08.331696 EDT | MinEsReturn                 3
2017-07-02 12:54:08.331829 EDT | AverageDiscountedReturn    99.9957
2017-07-02 12:54:08.331953 EDT | AverageQLoss                0.00990252
2017-07-02 12:54:08.332056 EDT | AveragePolicySurr          -1.46004
2017-07-02 12:54:08.332186 EDT | AverageQ                    1.3256
2017-07-02 12:54:08.332292 EDT | AverageAbsQ                 1.32964
2017-07-02 12:54:08.332425 EDT | AverageY                    1.32573
2017-07-02 12:54:08.332623 EDT | AverageAbsY                 1.32677
2017-07-02 12:54:08.332791 EDT | AverageAbsQYDiff            0.0379159
2017-07-02 12:54:08.332900 EDT | AverageAction               0.178591
2017-07-02 12:54:08.333052 EDT | PolicyRegParamNorm         34.6284
2017-07-02 12:54:08.333213 EDT | QFunRegParamNorm           35.0357
2017-07-02 12:54:08.333411 EDT | -----------------------  -------------
2017-07-02 12:54:08.333842 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #109 | Training started
2017-07-02 12:54:17.831475 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #109 | Training finished
2017-07-02 12:54:17.832025 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #109 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 12:54:17.832296 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #109 | Collecting samples for evaluation
2017-07-02 12:54:23.583505 EDT | -----------------------  ------------
2017-07-02 12:54:23.584107 EDT | Epoch                     109
2017-07-02 12:54:23.584332 EDT | Iteration                 109
2017-07-02 12:54:23.584539 EDT | AverageReturn            1000
2017-07-02 12:54:23.584650 EDT | StdReturn                   0
2017-07-02 12:54:23.584860 EDT | MaxReturn                1000
2017-07-02 12:54:23.585064 EDT | MinReturn                1000
2017-07-02 12:54:23.585180 EDT | AverageEsReturn            16.434
2017-07-02 12:54:23.585284 EDT | StdEsReturn                19.4388
2017-07-02 12:54:23.585440 EDT | MaxEsReturn               127
2017-07-02 12:54:23.585611 EDT | MinEsReturn                 3
2017-07-02 12:54:23.585717 EDT | AverageDiscountedReturn    99.9957
2017-07-02 12:54:23.585820 EDT | AverageQLoss                0.0107235
2017-07-02 12:54:23.585935 EDT | AveragePolicySurr          -1.4675
2017-07-02 12:54:23.586044 EDT | AverageQ                    1.33319
2017-07-02 12:54:23.586146 EDT | AverageAbsQ                 1.33794
2017-07-02 12:54:23.586247 EDT | AverageY                    1.3333
2017-07-02 12:54:23.586347 EDT | AverageAbsY                 1.33439
2017-07-02 12:54:23.586494 EDT | AverageAbsQYDiff            0.0394232
2017-07-02 12:54:23.586629 EDT | AverageAction               0.17681
2017-07-02 12:54:23.586771 EDT | PolicyRegParamNorm         34.7814
2017-07-02 12:54:23.586934 EDT | QFunRegParamNorm           35.1481
2017-07-02 12:54:23.587046 EDT | -----------------------  ------------
2017-07-02 12:54:23.587326 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #110 | Training started
2017-07-02 12:54:33.201258 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #110 | Training finished
2017-07-02 12:54:33.201846 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #110 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 12:54:33.202104 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #110 | Collecting samples for evaluation
2017-07-02 12:54:38.918863 EDT | -----------------------  -------------
2017-07-02 12:54:38.919081 EDT | Epoch                     110
2017-07-02 12:54:38.919194 EDT | Iteration                 110
2017-07-02 12:54:38.919343 EDT | AverageReturn            1000
2017-07-02 12:54:38.919448 EDT | StdReturn                   0
2017-07-02 12:54:38.919549 EDT | MaxReturn                1000
2017-07-02 12:54:38.919683 EDT | MinReturn                1000
2017-07-02 12:54:38.919787 EDT | AverageEsReturn            19.2807
2017-07-02 12:54:38.919894 EDT | StdEsReturn                22.4294
2017-07-02 12:54:38.920088 EDT | MaxEsReturn               136
2017-07-02 12:54:38.920214 EDT | MinEsReturn                 3
2017-07-02 12:54:38.920335 EDT | AverageDiscountedReturn    99.9957
2017-07-02 12:54:38.920436 EDT | AverageQLoss                0.00995779
2017-07-02 12:54:38.920582 EDT | AveragePolicySurr          -1.47842
2017-07-02 12:54:38.920686 EDT | AverageQ                    1.34586
2017-07-02 12:54:38.920814 EDT | AverageAbsQ                 1.35012
2017-07-02 12:54:38.920955 EDT | AverageY                    1.34599
2017-07-02 12:54:38.921081 EDT | AverageAbsY                 1.34678
2017-07-02 12:54:38.921183 EDT | AverageAbsQYDiff            0.0390963
2017-07-02 12:54:38.921287 EDT | AverageAction               0.111556
2017-07-02 12:54:38.921483 EDT | PolicyRegParamNorm         34.8005
2017-07-02 12:54:38.921775 EDT | QFunRegParamNorm           35.3271
2017-07-02 12:54:38.921937 EDT | -----------------------  -------------
2017-07-02 12:54:38.922204 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #111 | Training started
2017-07-02 12:54:48.712787 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #111 | Training finished
2017-07-02 12:54:48.713363 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #111 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 12:54:48.713531 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #111 | Collecting samples for evaluation
2017-07-02 12:54:54.522189 EDT | -----------------------  ------------
2017-07-02 12:54:54.522770 EDT | Epoch                     111
2017-07-02 12:54:54.522995 EDT | Iteration                 111
2017-07-02 12:54:54.523226 EDT | AverageReturn            1000
2017-07-02 12:54:54.523467 EDT | StdReturn                   0
2017-07-02 12:54:54.523738 EDT | MaxReturn                1000
2017-07-02 12:54:54.523894 EDT | MinReturn                1000
2017-07-02 12:54:54.524085 EDT | AverageEsReturn            16.7049
2017-07-02 12:54:54.524213 EDT | StdEsReturn                17.1907
2017-07-02 12:54:54.524341 EDT | MaxEsReturn                65
2017-07-02 12:54:54.524527 EDT | MinEsReturn                 3
2017-07-02 12:54:54.524688 EDT | AverageDiscountedReturn    99.9957
2017-07-02 12:54:54.524811 EDT | AverageQLoss                0.0111112
2017-07-02 12:54:54.524966 EDT | AveragePolicySurr          -1.49071
2017-07-02 12:54:54.525125 EDT | AverageQ                    1.35352
2017-07-02 12:54:54.525264 EDT | AverageAbsQ                 1.35774
2017-07-02 12:54:54.525367 EDT | AverageY                    1.35354
2017-07-02 12:54:54.525469 EDT | AverageAbsY                 1.35438
2017-07-02 12:54:54.525588 EDT | AverageAbsQYDiff            0.0400004
2017-07-02 12:54:54.525694 EDT | AverageAction               0.133568
2017-07-02 12:54:54.525834 EDT | PolicyRegParamNorm         34.9278
2017-07-02 12:54:54.525936 EDT | QFunRegParamNorm           35.482
2017-07-02 12:54:54.526036 EDT | -----------------------  ------------
2017-07-02 12:54:54.526206 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #112 | Training started
2017-07-02 12:55:04.089036 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #112 | Training finished
2017-07-02 12:55:04.089628 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #112 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 12:55:04.089883 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #112 | Collecting samples for evaluation
2017-07-02 12:55:09.808854 EDT | -----------------------  ------------
2017-07-02 12:55:09.809154 EDT | Epoch                     112
2017-07-02 12:55:09.809389 EDT | Iteration                 112
2017-07-02 12:55:09.809637 EDT | AverageReturn            1000
2017-07-02 12:55:09.809874 EDT | StdReturn                   0
2017-07-02 12:55:09.810084 EDT | MaxReturn                1000
2017-07-02 12:55:09.810306 EDT | MinReturn                1000
2017-07-02 12:55:09.810515 EDT | AverageEsReturn            13.1948
2017-07-02 12:55:09.810728 EDT | StdEsReturn                15.8786
2017-07-02 12:55:09.810962 EDT | MaxEsReturn                93
2017-07-02 12:55:09.811161 EDT | MinEsReturn                 3
2017-07-02 12:55:09.811373 EDT | AverageDiscountedReturn    99.9957
2017-07-02 12:55:09.811577 EDT | AverageQLoss                0.0107206
2017-07-02 12:55:09.811814 EDT | AveragePolicySurr          -1.49906
2017-07-02 12:55:09.811984 EDT | AverageQ                    1.36079
2017-07-02 12:55:09.812090 EDT | AverageAbsQ                 1.36542
2017-07-02 12:55:09.812200 EDT | AverageY                    1.36083
2017-07-02 12:55:09.812336 EDT | AverageAbsY                 1.3617
2017-07-02 12:55:09.812439 EDT | AverageAbsQYDiff            0.0394442
2017-07-02 12:55:09.812540 EDT | AverageAction               0.0176226
2017-07-02 12:55:09.812640 EDT | PolicyRegParamNorm         34.9628
2017-07-02 12:55:09.812790 EDT | QFunRegParamNorm           35.6223
2017-07-02 12:55:09.812893 EDT | -----------------------  ------------
2017-07-02 12:55:09.813062 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #113 | Training started
2017-07-02 12:55:19.551170 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #113 | Training finished
2017-07-02 12:55:19.551810 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #113 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 12:55:19.552077 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #113 | Collecting samples for evaluation
2017-07-02 12:55:25.624730 EDT | -----------------------  -------------
2017-07-02 12:55:25.625350 EDT | Epoch                     113
2017-07-02 12:55:25.625542 EDT | Iteration                 113
2017-07-02 12:55:25.625684 EDT | AverageReturn            1000
2017-07-02 12:55:25.625852 EDT | StdReturn                   0
2017-07-02 12:55:25.625970 EDT | MaxReturn                1000
2017-07-02 12:55:25.626074 EDT | MinReturn                1000
2017-07-02 12:55:25.626177 EDT | AverageEsReturn            14.6176
2017-07-02 12:55:25.626378 EDT | StdEsReturn                21.1889
2017-07-02 12:55:25.626485 EDT | MaxEsReturn                98
2017-07-02 12:55:25.626586 EDT | MinEsReturn                 2
2017-07-02 12:55:25.626686 EDT | AverageDiscountedReturn    99.9957
2017-07-02 12:55:25.626797 EDT | AverageQLoss                0.00971587
2017-07-02 12:55:25.626946 EDT | AveragePolicySurr          -1.50077
2017-07-02 12:55:25.627049 EDT | AverageQ                    1.36895
2017-07-02 12:55:25.627149 EDT | AverageAbsQ                 1.37317
2017-07-02 12:55:25.627248 EDT | AverageY                    1.36904
2017-07-02 12:55:25.627360 EDT | AverageAbsY                 1.36975
2017-07-02 12:55:25.627460 EDT | AverageAbsQYDiff            0.0375966
2017-07-02 12:55:25.627559 EDT | AverageAction               0.0394247
2017-07-02 12:55:25.627658 EDT | PolicyRegParamNorm         35.0076
2017-07-02 12:55:25.627757 EDT | QFunRegParamNorm           35.7104
2017-07-02 12:55:25.627883 EDT | -----------------------  -------------
2017-07-02 12:55:25.628048 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #114 | Training started
2017-07-02 12:55:35.091514 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #114 | Training finished
2017-07-02 12:55:35.092153 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #114 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 12:55:35.092426 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #114 | Collecting samples for evaluation
2017-07-02 12:55:40.879609 EDT | -----------------------  ------------
2017-07-02 12:55:40.879815 EDT | Epoch                     114
2017-07-02 12:55:40.879935 EDT | Iteration                 114
2017-07-02 12:55:40.880134 EDT | AverageReturn            1000
2017-07-02 12:55:40.880339 EDT | StdReturn                   0
2017-07-02 12:55:40.880523 EDT | MaxReturn                1000
2017-07-02 12:55:40.880627 EDT | MinReturn                1000
2017-07-02 12:55:40.880728 EDT | AverageEsReturn            12.7324
2017-07-02 12:55:40.880849 EDT | StdEsReturn                13.8431
2017-07-02 12:55:40.881012 EDT | MaxEsReturn                70
2017-07-02 12:55:40.881205 EDT | MinEsReturn                 3
2017-07-02 12:55:40.881309 EDT | AverageDiscountedReturn    99.9957
2017-07-02 12:55:40.881408 EDT | AverageQLoss                0.0113154
2017-07-02 12:55:40.881528 EDT | AveragePolicySurr          -1.50495
2017-07-02 12:55:40.881637 EDT | AverageQ                    1.37091
2017-07-02 12:55:40.881751 EDT | AverageAbsQ                 1.37568
2017-07-02 12:55:40.881848 EDT | AverageY                    1.37095
2017-07-02 12:55:40.881945 EDT | AverageAbsY                 1.37197
2017-07-02 12:55:40.882042 EDT | AverageAbsQYDiff            0.0400659
2017-07-02 12:55:40.882144 EDT | AverageAction               0.0316001
2017-07-02 12:55:40.882273 EDT | PolicyRegParamNorm         35.0973
2017-07-02 12:55:40.882399 EDT | QFunRegParamNorm           35.9107
2017-07-02 12:55:40.882591 EDT | -----------------------  ------------
2017-07-02 12:55:40.882767 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #115 | Training started
2017-07-02 12:55:50.582175 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #115 | Training finished
2017-07-02 12:55:50.583464 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #115 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 12:55:50.583708 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #115 | Collecting samples for evaluation
2017-07-02 12:55:56.271069 EDT | -----------------------  ------------
2017-07-02 12:55:56.271787 EDT | Epoch                     115
2017-07-02 12:55:56.272054 EDT | Iteration                 115
2017-07-02 12:55:56.272284 EDT | AverageReturn            1000
2017-07-02 12:55:56.272445 EDT | StdReturn                   0
2017-07-02 12:55:56.272597 EDT | MaxReturn                1000
2017-07-02 12:55:56.272831 EDT | MinReturn                1000
2017-07-02 12:55:56.273024 EDT | AverageEsReturn            20.2264
2017-07-02 12:55:56.273240 EDT | StdEsReturn                27.2401
2017-07-02 12:55:56.273467 EDT | MaxEsReturn               133
2017-07-02 12:55:56.273706 EDT | MinEsReturn                 3
2017-07-02 12:55:56.273939 EDT | AverageDiscountedReturn    99.9957
2017-07-02 12:55:56.274101 EDT | AverageQLoss                0.0114248
2017-07-02 12:55:56.274208 EDT | AveragePolicySurr          -1.51565
2017-07-02 12:55:56.274347 EDT | AverageQ                    1.38066
2017-07-02 12:55:56.274516 EDT | AverageAbsQ                 1.38537
2017-07-02 12:55:56.274746 EDT | AverageY                    1.38075
2017-07-02 12:55:56.274939 EDT | AverageAbsY                 1.38182
2017-07-02 12:55:56.275172 EDT | AverageAbsQYDiff            0.0399061
2017-07-02 12:55:56.275394 EDT | AverageAction               0.615257
2017-07-02 12:55:56.275623 EDT | PolicyRegParamNorm         35.1931
2017-07-02 12:55:56.275851 EDT | QFunRegParamNorm           36.0243
2017-07-02 12:55:56.276049 EDT | -----------------------  ------------
2017-07-02 12:55:56.276376 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #116 | Training started
2017-07-02 12:56:05.984950 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #116 | Training finished
2017-07-02 12:56:05.985463 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #116 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 12:56:05.985691 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #116 | Collecting samples for evaluation
2017-07-02 12:56:11.650328 EDT | -----------------------  ------------
2017-07-02 12:56:11.650624 EDT | Epoch                     116
2017-07-02 12:56:11.650806 EDT | Iteration                 116
2017-07-02 12:56:11.650933 EDT | AverageReturn            1000
2017-07-02 12:56:11.651040 EDT | StdReturn                   0
2017-07-02 12:56:11.651252 EDT | MaxReturn                1000
2017-07-02 12:56:11.651443 EDT | MinReturn                1000
2017-07-02 12:56:11.651587 EDT | AverageEsReturn            17.2373
2017-07-02 12:56:11.651710 EDT | StdEsReturn                21.0289
2017-07-02 12:56:11.651877 EDT | MaxEsReturn               114
2017-07-02 12:56:11.652011 EDT | MinEsReturn                 3
2017-07-02 12:56:11.652118 EDT | AverageDiscountedReturn    99.9957
2017-07-02 12:56:11.652321 EDT | AverageQLoss                0.0109393
2017-07-02 12:56:11.652467 EDT | AveragePolicySurr          -1.51698
2017-07-02 12:56:11.652602 EDT | AverageQ                    1.38084
2017-07-02 12:56:11.652708 EDT | AverageAbsQ                 1.38546
2017-07-02 12:56:11.652829 EDT | AverageY                    1.381
2017-07-02 12:56:11.652932 EDT | AverageAbsY                 1.38199
2017-07-02 12:56:11.653073 EDT | AverageAbsQYDiff            0.0398046
2017-07-02 12:56:11.653186 EDT | AverageAction               0.0530125
2017-07-02 12:56:11.653325 EDT | PolicyRegParamNorm         35.3314
2017-07-02 12:56:11.653466 EDT | QFunRegParamNorm           36.1387
2017-07-02 12:56:11.653692 EDT | -----------------------  ------------
2017-07-02 12:56:11.653956 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #117 | Training started
2017-07-02 12:56:21.291431 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #117 | Training finished
2017-07-02 12:56:21.291954 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #117 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 12:56:21.292112 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #117 | Collecting samples for evaluation
2017-07-02 12:56:26.959839 EDT | -----------------------  ------------
2017-07-02 12:56:26.960329 EDT | Epoch                     117
2017-07-02 12:56:26.960479 EDT | Iteration                 117
2017-07-02 12:56:26.960617 EDT | AverageReturn            1000
2017-07-02 12:56:26.960763 EDT | StdReturn                   0
2017-07-02 12:56:26.960905 EDT | MaxReturn                1000
2017-07-02 12:56:26.961037 EDT | MinReturn                1000
2017-07-02 12:56:26.961180 EDT | AverageEsReturn            22.6818
2017-07-02 12:56:26.961307 EDT | StdEsReturn                32.2911
2017-07-02 12:56:26.961417 EDT | MaxEsReturn               162
2017-07-02 12:56:26.961543 EDT | MinEsReturn                 3
2017-07-02 12:56:26.961676 EDT | AverageDiscountedReturn    99.9957
2017-07-02 12:56:26.961825 EDT | AverageQLoss                0.0115051
2017-07-02 12:56:26.961965 EDT | AveragePolicySurr          -1.52164
2017-07-02 12:56:26.962081 EDT | AverageQ                    1.38827
2017-07-02 12:56:26.962215 EDT | AverageAbsQ                 1.39287
2017-07-02 12:56:26.962319 EDT | AverageY                    1.38829
2017-07-02 12:56:26.962440 EDT | AverageAbsY                 1.38921
2017-07-02 12:56:26.962649 EDT | AverageAbsQYDiff            0.0403457
2017-07-02 12:56:26.962845 EDT | AverageAction               0.16076
2017-07-02 12:56:26.962951 EDT | PolicyRegParamNorm         35.3937
2017-07-02 12:56:26.963101 EDT | QFunRegParamNorm           36.2521
2017-07-02 12:56:26.963220 EDT | -----------------------  ------------
2017-07-02 12:56:26.963466 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #118 | Training started
2017-07-02 12:56:36.531795 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #118 | Training finished
2017-07-02 12:56:36.532392 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #118 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 12:56:36.532639 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #118 | Collecting samples for evaluation
2017-07-02 12:56:42.270400 EDT | -----------------------  ------------
2017-07-02 12:56:42.270689 EDT | Epoch                     118
2017-07-02 12:56:42.270887 EDT | Iteration                 118
2017-07-02 12:56:42.271096 EDT | AverageReturn            1000
2017-07-02 12:56:42.271271 EDT | StdReturn                   0
2017-07-02 12:56:42.271438 EDT | MaxReturn                1000
2017-07-02 12:56:42.271544 EDT | MinReturn                1000
2017-07-02 12:56:42.271700 EDT | AverageEsReturn            17.9643
2017-07-02 12:56:42.271826 EDT | StdEsReturn                17.34
2017-07-02 12:56:42.272021 EDT | MaxEsReturn                83
2017-07-02 12:56:42.272133 EDT | MinEsReturn                 3
2017-07-02 12:56:42.272233 EDT | AverageDiscountedReturn    99.9957
2017-07-02 12:56:42.272378 EDT | AverageQLoss                0.011686
2017-07-02 12:56:42.272478 EDT | AveragePolicySurr          -1.52193
2017-07-02 12:56:42.272660 EDT | AverageQ                    1.38907
2017-07-02 12:56:42.272764 EDT | AverageAbsQ                 1.39379
2017-07-02 12:56:42.272862 EDT | AverageY                    1.38906
2017-07-02 12:56:42.273040 EDT | AverageAbsY                 1.39005
2017-07-02 12:56:42.273222 EDT | AverageAbsQYDiff            0.0410021
2017-07-02 12:56:42.273398 EDT | AverageAction               0.202808
2017-07-02 12:56:42.273633 EDT | PolicyRegParamNorm         35.3846
2017-07-02 12:56:42.273837 EDT | QFunRegParamNorm           36.4486
2017-07-02 12:56:42.273965 EDT | -----------------------  ------------
2017-07-02 12:56:42.274138 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #119 | Training started
2017-07-02 12:56:51.833476 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #119 | Training finished
2017-07-02 12:56:51.834077 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #119 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 12:56:51.834312 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #119 | Collecting samples for evaluation
2017-07-02 12:56:57.653083 EDT | -----------------------  -------------
2017-07-02 12:56:57.653677 EDT | Epoch                     119
2017-07-02 12:56:57.653824 EDT | Iteration                 119
2017-07-02 12:56:57.653983 EDT | AverageReturn            1000
2017-07-02 12:56:57.654191 EDT | StdReturn                   0
2017-07-02 12:56:57.654337 EDT | MaxReturn                1000
2017-07-02 12:56:57.654441 EDT | MinReturn                1000
2017-07-02 12:56:57.654561 EDT | AverageEsReturn            19.5882
2017-07-02 12:56:57.654749 EDT | StdEsReturn                26.1438
2017-07-02 12:56:57.654909 EDT | MaxEsReturn               134
2017-07-02 12:56:57.655039 EDT | MinEsReturn                 3
2017-07-02 12:56:57.655142 EDT | AverageDiscountedReturn    99.9957
2017-07-02 12:56:57.655244 EDT | AverageQLoss                0.00999309
2017-07-02 12:56:57.655419 EDT | AveragePolicySurr          -1.52773
2017-07-02 12:56:57.655537 EDT | AverageQ                    1.39549
2017-07-02 12:56:57.655648 EDT | AverageAbsQ                 1.40007
2017-07-02 12:56:57.655811 EDT | AverageY                    1.39558
2017-07-02 12:56:57.655956 EDT | AverageAbsY                 1.39668
2017-07-02 12:56:57.656157 EDT | AverageAbsQYDiff            0.0370036
2017-07-02 12:56:57.656362 EDT | AverageAction               0.38728
2017-07-02 12:56:57.656560 EDT | PolicyRegParamNorm         35.453
2017-07-02 12:56:57.656751 EDT | QFunRegParamNorm           36.6315
2017-07-02 12:56:57.656897 EDT | -----------------------  -------------
2017-07-02 12:56:57.657208 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #120 | Training started
2017-07-02 12:57:07.182849 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #120 | Training finished
2017-07-02 12:57:07.183592 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #120 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 12:57:07.183866 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #120 | Collecting samples for evaluation
2017-07-02 12:57:12.962336 EDT | -----------------------  ------------
2017-07-02 12:57:12.962540 EDT | Epoch                     120
2017-07-02 12:57:12.962692 EDT | Iteration                 120
2017-07-02 12:57:12.962804 EDT | AverageReturn            1000
2017-07-02 12:57:12.962912 EDT | StdReturn                   0
2017-07-02 12:57:12.963099 EDT | MaxReturn                1000
2017-07-02 12:57:12.963223 EDT | MinReturn                1000
2017-07-02 12:57:12.963336 EDT | AverageEsReturn            22.9302
2017-07-02 12:57:12.963443 EDT | StdEsReturn                23.6027
2017-07-02 12:57:12.963542 EDT | MaxEsReturn                94
2017-07-02 12:57:12.963640 EDT | MinEsReturn                 3
2017-07-02 12:57:12.963744 EDT | AverageDiscountedReturn    99.9957
2017-07-02 12:57:12.963931 EDT | AverageQLoss                0.0111671
2017-07-02 12:57:12.964106 EDT | AveragePolicySurr          -1.53242
2017-07-02 12:57:12.964237 EDT | AverageQ                    1.39814
2017-07-02 12:57:12.964449 EDT | AverageAbsQ                 1.40345
2017-07-02 12:57:12.964605 EDT | AverageY                    1.39834
2017-07-02 12:57:12.964744 EDT | AverageAbsY                 1.39944
2017-07-02 12:57:12.964868 EDT | AverageAbsQYDiff            0.0391635
2017-07-02 12:57:12.964977 EDT | AverageAction               0.0910446
2017-07-02 12:57:12.965102 EDT | PolicyRegParamNorm         35.5058
2017-07-02 12:57:12.965210 EDT | QFunRegParamNorm           36.7939
2017-07-02 12:57:12.965317 EDT | -----------------------  ------------
2017-07-02 12:57:12.965543 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #121 | Training started
2017-07-02 12:57:22.567583 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #121 | Training finished
2017-07-02 12:57:22.568137 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #121 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 12:57:22.568399 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #121 | Collecting samples for evaluation
2017-07-02 12:57:28.226667 EDT | -----------------------  ------------
2017-07-02 12:57:28.227211 EDT | Epoch                     121
2017-07-02 12:57:28.227405 EDT | Iteration                 121
2017-07-02 12:57:28.227650 EDT | AverageReturn            1000
2017-07-02 12:57:28.227875 EDT | StdReturn                   0
2017-07-02 12:57:28.228097 EDT | MaxReturn                1000
2017-07-02 12:57:28.228309 EDT | MinReturn                1000
2017-07-02 12:57:28.228533 EDT | AverageEsReturn            17.05
2017-07-02 12:57:28.228751 EDT | StdEsReturn                19.8926
2017-07-02 12:57:28.228950 EDT | MaxEsReturn               106
2017-07-02 12:57:28.229067 EDT | MinEsReturn                 3
2017-07-02 12:57:28.229169 EDT | AverageDiscountedReturn    99.9957
2017-07-02 12:57:28.229324 EDT | AverageQLoss                0.0103781
2017-07-02 12:57:28.229574 EDT | AveragePolicySurr          -1.53234
2017-07-02 12:57:28.229826 EDT | AverageQ                    1.40234
2017-07-02 12:57:28.229944 EDT | AverageAbsQ                 1.40677
2017-07-02 12:57:28.230084 EDT | AverageY                    1.40222
2017-07-02 12:57:28.230187 EDT | AverageAbsY                 1.40309
2017-07-02 12:57:28.230288 EDT | AverageAbsQYDiff            0.0380018
2017-07-02 12:57:28.230389 EDT | AverageAction               0.109924
2017-07-02 12:57:28.230488 EDT | PolicyRegParamNorm         35.594
2017-07-02 12:57:28.230585 EDT | QFunRegParamNorm           36.9071
2017-07-02 12:57:28.230684 EDT | -----------------------  ------------
2017-07-02 12:57:28.230902 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #122 | Training started
2017-07-02 12:57:37.871986 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #122 | Training finished
2017-07-02 12:57:37.872638 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #122 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 12:57:37.872849 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #122 | Collecting samples for evaluation
2017-07-02 12:57:43.581874 EDT | -----------------------  ------------
2017-07-02 12:57:43.582132 EDT | Epoch                     122
2017-07-02 12:57:43.582243 EDT | Iteration                 122
2017-07-02 12:57:43.582348 EDT | AverageReturn            1000
2017-07-02 12:57:43.582494 EDT | StdReturn                   0
2017-07-02 12:57:43.582610 EDT | MaxReturn                1000
2017-07-02 12:57:43.582735 EDT | MinReturn                1000
2017-07-02 12:57:43.582846 EDT | AverageEsReturn            14.2286
2017-07-02 12:57:43.582953 EDT | StdEsReturn                13.8504
2017-07-02 12:57:43.583177 EDT | MaxEsReturn                60
2017-07-02 12:57:43.583385 EDT | MinEsReturn                 3
2017-07-02 12:57:43.583588 EDT | AverageDiscountedReturn    99.9957
2017-07-02 12:57:43.583822 EDT | AverageQLoss                0.0105132
2017-07-02 12:57:43.584034 EDT | AveragePolicySurr          -1.53858
2017-07-02 12:57:43.584253 EDT | AverageQ                    1.40569
2017-07-02 12:57:43.584454 EDT | AverageAbsQ                 1.40996
2017-07-02 12:57:43.584677 EDT | AverageY                    1.40582
2017-07-02 12:57:43.584906 EDT | AverageAbsY                 1.40674
2017-07-02 12:57:43.585097 EDT | AverageAbsQYDiff            0.0373625
2017-07-02 12:57:43.585329 EDT | AverageAction               0.444196
2017-07-02 12:57:43.585583 EDT | PolicyRegParamNorm         35.7159
2017-07-02 12:57:43.585796 EDT | QFunRegParamNorm           37.0508
2017-07-02 12:57:43.586032 EDT | -----------------------  ------------
2017-07-02 12:57:43.586322 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #123 | Training started
2017-07-02 12:57:53.226086 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #123 | Training finished
2017-07-02 12:57:53.226891 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #123 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 12:57:53.227134 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #123 | Collecting samples for evaluation
2017-07-02 12:57:58.981036 EDT | -----------------------  -----------
2017-07-02 12:57:58.998325 EDT | Epoch                     123
2017-07-02 12:57:58.998584 EDT | Iteration                 123
2017-07-02 12:57:58.998754 EDT | AverageReturn            1000
2017-07-02 12:57:58.998891 EDT | StdReturn                   0
2017-07-02 12:57:58.999006 EDT | MaxReturn                1000
2017-07-02 12:57:58.999130 EDT | MinReturn                1000
2017-07-02 12:57:58.999297 EDT | AverageEsReturn            20.1915
2017-07-02 12:57:58.999458 EDT | StdEsReturn                18.5549
2017-07-02 12:57:58.999567 EDT | MaxEsReturn                83
2017-07-02 12:57:58.999721 EDT | MinEsReturn                 3
2017-07-02 12:57:58.999872 EDT | AverageDiscountedReturn    99.9957
2017-07-02 12:57:59.000060 EDT | AverageQLoss                0.010434
2017-07-02 12:57:59.000174 EDT | AveragePolicySurr          -1.54268
2017-07-02 12:57:59.000351 EDT | AverageQ                    1.40888
2017-07-02 12:57:59.000456 EDT | AverageAbsQ                 1.41346
2017-07-02 12:57:59.000559 EDT | AverageY                    1.40887
2017-07-02 12:57:59.000672 EDT | AverageAbsY                 1.40984
2017-07-02 12:57:59.000874 EDT | AverageAbsQYDiff            0.036879
2017-07-02 12:57:59.001068 EDT | AverageAction               0.271823
2017-07-02 12:57:59.001260 EDT | PolicyRegParamNorm         35.8446
2017-07-02 12:57:59.001374 EDT | QFunRegParamNorm           37.2156
2017-07-02 12:57:59.001546 EDT | -----------------------  -----------
2017-07-02 12:57:59.001728 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #124 | Training started
2017-07-02 12:58:08.618893 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #124 | Training finished
2017-07-02 12:58:08.619470 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #124 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 12:58:08.619682 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #124 | Collecting samples for evaluation
2017-07-02 12:58:14.377242 EDT | -----------------------  ------------
2017-07-02 12:58:14.377440 EDT | Epoch                     124
2017-07-02 12:58:14.377634 EDT | Iteration                 124
2017-07-02 12:58:14.377859 EDT | AverageReturn            1000
2017-07-02 12:58:14.378082 EDT | StdReturn                   0
2017-07-02 12:58:14.378265 EDT | MaxReturn                1000
2017-07-02 12:58:14.378454 EDT | MinReturn                1000
2017-07-02 12:58:14.378689 EDT | AverageEsReturn            19.9808
2017-07-02 12:58:14.378808 EDT | StdEsReturn                23.211
2017-07-02 12:58:14.379016 EDT | MaxEsReturn               115
2017-07-02 12:58:14.379242 EDT | MinEsReturn                 3
2017-07-02 12:58:14.379429 EDT | AverageDiscountedReturn    99.9957
2017-07-02 12:58:14.379623 EDT | AverageQLoss                0.0109933
2017-07-02 12:58:14.379795 EDT | AveragePolicySurr          -1.54489
2017-07-02 12:58:14.380010 EDT | AverageQ                    1.41666
2017-07-02 12:58:14.380231 EDT | AverageAbsQ                 1.42142
2017-07-02 12:58:14.380351 EDT | AverageY                    1.41668
2017-07-02 12:58:14.380463 EDT | AverageAbsY                 1.41764
2017-07-02 12:58:14.380669 EDT | AverageAbsQYDiff            0.0384303
2017-07-02 12:58:14.380894 EDT | AverageAction               0.169848
2017-07-02 12:58:14.381111 EDT | PolicyRegParamNorm         35.9985
2017-07-02 12:58:14.381347 EDT | QFunRegParamNorm           37.352
2017-07-02 12:58:14.381578 EDT | -----------------------  ------------
2017-07-02 12:58:14.381897 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #125 | Training started
2017-07-02 12:58:24.033882 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #125 | Training finished
2017-07-02 12:58:24.034597 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #125 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 12:58:24.034792 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #125 | Collecting samples for evaluation
2017-07-02 12:58:29.701529 EDT | -----------------------  ------------
2017-07-02 12:58:29.702158 EDT | Epoch                     125
2017-07-02 12:58:29.702446 EDT | Iteration                 125
2017-07-02 12:58:29.702657 EDT | AverageReturn            1000
2017-07-02 12:58:29.702889 EDT | StdReturn                   0
2017-07-02 12:58:29.703067 EDT | MaxReturn                1000
2017-07-02 12:58:29.703300 EDT | MinReturn                1000
2017-07-02 12:58:29.703503 EDT | AverageEsReturn            19.1923
2017-07-02 12:58:29.703735 EDT | StdEsReturn                16.6121
2017-07-02 12:58:29.703959 EDT | MaxEsReturn                65
2017-07-02 12:58:29.704188 EDT | MinEsReturn                 3
2017-07-02 12:58:29.704412 EDT | AverageDiscountedReturn    99.9957
2017-07-02 12:58:29.704627 EDT | AverageQLoss                0.0118185
2017-07-02 12:58:29.704860 EDT | AveragePolicySurr          -1.54141
2017-07-02 12:58:29.705090 EDT | AverageQ                    1.41107
2017-07-02 12:58:29.705308 EDT | AverageAbsQ                 1.41635
2017-07-02 12:58:29.705633 EDT | AverageY                    1.41105
2017-07-02 12:58:29.705854 EDT | AverageAbsY                 1.41202
2017-07-02 12:58:29.706164 EDT | AverageAbsQYDiff            0.0401577
2017-07-02 12:58:29.706313 EDT | AverageAction               0.186021
2017-07-02 12:58:29.706422 EDT | PolicyRegParamNorm         36.0684
2017-07-02 12:58:29.706525 EDT | QFunRegParamNorm           37.3789
2017-07-02 12:58:29.706661 EDT | -----------------------  ------------
2017-07-02 12:58:29.706995 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #126 | Training started
2017-07-02 12:58:39.294627 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #126 | Training finished
2017-07-02 12:58:39.295593 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #126 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 12:58:39.295748 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #126 | Collecting samples for evaluation
2017-07-02 12:58:44.941513 EDT | -----------------------  -------------
2017-07-02 12:58:44.942019 EDT | Epoch                     126
2017-07-02 12:58:44.942251 EDT | Iteration                 126
2017-07-02 12:58:44.942424 EDT | AverageReturn            1000
2017-07-02 12:58:44.942601 EDT | StdReturn                   0
2017-07-02 12:58:44.942791 EDT | MaxReturn                1000
2017-07-02 12:58:44.942913 EDT | MinReturn                1000
2017-07-02 12:58:44.943040 EDT | AverageEsReturn            17.0364
2017-07-02 12:58:44.943143 EDT | StdEsReturn                19.5717
2017-07-02 12:58:44.943301 EDT | MaxEsReturn                82
2017-07-02 12:58:44.943434 EDT | MinEsReturn                 3
2017-07-02 12:58:44.943537 EDT | AverageDiscountedReturn    99.9957
2017-07-02 12:58:44.943659 EDT | AverageQLoss                0.00946462
2017-07-02 12:58:44.943777 EDT | AveragePolicySurr          -1.54627
2017-07-02 12:58:44.943878 EDT | AverageQ                    1.4206
2017-07-02 12:58:44.943992 EDT | AverageAbsQ                 1.42451
2017-07-02 12:58:44.944098 EDT | AverageY                    1.42076
2017-07-02 12:58:44.944197 EDT | AverageAbsY                 1.42145
2017-07-02 12:58:44.944336 EDT | AverageAbsQYDiff            0.0343996
2017-07-02 12:58:44.944524 EDT | AverageAction               0.15226
2017-07-02 12:58:44.944665 EDT | PolicyRegParamNorm         36.1973
2017-07-02 12:58:44.944853 EDT | QFunRegParamNorm           37.4985
2017-07-02 12:58:44.944992 EDT | -----------------------  -------------
2017-07-02 12:58:44.945197 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #127 | Training started
2017-07-02 12:58:54.720931 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #127 | Training finished
2017-07-02 12:58:54.721547 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #127 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 12:58:54.721821 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #127 | Collecting samples for evaluation
2017-07-02 12:59:00.283627 EDT | -----------------------  ------------
2017-07-02 12:59:00.283865 EDT | Epoch                     127
2017-07-02 12:59:00.284075 EDT | Iteration                 127
2017-07-02 12:59:00.284308 EDT | AverageReturn            1000
2017-07-02 12:59:00.284509 EDT | StdReturn                   0
2017-07-02 12:59:00.284641 EDT | MaxReturn                1000
2017-07-02 12:59:00.284855 EDT | MinReturn                1000
2017-07-02 12:59:00.285084 EDT | AverageEsReturn            20.0962
2017-07-02 12:59:00.285271 EDT | StdEsReturn                20.4284
2017-07-02 12:59:00.285378 EDT | MaxEsReturn                98
2017-07-02 12:59:00.285482 EDT | MinEsReturn                 3
2017-07-02 12:59:00.286008 EDT | AverageDiscountedReturn    99.9957
2017-07-02 12:59:00.286142 EDT | AverageQLoss                0.0104248
2017-07-02 12:59:00.286249 EDT | AveragePolicySurr          -1.55151
2017-07-02 12:59:00.286427 EDT | AverageQ                    1.42007
2017-07-02 12:59:00.286542 EDT | AverageAbsQ                 1.42416
2017-07-02 12:59:00.286666 EDT | AverageY                    1.42007
2017-07-02 12:59:00.286841 EDT | AverageAbsY                 1.42075
2017-07-02 12:59:00.286945 EDT | AverageAbsQYDiff            0.0376786
2017-07-02 12:59:00.287054 EDT | AverageAction               0.442076
2017-07-02 12:59:00.287160 EDT | PolicyRegParamNorm         36.24
2017-07-02 12:59:00.287284 EDT | QFunRegParamNorm           37.6313
2017-07-02 12:59:00.287485 EDT | -----------------------  ------------
2017-07-02 12:59:00.287695 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #128 | Training started
2017-07-02 12:59:10.089840 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #128 | Training finished
2017-07-02 12:59:10.090058 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #128 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 12:59:10.090188 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #128 | Collecting samples for evaluation
2017-07-02 12:59:15.731216 EDT | -----------------------  ------------
2017-07-02 12:59:15.731725 EDT | Epoch                     128
2017-07-02 12:59:15.731969 EDT | Iteration                 128
2017-07-02 12:59:15.732204 EDT | AverageReturn            1000
2017-07-02 12:59:15.732375 EDT | StdReturn                   0
2017-07-02 12:59:15.732570 EDT | MaxReturn                1000
2017-07-02 12:59:15.732767 EDT | MinReturn                1000
2017-07-02 12:59:15.732948 EDT | AverageEsReturn            17.5424
2017-07-02 12:59:15.733163 EDT | StdEsReturn                19.9782
2017-07-02 12:59:15.733389 EDT | MaxEsReturn                84
2017-07-02 12:59:15.733617 EDT | MinEsReturn                 3
2017-07-02 12:59:15.733847 EDT | AverageDiscountedReturn    99.9957
2017-07-02 12:59:15.734073 EDT | AverageQLoss                0.0106522
2017-07-02 12:59:15.734299 EDT | AveragePolicySurr          -1.55141
2017-07-02 12:59:15.734525 EDT | AverageQ                    1.42484
2017-07-02 12:59:15.734678 EDT | AverageAbsQ                 1.42888
2017-07-02 12:59:15.734908 EDT | AverageY                    1.4249
2017-07-02 12:59:15.735110 EDT | AverageAbsY                 1.42531
2017-07-02 12:59:15.735310 EDT | AverageAbsQYDiff            0.0377902
2017-07-02 12:59:15.735539 EDT | AverageAction               0.507057
2017-07-02 12:59:15.735752 EDT | PolicyRegParamNorm         36.3108
2017-07-02 12:59:15.735980 EDT | QFunRegParamNorm           37.7338
2017-07-02 12:59:15.736198 EDT | -----------------------  ------------
2017-07-02 12:59:15.736454 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #129 | Training started
2017-07-02 12:59:25.601204 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #129 | Training finished
2017-07-02 12:59:25.601829 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #129 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 12:59:25.602013 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #129 | Collecting samples for evaluation
2017-07-02 12:59:31.131714 EDT | -----------------------  ------------
2017-07-02 12:59:31.132005 EDT | Epoch                     129
2017-07-02 12:59:31.132124 EDT | Iteration                 129
2017-07-02 12:59:31.132229 EDT | AverageReturn            1000
2017-07-02 12:59:31.132331 EDT | StdReturn                   0
2017-07-02 12:59:31.132432 EDT | MaxReturn                1000
2017-07-02 12:59:31.132654 EDT | MinReturn                1000
2017-07-02 12:59:31.132867 EDT | AverageEsReturn            14.6765
2017-07-02 12:59:31.133095 EDT | StdEsReturn                15.5161
2017-07-02 12:59:31.133315 EDT | MaxEsReturn                72
2017-07-02 12:59:31.133555 EDT | MinEsReturn                 3
2017-07-02 12:59:31.133773 EDT | AverageDiscountedReturn    99.9957
2017-07-02 12:59:31.133996 EDT | AverageQLoss                0.0109904
2017-07-02 12:59:31.134218 EDT | AveragePolicySurr          -1.5567
2017-07-02 12:59:31.134391 EDT | AverageQ                    1.42697
2017-07-02 12:59:31.134620 EDT | AverageAbsQ                 1.43117
2017-07-02 12:59:31.134838 EDT | AverageY                    1.42698
2017-07-02 12:59:31.135064 EDT | AverageAbsY                 1.4274
2017-07-02 12:59:31.135264 EDT | AverageAbsQYDiff            0.0366647
2017-07-02 12:59:31.135491 EDT | AverageAction               0.656778
2017-07-02 12:59:31.135704 EDT | PolicyRegParamNorm         36.3814
2017-07-02 12:59:31.135932 EDT | QFunRegParamNorm           37.8629
2017-07-02 12:59:31.136150 EDT | -----------------------  ------------
2017-07-02 12:59:31.136473 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #130 | Training started
2017-07-02 12:59:41.134192 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #130 | Training finished
2017-07-02 12:59:41.134491 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #130 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 12:59:41.134739 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #130 | Collecting samples for evaluation
2017-07-02 12:59:46.693958 EDT | -----------------------  ------------
2017-07-02 12:59:46.694465 EDT | Epoch                     130
2017-07-02 12:59:46.694720 EDT | Iteration                 130
2017-07-02 12:59:46.694956 EDT | AverageReturn            1000
2017-07-02 12:59:46.695175 EDT | StdReturn                   0
2017-07-02 12:59:46.695409 EDT | MaxReturn                1000
2017-07-02 12:59:46.695605 EDT | MinReturn                1000
2017-07-02 12:59:46.695817 EDT | AverageEsReturn            15.4531
2017-07-02 12:59:46.696047 EDT | StdEsReturn                18.6731
2017-07-02 12:59:46.696217 EDT | MaxEsReturn                82
2017-07-02 12:59:46.696449 EDT | MinEsReturn                 3
2017-07-02 12:59:46.696662 EDT | AverageDiscountedReturn    99.9957
2017-07-02 12:59:46.696895 EDT | AverageQLoss                0.0115069
2017-07-02 12:59:46.697124 EDT | AveragePolicySurr          -1.56284
2017-07-02 12:59:46.697352 EDT | AverageQ                    1.4347
2017-07-02 12:59:46.697724 EDT | AverageAbsQ                 1.43852
2017-07-02 12:59:46.697961 EDT | AverageY                    1.43486
2017-07-02 12:59:46.698164 EDT | AverageAbsY                 1.4354
2017-07-02 12:59:46.698308 EDT | AverageAbsQYDiff            0.0374365
2017-07-02 12:59:46.698414 EDT | AverageAction               0.69112
2017-07-02 12:59:46.698517 EDT | PolicyRegParamNorm         36.4152
2017-07-02 12:59:46.698632 EDT | QFunRegParamNorm           38.0125
2017-07-02 12:59:46.698833 EDT | -----------------------  ------------
2017-07-02 12:59:46.699165 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #131 | Training started
2017-07-02 12:59:56.408356 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #131 | Training finished
2017-07-02 12:59:56.409032 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #131 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 12:59:56.409281 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #131 | Collecting samples for evaluation
2017-07-02 13:00:02.022137 EDT | -----------------------  ------------
2017-07-02 13:00:02.022402 EDT | Epoch                     131
2017-07-02 13:00:02.022623 EDT | Iteration                 131
2017-07-02 13:00:02.022744 EDT | AverageReturn            1000
2017-07-02 13:00:02.022849 EDT | StdReturn                   0
2017-07-02 13:00:02.022970 EDT | MaxReturn                1000
2017-07-02 13:00:02.023072 EDT | MinReturn                1000
2017-07-02 13:00:02.023172 EDT | AverageEsReturn            15.3485
2017-07-02 13:00:02.023295 EDT | StdEsReturn                17.6691
2017-07-02 13:00:02.023494 EDT | MaxEsReturn                85
2017-07-02 13:00:02.023682 EDT | MinEsReturn                 3
2017-07-02 13:00:02.023852 EDT | AverageDiscountedReturn    99.9957
2017-07-02 13:00:02.023967 EDT | AverageQLoss                0.0111316
2017-07-02 13:00:02.024123 EDT | AveragePolicySurr          -1.55798
2017-07-02 13:00:02.024279 EDT | AverageQ                    1.43033
2017-07-02 13:00:02.024382 EDT | AverageAbsQ                 1.43477
2017-07-02 13:00:02.024513 EDT | AverageY                    1.43036
2017-07-02 13:00:02.024615 EDT | AverageAbsY                 1.43083
2017-07-02 13:00:02.024790 EDT | AverageAbsQYDiff            0.0366123
2017-07-02 13:00:02.024961 EDT | AverageAction               0.452312
2017-07-02 13:00:02.025146 EDT | PolicyRegParamNorm         36.4702
2017-07-02 13:00:02.025251 EDT | QFunRegParamNorm           38.1186
2017-07-02 13:00:02.025360 EDT | -----------------------  ------------
2017-07-02 13:00:02.025611 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #132 | Training started
2017-07-02 13:00:11.713122 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #132 | Training finished
2017-07-02 13:00:11.713799 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #132 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 13:00:11.713937 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #132 | Collecting samples for evaluation
2017-07-02 13:00:17.400613 EDT | -----------------------  ------------
2017-07-02 13:00:17.400801 EDT | Epoch                     132
2017-07-02 13:00:17.400922 EDT | Iteration                 132
2017-07-02 13:00:17.401099 EDT | AverageReturn            1000
2017-07-02 13:00:17.401271 EDT | StdReturn                   0
2017-07-02 13:00:17.401423 EDT | MaxReturn                1000
2017-07-02 13:00:17.401549 EDT | MinReturn                1000
2017-07-02 13:00:17.401653 EDT | AverageEsReturn            21.6512
2017-07-02 13:00:17.401755 EDT | StdEsReturn                19.4229
2017-07-02 13:00:17.401857 EDT | MaxEsReturn                85
2017-07-02 13:00:17.401958 EDT | MinEsReturn                 3
2017-07-02 13:00:17.402058 EDT | AverageDiscountedReturn    99.9957
2017-07-02 13:00:17.402158 EDT | AverageQLoss                0.0115293
2017-07-02 13:00:17.402259 EDT | AveragePolicySurr          -1.55848
2017-07-02 13:00:17.402357 EDT | AverageQ                    1.43093
2017-07-02 13:00:17.402485 EDT | AverageAbsQ                 1.43512
2017-07-02 13:00:17.402587 EDT | AverageY                    1.43092
2017-07-02 13:00:17.402687 EDT | AverageAbsY                 1.43148
2017-07-02 13:00:17.402786 EDT | AverageAbsQYDiff            0.0378598
2017-07-02 13:00:17.402886 EDT | AverageAction               0.17595
2017-07-02 13:00:17.403011 EDT | PolicyRegParamNorm         36.6695
2017-07-02 13:00:17.403112 EDT | QFunRegParamNorm           38.27
2017-07-02 13:00:17.403213 EDT | -----------------------  ------------
2017-07-02 13:00:17.403435 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #133 | Training started
2017-07-02 13:00:27.676169 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #133 | Training finished
2017-07-02 13:00:27.676887 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #133 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 13:00:27.677086 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #133 | Collecting samples for evaluation
2017-07-02 13:00:33.328116 EDT | -----------------------  ------------
2017-07-02 13:00:33.328331 EDT | Epoch                     133
2017-07-02 13:00:33.328444 EDT | Iteration                 133
2017-07-02 13:00:33.328619 EDT | AverageReturn            1000
2017-07-02 13:00:33.328778 EDT | StdReturn                   0
2017-07-02 13:00:33.328956 EDT | MaxReturn                1000
2017-07-02 13:00:33.329102 EDT | MinReturn                1000
2017-07-02 13:00:33.329227 EDT | AverageEsReturn            18.5357
2017-07-02 13:00:33.329355 EDT | StdEsReturn                18.7664
2017-07-02 13:00:33.329457 EDT | MaxEsReturn                77
2017-07-02 13:00:33.329914 EDT | MinEsReturn                 3
2017-07-02 13:00:33.330108 EDT | AverageDiscountedReturn    99.9957
2017-07-02 13:00:33.330233 EDT | AverageQLoss                0.011615
2017-07-02 13:00:33.330390 EDT | AveragePolicySurr          -1.56065
2017-07-02 13:00:33.330592 EDT | AverageQ                    1.43454
2017-07-02 13:00:33.330789 EDT | AverageAbsQ                 1.43894
2017-07-02 13:00:33.330993 EDT | AverageY                    1.43461
2017-07-02 13:00:33.331159 EDT | AverageAbsY                 1.43519
2017-07-02 13:00:33.331289 EDT | AverageAbsQYDiff            0.0379485
2017-07-02 13:00:33.331403 EDT | AverageAction               0.829579
2017-07-02 13:00:33.331531 EDT | PolicyRegParamNorm         36.6884
2017-07-02 13:00:33.331637 EDT | QFunRegParamNorm           38.4251
2017-07-02 13:00:33.331769 EDT | -----------------------  ------------
2017-07-02 13:00:33.331983 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #134 | Training started
2017-07-02 13:00:43.009644 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #134 | Training finished
2017-07-02 13:00:43.010367 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #134 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 13:00:43.010689 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #134 | Collecting samples for evaluation
2017-07-02 13:00:48.664509 EDT | -----------------------  ------------
2017-07-02 13:00:48.664714 EDT | Epoch                     134
2017-07-02 13:00:48.664854 EDT | Iteration                 134
2017-07-02 13:00:48.665024 EDT | AverageReturn            1000
2017-07-02 13:00:48.665145 EDT | StdReturn                   0
2017-07-02 13:00:48.665249 EDT | MaxReturn                1000
2017-07-02 13:00:48.665383 EDT | MinReturn                1000
2017-07-02 13:00:48.665506 EDT | AverageEsReturn            23.3864
2017-07-02 13:00:48.665655 EDT | StdEsReturn                28.3503
2017-07-02 13:00:48.665773 EDT | MaxEsReturn               159
2017-07-02 13:00:48.665960 EDT | MinEsReturn                 3
2017-07-02 13:00:48.666141 EDT | AverageDiscountedReturn    99.9957
2017-07-02 13:00:48.666335 EDT | AverageQLoss                0.010704
2017-07-02 13:00:48.666454 EDT | AveragePolicySurr          -1.5605
2017-07-02 13:00:48.666580 EDT | AverageQ                    1.4315
2017-07-02 13:00:48.666717 EDT | AverageAbsQ                 1.43565
2017-07-02 13:00:48.666858 EDT | AverageY                    1.43159
2017-07-02 13:00:48.666965 EDT | AverageAbsY                 1.43188
2017-07-02 13:00:48.667085 EDT | AverageAbsQYDiff            0.0359512
2017-07-02 13:00:48.667202 EDT | AverageAction               0.221325
2017-07-02 13:00:48.667385 EDT | PolicyRegParamNorm         36.7995
2017-07-02 13:00:48.667579 EDT | QFunRegParamNorm           38.578
2017-07-02 13:00:48.667708 EDT | -----------------------  ------------
2017-07-02 13:00:48.667960 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #135 | Training started
2017-07-02 13:00:58.341729 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #135 | Training finished
2017-07-02 13:00:58.342329 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #135 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 13:00:58.342527 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #135 | Collecting samples for evaluation
2017-07-02 13:01:03.984203 EDT | -----------------------  ------------
2017-07-02 13:01:03.984401 EDT | Epoch                     135
2017-07-02 13:01:03.984514 EDT | Iteration                 135
2017-07-02 13:01:03.984669 EDT | AverageReturn            1000
2017-07-02 13:01:03.984803 EDT | StdReturn                   0
2017-07-02 13:01:03.984907 EDT | MaxReturn                1000
2017-07-02 13:01:03.985101 EDT | MinReturn                1000
2017-07-02 13:01:03.985283 EDT | AverageEsReturn            20.2653
2017-07-02 13:01:03.985450 EDT | StdEsReturn                17.6656
2017-07-02 13:01:03.985643 EDT | MaxEsReturn                74
2017-07-02 13:01:03.985825 EDT | MinEsReturn                 3
2017-07-02 13:01:03.985935 EDT | AverageDiscountedReturn    99.9957
2017-07-02 13:01:03.986074 EDT | AverageQLoss                0.0112364
2017-07-02 13:01:03.986176 EDT | AveragePolicySurr          -1.55847
2017-07-02 13:01:03.986330 EDT | AverageQ                    1.42922
2017-07-02 13:01:03.986495 EDT | AverageAbsQ                 1.43341
2017-07-02 13:01:03.986752 EDT | AverageY                    1.42923
2017-07-02 13:01:03.986944 EDT | AverageAbsY                 1.42962
2017-07-02 13:01:03.987186 EDT | AverageAbsQYDiff            0.0373867
2017-07-02 13:01:03.987401 EDT | AverageAction               0.500693
2017-07-02 13:01:03.987508 EDT | PolicyRegParamNorm         36.8761
2017-07-02 13:01:03.987610 EDT | QFunRegParamNorm           38.6919
2017-07-02 13:01:03.987710 EDT | -----------------------  ------------
2017-07-02 13:01:03.987880 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #136 | Training started
2017-07-02 13:01:13.672998 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #136 | Training finished
2017-07-02 13:01:13.673615 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #136 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 13:01:13.673762 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #136 | Collecting samples for evaluation
2017-07-02 13:01:19.275609 EDT | -----------------------  ------------
2017-07-02 13:01:19.275937 EDT | Epoch                     136
2017-07-02 13:01:19.276156 EDT | Iteration                 136
2017-07-02 13:01:19.276377 EDT | AverageReturn            1000
2017-07-02 13:01:19.276534 EDT | StdReturn                   0
2017-07-02 13:01:19.276766 EDT | MaxReturn                1000
2017-07-02 13:01:19.276899 EDT | MinReturn                1000
2017-07-02 13:01:19.277130 EDT | AverageEsReturn            21.2174
2017-07-02 13:01:19.277342 EDT | StdEsReturn                20.0921
2017-07-02 13:01:19.277451 EDT | MaxEsReturn               104
2017-07-02 13:01:19.277678 EDT | MinEsReturn                 3
2017-07-02 13:01:19.277873 EDT | AverageDiscountedReturn    99.9957
2017-07-02 13:01:19.278086 EDT | AverageQLoss                0.010864
2017-07-02 13:01:19.278313 EDT | AveragePolicySurr          -1.56011
2017-07-02 13:01:19.278540 EDT | AverageQ                    1.43108
2017-07-02 13:01:19.278739 EDT | AverageAbsQ                 1.43473
2017-07-02 13:01:19.278927 EDT | AverageY                    1.43117
2017-07-02 13:01:19.279149 EDT | AverageAbsY                 1.43137
2017-07-02 13:01:19.279373 EDT | AverageAbsQYDiff            0.0364251
2017-07-02 13:01:19.279584 EDT | AverageAction               0.45789
2017-07-02 13:01:19.279807 EDT | PolicyRegParamNorm         36.9496
2017-07-02 13:01:19.280041 EDT | QFunRegParamNorm           38.7969
2017-07-02 13:01:19.280267 EDT | -----------------------  ------------
2017-07-02 13:01:19.280595 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #137 | Training started
2017-07-02 13:01:28.994611 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #137 | Training finished
2017-07-02 13:01:28.995458 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #137 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 13:01:28.995740 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #137 | Collecting samples for evaluation
2017-07-02 13:01:34.661851 EDT | -----------------------  ------------
2017-07-02 13:01:34.662176 EDT | Epoch                     137
2017-07-02 13:01:34.662401 EDT | Iteration                 137
2017-07-02 13:01:34.662623 EDT | AverageReturn            1000
2017-07-02 13:01:34.662840 EDT | StdReturn                   0
2017-07-02 13:01:34.663047 EDT | MaxReturn                1000
2017-07-02 13:01:34.663214 EDT | MinReturn                1000
2017-07-02 13:01:34.663336 EDT | AverageEsReturn            16.3871
2017-07-02 13:01:34.663554 EDT | StdEsReturn                16.7999
2017-07-02 13:01:34.663765 EDT | MaxEsReturn                95
2017-07-02 13:01:34.663966 EDT | MinEsReturn                 3
2017-07-02 13:01:34.664280 EDT | AverageDiscountedReturn    99.9957
2017-07-02 13:01:34.664508 EDT | AverageQLoss                0.0112849
2017-07-02 13:01:34.664726 EDT | AveragePolicySurr          -1.56392
2017-07-02 13:01:34.664945 EDT | AverageQ                    1.43747
2017-07-02 13:01:34.665168 EDT | AverageAbsQ                 1.441
2017-07-02 13:01:34.665404 EDT | AverageY                    1.4376
2017-07-02 13:01:34.665631 EDT | AverageAbsY                 1.43775
2017-07-02 13:01:34.665850 EDT | AverageAbsQYDiff            0.0370047
2017-07-02 13:01:34.666075 EDT | AverageAction               0.366147
2017-07-02 13:01:34.666287 EDT | PolicyRegParamNorm         36.9899
2017-07-02 13:01:34.666509 EDT | QFunRegParamNorm           38.9263
2017-07-02 13:01:34.666708 EDT | -----------------------  ------------
2017-07-02 13:01:34.667021 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #138 | Training started
2017-07-02 13:01:44.319467 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #138 | Training finished
2017-07-02 13:01:44.320003 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #138 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 13:01:44.320134 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #138 | Collecting samples for evaluation
2017-07-02 13:01:49.988840 EDT | -----------------------  -------------
2017-07-02 13:01:49.989048 EDT | Epoch                     138
2017-07-02 13:01:49.989228 EDT | Iteration                 138
2017-07-02 13:01:49.989453 EDT | AverageReturn            1000
2017-07-02 13:01:49.989690 EDT | StdReturn                   0
2017-07-02 13:01:49.989836 EDT | MaxReturn                1000
2017-07-02 13:01:49.990032 EDT | MinReturn                1000
2017-07-02 13:01:49.990246 EDT | AverageEsReturn            13.5333
2017-07-02 13:01:49.990468 EDT | StdEsReturn                12.0536
2017-07-02 13:01:49.990675 EDT | MaxEsReturn                49
2017-07-02 13:01:49.990901 EDT | MinEsReturn                 3
2017-07-02 13:01:49.991095 EDT | AverageDiscountedReturn    99.9957
2017-07-02 13:01:49.991204 EDT | AverageQLoss                0.00915606
2017-07-02 13:01:49.991370 EDT | AveragePolicySurr          -1.5638
2017-07-02 13:01:49.991602 EDT | AverageQ                    1.43813
2017-07-02 13:01:49.991821 EDT | AverageAbsQ                 1.44196
2017-07-02 13:01:49.992045 EDT | AverageY                    1.4382
2017-07-02 13:01:49.992255 EDT | AverageAbsY                 1.43849
2017-07-02 13:01:49.992457 EDT | AverageAbsQYDiff            0.0348792
2017-07-02 13:01:49.992681 EDT | AverageAction               0.25979
2017-07-02 13:01:49.992935 EDT | PolicyRegParamNorm         37.0058
2017-07-02 13:01:49.993462 EDT | QFunRegParamNorm           39.0401
2017-07-02 13:01:49.993608 EDT | -----------------------  -------------
2017-07-02 13:01:49.993937 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #139 | Training started
2017-07-02 13:01:59.739749 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #139 | Training finished
2017-07-02 13:01:59.740373 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #139 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 13:01:59.740530 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #139 | Collecting samples for evaluation
2017-07-02 13:02:05.344448 EDT | -----------------------  ------------
2017-07-02 13:02:05.344642 EDT | Epoch                     139
2017-07-02 13:02:05.344754 EDT | Iteration                 139
2017-07-02 13:02:05.344860 EDT | AverageReturn            1000
2017-07-02 13:02:05.344964 EDT | StdReturn                   0
2017-07-02 13:02:05.345067 EDT | MaxReturn                1000
2017-07-02 13:02:05.345168 EDT | MinReturn                1000
2017-07-02 13:02:05.345268 EDT | AverageEsReturn            15.9365
2017-07-02 13:02:05.345368 EDT | StdEsReturn                15.5572
2017-07-02 13:02:05.345469 EDT | MaxEsReturn                74
2017-07-02 13:02:05.345656 EDT | MinEsReturn                 3
2017-07-02 13:02:05.345890 EDT | AverageDiscountedReturn    99.9957
2017-07-02 13:02:05.346104 EDT | AverageQLoss                0.0117647
2017-07-02 13:02:05.346338 EDT | AveragePolicySurr          -1.56172
2017-07-02 13:02:05.346534 EDT | AverageQ                    1.44174
2017-07-02 13:02:05.346760 EDT | AverageAbsQ                 1.4464
2017-07-02 13:02:05.346978 EDT | AverageY                    1.44175
2017-07-02 13:02:05.347212 EDT | AverageAbsY                 1.44201
2017-07-02 13:02:05.347416 EDT | AverageAbsQYDiff            0.0381686
2017-07-02 13:02:05.347631 EDT | AverageAction               0.194112
2017-07-02 13:02:05.347856 EDT | PolicyRegParamNorm         37.0571
2017-07-02 13:02:05.348083 EDT | QFunRegParamNorm           39.0837
2017-07-02 13:02:05.348317 EDT | -----------------------  ------------
2017-07-02 13:02:05.348636 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #140 | Training started
2017-07-02 13:02:15.075931 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #140 | Training finished
2017-07-02 13:02:15.076547 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #140 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 13:02:15.076984 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #140 | Collecting samples for evaluation
2017-07-02 13:02:20.626853 EDT | -----------------------  ------------
2017-07-02 13:02:20.627132 EDT | Epoch                     140
2017-07-02 13:02:20.627286 EDT | Iteration                 140
2017-07-02 13:02:20.627393 EDT | AverageReturn            1000
2017-07-02 13:02:20.627598 EDT | StdReturn                   0
2017-07-02 13:02:20.627729 EDT | MaxReturn                1000
2017-07-02 13:02:20.627873 EDT | MinReturn                1000
2017-07-02 13:02:20.627999 EDT | AverageEsReturn            11.2159
2017-07-02 13:02:20.628151 EDT | StdEsReturn                11.7893
2017-07-02 13:02:20.628358 EDT | MaxEsReturn                55
2017-07-02 13:02:20.628534 EDT | MinEsReturn                 2
2017-07-02 13:02:20.628677 EDT | AverageDiscountedReturn    99.9957
2017-07-02 13:02:20.628782 EDT | AverageQLoss                0.0107614
2017-07-02 13:02:20.628968 EDT | AveragePolicySurr          -1.56782
2017-07-02 13:02:20.629160 EDT | AverageQ                    1.44061
2017-07-02 13:02:20.629350 EDT | AverageAbsQ                 1.44472
2017-07-02 13:02:20.629696 EDT | AverageY                    1.44062
2017-07-02 13:02:20.629821 EDT | AverageAbsY                 1.44086
2017-07-02 13:02:20.629954 EDT | AverageAbsQYDiff            0.0356765
2017-07-02 13:02:20.630067 EDT | AverageAction               0.11057
2017-07-02 13:02:20.630277 EDT | PolicyRegParamNorm         37.1205
2017-07-02 13:02:20.630386 EDT | QFunRegParamNorm           39.189
2017-07-02 13:02:20.630488 EDT | -----------------------  ------------
2017-07-02 13:02:20.630694 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #141 | Training started
2017-07-02 13:02:30.368295 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #141 | Training finished
2017-07-02 13:02:30.368899 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #141 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 13:02:30.369118 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #141 | Collecting samples for evaluation
2017-07-02 13:02:35.962055 EDT | -----------------------  -------------
2017-07-02 13:02:35.962695 EDT | Epoch                     141
2017-07-02 13:02:35.962929 EDT | Iteration                 141
2017-07-02 13:02:35.963044 EDT | AverageReturn            1000
2017-07-02 13:02:35.963166 EDT | StdReturn                   0
2017-07-02 13:02:35.963276 EDT | MaxReturn                1000
2017-07-02 13:02:35.963398 EDT | MinReturn                1000
2017-07-02 13:02:35.963556 EDT | AverageEsReturn            13.9265
2017-07-02 13:02:35.963725 EDT | StdEsReturn                13.122
2017-07-02 13:02:35.963842 EDT | MaxEsReturn                51
2017-07-02 13:02:35.963970 EDT | MinEsReturn                 3
2017-07-02 13:02:35.964112 EDT | AverageDiscountedReturn    99.9957
2017-07-02 13:02:35.964287 EDT | AverageQLoss                0.00989157
2017-07-02 13:02:35.964430 EDT | AveragePolicySurr          -1.56809
2017-07-02 13:02:35.964534 EDT | AverageQ                    1.4381
2017-07-02 13:02:35.964637 EDT | AverageAbsQ                 1.44151
2017-07-02 13:02:35.964778 EDT | AverageY                    1.43823
2017-07-02 13:02:35.964945 EDT | AverageAbsY                 1.43833
2017-07-02 13:02:35.965110 EDT | AverageAbsQYDiff            0.034713
2017-07-02 13:02:35.965223 EDT | AverageAction               0.029755
2017-07-02 13:02:35.965343 EDT | PolicyRegParamNorm         37.2808
2017-07-02 13:02:35.965456 EDT | QFunRegParamNorm           39.3117
2017-07-02 13:02:35.965574 EDT | -----------------------  -------------
2017-07-02 13:02:35.965742 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #142 | Training started
2017-07-02 13:02:45.551367 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #142 | Training finished
2017-07-02 13:02:45.551908 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #142 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 13:02:45.552064 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #142 | Collecting samples for evaluation
2017-07-02 13:02:51.330819 EDT | -----------------------  ------------
2017-07-02 13:02:51.331120 EDT | Epoch                     142
2017-07-02 13:02:51.331270 EDT | Iteration                 142
2017-07-02 13:02:51.331403 EDT | AverageReturn            1000
2017-07-02 13:02:51.331529 EDT | StdReturn                   0
2017-07-02 13:02:51.331662 EDT | MaxReturn                1000
2017-07-02 13:02:51.331836 EDT | MinReturn                1000
2017-07-02 13:02:51.331960 EDT | AverageEsReturn            19.2909
2017-07-02 13:02:51.332071 EDT | StdEsReturn                21.8704
2017-07-02 13:02:51.332210 EDT | MaxEsReturn               112
2017-07-02 13:02:51.332317 EDT | MinEsReturn                 3
2017-07-02 13:02:51.332423 EDT | AverageDiscountedReturn    99.9957
2017-07-02 13:02:51.332536 EDT | AverageQLoss                0.0108431
2017-07-02 13:02:51.332650 EDT | AveragePolicySurr          -1.56369
2017-07-02 13:02:51.332793 EDT | AverageQ                    1.44131
2017-07-02 13:02:51.332907 EDT | AverageAbsQ                 1.4451
2017-07-02 13:02:51.333015 EDT | AverageY                    1.44131
2017-07-02 13:02:51.333142 EDT | AverageAbsY                 1.44152
2017-07-02 13:02:51.333249 EDT | AverageAbsQYDiff            0.0359896
2017-07-02 13:02:51.333353 EDT | AverageAction               0.0290755
2017-07-02 13:02:51.333785 EDT | PolicyRegParamNorm         37.319
2017-07-02 13:02:51.333910 EDT | QFunRegParamNorm           39.3661
2017-07-02 13:02:51.334126 EDT | -----------------------  ------------
2017-07-02 13:02:51.334400 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #143 | Training started
2017-07-02 13:03:00.785149 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #143 | Training finished
2017-07-02 13:03:00.785692 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #143 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 13:03:00.786207 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #143 | Collecting samples for evaluation
2017-07-02 13:03:06.536112 EDT | -----------------------  ------------
2017-07-02 13:03:06.536301 EDT | Epoch                     143
2017-07-02 13:03:06.536412 EDT | Iteration                 143
2017-07-02 13:03:06.536523 EDT | AverageReturn            1000
2017-07-02 13:03:06.536723 EDT | StdReturn                   0
2017-07-02 13:03:06.536859 EDT | MaxReturn                1000
2017-07-02 13:03:06.536964 EDT | MinReturn                1000
2017-07-02 13:03:06.537120 EDT | AverageEsReturn            17.0339
2017-07-02 13:03:06.537254 EDT | StdEsReturn                17.5518
2017-07-02 13:03:06.537408 EDT | MaxEsReturn                83
2017-07-02 13:03:06.537632 EDT | MinEsReturn                 3
2017-07-02 13:03:06.537743 EDT | AverageDiscountedReturn    99.9957
2017-07-02 13:03:06.537846 EDT | AverageQLoss                0.0116994
2017-07-02 13:03:06.537958 EDT | AveragePolicySurr          -1.55711
2017-07-02 13:03:06.538149 EDT | AverageQ                    1.43625
2017-07-02 13:03:06.538267 EDT | AverageAbsQ                 1.44055
2017-07-02 13:03:06.538374 EDT | AverageY                    1.43618
2017-07-02 13:03:06.538480 EDT | AverageAbsY                 1.43645
2017-07-02 13:03:06.538591 EDT | AverageAbsQYDiff            0.0370046
2017-07-02 13:03:06.538710 EDT | AverageAction               0.446302
2017-07-02 13:03:06.538816 EDT | PolicyRegParamNorm         37.3178
2017-07-02 13:03:06.538921 EDT | QFunRegParamNorm           39.4854
2017-07-02 13:03:06.539026 EDT | -----------------------  ------------
2017-07-02 13:03:06.539198 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #144 | Training started
2017-07-02 13:03:16.002909 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #144 | Training finished
2017-07-02 13:03:16.003429 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #144 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 13:03:16.003683 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #144 | Collecting samples for evaluation
2017-07-02 13:03:21.735243 EDT | -----------------------  ------------
2017-07-02 13:03:21.735466 EDT | Epoch                     144
2017-07-02 13:03:21.735596 EDT | Iteration                 144
2017-07-02 13:03:21.735766 EDT | AverageReturn            1000
2017-07-02 13:03:21.736688 EDT | StdReturn                   0
2017-07-02 13:03:21.736916 EDT | MaxReturn                1000
2017-07-02 13:03:21.737083 EDT | MinReturn                1000
2017-07-02 13:03:21.737254 EDT | AverageEsReturn            13.1067
2017-07-02 13:03:21.737406 EDT | StdEsReturn                13.0768
2017-07-02 13:03:21.737549 EDT | MaxEsReturn                78
2017-07-02 13:03:21.737778 EDT | MinEsReturn                 2
2017-07-02 13:03:21.738060 EDT | AverageDiscountedReturn    99.9957
2017-07-02 13:03:21.738264 EDT | AverageQLoss                0.0121718
2017-07-02 13:03:21.738379 EDT | AveragePolicySurr          -1.56442
2017-07-02 13:03:21.738488 EDT | AverageQ                    1.43716
2017-07-02 13:03:21.738602 EDT | AverageAbsQ                 1.44202
2017-07-02 13:03:21.738756 EDT | AverageY                    1.43722
2017-07-02 13:03:21.738938 EDT | AverageAbsY                 1.4375
2017-07-02 13:03:21.739114 EDT | AverageAbsQYDiff            0.0384542
2017-07-02 13:03:21.739267 EDT | AverageAction               0.389526
2017-07-02 13:03:21.739400 EDT | PolicyRegParamNorm         37.4061
2017-07-02 13:03:21.739509 EDT | QFunRegParamNorm           39.5457
2017-07-02 13:03:21.739616 EDT | -----------------------  ------------
2017-07-02 13:03:21.739877 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #145 | Training started
2017-07-02 13:03:31.246022 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #145 | Training finished
2017-07-02 13:03:31.246828 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #145 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 13:03:31.247106 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #145 | Collecting samples for evaluation
2017-07-02 13:03:36.989642 EDT | -----------------------  ------------
2017-07-02 13:03:36.989900 EDT | Epoch                     145
2017-07-02 13:03:36.990083 EDT | Iteration                 145
2017-07-02 13:03:36.990237 EDT | AverageReturn            1000
2017-07-02 13:03:36.990399 EDT | StdReturn                   0
2017-07-02 13:03:36.990524 EDT | MaxReturn                1000
2017-07-02 13:03:36.990712 EDT | MinReturn                1000
2017-07-02 13:03:36.990863 EDT | AverageEsReturn            15.8689
2017-07-02 13:03:36.991186 EDT | StdEsReturn                16.2687
2017-07-02 13:03:36.991326 EDT | MaxEsReturn                71
2017-07-02 13:03:36.991451 EDT | MinEsReturn                 3
2017-07-02 13:03:36.991560 EDT | AverageDiscountedReturn    99.9957
2017-07-02 13:03:36.991669 EDT | AverageQLoss                0.0105557
2017-07-02 13:03:36.991800 EDT | AveragePolicySurr          -1.56428
2017-07-02 13:03:36.992001 EDT | AverageQ                    1.44014
2017-07-02 13:03:36.992197 EDT | AverageAbsQ                 1.44403
2017-07-02 13:03:36.992385 EDT | AverageY                    1.44002
2017-07-02 13:03:36.992600 EDT | AverageAbsY                 1.44032
2017-07-02 13:03:36.992747 EDT | AverageAbsQYDiff            0.0356599
2017-07-02 13:03:36.992883 EDT | AverageAction               0.467695
2017-07-02 13:03:36.993010 EDT | PolicyRegParamNorm         37.5149
2017-07-02 13:03:36.993113 EDT | QFunRegParamNorm           39.7062
2017-07-02 13:03:36.993234 EDT | -----------------------  ------------
2017-07-02 13:03:36.993416 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #146 | Training started
2017-07-02 13:03:46.637829 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #146 | Training finished
2017-07-02 13:03:46.638432 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #146 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 13:03:46.638586 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #146 | Collecting samples for evaluation
2017-07-02 13:03:52.348455 EDT | -----------------------  ------------
2017-07-02 13:03:52.348944 EDT | Epoch                     146
2017-07-02 13:03:52.349106 EDT | Iteration                 146
2017-07-02 13:03:52.349307 EDT | AverageReturn            1000
2017-07-02 13:03:52.349464 EDT | StdReturn                   0
2017-07-02 13:03:52.349677 EDT | MaxReturn                1000
2017-07-02 13:03:52.349870 EDT | MinReturn                1000
2017-07-02 13:03:52.350000 EDT | AverageEsReturn            19.0182
2017-07-02 13:03:52.350163 EDT | StdEsReturn                21.3196
2017-07-02 13:03:52.350287 EDT | MaxEsReturn                85
2017-07-02 13:03:52.350388 EDT | MinEsReturn                 3
2017-07-02 13:03:52.350502 EDT | AverageDiscountedReturn    99.9957
2017-07-02 13:03:52.350678 EDT | AverageQLoss                0.0103527
2017-07-02 13:03:52.350897 EDT | AveragePolicySurr          -1.55861
2017-07-02 13:03:52.351124 EDT | AverageQ                    1.43546
2017-07-02 13:03:52.351310 EDT | AverageAbsQ                 1.43924
2017-07-02 13:03:52.351414 EDT | AverageY                    1.43553
2017-07-02 13:03:52.351571 EDT | AverageAbsY                 1.43575
2017-07-02 13:03:52.351798 EDT | AverageAbsQYDiff            0.0355175
2017-07-02 13:03:52.352009 EDT | AverageAction               0.404722
2017-07-02 13:03:52.352236 EDT | PolicyRegParamNorm         37.6264
2017-07-02 13:03:52.352458 EDT | QFunRegParamNorm           39.8095
2017-07-02 13:03:52.352656 EDT | -----------------------  ------------
2017-07-02 13:03:52.352985 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #147 | Training started
2017-07-02 13:04:02.101927 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #147 | Training finished
2017-07-02 13:04:02.102492 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #147 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 13:04:02.102664 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #147 | Collecting samples for evaluation
2017-07-02 13:04:07.815112 EDT | -----------------------  ------------
2017-07-02 13:04:07.815404 EDT | Epoch                     147
2017-07-02 13:04:07.815617 EDT | Iteration                 147
2017-07-02 13:04:07.815809 EDT | AverageReturn            1000
2017-07-02 13:04:07.815974 EDT | StdReturn                   0
2017-07-02 13:04:07.816103 EDT | MaxReturn                1000
2017-07-02 13:04:07.816252 EDT | MinReturn                1000
2017-07-02 13:04:07.816382 EDT | AverageEsReturn            12
2017-07-02 13:04:07.816548 EDT | StdEsReturn                11.7975
2017-07-02 13:04:07.816690 EDT | MaxEsReturn                57
2017-07-02 13:04:07.816828 EDT | MinEsReturn                 3
2017-07-02 13:04:07.817034 EDT | AverageDiscountedReturn    99.9957
2017-07-02 13:04:07.817154 EDT | AverageQLoss                0.0104225
2017-07-02 13:04:07.817309 EDT | AveragePolicySurr          -1.5588
2017-07-02 13:04:07.817872 EDT | AverageQ                    1.43858
2017-07-02 13:04:07.818084 EDT | AverageAbsQ                 1.44255
2017-07-02 13:04:07.818260 EDT | AverageY                    1.43862
2017-07-02 13:04:07.818410 EDT | AverageAbsY                 1.43886
2017-07-02 13:04:07.818609 EDT | AverageAbsQYDiff            0.0347118
2017-07-02 13:04:07.818720 EDT | AverageAction               0.408758
2017-07-02 13:04:07.818863 EDT | PolicyRegParamNorm         37.7213
2017-07-02 13:04:07.818973 EDT | QFunRegParamNorm           39.9459
2017-07-02 13:04:07.819137 EDT | -----------------------  ------------
2017-07-02 13:04:07.819332 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #148 | Training started
2017-07-02 13:04:17.537554 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #148 | Training finished
2017-07-02 13:04:17.538398 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #148 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 13:04:17.538786 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #148 | Collecting samples for evaluation
2017-07-02 13:04:23.251796 EDT | -----------------------  -------------
2017-07-02 13:04:23.252102 EDT | Epoch                     148
2017-07-02 13:04:23.252328 EDT | Iteration                 148
2017-07-02 13:04:23.252566 EDT | AverageReturn            1000
2017-07-02 13:04:23.252803 EDT | StdReturn                   0
2017-07-02 13:04:23.253038 EDT | MaxReturn                1000
2017-07-02 13:04:23.253272 EDT | MinReturn                1000
2017-07-02 13:04:23.253523 EDT | AverageEsReturn            14.9701
2017-07-02 13:04:23.253754 EDT | StdEsReturn                19.9507
2017-07-02 13:04:23.253988 EDT | MaxEsReturn               107
2017-07-02 13:04:23.254218 EDT | MinEsReturn                 3
2017-07-02 13:04:23.254455 EDT | AverageDiscountedReturn    99.9957
2017-07-02 13:04:23.254679 EDT | AverageQLoss                0.00946331
2017-07-02 13:04:23.254854 EDT | AveragePolicySurr          -1.55983
2017-07-02 13:04:23.255087 EDT | AverageQ                    1.43784
2017-07-02 13:04:23.255318 EDT | AverageAbsQ                 1.44195
2017-07-02 13:04:23.255537 EDT | AverageY                    1.43788
2017-07-02 13:04:23.255739 EDT | AverageAbsY                 1.43823
2017-07-02 13:04:23.255962 EDT | AverageAbsQYDiff            0.0338593
2017-07-02 13:04:23.256092 EDT | AverageAction               0.39105
2017-07-02 13:04:23.256201 EDT | PolicyRegParamNorm         37.7754
2017-07-02 13:04:23.256305 EDT | QFunRegParamNorm           40.0343
2017-07-02 13:04:23.256407 EDT | -----------------------  -------------
2017-07-02 13:04:23.256654 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #149 | Training started
2017-07-02 13:04:32.923472 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #149 | Training finished
2017-07-02 13:04:32.924212 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #149 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 13:04:32.924566 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #149 | Collecting samples for evaluation
2017-07-02 13:04:38.598273 EDT | -----------------------  ------------
2017-07-02 13:04:38.598543 EDT | Epoch                     149
2017-07-02 13:04:38.598722 EDT | Iteration                 149
2017-07-02 13:04:38.598926 EDT | AverageReturn            1000
2017-07-02 13:04:38.599163 EDT | StdReturn                   0
2017-07-02 13:04:38.599377 EDT | MaxReturn                1000
2017-07-02 13:04:38.599607 EDT | MinReturn                1000
2017-07-02 13:04:38.599833 EDT | AverageEsReturn            13.9718
2017-07-02 13:04:38.600021 EDT | StdEsReturn                13.6526
2017-07-02 13:04:38.600253 EDT | MaxEsReturn                55
2017-07-02 13:04:38.600469 EDT | MinEsReturn                 3
2017-07-02 13:04:38.600670 EDT | AverageDiscountedReturn    99.9957
2017-07-02 13:04:38.600865 EDT | AverageQLoss                0.0121226
2017-07-02 13:04:38.601070 EDT | AveragePolicySurr          -1.55649
2017-07-02 13:04:38.601259 EDT | AverageQ                    1.43311
2017-07-02 13:04:38.601635 EDT | AverageAbsQ                 1.43802
2017-07-02 13:04:38.601868 EDT | AverageY                    1.43318
2017-07-02 13:04:38.602058 EDT | AverageAbsY                 1.4335
2017-07-02 13:04:38.602247 EDT | AverageAbsQYDiff            0.038368
2017-07-02 13:04:38.602479 EDT | AverageAction               0.274852
2017-07-02 13:04:38.602696 EDT | PolicyRegParamNorm         37.9119
2017-07-02 13:04:38.602879 EDT | QFunRegParamNorm           40.1924
2017-07-02 13:04:38.603108 EDT | -----------------------  ------------
2017-07-02 13:04:38.603361 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #150 | Training started
2017-07-02 13:04:48.372115 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #150 | Training finished
2017-07-02 13:04:48.372678 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #150 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 13:04:48.372830 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #150 | Collecting samples for evaluation
2017-07-02 13:04:54.091432 EDT | -----------------------  ------------
2017-07-02 13:04:54.091735 EDT | Epoch                     150
2017-07-02 13:04:54.091943 EDT | Iteration                 150
2017-07-02 13:04:54.092111 EDT | AverageReturn            1000
2017-07-02 13:04:54.092292 EDT | StdReturn                   0
2017-07-02 13:04:54.092483 EDT | MaxReturn                1000
2017-07-02 13:04:54.092663 EDT | MinReturn                1000
2017-07-02 13:04:54.092775 EDT | AverageEsReturn            14.0278
2017-07-02 13:04:54.092880 EDT | StdEsReturn                11.8568
2017-07-02 13:04:54.093044 EDT | MaxEsReturn                61
2017-07-02 13:04:54.093154 EDT | MinEsReturn                 3
2017-07-02 13:04:54.093258 EDT | AverageDiscountedReturn    99.9957
2017-07-02 13:04:54.093360 EDT | AverageQLoss                0.010662
2017-07-02 13:04:54.093460 EDT | AveragePolicySurr          -1.55183
2017-07-02 13:04:54.093580 EDT | AverageQ                    1.43016
2017-07-02 13:04:54.093731 EDT | AverageAbsQ                 1.43383
2017-07-02 13:04:54.093872 EDT | AverageY                    1.43016
2017-07-02 13:04:54.093978 EDT | AverageAbsY                 1.43033
2017-07-02 13:04:54.094081 EDT | AverageAbsQYDiff            0.0349198
2017-07-02 13:04:54.094185 EDT | AverageAction               0.551357
2017-07-02 13:04:54.094314 EDT | PolicyRegParamNorm         37.9478
2017-07-02 13:04:54.094415 EDT | QFunRegParamNorm           40.2793
2017-07-02 13:04:54.094515 EDT | -----------------------  ------------
2017-07-02 13:04:54.094708 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #151 | Training started
2017-07-02 13:05:03.779452 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #151 | Training finished
2017-07-02 13:05:03.780177 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #151 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 13:05:03.780337 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #151 | Collecting samples for evaluation
2017-07-02 13:05:09.447942 EDT | -----------------------  ------------
2017-07-02 13:05:09.448228 EDT | Epoch                     151
2017-07-02 13:05:09.448374 EDT | Iteration                 151
2017-07-02 13:05:09.448524 EDT | AverageReturn            1000
2017-07-02 13:05:09.448631 EDT | StdReturn                   0
2017-07-02 13:05:09.448734 EDT | MaxReturn                1000
2017-07-02 13:05:09.448859 EDT | MinReturn                1000
2017-07-02 13:05:09.448967 EDT | AverageEsReturn            14
2017-07-02 13:05:09.449069 EDT | StdEsReturn                23.4253
2017-07-02 13:05:09.449170 EDT | MaxEsReturn               157
2017-07-02 13:05:09.449325 EDT | MinEsReturn                 3
2017-07-02 13:05:09.449464 EDT | AverageDiscountedReturn    99.9957
2017-07-02 13:05:09.449651 EDT | AverageQLoss                0.0103568
2017-07-02 13:05:09.449805 EDT | AveragePolicySurr          -1.55168
2017-07-02 13:05:09.449932 EDT | AverageQ                    1.43009
2017-07-02 13:05:09.450074 EDT | AverageAbsQ                 1.4342
2017-07-02 13:05:09.450288 EDT | AverageY                    1.43002
2017-07-02 13:05:09.450537 EDT | AverageAbsY                 1.43015
2017-07-02 13:05:09.450671 EDT | AverageAbsQYDiff            0.0348214
2017-07-02 13:05:09.450835 EDT | AverageAction               0.8622
2017-07-02 13:05:09.450969 EDT | PolicyRegParamNorm         38.0308
2017-07-02 13:05:09.451098 EDT | QFunRegParamNorm           40.3887
2017-07-02 13:05:09.451300 EDT | -----------------------  ------------
2017-07-02 13:05:09.451564 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #152 | Training started
2017-07-02 13:05:19.412761 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #152 | Training finished
2017-07-02 13:05:19.413341 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #152 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 13:05:19.413545 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #152 | Collecting samples for evaluation
2017-07-02 13:05:25.430052 EDT | -----------------------  ------------
2017-07-02 13:05:25.430343 EDT | Epoch                     152
2017-07-02 13:05:25.430517 EDT | Iteration                 152
2017-07-02 13:05:25.430625 EDT | AverageReturn            1000
2017-07-02 13:05:25.430917 EDT | StdReturn                   0
2017-07-02 13:05:25.431086 EDT | MaxReturn                1000
2017-07-02 13:05:25.431246 EDT | MinReturn                1000
2017-07-02 13:05:25.431393 EDT | AverageEsReturn            15.2537
2017-07-02 13:05:25.431576 EDT | StdEsReturn                16.1146
2017-07-02 13:05:25.431739 EDT | MaxEsReturn                62
2017-07-02 13:05:25.431913 EDT | MinEsReturn                 3
2017-07-02 13:05:25.432059 EDT | AverageDiscountedReturn    99.9957
2017-07-02 13:05:25.432164 EDT | AverageQLoss                0.0111778
2017-07-02 13:05:25.432265 EDT | AveragePolicySurr          -1.54812
2017-07-02 13:05:25.432416 EDT | AverageQ                    1.42776
2017-07-02 13:05:25.432519 EDT | AverageAbsQ                 1.43202
2017-07-02 13:05:25.432640 EDT | AverageY                    1.42791
2017-07-02 13:05:25.432861 EDT | AverageAbsY                 1.42823
2017-07-02 13:05:25.433087 EDT | AverageAbsQYDiff            0.036039
2017-07-02 13:05:25.433309 EDT | AverageAction               0.774175
2017-07-02 13:05:25.433526 EDT | PolicyRegParamNorm         38.0732
2017-07-02 13:05:25.433747 EDT | QFunRegParamNorm           40.4531
2017-07-02 13:05:25.433942 EDT | -----------------------  ------------
2017-07-02 13:05:25.434257 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #153 | Training started
2017-07-02 13:05:35.088088 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #153 | Training finished
2017-07-02 13:05:35.088571 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #153 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 13:05:35.088704 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #153 | Collecting samples for evaluation
2017-07-02 13:05:40.773179 EDT | -----------------------  -------------
2017-07-02 13:05:40.773510 EDT | Epoch                     153
2017-07-02 13:05:40.773742 EDT | Iteration                 153
2017-07-02 13:05:40.773975 EDT | AverageReturn            1000
2017-07-02 13:05:40.774204 EDT | StdReturn                   0
2017-07-02 13:05:40.774422 EDT | MaxReturn                1000
2017-07-02 13:05:40.774598 EDT | MinReturn                1000
2017-07-02 13:05:40.774823 EDT | AverageEsReturn            12.8961
2017-07-02 13:05:40.774973 EDT | StdEsReturn                14.3614
2017-07-02 13:05:40.775192 EDT | MaxEsReturn                63
2017-07-02 13:05:40.775404 EDT | MinEsReturn                 2
2017-07-02 13:05:40.775635 EDT | AverageDiscountedReturn    99.9957
2017-07-02 13:05:40.775856 EDT | AverageQLoss                0.00964689
2017-07-02 13:05:40.776043 EDT | AveragePolicySurr          -1.55118
2017-07-02 13:05:40.776165 EDT | AverageQ                    1.42912
2017-07-02 13:05:40.776390 EDT | AverageAbsQ                 1.43329
2017-07-02 13:05:40.776542 EDT | AverageY                    1.42909
2017-07-02 13:05:40.776772 EDT | AverageAbsY                 1.42955
2017-07-02 13:05:40.776988 EDT | AverageAbsQYDiff            0.0343188
2017-07-02 13:05:40.777099 EDT | AverageAction               0.778205
2017-07-02 13:05:40.777208 EDT | PolicyRegParamNorm         38.174
2017-07-02 13:05:40.777327 EDT | QFunRegParamNorm           40.5547
2017-07-02 13:05:40.777948 EDT | -----------------------  -------------
2017-07-02 13:05:40.778733 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #154 | Training started
2017-07-02 13:05:50.352565 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #154 | Training finished
2017-07-02 13:05:50.353161 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #154 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 13:05:50.353372 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #154 | Collecting samples for evaluation
2017-07-02 13:05:56.068012 EDT | -----------------------  ------------
2017-07-02 13:05:56.068308 EDT | Epoch                     154
2017-07-02 13:05:56.068523 EDT | Iteration                 154
2017-07-02 13:05:56.068635 EDT | AverageReturn            1000
2017-07-02 13:05:56.068746 EDT | StdReturn                   0
2017-07-02 13:05:56.068978 EDT | MaxReturn                1000
2017-07-02 13:05:56.069198 EDT | MinReturn                1000
2017-07-02 13:05:56.069404 EDT | AverageEsReturn            13.5333
2017-07-02 13:05:56.069653 EDT | StdEsReturn                15.9577
2017-07-02 13:05:56.069830 EDT | MaxEsReturn                69
2017-07-02 13:05:56.070065 EDT | MinEsReturn                 3
2017-07-02 13:05:56.070247 EDT | AverageDiscountedReturn    99.9957
2017-07-02 13:05:56.070471 EDT | AverageQLoss                0.0111842
2017-07-02 13:05:56.070700 EDT | AveragePolicySurr          -1.55179
2017-07-02 13:05:56.070822 EDT | AverageQ                    1.42686
2017-07-02 13:05:56.070938 EDT | AverageAbsQ                 1.43119
2017-07-02 13:05:56.071153 EDT | AverageY                    1.42676
2017-07-02 13:05:56.071385 EDT | AverageAbsY                 1.4277
2017-07-02 13:05:56.071526 EDT | AverageAbsQYDiff            0.036165
2017-07-02 13:05:56.071757 EDT | AverageAction               0.728927
2017-07-02 13:05:56.071962 EDT | PolicyRegParamNorm         38.2887
2017-07-02 13:05:56.072137 EDT | QFunRegParamNorm           40.6433
2017-07-02 13:05:56.072369 EDT | -----------------------  ------------
2017-07-02 13:05:56.072824 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #155 | Training started
2017-07-02 13:06:05.638352 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #155 | Training finished
2017-07-02 13:06:05.638873 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #155 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 13:06:05.639093 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #155 | Collecting samples for evaluation
2017-07-02 13:06:11.312408 EDT | -----------------------  ------------
2017-07-02 13:06:11.312673 EDT | Epoch                     155
2017-07-02 13:06:11.312907 EDT | Iteration                 155
2017-07-02 13:06:11.313106 EDT | AverageReturn            1000
2017-07-02 13:06:11.313338 EDT | StdReturn                   0
2017-07-02 13:06:11.313540 EDT | MaxReturn                1000
2017-07-02 13:06:11.313776 EDT | MinReturn                1000
2017-07-02 13:06:11.313987 EDT | AverageEsReturn            13.6667
2017-07-02 13:06:11.314202 EDT | StdEsReturn                24.3484
2017-07-02 13:06:11.314425 EDT | MaxEsReturn               197
2017-07-02 13:06:11.314581 EDT | MinEsReturn                 3
2017-07-02 13:06:11.314812 EDT | AverageDiscountedReturn    99.9957
2017-07-02 13:06:11.315030 EDT | AverageQLoss                0.011464
2017-07-02 13:06:11.315261 EDT | AveragePolicySurr          -1.55018
2017-07-02 13:06:11.315488 EDT | AverageQ                    1.42428
2017-07-02 13:06:11.315708 EDT | AverageAbsQ                 1.42937
2017-07-02 13:06:11.315946 EDT | AverageY                    1.42434
2017-07-02 13:06:11.316130 EDT | AverageAbsY                 1.42486
2017-07-02 13:06:11.316363 EDT | AverageAbsQYDiff            0.0377536
2017-07-02 13:06:11.316566 EDT | AverageAction               0.761262
2017-07-02 13:06:11.316787 EDT | PolicyRegParamNorm         38.3581
2017-07-02 13:06:11.317015 EDT | QFunRegParamNorm           40.6621
2017-07-02 13:06:11.317177 EDT | -----------------------  ------------
2017-07-02 13:06:11.317523 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #156 | Training started
2017-07-02 13:06:20.914536 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #156 | Training finished
2017-07-02 13:06:20.914832 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #156 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 13:06:20.915045 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #156 | Collecting samples for evaluation
2017-07-02 13:06:26.494566 EDT | -----------------------  ------------
2017-07-02 13:06:26.494841 EDT | Epoch                     156
2017-07-02 13:06:26.495008 EDT | Iteration                 156
2017-07-02 13:06:26.495191 EDT | AverageReturn            1000
2017-07-02 13:06:26.495303 EDT | StdReturn                   0
2017-07-02 13:06:26.495436 EDT | MaxReturn                1000
2017-07-02 13:06:26.495541 EDT | MinReturn                1000
2017-07-02 13:06:26.495739 EDT | AverageEsReturn            11.0562
2017-07-02 13:06:26.495921 EDT | StdEsReturn                12.7238
2017-07-02 13:06:26.496046 EDT | MaxEsReturn                75
2017-07-02 13:06:26.496210 EDT | MinEsReturn                 3
2017-07-02 13:06:26.496361 EDT | AverageDiscountedReturn    99.9957
2017-07-02 13:06:26.496485 EDT | AverageQLoss                0.01147
2017-07-02 13:06:26.496588 EDT | AveragePolicySurr          -1.5499
2017-07-02 13:06:26.496735 EDT | AverageQ                    1.42702
2017-07-02 13:06:26.496874 EDT | AverageAbsQ                 1.43161
2017-07-02 13:06:26.497006 EDT | AverageY                    1.42716
2017-07-02 13:06:26.497119 EDT | AverageAbsY                 1.42752
2017-07-02 13:06:26.497235 EDT | AverageAbsQYDiff            0.0370583
2017-07-02 13:06:26.497377 EDT | AverageAction               0.781743
2017-07-02 13:06:26.497837 EDT | PolicyRegParamNorm         38.4293
2017-07-02 13:06:26.498027 EDT | QFunRegParamNorm           40.7161
2017-07-02 13:06:26.498199 EDT | -----------------------  ------------
2017-07-02 13:06:26.498401 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #157 | Training started
2017-07-02 13:06:36.218547 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #157 | Training finished
2017-07-02 13:06:36.218722 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #157 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 13:06:36.218843 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #157 | Collecting samples for evaluation
2017-07-02 13:06:41.840335 EDT | -----------------------  ------------
2017-07-02 13:06:41.840953 EDT | Epoch                     157
2017-07-02 13:06:41.841114 EDT | Iteration                 157
2017-07-02 13:06:41.841311 EDT | AverageReturn            1000
2017-07-02 13:06:41.841500 EDT | StdReturn                   0
2017-07-02 13:06:41.841613 EDT | MaxReturn                1000
2017-07-02 13:06:41.841831 EDT | MinReturn                1000
2017-07-02 13:06:41.842060 EDT | AverageEsReturn            13.9589
2017-07-02 13:06:41.842251 EDT | StdEsReturn                14.8217
2017-07-02 13:06:41.842477 EDT | MaxEsReturn                78
2017-07-02 13:06:41.842706 EDT | MinEsReturn                 3
2017-07-02 13:06:41.842933 EDT | AverageDiscountedReturn    99.9957
2017-07-02 13:06:41.843161 EDT | AverageQLoss                0.0101836
2017-07-02 13:06:41.843346 EDT | AveragePolicySurr          -1.54842
2017-07-02 13:06:41.843451 EDT | AverageQ                    1.4227
2017-07-02 13:06:41.843551 EDT | AverageAbsQ                 1.42718
2017-07-02 13:06:41.843666 EDT | AverageY                    1.42271
2017-07-02 13:06:41.843893 EDT | AverageAbsY                 1.42313
2017-07-02 13:06:41.844110 EDT | AverageAbsQYDiff            0.0350498
2017-07-02 13:06:41.844310 EDT | AverageAction               0.845702
2017-07-02 13:06:41.844537 EDT | PolicyRegParamNorm         38.5047
2017-07-02 13:06:41.844702 EDT | QFunRegParamNorm           40.771
2017-07-02 13:06:41.844930 EDT | -----------------------  ------------
2017-07-02 13:06:41.845226 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #158 | Training started
2017-07-02 13:06:51.721748 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #158 | Training finished
2017-07-02 13:06:51.722310 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #158 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 13:06:51.722460 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #158 | Collecting samples for evaluation
2017-07-02 13:06:57.239552 EDT | -----------------------  ------------
2017-07-02 13:06:57.239815 EDT | Epoch                     158
2017-07-02 13:06:57.239945 EDT | Iteration                 158
2017-07-02 13:06:57.240087 EDT | AverageReturn            1000
2017-07-02 13:06:57.240260 EDT | StdReturn                   0
2017-07-02 13:06:57.240452 EDT | MaxReturn                1000
2017-07-02 13:06:57.240589 EDT | MinReturn                1000
2017-07-02 13:06:57.240698 EDT | AverageEsReturn            28.6571
2017-07-02 13:06:57.240821 EDT | StdEsReturn                37.93
2017-07-02 13:06:57.240988 EDT | MaxEsReturn               164
2017-07-02 13:06:57.241093 EDT | MinEsReturn                 3
2017-07-02 13:06:57.241204 EDT | AverageDiscountedReturn    99.9957
2017-07-02 13:06:57.241310 EDT | AverageQLoss                0.010305
2017-07-02 13:06:57.241426 EDT | AveragePolicySurr          -1.55106
2017-07-02 13:06:57.241598 EDT | AverageQ                    1.42845
2017-07-02 13:06:57.241713 EDT | AverageAbsQ                 1.43303
2017-07-02 13:06:57.241835 EDT | AverageY                    1.42848
2017-07-02 13:06:57.241936 EDT | AverageAbsY                 1.42893
2017-07-02 13:06:57.242056 EDT | AverageAbsQYDiff            0.0349475
2017-07-02 13:06:57.242160 EDT | AverageAction               0.80644
2017-07-02 13:06:57.242279 EDT | PolicyRegParamNorm         38.5489
2017-07-02 13:06:57.242380 EDT | QFunRegParamNorm           40.9498
2017-07-02 13:06:57.242519 EDT | -----------------------  ------------
2017-07-02 13:06:57.242713 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #159 | Training started
2017-07-02 13:07:07.038561 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #159 | Training finished
2017-07-02 13:07:07.038842 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #159 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 13:07:07.039049 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #159 | Collecting samples for evaluation
2017-07-02 13:07:12.672982 EDT | -----------------------  ------------
2017-07-02 13:07:12.673467 EDT | Epoch                     159
2017-07-02 13:07:12.673641 EDT | Iteration                 159
2017-07-02 13:07:12.673750 EDT | AverageReturn            1000
2017-07-02 13:07:12.673887 EDT | StdReturn                   0
2017-07-02 13:07:12.673998 EDT | MaxReturn                1000
2017-07-02 13:07:12.674128 EDT | MinReturn                1000
2017-07-02 13:07:12.674259 EDT | AverageEsReturn            13.3333
2017-07-02 13:07:12.674385 EDT | StdEsReturn                19.1787
2017-07-02 13:07:12.674486 EDT | MaxEsReturn               116
2017-07-02 13:07:12.674621 EDT | MinEsReturn                 2
2017-07-02 13:07:12.674765 EDT | AverageDiscountedReturn    99.9957
2017-07-02 13:07:12.674868 EDT | AverageQLoss                0.0117142
2017-07-02 13:07:12.674967 EDT | AveragePolicySurr          -1.54685
2017-07-02 13:07:12.675133 EDT | AverageQ                    1.42688
2017-07-02 13:07:12.675362 EDT | AverageAbsQ                 1.43175
2017-07-02 13:07:12.675582 EDT | AverageY                    1.4269
2017-07-02 13:07:12.675802 EDT | AverageAbsY                 1.42742
2017-07-02 13:07:12.676029 EDT | AverageAbsQYDiff            0.0373518
2017-07-02 13:07:12.676237 EDT | AverageAction               0.756306
2017-07-02 13:07:12.676467 EDT | PolicyRegParamNorm         38.6738
2017-07-02 13:07:12.676653 EDT | QFunRegParamNorm           41.0677
2017-07-02 13:07:12.676884 EDT | -----------------------  ------------
2017-07-02 13:07:12.677211 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #160 | Training started
2017-07-02 13:07:22.413165 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #160 | Training finished
2017-07-02 13:07:22.413777 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #160 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 13:07:22.414023 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #160 | Collecting samples for evaluation
2017-07-02 13:07:27.941578 EDT | -----------------------  ------------
2017-07-02 13:07:27.941891 EDT | Epoch                     160
2017-07-02 13:07:27.942118 EDT | Iteration                 160
2017-07-02 13:07:27.942312 EDT | AverageReturn            1000
2017-07-02 13:07:27.942538 EDT | StdReturn                   0
2017-07-02 13:07:27.942766 EDT | MaxReturn                1000
2017-07-02 13:07:27.942976 EDT | MinReturn                1000
2017-07-02 13:07:27.943208 EDT | AverageEsReturn            14.0282
2017-07-02 13:07:27.943350 EDT | StdEsReturn                14.1849
2017-07-02 13:07:27.943547 EDT | MaxEsReturn                62
2017-07-02 13:07:27.943748 EDT | MinEsReturn                 2
2017-07-02 13:07:27.943855 EDT | AverageDiscountedReturn    99.9957
2017-07-02 13:07:27.944004 EDT | AverageQLoss                0.0100972
2017-07-02 13:07:27.944231 EDT | AveragePolicySurr          -1.54448
2017-07-02 13:07:27.944442 EDT | AverageQ                    1.42448
2017-07-02 13:07:27.944578 EDT | AverageAbsQ                 1.42874
2017-07-02 13:07:27.944691 EDT | AverageY                    1.42454
2017-07-02 13:07:27.944820 EDT | AverageAbsY                 1.42506
2017-07-02 13:07:27.944971 EDT | AverageAbsQYDiff            0.0337585
2017-07-02 13:07:27.945196 EDT | AverageAction               0.822225
2017-07-02 13:07:27.945384 EDT | PolicyRegParamNorm         38.7508
2017-07-02 13:07:27.945630 EDT | QFunRegParamNorm           41.1549
2017-07-02 13:07:27.945759 EDT | -----------------------  ------------
2017-07-02 13:07:27.945938 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #161 | Training started
2017-07-02 13:07:37.640963 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #161 | Training finished
2017-07-02 13:07:37.641180 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #161 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 13:07:37.641358 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #161 | Collecting samples for evaluation
2017-07-02 13:07:43.295266 EDT | -----------------------  ------------
2017-07-02 13:07:43.295844 EDT | Epoch                     161
2017-07-02 13:07:43.295987 EDT | Iteration                 161
2017-07-02 13:07:43.296122 EDT | AverageReturn            1000
2017-07-02 13:07:43.296294 EDT | StdReturn                   0
2017-07-02 13:07:43.296497 EDT | MaxReturn                1000
2017-07-02 13:07:43.296609 EDT | MinReturn                1000
2017-07-02 13:07:43.296731 EDT | AverageEsReturn            17.8571
2017-07-02 13:07:43.296899 EDT | StdEsReturn                19.4986
2017-07-02 13:07:43.297001 EDT | MaxEsReturn                86
2017-07-02 13:07:43.297103 EDT | MinEsReturn                 3
2017-07-02 13:07:43.297300 EDT | AverageDiscountedReturn    99.9957
2017-07-02 13:07:43.297456 EDT | AverageQLoss                0.0115264
2017-07-02 13:07:43.297587 EDT | AveragePolicySurr          -1.54411
2017-07-02 13:07:43.297714 EDT | AverageQ                    1.41816
2017-07-02 13:07:43.297814 EDT | AverageAbsQ                 1.42259
2017-07-02 13:07:43.297931 EDT | AverageY                    1.4181
2017-07-02 13:07:43.298032 EDT | AverageAbsY                 1.41831
2017-07-02 13:07:43.298220 EDT | AverageAbsQYDiff            0.0365443
2017-07-02 13:07:43.298440 EDT | AverageAction               0.661049
2017-07-02 13:07:43.298654 EDT | PolicyRegParamNorm         38.8268
2017-07-02 13:07:43.298789 EDT | QFunRegParamNorm           41.223
2017-07-02 13:07:43.298895 EDT | -----------------------  ------------
2017-07-02 13:07:43.299117 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #162 | Training started
2017-07-02 13:07:53.046400 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #162 | Training finished
2017-07-02 13:07:53.046982 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #162 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 13:07:53.047201 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #162 | Collecting samples for evaluation
2017-07-02 13:07:58.614729 EDT | -----------------------  -------------
2017-07-02 13:07:58.614933 EDT | Epoch                     162
2017-07-02 13:07:58.615045 EDT | Iteration                 162
2017-07-02 13:07:58.615148 EDT | AverageReturn            1000
2017-07-02 13:07:58.615251 EDT | StdReturn                   0
2017-07-02 13:07:58.615352 EDT | MaxReturn                1000
2017-07-02 13:07:58.615499 EDT | MinReturn                1000
2017-07-02 13:07:58.615612 EDT | AverageEsReturn            22.2
2017-07-02 13:07:58.615722 EDT | StdEsReturn                18.5551
2017-07-02 13:07:58.615915 EDT | MaxEsReturn                80
2017-07-02 13:07:58.616109 EDT | MinEsReturn                 4
2017-07-02 13:07:58.616315 EDT | AverageDiscountedReturn    99.9957
2017-07-02 13:07:58.616550 EDT | AverageQLoss                0.00930239
2017-07-02 13:07:58.616765 EDT | AveragePolicySurr          -1.53691
2017-07-02 13:07:58.616996 EDT | AverageQ                    1.41594
2017-07-02 13:07:58.617220 EDT | AverageAbsQ                 1.42058
2017-07-02 13:07:58.617398 EDT | AverageY                    1.41608
2017-07-02 13:07:58.617692 EDT | AverageAbsY                 1.4164
2017-07-02 13:07:58.617856 EDT | AverageAbsQYDiff            0.0334267
2017-07-02 13:07:58.618092 EDT | AverageAction               0.869051
2017-07-02 13:07:58.618314 EDT | PolicyRegParamNorm         38.9472
2017-07-02 13:07:58.618541 EDT | QFunRegParamNorm           41.273
2017-07-02 13:07:58.618772 EDT | -----------------------  -------------
2017-07-02 13:07:58.619034 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #163 | Training started
2017-07-02 13:08:08.360415 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #163 | Training finished
2017-07-02 13:08:08.360588 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #163 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 13:08:08.360777 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #163 | Collecting samples for evaluation
2017-07-02 13:08:14.041157 EDT | -----------------------  ------------
2017-07-02 13:08:14.041764 EDT | Epoch                     163
2017-07-02 13:08:14.041910 EDT | Iteration                 163
2017-07-02 13:08:14.042111 EDT | AverageReturn            1000
2017-07-02 13:08:14.042224 EDT | StdReturn                   0
2017-07-02 13:08:14.042326 EDT | MaxReturn                1000
2017-07-02 13:08:14.042432 EDT | MinReturn                1000
2017-07-02 13:08:14.042619 EDT | AverageEsReturn            25.5897
2017-07-02 13:08:14.042816 EDT | StdEsReturn                17.1998
2017-07-02 13:08:14.042923 EDT | MaxEsReturn                74
2017-07-02 13:08:14.043051 EDT | MinEsReturn                 5
2017-07-02 13:08:14.043201 EDT | AverageDiscountedReturn    99.9957
2017-07-02 13:08:14.043316 EDT | AverageQLoss                0.0119729
2017-07-02 13:08:14.043441 EDT | AveragePolicySurr          -1.53856
2017-07-02 13:08:14.043579 EDT | AverageQ                    1.41641
2017-07-02 13:08:14.043706 EDT | AverageAbsQ                 1.42091
2017-07-02 13:08:14.043858 EDT | AverageY                    1.41636
2017-07-02 13:08:14.043998 EDT | AverageAbsY                 1.41689
2017-07-02 13:08:14.044104 EDT | AverageAbsQYDiff            0.0375798
2017-07-02 13:08:14.044284 EDT | AverageAction               0.661381
2017-07-02 13:08:14.044421 EDT | PolicyRegParamNorm         38.9039
2017-07-02 13:08:14.044523 EDT | QFunRegParamNorm           41.3458
2017-07-02 13:08:14.044624 EDT | -----------------------  ------------
2017-07-02 13:08:14.044865 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #164 | Training started
2017-07-02 13:08:23.781976 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #164 | Training finished
2017-07-02 13:08:23.782588 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #164 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 13:08:23.782900 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #164 | Collecting samples for evaluation
2017-07-02 13:08:29.412720 EDT | -----------------------  ------------
2017-07-02 13:08:29.412945 EDT | Epoch                     164
2017-07-02 13:08:29.413067 EDT | Iteration                 164
2017-07-02 13:08:29.413183 EDT | AverageReturn            1000
2017-07-02 13:08:29.413368 EDT | StdReturn                   0
2017-07-02 13:08:29.413594 EDT | MaxReturn                1000
2017-07-02 13:08:29.413807 EDT | MinReturn                1000
2017-07-02 13:08:29.413982 EDT | AverageEsReturn            17.3448
2017-07-02 13:08:29.414110 EDT | StdEsReturn                18.6562
2017-07-02 13:08:29.414274 EDT | MaxEsReturn               112
2017-07-02 13:08:29.414463 EDT | MinEsReturn                 3
2017-07-02 13:08:29.414606 EDT | AverageDiscountedReturn    99.9957
2017-07-02 13:08:29.414710 EDT | AverageQLoss                0.009862
2017-07-02 13:08:29.414812 EDT | AveragePolicySurr          -1.53799
2017-07-02 13:08:29.414934 EDT | AverageQ                    1.421
2017-07-02 13:08:29.415042 EDT | AverageAbsQ                 1.42545
2017-07-02 13:08:29.415151 EDT | AverageY                    1.421
2017-07-02 13:08:29.415257 EDT | AverageAbsY                 1.42144
2017-07-02 13:08:29.415378 EDT | AverageAbsQYDiff            0.0339351
2017-07-02 13:08:29.415484 EDT | AverageAction               0.50685
2017-07-02 13:08:29.415589 EDT | PolicyRegParamNorm         38.9716
2017-07-02 13:08:29.415694 EDT | QFunRegParamNorm           41.4046
2017-07-02 13:08:29.415837 EDT | -----------------------  ------------
2017-07-02 13:08:29.416011 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #165 | Training started
2017-07-02 13:08:39.133981 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #165 | Training finished
2017-07-02 13:08:39.134236 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #165 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 13:08:39.134427 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #165 | Collecting samples for evaluation
2017-07-02 13:08:44.876521 EDT | -----------------------  ------------
2017-07-02 13:08:44.877144 EDT | Epoch                     165
2017-07-02 13:08:44.877342 EDT | Iteration                 165
2017-07-02 13:08:44.877477 EDT | AverageReturn            1000
2017-07-02 13:08:44.877709 EDT | StdReturn                   0
2017-07-02 13:08:44.877903 EDT | MaxReturn                1000
2017-07-02 13:08:44.878043 EDT | MinReturn                1000
2017-07-02 13:08:44.878177 EDT | AverageEsReturn            21.6739
2017-07-02 13:08:44.878308 EDT | StdEsReturn                28.3227
2017-07-02 13:08:44.878430 EDT | MaxEsReturn               113
2017-07-02 13:08:44.878553 EDT | MinEsReturn                 3
2017-07-02 13:08:44.878699 EDT | AverageDiscountedReturn    99.9957
2017-07-02 13:08:44.878802 EDT | AverageQLoss                0.0107332
2017-07-02 13:08:44.878902 EDT | AveragePolicySurr          -1.53254
2017-07-02 13:08:44.879092 EDT | AverageQ                    1.41759
2017-07-02 13:08:44.879325 EDT | AverageAbsQ                 1.42257
2017-07-02 13:08:44.879536 EDT | AverageY                    1.41761
2017-07-02 13:08:44.879662 EDT | AverageAbsY                 1.4182
2017-07-02 13:08:44.879766 EDT | AverageAbsQYDiff            0.035541
2017-07-02 13:08:44.879869 EDT | AverageAction               0.844737
2017-07-02 13:08:44.879969 EDT | PolicyRegParamNorm         39.07
2017-07-02 13:08:44.880069 EDT | QFunRegParamNorm           41.4838
2017-07-02 13:08:44.880201 EDT | -----------------------  ------------
2017-07-02 13:08:44.880368 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #166 | Training started
2017-07-02 13:08:54.562123 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #166 | Training finished
2017-07-02 13:08:54.563072 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #166 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 13:08:54.563309 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #166 | Collecting samples for evaluation
2017-07-02 13:09:00.164727 EDT | -----------------------  ------------
2017-07-02 13:09:00.165051 EDT | Epoch                     166
2017-07-02 13:09:00.165292 EDT | Iteration                 166
2017-07-02 13:09:00.165536 EDT | AverageReturn            1000
2017-07-02 13:09:00.165655 EDT | StdReturn                   0
2017-07-02 13:09:00.165761 EDT | MaxReturn                1000
2017-07-02 13:09:00.165877 EDT | MinReturn                1000
2017-07-02 13:09:00.166012 EDT | AverageEsReturn            18.6346
2017-07-02 13:09:00.166242 EDT | StdEsReturn                25.3241
2017-07-02 13:09:00.166472 EDT | MaxEsReturn               150
2017-07-02 13:09:00.166705 EDT | MinEsReturn                 3
2017-07-02 13:09:00.166934 EDT | AverageDiscountedReturn    99.9957
2017-07-02 13:09:00.167103 EDT | AverageQLoss                0.0104164
2017-07-02 13:09:00.167338 EDT | AveragePolicySurr          -1.53285
2017-07-02 13:09:00.167538 EDT | AverageQ                    1.41063
2017-07-02 13:09:00.167775 EDT | AverageAbsQ                 1.41522
2017-07-02 13:09:00.167997 EDT | AverageY                    1.41069
2017-07-02 13:09:00.168183 EDT | AverageAbsY                 1.41145
2017-07-02 13:09:00.168414 EDT | AverageAbsQYDiff            0.0354267
2017-07-02 13:09:00.168580 EDT | AverageAction               0.812366
2017-07-02 13:09:00.168693 EDT | PolicyRegParamNorm         39.1677
2017-07-02 13:09:00.168796 EDT | QFunRegParamNorm           41.5344
2017-07-02 13:09:00.168897 EDT | -----------------------  ------------
2017-07-02 13:09:00.169196 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #167 | Training started
2017-07-02 13:09:09.810098 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #167 | Training finished
2017-07-02 13:09:09.810663 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #167 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 13:09:09.810831 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #167 | Collecting samples for evaluation
2017-07-02 13:09:15.420345 EDT | -----------------------  ------------
2017-07-02 13:09:15.420556 EDT | Epoch                     167
2017-07-02 13:09:15.420671 EDT | Iteration                 167
2017-07-02 13:09:15.420776 EDT | AverageReturn            1000
2017-07-02 13:09:15.420939 EDT | StdReturn                   0
2017-07-02 13:09:15.421120 EDT | MaxReturn                1000
2017-07-02 13:09:15.421312 EDT | MinReturn                1000
2017-07-02 13:09:15.421427 EDT | AverageEsReturn            15.1765
2017-07-02 13:09:15.421591 EDT | StdEsReturn                14.3475
2017-07-02 13:09:15.421815 EDT | MaxEsReturn                64
2017-07-02 13:09:15.422033 EDT | MinEsReturn                 3
2017-07-02 13:09:15.422236 EDT | AverageDiscountedReturn    99.9957
2017-07-02 13:09:15.422359 EDT | AverageQLoss                0.0109401
2017-07-02 13:09:15.422500 EDT | AveragePolicySurr          -1.5302
2017-07-02 13:09:15.422609 EDT | AverageQ                    1.40909
2017-07-02 13:09:15.422713 EDT | AverageAbsQ                 1.41393
2017-07-02 13:09:15.422871 EDT | AverageY                    1.40909
2017-07-02 13:09:15.422980 EDT | AverageAbsY                 1.40964
2017-07-02 13:09:15.423081 EDT | AverageAbsQYDiff            0.0365103
2017-07-02 13:09:15.423203 EDT | AverageAction               0.703032
2017-07-02 13:09:15.423305 EDT | PolicyRegParamNorm         39.1164
2017-07-02 13:09:15.423404 EDT | QFunRegParamNorm           41.7672
2017-07-02 13:09:15.423503 EDT | -----------------------  ------------
2017-07-02 13:09:15.423740 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #168 | Training started
2017-07-02 13:09:25.148063 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #168 | Training finished
2017-07-02 13:09:25.148575 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #168 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 13:09:25.148711 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #168 | Collecting samples for evaluation
2017-07-02 13:09:30.720969 EDT | -----------------------  ------------
2017-07-02 13:09:30.721373 EDT | Epoch                     168
2017-07-02 13:09:30.721655 EDT | Iteration                 168
2017-07-02 13:09:30.721904 EDT | AverageReturn             914.273
2017-07-02 13:09:30.722169 EDT | StdReturn                 271.093
2017-07-02 13:09:30.722483 EDT | MaxReturn                1000
2017-07-02 13:09:30.722719 EDT | MinReturn                  57
2017-07-02 13:09:30.722958 EDT | AverageEsReturn            13.4444
2017-07-02 13:09:30.723171 EDT | StdEsReturn                14.2944
2017-07-02 13:09:30.723359 EDT | MaxEsReturn                61
2017-07-02 13:09:30.723527 EDT | MinEsReturn                 3
2017-07-02 13:09:30.723730 EDT | AverageDiscountedReturn    94.8697
2017-07-02 13:09:30.723943 EDT | AverageQLoss                0.011077
2017-07-02 13:09:30.724178 EDT | AveragePolicySurr          -1.52854
2017-07-02 13:09:30.724413 EDT | AverageQ                    1.40824
2017-07-02 13:09:30.724593 EDT | AverageAbsQ                 1.41281
2017-07-02 13:09:30.724779 EDT | AverageY                    1.40837
2017-07-02 13:09:30.724950 EDT | AverageAbsY                 1.4091
2017-07-02 13:09:30.725141 EDT | AverageAbsQYDiff            0.0352303
2017-07-02 13:09:30.725372 EDT | AverageAction               0.523019
2017-07-02 13:09:30.725632 EDT | PolicyRegParamNorm         39.2285
2017-07-02 13:09:30.725851 EDT | QFunRegParamNorm           41.8949
2017-07-02 13:09:30.725982 EDT | -----------------------  ------------
2017-07-02 13:09:30.726221 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #169 | Training started
2017-07-02 13:09:40.760524 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #169 | Training finished
2017-07-02 13:09:40.761133 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #169 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 13:09:40.761517 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #169 | Collecting samples for evaluation
2017-07-02 13:09:46.410960 EDT | -----------------------  ------------
2017-07-02 13:09:46.411265 EDT | Epoch                     169
2017-07-02 13:09:46.411457 EDT | Iteration                 169
2017-07-02 13:09:46.411683 EDT | AverageReturn            1000
2017-07-02 13:09:46.411902 EDT | StdReturn                   0
2017-07-02 13:09:46.412127 EDT | MaxReturn                1000
2017-07-02 13:09:46.412266 EDT | MinReturn                1000
2017-07-02 13:09:46.412490 EDT | AverageEsReturn            14.1389
2017-07-02 13:09:46.412667 EDT | StdEsReturn                14.9055
2017-07-02 13:09:46.412893 EDT | MaxEsReturn                67
2017-07-02 13:09:46.413112 EDT | MinEsReturn                 3
2017-07-02 13:09:46.413276 EDT | AverageDiscountedReturn    99.9957
2017-07-02 13:09:46.413381 EDT | AverageQLoss                0.0114738
2017-07-02 13:09:46.413540 EDT | AveragePolicySurr          -1.52497
2017-07-02 13:09:46.413667 EDT | AverageQ                    1.40697
2017-07-02 13:09:46.413773 EDT | AverageAbsQ                 1.41224
2017-07-02 13:09:46.413986 EDT | AverageY                    1.40688
2017-07-02 13:09:46.414200 EDT | AverageAbsY                 1.40747
2017-07-02 13:09:46.414417 EDT | AverageAbsQYDiff            0.0378844
2017-07-02 13:09:46.414633 EDT | AverageAction               0.634383
2017-07-02 13:09:46.414861 EDT | PolicyRegParamNorm         39.2819
2017-07-02 13:09:46.415086 EDT | QFunRegParamNorm           42.0185
2017-07-02 13:09:46.415310 EDT | -----------------------  ------------
2017-07-02 13:09:46.415602 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #170 | Training started
2017-07-02 13:09:56.191813 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #170 | Training finished
2017-07-02 13:09:56.192365 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #170 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 13:09:56.192568 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #170 | Collecting samples for evaluation
2017-07-02 13:10:01.852608 EDT | -----------------------  -------------
2017-07-02 13:10:01.852934 EDT | Epoch                     170
2017-07-02 13:10:01.853171 EDT | Iteration                 170
2017-07-02 13:10:01.853380 EDT | AverageReturn            1000
2017-07-02 13:10:01.853642 EDT | StdReturn                   0
2017-07-02 13:10:01.853877 EDT | MaxReturn                1000
2017-07-02 13:10:01.854060 EDT | MinReturn                1000
2017-07-02 13:10:01.854297 EDT | AverageEsReturn            14.6471
2017-07-02 13:10:01.854517 EDT | StdEsReturn                17.5514
2017-07-02 13:10:01.854642 EDT | MaxEsReturn                86
2017-07-02 13:10:01.854749 EDT | MinEsReturn                 3
2017-07-02 13:10:01.854874 EDT | AverageDiscountedReturn    99.9957
2017-07-02 13:10:01.855011 EDT | AverageQLoss                0.00981777
2017-07-02 13:10:01.855115 EDT | AveragePolicySurr          -1.52386
2017-07-02 13:10:01.855215 EDT | AverageQ                    1.4037
2017-07-02 13:10:01.855315 EDT | AverageAbsQ                 1.40829
2017-07-02 13:10:01.855454 EDT | AverageY                    1.4038
2017-07-02 13:10:01.855580 EDT | AverageAbsY                 1.40446
2017-07-02 13:10:01.855680 EDT | AverageAbsQYDiff            0.0339938
2017-07-02 13:10:01.855778 EDT | AverageAction               0.610217
2017-07-02 13:10:01.855890 EDT | PolicyRegParamNorm         39.3588
2017-07-02 13:10:01.855992 EDT | QFunRegParamNorm           42.1027
2017-07-02 13:10:01.856091 EDT | -----------------------  -------------
2017-07-02 13:10:01.856254 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #171 | Training started
2017-07-02 13:10:11.576839 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #171 | Training finished
2017-07-02 13:10:11.577477 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #171 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 13:10:11.577970 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #171 | Collecting samples for evaluation
2017-07-02 13:10:17.420941 EDT | -----------------------  -----------
2017-07-02 13:10:17.421262 EDT | Epoch                    171
2017-07-02 13:10:17.421446 EDT | Iteration                171
2017-07-02 13:10:17.421688 EDT | AverageReturn             42.1941
2017-07-02 13:10:17.421996 EDT | StdReturn                  1.2479
2017-07-02 13:10:17.422191 EDT | MaxReturn                 48
2017-07-02 13:10:17.422417 EDT | MinReturn                 39
2017-07-02 13:10:17.422653 EDT | AverageEsReturn           14.9265
2017-07-02 13:10:17.422880 EDT | StdEsReturn               21.6145
2017-07-02 13:10:17.423016 EDT | MaxEsReturn              141
2017-07-02 13:10:17.423256 EDT | MinEsReturn                3
2017-07-02 13:10:17.423480 EDT | AverageDiscountedReturn   34.5567
2017-07-02 13:10:17.423720 EDT | AverageQLoss               0.0110091
2017-07-02 13:10:17.423941 EDT | AveragePolicySurr         -1.5251
2017-07-02 13:10:17.424123 EDT | AverageQ                   1.407
2017-07-02 13:10:17.424342 EDT | AverageAbsQ                1.41105
2017-07-02 13:10:17.424567 EDT | AverageY                   1.40693
2017-07-02 13:10:17.424766 EDT | AverageAbsY                1.40732
2017-07-02 13:10:17.424969 EDT | AverageAbsQYDiff           0.0354028
2017-07-02 13:10:17.425186 EDT | AverageAction              0.504718
2017-07-02 13:10:17.425416 EDT | PolicyRegParamNorm        39.4027
2017-07-02 13:10:17.425604 EDT | QFunRegParamNorm          42.189
2017-07-02 13:10:17.425830 EDT | -----------------------  -----------
2017-07-02 13:10:17.426144 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #172 | Training started
2017-07-02 13:10:27.491444 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #172 | Training finished
2017-07-02 13:10:27.492065 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #172 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 13:10:27.492515 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #172 | Collecting samples for evaluation
2017-07-02 13:10:33.177540 EDT | -----------------------  ------------
2017-07-02 13:10:33.178019 EDT | Epoch                     172
2017-07-02 13:10:33.178204 EDT | Iteration                 172
2017-07-02 13:10:33.178388 EDT | AverageReturn            1000
2017-07-02 13:10:33.178587 EDT | StdReturn                   0
2017-07-02 13:10:33.178705 EDT | MaxReturn                1000
2017-07-02 13:10:33.178901 EDT | MinReturn                1000
2017-07-02 13:10:33.179094 EDT | AverageEsReturn            10.5684
2017-07-02 13:10:33.179305 EDT | StdEsReturn                12.0749
2017-07-02 13:10:33.179523 EDT | MaxEsReturn                56
2017-07-02 13:10:33.179734 EDT | MinEsReturn                 3
2017-07-02 13:10:33.179844 EDT | AverageDiscountedReturn    99.9957
2017-07-02 13:10:33.180001 EDT | AverageQLoss                0.0112381
2017-07-02 13:10:33.180223 EDT | AveragePolicySurr          -1.52206
2017-07-02 13:10:33.180437 EDT | AverageQ                    1.40362
2017-07-02 13:10:33.180560 EDT | AverageAbsQ                 1.40812
2017-07-02 13:10:33.180688 EDT | AverageY                    1.40369
2017-07-02 13:10:33.180815 EDT | AverageAbsY                 1.40402
2017-07-02 13:10:33.180996 EDT | AverageAbsQYDiff            0.0371853
2017-07-02 13:10:33.181164 EDT | AverageAction               0.725777
2017-07-02 13:10:33.181340 EDT | PolicyRegParamNorm         39.4835
2017-07-02 13:10:33.181508 EDT | QFunRegParamNorm           42.2611
2017-07-02 13:10:33.181668 EDT | -----------------------  ------------
2017-07-02 13:10:33.181878 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #173 | Training started
2017-07-02 13:10:42.686122 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #173 | Training finished
2017-07-02 13:10:42.884174 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #173 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 13:10:42.884387 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #173 | Collecting samples for evaluation
2017-07-02 13:10:48.609425 EDT | -----------------------  ------------
2017-07-02 13:10:48.609638 EDT | Epoch                     173
2017-07-02 13:10:48.609794 EDT | Iteration                 173
2017-07-02 13:10:48.609924 EDT | AverageReturn            1000
2017-07-02 13:10:48.610051 EDT | StdReturn                   0
2017-07-02 13:10:48.610238 EDT | MaxReturn                1000
2017-07-02 13:10:48.610441 EDT | MinReturn                1000
2017-07-02 13:10:48.610604 EDT | AverageEsReturn            13.527
2017-07-02 13:10:48.610719 EDT | StdEsReturn                14.2518
2017-07-02 13:10:48.610823 EDT | MaxEsReturn                75
2017-07-02 13:10:48.610960 EDT | MinEsReturn                 3
2017-07-02 13:10:48.611066 EDT | AverageDiscountedReturn    99.9957
2017-07-02 13:10:48.611166 EDT | AverageQLoss                0.0101735
2017-07-02 13:10:48.611266 EDT | AveragePolicySurr          -1.52055
2017-07-02 13:10:48.611366 EDT | AverageQ                    1.4008
2017-07-02 13:10:48.611464 EDT | AverageAbsQ                 1.40526
2017-07-02 13:10:48.611573 EDT | AverageY                    1.40085
2017-07-02 13:10:48.611711 EDT | AverageAbsY                 1.40136
2017-07-02 13:10:48.611811 EDT | AverageAbsQYDiff            0.0355839
2017-07-02 13:10:48.611911 EDT | AverageAction               0.730684
2017-07-02 13:10:48.612011 EDT | PolicyRegParamNorm         39.5713
2017-07-02 13:10:48.612111 EDT | QFunRegParamNorm           42.3654
2017-07-02 13:10:48.612210 EDT | -----------------------  ------------
2017-07-02 13:10:48.612373 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #174 | Training started
2017-07-02 13:10:58.186172 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #174 | Training finished
2017-07-02 13:10:58.186818 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #174 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 13:10:58.186957 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #174 | Collecting samples for evaluation
2017-07-02 13:11:03.841402 EDT | -----------------------  ------------
2017-07-02 13:11:03.841931 EDT | Epoch                     174
2017-07-02 13:11:03.842134 EDT | Iteration                 174
2017-07-02 13:11:03.842285 EDT | AverageReturn            1000
2017-07-02 13:11:03.842471 EDT | StdReturn                   0
2017-07-02 13:11:03.842601 EDT | MaxReturn                1000
2017-07-02 13:11:03.842706 EDT | MinReturn                1000
2017-07-02 13:11:03.842905 EDT | AverageEsReturn            12.3636
2017-07-02 13:11:03.843067 EDT | StdEsReturn                13.9264
2017-07-02 13:11:03.843226 EDT | MaxEsReturn                67
2017-07-02 13:11:03.843425 EDT | MinEsReturn                 3
2017-07-02 13:11:03.843557 EDT | AverageDiscountedReturn    99.9957
2017-07-02 13:11:03.843728 EDT | AverageQLoss                0.0103072
2017-07-02 13:11:03.843908 EDT | AveragePolicySurr          -1.52591
2017-07-02 13:11:03.844014 EDT | AverageQ                    1.40967
2017-07-02 13:11:03.844150 EDT | AverageAbsQ                 1.41425
2017-07-02 13:11:03.844258 EDT | AverageY                    1.40971
2017-07-02 13:11:03.844382 EDT | AverageAbsY                 1.41016
2017-07-02 13:11:03.844548 EDT | AverageAbsQYDiff            0.0349304
2017-07-02 13:11:03.844682 EDT | AverageAction               0.78933
2017-07-02 13:11:03.844808 EDT | PolicyRegParamNorm         39.664
2017-07-02 13:11:03.844959 EDT | QFunRegParamNorm           42.4548
2017-07-02 13:11:03.845065 EDT | -----------------------  ------------
2017-07-02 13:11:03.845275 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #175 | Training started
2017-07-02 13:11:13.566010 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #175 | Training finished
2017-07-02 13:11:13.566658 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #175 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 13:11:13.566971 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #175 | Collecting samples for evaluation
2017-07-02 13:11:19.212252 EDT | -----------------------  ------------
2017-07-02 13:11:19.212450 EDT | Epoch                     175
2017-07-02 13:11:19.212564 EDT | Iteration                 175
2017-07-02 13:11:19.212667 EDT | AverageReturn            1000
2017-07-02 13:11:19.212771 EDT | StdReturn                   0
2017-07-02 13:11:19.212880 EDT | MaxReturn                1000
2017-07-02 13:11:19.212978 EDT | MinReturn                1000
2017-07-02 13:11:19.213099 EDT | AverageEsReturn            12.7195
2017-07-02 13:11:19.213200 EDT | StdEsReturn                15.2997
2017-07-02 13:11:19.213319 EDT | MaxEsReturn                98
2017-07-02 13:11:19.213418 EDT | MinEsReturn                 3
2017-07-02 13:11:19.213532 EDT | AverageDiscountedReturn    99.9957
2017-07-02 13:11:19.213675 EDT | AverageQLoss                0.0102917
2017-07-02 13:11:19.213783 EDT | AveragePolicySurr          -1.52045
2017-07-02 13:11:19.213883 EDT | AverageQ                    1.40069
2017-07-02 13:11:19.214000 EDT | AverageAbsQ                 1.40548
2017-07-02 13:11:19.214153 EDT | AverageY                    1.40068
2017-07-02 13:11:19.214311 EDT | AverageAbsY                 1.4009
2017-07-02 13:11:19.214469 EDT | AverageAbsQYDiff            0.0366016
2017-07-02 13:11:19.214647 EDT | AverageAction               0.872539
2017-07-02 13:11:19.214808 EDT | PolicyRegParamNorm         39.7718
2017-07-02 13:11:19.214965 EDT | QFunRegParamNorm           42.611
2017-07-02 13:11:19.215089 EDT | -----------------------  ------------
2017-07-02 13:11:19.215305 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #176 | Training started
2017-07-02 13:11:28.930188 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #176 | Training finished
2017-07-02 13:11:28.930718 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #176 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 13:11:28.930985 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #176 | Collecting samples for evaluation
2017-07-02 13:11:34.609618 EDT | -----------------------  ------------
2017-07-02 13:11:34.610143 EDT | Epoch                     176
2017-07-02 13:11:34.610297 EDT | Iteration                 176
2017-07-02 13:11:34.610407 EDT | AverageReturn            1000
2017-07-02 13:11:34.610534 EDT | StdReturn                   0
2017-07-02 13:11:34.610640 EDT | MaxReturn                1000
2017-07-02 13:11:34.610760 EDT | MinReturn                1000
2017-07-02 13:11:34.610862 EDT | AverageEsReturn            13.6301
2017-07-02 13:11:34.611003 EDT | StdEsReturn                19.909
2017-07-02 13:11:34.611110 EDT | MaxEsReturn               129
2017-07-02 13:11:34.611225 EDT | MinEsReturn                 3
2017-07-02 13:11:34.611327 EDT | AverageDiscountedReturn    99.9957
2017-07-02 13:11:34.611445 EDT | AverageQLoss                0.011329
2017-07-02 13:11:34.611548 EDT | AveragePolicySurr          -1.5202
2017-07-02 13:11:34.611665 EDT | AverageQ                    1.39713
2017-07-02 13:11:34.611771 EDT | AverageAbsQ                 1.40157
2017-07-02 13:11:34.611873 EDT | AverageY                    1.39723
2017-07-02 13:11:34.611979 EDT | AverageAbsY                 1.39767
2017-07-02 13:11:34.612126 EDT | AverageAbsQYDiff            0.0369404
2017-07-02 13:11:34.612292 EDT | AverageAction               0.840406
2017-07-02 13:11:34.612414 EDT | PolicyRegParamNorm         39.8275
2017-07-02 13:11:34.612530 EDT | QFunRegParamNorm           42.6655
2017-07-02 13:11:34.612658 EDT | -----------------------  ------------
2017-07-02 13:11:34.612841 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #177 | Training started
2017-07-02 13:11:44.258376 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #177 | Training finished
2017-07-02 13:11:44.258910 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #177 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 13:11:44.259082 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #177 | Collecting samples for evaluation
2017-07-02 13:11:49.907649 EDT | -----------------------  ------------
2017-07-02 13:11:49.907883 EDT | Epoch                     177
2017-07-02 13:11:49.908120 EDT | Iteration                 177
2017-07-02 13:11:49.908329 EDT | AverageReturn            1000
2017-07-02 13:11:49.908534 EDT | StdReturn                   0
2017-07-02 13:11:49.908771 EDT | MaxReturn                1000
2017-07-02 13:11:49.908940 EDT | MinReturn                1000
2017-07-02 13:11:49.909081 EDT | AverageEsReturn            16.1129
2017-07-02 13:11:49.909185 EDT | StdEsReturn                19.568
2017-07-02 13:11:49.909286 EDT | MaxEsReturn               126
2017-07-02 13:11:49.909388 EDT | MinEsReturn                 3
2017-07-02 13:11:49.909546 EDT | AverageDiscountedReturn    99.9957
2017-07-02 13:11:49.909651 EDT | AverageQLoss                0.0105168
2017-07-02 13:11:49.909753 EDT | AveragePolicySurr          -1.51848
2017-07-02 13:11:49.909854 EDT | AverageQ                    1.3968
2017-07-02 13:11:49.909993 EDT | AverageAbsQ                 1.40111
2017-07-02 13:11:49.910106 EDT | AverageY                    1.39686
2017-07-02 13:11:49.910208 EDT | AverageAbsY                 1.39736
2017-07-02 13:11:49.910328 EDT | AverageAbsQYDiff            0.0359716
2017-07-02 13:11:49.910453 EDT | AverageAction               0.788858
2017-07-02 13:11:49.910557 EDT | PolicyRegParamNorm         39.9546
2017-07-02 13:11:49.910665 EDT | QFunRegParamNorm           42.8068
2017-07-02 13:11:49.910770 EDT | -----------------------  ------------
2017-07-02 13:11:49.910972 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #178 | Training started
2017-07-02 13:11:59.417913 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #178 | Training finished
2017-07-02 13:11:59.418539 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #178 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 13:11:59.418767 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #178 | Collecting samples for evaluation
2017-07-02 13:12:05.125912 EDT | -----------------------  ------------
2017-07-02 13:12:05.126522 EDT | Epoch                     178
2017-07-02 13:12:05.126749 EDT | Iteration                 178
2017-07-02 13:12:05.126991 EDT | AverageReturn            1000
2017-07-02 13:12:05.127271 EDT | StdReturn                   0
2017-07-02 13:12:05.127524 EDT | MaxReturn                1000
2017-07-02 13:12:05.127699 EDT | MinReturn                1000
2017-07-02 13:12:05.127939 EDT | AverageEsReturn            19.3077
2017-07-02 13:12:05.128157 EDT | StdEsReturn                19.1447
2017-07-02 13:12:05.128269 EDT | MaxEsReturn                72
2017-07-02 13:12:05.128370 EDT | MinEsReturn                 3
2017-07-02 13:12:05.128470 EDT | AverageDiscountedReturn    99.9957
2017-07-02 13:12:05.128624 EDT | AverageQLoss                0.0102143
2017-07-02 13:12:05.128737 EDT | AveragePolicySurr          -1.51595
2017-07-02 13:12:05.128840 EDT | AverageQ                    1.40127
2017-07-02 13:12:05.128942 EDT | AverageAbsQ                 1.40608
2017-07-02 13:12:05.129091 EDT | AverageY                    1.40124
2017-07-02 13:12:05.129195 EDT | AverageAbsY                 1.4018
2017-07-02 13:12:05.129301 EDT | AverageAbsQYDiff            0.0354236
2017-07-02 13:12:05.129415 EDT | AverageAction               0.673805
2017-07-02 13:12:05.129561 EDT | PolicyRegParamNorm         39.9814
2017-07-02 13:12:05.129686 EDT | QFunRegParamNorm           42.8458
2017-07-02 13:12:05.129794 EDT | -----------------------  ------------
2017-07-02 13:12:05.129963 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #179 | Training started
2017-07-02 13:12:14.677805 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #179 | Training finished
2017-07-02 13:12:14.678405 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #179 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 13:12:14.678576 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #179 | Collecting samples for evaluation
2017-07-02 13:12:20.406387 EDT | -----------------------  ------------
2017-07-02 13:12:20.406631 EDT | Epoch                     179
2017-07-02 13:12:20.406759 EDT | Iteration                 179
2017-07-02 13:12:20.406897 EDT | AverageReturn            1000
2017-07-02 13:12:20.407008 EDT | StdReturn                   0
2017-07-02 13:12:20.407124 EDT | MaxReturn                1000
2017-07-02 13:12:20.407227 EDT | MinReturn                1000
2017-07-02 13:12:20.407346 EDT | AverageEsReturn            17.9643
2017-07-02 13:12:20.407494 EDT | StdEsReturn                14.7103
2017-07-02 13:12:20.407642 EDT | MaxEsReturn                65
2017-07-02 13:12:20.407748 EDT | MinEsReturn                 4
2017-07-02 13:12:20.407875 EDT | AverageDiscountedReturn    99.9957
2017-07-02 13:12:20.407979 EDT | AverageQLoss                0.01032
2017-07-02 13:12:20.408119 EDT | AveragePolicySurr          -1.50935
2017-07-02 13:12:20.408226 EDT | AverageQ                    1.39397
2017-07-02 13:12:20.408365 EDT | AverageAbsQ                 1.39829
2017-07-02 13:12:20.408496 EDT | AverageY                    1.39399
2017-07-02 13:12:20.408649 EDT | AverageAbsY                 1.39472
2017-07-02 13:12:20.408786 EDT | AverageAbsQYDiff            0.0348654
2017-07-02 13:12:20.408918 EDT | AverageAction               0.615842
2017-07-02 13:12:20.409029 EDT | PolicyRegParamNorm         40.1014
2017-07-02 13:12:20.409222 EDT | QFunRegParamNorm           42.9165
2017-07-02 13:12:20.409373 EDT | -----------------------  ------------
2017-07-02 13:12:20.409776 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #180 | Training started
2017-07-02 13:12:30.005755 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #180 | Training finished
2017-07-02 13:12:30.006528 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #180 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 13:12:30.006794 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #180 | Collecting samples for evaluation
2017-07-02 13:12:35.678060 EDT | -----------------------  ------------
2017-07-02 13:12:35.678678 EDT | Epoch                     180
2017-07-02 13:12:35.678927 EDT | Iteration                 180
2017-07-02 13:12:35.679121 EDT | AverageReturn            1000
2017-07-02 13:12:35.679270 EDT | StdReturn                   0
2017-07-02 13:12:35.679388 EDT | MaxReturn                1000
2017-07-02 13:12:35.679523 EDT | MinReturn                1000
2017-07-02 13:12:35.679627 EDT | AverageEsReturn            18.2
2017-07-02 13:12:35.679728 EDT | StdEsReturn                20.256
2017-07-02 13:12:35.679873 EDT | MaxEsReturn               113
2017-07-02 13:12:35.679990 EDT | MinEsReturn                 4
2017-07-02 13:12:35.680142 EDT | AverageDiscountedReturn    99.9957
2017-07-02 13:12:35.680289 EDT | AverageQLoss                0.0123792
2017-07-02 13:12:35.680410 EDT | AveragePolicySurr          -1.50961
2017-07-02 13:12:35.680571 EDT | AverageQ                    1.39272
2017-07-02 13:12:35.680770 EDT | AverageAbsQ                 1.39757
2017-07-02 13:12:35.680880 EDT | AverageY                    1.39271
2017-07-02 13:12:35.680984 EDT | AverageAbsY                 1.39342
2017-07-02 13:12:35.681088 EDT | AverageAbsQYDiff            0.0391012
2017-07-02 13:12:35.681228 EDT | AverageAction               0.829872
2017-07-02 13:12:35.681388 EDT | PolicyRegParamNorm         40.1937
2017-07-02 13:12:35.681534 EDT | QFunRegParamNorm           42.9603
2017-07-02 13:12:35.681744 EDT | -----------------------  ------------
2017-07-02 13:12:35.682063 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #181 | Training started
2017-07-02 13:12:45.288895 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #181 | Training finished
2017-07-02 13:12:45.289445 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #181 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 13:12:45.289703 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #181 | Collecting samples for evaluation
2017-07-02 13:12:50.981766 EDT | -----------------------  ------------
2017-07-02 13:12:50.982105 EDT | Epoch                     181
2017-07-02 13:12:50.982346 EDT | Iteration                 181
2017-07-02 13:12:50.982550 EDT | AverageReturn            1000
2017-07-02 13:12:50.982773 EDT | StdReturn                   0
2017-07-02 13:12:50.982987 EDT | MaxReturn                1000
2017-07-02 13:12:50.983197 EDT | MinReturn                1000
2017-07-02 13:12:50.983405 EDT | AverageEsReturn            23.7368
2017-07-02 13:12:50.983602 EDT | StdEsReturn                27.4827
2017-07-02 13:12:50.983732 EDT | MaxEsReturn               138
2017-07-02 13:12:50.983979 EDT | MinEsReturn                 3
2017-07-02 13:12:50.984187 EDT | AverageDiscountedReturn    99.9957
2017-07-02 13:12:50.984385 EDT | AverageQLoss                0.0106168
2017-07-02 13:12:50.984579 EDT | AveragePolicySurr          -1.50631
2017-07-02 13:12:50.984727 EDT | AverageQ                    1.39046
2017-07-02 13:12:50.984832 EDT | AverageAbsQ                 1.39553
2017-07-02 13:12:50.984942 EDT | AverageY                    1.39047
2017-07-02 13:12:50.985045 EDT | AverageAbsY                 1.39145
2017-07-02 13:12:50.985199 EDT | AverageAbsQYDiff            0.0356808
2017-07-02 13:12:50.985348 EDT | AverageAction               0.840643
2017-07-02 13:12:50.985479 EDT | PolicyRegParamNorm         40.255
2017-07-02 13:12:50.985650 EDT | QFunRegParamNorm           43.0596
2017-07-02 13:12:50.985780 EDT | -----------------------  ------------
2017-07-02 13:12:50.986017 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #182 | Training started
2017-07-02 13:13:00.594853 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #182 | Training finished
2017-07-02 13:13:00.595351 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #182 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 13:13:00.595529 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #182 | Collecting samples for evaluation
2017-07-02 13:13:06.282016 EDT | -----------------------  ------------
2017-07-02 13:13:06.282501 EDT | Epoch                     182
2017-07-02 13:13:06.282751 EDT | Iteration                 182
2017-07-02 13:13:06.282981 EDT | AverageReturn            1000
2017-07-02 13:13:06.283186 EDT | StdReturn                   0
2017-07-02 13:13:06.283294 EDT | MaxReturn                1000
2017-07-02 13:13:06.283420 EDT | MinReturn                1000
2017-07-02 13:13:06.283529 EDT | AverageEsReturn            28.1143
2017-07-02 13:13:06.283686 EDT | StdEsReturn                28.2416
2017-07-02 13:13:06.283800 EDT | MaxEsReturn               101
2017-07-02 13:13:06.283903 EDT | MinEsReturn                 3
2017-07-02 13:13:06.284004 EDT | AverageDiscountedReturn    99.9957
2017-07-02 13:13:06.284104 EDT | AverageQLoss                0.0122358
2017-07-02 13:13:06.284203 EDT | AveragePolicySurr          -1.51143
2017-07-02 13:13:06.284304 EDT | AverageQ                    1.3892
2017-07-02 13:13:06.284465 EDT | AverageAbsQ                 1.39439
2017-07-02 13:13:06.284568 EDT | AverageY                    1.38931
2017-07-02 13:13:06.284695 EDT | AverageAbsY                 1.38983
2017-07-02 13:13:06.284797 EDT | AverageAbsQYDiff            0.0385039
2017-07-02 13:13:06.284897 EDT | AverageAction               0.904725
2017-07-02 13:13:06.285018 EDT | PolicyRegParamNorm         40.2899
2017-07-02 13:13:06.285119 EDT | QFunRegParamNorm           43.1209
2017-07-02 13:13:06.285218 EDT | -----------------------  ------------
2017-07-02 13:13:06.285378 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #183 | Training started
2017-07-02 13:13:15.863979 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #183 | Training finished
2017-07-02 13:13:15.866640 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #183 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 13:13:15.866908 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #183 | Collecting samples for evaluation
2017-07-02 13:13:21.529516 EDT | -----------------------  ------------
2017-07-02 13:13:21.529809 EDT | Epoch                     183
2017-07-02 13:13:21.530037 EDT | Iteration                 183
2017-07-02 13:13:21.530242 EDT | AverageReturn            1000
2017-07-02 13:13:21.530462 EDT | StdReturn                   0
2017-07-02 13:13:21.530682 EDT | MaxReturn                1000
2017-07-02 13:13:21.530977 EDT | MinReturn                1000
2017-07-02 13:13:21.531215 EDT | AverageEsReturn            35.8387
2017-07-02 13:13:21.531446 EDT | StdEsReturn                23.5209
2017-07-02 13:13:21.531664 EDT | MaxEsReturn               117
2017-07-02 13:13:21.531887 EDT | MinEsReturn                 4
2017-07-02 13:13:21.532024 EDT | AverageDiscountedReturn    99.9957
2017-07-02 13:13:21.532134 EDT | AverageQLoss                0.0095985
2017-07-02 13:13:21.532262 EDT | AveragePolicySurr          -1.51056
2017-07-02 13:13:21.532411 EDT | AverageQ                    1.39634
2017-07-02 13:13:21.532515 EDT | AverageAbsQ                 1.40056
2017-07-02 13:13:21.532616 EDT | AverageY                    1.3963
2017-07-02 13:13:21.532736 EDT | AverageAbsY                 1.39667
2017-07-02 13:13:21.532953 EDT | AverageAbsQYDiff            0.0346599
2017-07-02 13:13:21.533155 EDT | AverageAction               0.907261
2017-07-02 13:13:21.533376 EDT | PolicyRegParamNorm         40.3803
2017-07-02 13:13:21.533607 EDT | QFunRegParamNorm           43.1752
2017-07-02 13:13:21.533839 EDT | -----------------------  ------------
2017-07-02 13:13:21.534156 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #184 | Training started
2017-07-02 13:13:31.080943 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #184 | Training finished
2017-07-02 13:13:31.086043 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #184 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 13:13:31.086297 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #184 | Collecting samples for evaluation
2017-07-02 13:13:36.808580 EDT | -----------------------  ------------
2017-07-02 13:13:36.808789 EDT | Epoch                     184
2017-07-02 13:13:36.808900 EDT | Iteration                 184
2017-07-02 13:13:36.809031 EDT | AverageReturn            1000
2017-07-02 13:13:36.809135 EDT | StdReturn                   0
2017-07-02 13:13:36.809236 EDT | MaxReturn                1000
2017-07-02 13:13:36.809381 EDT | MinReturn                1000
2017-07-02 13:13:36.809556 EDT | AverageEsReturn            26.2162
2017-07-02 13:13:36.809687 EDT | StdEsReturn                15.1998
2017-07-02 13:13:36.809791 EDT | MaxEsReturn                57
2017-07-02 13:13:36.809893 EDT | MinEsReturn                 3
2017-07-02 13:13:36.809994 EDT | AverageDiscountedReturn    99.9957
2017-07-02 13:13:36.810189 EDT | AverageQLoss                0.0100436
2017-07-02 13:13:36.810383 EDT | AveragePolicySurr          -1.51086
2017-07-02 13:13:36.810578 EDT | AverageQ                    1.39583
2017-07-02 13:13:36.810684 EDT | AverageAbsQ                 1.40026
2017-07-02 13:13:36.810787 EDT | AverageY                    1.39581
2017-07-02 13:13:36.810903 EDT | AverageAbsY                 1.3962
2017-07-02 13:13:36.811108 EDT | AverageAbsQYDiff            0.0344392
2017-07-02 13:13:36.811337 EDT | AverageAction               0.929702
2017-07-02 13:13:36.811513 EDT | PolicyRegParamNorm         40.4445
2017-07-02 13:13:36.811619 EDT | QFunRegParamNorm           43.3065
2017-07-02 13:13:36.811782 EDT | -----------------------  ------------
2017-07-02 13:13:36.811955 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #185 | Training started
2017-07-02 13:13:46.389367 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #185 | Training finished
2017-07-02 13:13:46.390008 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #185 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 13:13:46.390220 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #185 | Collecting samples for evaluation
2017-07-02 13:13:52.083283 EDT | -----------------------  ------------
2017-07-02 13:13:52.083838 EDT | Epoch                     185
2017-07-02 13:13:52.083973 EDT | Iteration                 185
2017-07-02 13:13:52.084130 EDT | AverageReturn            1000
2017-07-02 13:13:52.084243 EDT | StdReturn                   0
2017-07-02 13:13:52.084362 EDT | MaxReturn                1000
2017-07-02 13:13:52.084495 EDT | MinReturn                1000
2017-07-02 13:13:52.084611 EDT | AverageEsReturn            44.8696
2017-07-02 13:13:52.084775 EDT | StdEsReturn                28.6695
2017-07-02 13:13:52.084951 EDT | MaxEsReturn               116
2017-07-02 13:13:52.085145 EDT | MinEsReturn                 4
2017-07-02 13:13:52.085354 EDT | AverageDiscountedReturn    99.9957
2017-07-02 13:13:52.085558 EDT | AverageQLoss                0.0102193
2017-07-02 13:13:52.085733 EDT | AveragePolicySurr          -1.5065
2017-07-02 13:13:52.085856 EDT | AverageQ                    1.39182
2017-07-02 13:13:52.085984 EDT | AverageAbsQ                 1.39659
2017-07-02 13:13:52.086122 EDT | AverageY                    1.39186
2017-07-02 13:13:52.086248 EDT | AverageAbsY                 1.39247
2017-07-02 13:13:52.086352 EDT | AverageAbsQYDiff            0.0363498
2017-07-02 13:13:52.086471 EDT | AverageAction               0.889995
2017-07-02 13:13:52.086572 EDT | PolicyRegParamNorm         40.5628
2017-07-02 13:13:52.086707 EDT | QFunRegParamNorm           43.3544
2017-07-02 13:13:52.086823 EDT | -----------------------  ------------
2017-07-02 13:13:52.086988 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #186 | Training started
2017-07-02 13:14:01.781405 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #186 | Training finished
2017-07-02 13:14:01.782043 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #186 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 13:14:01.782296 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #186 | Collecting samples for evaluation
2017-07-02 13:14:07.391511 EDT | -----------------------  ------------
2017-07-02 13:14:07.391733 EDT | Epoch                     186
2017-07-02 13:14:07.391856 EDT | Iteration                 186
2017-07-02 13:14:07.392014 EDT | AverageReturn            1000
2017-07-02 13:14:07.392140 EDT | StdReturn                   0
2017-07-02 13:14:07.392264 EDT | MaxReturn                1000
2017-07-02 13:14:07.392381 EDT | MinReturn                1000
2017-07-02 13:14:07.392490 EDT | AverageEsReturn            39.96
2017-07-02 13:14:07.392626 EDT | StdEsReturn                35.0616
2017-07-02 13:14:07.392807 EDT | MaxEsReturn               173
2017-07-02 13:14:07.393007 EDT | MinEsReturn                 3
2017-07-02 13:14:07.393279 EDT | AverageDiscountedReturn    99.9957
2017-07-02 13:14:07.393468 EDT | AverageQLoss                0.009973
2017-07-02 13:14:07.393674 EDT | AveragePolicySurr          -1.50444
2017-07-02 13:14:07.393828 EDT | AverageQ                    1.38875
2017-07-02 13:14:07.393990 EDT | AverageAbsQ                 1.39306
2017-07-02 13:14:07.394116 EDT | AverageY                    1.3887
2017-07-02 13:14:07.394269 EDT | AverageAbsY                 1.38921
2017-07-02 13:14:07.394395 EDT | AverageAbsQYDiff            0.0346051
2017-07-02 13:14:07.394517 EDT | AverageAction               0.899013
2017-07-02 13:14:07.394652 EDT | PolicyRegParamNorm         40.5854
2017-07-02 13:14:07.394771 EDT | QFunRegParamNorm           43.4069
2017-07-02 13:14:07.394871 EDT | -----------------------  ------------
2017-07-02 13:14:07.395039 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #187 | Training started
2017-07-02 13:14:17.174608 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #187 | Training finished
2017-07-02 13:14:17.175132 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #187 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 13:14:17.175741 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #187 | Collecting samples for evaluation
2017-07-02 13:14:22.774843 EDT | -----------------------  ------------
2017-07-02 13:14:22.775217 EDT | Epoch                     187
2017-07-02 13:14:22.775500 EDT | Iteration                 187
2017-07-02 13:14:22.775714 EDT | AverageReturn            1000
2017-07-02 13:14:22.775894 EDT | StdReturn                   0
2017-07-02 13:14:22.776020 EDT | MaxReturn                1000
2017-07-02 13:14:22.776209 EDT | MinReturn                1000
2017-07-02 13:14:22.776353 EDT | AverageEsReturn            32.2903
2017-07-02 13:14:22.776498 EDT | StdEsReturn                34.2761
2017-07-02 13:14:22.776681 EDT | MaxEsReturn               143
2017-07-02 13:14:22.776823 EDT | MinEsReturn                 3
2017-07-02 13:14:22.776972 EDT | AverageDiscountedReturn    99.9957
2017-07-02 13:14:22.777075 EDT | AverageQLoss                0.01184
2017-07-02 13:14:22.777204 EDT | AveragePolicySurr          -1.50562
2017-07-02 13:14:22.777416 EDT | AverageQ                    1.38891
2017-07-02 13:14:22.777647 EDT | AverageAbsQ                 1.39411
2017-07-02 13:14:22.777762 EDT | AverageY                    1.38904
2017-07-02 13:14:22.777973 EDT | AverageAbsY                 1.38957
2017-07-02 13:14:22.778164 EDT | AverageAbsQYDiff            0.0379745
2017-07-02 13:14:22.778293 EDT | AverageAction               0.934082
2017-07-02 13:14:22.778402 EDT | PolicyRegParamNorm         40.7579
2017-07-02 13:14:22.778533 EDT | QFunRegParamNorm           43.5522
2017-07-02 13:14:22.778650 EDT | -----------------------  ------------
2017-07-02 13:14:22.778858 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #188 | Training started
2017-07-02 13:14:32.441140 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #188 | Training finished
2017-07-02 13:14:32.441696 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #188 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 13:14:32.441951 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #188 | Collecting samples for evaluation
2017-07-02 13:14:38.134711 EDT | -----------------------  -------------
2017-07-02 13:14:38.135011 EDT | Epoch                     188
2017-07-02 13:14:38.135252 EDT | Iteration                 188
2017-07-02 13:14:38.135477 EDT | AverageReturn            1000
2017-07-02 13:14:38.135693 EDT | StdReturn                   0
2017-07-02 13:14:38.135917 EDT | MaxReturn                1000
2017-07-02 13:14:38.136043 EDT | MinReturn                1000
2017-07-02 13:14:38.136274 EDT | AverageEsReturn            29.4118
2017-07-02 13:14:38.136470 EDT | StdEsReturn                25.6195
2017-07-02 13:14:38.136603 EDT | MaxEsReturn               102
2017-07-02 13:14:38.136732 EDT | MinEsReturn                 3
2017-07-02 13:14:38.136859 EDT | AverageDiscountedReturn    99.9957
2017-07-02 13:14:38.136985 EDT | AverageQLoss                0.00986747
2017-07-02 13:14:38.137107 EDT | AveragePolicySurr          -1.50703
2017-07-02 13:14:38.137215 EDT | AverageQ                    1.3916
2017-07-02 13:14:38.137322 EDT | AverageAbsQ                 1.39542
2017-07-02 13:14:38.137428 EDT | AverageY                    1.39149
2017-07-02 13:14:38.137552 EDT | AverageAbsY                 1.39198
2017-07-02 13:14:38.137659 EDT | AverageAbsQYDiff            0.0334106
2017-07-02 13:14:38.137764 EDT | AverageAction               0.945682
2017-07-02 13:14:38.137870 EDT | PolicyRegParamNorm         40.8538
2017-07-02 13:14:38.137975 EDT | QFunRegParamNorm           43.6303
2017-07-02 13:14:38.138079 EDT | -----------------------  -------------
2017-07-02 13:14:38.138248 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #189 | Training started
2017-07-02 13:14:47.884103 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #189 | Training finished
2017-07-02 13:14:47.884729 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #189 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 13:14:47.884963 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #189 | Collecting samples for evaluation
2017-07-02 13:14:53.551088 EDT | -----------------------  -------------
2017-07-02 13:14:53.551376 EDT | Epoch                     189
2017-07-02 13:14:53.551559 EDT | Iteration                 189
2017-07-02 13:14:53.551701 EDT | AverageReturn            1000
2017-07-02 13:14:53.551815 EDT | StdReturn                   0
2017-07-02 13:14:53.551944 EDT | MaxReturn                1000
2017-07-02 13:14:53.552052 EDT | MinReturn                1000
2017-07-02 13:14:53.552153 EDT | AverageEsReturn            28.3714
2017-07-02 13:14:53.552254 EDT | StdEsReturn                32.3923
2017-07-02 13:14:53.552428 EDT | MaxEsReturn               103
2017-07-02 13:14:53.552537 EDT | MinEsReturn                 3
2017-07-02 13:14:53.552640 EDT | AverageDiscountedReturn    99.9957
2017-07-02 13:14:53.552762 EDT | AverageQLoss                0.00960195
2017-07-02 13:14:53.552865 EDT | AveragePolicySurr          -1.50914
2017-07-02 13:14:53.552965 EDT | AverageQ                    1.39447
2017-07-02 13:14:53.553101 EDT | AverageAbsQ                 1.39905
2017-07-02 13:14:53.553238 EDT | AverageY                    1.39453
2017-07-02 13:14:53.553369 EDT | AverageAbsY                 1.39514
2017-07-02 13:14:53.553576 EDT | AverageAbsQYDiff            0.0337923
2017-07-02 13:14:53.553770 EDT | AverageAction               0.897762
2017-07-02 13:14:53.553966 EDT | PolicyRegParamNorm         40.9396
2017-07-02 13:14:53.554159 EDT | QFunRegParamNorm           43.7517
2017-07-02 13:14:53.554291 EDT | -----------------------  -------------
2017-07-02 13:14:53.554511 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #190 | Training started
2017-07-02 13:15:03.092646 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #190 | Training finished
2017-07-02 13:15:03.093193 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #190 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 13:15:03.093385 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #190 | Collecting samples for evaluation
2017-07-02 13:15:08.879765 EDT | -----------------------  -------------
2017-07-02 13:15:08.880091 EDT | Epoch                     190
2017-07-02 13:15:08.880316 EDT | Iteration                 190
2017-07-02 13:15:08.880493 EDT | AverageReturn            1000
2017-07-02 13:15:08.880623 EDT | StdReturn                   0
2017-07-02 13:15:08.880846 EDT | MaxReturn                1000
2017-07-02 13:15:08.881059 EDT | MinReturn                1000
2017-07-02 13:15:08.881284 EDT | AverageEsReturn            20.8333
2017-07-02 13:15:08.881536 EDT | StdEsReturn                21.1958
2017-07-02 13:15:08.881768 EDT | MaxEsReturn               103
2017-07-02 13:15:08.881993 EDT | MinEsReturn                 3
2017-07-02 13:15:08.882202 EDT | AverageDiscountedReturn    99.9957
2017-07-02 13:15:08.882312 EDT | AverageQLoss                0.00942569
2017-07-02 13:15:08.882415 EDT | AveragePolicySurr          -1.50861
2017-07-02 13:15:08.882516 EDT | AverageQ                    1.39295
2017-07-02 13:15:08.882634 EDT | AverageAbsQ                 1.39772
2017-07-02 13:15:08.882856 EDT | AverageY                    1.39298
2017-07-02 13:15:08.883029 EDT | AverageAbsY                 1.39354
2017-07-02 13:15:08.883242 EDT | AverageAbsQYDiff            0.0344611
2017-07-02 13:15:08.883469 EDT | AverageAction               0.885186
2017-07-02 13:15:08.883680 EDT | PolicyRegParamNorm         41.0645
2017-07-02 13:15:08.883900 EDT | QFunRegParamNorm           43.7798
2017-07-02 13:15:08.884075 EDT | -----------------------  -------------
2017-07-02 13:15:08.884275 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #191 | Training started
2017-07-02 13:15:18.617543 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #191 | Training finished
2017-07-02 13:15:18.618151 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #191 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 13:15:18.618285 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #191 | Collecting samples for evaluation
2017-07-02 13:15:24.549953 EDT | -----------------------  ------------
2017-07-02 13:15:24.550288 EDT | Epoch                     191
2017-07-02 13:15:24.550516 EDT | Iteration                 191
2017-07-02 13:15:24.550738 EDT | AverageReturn            1000
2017-07-02 13:15:24.550956 EDT | StdReturn                   0
2017-07-02 13:15:24.551224 EDT | MaxReturn                1000
2017-07-02 13:15:24.551450 EDT | MinReturn                1000
2017-07-02 13:15:24.551610 EDT | AverageEsReturn            24.7692
2017-07-02 13:15:24.551842 EDT | StdEsReturn                25.647
2017-07-02 13:15:24.552065 EDT | MaxEsReturn                99
2017-07-02 13:15:24.552285 EDT | MinEsReturn                 3
2017-07-02 13:15:24.552502 EDT | AverageDiscountedReturn    99.9957
2017-07-02 13:15:24.553216 EDT | AverageQLoss                0.011454
2017-07-02 13:15:24.553349 EDT | AveragePolicySurr          -1.50783
2017-07-02 13:15:24.553548 EDT | AverageQ                    1.39132
2017-07-02 13:15:24.553783 EDT | AverageAbsQ                 1.39679
2017-07-02 13:15:24.554026 EDT | AverageY                    1.39135
2017-07-02 13:15:24.554247 EDT | AverageAbsY                 1.39191
2017-07-02 13:15:24.554452 EDT | AverageAbsQYDiff            0.0373569
2017-07-02 13:15:24.554663 EDT | AverageAction               0.904818
2017-07-02 13:15:24.554882 EDT | PolicyRegParamNorm         41.1587
2017-07-02 13:15:24.555101 EDT | QFunRegParamNorm           43.848
2017-07-02 13:15:24.555334 EDT | -----------------------  ------------
2017-07-02 13:15:24.555673 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #192 | Training started
2017-07-02 13:15:34.309342 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #192 | Training finished
2017-07-02 13:15:34.309932 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #192 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 13:15:34.310098 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #192 | Collecting samples for evaluation
2017-07-02 13:15:39.967695 EDT | -----------------------  ------------
2017-07-02 13:15:39.967888 EDT | Epoch                     192
2017-07-02 13:15:39.968087 EDT | Iteration                 192
2017-07-02 13:15:39.968290 EDT | AverageReturn            1000
2017-07-02 13:15:39.968528 EDT | StdReturn                   0
2017-07-02 13:15:39.968755 EDT | MaxReturn                1000
2017-07-02 13:15:39.968875 EDT | MinReturn                1000
2017-07-02 13:15:39.969104 EDT | AverageEsReturn            25
2017-07-02 13:15:39.969335 EDT | StdEsReturn                24.293
2017-07-02 13:15:39.969541 EDT | MaxEsReturn               106
2017-07-02 13:15:39.969775 EDT | MinEsReturn                 3
2017-07-02 13:15:39.969986 EDT | AverageDiscountedReturn    99.9957
2017-07-02 13:15:39.970217 EDT | AverageQLoss                0.0116184
2017-07-02 13:15:39.970448 EDT | AveragePolicySurr          -1.50514
2017-07-02 13:15:39.970639 EDT | AverageQ                    1.39823
2017-07-02 13:15:39.970874 EDT | AverageAbsQ                 1.40276
2017-07-02 13:15:39.971059 EDT | AverageY                    1.39832
2017-07-02 13:15:39.971290 EDT | AverageAbsY                 1.39857
2017-07-02 13:15:39.971518 EDT | AverageAbsQYDiff            0.0375894
2017-07-02 13:15:39.971689 EDT | AverageAction               0.880393
2017-07-02 13:15:39.971923 EDT | PolicyRegParamNorm         41.2461
2017-07-02 13:15:39.972144 EDT | QFunRegParamNorm           43.9223
2017-07-02 13:15:39.972377 EDT | -----------------------  ------------
2017-07-02 13:15:39.972673 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #193 | Training started
2017-07-02 13:15:49.718632 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #193 | Training finished
2017-07-02 13:15:49.719230 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #193 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 13:15:49.719504 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #193 | Collecting samples for evaluation
2017-07-02 13:15:55.390459 EDT | -----------------------  ------------
2017-07-02 13:15:55.390781 EDT | Epoch                     193
2017-07-02 13:15:55.391015 EDT | Iteration                 193
2017-07-02 13:15:55.391241 EDT | AverageReturn            1000
2017-07-02 13:15:55.391464 EDT | StdReturn                   0
2017-07-02 13:15:55.391686 EDT | MaxReturn                1000
2017-07-02 13:15:55.391916 EDT | MinReturn                1000
2017-07-02 13:15:55.392139 EDT | AverageEsReturn            28.1351
2017-07-02 13:15:55.392356 EDT | StdEsReturn                17.9461
2017-07-02 13:15:55.392586 EDT | MaxEsReturn                72
2017-07-02 13:15:55.392812 EDT | MinEsReturn                 3
2017-07-02 13:15:55.392942 EDT | AverageDiscountedReturn    99.9957
2017-07-02 13:15:55.393119 EDT | AverageQLoss                0.0115342
2017-07-02 13:15:55.393343 EDT | AveragePolicySurr          -1.50011
2017-07-02 13:15:55.393667 EDT | AverageQ                    1.3838
2017-07-02 13:15:55.393891 EDT | AverageAbsQ                 1.38788
2017-07-02 13:15:55.394112 EDT | AverageY                    1.38359
2017-07-02 13:15:55.394292 EDT | AverageAbsY                 1.38384
2017-07-02 13:15:55.394512 EDT | AverageAbsQYDiff            0.0371508
2017-07-02 13:15:55.394707 EDT | AverageAction               0.889998
2017-07-02 13:15:55.395035 EDT | PolicyRegParamNorm         41.3273
2017-07-02 13:15:55.395259 EDT | QFunRegParamNorm           44.0427
2017-07-02 13:15:55.395477 EDT | -----------------------  ------------
2017-07-02 13:15:55.395674 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #194 | Training started
2017-07-02 13:16:04.986105 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #194 | Training finished
2017-07-02 13:16:04.986648 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #194 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 13:16:04.986970 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #194 | Collecting samples for evaluation
2017-07-02 13:16:10.685156 EDT | -----------------------  ------------
2017-07-02 13:16:10.685476 EDT | Epoch                     194
2017-07-02 13:16:10.685695 EDT | Iteration                 194
2017-07-02 13:16:10.685851 EDT | AverageReturn            1000
2017-07-02 13:16:10.686077 EDT | StdReturn                   0
2017-07-02 13:16:10.686202 EDT | MaxReturn                1000
2017-07-02 13:16:10.686309 EDT | MinReturn                1000
2017-07-02 13:16:10.686412 EDT | AverageEsReturn            22.9535
2017-07-02 13:16:10.686514 EDT | StdEsReturn                19.6101
2017-07-02 13:16:10.686615 EDT | MaxEsReturn                85
2017-07-02 13:16:10.686715 EDT | MinEsReturn                 3
2017-07-02 13:16:10.686893 EDT | AverageDiscountedReturn    99.9957
2017-07-02 13:16:10.687096 EDT | AverageQLoss                0.0102422
2017-07-02 13:16:10.687315 EDT | AveragePolicySurr          -1.50469
2017-07-02 13:16:10.687518 EDT | AverageQ                    1.39475
2017-07-02 13:16:10.687698 EDT | AverageAbsQ                 1.39893
2017-07-02 13:16:10.687930 EDT | AverageY                    1.39486
2017-07-02 13:16:10.688158 EDT | AverageAbsY                 1.39502
2017-07-02 13:16:10.688379 EDT | AverageAbsQYDiff            0.0347075
2017-07-02 13:16:10.688538 EDT | AverageAction               0.899125
2017-07-02 13:16:10.688754 EDT | PolicyRegParamNorm         41.3318
2017-07-02 13:16:10.688958 EDT | QFunRegParamNorm           44.1412
2017-07-02 13:16:10.689188 EDT | -----------------------  ------------
2017-07-02 13:16:10.689553 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #195 | Training started
2017-07-02 13:16:20.331871 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #195 | Training finished
2017-07-02 13:16:20.332369 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #195 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 13:16:20.332502 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #195 | Collecting samples for evaluation
2017-07-02 13:16:25.995920 EDT | -----------------------  ------------
2017-07-02 13:16:25.996250 EDT | Epoch                     195
2017-07-02 13:16:25.996446 EDT | Iteration                 195
2017-07-02 13:16:25.996682 EDT | AverageReturn            1000
2017-07-02 13:16:25.996860 EDT | StdReturn                   0
2017-07-02 13:16:25.997100 EDT | MaxReturn                1000
2017-07-02 13:16:25.997311 EDT | MinReturn                1000
2017-07-02 13:16:25.997457 EDT | AverageEsReturn            29.7059
2017-07-02 13:16:25.997719 EDT | StdEsReturn                27.3663
2017-07-02 13:16:25.997961 EDT | MaxEsReturn                98
2017-07-02 13:16:25.998239 EDT | MinEsReturn                 3
2017-07-02 13:16:25.998473 EDT | AverageDiscountedReturn    99.9957
2017-07-02 13:16:25.998665 EDT | AverageQLoss                0.0103544
2017-07-02 13:16:25.998892 EDT | AveragePolicySurr          -1.50233
2017-07-02 13:16:25.999108 EDT | AverageQ                    1.39233
2017-07-02 13:16:25.999327 EDT | AverageAbsQ                 1.39689
2017-07-02 13:16:25.999558 EDT | AverageY                    1.39233
2017-07-02 13:16:25.999746 EDT | AverageAbsY                 1.39255
2017-07-02 13:16:25.999986 EDT | AverageAbsQYDiff            0.0350163
2017-07-02 13:16:26.000190 EDT | AverageAction               0.916653
2017-07-02 13:16:26.000372 EDT | PolicyRegParamNorm         41.4378
2017-07-02 13:16:26.000607 EDT | QFunRegParamNorm           44.2261
2017-07-02 13:16:26.000798 EDT | -----------------------  ------------
2017-07-02 13:16:26.000970 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #196 | Training started
2017-07-02 13:16:35.589271 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #196 | Training finished
2017-07-02 13:16:35.589893 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #196 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 13:16:35.590035 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #196 | Collecting samples for evaluation
2017-07-02 13:16:41.218961 EDT | -----------------------  ------------
2017-07-02 13:16:41.219159 EDT | Epoch                     196
2017-07-02 13:16:41.219271 EDT | Iteration                 196
2017-07-02 13:16:41.219387 EDT | AverageReturn            1000
2017-07-02 13:16:41.219522 EDT | StdReturn                   0
2017-07-02 13:16:41.219626 EDT | MaxReturn                1000
2017-07-02 13:16:41.219726 EDT | MinReturn                1000
2017-07-02 13:16:41.219826 EDT | AverageEsReturn            41.2381
2017-07-02 13:16:41.219963 EDT | StdEsReturn                38.1612
2017-07-02 13:16:41.220068 EDT | MaxEsReturn               143
2017-07-02 13:16:41.220169 EDT | MinEsReturn                 6
2017-07-02 13:16:41.220276 EDT | AverageDiscountedReturn    99.9957
2017-07-02 13:16:41.220416 EDT | AverageQLoss                0.0101447
2017-07-02 13:16:41.220546 EDT | AveragePolicySurr          -1.50263
2017-07-02 13:16:41.220674 EDT | AverageQ                    1.39208
2017-07-02 13:16:41.220778 EDT | AverageAbsQ                 1.39559
2017-07-02 13:16:41.220911 EDT | AverageY                    1.39208
2017-07-02 13:16:41.221098 EDT | AverageAbsY                 1.39231
2017-07-02 13:16:41.221294 EDT | AverageAbsQYDiff            0.0336971
2017-07-02 13:16:41.221446 EDT | AverageAction               0.932894
2017-07-02 13:16:41.221668 EDT | PolicyRegParamNorm         41.533
2017-07-02 13:16:41.221887 EDT | QFunRegParamNorm           44.352
2017-07-02 13:16:41.222068 EDT | -----------------------  ------------
2017-07-02 13:16:41.222375 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #197 | Training started
2017-07-02 13:16:50.839431 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #197 | Training finished
2017-07-02 13:16:50.840372 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #197 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 13:16:50.840613 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #197 | Collecting samples for evaluation
2017-07-02 13:16:56.438658 EDT | -----------------------  -------------
2017-07-02 13:16:56.438887 EDT | Epoch                     197
2017-07-02 13:16:56.439084 EDT | Iteration                 197
2017-07-02 13:16:56.439274 EDT | AverageReturn            1000
2017-07-02 13:16:56.439442 EDT | StdReturn                   0
2017-07-02 13:16:56.439584 EDT | MaxReturn                1000
2017-07-02 13:16:56.439686 EDT | MinReturn                1000
2017-07-02 13:16:56.439800 EDT | AverageEsReturn            31.3333
2017-07-02 13:16:56.439920 EDT | StdEsReturn                29.0565
2017-07-02 13:16:56.440022 EDT | MaxEsReturn               141
2017-07-02 13:16:56.440124 EDT | MinEsReturn                 3
2017-07-02 13:16:56.440232 EDT | AverageDiscountedReturn    99.9957
2017-07-02 13:16:56.440370 EDT | AverageQLoss                0.00890036
2017-07-02 13:16:56.440518 EDT | AveragePolicySurr          -1.50025
2017-07-02 13:16:56.440641 EDT | AverageQ                    1.3908
2017-07-02 13:16:56.440745 EDT | AverageAbsQ                 1.39481
2017-07-02 13:16:56.440859 EDT | AverageY                    1.39081
2017-07-02 13:16:56.441015 EDT | AverageAbsY                 1.39105
2017-07-02 13:16:56.441137 EDT | AverageAbsQYDiff            0.0332491
2017-07-02 13:16:56.441331 EDT | AverageAction               0.884681
2017-07-02 13:16:56.441470 EDT | PolicyRegParamNorm         41.5861
2017-07-02 13:16:56.443333 EDT | QFunRegParamNorm           44.4296
2017-07-02 13:16:56.443530 EDT | -----------------------  -------------
2017-07-02 13:16:56.444084 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #198 | Training started
2017-07-02 13:17:06.094798 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #198 | Training finished
2017-07-02 13:17:06.095517 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #198 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 13:17:06.095758 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #198 | Collecting samples for evaluation
2017-07-02 13:17:11.836766 EDT | -----------------------  ------------
2017-07-02 13:17:11.837026 EDT | Epoch                     198
2017-07-02 13:17:11.837163 EDT | Iteration                 198
2017-07-02 13:17:11.837360 EDT | AverageReturn            1000
2017-07-02 13:17:11.837549 EDT | StdReturn                   0
2017-07-02 13:17:11.837718 EDT | MaxReturn                1000
2017-07-02 13:17:11.837866 EDT | MinReturn                1000
2017-07-02 13:17:11.837980 EDT | AverageEsReturn            28.8
2017-07-02 13:17:11.838119 EDT | StdEsReturn                24.2661
2017-07-02 13:17:11.838278 EDT | MaxEsReturn               102
2017-07-02 13:17:11.838391 EDT | MinEsReturn                 4
2017-07-02 13:17:11.838541 EDT | AverageDiscountedReturn    99.9957
2017-07-02 13:17:11.838664 EDT | AverageQLoss                0.0115029
2017-07-02 13:17:11.838766 EDT | AveragePolicySurr          -1.50138
2017-07-02 13:17:11.838890 EDT | AverageQ                    1.39257
2017-07-02 13:17:11.839041 EDT | AverageAbsQ                 1.39754
2017-07-02 13:17:11.839340 EDT | AverageY                    1.39264
2017-07-02 13:17:11.839490 EDT | AverageAbsY                 1.39285
2017-07-02 13:17:11.839624 EDT | AverageAbsQYDiff            0.0369215
2017-07-02 13:17:11.839740 EDT | AverageAction               0.93424
2017-07-02 13:17:11.839848 EDT | PolicyRegParamNorm         41.7004
2017-07-02 13:17:11.840008 EDT | QFunRegParamNorm           44.5121
2017-07-02 13:17:11.840115 EDT | -----------------------  ------------
2017-07-02 13:17:11.840341 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #199 | Training started
2017-07-02 13:17:21.409575 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #199 | Training finished
2017-07-02 13:17:21.410074 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #199 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 13:17:21.410207 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #199 | Collecting samples for evaluation
2017-07-02 13:17:27.089687 EDT | -----------------------  ------------
2017-07-02 13:17:27.090099 EDT | Epoch                     199
2017-07-02 13:17:27.090717 EDT | Iteration                 199
2017-07-02 13:17:27.090849 EDT | AverageReturn            1000
2017-07-02 13:17:27.090998 EDT | StdReturn                   0
2017-07-02 13:17:27.091128 EDT | MaxReturn                1000
2017-07-02 13:17:27.091260 EDT | MinReturn                1000
2017-07-02 13:17:27.091369 EDT | AverageEsReturn            27.3333
2017-07-02 13:17:27.091498 EDT | StdEsReturn                19.6271
2017-07-02 13:17:27.091607 EDT | MaxEsReturn                73
2017-07-02 13:17:27.091718 EDT | MinEsReturn                 3
2017-07-02 13:17:27.091883 EDT | AverageDiscountedReturn    99.9957
2017-07-02 13:17:27.092009 EDT | AverageQLoss                0.0106999
2017-07-02 13:17:27.092116 EDT | AveragePolicySurr          -1.49948
2017-07-02 13:17:27.092221 EDT | AverageQ                    1.38983
2017-07-02 13:17:27.092339 EDT | AverageAbsQ                 1.39414
2017-07-02 13:17:27.092467 EDT | AverageY                    1.38981
2017-07-02 13:17:27.092575 EDT | AverageAbsY                 1.39013
2017-07-02 13:17:27.092682 EDT | AverageAbsQYDiff            0.03651
2017-07-02 13:17:27.092805 EDT | AverageAction               0.94828
2017-07-02 13:17:27.093003 EDT | PolicyRegParamNorm         41.7383
2017-07-02 13:17:27.093176 EDT | QFunRegParamNorm           44.6255
2017-07-02 13:17:27.093373 EDT | -----------------------  ------------
2017-07-02 13:17:27.093622 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #200 | Training started
2017-07-02 13:17:36.599007 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #200 | Training finished
2017-07-02 13:17:36.599603 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #200 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 13:17:36.599840 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #200 | Collecting samples for evaluation
2017-07-02 13:17:42.290411 EDT | -----------------------  -------------
2017-07-02 13:17:42.290633 EDT | Epoch                     200
2017-07-02 13:17:42.290776 EDT | Iteration                 200
2017-07-02 13:17:42.290951 EDT | AverageReturn            1000
2017-07-02 13:17:42.291149 EDT | StdReturn                   0
2017-07-02 13:17:42.291293 EDT | MaxReturn                1000
2017-07-02 13:17:42.291424 EDT | MinReturn                1000
2017-07-02 13:17:42.291584 EDT | AverageEsReturn            28.6471
2017-07-02 13:17:42.291697 EDT | StdEsReturn                18.232
2017-07-02 13:17:42.291841 EDT | MaxEsReturn                86
2017-07-02 13:17:42.291995 EDT | MinEsReturn                 4
2017-07-02 13:17:42.292216 EDT | AverageDiscountedReturn    99.9957
2017-07-02 13:17:42.292449 EDT | AverageQLoss                0.00880038
2017-07-02 13:17:42.292643 EDT | AveragePolicySurr          -1.49742
2017-07-02 13:17:42.292791 EDT | AverageQ                    1.3887
2017-07-02 13:17:42.293023 EDT | AverageAbsQ                 1.39275
2017-07-02 13:17:42.293247 EDT | AverageY                    1.38879
2017-07-02 13:17:42.293460 EDT | AverageAbsY                 1.38921
2017-07-02 13:17:42.293882 EDT | AverageAbsQYDiff            0.0318815
2017-07-02 13:17:42.294072 EDT | AverageAction               0.918764
2017-07-02 13:17:42.294181 EDT | PolicyRegParamNorm         41.8489
2017-07-02 13:17:42.294318 EDT | QFunRegParamNorm           44.6821
2017-07-02 13:17:42.294445 EDT | -----------------------  -------------
2017-07-02 13:17:42.294640 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #201 | Training started
2017-07-02 13:17:51.772637 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #201 | Training finished
2017-07-02 13:17:51.773139 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #201 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 13:17:51.773310 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #201 | Collecting samples for evaluation
2017-07-02 13:17:57.752677 EDT | -----------------------  ------------
2017-07-02 13:17:57.752861 EDT | Epoch                     201
2017-07-02 13:17:57.752972 EDT | Iteration                 201
2017-07-02 13:17:57.753077 EDT | AverageReturn             862.667
2017-07-02 13:17:57.753178 EDT | StdReturn                 217.892
2017-07-02 13:17:57.753318 EDT | MaxReturn                1000
2017-07-02 13:17:57.753477 EDT | MinReturn                 307
2017-07-02 13:17:57.753723 EDT | AverageEsReturn            43.25
2017-07-02 13:17:57.753884 EDT | StdEsReturn                43.1338
2017-07-02 13:17:57.753990 EDT | MaxEsReturn               147
2017-07-02 13:17:57.754209 EDT | MinEsReturn                 3
2017-07-02 13:17:57.754490 EDT | AverageDiscountedReturn    99.585
2017-07-02 13:17:57.754785 EDT | AverageQLoss                0.0113212
2017-07-02 13:17:57.755022 EDT | AveragePolicySurr          -1.4954
2017-07-02 13:17:57.755255 EDT | AverageQ                    1.3899
2017-07-02 13:17:57.755424 EDT | AverageAbsQ                 1.39429
2017-07-02 13:17:57.755542 EDT | AverageY                    1.38991
2017-07-02 13:17:57.755645 EDT | AverageAbsY                 1.39032
2017-07-02 13:17:57.755747 EDT | AverageAbsQYDiff            0.0377398
2017-07-02 13:17:57.755898 EDT | AverageAction               0.828831
2017-07-02 13:17:57.756064 EDT | PolicyRegParamNorm         41.9733
2017-07-02 13:17:57.756229 EDT | QFunRegParamNorm           44.7534
2017-07-02 13:17:57.756370 EDT | -----------------------  ------------
2017-07-02 13:17:57.756554 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #202 | Training started
2017-07-02 13:18:07.479915 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #202 | Training finished
2017-07-02 13:18:07.480580 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #202 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 13:18:07.480930 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #202 | Collecting samples for evaluation
2017-07-02 13:18:13.359249 EDT | -----------------------  ------------
2017-07-02 13:18:13.359455 EDT | Epoch                     202
2017-07-02 13:18:13.359571 EDT | Iteration                 202
2017-07-02 13:18:13.359682 EDT | AverageReturn            1000
2017-07-02 13:18:13.359787 EDT | StdReturn                   0
2017-07-02 13:18:13.359889 EDT | MaxReturn                1000
2017-07-02 13:18:13.360071 EDT | MinReturn                1000
2017-07-02 13:18:13.360300 EDT | AverageEsReturn            29.5152
2017-07-02 13:18:13.360493 EDT | StdEsReturn                20.0365
2017-07-02 13:18:13.360603 EDT | MaxEsReturn                90
2017-07-02 13:18:13.360709 EDT | MinEsReturn                 5
2017-07-02 13:18:13.360893 EDT | AverageDiscountedReturn    99.9957
2017-07-02 13:18:13.361120 EDT | AverageQLoss                0.0108774
2017-07-02 13:18:13.361309 EDT | AveragePolicySurr          -1.49431
2017-07-02 13:18:13.361416 EDT | AverageQ                    1.38629
2017-07-02 13:18:13.361843 EDT | AverageAbsQ                 1.39149
2017-07-02 13:18:13.362055 EDT | AverageY                    1.38632
2017-07-02 13:18:13.362284 EDT | AverageAbsY                 1.38693
2017-07-02 13:18:13.362493 EDT | AverageAbsQYDiff            0.035911
2017-07-02 13:18:13.362726 EDT | AverageAction               0.929052
2017-07-02 13:18:13.362953 EDT | PolicyRegParamNorm         42.1036
2017-07-02 13:18:13.363181 EDT | QFunRegParamNorm           44.8886
2017-07-02 13:18:13.363399 EDT | -----------------------  ------------
2017-07-02 13:18:13.363690 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #203 | Training started
2017-07-02 13:18:23.089157 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #203 | Training finished
2017-07-02 13:18:23.089675 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #203 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 13:18:23.090010 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #203 | Collecting samples for evaluation
2017-07-02 13:18:28.746147 EDT | -----------------------  -------------
2017-07-02 13:18:28.746465 EDT | Epoch                     203
2017-07-02 13:18:28.746658 EDT | Iteration                 203
2017-07-02 13:18:28.746877 EDT | AverageReturn            1000
2017-07-02 13:18:28.747102 EDT | StdReturn                   0
2017-07-02 13:18:28.747260 EDT | MaxReturn                1000
2017-07-02 13:18:28.747442 EDT | MinReturn                1000
2017-07-02 13:18:28.747633 EDT | AverageEsReturn            26.5263
2017-07-02 13:18:28.747852 EDT | StdEsReturn                15.7509
2017-07-02 13:18:28.748007 EDT | MaxEsReturn                67
2017-07-02 13:18:28.748228 EDT | MinEsReturn                 4
2017-07-02 13:18:28.748434 EDT | AverageDiscountedReturn    99.9957
2017-07-02 13:18:28.748541 EDT | AverageQLoss                0.00895737
2017-07-02 13:18:28.748677 EDT | AveragePolicySurr          -1.48588
2017-07-02 13:18:28.748884 EDT | AverageQ                    1.37996
2017-07-02 13:18:28.749058 EDT | AverageAbsQ                 1.3839
2017-07-02 13:18:28.749206 EDT | AverageY                    1.37986
2017-07-02 13:18:28.749391 EDT | AverageAbsY                 1.3802
2017-07-02 13:18:28.749625 EDT | AverageAbsQYDiff            0.0331994
2017-07-02 13:18:28.749801 EDT | AverageAction               0.836963
2017-07-02 13:18:28.749925 EDT | PolicyRegParamNorm         42.167
2017-07-02 13:18:28.750048 EDT | QFunRegParamNorm           45.0048
2017-07-02 13:18:28.750183 EDT | -----------------------  -------------
2017-07-02 13:18:28.750429 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #204 | Training started
2017-07-02 13:18:38.492546 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #204 | Training finished
2017-07-02 13:18:38.493091 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #204 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 13:18:38.493272 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #204 | Collecting samples for evaluation
2017-07-02 13:18:44.057723 EDT | -----------------------  ------------
2017-07-02 13:18:44.057985 EDT | Epoch                     204
2017-07-02 13:18:44.058186 EDT | Iteration                 204
2017-07-02 13:18:44.058389 EDT | AverageReturn            1000
2017-07-02 13:18:44.058508 EDT | StdReturn                   0
2017-07-02 13:18:44.058766 EDT | MaxReturn                1000
2017-07-02 13:18:44.058882 EDT | MinReturn                1000
2017-07-02 13:18:44.058986 EDT | AverageEsReturn            30.8182
2017-07-02 13:18:44.059130 EDT | StdEsReturn                25.7652
2017-07-02 13:18:44.059236 EDT | MaxEsReturn               114
2017-07-02 13:18:44.059365 EDT | MinEsReturn                 3
2017-07-02 13:18:44.059467 EDT | AverageDiscountedReturn    99.9957
2017-07-02 13:18:44.059567 EDT | AverageQLoss                0.0103791
2017-07-02 13:18:44.059691 EDT | AveragePolicySurr          -1.48599
2017-07-02 13:18:44.059793 EDT | AverageQ                    1.37696
2017-07-02 13:18:44.059892 EDT | AverageAbsQ                 1.38135
2017-07-02 13:18:44.059991 EDT | AverageY                    1.37707
2017-07-02 13:18:44.060089 EDT | AverageAbsY                 1.37759
2017-07-02 13:18:44.060214 EDT | AverageAbsQYDiff            0.0357949
2017-07-02 13:18:44.060344 EDT | AverageAction               0.721987
2017-07-02 13:18:44.060446 EDT | PolicyRegParamNorm         42.1669
2017-07-02 13:18:44.060564 EDT | QFunRegParamNorm           45.0372
2017-07-02 13:18:44.060705 EDT | -----------------------  ------------
2017-07-02 13:18:44.060894 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #205 | Training started
2017-07-02 13:18:53.813196 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #205 | Training finished
2017-07-02 13:18:53.813692 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #205 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 13:18:53.813839 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #205 | Collecting samples for evaluation
2017-07-02 13:18:59.874930 EDT | -----------------------  ------------
2017-07-02 13:18:59.875423 EDT | Epoch                     205
2017-07-02 13:18:59.875576 EDT | Iteration                 205
2017-07-02 13:18:59.875730 EDT | AverageReturn             718.933
2017-07-02 13:18:59.875876 EDT | StdReturn                 330.431
2017-07-02 13:18:59.875984 EDT | MaxReturn                1000
2017-07-02 13:18:59.876155 EDT | MinReturn                 110
2017-07-02 13:18:59.876282 EDT | AverageEsReturn            35.9643
2017-07-02 13:18:59.876385 EDT | StdEsReturn                40.7461
2017-07-02 13:18:59.876502 EDT | MaxEsReturn               176
2017-07-02 13:18:59.876644 EDT | MinEsReturn                 6
2017-07-02 13:18:59.876746 EDT | AverageDiscountedReturn    95.8303
2017-07-02 13:18:59.876859 EDT | AverageQLoss                0.010973
2017-07-02 13:18:59.877024 EDT | AveragePolicySurr          -1.4903
2017-07-02 13:18:59.877212 EDT | AverageQ                    1.37963
2017-07-02 13:18:59.877392 EDT | AverageAbsQ                 1.38472
2017-07-02 13:18:59.877512 EDT | AverageY                    1.37956
2017-07-02 13:18:59.877679 EDT | AverageAbsY                 1.38004
2017-07-02 13:18:59.877888 EDT | AverageAbsQYDiff            0.0376601
2017-07-02 13:18:59.878073 EDT | AverageAction               0.920494
2017-07-02 13:18:59.878208 EDT | PolicyRegParamNorm         42.245
2017-07-02 13:18:59.878316 EDT | QFunRegParamNorm           45.1061
2017-07-02 13:18:59.878457 EDT | -----------------------  ------------
2017-07-02 13:18:59.878645 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #206 | Training started
2017-07-02 13:19:09.532879 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #206 | Training finished
2017-07-02 13:19:09.533145 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #206 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 13:19:09.533292 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #206 | Collecting samples for evaluation
2017-07-02 13:19:15.200880 EDT | -----------------------  -------------
2017-07-02 13:19:15.201661 EDT | Epoch                     206
2017-07-02 13:19:15.202424 EDT | Iteration                 206
2017-07-02 13:19:15.202681 EDT | AverageReturn            1000
2017-07-02 13:19:15.202856 EDT | StdReturn                   0
2017-07-02 13:19:15.203088 EDT | MaxReturn                1000
2017-07-02 13:19:15.203299 EDT | MinReturn                1000
2017-07-02 13:19:15.203537 EDT | AverageEsReturn            16.7797
2017-07-02 13:19:15.203732 EDT | StdEsReturn                17.8905
2017-07-02 13:19:15.203952 EDT | MaxEsReturn                92
2017-07-02 13:19:15.204175 EDT | MinEsReturn                 3
2017-07-02 13:19:15.204402 EDT | AverageDiscountedReturn    99.9957
2017-07-02 13:19:15.205710 EDT | AverageQLoss                0.00943405
2017-07-02 13:19:15.206298 EDT | AveragePolicySurr          -1.49368
2017-07-02 13:19:15.207561 EDT | AverageQ                    1.3846
2017-07-02 13:19:15.207827 EDT | AverageAbsQ                 1.38919
2017-07-02 13:19:15.207990 EDT | AverageY                    1.38451
2017-07-02 13:19:15.208104 EDT | AverageAbsY                 1.38547
2017-07-02 13:19:15.208224 EDT | AverageAbsQYDiff            0.0351927
2017-07-02 13:19:15.208459 EDT | AverageAction               0.159631
2017-07-02 13:19:15.208670 EDT | PolicyRegParamNorm         42.3292
2017-07-02 13:19:15.208877 EDT | QFunRegParamNorm           45.1455
2017-07-02 13:19:15.209088 EDT | -----------------------  -------------
2017-07-02 13:19:15.209426 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #207 | Training started
2017-07-02 13:19:24.786936 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #207 | Training finished
2017-07-02 13:19:24.787128 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #207 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 13:19:24.787326 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #207 | Collecting samples for evaluation
2017-07-02 13:19:30.510883 EDT | -----------------------  ------------
2017-07-02 13:19:30.511096 EDT | Epoch                     207
2017-07-02 13:19:30.511278 EDT | Iteration                 207
2017-07-02 13:19:30.511470 EDT | AverageReturn            1000
2017-07-02 13:19:30.511639 EDT | StdReturn                   0
2017-07-02 13:19:30.511743 EDT | MaxReturn                1000
2017-07-02 13:19:30.511842 EDT | MinReturn                1000
2017-07-02 13:19:30.511941 EDT | AverageEsReturn            11.4118
2017-07-02 13:19:30.512076 EDT | StdEsReturn                 8.86937
2017-07-02 13:19:30.512183 EDT | MaxEsReturn                51
2017-07-02 13:19:30.512283 EDT | MinEsReturn                 3
2017-07-02 13:19:30.512381 EDT | AverageDiscountedReturn    99.9957
2017-07-02 13:19:30.512508 EDT | AverageQLoss                0.0119325
2017-07-02 13:19:30.512654 EDT | AveragePolicySurr          -1.50402
2017-07-02 13:19:30.512754 EDT | AverageQ                    1.39272
2017-07-02 13:19:30.512852 EDT | AverageAbsQ                 1.39809
2017-07-02 13:19:30.512949 EDT | AverageY                    1.39269
2017-07-02 13:19:30.513062 EDT | AverageAbsY                 1.39357
2017-07-02 13:19:30.513176 EDT | AverageAbsQYDiff            0.040349
2017-07-02 13:19:30.513275 EDT | AverageAction               0.0936604
2017-07-02 13:19:30.513372 EDT | PolicyRegParamNorm         42.4423
2017-07-02 13:19:30.513469 EDT | QFunRegParamNorm           45.1968
2017-07-02 13:19:30.513849 EDT | -----------------------  ------------
2017-07-02 13:19:30.514023 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #208 | Training started
2017-07-02 13:19:40.262999 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #208 | Training finished
2017-07-02 13:19:40.263618 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #208 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 13:19:40.263783 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #208 | Collecting samples for evaluation
2017-07-02 13:19:45.998703 EDT | -----------------------  ------------
2017-07-02 13:19:45.998955 EDT | Epoch                     208
2017-07-02 13:19:45.999077 EDT | Iteration                 208
2017-07-02 13:19:45.999184 EDT | AverageReturn            1000
2017-07-02 13:19:45.999370 EDT | StdReturn                   0
2017-07-02 13:19:45.999543 EDT | MaxReturn                1000
2017-07-02 13:19:45.999742 EDT | MinReturn                1000
2017-07-02 13:19:45.999931 EDT | AverageEsReturn            17.8966
2017-07-02 13:19:46.000043 EDT | StdEsReturn                16.8663
2017-07-02 13:19:46.000147 EDT | MaxEsReturn                76
2017-07-02 13:19:46.000247 EDT | MinEsReturn                 3
2017-07-02 13:19:46.000378 EDT | AverageDiscountedReturn    99.9957
2017-07-02 13:19:46.000480 EDT | AverageQLoss                0.0127903
2017-07-02 13:19:46.000581 EDT | AveragePolicySurr          -1.52013
2017-07-02 13:19:46.000724 EDT | AverageQ                    1.39959
2017-07-02 13:19:46.000912 EDT | AverageAbsQ                 1.40497
2017-07-02 13:19:46.001068 EDT | AverageY                    1.39986
2017-07-02 13:19:46.001171 EDT | AverageAbsY                 1.40087
2017-07-02 13:19:46.001308 EDT | AverageAbsQYDiff            0.0415885
2017-07-02 13:19:46.001410 EDT | AverageAction               0.116711
2017-07-02 13:19:46.001520 EDT | PolicyRegParamNorm         42.477
2017-07-02 13:19:46.001628 EDT | QFunRegParamNorm           45.2786
2017-07-02 13:19:46.001756 EDT | -----------------------  ------------
2017-07-02 13:19:46.001936 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #209 | Training started
2017-07-02 13:19:55.681882 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #209 | Training finished
2017-07-02 13:19:55.682581 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #209 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 13:19:55.682937 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #209 | Collecting samples for evaluation
2017-07-02 13:20:01.406841 EDT | -----------------------  ------------
2017-07-02 13:20:01.407050 EDT | Epoch                     209
2017-07-02 13:20:01.407188 EDT | Iteration                 209
2017-07-02 13:20:01.407299 EDT | AverageReturn            1000
2017-07-02 13:20:01.407403 EDT | StdReturn                   0
2017-07-02 13:20:01.407515 EDT | MaxReturn                1000
2017-07-02 13:20:01.407685 EDT | MinReturn                1000
2017-07-02 13:20:01.407795 EDT | AverageEsReturn            14.3731
2017-07-02 13:20:01.407933 EDT | StdEsReturn                15.486
2017-07-02 13:20:01.408038 EDT | MaxEsReturn                78
2017-07-02 13:20:01.408170 EDT | MinEsReturn                 3
2017-07-02 13:20:01.408362 EDT | AverageDiscountedReturn    99.9957
2017-07-02 13:20:01.408536 EDT | AverageQLoss                0.011411
2017-07-02 13:20:01.408722 EDT | AveragePolicySurr          -1.5376
2017-07-02 13:20:01.408937 EDT | AverageQ                    1.41064
2017-07-02 13:20:01.409150 EDT | AverageAbsQ                 1.41539
2017-07-02 13:20:01.409340 EDT | AverageY                    1.4105
2017-07-02 13:20:01.409744 EDT | AverageAbsY                 1.41159
2017-07-02 13:20:01.409978 EDT | AverageAbsQYDiff            0.0424092
2017-07-02 13:20:01.410205 EDT | AverageAction               0.110797
2017-07-02 13:20:01.410426 EDT | PolicyRegParamNorm         42.5271
2017-07-02 13:20:01.410643 EDT | QFunRegParamNorm           45.3703
2017-07-02 13:20:01.410861 EDT | -----------------------  ------------
2017-07-02 13:20:01.411173 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #210 | Training started
2017-07-02 13:20:11.215014 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #210 | Training finished
2017-07-02 13:20:11.215891 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #210 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 13:20:11.216159 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #210 | Collecting samples for evaluation
2017-07-02 13:20:16.895773 EDT | -----------------------  ------------
2017-07-02 13:20:16.896079 EDT | Epoch                     210
2017-07-02 13:20:16.896239 EDT | Iteration                 210
2017-07-02 13:20:16.896472 EDT | AverageReturn            1000
2017-07-02 13:20:16.896661 EDT | StdReturn                   0
2017-07-02 13:20:16.896854 EDT | MaxReturn                1000
2017-07-02 13:20:16.897083 EDT | MinReturn                1000
2017-07-02 13:20:16.897267 EDT | AverageEsReturn            14.7714
2017-07-02 13:20:16.897510 EDT | StdEsReturn                14.9199
2017-07-02 13:20:16.897710 EDT | MaxEsReturn                76
2017-07-02 13:20:16.897940 EDT | MinEsReturn                 3
2017-07-02 13:20:16.898170 EDT | AverageDiscountedReturn    99.9957
2017-07-02 13:20:16.898351 EDT | AverageQLoss                0.0126521
2017-07-02 13:20:16.898584 EDT | AveragePolicySurr          -1.57046
2017-07-02 13:20:16.898768 EDT | AverageQ                    1.43755
2017-07-02 13:20:16.899000 EDT | AverageAbsQ                 1.44277
2017-07-02 13:20:16.899206 EDT | AverageY                    1.43769
2017-07-02 13:20:16.899434 EDT | AverageAbsY                 1.43854
2017-07-02 13:20:16.899657 EDT | AverageAbsQYDiff            0.0434965
2017-07-02 13:20:16.899796 EDT | AverageAction               0.0544208
2017-07-02 13:20:16.900025 EDT | PolicyRegParamNorm         42.5893
2017-07-02 13:20:16.900230 EDT | QFunRegParamNorm           45.3995
2017-07-02 13:20:16.900450 EDT | -----------------------  ------------
2017-07-02 13:20:16.900763 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #211 | Training started
2017-07-02 13:20:27.194383 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #211 | Training finished
2017-07-02 13:20:27.194951 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #211 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 13:20:27.195188 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #211 | Collecting samples for evaluation
2017-07-02 13:20:32.874855 EDT | -----------------------  ------------
2017-07-02 13:20:32.875450 EDT | Epoch                     211
2017-07-02 13:20:32.875601 EDT | Iteration                 211
2017-07-02 13:20:32.875772 EDT | AverageReturn            1000
2017-07-02 13:20:32.875881 EDT | StdReturn                   0
2017-07-02 13:20:32.876000 EDT | MaxReturn                1000
2017-07-02 13:20:32.876160 EDT | MinReturn                1000
2017-07-02 13:20:32.876305 EDT | AverageEsReturn            13.3867
2017-07-02 13:20:32.876454 EDT | StdEsReturn                14.2762
2017-07-02 13:20:32.876601 EDT | MaxEsReturn                52
2017-07-02 13:20:32.876704 EDT | MinEsReturn                 3
2017-07-02 13:20:32.876829 EDT | AverageDiscountedReturn    99.9957
2017-07-02 13:20:32.876945 EDT | AverageQLoss                0.0142532
2017-07-02 13:20:32.877140 EDT | AveragePolicySurr          -1.60437
2017-07-02 13:20:32.877246 EDT | AverageQ                    1.46161
2017-07-02 13:20:32.877367 EDT | AverageAbsQ                 1.46755
2017-07-02 13:20:32.877468 EDT | AverageY                    1.46168
2017-07-02 13:20:32.877625 EDT | AverageAbsY                 1.46256
2017-07-02 13:20:32.877742 EDT | AverageAbsQYDiff            0.0477816
2017-07-02 13:20:32.877843 EDT | AverageAction               0.0205301
2017-07-02 13:20:32.877943 EDT | PolicyRegParamNorm         42.6621
2017-07-02 13:20:32.878117 EDT | QFunRegParamNorm           45.3974
2017-07-02 13:20:32.878298 EDT | -----------------------  ------------
2017-07-02 13:20:32.878499 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #212 | Training started
2017-07-02 13:20:42.590706 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #212 | Training finished
2017-07-02 13:20:42.591356 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #212 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 13:20:42.591551 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #212 | Collecting samples for evaluation
2017-07-02 13:20:48.267459 EDT | -----------------------  ------------
2017-07-02 13:20:48.267659 EDT | Epoch                     212
2017-07-02 13:20:48.267887 EDT | Iteration                 212
2017-07-02 13:20:48.268094 EDT | AverageReturn            1000
2017-07-02 13:20:48.268318 EDT | StdReturn                   0
2017-07-02 13:20:48.268442 EDT | MaxReturn                1000
2017-07-02 13:20:48.268551 EDT | MinReturn                1000
2017-07-02 13:20:48.268777 EDT | AverageEsReturn             9.63462
2017-07-02 13:20:48.269013 EDT | StdEsReturn                 9.79998
2017-07-02 13:20:48.269238 EDT | MaxEsReturn                53
2017-07-02 13:20:48.269458 EDT | MinEsReturn                 3
2017-07-02 13:20:48.269693 EDT | AverageDiscountedReturn    99.9957
2017-07-02 13:20:48.269929 EDT | AverageQLoss                0.0139827
2017-07-02 13:20:48.270164 EDT | AveragePolicySurr          -1.64057
2017-07-02 13:20:48.270393 EDT | AverageQ                    1.4885
2017-07-02 13:20:48.270529 EDT | AverageAbsQ                 1.49401
2017-07-02 13:20:48.270646 EDT | AverageY                    1.4885
2017-07-02 13:20:48.270881 EDT | AverageAbsY                 1.48929
2017-07-02 13:20:48.271116 EDT | AverageAbsQYDiff            0.0478108
2017-07-02 13:20:48.271314 EDT | AverageAction               0.0311518
2017-07-02 13:20:48.271546 EDT | PolicyRegParamNorm         42.7912
2017-07-02 13:20:48.271780 EDT | QFunRegParamNorm           45.4409
2017-07-02 13:20:48.271981 EDT | -----------------------  ------------
2017-07-02 13:20:48.272309 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #213 | Training started
2017-07-02 13:20:57.974198 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #213 | Training finished
2017-07-02 13:20:57.974779 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #213 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 13:20:57.974930 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #213 | Collecting samples for evaluation
2017-07-02 13:21:03.572541 EDT | -----------------------  ------------
2017-07-02 13:21:03.573149 EDT | Epoch                     213
2017-07-02 13:21:03.573395 EDT | Iteration                 213
2017-07-02 13:21:03.573627 EDT | AverageReturn            1000
2017-07-02 13:21:03.573861 EDT | StdReturn                   0
2017-07-02 13:21:03.574047 EDT | MaxReturn                1000
2017-07-02 13:21:03.574156 EDT | MinReturn                1000
2017-07-02 13:21:03.574259 EDT | AverageEsReturn            11.3068
2017-07-02 13:21:03.574362 EDT | StdEsReturn                10.522
2017-07-02 13:21:03.574490 EDT | MaxEsReturn                46
2017-07-02 13:21:03.574717 EDT | MinEsReturn                 2
2017-07-02 13:21:03.574932 EDT | AverageDiscountedReturn    99.9957
2017-07-02 13:21:03.575044 EDT | AverageQLoss                0.0135992
2017-07-02 13:21:03.575153 EDT | AveragePolicySurr          -1.68283
2017-07-02 13:21:03.575346 EDT | AverageQ                    1.51193
2017-07-02 13:21:03.575575 EDT | AverageAbsQ                 1.51713
2017-07-02 13:21:03.575747 EDT | AverageY                    1.51203
2017-07-02 13:21:03.575978 EDT | AverageAbsY                 1.51293
2017-07-02 13:21:03.576400 EDT | AverageAbsQYDiff            0.0498488
2017-07-02 13:21:03.576685 EDT | AverageAction               0.0411496
2017-07-02 13:21:03.576965 EDT | PolicyRegParamNorm         42.8323
2017-07-02 13:21:03.577321 EDT | QFunRegParamNorm           45.5038
2017-07-02 13:21:03.577562 EDT | -----------------------  ------------
2017-07-02 13:21:03.577836 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #214 | Training started
2017-07-02 13:21:13.307761 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #214 | Training finished
2017-07-02 13:21:13.308358 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #214 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 13:21:13.308687 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #214 | Collecting samples for evaluation
2017-07-02 13:21:18.856626 EDT | -----------------------  -------------
2017-07-02 13:21:18.856830 EDT | Epoch                     214
2017-07-02 13:21:18.856998 EDT | Iteration                 214
2017-07-02 13:21:18.857107 EDT | AverageReturn            1000
2017-07-02 13:21:18.857210 EDT | StdReturn                   0
2017-07-02 13:21:18.857321 EDT | MaxReturn                1000
2017-07-02 13:21:18.857429 EDT | MinReturn                1000
2017-07-02 13:21:18.857560 EDT | AverageEsReturn            15.2121
2017-07-02 13:21:18.857681 EDT | StdEsReturn                14.5899
2017-07-02 13:21:18.857812 EDT | MaxEsReturn                70
2017-07-02 13:21:18.857959 EDT | MinEsReturn                 3
2017-07-02 13:21:18.858070 EDT | AverageDiscountedReturn    99.9957
2017-07-02 13:21:18.858172 EDT | AverageQLoss                0.0153478
2017-07-02 13:21:18.858330 EDT | AveragePolicySurr          -1.74058
2017-07-02 13:21:18.858435 EDT | AverageQ                    1.56028
2017-07-02 13:21:18.858536 EDT | AverageAbsQ                 1.56519
2017-07-02 13:21:18.858660 EDT | AverageY                    1.56051
2017-07-02 13:21:18.858767 EDT | AverageAbsY                 1.56109
2017-07-02 13:21:18.858940 EDT | AverageAbsQYDiff            0.0520192
2017-07-02 13:21:18.859103 EDT | AverageAction               0.00159897
2017-07-02 13:21:18.859207 EDT | PolicyRegParamNorm         42.8523
2017-07-02 13:21:18.859366 EDT | QFunRegParamNorm           45.583
2017-07-02 13:21:18.859472 EDT | -----------------------  -------------
2017-07-02 13:21:18.859669 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #215 | Training started
2017-07-02 13:21:28.629060 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #215 | Training finished
2017-07-02 13:21:28.629612 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #215 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 13:21:28.629836 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #215 | Collecting samples for evaluation
2017-07-02 13:21:34.193734 EDT | -----------------------  ------------
2017-07-02 13:21:34.194303 EDT | Epoch                     215
2017-07-02 13:21:34.194520 EDT | Iteration                 215
2017-07-02 13:21:34.194755 EDT | AverageReturn            1000
2017-07-02 13:21:34.194988 EDT | StdReturn                   0
2017-07-02 13:21:34.195187 EDT | MaxReturn                1000
2017-07-02 13:21:34.195348 EDT | MinReturn                1000
2017-07-02 13:21:34.195478 EDT | AverageEsReturn            13.5
2017-07-02 13:21:34.195627 EDT | StdEsReturn                18.172
2017-07-02 13:21:34.195737 EDT | MaxEsReturn                85
2017-07-02 13:21:34.195844 EDT | MinEsReturn                 3
2017-07-02 13:21:34.195951 EDT | AverageDiscountedReturn    99.9957
2017-07-02 13:21:34.196057 EDT | AverageQLoss                0.0165369
2017-07-02 13:21:34.196163 EDT | AveragePolicySurr          -1.79299
2017-07-02 13:21:34.196268 EDT | AverageQ                    1.60095
2017-07-02 13:21:34.196373 EDT | AverageAbsQ                 1.60654
2017-07-02 13:21:34.196478 EDT | AverageY                    1.60091
2017-07-02 13:21:34.196582 EDT | AverageAbsY                 1.60171
2017-07-02 13:21:34.196714 EDT | AverageAbsQYDiff            0.0555533
2017-07-02 13:21:34.196828 EDT | AverageAction               0.0157066
2017-07-02 13:21:34.196933 EDT | PolicyRegParamNorm         42.9405
2017-07-02 13:21:34.197038 EDT | QFunRegParamNorm           45.6882
2017-07-02 13:21:34.197162 EDT | -----------------------  ------------
2017-07-02 13:21:34.197332 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #216 | Training started
2017-07-02 13:21:43.968097 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #216 | Training finished
2017-07-02 13:21:43.968655 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #216 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 13:21:43.968864 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #216 | Collecting samples for evaluation
2017-07-02 13:21:49.603102 EDT | -----------------------  -------------
2017-07-02 13:21:49.603422 EDT | Epoch                     216
2017-07-02 13:21:49.603667 EDT | Iteration                 216
2017-07-02 13:21:49.603890 EDT | AverageReturn            1000
2017-07-02 13:21:49.603999 EDT | StdReturn                   0
2017-07-02 13:21:49.604147 EDT | MaxReturn                1000
2017-07-02 13:21:49.604309 EDT | MinReturn                1000
2017-07-02 13:21:49.604545 EDT | AverageEsReturn            12.9091
2017-07-02 13:21:49.604731 EDT | StdEsReturn                13.6545
2017-07-02 13:21:49.604906 EDT | MaxEsReturn                62
2017-07-02 13:21:49.605144 EDT | MinEsReturn                 3
2017-07-02 13:21:49.605323 EDT | AverageDiscountedReturn    99.9957
2017-07-02 13:21:49.605666 EDT | AverageQLoss                0.0165687
2017-07-02 13:21:49.605837 EDT | AveragePolicySurr          -1.85332
2017-07-02 13:21:49.605979 EDT | AverageQ                    1.64835
2017-07-02 13:21:49.606084 EDT | AverageAbsQ                 1.65403
2017-07-02 13:21:49.606185 EDT | AverageY                    1.64852
2017-07-02 13:21:49.606344 EDT | AverageAbsY                 1.64907
2017-07-02 13:21:49.606580 EDT | AverageAbsQYDiff            0.0565502
2017-07-02 13:21:49.606796 EDT | AverageAction               0.00821759
2017-07-02 13:21:49.607009 EDT | PolicyRegParamNorm         42.9802
2017-07-02 13:21:49.607245 EDT | QFunRegParamNorm           45.8047
2017-07-02 13:21:49.607432 EDT | -----------------------  -------------
2017-07-02 13:21:49.607770 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #217 | Training started
2017-07-02 13:21:59.292671 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #217 | Training finished
2017-07-02 13:21:59.293393 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #217 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 13:21:59.293640 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #217 | Collecting samples for evaluation
2017-07-02 13:22:04.971869 EDT | -----------------------  ------------
2017-07-02 13:22:04.972489 EDT | Epoch                     217
2017-07-02 13:22:04.972647 EDT | Iteration                 217
2017-07-02 13:22:04.972875 EDT | AverageReturn            1000
2017-07-02 13:22:04.973014 EDT | StdReturn                   0
2017-07-02 13:22:04.973172 EDT | MaxReturn                1000
2017-07-02 13:22:04.973277 EDT | MinReturn                1000
2017-07-02 13:22:04.973397 EDT | AverageEsReturn            16.129
2017-07-02 13:22:04.973519 EDT | StdEsReturn                16.7856
2017-07-02 13:22:04.973726 EDT | MaxEsReturn                73
2017-07-02 13:22:04.973899 EDT | MinEsReturn                 3
2017-07-02 13:22:04.974029 EDT | AverageDiscountedReturn    99.9957
2017-07-02 13:22:04.974149 EDT | AverageQLoss                0.0197653
2017-07-02 13:22:04.974294 EDT | AveragePolicySurr          -1.90545
2017-07-02 13:22:04.974396 EDT | AverageQ                    1.69575
2017-07-02 13:22:04.974496 EDT | AverageAbsQ                 1.70132
2017-07-02 13:22:04.974595 EDT | AverageY                    1.69581
2017-07-02 13:22:04.974702 EDT | AverageAbsY                 1.69623
2017-07-02 13:22:04.974923 EDT | AverageAbsQYDiff            0.0582703
2017-07-02 13:22:04.975076 EDT | AverageAction               0.302991
2017-07-02 13:22:04.975183 EDT | PolicyRegParamNorm         43.0506
2017-07-02 13:22:04.975314 EDT | QFunRegParamNorm           45.8378
2017-07-02 13:22:04.975518 EDT | -----------------------  ------------
2017-07-02 13:22:04.975814 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #218 | Training started
2017-07-02 13:22:14.605060 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #218 | Training finished
2017-07-02 13:22:14.605796 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #218 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 13:22:14.606021 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #218 | Collecting samples for evaluation
2017-07-02 13:22:20.295379 EDT | -----------------------  -------------
2017-07-02 13:22:20.295613 EDT | Epoch                     218
2017-07-02 13:22:20.295730 EDT | Iteration                 218
2017-07-02 13:22:20.295837 EDT | AverageReturn            1000
2017-07-02 13:22:20.295941 EDT | StdReturn                   0
2017-07-02 13:22:20.296088 EDT | MaxReturn                1000
2017-07-02 13:22:20.296194 EDT | MinReturn                1000
2017-07-02 13:22:20.296317 EDT | AverageEsReturn            16.6102
2017-07-02 13:22:20.296464 EDT | StdEsReturn                17.3821
2017-07-02 13:22:20.296630 EDT | MaxEsReturn                75
2017-07-02 13:22:20.296734 EDT | MinEsReturn                 3
2017-07-02 13:22:20.296836 EDT | AverageDiscountedReturn    99.9957
2017-07-02 13:22:20.296951 EDT | AverageQLoss                0.0223476
2017-07-02 13:22:20.297089 EDT | AveragePolicySurr          -1.9619
2017-07-02 13:22:20.297231 EDT | AverageQ                    1.74701
2017-07-02 13:22:20.297335 EDT | AverageAbsQ                 1.75286
2017-07-02 13:22:20.297525 EDT | AverageY                    1.74721
2017-07-02 13:22:20.297686 EDT | AverageAbsY                 1.74783
2017-07-02 13:22:20.297827 EDT | AverageAbsQYDiff            0.061115
2017-07-02 13:22:20.298036 EDT | AverageAction               0.00415528
2017-07-02 13:22:20.298259 EDT | PolicyRegParamNorm         43.2054
2017-07-02 13:22:20.298491 EDT | QFunRegParamNorm           45.9139
2017-07-02 13:22:20.298722 EDT | -----------------------  -------------
2017-07-02 13:22:20.298960 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #219 | Training started
2017-07-02 13:22:29.842623 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #219 | Training finished
2017-07-02 13:22:29.843125 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #219 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 13:22:29.843337 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #219 | Collecting samples for evaluation
2017-07-02 13:22:35.504708 EDT | -----------------------  -------------
2017-07-02 13:22:35.505613 EDT | Epoch                     219
2017-07-02 13:22:35.505871 EDT | Iteration                 219
2017-07-02 13:22:35.506106 EDT | AverageReturn            1000
2017-07-02 13:22:35.506344 EDT | StdReturn                   0
2017-07-02 13:22:35.506586 EDT | MaxReturn                1000
2017-07-02 13:22:35.506825 EDT | MinReturn                1000
2017-07-02 13:22:35.507069 EDT | AverageEsReturn            19.7255
2017-07-02 13:22:35.507317 EDT | StdEsReturn                23.3843
2017-07-02 13:22:35.507559 EDT | MaxEsReturn               122
2017-07-02 13:22:35.507803 EDT | MinEsReturn                 3
2017-07-02 13:22:35.508038 EDT | AverageDiscountedReturn    99.9957
2017-07-02 13:22:35.508275 EDT | AverageQLoss                0.0230055
2017-07-02 13:22:35.508519 EDT | AveragePolicySurr          -2.00747
2017-07-02 13:22:35.508762 EDT | AverageQ                    1.78636
2017-07-02 13:22:35.508996 EDT | AverageAbsQ                 1.79311
2017-07-02 13:22:35.509227 EDT | AverageY                    1.78639
2017-07-02 13:22:35.509461 EDT | AverageAbsY                 1.78696
2017-07-02 13:22:35.509700 EDT | AverageAbsQYDiff            0.06182
2017-07-02 13:22:35.509931 EDT | AverageAction               0.00496045
2017-07-02 13:22:35.510163 EDT | PolicyRegParamNorm         43.3364
2017-07-02 13:22:35.510335 EDT | QFunRegParamNorm           46.0093
2017-07-02 13:22:35.510516 EDT | -----------------------  -------------
2017-07-02 13:22:35.510847 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #220 | Training started
2017-07-02 13:22:45.033146 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #220 | Training finished
2017-07-02 13:22:45.033725 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #220 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 13:22:45.033992 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #220 | Collecting samples for evaluation
2017-07-02 13:22:50.744816 EDT | -----------------------  ------------
2017-07-02 13:22:50.745027 EDT | Epoch                     220
2017-07-02 13:22:50.745139 EDT | Iteration                 220
2017-07-02 13:22:50.745327 EDT | AverageReturn            1000
2017-07-02 13:22:50.745509 EDT | StdReturn                   0
2017-07-02 13:22:50.745644 EDT | MaxReturn                1000
2017-07-02 13:22:50.745782 EDT | MinReturn                1000
2017-07-02 13:22:50.745886 EDT | AverageEsReturn            23.1818
2017-07-02 13:22:50.746026 EDT | StdEsReturn                22.1188
2017-07-02 13:22:50.746255 EDT | MaxEsReturn                88
2017-07-02 13:22:50.746484 EDT | MinEsReturn                 3
2017-07-02 13:22:50.746631 EDT | AverageDiscountedReturn    99.9957
2017-07-02 13:22:50.746829 EDT | AverageQLoss                0.022692
2017-07-02 13:22:50.747004 EDT | AveragePolicySurr          -2.07243
2017-07-02 13:22:50.747123 EDT | AverageQ                    1.84189
2017-07-02 13:22:50.747323 EDT | AverageAbsQ                 1.848
2017-07-02 13:22:50.747520 EDT | AverageY                    1.8421
2017-07-02 13:22:50.747654 EDT | AverageAbsY                 1.84265
2017-07-02 13:22:50.747787 EDT | AverageAbsQYDiff            0.0641396
2017-07-02 13:22:50.747951 EDT | AverageAction               0.544139
2017-07-02 13:22:50.748188 EDT | PolicyRegParamNorm         43.4086
2017-07-02 13:22:50.748419 EDT | QFunRegParamNorm           46.0715
2017-07-02 13:22:50.748647 EDT | -----------------------  ------------
2017-07-02 13:22:50.748962 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #221 | Training started
2017-07-02 13:23:00.316467 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #221 | Training finished
2017-07-02 13:23:00.317355 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #221 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 13:23:00.317637 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #221 | Collecting samples for evaluation
2017-07-02 13:23:05.922828 EDT | -----------------------  ------------
2017-07-02 13:23:05.923088 EDT | Epoch                     221
2017-07-02 13:23:05.923260 EDT | Iteration                 221
2017-07-02 13:23:05.923375 EDT | AverageReturn            1000
2017-07-02 13:23:05.923484 EDT | StdReturn                   0
2017-07-02 13:23:05.923630 EDT | MaxReturn                1000
2017-07-02 13:23:05.923774 EDT | MinReturn                1000
2017-07-02 13:23:05.923883 EDT | AverageEsReturn            28.7941
2017-07-02 13:23:05.924006 EDT | StdEsReturn                29.4646
2017-07-02 13:23:05.924147 EDT | MaxEsReturn               111
2017-07-02 13:23:05.924256 EDT | MinEsReturn                 3
2017-07-02 13:23:05.924363 EDT | AverageDiscountedReturn    99.9957
2017-07-02 13:23:05.924474 EDT | AverageQLoss                0.0256971
2017-07-02 13:23:05.924606 EDT | AveragePolicySurr          -2.12172
2017-07-02 13:23:05.924770 EDT | AverageQ                    1.88654
2017-07-02 13:23:05.924880 EDT | AverageAbsQ                 1.89257
2017-07-02 13:23:05.924986 EDT | AverageY                    1.88673
2017-07-02 13:23:05.925125 EDT | AverageAbsY                 1.88708
2017-07-02 13:23:05.925332 EDT | AverageAbsQYDiff            0.0663618
2017-07-02 13:23:05.925478 EDT | AverageAction               0.106082
2017-07-02 13:23:05.925652 EDT | PolicyRegParamNorm         43.4892
2017-07-02 13:23:05.925789 EDT | QFunRegParamNorm           46.1702
2017-07-02 13:23:05.925934 EDT | -----------------------  ------------
2017-07-02 13:23:05.926123 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #222 | Training started
2017-07-02 13:23:15.577678 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #222 | Training finished
2017-07-02 13:23:15.578296 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #222 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 13:23:15.578541 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #222 | Collecting samples for evaluation
2017-07-02 13:23:21.225422 EDT | -----------------------  ------------
2017-07-02 13:23:21.225738 EDT | Epoch                     222
2017-07-02 13:23:21.225908 EDT | Iteration                 222
2017-07-02 13:23:21.226016 EDT | AverageReturn            1000
2017-07-02 13:23:21.226119 EDT | StdReturn                   0
2017-07-02 13:23:21.226221 EDT | MaxReturn                1000
2017-07-02 13:23:21.226322 EDT | MinReturn                1000
2017-07-02 13:23:21.226470 EDT | AverageEsReturn            20.4694
2017-07-02 13:23:21.226600 EDT | StdEsReturn                18.5341
2017-07-02 13:23:21.226745 EDT | MaxEsReturn                76
2017-07-02 13:23:21.226868 EDT | MinEsReturn                 3
2017-07-02 13:23:21.226980 EDT | AverageDiscountedReturn    99.9957
2017-07-02 13:23:21.227148 EDT | AverageQLoss                0.0282486
2017-07-02 13:23:21.227331 EDT | AveragePolicySurr          -2.19911
2017-07-02 13:23:21.227505 EDT | AverageQ                    1.94962
2017-07-02 13:23:21.227717 EDT | AverageAbsQ                 1.95579
2017-07-02 13:23:21.227886 EDT | AverageY                    1.94993
2017-07-02 13:23:21.228051 EDT | AverageAbsY                 1.95035
2017-07-02 13:23:21.228237 EDT | AverageAbsQYDiff            0.069846
2017-07-02 13:23:21.228414 EDT | AverageAction               0.0576444
2017-07-02 13:23:21.228622 EDT | PolicyRegParamNorm         43.5562
2017-07-02 13:23:21.228761 EDT | QFunRegParamNorm           46.2418
2017-07-02 13:23:21.228865 EDT | -----------------------  ------------
2017-07-02 13:23:21.229042 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #223 | Training started
2017-07-02 13:23:30.983951 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #223 | Training finished
2017-07-02 13:23:30.984814 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #223 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 13:23:30.985066 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #223 | Collecting samples for evaluation
2017-07-02 13:23:36.608533 EDT | -----------------------  ------------
2017-07-02 13:23:36.608864 EDT | Epoch                     223
2017-07-02 13:23:36.609097 EDT | Iteration                 223
2017-07-02 13:23:36.609314 EDT | AverageReturn            1000
2017-07-02 13:23:36.609525 EDT | StdReturn                   0
2017-07-02 13:23:36.609742 EDT | MaxReturn                1000
2017-07-02 13:23:36.609977 EDT | MinReturn                1000
2017-07-02 13:23:36.610209 EDT | AverageEsReturn            23.4524
2017-07-02 13:23:36.610440 EDT | StdEsReturn                27.8065
2017-07-02 13:23:36.610671 EDT | MaxEsReturn               109
2017-07-02 13:23:36.610849 EDT | MinEsReturn                 3
2017-07-02 13:23:36.610980 EDT | AverageDiscountedReturn    99.9957
2017-07-02 13:23:36.611204 EDT | AverageQLoss                0.0263129
2017-07-02 13:23:36.611357 EDT | AveragePolicySurr          -2.26313
2017-07-02 13:23:36.611582 EDT | AverageQ                    2.00698
2017-07-02 13:23:36.611802 EDT | AverageAbsQ                 2.01296
2017-07-02 13:23:36.612029 EDT | AverageY                    2.00723
2017-07-02 13:23:36.612265 EDT | AverageAbsY                 2.00772
2017-07-02 13:23:36.612492 EDT | AverageAbsQYDiff            0.0687124
2017-07-02 13:23:36.612715 EDT | AverageAction               0.0120833
2017-07-02 13:23:36.612869 EDT | PolicyRegParamNorm         43.5834
2017-07-02 13:23:36.613093 EDT | QFunRegParamNorm           46.3404
2017-07-02 13:23:36.613276 EDT | -----------------------  ------------
2017-07-02 13:23:36.613449 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #224 | Training started
2017-07-02 13:23:46.213769 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #224 | Training finished
2017-07-02 13:23:46.214646 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #224 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 13:23:46.214875 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #224 | Collecting samples for evaluation
2017-07-02 13:23:51.939064 EDT | -----------------------  ------------
2017-07-02 13:23:51.939533 EDT | Epoch                     224
2017-07-02 13:23:51.939670 EDT | Iteration                 224
2017-07-02 13:23:51.939843 EDT | AverageReturn            1000
2017-07-02 13:23:51.940024 EDT | StdReturn                   0
2017-07-02 13:23:51.940182 EDT | MaxReturn                1000
2017-07-02 13:23:51.940325 EDT | MinReturn                1000
2017-07-02 13:23:51.940435 EDT | AverageEsReturn            34.4483
2017-07-02 13:23:51.940548 EDT | StdEsReturn                30.7163
2017-07-02 13:23:51.940655 EDT | MaxEsReturn               101
2017-07-02 13:23:51.940765 EDT | MinEsReturn                 3
2017-07-02 13:23:51.940882 EDT | AverageDiscountedReturn    99.9957
2017-07-02 13:23:51.940989 EDT | AverageQLoss                0.0296657
2017-07-02 13:23:51.941094 EDT | AveragePolicySurr          -2.33131
2017-07-02 13:23:51.941216 EDT | AverageQ                    2.07008
2017-07-02 13:23:51.941367 EDT | AverageAbsQ                 2.07646
2017-07-02 13:23:51.941476 EDT | AverageY                    2.07032
2017-07-02 13:23:51.941623 EDT | AverageAbsY                 2.07087
2017-07-02 13:23:51.941752 EDT | AverageAbsQYDiff            0.073468
2017-07-02 13:23:51.941901 EDT | AverageAction               0.348874
2017-07-02 13:23:51.942007 EDT | PolicyRegParamNorm         43.6426
2017-07-02 13:23:51.942119 EDT | QFunRegParamNorm           46.4509
2017-07-02 13:23:51.942250 EDT | -----------------------  ------------
2017-07-02 13:23:51.942421 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #225 | Training started
2017-07-02 13:24:01.489667 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #225 | Training finished
2017-07-02 13:24:01.490908 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #225 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 13:24:01.491170 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #225 | Collecting samples for evaluation
2017-07-02 13:24:07.162339 EDT | -----------------------  ------------
2017-07-02 13:24:07.162547 EDT | Epoch                     225
2017-07-02 13:24:07.162758 EDT | Iteration                 225
2017-07-02 13:24:07.162904 EDT | AverageReturn            1000
2017-07-02 13:24:07.163113 EDT | StdReturn                   0
2017-07-02 13:24:07.163324 EDT | MaxReturn                1000
2017-07-02 13:24:07.163457 EDT | MinReturn                1000
2017-07-02 13:24:07.163604 EDT | AverageEsReturn            24.2381
2017-07-02 13:24:07.163737 EDT | StdEsReturn                25.4032
2017-07-02 13:24:07.163845 EDT | MaxEsReturn               133
2017-07-02 13:24:07.163969 EDT | MinEsReturn                 3
2017-07-02 13:24:07.164104 EDT | AverageDiscountedReturn    99.9957
2017-07-02 13:24:07.164215 EDT | AverageQLoss                0.0284752
2017-07-02 13:24:07.164322 EDT | AveragePolicySurr          -2.39369
2017-07-02 13:24:07.164427 EDT | AverageQ                    2.12038
2017-07-02 13:24:07.164575 EDT | AverageAbsQ                 2.12726
2017-07-02 13:24:07.164720 EDT | AverageY                    2.12079
2017-07-02 13:24:07.164934 EDT | AverageAbsY                 2.12152
2017-07-02 13:24:07.165112 EDT | AverageAbsQYDiff            0.0732328
2017-07-02 13:24:07.165237 EDT | AverageAction               0.590652
2017-07-02 13:24:07.165402 EDT | PolicyRegParamNorm         43.7911
2017-07-02 13:24:07.165627 EDT | QFunRegParamNorm           46.5772
2017-07-02 13:24:07.165759 EDT | -----------------------  ------------
2017-07-02 13:24:07.166060 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #226 | Training started
2017-07-02 13:24:16.749087 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #226 | Training finished
2017-07-02 13:24:16.749588 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #226 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 13:24:16.749773 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #226 | Collecting samples for evaluation
2017-07-02 13:24:22.441722 EDT | -----------------------  ------------
2017-07-02 13:24:22.442044 EDT | Epoch                     226
2017-07-02 13:24:22.442270 EDT | Iteration                 226
2017-07-02 13:24:22.442505 EDT | AverageReturn            1000
2017-07-02 13:24:22.442729 EDT | StdReturn                   0
2017-07-02 13:24:22.442955 EDT | MaxReturn                1000
2017-07-02 13:24:22.443179 EDT | MinReturn                1000
2017-07-02 13:24:22.443397 EDT | AverageEsReturn            31.2
2017-07-02 13:24:22.443606 EDT | StdEsReturn                26.5398
2017-07-02 13:24:22.443717 EDT | MaxEsReturn               126
2017-07-02 13:24:22.443890 EDT | MinEsReturn                 3
2017-07-02 13:24:22.444102 EDT | AverageDiscountedReturn    99.9957
2017-07-02 13:24:22.444212 EDT | AverageQLoss                0.0327343
2017-07-02 13:24:22.444315 EDT | AveragePolicySurr          -2.45791
2017-07-02 13:24:22.444416 EDT | AverageQ                    2.17979
2017-07-02 13:24:22.444536 EDT | AverageAbsQ                 2.18581
2017-07-02 13:24:22.444757 EDT | AverageY                    2.18007
2017-07-02 13:24:22.444968 EDT | AverageAbsY                 2.18105
2017-07-02 13:24:22.445078 EDT | AverageAbsQYDiff            0.0745242
2017-07-02 13:24:22.445181 EDT | AverageAction               0.501664
2017-07-02 13:24:22.445282 EDT | PolicyRegParamNorm         43.882
2017-07-02 13:24:22.445381 EDT | QFunRegParamNorm           46.6831
2017-07-02 13:24:22.445480 EDT | -----------------------  ------------
2017-07-02 13:24:22.445725 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #227 | Training started
2017-07-02 13:24:32.013079 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #227 | Training finished
2017-07-02 13:24:32.013658 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #227 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 13:24:32.013870 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #227 | Collecting samples for evaluation
2017-07-02 13:24:37.718069 EDT | -----------------------  ------------
2017-07-02 13:24:37.718283 EDT | Epoch                     227
2017-07-02 13:24:37.718482 EDT | Iteration                 227
2017-07-02 13:24:37.718644 EDT | AverageReturn            1000
2017-07-02 13:24:37.718840 EDT | StdReturn                   0
2017-07-02 13:24:37.719051 EDT | MaxReturn                1000
2017-07-02 13:24:37.719268 EDT | MinReturn                1000
2017-07-02 13:24:37.719483 EDT | AverageEsReturn            34.7097
2017-07-02 13:24:37.719709 EDT | StdEsReturn                31.8547
2017-07-02 13:24:37.719874 EDT | MaxEsReturn               137
2017-07-02 13:24:37.719980 EDT | MinEsReturn                 3
2017-07-02 13:24:37.720145 EDT | AverageDiscountedReturn    99.9957
2017-07-02 13:24:37.720377 EDT | AverageQLoss                0.0325646
2017-07-02 13:24:37.720599 EDT | AveragePolicySurr          -2.5113
2017-07-02 13:24:37.720819 EDT | AverageQ                    2.23285
2017-07-02 13:24:37.721029 EDT | AverageAbsQ                 2.23918
2017-07-02 13:24:37.721252 EDT | AverageY                    2.23307
2017-07-02 13:24:37.721442 EDT | AverageAbsY                 2.23442
2017-07-02 13:24:37.721630 EDT | AverageAbsQYDiff            0.0770865
2017-07-02 13:24:37.721862 EDT | AverageAction               0.745275
2017-07-02 13:24:37.722078 EDT | PolicyRegParamNorm         43.9368
2017-07-02 13:24:37.722297 EDT | QFunRegParamNorm           46.7304
2017-07-02 13:24:37.722512 EDT | -----------------------  ------------
2017-07-02 13:24:37.722802 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #228 | Training started
2017-07-02 13:24:47.401365 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #228 | Training finished
2017-07-02 13:24:47.402009 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #228 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 13:24:47.402145 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #228 | Collecting samples for evaluation
2017-07-02 13:24:53.113746 EDT | -----------------------  ------------
2017-07-02 13:24:53.114026 EDT | Epoch                     228
2017-07-02 13:24:53.114230 EDT | Iteration                 228
2017-07-02 13:24:53.114408 EDT | AverageReturn            1000
2017-07-02 13:24:53.114606 EDT | StdReturn                   0
2017-07-02 13:24:53.114713 EDT | MaxReturn                1000
2017-07-02 13:24:53.114880 EDT | MinReturn                1000
2017-07-02 13:24:53.115080 EDT | AverageEsReturn            33.7778
2017-07-02 13:24:53.115289 EDT | StdEsReturn                40.4478
2017-07-02 13:24:53.115442 EDT | MaxEsReturn               196
2017-07-02 13:24:53.115569 EDT | MinEsReturn                 3
2017-07-02 13:24:53.115776 EDT | AverageDiscountedReturn    99.9957
2017-07-02 13:24:53.115973 EDT | AverageQLoss                0.0294195
2017-07-02 13:24:53.116172 EDT | AveragePolicySurr          -2.56223
2017-07-02 13:24:53.116301 EDT | AverageQ                    2.27772
2017-07-02 13:24:53.116436 EDT | AverageAbsQ                 2.28428
2017-07-02 13:24:53.116540 EDT | AverageY                    2.27806
2017-07-02 13:24:53.116667 EDT | AverageAbsY                 2.27947
2017-07-02 13:24:53.116794 EDT | AverageAbsQYDiff            0.0741723
2017-07-02 13:24:53.116902 EDT | AverageAction               0.6886
2017-07-02 13:24:53.117045 EDT | PolicyRegParamNorm         44.0491
2017-07-02 13:24:53.117149 EDT | QFunRegParamNorm           46.8322
2017-07-02 13:24:53.117250 EDT | -----------------------  ------------
2017-07-02 13:24:53.117436 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #229 | Training started
2017-07-02 13:25:02.634357 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #229 | Training finished
2017-07-02 13:25:02.634878 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #229 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 13:25:02.635071 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #229 | Collecting samples for evaluation
2017-07-02 13:25:08.375304 EDT | -----------------------  ------------
2017-07-02 13:25:08.375505 EDT | Epoch                     229
2017-07-02 13:25:08.375653 EDT | Iteration                 229
2017-07-02 13:25:08.375761 EDT | AverageReturn            1000
2017-07-02 13:25:08.375883 EDT | StdReturn                   0
2017-07-02 13:25:08.375998 EDT | MaxReturn                1000
2017-07-02 13:25:08.376107 EDT | MinReturn                1000
2017-07-02 13:25:08.376210 EDT | AverageEsReturn            32.2424
2017-07-02 13:25:08.376313 EDT | StdEsReturn                36.204
2017-07-02 13:25:08.376415 EDT | MaxEsReturn               158
2017-07-02 13:25:08.376543 EDT | MinEsReturn                 3
2017-07-02 13:25:08.376650 EDT | AverageDiscountedReturn    99.9957
2017-07-02 13:25:08.376752 EDT | AverageQLoss                0.0335854
2017-07-02 13:25:08.376915 EDT | AveragePolicySurr          -2.624
2017-07-02 13:25:08.377025 EDT | AverageQ                    2.32755
2017-07-02 13:25:08.377150 EDT | AverageAbsQ                 2.33573
2017-07-02 13:25:08.377253 EDT | AverageY                    2.32821
2017-07-02 13:25:08.377355 EDT | AverageAbsY                 2.32984
2017-07-02 13:25:08.377455 EDT | AverageAbsQYDiff            0.0774466
2017-07-02 13:25:08.377606 EDT | AverageAction               0.830546
2017-07-02 13:25:08.377802 EDT | PolicyRegParamNorm         44.185
2017-07-02 13:25:08.377943 EDT | QFunRegParamNorm           46.9342
2017-07-02 13:25:08.378072 EDT | -----------------------  ------------
2017-07-02 13:25:08.378334 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #230 | Training started
2017-07-02 13:25:17.853315 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #230 | Training finished
2017-07-02 13:25:17.854064 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #230 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 13:25:17.854198 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #230 | Collecting samples for evaluation
2017-07-02 13:25:24.114005 EDT | -----------------------  ------------
2017-07-02 13:25:24.114325 EDT | Epoch                     230
2017-07-02 13:25:24.114531 EDT | Iteration                 230
2017-07-02 13:25:24.114767 EDT | AverageReturn            1000
2017-07-02 13:25:24.114995 EDT | StdReturn                   0
2017-07-02 13:25:24.115214 EDT | MaxReturn                1000
2017-07-02 13:25:24.115434 EDT | MinReturn                1000
2017-07-02 13:25:24.115643 EDT | AverageEsReturn            31.4375
2017-07-02 13:25:24.115765 EDT | StdEsReturn                37.2432
2017-07-02 13:25:24.115982 EDT | MaxEsReturn               175
2017-07-02 13:25:24.116258 EDT | MinEsReturn                 3
2017-07-02 13:25:24.116444 EDT | AverageDiscountedReturn    99.9957
2017-07-02 13:25:24.116679 EDT | AverageQLoss                0.0358818
2017-07-02 13:25:24.116901 EDT | AveragePolicySurr          -2.68099
2017-07-02 13:25:24.117119 EDT | AverageQ                    2.38564
2017-07-02 13:25:24.117335 EDT | AverageAbsQ                 2.39318
2017-07-02 13:25:24.117545 EDT | AverageY                    2.3858
2017-07-02 13:25:24.117732 EDT | AverageAbsY                 2.38721
2017-07-02 13:25:24.117848 EDT | AverageAbsQYDiff            0.0797896
2017-07-02 13:25:24.117953 EDT | AverageAction               0.682786
2017-07-02 13:25:24.118077 EDT | PolicyRegParamNorm         44.3029
2017-07-02 13:25:24.118177 EDT | QFunRegParamNorm           47.0383
2017-07-02 13:25:24.118275 EDT | -----------------------  ------------
2017-07-02 13:25:24.118552 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #231 | Training started
2017-07-02 13:25:33.507069 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #231 | Training finished
2017-07-02 13:25:33.507680 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #231 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 13:25:33.507880 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #231 | Collecting samples for evaluation
2017-07-02 13:25:39.312583 EDT | -----------------------  ------------
2017-07-02 13:25:39.312898 EDT | Epoch                     231
2017-07-02 13:25:39.313110 EDT | Iteration                 231
2017-07-02 13:25:39.313347 EDT | AverageReturn            1000
2017-07-02 13:25:39.313590 EDT | StdReturn                   0
2017-07-02 13:25:39.313810 EDT | MaxReturn                1000
2017-07-02 13:25:39.314026 EDT | MinReturn                1000
2017-07-02 13:25:39.314198 EDT | AverageEsReturn            43.8696
2017-07-02 13:25:39.314412 EDT | StdEsReturn                41.5842
2017-07-02 13:25:39.314635 EDT | MaxEsReturn               147
2017-07-02 13:25:39.314850 EDT | MinEsReturn                 3
2017-07-02 13:25:39.315064 EDT | AverageDiscountedReturn    99.9957
2017-07-02 13:25:39.315284 EDT | AverageQLoss                0.0369193
2017-07-02 13:25:39.315500 EDT | AveragePolicySurr          -2.74246
2017-07-02 13:25:39.315723 EDT | AverageQ                    2.45216
2017-07-02 13:25:39.315898 EDT | AverageAbsQ                 2.45958
2017-07-02 13:25:39.316090 EDT | AverageY                    2.45263
2017-07-02 13:25:39.316312 EDT | AverageAbsY                 2.4536
2017-07-02 13:25:39.316473 EDT | AverageAbsQYDiff            0.0802877
2017-07-02 13:25:39.316696 EDT | AverageAction               0.752403
2017-07-02 13:25:39.316913 EDT | PolicyRegParamNorm         44.4063
2017-07-02 13:25:39.317100 EDT | QFunRegParamNorm           47.1144
2017-07-02 13:25:39.317264 EDT | -----------------------  ------------
2017-07-02 13:25:39.317665 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #232 | Training started
2017-07-02 13:25:48.829776 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #232 | Training finished
2017-07-02 13:25:48.830409 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #232 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 13:25:48.830689 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #232 | Collecting samples for evaluation
2017-07-02 13:25:54.515476 EDT | -----------------------  ------------
2017-07-02 13:25:54.515764 EDT | Epoch                     232
2017-07-02 13:25:54.515997 EDT | Iteration                 232
2017-07-02 13:25:54.516211 EDT | AverageReturn            1000
2017-07-02 13:25:54.516433 EDT | StdReturn                   0
2017-07-02 13:25:54.516600 EDT | MaxReturn                1000
2017-07-02 13:25:54.516707 EDT | MinReturn                1000
2017-07-02 13:25:54.516821 EDT | AverageEsReturn            33.7931
2017-07-02 13:25:54.516925 EDT | StdEsReturn                29.0165
2017-07-02 13:25:54.517030 EDT | MaxEsReturn               112
2017-07-02 13:25:54.517252 EDT | MinEsReturn                 3
2017-07-02 13:25:54.517424 EDT | AverageDiscountedReturn    99.9957
2017-07-02 13:25:54.517647 EDT | AverageQLoss                0.0335217
2017-07-02 13:25:54.517829 EDT | AveragePolicySurr          -2.80524
2017-07-02 13:25:54.518056 EDT | AverageQ                    2.49383
2017-07-02 13:25:54.518268 EDT | AverageAbsQ                 2.50073
2017-07-02 13:25:54.518413 EDT | AverageY                    2.4939
2017-07-02 13:25:54.518519 EDT | AverageAbsY                 2.49512
2017-07-02 13:25:54.518622 EDT | AverageAbsQYDiff            0.077445
2017-07-02 13:25:54.518721 EDT | AverageAction               0.617158
2017-07-02 13:25:54.518818 EDT | PolicyRegParamNorm         44.509
2017-07-02 13:25:54.518916 EDT | QFunRegParamNorm           47.2033
2017-07-02 13:25:54.519057 EDT | -----------------------  ------------
2017-07-02 13:25:54.519347 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #233 | Training started
2017-07-02 13:26:04.162916 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #233 | Training finished
2017-07-02 13:26:04.163529 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #233 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 13:26:04.163838 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #233 | Collecting samples for evaluation
2017-07-02 13:26:09.775568 EDT | -----------------------  ------------
2017-07-02 13:26:09.775752 EDT | Epoch                     233
2017-07-02 13:26:09.775888 EDT | Iteration                 233
2017-07-02 13:26:09.776002 EDT | AverageReturn            1000
2017-07-02 13:26:09.776106 EDT | StdReturn                   0
2017-07-02 13:26:09.776247 EDT | MaxReturn                1000
2017-07-02 13:26:09.776351 EDT | MinReturn                1000
2017-07-02 13:26:09.776480 EDT | AverageEsReturn            51.65
2017-07-02 13:26:09.776583 EDT | StdEsReturn                34.2874
2017-07-02 13:26:09.776694 EDT | MaxEsReturn               149
2017-07-02 13:26:09.776840 EDT | MinEsReturn                 4
2017-07-02 13:26:09.776943 EDT | AverageDiscountedReturn    99.9957
2017-07-02 13:26:09.777054 EDT | AverageQLoss                0.0410404
2017-07-02 13:26:09.777159 EDT | AveragePolicySurr          -2.84742
2017-07-02 13:26:09.777259 EDT | AverageQ                    2.53458
2017-07-02 13:26:09.777358 EDT | AverageAbsQ                 2.54258
2017-07-02 13:26:09.777500 EDT | AverageY                    2.53493
2017-07-02 13:26:09.777646 EDT | AverageAbsY                 2.53616
2017-07-02 13:26:09.777840 EDT | AverageAbsQYDiff            0.0832599
2017-07-02 13:26:09.777946 EDT | AverageAction               0.811046
2017-07-02 13:26:09.778064 EDT | PolicyRegParamNorm         44.5472
2017-07-02 13:26:09.778165 EDT | QFunRegParamNorm           47.2632
2017-07-02 13:26:09.778282 EDT | -----------------------  ------------
2017-07-02 13:26:09.778447 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #234 | Training started
2017-07-02 13:26:19.505571 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #234 | Training finished
2017-07-02 13:26:19.506077 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #234 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 13:26:19.506465 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #234 | Collecting samples for evaluation
2017-07-02 13:26:25.214745 EDT | -----------------------  -----------
2017-07-02 13:26:25.214951 EDT | Epoch                     234
2017-07-02 13:26:25.215113 EDT | Iteration                 234
2017-07-02 13:26:25.215248 EDT | AverageReturn            1000
2017-07-02 13:26:25.215436 EDT | StdReturn                   0
2017-07-02 13:26:25.215624 EDT | MaxReturn                1000
2017-07-02 13:26:25.215779 EDT | MinReturn                1000
2017-07-02 13:26:25.215931 EDT | AverageEsReturn            31.9355
2017-07-02 13:26:25.216130 EDT | StdEsReturn                31.6889
2017-07-02 13:26:25.216262 EDT | MaxEsReturn               176
2017-07-02 13:26:25.216384 EDT | MinEsReturn                 3
2017-07-02 13:26:25.216493 EDT | AverageDiscountedReturn    99.9957
2017-07-02 13:26:25.216600 EDT | AverageQLoss                0.035425
2017-07-02 13:26:25.216706 EDT | AveragePolicySurr          -2.9108
2017-07-02 13:26:25.216848 EDT | AverageQ                    2.59476
2017-07-02 13:26:25.216970 EDT | AverageAbsQ                 2.60214
2017-07-02 13:26:25.217156 EDT | AverageY                    2.59538
2017-07-02 13:26:25.217313 EDT | AverageAbsY                 2.59663
2017-07-02 13:26:25.217433 EDT | AverageAbsQYDiff            0.078432
2017-07-02 13:26:25.217662 EDT | AverageAction               0.730941
2017-07-02 13:26:25.217800 EDT | PolicyRegParamNorm         44.6132
2017-07-02 13:26:25.217921 EDT | QFunRegParamNorm           47.3873
2017-07-02 13:26:25.218027 EDT | -----------------------  -----------
2017-07-02 13:26:25.218190 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #235 | Training started
2017-07-02 13:26:34.859606 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #235 | Training finished
2017-07-02 13:26:34.874731 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #235 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 13:26:34.874935 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #235 | Collecting samples for evaluation
2017-07-02 13:26:40.590891 EDT | -----------------------  ------------
2017-07-02 13:26:40.591083 EDT | Epoch                     235
2017-07-02 13:26:40.591219 EDT | Iteration                 235
2017-07-02 13:26:40.591409 EDT | AverageReturn            1000
2017-07-02 13:26:40.591594 EDT | StdReturn                   0
2017-07-02 13:26:40.591701 EDT | MaxReturn                1000
2017-07-02 13:26:40.591827 EDT | MinReturn                1000
2017-07-02 13:26:40.592041 EDT | AverageEsReturn            35.5556
2017-07-02 13:26:40.592275 EDT | StdEsReturn                31.4576
2017-07-02 13:26:40.592496 EDT | MaxEsReturn               151
2017-07-02 13:26:40.592703 EDT | MinEsReturn                 6
2017-07-02 13:26:40.592858 EDT | AverageDiscountedReturn    99.9957
2017-07-02 13:26:40.592971 EDT | AverageQLoss                0.0400995
2017-07-02 13:26:40.593192 EDT | AveragePolicySurr          -2.9585
2017-07-02 13:26:40.593427 EDT | AverageQ                    2.64884
2017-07-02 13:26:40.593715 EDT | AverageAbsQ                 2.65592
2017-07-02 13:26:40.593952 EDT | AverageY                    2.64897
2017-07-02 13:26:40.594170 EDT | AverageAbsY                 2.65029
2017-07-02 13:26:40.594287 EDT | AverageAbsQYDiff            0.0798174
2017-07-02 13:26:40.594475 EDT | AverageAction               0.774572
2017-07-02 13:26:40.594583 EDT | PolicyRegParamNorm         44.6798
2017-07-02 13:26:40.594688 EDT | QFunRegParamNorm           47.4827
2017-07-02 13:26:40.594810 EDT | -----------------------  ------------
2017-07-02 13:26:40.595094 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #236 | Training started
2017-07-02 13:26:50.130899 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #236 | Training finished
2017-07-02 13:26:50.131597 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #236 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 13:26:50.131775 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #236 | Collecting samples for evaluation
2017-07-02 13:26:55.835156 EDT | -----------------------  ------------
2017-07-02 13:26:55.835363 EDT | Epoch                     236
2017-07-02 13:26:55.835476 EDT | Iteration                 236
2017-07-02 13:26:55.835638 EDT | AverageReturn            1000
2017-07-02 13:26:55.835750 EDT | StdReturn                   0
2017-07-02 13:26:55.835855 EDT | MaxReturn                1000
2017-07-02 13:26:55.835957 EDT | MinReturn                1000
2017-07-02 13:26:55.836057 EDT | AverageEsReturn            31.125
2017-07-02 13:26:55.836157 EDT | StdEsReturn                25.8127
2017-07-02 13:26:55.836258 EDT | MaxEsReturn               112
2017-07-02 13:26:55.836358 EDT | MinEsReturn                 4
2017-07-02 13:26:55.836459 EDT | AverageDiscountedReturn    99.9957
2017-07-02 13:26:55.836601 EDT | AverageQLoss                0.0419712
2017-07-02 13:26:55.836800 EDT | AveragePolicySurr          -3.01599
2017-07-02 13:26:55.836999 EDT | AverageQ                    2.70345
2017-07-02 13:26:55.837158 EDT | AverageAbsQ                 2.71104
2017-07-02 13:26:55.837271 EDT | AverageY                    2.70338
2017-07-02 13:26:55.837381 EDT | AverageAbsY                 2.7045
2017-07-02 13:26:55.837549 EDT | AverageAbsQYDiff            0.0812209
2017-07-02 13:26:55.837688 EDT | AverageAction               0.81806
2017-07-02 13:26:55.837816 EDT | PolicyRegParamNorm         44.7754
2017-07-02 13:26:55.837930 EDT | QFunRegParamNorm           47.63
2017-07-02 13:26:55.838086 EDT | -----------------------  ------------
2017-07-02 13:26:55.838355 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #237 | Training started
2017-07-02 13:27:05.365608 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #237 | Training finished
2017-07-02 13:27:05.366234 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #237 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 13:27:05.366484 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #237 | Collecting samples for evaluation
2017-07-02 13:27:11.035561 EDT | -----------------------  ------------
2017-07-02 13:27:11.035821 EDT | Epoch                     237
2017-07-02 13:27:11.035940 EDT | Iteration                 237
2017-07-02 13:27:11.036067 EDT | AverageReturn            1000
2017-07-02 13:27:11.036186 EDT | StdReturn                   0
2017-07-02 13:27:11.036325 EDT | MaxReturn                1000
2017-07-02 13:27:11.036513 EDT | MinReturn                1000
2017-07-02 13:27:11.036662 EDT | AverageEsReturn            35.9643
2017-07-02 13:27:11.036833 EDT | StdEsReturn                43.2637
2017-07-02 13:27:11.036953 EDT | MaxEsReturn               175
2017-07-02 13:27:11.037059 EDT | MinEsReturn                 3
2017-07-02 13:27:11.037171 EDT | AverageDiscountedReturn    99.9957
2017-07-02 13:27:11.037325 EDT | AverageQLoss                0.0467185
2017-07-02 13:27:11.037480 EDT | AveragePolicySurr          -3.05664
2017-07-02 13:27:11.037603 EDT | AverageQ                    2.75424
2017-07-02 13:27:11.037707 EDT | AverageAbsQ                 2.76214
2017-07-02 13:27:11.037820 EDT | AverageY                    2.75457
2017-07-02 13:27:11.038005 EDT | AverageAbsY                 2.75545
2017-07-02 13:27:11.038193 EDT | AverageAbsQYDiff            0.0818681
2017-07-02 13:27:11.038320 EDT | AverageAction               0.763259
2017-07-02 13:27:11.038426 EDT | PolicyRegParamNorm         44.911
2017-07-02 13:27:11.038529 EDT | QFunRegParamNorm           47.7219
2017-07-02 13:27:11.038703 EDT | -----------------------  ------------
2017-07-02 13:27:11.038953 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #238 | Training started
2017-07-02 13:27:20.514577 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #238 | Training finished
2017-07-02 13:27:20.515196 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #238 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 13:27:20.515448 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #238 | Collecting samples for evaluation
2017-07-02 13:27:26.219423 EDT | -----------------------  ------------
2017-07-02 13:27:26.219654 EDT | Epoch                     238
2017-07-02 13:27:26.219772 EDT | Iteration                 238
2017-07-02 13:27:26.219923 EDT | AverageReturn            1000
2017-07-02 13:27:26.220029 EDT | StdReturn                   0
2017-07-02 13:27:26.220159 EDT | MaxReturn                1000
2017-07-02 13:27:26.220262 EDT | MinReturn                1000
2017-07-02 13:27:26.220387 EDT | AverageEsReturn            28.5833
2017-07-02 13:27:26.220558 EDT | StdEsReturn                21.653
2017-07-02 13:27:26.220661 EDT | MaxEsReturn                97
2017-07-02 13:27:26.220795 EDT | MinEsReturn                 4
2017-07-02 13:27:26.220927 EDT | AverageDiscountedReturn    99.9957
2017-07-02 13:27:26.221036 EDT | AverageQLoss                0.0440548
2017-07-02 13:27:26.221153 EDT | AveragePolicySurr          -3.11486
2017-07-02 13:27:26.221269 EDT | AverageQ                    2.80947
2017-07-02 13:27:26.221374 EDT | AverageAbsQ                 2.81604
2017-07-02 13:27:26.221474 EDT | AverageY                    2.80974
2017-07-02 13:27:26.221610 EDT | AverageAbsY                 2.81073
2017-07-02 13:27:26.221714 EDT | AverageAbsQYDiff            0.079984
2017-07-02 13:27:26.221829 EDT | AverageAction               0.817599
2017-07-02 13:27:26.221930 EDT | PolicyRegParamNorm         45.0213
2017-07-02 13:27:26.222029 EDT | QFunRegParamNorm           47.872
2017-07-02 13:27:26.222165 EDT | -----------------------  ------------
2017-07-02 13:27:26.222331 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #239 | Training started
2017-07-02 13:27:35.784631 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #239 | Training finished
2017-07-02 13:27:35.785236 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #239 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 13:27:35.785419 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #239 | Collecting samples for evaluation
2017-07-02 13:27:41.439370 EDT | -----------------------  ------------
2017-07-02 13:27:41.439619 EDT | Epoch                     239
2017-07-02 13:27:41.439806 EDT | Iteration                 239
2017-07-02 13:27:41.440019 EDT | AverageReturn            1000
2017-07-02 13:27:41.440208 EDT | StdReturn                   0
2017-07-02 13:27:41.440326 EDT | MaxReturn                1000
2017-07-02 13:27:41.440489 EDT | MinReturn                1000
2017-07-02 13:27:41.440688 EDT | AverageEsReturn            35.6429
2017-07-02 13:27:41.440796 EDT | StdEsReturn                36.0696
2017-07-02 13:27:41.440898 EDT | MaxEsReturn               131
2017-07-02 13:27:41.440999 EDT | MinEsReturn                 3
2017-07-02 13:27:41.441126 EDT | AverageDiscountedReturn    99.9957
2017-07-02 13:27:41.441276 EDT | AverageQLoss                0.0446821
2017-07-02 13:27:41.441379 EDT | AveragePolicySurr          -3.15054
2017-07-02 13:27:41.441481 EDT | AverageQ                    2.84411
2017-07-02 13:27:41.442218 EDT | AverageAbsQ                 2.85207
2017-07-02 13:27:41.442373 EDT | AverageY                    2.84425
2017-07-02 13:27:41.442517 EDT | AverageAbsY                 2.84543
2017-07-02 13:27:41.442630 EDT | AverageAbsQYDiff            0.080403
2017-07-02 13:27:41.442757 EDT | AverageAction               0.651862
2017-07-02 13:27:41.442933 EDT | PolicyRegParamNorm         45.1471
2017-07-02 13:27:41.443096 EDT | QFunRegParamNorm           48.0146
2017-07-02 13:27:41.443287 EDT | -----------------------  ------------
2017-07-02 13:27:41.443542 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #240 | Training started
2017-07-02 13:27:51.014719 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #240 | Training finished
2017-07-02 13:27:51.015335 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #240 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 13:27:51.015511 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #240 | Collecting samples for evaluation
2017-07-02 13:27:56.653677 EDT | -----------------------  ------------
2017-07-02 13:27:56.653882 EDT | Epoch                     240
2017-07-02 13:27:56.653994 EDT | Iteration                 240
2017-07-02 13:27:56.654097 EDT | AverageReturn            1000
2017-07-02 13:27:56.654238 EDT | StdReturn                   0
2017-07-02 13:27:56.654342 EDT | MaxReturn                1000
2017-07-02 13:27:56.654444 EDT | MinReturn                1000
2017-07-02 13:27:56.654545 EDT | AverageEsReturn            24.0244
2017-07-02 13:27:56.654667 EDT | StdEsReturn                25.1187
2017-07-02 13:27:56.654861 EDT | MaxEsReturn               105
2017-07-02 13:27:56.655019 EDT | MinEsReturn                 4
2017-07-02 13:27:56.655120 EDT | AverageDiscountedReturn    99.9957
2017-07-02 13:27:56.655281 EDT | AverageQLoss                0.0446555
2017-07-02 13:27:56.655476 EDT | AveragePolicySurr          -3.18891
2017-07-02 13:27:56.655639 EDT | AverageQ                    2.88954
2017-07-02 13:27:56.655819 EDT | AverageAbsQ                 2.89707
2017-07-02 13:27:56.656002 EDT | AverageY                    2.88996
2017-07-02 13:27:56.656150 EDT | AverageAbsY                 2.89113
2017-07-02 13:27:56.656276 EDT | AverageAbsQYDiff            0.0801213
2017-07-02 13:27:56.656382 EDT | AverageAction               0.740401
2017-07-02 13:27:56.656523 EDT | PolicyRegParamNorm         45.202
2017-07-02 13:27:56.656642 EDT | QFunRegParamNorm           48.1131
2017-07-02 13:27:56.656744 EDT | -----------------------  ------------
2017-07-02 13:27:56.656905 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #241 | Training started
2017-07-02 13:28:06.233853 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #241 | Training finished
2017-07-02 13:28:06.234433 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #241 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 13:28:06.234641 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #241 | Collecting samples for evaluation
2017-07-02 13:28:11.978624 EDT | -----------------------  ------------
2017-07-02 13:28:11.978925 EDT | Epoch                     241
2017-07-02 13:28:11.979044 EDT | Iteration                 241
2017-07-02 13:28:11.979152 EDT | AverageReturn            1000
2017-07-02 13:28:11.979290 EDT | StdReturn                   0
2017-07-02 13:28:11.979478 EDT | MaxReturn                1000
2017-07-02 13:28:11.979655 EDT | MinReturn                1000
2017-07-02 13:28:11.979847 EDT | AverageEsReturn            23.975
2017-07-02 13:28:11.980054 EDT | StdEsReturn                21.0493
2017-07-02 13:28:11.980224 EDT | MaxEsReturn                99
2017-07-02 13:28:11.980393 EDT | MinEsReturn                 3
2017-07-02 13:28:11.980584 EDT | AverageDiscountedReturn    99.9957
2017-07-02 13:28:11.980784 EDT | AverageQLoss                0.0494648
2017-07-02 13:28:11.980954 EDT | AveragePolicySurr          -3.21688
2017-07-02 13:28:11.981156 EDT | AverageQ                    2.91835
2017-07-02 13:28:11.981358 EDT | AverageAbsQ                 2.92578
2017-07-02 13:28:11.981705 EDT | AverageY                    2.9183
2017-07-02 13:28:11.981895 EDT | AverageAbsY                 2.91914
2017-07-02 13:28:11.982046 EDT | AverageAbsQYDiff            0.0812868
2017-07-02 13:28:11.982175 EDT | AverageAction               0.820973
2017-07-02 13:28:11.982310 EDT | PolicyRegParamNorm         45.2878
2017-07-02 13:28:11.982414 EDT | QFunRegParamNorm           48.2818
2017-07-02 13:28:11.982517 EDT | -----------------------  ------------
2017-07-02 13:28:11.982703 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #242 | Training started
2017-07-02 13:28:21.566052 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #242 | Training finished
2017-07-02 13:28:21.566639 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #242 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 13:28:21.566901 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #242 | Collecting samples for evaluation
2017-07-02 13:28:27.337892 EDT | -----------------------  ------------
2017-07-02 13:28:27.338094 EDT | Epoch                     242
2017-07-02 13:28:27.338207 EDT | Iteration                 242
2017-07-02 13:28:27.338312 EDT | AverageReturn            1000
2017-07-02 13:28:27.338428 EDT | StdReturn                   0
2017-07-02 13:28:27.338534 EDT | MaxReturn                1000
2017-07-02 13:28:27.338637 EDT | MinReturn                1000
2017-07-02 13:28:27.338738 EDT | AverageEsReturn            36.8276
2017-07-02 13:28:27.338839 EDT | StdEsReturn                41.6977
2017-07-02 13:28:27.338939 EDT | MaxEsReturn               200
2017-07-02 13:28:27.339038 EDT | MinEsReturn                 4
2017-07-02 13:28:27.339138 EDT | AverageDiscountedReturn    99.9957
2017-07-02 13:28:27.339237 EDT | AverageQLoss                0.0436471
2017-07-02 13:28:27.339336 EDT | AveragePolicySurr          -3.25132
2017-07-02 13:28:27.339434 EDT | AverageQ                    2.94814
2017-07-02 13:28:27.339532 EDT | AverageAbsQ                 2.9553
2017-07-02 13:28:27.339631 EDT | AverageY                    2.9483
2017-07-02 13:28:27.339729 EDT | AverageAbsY                 2.94918
2017-07-02 13:28:27.339829 EDT | AverageAbsQYDiff            0.0789265
2017-07-02 13:28:27.339928 EDT | AverageAction               0.535833
2017-07-02 13:28:27.340037 EDT | PolicyRegParamNorm         45.3759
2017-07-02 13:28:27.340154 EDT | QFunRegParamNorm           48.4454
2017-07-02 13:28:27.340256 EDT | -----------------------  ------------
2017-07-02 13:28:27.340417 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #243 | Training started
2017-07-02 13:28:37.015870 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #243 | Training finished
2017-07-02 13:28:37.016654 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #243 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 13:28:37.016833 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #243 | Collecting samples for evaluation
2017-07-02 13:28:42.655979 EDT | -----------------------  ------------
2017-07-02 13:28:42.656584 EDT | Epoch                     243
2017-07-02 13:28:42.656856 EDT | Iteration                 243
2017-07-02 13:28:42.657151 EDT | AverageReturn            1000
2017-07-02 13:28:42.657305 EDT | StdReturn                   0
2017-07-02 13:28:42.657418 EDT | MaxReturn                1000
2017-07-02 13:28:42.657574 EDT | MinReturn                1000
2017-07-02 13:28:42.657769 EDT | AverageEsReturn            29.9394
2017-07-02 13:28:42.658020 EDT | StdEsReturn                29.8501
2017-07-02 13:28:42.658221 EDT | MaxEsReturn               106
2017-07-02 13:28:42.658390 EDT | MinEsReturn                 4
2017-07-02 13:28:42.658611 EDT | AverageDiscountedReturn    99.9957
2017-07-02 13:28:42.658846 EDT | AverageQLoss                0.0443331
2017-07-02 13:28:42.659026 EDT | AveragePolicySurr          -3.28102
2017-07-02 13:28:42.659250 EDT | AverageQ                    2.98114
2017-07-02 13:28:42.659482 EDT | AverageAbsQ                 2.98973
2017-07-02 13:28:42.659720 EDT | AverageY                    2.98152
2017-07-02 13:28:42.659920 EDT | AverageAbsY                 2.98233
2017-07-02 13:28:42.660127 EDT | AverageAbsQYDiff            0.0816602
2017-07-02 13:28:42.660365 EDT | AverageAction               0.890991
2017-07-02 13:28:42.660586 EDT | PolicyRegParamNorm         45.4851
2017-07-02 13:28:42.660818 EDT | QFunRegParamNorm           48.5631
2017-07-02 13:28:42.661054 EDT | -----------------------  ------------
2017-07-02 13:28:42.661317 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #244 | Training started
2017-07-02 13:28:52.362188 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #244 | Training finished
2017-07-02 13:28:52.363373 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #244 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 13:28:52.363558 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #244 | Collecting samples for evaluation
2017-07-02 13:28:57.999480 EDT | -----------------------  ------------
2017-07-02 13:28:57.999667 EDT | Epoch                     244
2017-07-02 13:28:57.999788 EDT | Iteration                 244
2017-07-02 13:28:57.999967 EDT | AverageReturn            1000
2017-07-02 13:28:58.000133 EDT | StdReturn                   0
2017-07-02 13:28:58.000304 EDT | MaxReturn                1000
2017-07-02 13:28:58.000433 EDT | MinReturn                1000
2017-07-02 13:28:58.000537 EDT | AverageEsReturn            23.9762
2017-07-02 13:28:58.000659 EDT | StdEsReturn                16.0557
2017-07-02 13:28:58.000800 EDT | MaxEsReturn                75
2017-07-02 13:28:58.000904 EDT | MinEsReturn                 3
2017-07-02 13:28:58.001005 EDT | AverageDiscountedReturn    99.9957
2017-07-02 13:28:58.001133 EDT | AverageQLoss                0.0488629
2017-07-02 13:28:58.001248 EDT | AveragePolicySurr          -3.31553
2017-07-02 13:28:58.001351 EDT | AverageQ                    3.02157
2017-07-02 13:28:58.001481 EDT | AverageAbsQ                 3.02842
2017-07-02 13:28:58.001730 EDT | AverageY                    3.02175
2017-07-02 13:28:58.001877 EDT | AverageAbsY                 3.02237
2017-07-02 13:28:58.002012 EDT | AverageAbsQYDiff            0.0792494
2017-07-02 13:28:58.002202 EDT | AverageAction               0.740438
2017-07-02 13:28:58.002341 EDT | PolicyRegParamNorm         45.5671
2017-07-02 13:28:58.002507 EDT | QFunRegParamNorm           48.6086
2017-07-02 13:28:58.002680 EDT | -----------------------  ------------
2017-07-02 13:28:58.002874 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #245 | Training started
2017-07-02 13:29:07.714795 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #245 | Training finished
2017-07-02 13:29:07.715478 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #245 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 13:29:07.715713 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #245 | Collecting samples for evaluation
2017-07-02 13:29:13.274272 EDT | -----------------------  ------------
2017-07-02 13:29:13.274552 EDT | Epoch                     245
2017-07-02 13:29:13.274773 EDT | Iteration                 245
2017-07-02 13:29:13.274980 EDT | AverageReturn            1000
2017-07-02 13:29:13.275214 EDT | StdReturn                   0
2017-07-02 13:29:13.275415 EDT | MaxReturn                1000
2017-07-02 13:29:13.275561 EDT | MinReturn                1000
2017-07-02 13:29:13.275725 EDT | AverageEsReturn            30.875
2017-07-02 13:29:13.275875 EDT | StdEsReturn                33.6867
2017-07-02 13:29:13.276027 EDT | MaxEsReturn               161
2017-07-02 13:29:13.276155 EDT | MinEsReturn                 4
2017-07-02 13:29:13.276281 EDT | AverageDiscountedReturn    99.9957
2017-07-02 13:29:13.276396 EDT | AverageQLoss                0.0463041
2017-07-02 13:29:13.276580 EDT | AveragePolicySurr          -3.34227
2017-07-02 13:29:13.276722 EDT | AverageQ                    3.038
2017-07-02 13:29:13.276824 EDT | AverageAbsQ                 3.04529
2017-07-02 13:29:13.276989 EDT | AverageY                    3.03823
2017-07-02 13:29:13.277098 EDT | AverageAbsY                 3.03903
2017-07-02 13:29:13.277221 EDT | AverageAbsQYDiff            0.0789733
2017-07-02 13:29:13.277358 EDT | AverageAction               0.675042
2017-07-02 13:29:13.277535 EDT | PolicyRegParamNorm         45.6923
2017-07-02 13:29:13.277642 EDT | QFunRegParamNorm           48.7063
2017-07-02 13:29:13.277754 EDT | -----------------------  ------------
2017-07-02 13:29:13.277922 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #246 | Training started
2017-07-02 13:29:22.983703 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #246 | Training finished
2017-07-02 13:29:22.984230 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #246 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 13:29:22.984398 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #246 | Collecting samples for evaluation
2017-07-02 13:29:28.644422 EDT | -----------------------  ------------
2017-07-02 13:29:28.644721 EDT | Epoch                     246
2017-07-02 13:29:28.644917 EDT | Iteration                 246
2017-07-02 13:29:28.645143 EDT | AverageReturn            1000
2017-07-02 13:29:28.645370 EDT | StdReturn                   0
2017-07-02 13:29:28.645616 EDT | MaxReturn                1000
2017-07-02 13:29:28.645834 EDT | MinReturn                1000
2017-07-02 13:29:28.645980 EDT | AverageEsReturn            24.3333
2017-07-02 13:29:28.646212 EDT | StdEsReturn                16.587
2017-07-02 13:29:28.646418 EDT | MaxEsReturn                65
2017-07-02 13:29:28.646654 EDT | MinEsReturn                 3
2017-07-02 13:29:28.646877 EDT | AverageDiscountedReturn    99.9957
2017-07-02 13:29:28.647097 EDT | AverageQLoss                0.0450118
2017-07-02 13:29:28.647243 EDT | AveragePolicySurr          -3.36294
2017-07-02 13:29:28.647477 EDT | AverageQ                    3.07505
2017-07-02 13:29:28.647701 EDT | AverageAbsQ                 3.08389
2017-07-02 13:29:28.647923 EDT | AverageY                    3.07527
2017-07-02 13:29:28.648150 EDT | AverageAbsY                 3.07736
2017-07-02 13:29:28.648351 EDT | AverageAbsQYDiff            0.0787437
2017-07-02 13:29:28.648554 EDT | AverageAction               0.625872
2017-07-02 13:29:28.648780 EDT | PolicyRegParamNorm         45.7302
2017-07-02 13:29:28.649002 EDT | QFunRegParamNorm           48.79
2017-07-02 13:29:28.649186 EDT | -----------------------  ------------
2017-07-02 13:29:28.649452 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #247 | Training started
2017-07-02 13:29:38.288797 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #247 | Training finished
2017-07-02 13:29:38.289417 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #247 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 13:29:38.289686 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #247 | Collecting samples for evaluation
2017-07-02 13:29:44.101730 EDT | -----------------------  ------------
2017-07-02 13:29:44.101954 EDT | Epoch                     247
2017-07-02 13:29:44.102068 EDT | Iteration                 247
2017-07-02 13:29:44.102285 EDT | AverageReturn            1000
2017-07-02 13:29:44.102499 EDT | StdReturn                   0
2017-07-02 13:29:44.102729 EDT | MaxReturn                1000
2017-07-02 13:29:44.102944 EDT | MinReturn                1000
2017-07-02 13:29:44.103174 EDT | AverageEsReturn            21.9778
2017-07-02 13:29:44.103403 EDT | StdEsReturn                19.5215
2017-07-02 13:29:44.103630 EDT | MaxEsReturn                78
2017-07-02 13:29:44.103849 EDT | MinEsReturn                 3
2017-07-02 13:29:44.104015 EDT | AverageDiscountedReturn    99.9957
2017-07-02 13:29:44.104241 EDT | AverageQLoss                0.0510881
2017-07-02 13:29:44.104457 EDT | AveragePolicySurr          -3.38577
2017-07-02 13:29:44.104696 EDT | AverageQ                    3.09766
2017-07-02 13:29:44.104923 EDT | AverageAbsQ                 3.10691
2017-07-02 13:29:44.105146 EDT | AverageY                    3.09765
2017-07-02 13:29:44.105341 EDT | AverageAbsY                 3.09935
2017-07-02 13:29:44.105668 EDT | AverageAbsQYDiff            0.0845685
2017-07-02 13:29:44.105888 EDT | AverageAction               0.80606
2017-07-02 13:29:44.106104 EDT | PolicyRegParamNorm         45.7661
2017-07-02 13:29:44.106322 EDT | QFunRegParamNorm           48.8324
2017-07-02 13:29:44.106616 EDT | -----------------------  ------------
2017-07-02 13:29:44.107012 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #248 | Training started
2017-07-02 13:29:53.705706 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #248 | Training finished
2017-07-02 13:29:53.706260 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #248 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 13:29:53.706480 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #248 | Collecting samples for evaluation
2017-07-02 13:29:59.374897 EDT | -----------------------  ------------
2017-07-02 13:29:59.375094 EDT | Epoch                     248
2017-07-02 13:29:59.375263 EDT | Iteration                 248
2017-07-02 13:29:59.375371 EDT | AverageReturn            1000
2017-07-02 13:29:59.375488 EDT | StdReturn                   0
2017-07-02 13:29:59.375716 EDT | MaxReturn                1000
2017-07-02 13:29:59.375952 EDT | MinReturn                1000
2017-07-02 13:29:59.376159 EDT | AverageEsReturn            28.7714
2017-07-02 13:29:59.376397 EDT | StdEsReturn                24.8597
2017-07-02 13:29:59.376603 EDT | MaxEsReturn               100
2017-07-02 13:29:59.376842 EDT | MinEsReturn                 4
2017-07-02 13:29:59.377075 EDT | AverageDiscountedReturn    99.9957
2017-07-02 13:29:59.377290 EDT | AverageQLoss                0.0485705
2017-07-02 13:29:59.377626 EDT | AveragePolicySurr          -3.40601
2017-07-02 13:29:59.377828 EDT | AverageQ                    3.12517
2017-07-02 13:29:59.378064 EDT | AverageAbsQ                 3.13377
2017-07-02 13:29:59.378303 EDT | AverageY                    3.12557
2017-07-02 13:29:59.378449 EDT | AverageAbsY                 3.12689
2017-07-02 13:29:59.378578 EDT | AverageAbsQYDiff            0.0809131
2017-07-02 13:29:59.378687 EDT | AverageAction               0.89244
2017-07-02 13:29:59.378795 EDT | PolicyRegParamNorm         45.8965
2017-07-02 13:29:59.378937 EDT | QFunRegParamNorm           48.9089
2017-07-02 13:29:59.379087 EDT | -----------------------  ------------
2017-07-02 13:29:59.379423 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #249 | Training started
2017-07-02 13:30:08.971953 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #249 | Training finished
2017-07-02 13:30:08.972813 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #249 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 13:30:08.972974 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #249 | Collecting samples for evaluation
2017-07-02 13:30:14.632829 EDT | -----------------------  ------------
2017-07-02 13:30:14.633140 EDT | Epoch                     249
2017-07-02 13:30:14.633345 EDT | Iteration                 249
2017-07-02 13:30:14.633587 EDT | AverageReturn            1000
2017-07-02 13:30:14.633813 EDT | StdReturn                   0
2017-07-02 13:30:14.634034 EDT | MaxReturn                1000
2017-07-02 13:30:14.634249 EDT | MinReturn                1000
2017-07-02 13:30:14.634434 EDT | AverageEsReturn            32.5484
2017-07-02 13:30:14.634653 EDT | StdEsReturn                25.8205
2017-07-02 13:30:14.634867 EDT | MaxEsReturn                91
2017-07-02 13:30:14.635089 EDT | MinEsReturn                 3
2017-07-02 13:30:14.635276 EDT | AverageDiscountedReturn    99.9957
2017-07-02 13:30:14.635498 EDT | AverageQLoss                0.0473568
2017-07-02 13:30:14.635659 EDT | AveragePolicySurr          -3.43237
2017-07-02 13:30:14.635846 EDT | AverageQ                    3.14167
2017-07-02 13:30:14.636067 EDT | AverageAbsQ                 3.14978
2017-07-02 13:30:14.636256 EDT | AverageY                    3.1417
2017-07-02 13:30:14.636363 EDT | AverageAbsY                 3.14301
2017-07-02 13:30:14.636466 EDT | AverageAbsQYDiff            0.0802345
2017-07-02 13:30:14.636567 EDT | AverageAction               0.70089
2017-07-02 13:30:14.636689 EDT | PolicyRegParamNorm         45.9885
2017-07-02 13:30:14.636905 EDT | QFunRegParamNorm           48.9715
2017-07-02 13:30:14.637120 EDT | -----------------------  ------------
2017-07-02 13:30:14.637431 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #250 | Training started
2017-07-02 13:30:24.827763 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #250 | Training finished
2017-07-02 13:30:24.828300 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #250 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 13:30:24.828558 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #250 | Collecting samples for evaluation
2017-07-02 13:30:30.381816 EDT | -----------------------  ------------
2017-07-02 13:30:30.382212 EDT | Epoch                     250
2017-07-02 13:30:30.382480 EDT | Iteration                 250
2017-07-02 13:30:30.382606 EDT | AverageReturn            1000
2017-07-02 13:30:30.382773 EDT | StdReturn                   0
2017-07-02 13:30:30.382930 EDT | MaxReturn                1000
2017-07-02 13:30:30.383059 EDT | MinReturn                1000
2017-07-02 13:30:30.383210 EDT | AverageEsReturn            26.0526
2017-07-02 13:30:30.383394 EDT | StdEsReturn                35.7078
2017-07-02 13:30:30.383594 EDT | MaxEsReturn               160
2017-07-02 13:30:30.383746 EDT | MinEsReturn                 2
2017-07-02 13:30:30.383891 EDT | AverageDiscountedReturn    99.9957
2017-07-02 13:30:30.383995 EDT | AverageQLoss                0.0566138
2017-07-02 13:30:30.384101 EDT | AveragePolicySurr          -3.44672
2017-07-02 13:30:30.384245 EDT | AverageQ                    3.17427
2017-07-02 13:30:30.384347 EDT | AverageAbsQ                 3.1837
2017-07-02 13:30:30.384448 EDT | AverageY                    3.17465
2017-07-02 13:30:30.384584 EDT | AverageAbsY                 3.17636
2017-07-02 13:30:30.384711 EDT | AverageAbsQYDiff            0.0861932
2017-07-02 13:30:30.384879 EDT | AverageAction               0.751109
2017-07-02 13:30:30.385045 EDT | PolicyRegParamNorm         46.1468
2017-07-02 13:30:30.385202 EDT | QFunRegParamNorm           49.0763
2017-07-02 13:30:30.385307 EDT | -----------------------  ------------
2017-07-02 13:30:30.385625 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #251 | Training started
2017-07-02 13:30:40.062020 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #251 | Training finished
2017-07-02 13:30:40.062571 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #251 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 13:30:40.062829 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #251 | Collecting samples for evaluation
2017-07-02 13:30:45.664688 EDT | -----------------------  ------------
2017-07-02 13:30:45.664928 EDT | Epoch                     251
2017-07-02 13:30:45.665099 EDT | Iteration                 251
2017-07-02 13:30:45.665248 EDT | AverageReturn            1000
2017-07-02 13:30:45.665408 EDT | StdReturn                   0
2017-07-02 13:30:45.665559 EDT | MaxReturn                1000
2017-07-02 13:30:45.665751 EDT | MinReturn                1000
2017-07-02 13:30:45.665909 EDT | AverageEsReturn            25.973
2017-07-02 13:30:45.666056 EDT | StdEsReturn                22.1804
2017-07-02 13:30:45.666182 EDT | MaxEsReturn               103
2017-07-02 13:30:45.666309 EDT | MinEsReturn                 3
2017-07-02 13:30:45.666514 EDT | AverageDiscountedReturn    99.9957
2017-07-02 13:30:45.666726 EDT | AverageQLoss                0.0461517
2017-07-02 13:30:45.666842 EDT | AveragePolicySurr          -3.4618
2017-07-02 13:30:45.666947 EDT | AverageQ                    3.18507
2017-07-02 13:30:45.667066 EDT | AverageAbsQ                 3.19261
2017-07-02 13:30:45.667184 EDT | AverageY                    3.18514
2017-07-02 13:30:45.667333 EDT | AverageAbsY                 3.18684
2017-07-02 13:30:45.667454 EDT | AverageAbsQYDiff            0.0776525
2017-07-02 13:30:45.667557 EDT | AverageAction               0.841522
2017-07-02 13:30:45.667658 EDT | PolicyRegParamNorm         46.2687
2017-07-02 13:30:45.667758 EDT | QFunRegParamNorm           49.1901
2017-07-02 13:30:45.667859 EDT | -----------------------  ------------
2017-07-02 13:30:45.668043 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #252 | Training started
2017-07-02 13:30:55.269538 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #252 | Training finished
2017-07-02 13:30:55.270401 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #252 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 13:30:55.270628 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #252 | Collecting samples for evaluation
2017-07-02 13:31:01.007810 EDT | -----------------------  ------------
2017-07-02 13:31:01.008013 EDT | Epoch                     252
2017-07-02 13:31:01.008168 EDT | Iteration                 252
2017-07-02 13:31:01.008313 EDT | AverageReturn            1000
2017-07-02 13:31:01.008424 EDT | StdReturn                   0
2017-07-02 13:31:01.008529 EDT | MaxReturn                1000
2017-07-02 13:31:01.008657 EDT | MinReturn                1000
2017-07-02 13:31:01.008786 EDT | AverageEsReturn            22.2826
2017-07-02 13:31:01.008889 EDT | StdEsReturn                17.8358
2017-07-02 13:31:01.009003 EDT | MaxEsReturn                82
2017-07-02 13:31:01.009117 EDT | MinEsReturn                 3
2017-07-02 13:31:01.009304 EDT | AverageDiscountedReturn    99.9957
2017-07-02 13:31:01.009693 EDT | AverageQLoss                0.0541853
2017-07-02 13:31:01.009883 EDT | AveragePolicySurr          -3.4616
2017-07-02 13:31:01.010035 EDT | AverageQ                    3.18787
2017-07-02 13:31:01.010237 EDT | AverageAbsQ                 3.19742
2017-07-02 13:31:01.010471 EDT | AverageY                    3.18821
2017-07-02 13:31:01.010677 EDT | AverageAbsY                 3.19002
2017-07-02 13:31:01.010882 EDT | AverageAbsQYDiff            0.0848001
2017-07-02 13:31:01.011119 EDT | AverageAction               0.814817
2017-07-02 13:31:01.011340 EDT | PolicyRegParamNorm         46.3469
2017-07-02 13:31:01.011559 EDT | QFunRegParamNorm           49.3264
2017-07-02 13:31:01.011763 EDT | -----------------------  ------------
2017-07-02 13:31:01.012084 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #253 | Training started
2017-07-02 13:31:10.484486 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #253 | Training finished
2017-07-02 13:31:10.485590 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #253 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 13:31:10.485897 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #253 | Collecting samples for evaluation
2017-07-02 13:31:16.242019 EDT | -----------------------  ------------
2017-07-02 13:31:16.242327 EDT | Epoch                     253
2017-07-02 13:31:16.242554 EDT | Iteration                 253
2017-07-02 13:31:16.242765 EDT | AverageReturn            1000
2017-07-02 13:31:16.242995 EDT | StdReturn                   0
2017-07-02 13:31:16.243196 EDT | MaxReturn                1000
2017-07-02 13:31:16.243434 EDT | MinReturn                1000
2017-07-02 13:31:16.243641 EDT | AverageEsReturn            30.9688
2017-07-02 13:31:16.243850 EDT | StdEsReturn                23.398
2017-07-02 13:31:16.244085 EDT | MaxEsReturn                91
2017-07-02 13:31:16.244220 EDT | MinEsReturn                 4
2017-07-02 13:31:16.244326 EDT | AverageDiscountedReturn    99.9957
2017-07-02 13:31:16.244428 EDT | AverageQLoss                0.0493313
2017-07-02 13:31:16.244562 EDT | AveragePolicySurr          -3.46941
2017-07-02 13:31:16.244790 EDT | AverageQ                    3.20149
2017-07-02 13:31:16.244993 EDT | AverageAbsQ                 3.21032
2017-07-02 13:31:16.245212 EDT | AverageY                    3.20144
2017-07-02 13:31:16.245441 EDT | AverageAbsY                 3.2036
2017-07-02 13:31:16.245951 EDT | AverageAbsQYDiff            0.0793875
2017-07-02 13:31:16.246131 EDT | AverageAction               0.801162
2017-07-02 13:31:16.246309 EDT | PolicyRegParamNorm         46.4783
2017-07-02 13:31:16.246473 EDT | QFunRegParamNorm           49.442
2017-07-02 13:31:16.246579 EDT | -----------------------  ------------
2017-07-02 13:31:16.246744 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #254 | Training started
2017-07-02 13:31:25.765916 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #254 | Training finished
2017-07-02 13:31:25.766516 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #254 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 13:31:25.766725 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #254 | Collecting samples for evaluation
2017-07-02 13:31:31.405921 EDT | -----------------------  ------------
2017-07-02 13:31:31.406190 EDT | Epoch                     254
2017-07-02 13:31:31.406361 EDT | Iteration                 254
2017-07-02 13:31:31.406510 EDT | AverageReturn            1000
2017-07-02 13:31:31.406628 EDT | StdReturn                   0
2017-07-02 13:31:31.406731 EDT | MaxReturn                1000
2017-07-02 13:31:31.406832 EDT | MinReturn                1000
2017-07-02 13:31:31.406931 EDT | AverageEsReturn            23.2727
2017-07-02 13:31:31.407073 EDT | StdEsReturn                19.7477
2017-07-02 13:31:31.407178 EDT | MaxEsReturn                89
2017-07-02 13:31:31.407278 EDT | MinEsReturn                 3
2017-07-02 13:31:31.407415 EDT | AverageDiscountedReturn    99.9957
2017-07-02 13:31:31.407569 EDT | AverageQLoss                0.0545488
2017-07-02 13:31:31.407675 EDT | AveragePolicySurr          -3.46444
2017-07-02 13:31:31.407833 EDT | AverageQ                    3.2066
2017-07-02 13:31:31.407938 EDT | AverageAbsQ                 3.21601
2017-07-02 13:31:31.408080 EDT | AverageY                    3.20687
2017-07-02 13:31:31.408183 EDT | AverageAbsY                 3.20911
2017-07-02 13:31:31.408283 EDT | AverageAbsQYDiff            0.0832847
2017-07-02 13:31:31.408391 EDT | AverageAction               0.631251
2017-07-02 13:31:31.408596 EDT | PolicyRegParamNorm         46.6728
2017-07-02 13:31:31.408722 EDT | QFunRegParamNorm           49.5432
2017-07-02 13:31:31.408826 EDT | -----------------------  ------------
2017-07-02 13:31:31.409077 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #255 | Training started
2017-07-02 13:31:40.945476 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #255 | Training finished
2017-07-02 13:31:40.946355 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #255 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 13:31:40.946709 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #255 | Collecting samples for evaluation
2017-07-02 13:31:46.654282 EDT | -----------------------  ------------
2017-07-02 13:31:46.654562 EDT | Epoch                     255
2017-07-02 13:31:46.654761 EDT | Iteration                 255
2017-07-02 13:31:46.654933 EDT | AverageReturn            1000
2017-07-02 13:31:46.655066 EDT | StdReturn                   0
2017-07-02 13:31:46.655247 EDT | MaxReturn                1000
2017-07-02 13:31:46.655406 EDT | MinReturn                1000
2017-07-02 13:31:46.655593 EDT | AverageEsReturn            19.5686
2017-07-02 13:31:46.655760 EDT | StdEsReturn                17.0101
2017-07-02 13:31:46.655865 EDT | MaxEsReturn                89
2017-07-02 13:31:46.655966 EDT | MinEsReturn                 3
2017-07-02 13:31:46.656066 EDT | AverageDiscountedReturn    99.9957
2017-07-02 13:31:46.656183 EDT | AverageQLoss                0.0492621
2017-07-02 13:31:46.656297 EDT | AveragePolicySurr          -3.4544
2017-07-02 13:31:46.656469 EDT | AverageQ                    3.20649
2017-07-02 13:31:46.656574 EDT | AverageAbsQ                 3.21596
2017-07-02 13:31:46.656741 EDT | AverageY                    3.20637
2017-07-02 13:31:46.656936 EDT | AverageAbsY                 3.20929
2017-07-02 13:31:46.657113 EDT | AverageAbsQYDiff            0.078396
2017-07-02 13:31:46.657234 EDT | AverageAction               0.74972
2017-07-02 13:31:46.657336 EDT | PolicyRegParamNorm         46.8601
2017-07-02 13:31:46.657466 EDT | QFunRegParamNorm           49.6074
2017-07-02 13:31:46.657679 EDT | -----------------------  ------------
2017-07-02 13:31:46.657858 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #256 | Training started
2017-07-02 13:31:56.257800 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #256 | Training finished
2017-07-02 13:31:56.258411 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #256 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 13:31:56.258579 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #256 | Collecting samples for evaluation
2017-07-02 13:32:01.937822 EDT | -----------------------  ------------
2017-07-02 13:32:01.938122 EDT | Epoch                     256
2017-07-02 13:32:01.938318 EDT | Iteration                 256
2017-07-02 13:32:01.938473 EDT | AverageReturn            1000
2017-07-02 13:32:01.938626 EDT | StdReturn                   0
2017-07-02 13:32:01.938731 EDT | MaxReturn                1000
2017-07-02 13:32:01.938835 EDT | MinReturn                1000
2017-07-02 13:32:01.939047 EDT | AverageEsReturn            27.2778
2017-07-02 13:32:01.939290 EDT | StdEsReturn                25.0717
2017-07-02 13:32:01.939517 EDT | MaxEsReturn               119
2017-07-02 13:32:01.939746 EDT | MinEsReturn                 4
2017-07-02 13:32:01.939970 EDT | AverageDiscountedReturn    99.9957
2017-07-02 13:32:01.940186 EDT | AverageQLoss                0.0553965
2017-07-02 13:32:01.940398 EDT | AveragePolicySurr          -3.45635
2017-07-02 13:32:01.940622 EDT | AverageQ                    3.20083
2017-07-02 13:32:01.940828 EDT | AverageAbsQ                 3.21097
2017-07-02 13:32:01.941066 EDT | AverageY                    3.20106
2017-07-02 13:32:01.941291 EDT | AverageAbsY                 3.20448
2017-07-02 13:32:01.941569 EDT | AverageAbsQYDiff            0.0832388
2017-07-02 13:32:01.941777 EDT | AverageAction               0.576601
2017-07-02 13:32:01.941996 EDT | PolicyRegParamNorm         47.0166
2017-07-02 13:32:01.942204 EDT | QFunRegParamNorm           49.6535
2017-07-02 13:32:01.942403 EDT | -----------------------  ------------
2017-07-02 13:32:01.942662 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #257 | Training started
2017-07-02 13:32:11.497119 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #257 | Training finished
2017-07-02 13:32:11.497658 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #257 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 13:32:11.497883 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #257 | Collecting samples for evaluation
2017-07-02 13:32:17.221288 EDT | -----------------------  ------------
2017-07-02 13:32:17.221627 EDT | Epoch                     257
2017-07-02 13:32:17.221750 EDT | Iteration                 257
2017-07-02 13:32:17.221855 EDT | AverageReturn            1000
2017-07-02 13:32:17.221957 EDT | StdReturn                   0
2017-07-02 13:32:17.222057 EDT | MaxReturn                1000
2017-07-02 13:32:17.222156 EDT | MinReturn                1000
2017-07-02 13:32:17.222253 EDT | AverageEsReturn            25.075
2017-07-02 13:32:17.222350 EDT | StdEsReturn                18.5814
2017-07-02 13:32:17.222447 EDT | MaxEsReturn                92
2017-07-02 13:32:17.222547 EDT | MinEsReturn                 5
2017-07-02 13:32:17.222648 EDT | AverageDiscountedReturn    99.9957
2017-07-02 13:32:17.222864 EDT | AverageQLoss                0.0497534
2017-07-02 13:32:17.223038 EDT | AveragePolicySurr          -3.45576
2017-07-02 13:32:17.223144 EDT | AverageQ                    3.19729
2017-07-02 13:32:17.223246 EDT | AverageAbsQ                 3.20696
2017-07-02 13:32:17.223346 EDT | AverageY                    3.19724
2017-07-02 13:32:17.223446 EDT | AverageAbsY                 3.20017
2017-07-02 13:32:17.223546 EDT | AverageAbsQYDiff            0.0790868
2017-07-02 13:32:17.223645 EDT | AverageAction               0.533423
2017-07-02 13:32:17.223745 EDT | PolicyRegParamNorm         47.2036
2017-07-02 13:32:17.223854 EDT | QFunRegParamNorm           49.7288
2017-07-02 13:32:17.224075 EDT | -----------------------  ------------
2017-07-02 13:32:17.224394 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #258 | Training started
2017-07-02 13:32:26.756168 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #258 | Training finished
2017-07-02 13:32:26.756731 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #258 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 13:32:26.756872 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #258 | Collecting samples for evaluation
2017-07-02 13:32:32.584888 EDT | -----------------------  ------------
2017-07-02 13:32:32.585264 EDT | Epoch                     258
2017-07-02 13:32:32.585531 EDT | Iteration                 258
2017-07-02 13:32:32.585791 EDT | AverageReturn            1000
2017-07-02 13:32:32.586068 EDT | StdReturn                   0
2017-07-02 13:32:32.586260 EDT | MaxReturn                1000
2017-07-02 13:32:32.586446 EDT | MinReturn                1000
2017-07-02 13:32:32.586572 EDT | AverageEsReturn            25.425
2017-07-02 13:32:32.586681 EDT | StdEsReturn                22.5409
2017-07-02 13:32:32.586815 EDT | MaxEsReturn               108
2017-07-02 13:32:32.587003 EDT | MinEsReturn                 3
2017-07-02 13:32:32.587188 EDT | AverageDiscountedReturn    99.9957
2017-07-02 13:32:32.587383 EDT | AverageQLoss                0.0461746
2017-07-02 13:32:32.587511 EDT | AveragePolicySurr          -3.47259
2017-07-02 13:32:32.587615 EDT | AverageQ                    3.21759
2017-07-02 13:32:32.587757 EDT | AverageAbsQ                 3.22629
2017-07-02 13:32:32.587865 EDT | AverageY                    3.21758
2017-07-02 13:32:32.587966 EDT | AverageAbsY                 3.22007
2017-07-02 13:32:32.588067 EDT | AverageAbsQYDiff            0.0749808
2017-07-02 13:32:32.588198 EDT | AverageAction               0.513474
2017-07-02 13:32:32.588391 EDT | PolicyRegParamNorm         47.3298
2017-07-02 13:32:32.588577 EDT | QFunRegParamNorm           49.7914
2017-07-02 13:32:32.588706 EDT | -----------------------  ------------
2017-07-02 13:32:32.588880 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #259 | Training started
2017-07-02 13:32:42.044989 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #259 | Training finished
2017-07-02 13:32:42.045496 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #259 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 13:32:42.045668 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #259 | Collecting samples for evaluation
2017-07-02 13:32:47.745110 EDT | -----------------------  ------------
2017-07-02 13:32:47.745310 EDT | Epoch                     259
2017-07-02 13:32:47.745421 EDT | Iteration                 259
2017-07-02 13:32:47.745657 EDT | AverageReturn            1000
2017-07-02 13:32:47.745828 EDT | StdReturn                   0
2017-07-02 13:32:47.745959 EDT | MaxReturn                1000
2017-07-02 13:32:47.746151 EDT | MinReturn                1000
2017-07-02 13:32:47.746283 EDT | AverageEsReturn            27.1944
2017-07-02 13:32:47.746411 EDT | StdEsReturn                33.5558
2017-07-02 13:32:47.746564 EDT | MaxEsReturn               176
2017-07-02 13:32:47.746686 EDT | MinEsReturn                 3
2017-07-02 13:32:47.746793 EDT | AverageDiscountedReturn    99.9957
2017-07-02 13:32:47.746899 EDT | AverageQLoss                0.0523279
2017-07-02 13:32:47.747071 EDT | AveragePolicySurr          -3.47012
2017-07-02 13:32:47.747180 EDT | AverageQ                    3.20554
2017-07-02 13:32:47.747293 EDT | AverageAbsQ                 3.21569
2017-07-02 13:32:47.747528 EDT | AverageY                    3.20582
2017-07-02 13:32:47.747781 EDT | AverageAbsY                 3.20787
2017-07-02 13:32:47.747915 EDT | AverageAbsQYDiff            0.0794973
2017-07-02 13:32:47.748129 EDT | AverageAction               0.339153
2017-07-02 13:32:47.748348 EDT | PolicyRegParamNorm         47.3747
2017-07-02 13:32:47.748685 EDT | QFunRegParamNorm           49.8485
2017-07-02 13:32:47.748898 EDT | -----------------------  ------------
2017-07-02 13:32:47.749201 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #260 | Training started
2017-07-02 13:32:57.242835 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #260 | Training finished
2017-07-02 13:32:57.243347 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #260 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 13:32:57.243487 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #260 | Collecting samples for evaluation
2017-07-02 13:33:02.948220 EDT | -----------------------  ------------
2017-07-02 13:33:02.948495 EDT | Epoch                     260
2017-07-02 13:33:02.948617 EDT | Iteration                 260
2017-07-02 13:33:02.948801 EDT | AverageReturn            1000
2017-07-02 13:33:02.948919 EDT | StdReturn                   0
2017-07-02 13:33:02.949027 EDT | MaxReturn                1000
2017-07-02 13:33:02.949137 EDT | MinReturn                1000
2017-07-02 13:33:02.949243 EDT | AverageEsReturn            27.1081
2017-07-02 13:33:02.949348 EDT | StdEsReturn                29.8318
2017-07-02 13:33:02.949484 EDT | MaxEsReturn               156
2017-07-02 13:33:02.949638 EDT | MinEsReturn                 3
2017-07-02 13:33:02.949838 EDT | AverageDiscountedReturn    99.9957
2017-07-02 13:33:02.950048 EDT | AverageQLoss                0.0460484
2017-07-02 13:33:02.950248 EDT | AveragePolicySurr          -3.47601
2017-07-02 13:33:02.950369 EDT | AverageQ                    3.21551
2017-07-02 13:33:02.950477 EDT | AverageAbsQ                 3.22485
2017-07-02 13:33:02.950583 EDT | AverageY                    3.2155
2017-07-02 13:33:02.950688 EDT | AverageAbsY                 3.21774
2017-07-02 13:33:02.950830 EDT | AverageAbsQYDiff            0.0745087
2017-07-02 13:33:02.950936 EDT | AverageAction               0.159653
2017-07-02 13:33:02.951102 EDT | PolicyRegParamNorm         47.4213
2017-07-02 13:33:02.951234 EDT | QFunRegParamNorm           49.9183
2017-07-02 13:33:02.951349 EDT | -----------------------  ------------
2017-07-02 13:33:02.951538 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #261 | Training started
2017-07-02 13:33:12.488254 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #261 | Training finished
2017-07-02 13:33:12.488980 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #261 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 13:33:12.489225 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #261 | Collecting samples for evaluation
2017-07-02 13:33:18.109462 EDT | -----------------------  ------------
2017-07-02 13:33:18.109861 EDT | Epoch                     261
2017-07-02 13:33:18.110102 EDT | Iteration                 261
2017-07-02 13:33:18.110274 EDT | AverageReturn            1000
2017-07-02 13:33:18.110382 EDT | StdReturn                   0
2017-07-02 13:33:18.110522 EDT | MaxReturn                1000
2017-07-02 13:33:18.110629 EDT | MinReturn                1000
2017-07-02 13:33:18.110779 EDT | AverageEsReturn            36.3571
2017-07-02 13:33:18.110994 EDT | StdEsReturn                25.6755
2017-07-02 13:33:18.111154 EDT | MaxEsReturn               104
2017-07-02 13:33:18.111269 EDT | MinEsReturn                 3
2017-07-02 13:33:18.111396 EDT | AverageDiscountedReturn    99.9957
2017-07-02 13:33:18.111620 EDT | AverageQLoss                0.0499048
2017-07-02 13:33:18.111833 EDT | AveragePolicySurr          -3.47898
2017-07-02 13:33:18.112073 EDT | AverageQ                    3.21489
2017-07-02 13:33:18.112299 EDT | AverageAbsQ                 3.22473
2017-07-02 13:33:18.112523 EDT | AverageY                    3.21486
2017-07-02 13:33:18.112740 EDT | AverageAbsY                 3.21684
2017-07-02 13:33:18.112892 EDT | AverageAbsQYDiff            0.0761401
2017-07-02 13:33:18.113115 EDT | AverageAction               0.153677
2017-07-02 13:33:18.113297 EDT | PolicyRegParamNorm         47.5235
2017-07-02 13:33:18.113431 EDT | QFunRegParamNorm           49.9983
2017-07-02 13:33:18.113568 EDT | -----------------------  ------------
2017-07-02 13:33:18.113767 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #262 | Training started
2017-07-02 13:33:27.666629 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #262 | Training finished
2017-07-02 13:33:27.667170 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #262 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 13:33:27.667377 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #262 | Collecting samples for evaluation
2017-07-02 13:33:33.365525 EDT | -----------------------  ------------
2017-07-02 13:33:33.365747 EDT | Epoch                     262
2017-07-02 13:33:33.365859 EDT | Iteration                 262
2017-07-02 13:33:33.365992 EDT | AverageReturn            1000
2017-07-02 13:33:33.366097 EDT | StdReturn                   0
2017-07-02 13:33:33.366210 EDT | MaxReturn                1000
2017-07-02 13:33:33.366339 EDT | MinReturn                1000
2017-07-02 13:33:33.366447 EDT | AverageEsReturn            30.5152
2017-07-02 13:33:33.366554 EDT | StdEsReturn                29.5862
2017-07-02 13:33:33.366696 EDT | MaxEsReturn               128
2017-07-02 13:33:33.366804 EDT | MinEsReturn                 3
2017-07-02 13:33:33.366910 EDT | AverageDiscountedReturn    99.9957
2017-07-02 13:33:33.367016 EDT | AverageQLoss                0.0567775
2017-07-02 13:33:33.367121 EDT | AveragePolicySurr          -3.49106
2017-07-02 13:33:33.367299 EDT | AverageQ                    3.22335
2017-07-02 13:33:33.367414 EDT | AverageAbsQ                 3.23286
2017-07-02 13:33:33.367556 EDT | AverageY                    3.22318
2017-07-02 13:33:33.367747 EDT | AverageAbsY                 3.22564
2017-07-02 13:33:33.367897 EDT | AverageAbsQYDiff            0.0809962
2017-07-02 13:33:33.368079 EDT | AverageAction               0.267716
2017-07-02 13:33:33.368259 EDT | PolicyRegParamNorm         47.6372
2017-07-02 13:33:33.368364 EDT | QFunRegParamNorm           50.0264
2017-07-02 13:33:33.368494 EDT | -----------------------  ------------
2017-07-02 13:33:33.368844 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #263 | Training started
2017-07-02 13:33:42.818104 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #263 | Training finished
2017-07-02 13:33:42.818703 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #263 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 13:33:42.818849 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #263 | Collecting samples for evaluation
2017-07-02 13:33:48.666514 EDT | -----------------------  ------------
2017-07-02 13:33:48.666757 EDT | Epoch                     263
2017-07-02 13:33:48.666914 EDT | Iteration                 263
2017-07-02 13:33:48.667058 EDT | AverageReturn            1000
2017-07-02 13:33:48.667187 EDT | StdReturn                   0
2017-07-02 13:33:48.667365 EDT | MaxReturn                1000
2017-07-02 13:33:48.667513 EDT | MinReturn                1000
2017-07-02 13:33:48.667715 EDT | AverageEsReturn            25.8919
2017-07-02 13:33:48.667848 EDT | StdEsReturn                26.1242
2017-07-02 13:33:48.667969 EDT | MaxEsReturn               123
2017-07-02 13:33:48.668073 EDT | MinEsReturn                 3
2017-07-02 13:33:48.668215 EDT | AverageDiscountedReturn    99.9957
2017-07-02 13:33:48.668324 EDT | AverageQLoss                0.0536234
2017-07-02 13:33:48.668451 EDT | AveragePolicySurr          -3.50141
2017-07-02 13:33:48.668637 EDT | AverageQ                    3.24447
2017-07-02 13:33:48.668815 EDT | AverageAbsQ                 3.25348
2017-07-02 13:33:48.668918 EDT | AverageY                    3.24489
2017-07-02 13:33:48.669035 EDT | AverageAbsY                 3.24701
2017-07-02 13:33:48.669199 EDT | AverageAbsQYDiff            0.0784138
2017-07-02 13:33:48.669302 EDT | AverageAction               0.175942
2017-07-02 13:33:48.669403 EDT | PolicyRegParamNorm         47.7277
2017-07-02 13:33:48.669833 EDT | QFunRegParamNorm           50.1042
2017-07-02 13:33:48.670079 EDT | -----------------------  ------------
2017-07-02 13:33:48.670468 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #264 | Training started
2017-07-02 13:33:58.047400 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #264 | Training finished
2017-07-02 13:33:58.047962 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #264 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 13:33:58.048127 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #264 | Collecting samples for evaluation
2017-07-02 13:34:03.905017 EDT | -----------------------  ------------
2017-07-02 13:34:03.905217 EDT | Epoch                     264
2017-07-02 13:34:03.905414 EDT | Iteration                 264
2017-07-02 13:34:03.905654 EDT | AverageReturn            1000
2017-07-02 13:34:03.905881 EDT | StdReturn                   0
2017-07-02 13:34:03.906110 EDT | MaxReturn                1000
2017-07-02 13:34:03.906325 EDT | MinReturn                1000
2017-07-02 13:34:03.906542 EDT | AverageEsReturn            35.0357
2017-07-02 13:34:03.906765 EDT | StdEsReturn                30.1904
2017-07-02 13:34:03.906986 EDT | MaxEsReturn               112
2017-07-02 13:34:03.907198 EDT | MinEsReturn                 3
2017-07-02 13:34:03.907352 EDT | AverageDiscountedReturn    99.9957
2017-07-02 13:34:03.907579 EDT | AverageQLoss                0.0481341
2017-07-02 13:34:03.907724 EDT | AveragePolicySurr          -3.49466
2017-07-02 13:34:03.907953 EDT | AverageQ                    3.24223
2017-07-02 13:34:03.908174 EDT | AverageAbsQ                 3.25128
2017-07-02 13:34:03.908288 EDT | AverageY                    3.24204
2017-07-02 13:34:03.908446 EDT | AverageAbsY                 3.24393
2017-07-02 13:34:03.908621 EDT | AverageAbsQYDiff            0.0747111
2017-07-02 13:34:03.908818 EDT | AverageAction               0.111945
2017-07-02 13:34:03.909043 EDT | PolicyRegParamNorm         47.7443
2017-07-02 13:34:03.909260 EDT | QFunRegParamNorm           50.1543
2017-07-02 13:34:03.909533 EDT | -----------------------  ------------
2017-07-02 13:34:03.909866 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #265 | Training started
2017-07-02 13:34:13.217201 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #265 | Training finished
2017-07-02 13:34:13.218109 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #265 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 13:34:13.218419 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #265 | Collecting samples for evaluation
2017-07-02 13:34:19.050521 EDT | -----------------------  ------------
2017-07-02 13:34:19.050819 EDT | Epoch                     265
2017-07-02 13:34:19.051051 EDT | Iteration                 265
2017-07-02 13:34:19.051271 EDT | AverageReturn            1000
2017-07-02 13:34:19.051425 EDT | StdReturn                   0
2017-07-02 13:34:19.051539 EDT | MaxReturn                1000
2017-07-02 13:34:19.051675 EDT | MinReturn                1000
2017-07-02 13:34:19.051779 EDT | AverageEsReturn            24.6905
2017-07-02 13:34:19.051929 EDT | StdEsReturn                22.6763
2017-07-02 13:34:19.052061 EDT | MaxEsReturn                97
2017-07-02 13:34:19.052164 EDT | MinEsReturn                 3
2017-07-02 13:34:19.052266 EDT | AverageDiscountedReturn    99.9957
2017-07-02 13:34:19.052407 EDT | AverageQLoss                0.0510791
2017-07-02 13:34:19.052557 EDT | AveragePolicySurr          -3.49429
2017-07-02 13:34:19.052661 EDT | AverageQ                    3.23504
2017-07-02 13:34:19.052850 EDT | AverageAbsQ                 3.24418
2017-07-02 13:34:19.052958 EDT | AverageY                    3.23529
2017-07-02 13:34:19.053070 EDT | AverageAbsY                 3.23717
2017-07-02 13:34:19.053242 EDT | AverageAbsQYDiff            0.0750525
2017-07-02 13:34:19.053350 EDT | AverageAction               0.14122
2017-07-02 13:34:19.053452 EDT | PolicyRegParamNorm         47.7815
2017-07-02 13:34:19.053640 EDT | QFunRegParamNorm           50.272
2017-07-02 13:34:19.053808 EDT | -----------------------  ------------
2017-07-02 13:34:19.054061 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #266 | Training started
2017-07-02 13:34:28.491391 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #266 | Training finished
2017-07-02 13:34:28.492195 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #266 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 13:34:28.492401 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #266 | Collecting samples for evaluation
2017-07-02 13:34:34.200499 EDT | -----------------------  ------------
2017-07-02 13:34:34.200740 EDT | Epoch                     266
2017-07-02 13:34:34.200882 EDT | Iteration                 266
2017-07-02 13:34:34.201098 EDT | AverageReturn            1000
2017-07-02 13:34:34.201382 EDT | StdReturn                   0
2017-07-02 13:34:34.201600 EDT | MaxReturn                1000
2017-07-02 13:34:34.201768 EDT | MinReturn                1000
2017-07-02 13:34:34.201920 EDT | AverageEsReturn            28.1111
2017-07-02 13:34:34.202032 EDT | StdEsReturn                28.3508
2017-07-02 13:34:34.202163 EDT | MaxEsReturn               140
2017-07-02 13:34:34.202265 EDT | MinEsReturn                 3
2017-07-02 13:34:34.202374 EDT | AverageDiscountedReturn    99.9957
2017-07-02 13:34:34.202528 EDT | AverageQLoss                0.0474844
2017-07-02 13:34:34.202662 EDT | AveragePolicySurr          -3.49251
2017-07-02 13:34:34.202793 EDT | AverageQ                    3.23495
2017-07-02 13:34:34.202983 EDT | AverageAbsQ                 3.24454
2017-07-02 13:34:34.203123 EDT | AverageY                    3.23522
2017-07-02 13:34:34.203275 EDT | AverageAbsY                 3.23672
2017-07-02 13:34:34.203381 EDT | AverageAbsQYDiff            0.0737976
2017-07-02 13:34:34.203524 EDT | AverageAction               0.155821
2017-07-02 13:34:34.203629 EDT | PolicyRegParamNorm         47.8824
2017-07-02 13:34:34.203731 EDT | QFunRegParamNorm           50.3824
2017-07-02 13:34:34.203830 EDT | -----------------------  ------------
2017-07-02 13:34:34.204017 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #267 | Training started
2017-07-02 13:34:43.998535 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #267 | Training finished
2017-07-02 13:34:43.999038 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #267 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 13:34:43.999183 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #267 | Collecting samples for evaluation
2017-07-02 13:34:49.718967 EDT | -----------------------  ------------
2017-07-02 13:34:49.719215 EDT | Epoch                     267
2017-07-02 13:34:49.719355 EDT | Iteration                 267
2017-07-02 13:34:49.719468 EDT | AverageReturn            1000
2017-07-02 13:34:49.719584 EDT | StdReturn                   0
2017-07-02 13:34:49.719722 EDT | MaxReturn                1000
2017-07-02 13:34:49.719865 EDT | MinReturn                1000
2017-07-02 13:34:49.720002 EDT | AverageEsReturn            30.3939
2017-07-02 13:34:49.720130 EDT | StdEsReturn                25.7128
2017-07-02 13:34:49.720277 EDT | MaxEsReturn                87
2017-07-02 13:34:49.720382 EDT | MinEsReturn                 3
2017-07-02 13:34:49.720589 EDT | AverageDiscountedReturn    99.9957
2017-07-02 13:34:49.720809 EDT | AverageQLoss                0.0450411
2017-07-02 13:34:49.721034 EDT | AveragePolicySurr          -3.49804
2017-07-02 13:34:49.721261 EDT | AverageQ                    3.24565
2017-07-02 13:34:49.721435 EDT | AverageAbsQ                 3.25409
2017-07-02 13:34:49.721677 EDT | AverageY                    3.24548
2017-07-02 13:34:49.721837 EDT | AverageAbsY                 3.24687
2017-07-02 13:34:49.722033 EDT | AverageAbsQYDiff            0.0720942
2017-07-02 13:34:49.722162 EDT | AverageAction               0.0539034
2017-07-02 13:34:49.722389 EDT | PolicyRegParamNorm         47.956
2017-07-02 13:34:49.722618 EDT | QFunRegParamNorm           50.4282
2017-07-02 13:34:49.722824 EDT | -----------------------  ------------
2017-07-02 13:34:49.723159 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #268 | Training started
2017-07-02 13:34:59.364988 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #268 | Training finished
2017-07-02 13:34:59.365522 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #268 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 13:34:59.365775 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #268 | Collecting samples for evaluation
2017-07-02 13:35:04.961304 EDT | -----------------------  ------------
2017-07-02 13:35:04.961516 EDT | Epoch                     268
2017-07-02 13:35:04.961631 EDT | Iteration                 268
2017-07-02 13:35:04.961737 EDT | AverageReturn            1000
2017-07-02 13:35:04.961863 EDT | StdReturn                   0
2017-07-02 13:35:04.962032 EDT | MaxReturn                1000
2017-07-02 13:35:04.962185 EDT | MinReturn                1000
2017-07-02 13:35:04.962327 EDT | AverageEsReturn            44.4211
2017-07-02 13:35:04.962433 EDT | StdEsReturn                52.6051
2017-07-02 13:35:04.962534 EDT | MaxEsReturn               233
2017-07-02 13:35:04.962636 EDT | MinEsReturn                 3
2017-07-02 13:35:04.962736 EDT | AverageDiscountedReturn    99.9957
2017-07-02 13:35:04.962835 EDT | AverageQLoss                0.0473016
2017-07-02 13:35:04.962959 EDT | AveragePolicySurr          -3.49188
2017-07-02 13:35:04.963092 EDT | AverageQ                    3.23986
2017-07-02 13:35:04.963267 EDT | AverageAbsQ                 3.24788
2017-07-02 13:35:04.963440 EDT | AverageY                    3.23994
2017-07-02 13:35:04.963628 EDT | AverageAbsY                 3.2408
2017-07-02 13:35:04.963766 EDT | AverageAbsQYDiff            0.0711696
2017-07-02 13:35:04.963972 EDT | AverageAction               0.0547987
2017-07-02 13:35:04.964175 EDT | PolicyRegParamNorm         48.046
2017-07-02 13:35:04.964384 EDT | QFunRegParamNorm           50.5271
2017-07-02 13:35:04.964584 EDT | -----------------------  ------------
2017-07-02 13:35:04.964865 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #269 | Training started
2017-07-02 13:35:14.565633 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #269 | Training finished
2017-07-02 13:35:14.566177 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #269 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 13:35:14.566405 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #269 | Collecting samples for evaluation
2017-07-02 13:35:20.564550 EDT | -----------------------  ------------
2017-07-02 13:35:20.564817 EDT | Epoch                     269
2017-07-02 13:35:20.564977 EDT | Iteration                 269
2017-07-02 13:35:20.565139 EDT | AverageReturn            1000
2017-07-02 13:35:20.565283 EDT | StdReturn                   0
2017-07-02 13:35:20.565418 EDT | MaxReturn                1000
2017-07-02 13:35:20.565592 EDT | MinReturn                1000
2017-07-02 13:35:20.565869 EDT | AverageEsReturn            38
2017-07-02 13:35:20.566126 EDT | StdEsReturn                37.9886
2017-07-02 13:35:20.566280 EDT | MaxEsReturn               169
2017-07-02 13:35:20.566428 EDT | MinEsReturn                 3
2017-07-02 13:35:20.566663 EDT | AverageDiscountedReturn    99.9957
2017-07-02 13:35:20.566944 EDT | AverageQLoss                0.0464146
2017-07-02 13:35:20.567207 EDT | AveragePolicySurr          -3.48172
2017-07-02 13:35:20.567417 EDT | AverageQ                    3.22369
2017-07-02 13:35:20.567578 EDT | AverageAbsQ                 3.23211
2017-07-02 13:35:20.567708 EDT | AverageY                    3.22381
2017-07-02 13:35:20.567835 EDT | AverageAbsY                 3.22538
2017-07-02 13:35:20.568043 EDT | AverageAbsQYDiff            0.0689841
2017-07-02 13:35:20.568246 EDT | AverageAction               0.0742882
2017-07-02 13:35:20.568431 EDT | PolicyRegParamNorm         48.0638
2017-07-02 13:35:20.568618 EDT | QFunRegParamNorm           50.584
2017-07-02 13:35:20.568745 EDT | -----------------------  ------------
2017-07-02 13:35:20.569018 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #270 | Training started
2017-07-02 13:35:30.354879 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #270 | Training finished
2017-07-02 13:35:30.355387 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #270 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 13:35:30.355586 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #270 | Collecting samples for evaluation
2017-07-02 13:35:36.071038 EDT | -----------------------  --------------
2017-07-02 13:35:36.071301 EDT | Epoch                     270
2017-07-02 13:35:36.071479 EDT | Iteration                 270
2017-07-02 13:35:36.071588 EDT | AverageReturn            1000
2017-07-02 13:35:36.071700 EDT | StdReturn                   0
2017-07-02 13:35:36.071801 EDT | MaxReturn                1000
2017-07-02 13:35:36.071903 EDT | MinReturn                1000
2017-07-02 13:35:36.072041 EDT | AverageEsReturn            25.0244
2017-07-02 13:35:36.072156 EDT | StdEsReturn                21.5355
2017-07-02 13:35:36.072259 EDT | MaxEsReturn                81
2017-07-02 13:35:36.072361 EDT | MinEsReturn                 3
2017-07-02 13:35:36.072499 EDT | AverageDiscountedReturn    99.9957
2017-07-02 13:35:36.072618 EDT | AverageQLoss                0.047398
2017-07-02 13:35:36.072723 EDT | AveragePolicySurr          -3.4772
2017-07-02 13:35:36.072824 EDT | AverageQ                    3.22512
2017-07-02 13:35:36.073018 EDT | AverageAbsQ                 3.23408
2017-07-02 13:35:36.073217 EDT | AverageY                    3.22534
2017-07-02 13:35:36.073354 EDT | AverageAbsY                 3.22688
2017-07-02 13:35:36.073648 EDT | AverageAbsQYDiff            0.0686328
2017-07-02 13:35:36.073828 EDT | AverageAction               0.000236524
2017-07-02 13:35:36.073941 EDT | PolicyRegParamNorm         48.1451
2017-07-02 13:35:36.074046 EDT | QFunRegParamNorm           50.612
2017-07-02 13:35:36.074185 EDT | -----------------------  --------------
2017-07-02 13:35:36.074431 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #271 | Training started
2017-07-02 13:35:45.625798 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #271 | Training finished
2017-07-02 13:35:45.626383 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #271 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 13:35:45.626541 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #271 | Collecting samples for evaluation
2017-07-02 13:35:51.338330 EDT | -----------------------  ------------
2017-07-02 13:35:51.338536 EDT | Epoch                     271
2017-07-02 13:35:51.338649 EDT | Iteration                 271
2017-07-02 13:35:51.338854 EDT | AverageReturn            1000
2017-07-02 13:35:51.339033 EDT | StdReturn                   0
2017-07-02 13:35:51.339240 EDT | MaxReturn                1000
2017-07-02 13:35:51.339454 EDT | MinReturn                1000
2017-07-02 13:35:51.339681 EDT | AverageEsReturn            32.4
2017-07-02 13:35:51.339910 EDT | StdEsReturn                33.0974
2017-07-02 13:35:51.340120 EDT | MaxEsReturn               173
2017-07-02 13:35:51.340340 EDT | MinEsReturn                 3
2017-07-02 13:35:51.340540 EDT | AverageDiscountedReturn    99.9957
2017-07-02 13:35:51.340659 EDT | AverageQLoss                0.044645
2017-07-02 13:35:51.340889 EDT | AveragePolicySurr          -3.4742
2017-07-02 13:35:51.341060 EDT | AverageQ                    3.22122
2017-07-02 13:35:51.341167 EDT | AverageAbsQ                 3.22964
2017-07-02 13:35:51.341364 EDT | AverageY                    3.22113
2017-07-02 13:35:51.341687 EDT | AverageAbsY                 3.22216
2017-07-02 13:35:51.341807 EDT | AverageAbsQYDiff            0.0673024
2017-07-02 13:35:51.341911 EDT | AverageAction               0.0509644
2017-07-02 13:35:51.342026 EDT | PolicyRegParamNorm         48.1655
2017-07-02 13:35:51.342148 EDT | QFunRegParamNorm           50.619
2017-07-02 13:35:51.342250 EDT | -----------------------  ------------
2017-07-02 13:35:51.342416 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #272 | Training started
2017-07-02 13:36:00.970205 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #272 | Training finished
2017-07-02 13:36:00.970763 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #272 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 13:36:00.970967 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #272 | Collecting samples for evaluation
2017-07-02 13:36:06.695271 EDT | -----------------------  ------------
2017-07-02 13:36:06.695586 EDT | Epoch                     272
2017-07-02 13:36:06.695785 EDT | Iteration                 272
2017-07-02 13:36:06.695899 EDT | AverageReturn            1000
2017-07-02 13:36:06.696073 EDT | StdReturn                   0
2017-07-02 13:36:06.696286 EDT | MaxReturn                1000
2017-07-02 13:36:06.696501 EDT | MinReturn                1000
2017-07-02 13:36:06.696717 EDT | AverageEsReturn            22.9524
2017-07-02 13:36:06.696937 EDT | StdEsReturn                19.2353
2017-07-02 13:36:06.697140 EDT | MaxEsReturn                85
2017-07-02 13:36:06.697374 EDT | MinEsReturn                 3
2017-07-02 13:36:06.697654 EDT | AverageDiscountedReturn    99.9957
2017-07-02 13:36:06.697887 EDT | AverageQLoss                0.0472344
2017-07-02 13:36:06.698110 EDT | AveragePolicySurr          -3.46001
2017-07-02 13:36:06.698332 EDT | AverageQ                    3.21789
2017-07-02 13:36:06.698553 EDT | AverageAbsQ                 3.226
2017-07-02 13:36:06.698785 EDT | AverageY                    3.21802
2017-07-02 13:36:06.698981 EDT | AverageAbsY                 3.21887
2017-07-02 13:36:06.699206 EDT | AverageAbsQYDiff            0.0696307
2017-07-02 13:36:06.699467 EDT | AverageAction               0.155952
2017-07-02 13:36:06.699651 EDT | PolicyRegParamNorm         48.1962
2017-07-02 13:36:06.699772 EDT | QFunRegParamNorm           50.7382
2017-07-02 13:36:06.700009 EDT | -----------------------  ------------
2017-07-02 13:36:06.700288 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #273 | Training started
2017-07-02 13:36:16.210509 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #273 | Training finished
2017-07-02 13:36:16.211039 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #273 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 13:36:16.211239 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #273 | Collecting samples for evaluation
2017-07-02 13:36:21.882418 EDT | -----------------------  ------------
2017-07-02 13:36:21.882655 EDT | Epoch                     273
2017-07-02 13:36:21.882799 EDT | Iteration                 273
2017-07-02 13:36:21.882933 EDT | AverageReturn            1000
2017-07-02 13:36:21.883114 EDT | StdReturn                   0
2017-07-02 13:36:21.883277 EDT | MaxReturn                1000
2017-07-02 13:36:21.883459 EDT | MinReturn                1000
2017-07-02 13:36:21.883647 EDT | AverageEsReturn            25.2439
2017-07-02 13:36:21.883880 EDT | StdEsReturn                20.8932
2017-07-02 13:36:21.884108 EDT | MaxEsReturn                90
2017-07-02 13:36:21.884340 EDT | MinEsReturn                 3
2017-07-02 13:36:21.884564 EDT | AverageDiscountedReturn    99.9957
2017-07-02 13:36:21.884776 EDT | AverageQLoss                0.0481128
2017-07-02 13:36:21.885007 EDT | AveragePolicySurr          -3.4534
2017-07-02 13:36:21.885222 EDT | AverageQ                    3.21416
2017-07-02 13:36:21.885454 EDT | AverageAbsQ                 3.22313
2017-07-02 13:36:21.885774 EDT | AverageY                    3.21424
2017-07-02 13:36:21.886004 EDT | AverageAbsY                 3.21557
2017-07-02 13:36:21.886185 EDT | AverageAbsQYDiff            0.0700187
2017-07-02 13:36:21.886416 EDT | AverageAction               0.0341952
2017-07-02 13:36:21.886605 EDT | PolicyRegParamNorm         48.3123
2017-07-02 13:36:21.886839 EDT | QFunRegParamNorm           50.7155
2017-07-02 13:36:21.887051 EDT | -----------------------  ------------
2017-07-02 13:36:21.887343 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #274 | Training started
2017-07-02 13:36:31.426006 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #274 | Training finished
2017-07-02 13:36:31.426533 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #274 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 13:36:31.426707 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #274 | Collecting samples for evaluation
2017-07-02 13:36:37.122261 EDT | -----------------------  ------------
2017-07-02 13:36:37.122472 EDT | Epoch                     274
2017-07-02 13:36:37.122581 EDT | Iteration                 274
2017-07-02 13:36:37.122685 EDT | AverageReturn            1000
2017-07-02 13:36:37.122873 EDT | StdReturn                   0
2017-07-02 13:36:37.123090 EDT | MaxReturn                1000
2017-07-02 13:36:37.123275 EDT | MinReturn                1000
2017-07-02 13:36:37.123461 EDT | AverageEsReturn            22.9773
2017-07-02 13:36:37.123690 EDT | StdEsReturn                21.5654
2017-07-02 13:36:37.123909 EDT | MaxEsReturn               116
2017-07-02 13:36:37.124149 EDT | MinEsReturn                 3
2017-07-02 13:36:37.124377 EDT | AverageDiscountedReturn    99.9957
2017-07-02 13:36:37.124604 EDT | AverageQLoss                0.0449343
2017-07-02 13:36:37.124806 EDT | AveragePolicySurr          -3.4431
2017-07-02 13:36:37.125016 EDT | AverageQ                    3.20823
2017-07-02 13:36:37.125242 EDT | AverageAbsQ                 3.21725
2017-07-02 13:36:37.125464 EDT | AverageY                    3.2083
2017-07-02 13:36:37.125953 EDT | AverageAbsY                 3.20964
2017-07-02 13:36:37.126178 EDT | AverageAbsQYDiff            0.0664648
2017-07-02 13:36:37.126392 EDT | AverageAction               0.0243817
2017-07-02 13:36:37.126602 EDT | PolicyRegParamNorm         48.3699
2017-07-02 13:36:37.126826 EDT | QFunRegParamNorm           50.789
2017-07-02 13:36:37.127037 EDT | -----------------------  ------------
2017-07-02 13:36:37.127358 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #275 | Training started
2017-07-02 13:36:46.586920 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #275 | Training finished
2017-07-02 13:36:46.587470 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #275 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 13:36:46.587626 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #275 | Collecting samples for evaluation
2017-07-02 13:36:52.276724 EDT | -----------------------  ------------
2017-07-02 13:36:52.276982 EDT | Epoch                     275
2017-07-02 13:36:52.277223 EDT | Iteration                 275
2017-07-02 13:36:52.277450 EDT | AverageReturn            1000
2017-07-02 13:36:52.277699 EDT | StdReturn                   0
2017-07-02 13:36:52.277930 EDT | MaxReturn                1000
2017-07-02 13:36:52.278121 EDT | MinReturn                1000
2017-07-02 13:36:52.278353 EDT | AverageEsReturn            31.375
2017-07-02 13:36:52.278530 EDT | StdEsReturn                26.929
2017-07-02 13:36:52.278761 EDT | MaxEsReturn               115
2017-07-02 13:36:52.278993 EDT | MinEsReturn                 3
2017-07-02 13:36:52.279127 EDT | AverageDiscountedReturn    99.9957
2017-07-02 13:36:52.279260 EDT | AverageQLoss                0.0415147
2017-07-02 13:36:52.279562 EDT | AveragePolicySurr          -3.42521
2017-07-02 13:36:52.279855 EDT | AverageQ                    3.19942
2017-07-02 13:36:52.280094 EDT | AverageAbsQ                 3.20744
2017-07-02 13:36:52.280321 EDT | AverageY                    3.19955
2017-07-02 13:36:52.280556 EDT | AverageAbsY                 3.20125
2017-07-02 13:36:52.280770 EDT | AverageAbsQYDiff            0.0619052
2017-07-02 13:36:52.280956 EDT | AverageAction               0.500615
2017-07-02 13:36:52.281189 EDT | PolicyRegParamNorm         48.4893
2017-07-02 13:36:52.281369 EDT | QFunRegParamNorm           50.8445
2017-07-02 13:36:52.281610 EDT | -----------------------  ------------
2017-07-02 13:36:52.281924 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #276 | Training started
2017-07-02 13:37:01.719761 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #276 | Training finished
2017-07-02 13:37:01.720262 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #276 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 13:37:01.720548 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #276 | Collecting samples for evaluation
2017-07-02 13:37:07.383782 EDT | -----------------------  ------------
2017-07-02 13:37:07.384077 EDT | Epoch                     276
2017-07-02 13:37:07.384276 EDT | Iteration                 276
2017-07-02 13:37:07.384482 EDT | AverageReturn            1000
2017-07-02 13:37:07.384621 EDT | StdReturn                   0
2017-07-02 13:37:07.384824 EDT | MaxReturn                1000
2017-07-02 13:37:07.385001 EDT | MinReturn                1000
2017-07-02 13:37:07.385195 EDT | AverageEsReturn            32.6129
2017-07-02 13:37:07.385417 EDT | StdEsReturn                22.9047
2017-07-02 13:37:07.385661 EDT | MaxEsReturn                94
2017-07-02 13:37:07.385883 EDT | MinEsReturn                 3
2017-07-02 13:37:07.386092 EDT | AverageDiscountedReturn    99.9957
2017-07-02 13:37:07.386327 EDT | AverageQLoss                0.0433562
2017-07-02 13:37:07.386554 EDT | AveragePolicySurr          -3.41574
2017-07-02 13:37:07.386779 EDT | AverageQ                    3.18193
2017-07-02 13:37:07.386984 EDT | AverageAbsQ                 3.1902
2017-07-02 13:37:07.387099 EDT | AverageY                    3.18179
2017-07-02 13:37:07.387202 EDT | AverageAbsY                 3.183
2017-07-02 13:37:07.387304 EDT | AverageAbsQYDiff            0.0638649
2017-07-02 13:37:07.387404 EDT | AverageAction               0.907751
2017-07-02 13:37:07.387513 EDT | PolicyRegParamNorm         48.5922
2017-07-02 13:37:07.387620 EDT | QFunRegParamNorm           50.8782
2017-07-02 13:37:07.387720 EDT | -----------------------  ------------
2017-07-02 13:37:07.387883 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #277 | Training started
2017-07-02 13:37:17.123383 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #277 | Training finished
2017-07-02 13:37:17.124022 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #277 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 13:37:17.124284 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #277 | Collecting samples for evaluation
2017-07-02 13:37:22.759168 EDT | -----------------------  ------------
2017-07-02 13:37:22.759401 EDT | Epoch                     277
2017-07-02 13:37:22.759513 EDT | Iteration                 277
2017-07-02 13:37:22.759693 EDT | AverageReturn            1000
2017-07-02 13:37:22.759879 EDT | StdReturn                   0
2017-07-02 13:37:22.760001 EDT | MaxReturn                1000
2017-07-02 13:37:22.760134 EDT | MinReturn                1000
2017-07-02 13:37:22.760242 EDT | AverageEsReturn            41.5
2017-07-02 13:37:22.760382 EDT | StdEsReturn                37.0821
2017-07-02 13:37:22.760545 EDT | MaxEsReturn               127
2017-07-02 13:37:22.760661 EDT | MinEsReturn                 6
2017-07-02 13:37:22.760768 EDT | AverageDiscountedReturn    99.9957
2017-07-02 13:37:22.760959 EDT | AverageQLoss                0.0442855
2017-07-02 13:37:22.761065 EDT | AveragePolicySurr          -3.40249
2017-07-02 13:37:22.761167 EDT | AverageQ                    3.1788
2017-07-02 13:37:22.761267 EDT | AverageAbsQ                 3.18824
2017-07-02 13:37:22.761428 EDT | AverageY                    3.17882
2017-07-02 13:37:22.762195 EDT | AverageAbsY                 3.18042
2017-07-02 13:37:22.762311 EDT | AverageAbsQYDiff            0.0657458
2017-07-02 13:37:22.762418 EDT | AverageAction               0.479273
2017-07-02 13:37:22.762542 EDT | PolicyRegParamNorm         48.6916
2017-07-02 13:37:22.762654 EDT | QFunRegParamNorm           50.9375
2017-07-02 13:37:22.762790 EDT | -----------------------  ------------
2017-07-02 13:37:22.762996 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #278 | Training started
2017-07-02 13:37:32.501747 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #278 | Training finished
2017-07-02 13:37:32.502333 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #278 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 13:37:32.502539 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #278 | Collecting samples for evaluation
2017-07-02 13:37:38.131245 EDT | -----------------------  ------------
2017-07-02 13:37:38.131554 EDT | Epoch                     278
2017-07-02 13:37:38.131789 EDT | Iteration                 278
2017-07-02 13:37:38.132009 EDT | AverageReturn            1000
2017-07-02 13:37:38.132247 EDT | StdReturn                   0
2017-07-02 13:37:38.132401 EDT | MaxReturn                1000
2017-07-02 13:37:38.132636 EDT | MinReturn                1000
2017-07-02 13:37:38.132854 EDT | AverageEsReturn            40.12
2017-07-02 13:37:38.132967 EDT | StdEsReturn                34.3457
2017-07-02 13:37:38.133072 EDT | MaxEsReturn               171
2017-07-02 13:37:38.133176 EDT | MinEsReturn                 4
2017-07-02 13:37:38.133316 EDT | AverageDiscountedReturn    99.9957
2017-07-02 13:37:38.133419 EDT | AverageQLoss                0.0455817
2017-07-02 13:37:38.133614 EDT | AveragePolicySurr          -3.38587
2017-07-02 13:37:38.133840 EDT | AverageQ                    3.16214
2017-07-02 13:37:38.134063 EDT | AverageAbsQ                 3.17188
2017-07-02 13:37:38.134184 EDT | AverageY                    3.16225
2017-07-02 13:37:38.134365 EDT | AverageAbsY                 3.16385
2017-07-02 13:37:38.134490 EDT | AverageAbsQYDiff            0.0681494
2017-07-02 13:37:38.134592 EDT | AverageAction               0.708855
2017-07-02 13:37:38.134747 EDT | PolicyRegParamNorm         48.7759
2017-07-02 13:37:38.134852 EDT | QFunRegParamNorm           51.0131
2017-07-02 13:37:38.134952 EDT | -----------------------  ------------
2017-07-02 13:37:38.135132 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #279 | Training started
2017-07-02 13:37:47.896540 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #279 | Training finished
2017-07-02 13:37:47.897133 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #279 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 13:37:47.897295 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #279 | Collecting samples for evaluation
2017-07-02 13:37:53.569471 EDT | -----------------------  ------------
2017-07-02 13:37:53.569733 EDT | Epoch                     279
2017-07-02 13:37:53.569924 EDT | Iteration                 279
2017-07-02 13:37:53.570130 EDT | AverageReturn            1000
2017-07-02 13:37:53.570276 EDT | StdReturn                   0
2017-07-02 13:37:53.570380 EDT | MaxReturn                1000
2017-07-02 13:37:53.570519 EDT | MinReturn                1000
2017-07-02 13:37:53.570686 EDT | AverageEsReturn            38.24
2017-07-02 13:37:53.570862 EDT | StdEsReturn                27.9131
2017-07-02 13:37:53.571061 EDT | MaxEsReturn               108
2017-07-02 13:37:53.571241 EDT | MinEsReturn                 7
2017-07-02 13:37:53.571347 EDT | AverageDiscountedReturn    99.9957
2017-07-02 13:37:53.571503 EDT | AverageQLoss                0.042302
2017-07-02 13:37:53.571673 EDT | AveragePolicySurr          -3.37389
2017-07-02 13:37:53.571798 EDT | AverageQ                    3.14535
2017-07-02 13:37:53.571929 EDT | AverageAbsQ                 3.1552
2017-07-02 13:37:53.572044 EDT | AverageY                    3.1455
2017-07-02 13:37:53.572146 EDT | AverageAbsY                 3.14718
2017-07-02 13:37:53.572266 EDT | AverageAbsQYDiff            0.0640277
2017-07-02 13:37:53.572460 EDT | AverageAction               0.835524
2017-07-02 13:37:53.572633 EDT | PolicyRegParamNorm         48.8429
2017-07-02 13:37:53.572745 EDT | QFunRegParamNorm           51.0705
2017-07-02 13:37:53.572977 EDT | -----------------------  ------------
2017-07-02 13:37:53.573274 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #280 | Training started
2017-07-02 13:38:03.259349 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #280 | Training finished
2017-07-02 13:38:03.259961 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #280 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 13:38:03.260134 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #280 | Collecting samples for evaluation
2017-07-02 13:38:08.949140 EDT | -----------------------  ------------
2017-07-02 13:38:08.949462 EDT | Epoch                     280
2017-07-02 13:38:08.949704 EDT | Iteration                 280
2017-07-02 13:38:08.949926 EDT | AverageReturn            1000
2017-07-02 13:38:08.950096 EDT | StdReturn                   0
2017-07-02 13:38:08.950320 EDT | MaxReturn                1000
2017-07-02 13:38:08.950484 EDT | MinReturn                1000
2017-07-02 13:38:08.950602 EDT | AverageEsReturn            38.7407
2017-07-02 13:38:08.950720 EDT | StdEsReturn                32.2417
2017-07-02 13:38:08.950824 EDT | MaxEsReturn               105
2017-07-02 13:38:08.950969 EDT | MinEsReturn                 3
2017-07-02 13:38:08.951147 EDT | AverageDiscountedReturn    99.9957
2017-07-02 13:38:08.951355 EDT | AverageQLoss                0.045596
2017-07-02 13:38:08.951576 EDT | AveragePolicySurr          -3.36721
2017-07-02 13:38:08.951790 EDT | AverageQ                    3.14811
2017-07-02 13:38:08.952016 EDT | AverageAbsQ                 3.15671
2017-07-02 13:38:08.952241 EDT | AverageY                    3.14788
2017-07-02 13:38:08.952464 EDT | AverageAbsY                 3.14943
2017-07-02 13:38:08.952683 EDT | AverageAbsQYDiff            0.0654486
2017-07-02 13:38:08.952906 EDT | AverageAction               0.827967
2017-07-02 13:38:08.953121 EDT | PolicyRegParamNorm         48.8415
2017-07-02 13:38:08.953345 EDT | QFunRegParamNorm           51.1814
2017-07-02 13:38:08.953662 EDT | -----------------------  ------------
2017-07-02 13:38:08.953982 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #281 | Training started
2017-07-02 13:38:18.571704 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #281 | Training finished
2017-07-02 13:38:18.572271 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #281 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 13:38:18.572543 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #281 | Collecting samples for evaluation
2017-07-02 13:38:24.185015 EDT | -----------------------  ------------
2017-07-02 13:38:24.185235 EDT | Epoch                     281
2017-07-02 13:38:24.185406 EDT | Iteration                 281
2017-07-02 13:38:24.185558 EDT | AverageReturn            1000
2017-07-02 13:38:24.185718 EDT | StdReturn                   0
2017-07-02 13:38:24.185825 EDT | MaxReturn                1000
2017-07-02 13:38:24.185928 EDT | MinReturn                1000
2017-07-02 13:38:24.186097 EDT | AverageEsReturn            39.52
2017-07-02 13:38:24.186222 EDT | StdEsReturn                41.136
2017-07-02 13:38:24.186329 EDT | MaxEsReturn               145
2017-07-02 13:38:24.186480 EDT | MinEsReturn                 4
2017-07-02 13:38:24.186601 EDT | AverageDiscountedReturn    99.9957
2017-07-02 13:38:24.186703 EDT | AverageQLoss                0.0458428
2017-07-02 13:38:24.186837 EDT | AveragePolicySurr          -3.35597
2017-07-02 13:38:24.186957 EDT | AverageQ                    3.13479
2017-07-02 13:38:24.187105 EDT | AverageAbsQ                 3.14337
2017-07-02 13:38:24.187209 EDT | AverageY                    3.13488
2017-07-02 13:38:24.187358 EDT | AverageAbsY                 3.13691
2017-07-02 13:38:24.187479 EDT | AverageAbsQYDiff            0.0654485
2017-07-02 13:38:24.187585 EDT | AverageAction               0.698938
2017-07-02 13:38:24.187788 EDT | PolicyRegParamNorm         48.8382
2017-07-02 13:38:24.188005 EDT | QFunRegParamNorm           51.2708
2017-07-02 13:38:24.188238 EDT | -----------------------  ------------
2017-07-02 13:38:24.188530 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #282 | Training started
2017-07-02 13:38:33.723648 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #282 | Training finished
2017-07-02 13:38:33.724188 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #282 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 13:38:33.724394 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #282 | Collecting samples for evaluation
2017-07-02 13:38:39.453938 EDT | -----------------------  ------------
2017-07-02 13:38:39.454162 EDT | Epoch                     282
2017-07-02 13:38:39.454285 EDT | Iteration                 282
2017-07-02 13:38:39.454439 EDT | AverageReturn            1000
2017-07-02 13:38:39.454545 EDT | StdReturn                   0
2017-07-02 13:38:39.454673 EDT | MaxReturn                1000
2017-07-02 13:38:39.454776 EDT | MinReturn                1000
2017-07-02 13:38:39.454927 EDT | AverageEsReturn            50.1
2017-07-02 13:38:39.455047 EDT | StdEsReturn                45.54
2017-07-02 13:38:39.455166 EDT | MaxEsReturn               147
2017-07-02 13:38:39.455269 EDT | MinEsReturn                 3
2017-07-02 13:38:39.455370 EDT | AverageDiscountedReturn    99.9957
2017-07-02 13:38:39.455513 EDT | AverageQLoss                0.0382725
2017-07-02 13:38:39.455617 EDT | AveragePolicySurr          -3.32977
2017-07-02 13:38:39.455754 EDT | AverageQ                    3.11242
2017-07-02 13:38:39.455930 EDT | AverageAbsQ                 3.12129
2017-07-02 13:38:39.456102 EDT | AverageY                    3.11241
2017-07-02 13:38:39.456271 EDT | AverageAbsY                 3.11461
2017-07-02 13:38:39.456400 EDT | AverageAbsQYDiff            0.0584604
2017-07-02 13:38:39.456565 EDT | AverageAction               0.7449
2017-07-02 13:38:39.456674 EDT | PolicyRegParamNorm         48.8929
2017-07-02 13:38:39.456812 EDT | QFunRegParamNorm           51.3569
2017-07-02 13:38:39.456944 EDT | -----------------------  ------------
2017-07-02 13:38:39.457182 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #283 | Training started
2017-07-02 13:38:49.058104 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #283 | Training finished
2017-07-02 13:38:49.058366 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #283 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 13:38:49.058605 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #283 | Collecting samples for evaluation
2017-07-02 13:38:54.706193 EDT | -----------------------  ------------
2017-07-02 13:38:54.706704 EDT | Epoch                     283
2017-07-02 13:38:54.706950 EDT | Iteration                 283
2017-07-02 13:38:54.707168 EDT | AverageReturn            1000
2017-07-02 13:38:54.707394 EDT | StdReturn                   0
2017-07-02 13:38:54.707616 EDT | MaxReturn                1000
2017-07-02 13:38:54.707846 EDT | MinReturn                1000
2017-07-02 13:38:54.708052 EDT | AverageEsReturn            39.8
2017-07-02 13:38:54.708245 EDT | StdEsReturn                37.6999
2017-07-02 13:38:54.708469 EDT | MaxEsReturn               129
2017-07-02 13:38:54.708696 EDT | MinEsReturn                 4
2017-07-02 13:38:54.708906 EDT | AverageDiscountedReturn    99.9957
2017-07-02 13:38:54.709082 EDT | AverageQLoss                0.0378334
2017-07-02 13:38:54.709304 EDT | AveragePolicySurr          -3.32109
2017-07-02 13:38:54.709505 EDT | AverageQ                    3.10262
2017-07-02 13:38:54.709655 EDT | AverageAbsQ                 3.11105
2017-07-02 13:38:54.709878 EDT | AverageY                    3.10271
2017-07-02 13:38:54.710100 EDT | AverageAbsY                 3.10427
2017-07-02 13:38:54.710316 EDT | AverageAbsQYDiff            0.0594737
2017-07-02 13:38:54.710531 EDT | AverageAction               0.937856
2017-07-02 13:38:54.710741 EDT | PolicyRegParamNorm         48.9139
2017-07-02 13:38:54.710918 EDT | QFunRegParamNorm           51.4404
2017-07-02 13:38:54.711134 EDT | -----------------------  ------------
2017-07-02 13:38:54.711438 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #284 | Training started
2017-07-02 13:39:04.299664 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #284 | Training finished
2017-07-02 13:39:04.300156 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #284 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 13:39:04.300344 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #284 | Collecting samples for evaluation
2017-07-02 13:39:09.966776 EDT | -----------------------  ------------
2017-07-02 13:39:09.967023 EDT | Epoch                     284
2017-07-02 13:39:09.967196 EDT | Iteration                 284
2017-07-02 13:39:09.967305 EDT | AverageReturn            1000
2017-07-02 13:39:09.967506 EDT | StdReturn                   0
2017-07-02 13:39:09.967680 EDT | MaxReturn                1000
2017-07-02 13:39:09.967843 EDT | MinReturn                1000
2017-07-02 13:39:09.968029 EDT | AverageEsReturn            30.1875
2017-07-02 13:39:09.968221 EDT | StdEsReturn                27.9234
2017-07-02 13:39:09.968401 EDT | MaxEsReturn               105
2017-07-02 13:39:09.968508 EDT | MinEsReturn                 4
2017-07-02 13:39:09.968689 EDT | AverageDiscountedReturn    99.9957
2017-07-02 13:39:09.968840 EDT | AverageQLoss                0.0385103
2017-07-02 13:39:09.968990 EDT | AveragePolicySurr          -3.30057
2017-07-02 13:39:09.969105 EDT | AverageQ                    3.09231
2017-07-02 13:39:09.969250 EDT | AverageAbsQ                 3.1013
2017-07-02 13:39:09.969393 EDT | AverageY                    3.09222
2017-07-02 13:39:09.969531 EDT | AverageAbsY                 3.09337
2017-07-02 13:39:09.969634 EDT | AverageAbsQYDiff            0.0602762
2017-07-02 13:39:09.969780 EDT | AverageAction               0.929453
2017-07-02 13:39:09.969885 EDT | PolicyRegParamNorm         48.9813
2017-07-02 13:39:09.969986 EDT | QFunRegParamNorm           51.4872
2017-07-02 13:39:09.970086 EDT | -----------------------  ------------
2017-07-02 13:39:09.970314 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #285 | Training started
2017-07-02 13:39:19.604470 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #285 | Training finished
2017-07-02 13:39:19.604963 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #285 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 13:39:19.605121 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #285 | Collecting samples for evaluation
2017-07-02 13:39:25.279551 EDT | -----------------------  ------------
2017-07-02 13:39:25.279874 EDT | Epoch                     285
2017-07-02 13:39:25.280103 EDT | Iteration                 285
2017-07-02 13:39:25.280318 EDT | AverageReturn            1000
2017-07-02 13:39:25.280462 EDT | StdReturn                   0
2017-07-02 13:39:25.280597 EDT | MaxReturn                1000
2017-07-02 13:39:25.280783 EDT | MinReturn                1000
2017-07-02 13:39:25.280991 EDT | AverageEsReturn            26.8378
2017-07-02 13:39:25.281190 EDT | StdEsReturn                23.1616
2017-07-02 13:39:25.281295 EDT | MaxEsReturn               102
2017-07-02 13:39:25.281449 EDT | MinEsReturn                 3
2017-07-02 13:39:25.281638 EDT | AverageDiscountedReturn    99.9957
2017-07-02 13:39:25.281744 EDT | AverageQLoss                0.0400057
2017-07-02 13:39:25.281845 EDT | AveragePolicySurr          -3.27244
2017-07-02 13:39:25.281946 EDT | AverageQ                    3.06048
2017-07-02 13:39:25.282069 EDT | AverageAbsQ                 3.06852
2017-07-02 13:39:25.282198 EDT | AverageY                    3.06049
2017-07-02 13:39:25.282300 EDT | AverageAbsY                 3.06155
2017-07-02 13:39:25.282417 EDT | AverageAbsQYDiff            0.05936
2017-07-02 13:39:25.282522 EDT | AverageAction               0.905842
2017-07-02 13:39:25.282624 EDT | PolicyRegParamNorm         49.0495
2017-07-02 13:39:25.282737 EDT | QFunRegParamNorm           51.5519
2017-07-02 13:39:25.282874 EDT | -----------------------  ------------
2017-07-02 13:39:25.283047 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #286 | Training started
2017-07-02 13:39:34.874695 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #286 | Training finished
2017-07-02 13:39:34.875226 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #286 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 13:39:34.875379 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #286 | Collecting samples for evaluation
2017-07-02 13:39:40.724691 EDT | -----------------------  ------------
2017-07-02 13:39:40.724895 EDT | Epoch                     286
2017-07-02 13:39:40.725007 EDT | Iteration                 286
2017-07-02 13:39:40.725112 EDT | AverageReturn            1000
2017-07-02 13:39:40.725230 EDT | StdReturn                   0
2017-07-02 13:39:40.725331 EDT | MaxReturn                1000
2017-07-02 13:39:40.725432 EDT | MinReturn                1000
2017-07-02 13:39:40.725599 EDT | AverageEsReturn            21.2245
2017-07-02 13:39:40.725795 EDT | StdEsReturn                19.4918
2017-07-02 13:39:40.725904 EDT | MaxEsReturn               103
2017-07-02 13:39:40.726052 EDT | MinEsReturn                 3
2017-07-02 13:39:40.726220 EDT | AverageDiscountedReturn    99.9957
2017-07-02 13:39:40.726325 EDT | AverageQLoss                0.0412617
2017-07-02 13:39:40.726427 EDT | AveragePolicySurr          -3.25413
2017-07-02 13:39:40.726528 EDT | AverageQ                    3.0467
2017-07-02 13:39:40.726648 EDT | AverageAbsQ                 3.05538
2017-07-02 13:39:40.726749 EDT | AverageY                    3.04675
2017-07-02 13:39:40.726848 EDT | AverageAbsY                 3.04747
2017-07-02 13:39:40.726948 EDT | AverageAbsQYDiff            0.0612794
2017-07-02 13:39:40.727066 EDT | AverageAction               0.912581
2017-07-02 13:39:40.727168 EDT | PolicyRegParamNorm         49.0347
2017-07-02 13:39:40.727268 EDT | QFunRegParamNorm           51.6233
2017-07-02 13:39:40.727368 EDT | -----------------------  ------------
2017-07-02 13:39:40.727533 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #287 | Training started
2017-07-02 13:39:50.325259 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #287 | Training finished
2017-07-02 13:39:50.325787 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #287 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 13:39:50.326040 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #287 | Collecting samples for evaluation
2017-07-02 13:39:55.934161 EDT | -----------------------  ------------
2017-07-02 13:39:55.934411 EDT | Epoch                     287
2017-07-02 13:39:55.934546 EDT | Iteration                 287
2017-07-02 13:39:55.934652 EDT | AverageReturn            1000
2017-07-02 13:39:55.934755 EDT | StdReturn                   0
2017-07-02 13:39:55.934898 EDT | MaxReturn                1000
2017-07-02 13:39:55.935003 EDT | MinReturn                1000
2017-07-02 13:39:55.935105 EDT | AverageEsReturn            24.0714
2017-07-02 13:39:55.935212 EDT | StdEsReturn                23.9646
2017-07-02 13:39:55.935403 EDT | MaxEsReturn               108
2017-07-02 13:39:55.935539 EDT | MinEsReturn                 3
2017-07-02 13:39:55.935661 EDT | AverageDiscountedReturn    99.9957
2017-07-02 13:39:55.935870 EDT | AverageQLoss                0.0431397
2017-07-02 13:39:55.936010 EDT | AveragePolicySurr          -3.24391
2017-07-02 13:39:55.936136 EDT | AverageQ                    3.03058
2017-07-02 13:39:55.936275 EDT | AverageAbsQ                 3.03946
2017-07-02 13:39:55.936379 EDT | AverageY                    3.03046
2017-07-02 13:39:55.936480 EDT | AverageAbsY                 3.03127
2017-07-02 13:39:55.936580 EDT | AverageAbsQYDiff            0.0633827
2017-07-02 13:39:55.936680 EDT | AverageAction               0.54685
2017-07-02 13:39:55.936779 EDT | PolicyRegParamNorm         49.0834
2017-07-02 13:39:55.936877 EDT | QFunRegParamNorm           51.7008
2017-07-02 13:39:55.936981 EDT | -----------------------  ------------
2017-07-02 13:39:55.937184 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #288 | Training started
2017-07-02 13:40:05.615005 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #288 | Training finished
2017-07-02 13:40:05.615580 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #288 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 13:40:05.615827 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #288 | Collecting samples for evaluation
2017-07-02 13:40:11.330283 EDT | -----------------------  ------------
2017-07-02 13:40:11.330477 EDT | Epoch                     288
2017-07-02 13:40:11.330629 EDT | Iteration                 288
2017-07-02 13:40:11.330769 EDT | AverageReturn            1000
2017-07-02 13:40:11.330886 EDT | StdReturn                   0
2017-07-02 13:40:11.331006 EDT | MaxReturn                1000
2017-07-02 13:40:11.331130 EDT | MinReturn                1000
2017-07-02 13:40:11.331233 EDT | AverageEsReturn            23.7073
2017-07-02 13:40:11.331339 EDT | StdEsReturn                26.2207
2017-07-02 13:40:11.331451 EDT | MaxEsReturn               110
2017-07-02 13:40:11.331573 EDT | MinEsReturn                 3
2017-07-02 13:40:11.331740 EDT | AverageDiscountedReturn    99.9957
2017-07-02 13:40:11.331906 EDT | AverageQLoss                0.0331337
2017-07-02 13:40:11.332096 EDT | AveragePolicySurr          -3.21697
2017-07-02 13:40:11.332228 EDT | AverageQ                    3.01535
2017-07-02 13:40:11.332331 EDT | AverageAbsQ                 3.02301
2017-07-02 13:40:11.332433 EDT | AverageY                    3.01529
2017-07-02 13:40:11.332686 EDT | AverageAbsY                 3.01593
2017-07-02 13:40:11.332804 EDT | AverageAbsQYDiff            0.0562095
2017-07-02 13:40:11.332927 EDT | AverageAction               0.657325
2017-07-02 13:40:11.333094 EDT | PolicyRegParamNorm         49.0911
2017-07-02 13:40:11.333214 EDT | QFunRegParamNorm           51.6987
2017-07-02 13:40:11.333316 EDT | -----------------------  ------------
2017-07-02 13:40:11.333554 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #289 | Training started
2017-07-02 13:40:21.440067 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #289 | Training finished
2017-07-02 13:40:21.440665 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #289 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 13:40:21.441017 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #289 | Collecting samples for evaluation
2017-07-02 13:40:27.136567 EDT | -----------------------  ------------
2017-07-02 13:40:27.136842 EDT | Epoch                     289
2017-07-02 13:40:27.137072 EDT | Iteration                 289
2017-07-02 13:40:27.137299 EDT | AverageReturn            1000
2017-07-02 13:40:27.137550 EDT | StdReturn                   0
2017-07-02 13:40:27.137792 EDT | MaxReturn                1000
2017-07-02 13:40:27.138006 EDT | MinReturn                1000
2017-07-02 13:40:27.138244 EDT | AverageEsReturn            21.7826
2017-07-02 13:40:27.138436 EDT | StdEsReturn                26.4936
2017-07-02 13:40:27.138663 EDT | MaxEsReturn               139
2017-07-02 13:40:27.138890 EDT | MinEsReturn                 3
2017-07-02 13:40:27.139117 EDT | AverageDiscountedReturn    99.9957
2017-07-02 13:40:27.139330 EDT | AverageQLoss                0.0390281
2017-07-02 13:40:27.139543 EDT | AveragePolicySurr          -3.21249
2017-07-02 13:40:27.139776 EDT | AverageQ                    3.00803
2017-07-02 13:40:27.139981 EDT | AverageAbsQ                 3.01621
2017-07-02 13:40:27.140089 EDT | AverageY                    3.00791
2017-07-02 13:40:27.140193 EDT | AverageAbsY                 3.00848
2017-07-02 13:40:27.140294 EDT | AverageAbsQYDiff            0.061112
2017-07-02 13:40:27.140396 EDT | AverageAction               0.715735
2017-07-02 13:40:27.140497 EDT | PolicyRegParamNorm         49.1139
2017-07-02 13:40:27.140597 EDT | QFunRegParamNorm           51.7786
2017-07-02 13:40:27.140728 EDT | -----------------------  ------------
2017-07-02 13:40:27.140892 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #290 | Training started
2017-07-02 13:40:36.839938 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #290 | Training finished
2017-07-02 13:40:36.840493 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #290 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 13:40:36.840746 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #290 | Collecting samples for evaluation
2017-07-02 13:40:42.431274 EDT | -----------------------  ------------
2017-07-02 13:40:42.431545 EDT | Epoch                     290
2017-07-02 13:40:42.431776 EDT | Iteration                 290
2017-07-02 13:40:42.431998 EDT | AverageReturn            1000
2017-07-02 13:40:42.432228 EDT | StdReturn                   0
2017-07-02 13:40:42.432419 EDT | MaxReturn                1000
2017-07-02 13:40:42.432589 EDT | MinReturn                1000
2017-07-02 13:40:42.432753 EDT | AverageEsReturn            23.25
2017-07-02 13:40:42.432915 EDT | StdEsReturn                21.1303
2017-07-02 13:40:42.433019 EDT | MaxEsReturn               111
2017-07-02 13:40:42.433121 EDT | MinEsReturn                 3
2017-07-02 13:40:42.433222 EDT | AverageDiscountedReturn    99.9957
2017-07-02 13:40:42.433349 EDT | AverageQLoss                0.04103
2017-07-02 13:40:42.433450 EDT | AveragePolicySurr          -3.19748
2017-07-02 13:40:42.433652 EDT | AverageQ                    2.99108
2017-07-02 13:40:42.433787 EDT | AverageAbsQ                 3.00039
2017-07-02 13:40:42.433942 EDT | AverageY                    2.99118
2017-07-02 13:40:42.434048 EDT | AverageAbsY                 2.99196
2017-07-02 13:40:42.434185 EDT | AverageAbsQYDiff            0.0628381
2017-07-02 13:40:42.434321 EDT | AverageAction               0.825215
2017-07-02 13:40:42.434424 EDT | PolicyRegParamNorm         49.1846
2017-07-02 13:40:42.434533 EDT | QFunRegParamNorm           51.8511
2017-07-02 13:40:42.434665 EDT | -----------------------  ------------
2017-07-02 13:40:42.434938 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #291 | Training started
2017-07-02 13:40:52.104548 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #291 | Training finished
2017-07-02 13:40:52.105108 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #291 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 13:40:52.105340 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #291 | Collecting samples for evaluation
2017-07-02 13:40:57.731817 EDT | -----------------------  ------------
2017-07-02 13:40:57.732026 EDT | Epoch                     291
2017-07-02 13:40:57.732140 EDT | Iteration                 291
2017-07-02 13:40:57.732257 EDT | AverageReturn            1000
2017-07-02 13:40:57.732363 EDT | StdReturn                   0
2017-07-02 13:40:57.732470 EDT | MaxReturn                1000
2017-07-02 13:40:57.732573 EDT | MinReturn                1000
2017-07-02 13:40:57.732694 EDT | AverageEsReturn            25.6744
2017-07-02 13:40:57.732845 EDT | StdEsReturn                24.9219
2017-07-02 13:40:57.732952 EDT | MaxEsReturn               106
2017-07-02 13:40:57.733086 EDT | MinEsReturn                 3
2017-07-02 13:40:57.733198 EDT | AverageDiscountedReturn    99.9957
2017-07-02 13:40:57.733300 EDT | AverageQLoss                0.0331897
2017-07-02 13:40:57.733437 EDT | AveragePolicySurr          -3.17895
2017-07-02 13:40:57.733666 EDT | AverageQ                    2.97879
2017-07-02 13:40:57.733892 EDT | AverageAbsQ                 2.98572
2017-07-02 13:40:57.734096 EDT | AverageY                    2.97867
2017-07-02 13:40:57.734231 EDT | AverageAbsY                 2.97931
2017-07-02 13:40:57.734415 EDT | AverageAbsQYDiff            0.0541034
2017-07-02 13:40:57.734640 EDT | AverageAction               0.600765
2017-07-02 13:40:57.734857 EDT | PolicyRegParamNorm         49.2526
2017-07-02 13:40:57.735085 EDT | QFunRegParamNorm           51.9222
2017-07-02 13:40:57.735314 EDT | -----------------------  ------------
2017-07-02 13:40:57.735636 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #292 | Training started
2017-07-02 13:41:07.209150 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #292 | Training finished
2017-07-02 13:41:07.209652 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #292 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 13:41:07.209811 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #292 | Collecting samples for evaluation
2017-07-02 13:41:13.017522 EDT | -----------------------  ------------
2017-07-02 13:41:13.017754 EDT | Epoch                     292
2017-07-02 13:41:13.017934 EDT | Iteration                 292
2017-07-02 13:41:13.018063 EDT | AverageReturn            1000
2017-07-02 13:41:13.018185 EDT | StdReturn                   0
2017-07-02 13:41:13.018311 EDT | MaxReturn                1000
2017-07-02 13:41:13.018417 EDT | MinReturn                1000
2017-07-02 13:41:13.018528 EDT | AverageEsReturn            32.7931
2017-07-02 13:41:13.018666 EDT | StdEsReturn                33.853
2017-07-02 13:41:13.018787 EDT | MaxEsReturn               115
2017-07-02 13:41:13.018988 EDT | MinEsReturn                 2
2017-07-02 13:41:13.019193 EDT | AverageDiscountedReturn    99.9957
2017-07-02 13:41:13.019402 EDT | AverageQLoss                0.0324516
2017-07-02 13:41:13.019584 EDT | AveragePolicySurr          -3.15427
2017-07-02 13:41:13.019789 EDT | AverageQ                    2.95586
2017-07-02 13:41:13.019977 EDT | AverageAbsQ                 2.96371
2017-07-02 13:41:13.020099 EDT | AverageY                    2.95592
2017-07-02 13:41:13.020205 EDT | AverageAbsY                 2.9565
2017-07-02 13:41:13.020307 EDT | AverageAbsQYDiff            0.0547008
2017-07-02 13:41:13.020497 EDT | AverageAction               0.624681
2017-07-02 13:41:13.020695 EDT | PolicyRegParamNorm         49.3461
2017-07-02 13:41:13.020818 EDT | QFunRegParamNorm           51.9909
2017-07-02 13:41:13.020922 EDT | -----------------------  ------------
2017-07-02 13:41:13.021115 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #293 | Training started
2017-07-02 13:41:22.419716 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #293 | Training finished
2017-07-02 13:41:22.420222 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #293 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 13:41:22.420401 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #293 | Collecting samples for evaluation
2017-07-02 13:41:28.197033 EDT | -----------------------  ------------
2017-07-02 13:41:28.197306 EDT | Epoch                     293
2017-07-02 13:41:28.197483 EDT | Iteration                 293
2017-07-02 13:41:28.197715 EDT | AverageReturn            1000
2017-07-02 13:41:28.197909 EDT | StdReturn                   0
2017-07-02 13:41:28.198020 EDT | MaxReturn                1000
2017-07-02 13:41:28.198132 EDT | MinReturn                1000
2017-07-02 13:41:28.198335 EDT | AverageEsReturn            23.75
2017-07-02 13:41:28.198524 EDT | StdEsReturn                24.7277
2017-07-02 13:41:28.198715 EDT | MaxEsReturn               120
2017-07-02 13:41:28.198866 EDT | MinEsReturn                 3
2017-07-02 13:41:28.198993 EDT | AverageDiscountedReturn    99.9957
2017-07-02 13:41:28.199176 EDT | AverageQLoss                0.036363
2017-07-02 13:41:28.199357 EDT | AveragePolicySurr          -3.14438
2017-07-02 13:41:28.199541 EDT | AverageQ                    2.94111
2017-07-02 13:41:28.199693 EDT | AverageAbsQ                 2.94905
2017-07-02 13:41:28.199873 EDT | AverageY                    2.94104
2017-07-02 13:41:28.200094 EDT | AverageAbsY                 2.9416
2017-07-02 13:41:28.200310 EDT | AverageAbsQYDiff            0.0576205
2017-07-02 13:41:28.200519 EDT | AverageAction               0.547173
2017-07-02 13:41:28.200694 EDT | PolicyRegParamNorm         49.3655
2017-07-02 13:41:28.200878 EDT | QFunRegParamNorm           52.0392
2017-07-02 13:41:28.200984 EDT | -----------------------  ------------
2017-07-02 13:41:28.201189 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #294 | Training started
2017-07-02 13:41:37.593723 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #294 | Training finished
2017-07-02 13:41:37.594275 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #294 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 13:41:37.594544 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #294 | Collecting samples for evaluation
2017-07-02 13:41:43.332406 EDT | -----------------------  ------------
2017-07-02 13:41:43.332596 EDT | Epoch                     294
2017-07-02 13:41:43.332708 EDT | Iteration                 294
2017-07-02 13:41:43.332813 EDT | AverageReturn            1000
2017-07-02 13:41:43.332949 EDT | StdReturn                   0
2017-07-02 13:41:43.333052 EDT | MaxReturn                1000
2017-07-02 13:41:43.333153 EDT | MinReturn                1000
2017-07-02 13:41:43.333256 EDT | AverageEsReturn            22.325
2017-07-02 13:41:43.333356 EDT | StdEsReturn                21.4002
2017-07-02 13:41:43.333457 EDT | MaxEsReturn               106
2017-07-02 13:41:43.333660 EDT | MinEsReturn                 3
2017-07-02 13:41:43.333884 EDT | AverageDiscountedReturn    99.9957
2017-07-02 13:41:43.334116 EDT | AverageQLoss                0.03532
2017-07-02 13:41:43.334346 EDT | AveragePolicySurr          -3.13256
2017-07-02 13:41:43.334507 EDT | AverageQ                    2.92741
2017-07-02 13:41:43.334737 EDT | AverageAbsQ                 2.93468
2017-07-02 13:41:43.334923 EDT | AverageY                    2.92731
2017-07-02 13:41:43.335157 EDT | AverageAbsY                 2.9278
2017-07-02 13:41:43.335378 EDT | AverageAbsQYDiff            0.0574035
2017-07-02 13:41:43.335601 EDT | AverageAction               0.401929
2017-07-02 13:41:43.335802 EDT | PolicyRegParamNorm         49.3919
2017-07-02 13:41:43.336019 EDT | QFunRegParamNorm           52.1008
2017-07-02 13:41:43.336258 EDT | -----------------------  ------------
2017-07-02 13:41:43.336583 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #295 | Training started
2017-07-02 13:41:52.869118 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #295 | Training finished
2017-07-02 13:41:52.869623 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #295 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 13:41:52.869792 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #295 | Collecting samples for evaluation
2017-07-02 13:41:58.646261 EDT | -----------------------  ------------
2017-07-02 13:41:58.646585 EDT | Epoch                     295
2017-07-02 13:41:58.646792 EDT | Iteration                 295
2017-07-02 13:41:58.647014 EDT | AverageReturn            1000
2017-07-02 13:41:58.647211 EDT | StdReturn                   0
2017-07-02 13:41:58.647444 EDT | MaxReturn                1000
2017-07-02 13:41:58.647665 EDT | MinReturn                1000
2017-07-02 13:41:58.647884 EDT | AverageEsReturn            31.4545
2017-07-02 13:41:58.648071 EDT | StdEsReturn                26.1384
2017-07-02 13:41:58.648290 EDT | MaxEsReturn               113
2017-07-02 13:41:58.648458 EDT | MinEsReturn                 3
2017-07-02 13:41:58.648668 EDT | AverageDiscountedReturn    99.9957
2017-07-02 13:41:58.648887 EDT | AverageQLoss                0.0381211
2017-07-02 13:41:58.649104 EDT | AveragePolicySurr          -3.10966
2017-07-02 13:41:58.649285 EDT | AverageQ                    2.90867
2017-07-02 13:41:58.649475 EDT | AverageAbsQ                 2.91609
2017-07-02 13:41:58.649715 EDT | AverageY                    2.9088
2017-07-02 13:41:58.649898 EDT | AverageAbsY                 2.90935
2017-07-02 13:41:58.650122 EDT | AverageAbsQYDiff            0.0599416
2017-07-02 13:41:58.650282 EDT | AverageAction               0.474404
2017-07-02 13:41:58.650422 EDT | PolicyRegParamNorm         49.4797
2017-07-02 13:41:58.650536 EDT | QFunRegParamNorm           52.1714
2017-07-02 13:41:58.650639 EDT | -----------------------  ------------
2017-07-02 13:41:58.650817 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #296 | Training started
2017-07-02 13:42:08.342649 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #296 | Training finished
2017-07-02 13:42:08.343159 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #296 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 13:42:08.343292 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #296 | Collecting samples for evaluation
2017-07-02 13:42:14.004787 EDT | -----------------------  ------------
2017-07-02 13:42:14.005067 EDT | Epoch                     296
2017-07-02 13:42:14.005253 EDT | Iteration                 296
2017-07-02 13:42:14.005436 EDT | AverageReturn            1000
2017-07-02 13:42:14.005605 EDT | StdReturn                   0
2017-07-02 13:42:14.005873 EDT | MaxReturn                1000
2017-07-02 13:42:14.006061 EDT | MinReturn                1000
2017-07-02 13:42:14.006180 EDT | AverageEsReturn            19.4259
2017-07-02 13:42:14.006359 EDT | StdEsReturn                18.2032
2017-07-02 13:42:14.006522 EDT | MaxEsReturn                75
2017-07-02 13:42:14.006714 EDT | MinEsReturn                 3
2017-07-02 13:42:14.006917 EDT | AverageDiscountedReturn    99.9957
2017-07-02 13:42:14.007171 EDT | AverageQLoss                0.0360128
2017-07-02 13:42:14.007414 EDT | AveragePolicySurr          -3.09192
2017-07-02 13:42:14.007642 EDT | AverageQ                    2.89392
2017-07-02 13:42:14.007823 EDT | AverageAbsQ                 2.90053
2017-07-02 13:42:14.008028 EDT | AverageY                    2.89382
2017-07-02 13:42:14.008227 EDT | AverageAbsY                 2.89437
2017-07-02 13:42:14.008387 EDT | AverageAbsQYDiff            0.0559744
2017-07-02 13:42:14.008570 EDT | AverageAction               0.648563
2017-07-02 13:42:14.008689 EDT | PolicyRegParamNorm         49.5169
2017-07-02 13:42:14.008792 EDT | QFunRegParamNorm           52.2447
2017-07-02 13:42:14.008948 EDT | -----------------------  ------------
2017-07-02 13:42:14.009121 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #297 | Training started
2017-07-02 13:42:23.586789 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #297 | Training finished
2017-07-02 13:42:23.587411 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #297 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 13:42:23.587618 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #297 | Collecting samples for evaluation
2017-07-02 13:42:29.305625 EDT | -----------------------  ------------
2017-07-02 13:42:29.305898 EDT | Epoch                     297
2017-07-02 13:42:29.306105 EDT | Iteration                 297
2017-07-02 13:42:29.306235 EDT | AverageReturn            1000
2017-07-02 13:42:29.306351 EDT | StdReturn                   0
2017-07-02 13:42:29.306538 EDT | MaxReturn                1000
2017-07-02 13:42:29.306646 EDT | MinReturn                1000
2017-07-02 13:42:29.306750 EDT | AverageEsReturn            35.069
2017-07-02 13:42:29.306852 EDT | StdEsReturn                37.6169
2017-07-02 13:42:29.306953 EDT | MaxEsReturn               179
2017-07-02 13:42:29.307066 EDT | MinEsReturn                 4
2017-07-02 13:42:29.307202 EDT | AverageDiscountedReturn    99.9957
2017-07-02 13:42:29.307324 EDT | AverageQLoss                0.0334024
2017-07-02 13:42:29.307468 EDT | AveragePolicySurr          -3.0769
2017-07-02 13:42:29.307622 EDT | AverageQ                    2.88092
2017-07-02 13:42:29.307808 EDT | AverageAbsQ                 2.88974
2017-07-02 13:42:29.308009 EDT | AverageY                    2.88097
2017-07-02 13:42:29.308143 EDT | AverageAbsY                 2.88165
2017-07-02 13:42:29.308284 EDT | AverageAbsQYDiff            0.0570176
2017-07-02 13:42:29.308479 EDT | AverageAction               0.608824
2017-07-02 13:42:29.308615 EDT | PolicyRegParamNorm         49.549
2017-07-02 13:42:29.308735 EDT | QFunRegParamNorm           52.2938
2017-07-02 13:42:29.308843 EDT | -----------------------  ------------
2017-07-02 13:42:29.309070 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #298 | Training started
2017-07-02 13:42:38.858718 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #298 | Training finished
2017-07-02 13:42:38.859212 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #298 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 13:42:38.859382 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #298 | Collecting samples for evaluation
2017-07-02 13:42:44.575781 EDT | -----------------------  ------------
2017-07-02 13:42:44.576021 EDT | Epoch                     298
2017-07-02 13:42:44.576215 EDT | Iteration                 298
2017-07-02 13:42:44.576363 EDT | AverageReturn            1000
2017-07-02 13:42:44.576470 EDT | StdReturn                   0
2017-07-02 13:42:44.576573 EDT | MaxReturn                1000
2017-07-02 13:42:44.576696 EDT | MinReturn                1000
2017-07-02 13:42:44.576797 EDT | AverageEsReturn            23.3023
2017-07-02 13:42:44.576897 EDT | StdEsReturn                21.6468
2017-07-02 13:42:44.577030 EDT | MaxEsReturn                92
2017-07-02 13:42:44.577231 EDT | MinEsReturn                 3
2017-07-02 13:42:44.577450 EDT | AverageDiscountedReturn    99.9957
2017-07-02 13:42:44.577685 EDT | AverageQLoss                0.0351503
2017-07-02 13:42:44.577915 EDT | AveragePolicySurr          -3.05326
2017-07-02 13:42:44.578132 EDT | AverageQ                    2.85635
2017-07-02 13:42:44.578351 EDT | AverageAbsQ                 2.86393
2017-07-02 13:42:44.578573 EDT | AverageY                    2.85627
2017-07-02 13:42:44.578793 EDT | AverageAbsY                 2.85698
2017-07-02 13:42:44.579009 EDT | AverageAbsQYDiff            0.0562878
2017-07-02 13:42:44.579229 EDT | AverageAction               0.416096
2017-07-02 13:42:44.579459 EDT | PolicyRegParamNorm         49.6661
2017-07-02 13:42:44.579643 EDT | QFunRegParamNorm           52.3551
2017-07-02 13:42:44.579871 EDT | -----------------------  ------------
2017-07-02 13:42:44.580187 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #299 | Training started
2017-07-02 13:42:54.152113 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #299 | Training finished
2017-07-02 13:42:54.152719 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #299 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 13:42:54.152962 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #299 | Collecting samples for evaluation
2017-07-02 13:42:59.885943 EDT | -----------------------  ------------
2017-07-02 13:42:59.886146 EDT | Epoch                     299
2017-07-02 13:42:59.886347 EDT | Iteration                 299
2017-07-02 13:42:59.886512 EDT | AverageReturn            1000
2017-07-02 13:42:59.886739 EDT | StdReturn                   0
2017-07-02 13:42:59.886933 EDT | MaxReturn                1000
2017-07-02 13:42:59.887164 EDT | MinReturn                1000
2017-07-02 13:42:59.887353 EDT | AverageEsReturn            21.2391
2017-07-02 13:42:59.887493 EDT | StdEsReturn                16.7022
2017-07-02 13:42:59.887598 EDT | MaxEsReturn                85
2017-07-02 13:42:59.887703 EDT | MinEsReturn                 4
2017-07-02 13:42:59.887833 EDT | AverageDiscountedReturn    99.9957
2017-07-02 13:42:59.887958 EDT | AverageQLoss                0.0311076
2017-07-02 13:42:59.888060 EDT | AveragePolicySurr          -3.04038
2017-07-02 13:42:59.888160 EDT | AverageQ                    2.85053
2017-07-02 13:42:59.888298 EDT | AverageAbsQ                 2.85726
2017-07-02 13:42:59.888454 EDT | AverageY                    2.85038
2017-07-02 13:42:59.888624 EDT | AverageAbsY                 2.85113
2017-07-02 13:42:59.888803 EDT | AverageAbsQYDiff            0.0528367
2017-07-02 13:42:59.888970 EDT | AverageAction               0.475637
2017-07-02 13:42:59.889073 EDT | PolicyRegParamNorm         49.8237
2017-07-02 13:42:59.889211 EDT | QFunRegParamNorm           52.3754
2017-07-02 13:42:59.889336 EDT | -----------------------  ------------
2017-07-02 13:42:59.889652 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #300 | Training started
2017-07-02 13:43:09.556904 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #300 | Training finished
2017-07-02 13:43:09.557553 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #300 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 13:43:09.557734 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #300 | Collecting samples for evaluation
2017-07-02 13:43:15.262206 EDT | -----------------------  ------------
2017-07-02 13:43:15.262408 EDT | Epoch                     300
2017-07-02 13:43:15.262577 EDT | Iteration                 300
2017-07-02 13:43:15.262700 EDT | AverageReturn            1000
2017-07-02 13:43:15.262836 EDT | StdReturn                   0
2017-07-02 13:43:15.262962 EDT | MaxReturn                1000
2017-07-02 13:43:15.263092 EDT | MinReturn                1000
2017-07-02 13:43:15.263223 EDT | AverageEsReturn            20.36
2017-07-02 13:43:15.263416 EDT | StdEsReturn                13.7532
2017-07-02 13:43:15.263549 EDT | MaxEsReturn                58
2017-07-02 13:43:15.263708 EDT | MinEsReturn                 3
2017-07-02 13:43:15.263891 EDT | AverageDiscountedReturn    99.9957
2017-07-02 13:43:15.264018 EDT | AverageQLoss                0.0341123
2017-07-02 13:43:15.264161 EDT | AveragePolicySurr          -3.02399
2017-07-02 13:43:15.264302 EDT | AverageQ                    2.82974
2017-07-02 13:43:15.264435 EDT | AverageAbsQ                 2.8377
2017-07-02 13:43:15.264546 EDT | AverageY                    2.82983
2017-07-02 13:43:15.264656 EDT | AverageAbsY                 2.83036
2017-07-02 13:43:15.264757 EDT | AverageAbsQYDiff            0.0575334
2017-07-02 13:43:15.264857 EDT | AverageAction               0.471033
2017-07-02 13:43:15.264957 EDT | PolicyRegParamNorm         49.8495
2017-07-02 13:43:15.265056 EDT | QFunRegParamNorm           52.4041
2017-07-02 13:43:15.265203 EDT | -----------------------  ------------
2017-07-02 13:43:15.265369 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #301 | Training started
2017-07-02 13:43:24.865694 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #301 | Training finished
2017-07-02 13:43:24.866383 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #301 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 13:43:24.866588 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #301 | Collecting samples for evaluation
2017-07-02 13:43:30.527196 EDT | -----------------------  ------------
2017-07-02 13:43:30.527398 EDT | Epoch                     301
2017-07-02 13:43:30.527525 EDT | Iteration                 301
2017-07-02 13:43:30.527682 EDT | AverageReturn            1000
2017-07-02 13:43:30.527789 EDT | StdReturn                   0
2017-07-02 13:43:30.527892 EDT | MaxReturn                1000
2017-07-02 13:43:30.528029 EDT | MinReturn                1000
2017-07-02 13:43:30.528151 EDT | AverageEsReturn            27.1143
2017-07-02 13:43:30.528293 EDT | StdEsReturn                24.4678
2017-07-02 13:43:30.528494 EDT | MaxEsReturn                99
2017-07-02 13:43:30.528676 EDT | MinEsReturn                 4
2017-07-02 13:43:30.528849 EDT | AverageDiscountedReturn    99.9957
2017-07-02 13:43:30.529010 EDT | AverageQLoss                0.0367646
2017-07-02 13:43:30.529147 EDT | AveragePolicySurr          -3.01408
2017-07-02 13:43:30.529292 EDT | AverageQ                    2.82106
2017-07-02 13:43:30.529435 EDT | AverageAbsQ                 2.82844
2017-07-02 13:43:30.529629 EDT | AverageY                    2.82087
2017-07-02 13:43:30.529735 EDT | AverageAbsY                 2.82155
2017-07-02 13:43:30.529859 EDT | AverageAbsQYDiff            0.0574976
2017-07-02 13:43:30.530012 EDT | AverageAction               0.476156
2017-07-02 13:43:30.530172 EDT | PolicyRegParamNorm         49.9114
2017-07-02 13:43:30.530275 EDT | QFunRegParamNorm           52.458
2017-07-02 13:43:30.530467 EDT | -----------------------  ------------
2017-07-02 13:43:30.530727 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #302 | Training started
2017-07-02 13:43:40.122468 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #302 | Training finished
2017-07-02 13:43:40.123129 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #302 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 13:43:40.123345 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #302 | Collecting samples for evaluation
2017-07-02 13:43:45.791512 EDT | -----------------------  ------------
2017-07-02 13:43:45.791778 EDT | Epoch                     302
2017-07-02 13:43:45.791961 EDT | Iteration                 302
2017-07-02 13:43:45.792079 EDT | AverageReturn            1000
2017-07-02 13:43:45.792229 EDT | StdReturn                   0
2017-07-02 13:43:45.792364 EDT | MaxReturn                1000
2017-07-02 13:43:45.792468 EDT | MinReturn                1000
2017-07-02 13:43:45.792639 EDT | AverageEsReturn            24.9762
2017-07-02 13:43:45.792853 EDT | StdEsReturn                25.1391
2017-07-02 13:43:45.793083 EDT | MaxEsReturn               101
2017-07-02 13:43:45.793315 EDT | MinEsReturn                 3
2017-07-02 13:43:45.793523 EDT | AverageDiscountedReturn    99.9957
2017-07-02 13:43:45.793663 EDT | AverageQLoss                0.0361424
2017-07-02 13:43:45.793854 EDT | AveragePolicySurr          -2.9914
2017-07-02 13:43:45.794076 EDT | AverageQ                    2.80094
2017-07-02 13:43:45.794300 EDT | AverageAbsQ                 2.80802
2017-07-02 13:43:45.794522 EDT | AverageY                    2.80089
2017-07-02 13:43:45.794746 EDT | AverageAbsY                 2.8013
2017-07-02 13:43:45.794970 EDT | AverageAbsQYDiff            0.0573412
2017-07-02 13:43:45.795204 EDT | AverageAction               0.481245
2017-07-02 13:43:45.795432 EDT | PolicyRegParamNorm         49.973
2017-07-02 13:43:45.795658 EDT | QFunRegParamNorm           52.5359
2017-07-02 13:43:45.795887 EDT | -----------------------  ------------
2017-07-02 13:43:45.796207 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #303 | Training started
2017-07-02 13:43:55.383576 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #303 | Training finished
2017-07-02 13:43:55.384068 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #303 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 13:43:55.384217 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #303 | Collecting samples for evaluation
2017-07-02 13:44:01.073251 EDT | -----------------------  ------------
2017-07-02 13:44:01.073453 EDT | Epoch                     303
2017-07-02 13:44:01.073608 EDT | Iteration                 303
2017-07-02 13:44:01.073738 EDT | AverageReturn            1000
2017-07-02 13:44:01.073848 EDT | StdReturn                   0
2017-07-02 13:44:01.073955 EDT | MaxReturn                1000
2017-07-02 13:44:01.074055 EDT | MinReturn                1000
2017-07-02 13:44:01.074223 EDT | AverageEsReturn            25.7949
2017-07-02 13:44:01.074466 EDT | StdEsReturn                19.3353
2017-07-02 13:44:01.074664 EDT | MaxEsReturn                79
2017-07-02 13:44:01.074798 EDT | MinEsReturn                 4
2017-07-02 13:44:01.074902 EDT | AverageDiscountedReturn    99.9957
2017-07-02 13:44:01.075021 EDT | AverageQLoss                0.0302745
2017-07-02 13:44:01.075153 EDT | AveragePolicySurr          -2.98666
2017-07-02 13:44:01.075262 EDT | AverageQ                    2.80164
2017-07-02 13:44:01.075363 EDT | AverageAbsQ                 2.80853
2017-07-02 13:44:01.075498 EDT | AverageY                    2.80145
2017-07-02 13:44:01.075600 EDT | AverageAbsY                 2.80182
2017-07-02 13:44:01.075714 EDT | AverageAbsQYDiff            0.0511644
2017-07-02 13:44:01.075861 EDT | AverageAction               0.430818
2017-07-02 13:44:01.075964 EDT | PolicyRegParamNorm         50.0128
2017-07-02 13:44:01.076065 EDT | QFunRegParamNorm           52.6208
2017-07-02 13:44:01.076248 EDT | -----------------------  ------------
2017-07-02 13:44:01.076493 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #304 | Training started
2017-07-02 13:44:10.603509 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #304 | Training finished
2017-07-02 13:44:10.604012 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #304 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 13:44:10.604271 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #304 | Collecting samples for evaluation
2017-07-02 13:44:16.348100 EDT | -----------------------  ------------
2017-07-02 13:44:16.348401 EDT | Epoch                     304
2017-07-02 13:44:16.348581 EDT | Iteration                 304
2017-07-02 13:44:16.348785 EDT | AverageReturn            1000
2017-07-02 13:44:16.348967 EDT | StdReturn                   0
2017-07-02 13:44:16.349105 EDT | MaxReturn                1000
2017-07-02 13:44:16.349217 EDT | MinReturn                1000
2017-07-02 13:44:16.349347 EDT | AverageEsReturn            17.9259
2017-07-02 13:44:16.349449 EDT | StdEsReturn                13.9799
2017-07-02 13:44:16.349665 EDT | MaxEsReturn                69
2017-07-02 13:44:16.349899 EDT | MinEsReturn                 4
2017-07-02 13:44:16.350117 EDT | AverageDiscountedReturn    99.9957
2017-07-02 13:44:16.350338 EDT | AverageQLoss                0.0314155
2017-07-02 13:44:16.350557 EDT | AveragePolicySurr          -2.96657
2017-07-02 13:44:16.350761 EDT | AverageQ                    2.78133
2017-07-02 13:44:16.350917 EDT | AverageAbsQ                 2.78814
2017-07-02 13:44:16.351094 EDT | AverageY                    2.7813
2017-07-02 13:44:16.351326 EDT | AverageAbsY                 2.78172
2017-07-02 13:44:16.351549 EDT | AverageAbsQYDiff            0.0517148
2017-07-02 13:44:16.351780 EDT | AverageAction               0.577083
2017-07-02 13:44:16.351994 EDT | PolicyRegParamNorm         50.0826
2017-07-02 13:44:16.352207 EDT | QFunRegParamNorm           52.7152
2017-07-02 13:44:16.352435 EDT | -----------------------  ------------
2017-07-02 13:44:16.352691 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #305 | Training started
2017-07-02 13:44:25.861082 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #305 | Training finished
2017-07-02 13:44:25.861633 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #305 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 13:44:25.861792 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #305 | Collecting samples for evaluation
2017-07-02 13:44:31.489897 EDT | -----------------------  ------------
2017-07-02 13:44:31.490407 EDT | Epoch                     305
2017-07-02 13:44:31.490534 EDT | Iteration                 305
2017-07-02 13:44:31.490643 EDT | AverageReturn            1000
2017-07-02 13:44:31.490748 EDT | StdReturn                   0
2017-07-02 13:44:31.490914 EDT | MaxReturn                1000
2017-07-02 13:44:31.491019 EDT | MinReturn                1000
2017-07-02 13:44:31.491126 EDT | AverageEsReturn            20.0196
2017-07-02 13:44:31.491254 EDT | StdEsReturn                20.2857
2017-07-02 13:44:31.491369 EDT | MaxEsReturn               131
2017-07-02 13:44:31.491472 EDT | MinEsReturn                 4
2017-07-02 13:44:31.491573 EDT | AverageDiscountedReturn    99.9957
2017-07-02 13:44:31.491673 EDT | AverageQLoss                0.0333957
2017-07-02 13:44:31.491775 EDT | AveragePolicySurr          -2.95776
2017-07-02 13:44:31.491874 EDT | AverageQ                    2.77458
2017-07-02 13:44:31.491988 EDT | AverageAbsQ                 2.78181
2017-07-02 13:44:31.492112 EDT | AverageY                    2.77457
2017-07-02 13:44:31.492279 EDT | AverageAbsY                 2.77526
2017-07-02 13:44:31.492398 EDT | AverageAbsQYDiff            0.0544122
2017-07-02 13:44:31.492524 EDT | AverageAction               0.420928
2017-07-02 13:44:31.492636 EDT | PolicyRegParamNorm         50.1657
2017-07-02 13:44:31.492815 EDT | QFunRegParamNorm           52.7346
2017-07-02 13:44:31.493022 EDT | -----------------------  ------------
2017-07-02 13:44:31.493322 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #306 | Training started
2017-07-02 13:44:41.270343 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #306 | Training finished
2017-07-02 13:44:41.270863 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #306 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 13:44:41.271036 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #306 | Collecting samples for evaluation
2017-07-02 13:44:46.934287 EDT | -----------------------  ------------
2017-07-02 13:44:46.934490 EDT | Epoch                     306
2017-07-02 13:44:46.934618 EDT | Iteration                 306
2017-07-02 13:44:46.934724 EDT | AverageReturn            1000
2017-07-02 13:44:46.934827 EDT | StdReturn                   0
2017-07-02 13:44:46.934929 EDT | MaxReturn                1000
2017-07-02 13:44:46.935080 EDT | MinReturn                1000
2017-07-02 13:44:46.935183 EDT | AverageEsReturn            21.5652
2017-07-02 13:44:46.935286 EDT | StdEsReturn                19.7414
2017-07-02 13:44:46.935387 EDT | MaxEsReturn               100
2017-07-02 13:44:46.935486 EDT | MinEsReturn                 3
2017-07-02 13:44:46.935630 EDT | AverageDiscountedReturn    99.9957
2017-07-02 13:44:46.935809 EDT | AverageQLoss                0.0298527
2017-07-02 13:44:46.935948 EDT | AveragePolicySurr          -2.94215
2017-07-02 13:44:46.936051 EDT | AverageQ                    2.75222
2017-07-02 13:44:46.936152 EDT | AverageAbsQ                 2.75907
2017-07-02 13:44:46.936288 EDT | AverageY                    2.75238
2017-07-02 13:44:46.936409 EDT | AverageAbsY                 2.75279
2017-07-02 13:44:46.936520 EDT | AverageAbsQYDiff            0.0503419
2017-07-02 13:44:46.936651 EDT | AverageAction               0.448677
2017-07-02 13:44:46.936769 EDT | PolicyRegParamNorm         50.1779
2017-07-02 13:44:46.936869 EDT | QFunRegParamNorm           52.7958
2017-07-02 13:44:46.937026 EDT | -----------------------  ------------
2017-07-02 13:44:46.937313 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #307 | Training started
2017-07-02 13:44:56.611646 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #307 | Training finished
2017-07-02 13:44:56.612589 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #307 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 13:44:56.612783 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #307 | Collecting samples for evaluation
2017-07-02 13:45:02.241981 EDT | -----------------------  ------------
2017-07-02 13:45:02.242453 EDT | Epoch                     307
2017-07-02 13:45:02.242626 EDT | Iteration                 307
2017-07-02 13:45:02.242780 EDT | AverageReturn            1000
2017-07-02 13:45:02.242929 EDT | StdReturn                   0
2017-07-02 13:45:02.243041 EDT | MaxReturn                1000
2017-07-02 13:45:02.243154 EDT | MinReturn                1000
2017-07-02 13:45:02.243269 EDT | AverageEsReturn            24.6341
2017-07-02 13:45:02.243407 EDT | StdEsReturn                19.4382
2017-07-02 13:45:02.243544 EDT | MaxEsReturn                87
2017-07-02 13:45:02.243717 EDT | MinEsReturn                 4
2017-07-02 13:45:02.243826 EDT | AverageDiscountedReturn    99.9957
2017-07-02 13:45:02.243933 EDT | AverageQLoss                0.0369819
2017-07-02 13:45:02.244081 EDT | AveragePolicySurr          -2.92453
2017-07-02 13:45:02.244278 EDT | AverageQ                    2.74498
2017-07-02 13:45:02.244500 EDT | AverageAbsQ                 2.75242
2017-07-02 13:45:02.244671 EDT | AverageY                    2.74488
2017-07-02 13:45:02.244810 EDT | AverageAbsY                 2.74513
2017-07-02 13:45:02.244964 EDT | AverageAbsQYDiff            0.0564665
2017-07-02 13:45:02.245185 EDT | AverageAction               0.503831
2017-07-02 13:45:02.245389 EDT | PolicyRegParamNorm         50.3394
2017-07-02 13:45:02.245744 EDT | QFunRegParamNorm           52.7775
2017-07-02 13:45:02.245978 EDT | -----------------------  ------------
2017-07-02 13:45:02.246298 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #308 | Training started
2017-07-02 13:45:11.957826 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #308 | Training finished
2017-07-02 13:45:11.958355 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #308 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 13:45:11.958724 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #308 | Collecting samples for evaluation
2017-07-02 13:45:17.592248 EDT | -----------------------  ------------
2017-07-02 13:45:17.592478 EDT | Epoch                     308
2017-07-02 13:45:17.592672 EDT | Iteration                 308
2017-07-02 13:45:17.592832 EDT | AverageReturn            1000
2017-07-02 13:45:17.592939 EDT | StdReturn                   0
2017-07-02 13:45:17.593043 EDT | MaxReturn                1000
2017-07-02 13:45:17.593163 EDT | MinReturn                1000
2017-07-02 13:45:17.593320 EDT | AverageEsReturn            24.6341
2017-07-02 13:45:17.593426 EDT | StdEsReturn                22.9854
2017-07-02 13:45:17.593558 EDT | MaxEsReturn               111
2017-07-02 13:45:17.593670 EDT | MinEsReturn                 3
2017-07-02 13:45:17.593779 EDT | AverageDiscountedReturn    99.9957
2017-07-02 13:45:17.593930 EDT | AverageQLoss                0.0307035
2017-07-02 13:45:17.594033 EDT | AveragePolicySurr          -2.90844
2017-07-02 13:45:17.594133 EDT | AverageQ                    2.72163
2017-07-02 13:45:17.594262 EDT | AverageAbsQ                 2.72935
2017-07-02 13:45:17.594377 EDT | AverageY                    2.72179
2017-07-02 13:45:17.594503 EDT | AverageAbsY                 2.72211
2017-07-02 13:45:17.594607 EDT | AverageAbsQYDiff            0.0533175
2017-07-02 13:45:17.594783 EDT | AverageAction               0.0099356
2017-07-02 13:45:17.594973 EDT | PolicyRegParamNorm         50.3791
2017-07-02 13:45:17.595153 EDT | QFunRegParamNorm           52.8199
2017-07-02 13:45:17.595369 EDT | -----------------------  ------------
2017-07-02 13:45:17.595691 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #309 | Training started
2017-07-02 13:45:27.844514 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #309 | Training finished
2017-07-02 13:45:27.845159 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #309 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 13:45:27.845617 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #309 | Collecting samples for evaluation
2017-07-02 13:45:33.560801 EDT | -----------------------  ------------
2017-07-02 13:45:33.562741 EDT | Epoch                     309
2017-07-02 13:45:33.562874 EDT | Iteration                 309
2017-07-02 13:45:33.562983 EDT | AverageReturn            1000
2017-07-02 13:45:33.563125 EDT | StdReturn                   0
2017-07-02 13:45:33.563233 EDT | MaxReturn                1000
2017-07-02 13:45:33.563400 EDT | MinReturn                1000
2017-07-02 13:45:33.563505 EDT | AverageEsReturn            23.4524
2017-07-02 13:45:33.563637 EDT | StdEsReturn                18.259
2017-07-02 13:45:33.563762 EDT | MaxEsReturn                88
2017-07-02 13:45:33.563865 EDT | MinEsReturn                 4
2017-07-02 13:45:33.563965 EDT | AverageDiscountedReturn    99.9957
2017-07-02 13:45:33.564102 EDT | AverageQLoss                0.029163
2017-07-02 13:45:33.564213 EDT | AveragePolicySurr          -2.88039
2017-07-02 13:45:33.565052 EDT | AverageQ                    2.70928
2017-07-02 13:45:33.565221 EDT | AverageAbsQ                 2.71695
2017-07-02 13:45:33.565375 EDT | AverageY                    2.70928
2017-07-02 13:45:33.565594 EDT | AverageAbsY                 2.70945
2017-07-02 13:45:33.565745 EDT | AverageAbsQYDiff            0.0505501
2017-07-02 13:45:33.565911 EDT | AverageAction               0.509466
2017-07-02 13:45:33.566133 EDT | PolicyRegParamNorm         50.4655
2017-07-02 13:45:33.566347 EDT | QFunRegParamNorm           52.8744
2017-07-02 13:45:33.566574 EDT | -----------------------  ------------
2017-07-02 13:45:33.566873 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #310 | Training started
2017-07-02 13:45:43.072371 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #310 | Training finished
2017-07-02 13:45:43.072898 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #310 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 13:45:43.073060 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #310 | Collecting samples for evaluation
2017-07-02 13:45:48.778137 EDT | -----------------------  ------------
2017-07-02 13:45:48.778328 EDT | Epoch                     310
2017-07-02 13:45:48.778485 EDT | Iteration                 310
2017-07-02 13:45:48.778593 EDT | AverageReturn            1000
2017-07-02 13:45:48.778697 EDT | StdReturn                   0
2017-07-02 13:45:48.778798 EDT | MaxReturn                1000
2017-07-02 13:45:48.778898 EDT | MinReturn                1000
2017-07-02 13:45:48.779042 EDT | AverageEsReturn            29.7353
2017-07-02 13:45:48.779177 EDT | StdEsReturn                25.8085
2017-07-02 13:45:48.779288 EDT | MaxEsReturn               116
2017-07-02 13:45:48.779508 EDT | MinEsReturn                 5
2017-07-02 13:45:48.779749 EDT | AverageDiscountedReturn    99.9957
2017-07-02 13:45:48.779976 EDT | AverageQLoss                0.028763
2017-07-02 13:45:48.780207 EDT | AveragePolicySurr          -2.86352
2017-07-02 13:45:48.780424 EDT | AverageQ                    2.69392
2017-07-02 13:45:48.780575 EDT | AverageAbsQ                 2.7014
2017-07-02 13:45:48.780680 EDT | AverageY                    2.6937
2017-07-02 13:45:48.780811 EDT | AverageAbsY                 2.69428
2017-07-02 13:45:48.780914 EDT | AverageAbsQYDiff            0.0506581
2017-07-02 13:45:48.781016 EDT | AverageAction               0.425193
2017-07-02 13:45:48.781115 EDT | PolicyRegParamNorm         50.5769
2017-07-02 13:45:48.781214 EDT | QFunRegParamNorm           52.9119
2017-07-02 13:45:48.781313 EDT | -----------------------  ------------
2017-07-02 13:45:48.781474 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #311 | Training started
2017-07-02 13:45:58.376791 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #311 | Training finished
2017-07-02 13:45:58.377306 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #311 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 13:45:58.377451 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #311 | Collecting samples for evaluation
2017-07-02 13:46:03.990680 EDT | -----------------------  ------------
2017-07-02 13:46:03.991171 EDT | Epoch                     311
2017-07-02 13:46:03.991358 EDT | Iteration                 311
2017-07-02 13:46:03.991520 EDT | AverageReturn            1000
2017-07-02 13:46:03.991626 EDT | StdReturn                   0
2017-07-02 13:46:03.991769 EDT | MaxReturn                1000
2017-07-02 13:46:03.991873 EDT | MinReturn                1000
2017-07-02 13:46:03.991974 EDT | AverageEsReturn            33.6333
2017-07-02 13:46:03.992104 EDT | StdEsReturn                26.6402
2017-07-02 13:46:03.992336 EDT | MaxEsReturn               144
2017-07-02 13:46:03.992560 EDT | MinEsReturn                 7
2017-07-02 13:46:03.992782 EDT | AverageDiscountedReturn    99.9957
2017-07-02 13:46:03.993395 EDT | AverageQLoss                0.0282163
2017-07-02 13:46:03.993709 EDT | AveragePolicySurr          -2.85104
2017-07-02 13:46:03.993851 EDT | AverageQ                    2.66983
2017-07-02 13:46:03.993967 EDT | AverageAbsQ                 2.67669
2017-07-02 13:46:03.994098 EDT | AverageY                    2.66991
2017-07-02 13:46:03.994204 EDT | AverageAbsY                 2.67061
2017-07-02 13:46:03.994357 EDT | AverageAbsQYDiff            0.0485409
2017-07-02 13:46:03.994569 EDT | AverageAction               0.183306
2017-07-02 13:46:03.994793 EDT | PolicyRegParamNorm         50.599
2017-07-02 13:46:03.994977 EDT | QFunRegParamNorm           53.0021
2017-07-02 13:46:03.995182 EDT | -----------------------  ------------
2017-07-02 13:46:03.995503 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #312 | Training started
2017-07-02 13:46:13.673309 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #312 | Training finished
2017-07-02 13:46:13.673929 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #312 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 13:46:13.674181 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #312 | Collecting samples for evaluation
2017-07-02 13:46:19.276739 EDT | -----------------------  ------------
2017-07-02 13:46:19.276995 EDT | Epoch                     312
2017-07-02 13:46:19.277108 EDT | Iteration                 312
2017-07-02 13:46:19.277215 EDT | AverageReturn            1000
2017-07-02 13:46:19.277317 EDT | StdReturn                   0
2017-07-02 13:46:19.277418 EDT | MaxReturn                1000
2017-07-02 13:46:19.277572 EDT | MinReturn                1000
2017-07-02 13:46:19.277753 EDT | AverageEsReturn            30.5312
2017-07-02 13:46:19.277896 EDT | StdEsReturn                31.3797
2017-07-02 13:46:19.277999 EDT | MaxEsReturn               142
2017-07-02 13:46:19.278100 EDT | MinEsReturn                 2
2017-07-02 13:46:19.278227 EDT | AverageDiscountedReturn    99.9957
2017-07-02 13:46:19.278330 EDT | AverageQLoss                0.0304346
2017-07-02 13:46:19.278479 EDT | AveragePolicySurr          -2.82825
2017-07-02 13:46:19.278604 EDT | AverageQ                    2.64808
2017-07-02 13:46:19.278712 EDT | AverageAbsQ                 2.65574
2017-07-02 13:46:19.278820 EDT | AverageY                    2.6481
2017-07-02 13:46:19.278952 EDT | AverageAbsY                 2.64887
2017-07-02 13:46:19.279058 EDT | AverageAbsQYDiff            0.051706
2017-07-02 13:46:19.279162 EDT | AverageAction               0.298944
2017-07-02 13:46:19.279274 EDT | PolicyRegParamNorm         50.7022
2017-07-02 13:46:19.279389 EDT | QFunRegParamNorm           52.9974
2017-07-02 13:46:19.279495 EDT | -----------------------  ------------
2017-07-02 13:46:19.279664 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #313 | Training started
2017-07-02 13:46:29.065659 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #313 | Training finished
2017-07-02 13:46:29.066149 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #313 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 13:46:29.066355 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #313 | Collecting samples for evaluation
2017-07-02 13:46:34.618822 EDT | -----------------------  ------------
2017-07-02 13:46:34.619313 EDT | Epoch                     313
2017-07-02 13:46:34.619510 EDT | Iteration                 313
2017-07-02 13:46:34.619623 EDT | AverageReturn            1000
2017-07-02 13:46:34.619728 EDT | StdReturn                   0
2017-07-02 13:46:34.619860 EDT | MaxReturn                1000
2017-07-02 13:46:34.619996 EDT | MinReturn                1000
2017-07-02 13:46:34.620099 EDT | AverageEsReturn            35.2963
2017-07-02 13:46:34.620202 EDT | StdEsReturn                22.7072
2017-07-02 13:46:34.620312 EDT | MaxEsReturn                83
2017-07-02 13:46:34.620474 EDT | MinEsReturn                 5
2017-07-02 13:46:34.620585 EDT | AverageDiscountedReturn    99.9957
2017-07-02 13:46:34.620711 EDT | AverageQLoss                0.0309208
2017-07-02 13:46:34.620855 EDT | AveragePolicySurr          -2.81501
2017-07-02 13:46:34.621036 EDT | AverageQ                    2.63553
2017-07-02 13:46:34.621237 EDT | AverageAbsQ                 2.64358
2017-07-02 13:46:34.621432 EDT | AverageY                    2.6355
2017-07-02 13:46:34.621635 EDT | AverageAbsY                 2.63639
2017-07-02 13:46:34.621807 EDT | AverageAbsQYDiff            0.0534904
2017-07-02 13:46:34.621978 EDT | AverageAction               0.457333
2017-07-02 13:46:34.622151 EDT | PolicyRegParamNorm         50.8019
2017-07-02 13:46:34.622320 EDT | QFunRegParamNorm           53.0204
2017-07-02 13:46:34.622484 EDT | -----------------------  ------------
2017-07-02 13:46:34.622760 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #314 | Training started
2017-07-02 13:46:44.355796 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #314 | Training finished
2017-07-02 13:46:44.356403 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #314 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 13:46:44.356548 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #314 | Collecting samples for evaluation
2017-07-02 13:46:49.939273 EDT | -----------------------  ------------
2017-07-02 13:46:49.939460 EDT | Epoch                     314
2017-07-02 13:46:49.939604 EDT | Iteration                 314
2017-07-02 13:46:49.939730 EDT | AverageReturn            1000
2017-07-02 13:46:49.939835 EDT | StdReturn                   0
2017-07-02 13:46:49.939938 EDT | MaxReturn                1000
2017-07-02 13:46:49.940073 EDT | MinReturn                1000
2017-07-02 13:46:49.940273 EDT | AverageEsReturn            33.4375
2017-07-02 13:46:49.940412 EDT | StdEsReturn                20.8041
2017-07-02 13:46:49.940612 EDT | MaxEsReturn                87
2017-07-02 13:46:49.940738 EDT | MinEsReturn                 4
2017-07-02 13:46:49.940938 EDT | AverageDiscountedReturn    99.9957
2017-07-02 13:46:49.941101 EDT | AverageQLoss                0.0256149
2017-07-02 13:46:49.941243 EDT | AveragePolicySurr          -2.80867
2017-07-02 13:46:49.941370 EDT | AverageQ                    2.63424
2017-07-02 13:46:49.942270 EDT | AverageAbsQ                 2.64149
2017-07-02 13:46:49.942426 EDT | AverageY                    2.63412
2017-07-02 13:46:49.942647 EDT | AverageAbsY                 2.63461
2017-07-02 13:46:49.942879 EDT | AverageAbsQYDiff            0.0471479
2017-07-02 13:46:49.943000 EDT | AverageAction               0.245417
2017-07-02 13:46:49.943105 EDT | PolicyRegParamNorm         50.7914
2017-07-02 13:46:49.943263 EDT | QFunRegParamNorm           53.075
2017-07-02 13:46:49.943465 EDT | -----------------------  ------------
2017-07-02 13:46:49.943780 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #315 | Training started
2017-07-02 13:46:59.656246 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #315 | Training finished
2017-07-02 13:46:59.656862 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #315 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 13:46:59.657030 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #315 | Collecting samples for evaluation
2017-07-02 13:47:05.196360 EDT | -----------------------  ------------
2017-07-02 13:47:05.196897 EDT | Epoch                     315
2017-07-02 13:47:05.197057 EDT | Iteration                 315
2017-07-02 13:47:05.197198 EDT | AverageReturn            1000
2017-07-02 13:47:05.197345 EDT | StdReturn                   0
2017-07-02 13:47:05.197556 EDT | MaxReturn                1000
2017-07-02 13:47:05.197665 EDT | MinReturn                1000
2017-07-02 13:47:05.197809 EDT | AverageEsReturn            27.4286
2017-07-02 13:47:05.197956 EDT | StdEsReturn                22.8477
2017-07-02 13:47:05.198058 EDT | MaxEsReturn                96
2017-07-02 13:47:05.198162 EDT | MinEsReturn                 2
2017-07-02 13:47:05.198286 EDT | AverageDiscountedReturn    99.9957
2017-07-02 13:47:05.198430 EDT | AverageQLoss                0.0326773
2017-07-02 13:47:05.198598 EDT | AveragePolicySurr          -2.79248
2017-07-02 13:47:05.198720 EDT | AverageQ                    2.61698
2017-07-02 13:47:05.198853 EDT | AverageAbsQ                 2.62492
2017-07-02 13:47:05.199006 EDT | AverageY                    2.61698
2017-07-02 13:47:05.199147 EDT | AverageAbsY                 2.61736
2017-07-02 13:47:05.199249 EDT | AverageAbsQYDiff            0.0536042
2017-07-02 13:47:05.199430 EDT | AverageAction               0.280089
2017-07-02 13:47:05.199604 EDT | PolicyRegParamNorm         50.895
2017-07-02 13:47:05.199805 EDT | QFunRegParamNorm           53.1492
2017-07-02 13:47:05.199994 EDT | -----------------------  ------------
2017-07-02 13:47:05.200273 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #316 | Training started
2017-07-02 13:47:14.863576 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #316 | Training finished
2017-07-02 13:47:14.864133 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #316 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 13:47:14.864368 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #316 | Collecting samples for evaluation
2017-07-02 13:47:20.478665 EDT | -----------------------  ------------
2017-07-02 13:47:20.478971 EDT | Epoch                     316
2017-07-02 13:47:20.479196 EDT | Iteration                 316
2017-07-02 13:47:20.479415 EDT | AverageReturn            1000
2017-07-02 13:47:20.479545 EDT | StdReturn                   0
2017-07-02 13:47:20.479652 EDT | MaxReturn                1000
2017-07-02 13:47:20.479789 EDT | MinReturn                1000
2017-07-02 13:47:20.479916 EDT | AverageEsReturn            28.1944
2017-07-02 13:47:20.480044 EDT | StdEsReturn                21.15
2017-07-02 13:47:20.480169 EDT | MaxEsReturn                83
2017-07-02 13:47:20.480294 EDT | MinEsReturn                 4
2017-07-02 13:47:20.480419 EDT | AverageDiscountedReturn    99.9957
2017-07-02 13:47:20.480555 EDT | AverageQLoss                0.0285156
2017-07-02 13:47:20.480696 EDT | AveragePolicySurr          -2.77722
2017-07-02 13:47:20.480822 EDT | AverageQ                    2.60186
2017-07-02 13:47:20.480981 EDT | AverageAbsQ                 2.60846
2017-07-02 13:47:20.481107 EDT | AverageY                    2.60174
2017-07-02 13:47:20.481230 EDT | AverageAbsY                 2.6022
2017-07-02 13:47:20.481355 EDT | AverageAbsQYDiff            0.0483402
2017-07-02 13:47:20.481477 EDT | AverageAction               0.307817
2017-07-02 13:47:20.481625 EDT | PolicyRegParamNorm         50.9672
2017-07-02 13:47:20.481801 EDT | QFunRegParamNorm           53.1968
2017-07-02 13:47:20.481977 EDT | -----------------------  ------------
2017-07-02 13:47:20.482194 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #317 | Training started
2017-07-02 13:47:30.155811 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #317 | Training finished
2017-07-02 13:47:30.156887 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #317 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 13:47:30.157059 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #317 | Collecting samples for evaluation
2017-07-02 13:47:35.806567 EDT | -----------------------  ------------
2017-07-02 13:47:35.807176 EDT | Epoch                     317
2017-07-02 13:47:35.807397 EDT | Iteration                 317
2017-07-02 13:47:35.807627 EDT | AverageReturn            1000
2017-07-02 13:47:35.807825 EDT | StdReturn                   0
2017-07-02 13:47:35.808051 EDT | MaxReturn                1000
2017-07-02 13:47:35.808220 EDT | MinReturn                1000
2017-07-02 13:47:35.808330 EDT | AverageEsReturn            39.2
2017-07-02 13:47:35.808443 EDT | StdEsReturn                33.9258
2017-07-02 13:47:35.808566 EDT | MaxEsReturn               143
2017-07-02 13:47:35.808669 EDT | MinEsReturn                 5
2017-07-02 13:47:35.808769 EDT | AverageDiscountedReturn    99.9957
2017-07-02 13:47:35.808870 EDT | AverageQLoss                0.0286733
2017-07-02 13:47:35.808992 EDT | AveragePolicySurr          -2.75915
2017-07-02 13:47:35.809096 EDT | AverageQ                    2.59018
2017-07-02 13:47:35.809196 EDT | AverageAbsQ                 2.59743
2017-07-02 13:47:35.809296 EDT | AverageY                    2.58993
2017-07-02 13:47:35.809396 EDT | AverageAbsY                 2.59076
2017-07-02 13:47:35.809510 EDT | AverageAbsQYDiff            0.0480472
2017-07-02 13:47:35.809649 EDT | AverageAction               0.393167
2017-07-02 13:47:35.809752 EDT | PolicyRegParamNorm         51.0628
2017-07-02 13:47:35.809853 EDT | QFunRegParamNorm           53.2396
2017-07-02 13:47:35.809955 EDT | -----------------------  ------------
2017-07-02 13:47:35.810120 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #318 | Training started
2017-07-02 13:47:45.473245 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #318 | Training finished
2017-07-02 13:47:45.473885 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #318 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 13:47:45.474247 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #318 | Collecting samples for evaluation
2017-07-02 13:47:51.071869 EDT | -----------------------  ------------
2017-07-02 13:47:51.072103 EDT | Epoch                     318
2017-07-02 13:47:51.072255 EDT | Iteration                 318
2017-07-02 13:47:51.072450 EDT | AverageReturn            1000
2017-07-02 13:47:51.072559 EDT | StdReturn                   0
2017-07-02 13:47:51.072858 EDT | MaxReturn                1000
2017-07-02 13:47:51.073014 EDT | MinReturn                1000
2017-07-02 13:47:51.073224 EDT | AverageEsReturn            28
2017-07-02 13:47:51.073433 EDT | StdEsReturn                22.4536
2017-07-02 13:47:51.073643 EDT | MaxEsReturn                94
2017-07-02 13:47:51.073772 EDT | MinEsReturn                 3
2017-07-02 13:47:51.073875 EDT | AverageDiscountedReturn    99.9957
2017-07-02 13:47:51.073978 EDT | AverageQLoss                0.0277985
2017-07-02 13:47:51.074145 EDT | AveragePolicySurr          -2.75379
2017-07-02 13:47:51.074270 EDT | AverageQ                    2.58617
2017-07-02 13:47:51.074373 EDT | AverageAbsQ                 2.59291
2017-07-02 13:47:51.074527 EDT | AverageY                    2.58614
2017-07-02 13:47:51.074706 EDT | AverageAbsY                 2.5871
2017-07-02 13:47:51.074807 EDT | AverageAbsQYDiff            0.0483499
2017-07-02 13:47:51.074946 EDT | AverageAction               0.521156
2017-07-02 13:47:51.075150 EDT | PolicyRegParamNorm         51.1313
2017-07-02 13:47:51.075364 EDT | QFunRegParamNorm           53.278
2017-07-02 13:47:51.075522 EDT | -----------------------  ------------
2017-07-02 13:47:51.075695 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #319 | Training started
2017-07-02 13:48:00.787389 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #319 | Training finished
2017-07-02 13:48:00.787874 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #319 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 13:48:00.788117 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #319 | Collecting samples for evaluation
2017-07-02 13:48:06.511773 EDT | -----------------------  ------------
2017-07-02 13:48:06.512261 EDT | Epoch                     319
2017-07-02 13:48:06.512482 EDT | Iteration                 319
2017-07-02 13:48:06.512622 EDT | AverageReturn            1000
2017-07-02 13:48:06.512744 EDT | StdReturn                   0
2017-07-02 13:48:06.512906 EDT | MaxReturn                1000
2017-07-02 13:48:06.513034 EDT | MinReturn                1000
2017-07-02 13:48:06.513137 EDT | AverageEsReturn            33.4643
2017-07-02 13:48:06.513250 EDT | StdEsReturn                22.6092
2017-07-02 13:48:06.513390 EDT | MaxEsReturn               104
2017-07-02 13:48:06.513608 EDT | MinEsReturn                 6
2017-07-02 13:48:06.513809 EDT | AverageDiscountedReturn    99.9957
2017-07-02 13:48:06.513996 EDT | AverageQLoss                0.0276963
2017-07-02 13:48:06.514156 EDT | AveragePolicySurr          -2.73294
2017-07-02 13:48:06.514334 EDT | AverageQ                    2.57281
2017-07-02 13:48:06.514527 EDT | AverageAbsQ                 2.58088
2017-07-02 13:48:06.514697 EDT | AverageY                    2.57283
2017-07-02 13:48:06.514871 EDT | AverageAbsY                 2.57379
2017-07-02 13:48:06.515059 EDT | AverageAbsQYDiff            0.0488098
2017-07-02 13:48:06.515188 EDT | AverageAction               0.285545
2017-07-02 13:48:06.515294 EDT | PolicyRegParamNorm         51.1396
2017-07-02 13:48:06.515428 EDT | QFunRegParamNorm           53.3625
2017-07-02 13:48:06.515560 EDT | -----------------------  ------------
2017-07-02 13:48:06.515723 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #320 | Training started
2017-07-02 13:48:16.444858 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #320 | Training finished
2017-07-02 13:48:16.445435 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #320 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 13:48:16.445599 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #320 | Collecting samples for evaluation
2017-07-02 13:48:22.093760 EDT | -----------------------  ------------
2017-07-02 13:48:22.093955 EDT | Epoch                     320
2017-07-02 13:48:22.094075 EDT | Iteration                 320
2017-07-02 13:48:22.094208 EDT | AverageReturn            1000
2017-07-02 13:48:22.094346 EDT | StdReturn                   0
2017-07-02 13:48:22.094455 EDT | MaxReturn                1000
2017-07-02 13:48:22.094568 EDT | MinReturn                1000
2017-07-02 13:48:22.094680 EDT | AverageEsReturn            28.0263
2017-07-02 13:48:22.094783 EDT | StdEsReturn                27.6382
2017-07-02 13:48:22.094905 EDT | MaxEsReturn               125
2017-07-02 13:48:22.095017 EDT | MinEsReturn                 3
2017-07-02 13:48:22.095137 EDT | AverageDiscountedReturn    99.9957
2017-07-02 13:48:22.095239 EDT | AverageQLoss                0.0261028
2017-07-02 13:48:22.095387 EDT | AveragePolicySurr          -2.7122
2017-07-02 13:48:22.095505 EDT | AverageQ                    2.54637
2017-07-02 13:48:22.095628 EDT | AverageAbsQ                 2.55364
2017-07-02 13:48:22.095744 EDT | AverageY                    2.54631
2017-07-02 13:48:22.095898 EDT | AverageAbsY                 2.54716
2017-07-02 13:48:22.096001 EDT | AverageAbsQYDiff            0.0482696
2017-07-02 13:48:22.096103 EDT | AverageAction               0.209099
2017-07-02 13:48:22.096227 EDT | PolicyRegParamNorm         51.1759
2017-07-02 13:48:22.096345 EDT | QFunRegParamNorm           53.4543
2017-07-02 13:48:22.096483 EDT | -----------------------  ------------
2017-07-02 13:48:22.096681 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #321 | Training started
2017-07-02 13:48:31.715163 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #321 | Training finished
2017-07-02 13:48:31.715720 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #321 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 13:48:31.715901 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #321 | Collecting samples for evaluation
2017-07-02 13:48:37.364845 EDT | -----------------------  ------------
2017-07-02 13:48:37.365738 EDT | Epoch                     321
2017-07-02 13:48:37.365971 EDT | Iteration                 321
2017-07-02 13:48:37.366214 EDT | AverageReturn            1000
2017-07-02 13:48:37.366427 EDT | StdReturn                   0
2017-07-02 13:48:37.366537 EDT | MaxReturn                1000
2017-07-02 13:48:37.366668 EDT | MinReturn                1000
2017-07-02 13:48:37.366788 EDT | AverageEsReturn            51.2105
2017-07-02 13:48:37.367027 EDT | StdEsReturn                34.6647
2017-07-02 13:48:37.367245 EDT | MaxEsReturn               126
2017-07-02 13:48:37.367354 EDT | MinEsReturn                 9
2017-07-02 13:48:37.367457 EDT | AverageDiscountedReturn    99.9957
2017-07-02 13:48:37.367558 EDT | AverageQLoss                0.021892
2017-07-02 13:48:37.367658 EDT | AveragePolicySurr          -2.69502
2017-07-02 13:48:37.367757 EDT | AverageQ                    2.52826
2017-07-02 13:48:37.367856 EDT | AverageAbsQ                 2.53464
2017-07-02 13:48:37.367971 EDT | AverageY                    2.52823
2017-07-02 13:48:37.368208 EDT | AverageAbsY                 2.52947
2017-07-02 13:48:37.368426 EDT | AverageAbsQYDiff            0.0434552
2017-07-02 13:48:37.368659 EDT | AverageAction               0.518812
2017-07-02 13:48:37.368889 EDT | PolicyRegParamNorm         51.1635
2017-07-02 13:48:37.369055 EDT | QFunRegParamNorm           53.5179
2017-07-02 13:48:37.369293 EDT | -----------------------  ------------
2017-07-02 13:48:37.369590 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #322 | Training started
2017-07-02 13:48:47.033134 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #322 | Training finished
2017-07-02 13:48:47.033770 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #322 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 13:48:47.033930 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #322 | Collecting samples for evaluation
2017-07-02 13:48:52.715898 EDT | -----------------------  ------------
2017-07-02 13:48:52.716421 EDT | Epoch                     322
2017-07-02 13:48:52.716657 EDT | Iteration                 322
2017-07-02 13:48:52.716870 EDT | AverageReturn            1000
2017-07-02 13:48:52.717026 EDT | StdReturn                   0
2017-07-02 13:48:52.717138 EDT | MaxReturn                1000
2017-07-02 13:48:52.717367 EDT | MinReturn                1000
2017-07-02 13:48:52.717562 EDT | AverageEsReturn            29.4571
2017-07-02 13:48:52.717700 EDT | StdEsReturn                22.029
2017-07-02 13:48:52.717900 EDT | MaxEsReturn                96
2017-07-02 13:48:52.718076 EDT | MinEsReturn                 3
2017-07-02 13:48:52.718220 EDT | AverageDiscountedReturn    99.9957
2017-07-02 13:48:52.718408 EDT | AverageQLoss                0.0257768
2017-07-02 13:48:52.718595 EDT | AveragePolicySurr          -2.6879
2017-07-02 13:48:52.718792 EDT | AverageQ                    2.52483
2017-07-02 13:48:52.719009 EDT | AverageAbsQ                 2.53192
2017-07-02 13:48:52.719127 EDT | AverageY                    2.52467
2017-07-02 13:48:52.719230 EDT | AverageAbsY                 2.52566
2017-07-02 13:48:52.719332 EDT | AverageAbsQYDiff            0.0472319
2017-07-02 13:48:52.719498 EDT | AverageAction               0.519192
2017-07-02 13:48:52.719661 EDT | PolicyRegParamNorm         51.1618
2017-07-02 13:48:52.719792 EDT | QFunRegParamNorm           53.5446
2017-07-02 13:48:52.719927 EDT | -----------------------  ------------
2017-07-02 13:48:52.720098 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #323 | Training started
2017-07-02 13:49:02.414594 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #323 | Training finished
2017-07-02 13:49:02.415201 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #323 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 13:49:02.415444 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #323 | Collecting samples for evaluation
2017-07-02 13:49:08.042928 EDT | -----------------------  ------------
2017-07-02 13:49:08.043234 EDT | Epoch                     323
2017-07-02 13:49:08.043469 EDT | Iteration                 323
2017-07-02 13:49:08.043706 EDT | AverageReturn            1000
2017-07-02 13:49:08.043939 EDT | StdReturn                   0
2017-07-02 13:49:08.044136 EDT | MaxReturn                1000
2017-07-02 13:49:08.044372 EDT | MinReturn                1000
2017-07-02 13:49:08.044561 EDT | AverageEsReturn            29.2941
2017-07-02 13:49:08.044796 EDT | StdEsReturn                24.2384
2017-07-02 13:49:08.045018 EDT | MaxEsReturn               102
2017-07-02 13:49:08.045149 EDT | MinEsReturn                 4
2017-07-02 13:49:08.045383 EDT | AverageDiscountedReturn    99.9957
2017-07-02 13:49:08.046128 EDT | AverageQLoss                0.0242648
2017-07-02 13:49:08.046271 EDT | AveragePolicySurr          -2.66634
2017-07-02 13:49:08.046509 EDT | AverageQ                    2.50294
2017-07-02 13:49:08.046728 EDT | AverageAbsQ                 2.51094
2017-07-02 13:49:08.046946 EDT | AverageY                    2.50296
2017-07-02 13:49:08.047178 EDT | AverageAbsY                 2.50428
2017-07-02 13:49:08.047348 EDT | AverageAbsQYDiff            0.0470285
2017-07-02 13:49:08.047583 EDT | AverageAction               0.432274
2017-07-02 13:49:08.047777 EDT | PolicyRegParamNorm         51.2269
2017-07-02 13:49:08.048009 EDT | QFunRegParamNorm           53.5944
2017-07-02 13:49:08.048229 EDT | -----------------------  ------------
2017-07-02 13:49:08.048525 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #324 | Training started
2017-07-02 13:49:17.871267 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #324 | Training finished
2017-07-02 13:49:17.871876 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #324 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 13:49:17.872145 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #324 | Collecting samples for evaluation
2017-07-02 13:49:23.509053 EDT | -----------------------  ------------
2017-07-02 13:49:23.509377 EDT | Epoch                     324
2017-07-02 13:49:23.509599 EDT | Iteration                 324
2017-07-02 13:49:23.509906 EDT | AverageReturn            1000
2017-07-02 13:49:23.510162 EDT | StdReturn                   0
2017-07-02 13:49:23.510334 EDT | MaxReturn                1000
2017-07-02 13:49:23.510507 EDT | MinReturn                1000
2017-07-02 13:49:23.510750 EDT | AverageEsReturn            29.2059
2017-07-02 13:49:23.510983 EDT | StdEsReturn                23.7311
2017-07-02 13:49:23.511147 EDT | MaxEsReturn                86
2017-07-02 13:49:23.511419 EDT | MinEsReturn                 3
2017-07-02 13:49:23.511628 EDT | AverageDiscountedReturn    99.9957
2017-07-02 13:49:23.511862 EDT | AverageQLoss                0.0257325
2017-07-02 13:49:23.512086 EDT | AveragePolicySurr          -2.65383
2017-07-02 13:49:23.512265 EDT | AverageQ                    2.49573
2017-07-02 13:49:23.512497 EDT | AverageAbsQ                 2.50305
2017-07-02 13:49:23.512682 EDT | AverageY                    2.49574
2017-07-02 13:49:23.512917 EDT | AverageAbsY                 2.4966
2017-07-02 13:49:23.513132 EDT | AverageAbsQYDiff            0.048161
2017-07-02 13:49:23.513242 EDT | AverageAction               0.417649
2017-07-02 13:49:23.513351 EDT | PolicyRegParamNorm         51.2965
2017-07-02 13:49:23.513454 EDT | QFunRegParamNorm           53.6386
2017-07-02 13:49:23.513630 EDT | -----------------------  ------------
2017-07-02 13:49:23.513960 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #325 | Training started
2017-07-02 13:49:33.260041 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #325 | Training finished
2017-07-02 13:49:33.260540 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #325 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 13:49:33.260753 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #325 | Collecting samples for evaluation
2017-07-02 13:49:39.034736 EDT | -----------------------  ------------
2017-07-02 13:49:39.035017 EDT | Epoch                     325
2017-07-02 13:49:39.035130 EDT | Iteration                 325
2017-07-02 13:49:39.035234 EDT | AverageReturn            1000
2017-07-02 13:49:39.035368 EDT | StdReturn                   0
2017-07-02 13:49:39.035470 EDT | MaxReturn                1000
2017-07-02 13:49:39.035571 EDT | MinReturn                1000
2017-07-02 13:49:39.035684 EDT | AverageEsReturn            38.88
2017-07-02 13:49:39.035826 EDT | StdEsReturn                27.7248
2017-07-02 13:49:39.035930 EDT | MaxEsReturn                96
2017-07-02 13:49:39.036030 EDT | MinEsReturn                 4
2017-07-02 13:49:39.036130 EDT | AverageDiscountedReturn    99.9957
2017-07-02 13:49:39.036233 EDT | AverageQLoss                0.0229357
2017-07-02 13:49:39.036342 EDT | AveragePolicySurr          -2.63182
2017-07-02 13:49:39.036456 EDT | AverageQ                    2.46897
2017-07-02 13:49:39.036557 EDT | AverageAbsQ                 2.47565
2017-07-02 13:49:39.036657 EDT | AverageY                    2.4689
2017-07-02 13:49:39.036772 EDT | AverageAbsY                 2.4701
2017-07-02 13:49:39.036904 EDT | AverageAbsQYDiff            0.0449899
2017-07-02 13:49:39.037044 EDT | AverageAction               0.491424
2017-07-02 13:49:39.037153 EDT | PolicyRegParamNorm         51.3138
2017-07-02 13:49:39.037261 EDT | QFunRegParamNorm           53.7769
2017-07-02 13:49:39.037420 EDT | -----------------------  ------------
2017-07-02 13:49:39.037706 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #326 | Training started
2017-07-02 13:49:48.724348 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #326 | Training finished
2017-07-02 13:49:48.779162 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #326 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 13:49:48.779373 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #326 | Collecting samples for evaluation
2017-07-02 13:49:54.487708 EDT | -----------------------  ------------
2017-07-02 13:49:54.487942 EDT | Epoch                     326
2017-07-02 13:49:54.488179 EDT | Iteration                 326
2017-07-02 13:49:54.488392 EDT | AverageReturn            1000
2017-07-02 13:49:54.488622 EDT | StdReturn                   0
2017-07-02 13:49:54.488840 EDT | MaxReturn                1000
2017-07-02 13:49:54.489036 EDT | MinReturn                1000
2017-07-02 13:49:54.489261 EDT | AverageEsReturn            31.5455
2017-07-02 13:49:54.489476 EDT | StdEsReturn                28.4787
2017-07-02 13:49:54.489778 EDT | MaxEsReturn               111
2017-07-02 13:49:54.489952 EDT | MinEsReturn                 3
2017-07-02 13:49:54.490172 EDT | AverageDiscountedReturn    99.9957
2017-07-02 13:49:54.490390 EDT | AverageQLoss                0.0253606
2017-07-02 13:49:54.490612 EDT | AveragePolicySurr          -2.61981
2017-07-02 13:49:54.490729 EDT | AverageQ                    2.46254
2017-07-02 13:49:54.490842 EDT | AverageAbsQ                 2.47043
2017-07-02 13:49:54.491074 EDT | AverageY                    2.46249
2017-07-02 13:49:54.491284 EDT | AverageAbsY                 2.46341
2017-07-02 13:49:54.491512 EDT | AverageAbsQYDiff            0.0473758
2017-07-02 13:49:54.491686 EDT | AverageAction               0.537181
2017-07-02 13:49:54.491910 EDT | PolicyRegParamNorm         51.3326
2017-07-02 13:49:54.492124 EDT | QFunRegParamNorm           53.8437
2017-07-02 13:49:54.492347 EDT | -----------------------  ------------
2017-07-02 13:49:54.492613 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #327 | Training started
2017-07-02 13:50:04.003040 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #327 | Training finished
2017-07-02 13:50:04.003722 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #327 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 13:50:04.003957 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #327 | Collecting samples for evaluation
2017-07-02 13:50:09.810017 EDT | -----------------------  ------------
2017-07-02 13:50:09.810342 EDT | Epoch                     327
2017-07-02 13:50:09.810589 EDT | Iteration                 327
2017-07-02 13:50:09.810821 EDT | AverageReturn            1000
2017-07-02 13:50:09.810942 EDT | StdReturn                   0
2017-07-02 13:50:09.811174 EDT | MaxReturn                1000
2017-07-02 13:50:09.811399 EDT | MinReturn                1000
2017-07-02 13:50:09.811534 EDT | AverageEsReturn            32.2667
2017-07-02 13:50:09.811773 EDT | StdEsReturn                24.2459
2017-07-02 13:50:09.812000 EDT | MaxEsReturn                90
2017-07-02 13:50:09.812113 EDT | MinEsReturn                 3
2017-07-02 13:50:09.812335 EDT | AverageDiscountedReturn    99.9957
2017-07-02 13:50:09.812568 EDT | AverageQLoss                0.0233438
2017-07-02 13:50:09.812737 EDT | AveragePolicySurr          -2.61153
2017-07-02 13:50:09.812972 EDT | AverageQ                    2.45399
2017-07-02 13:50:09.813190 EDT | AverageAbsQ                 2.46118
2017-07-02 13:50:09.813301 EDT | AverageY                    2.45399
2017-07-02 13:50:09.813571 EDT | AverageAbsY                 2.4552
2017-07-02 13:50:09.813799 EDT | AverageAbsQYDiff            0.0448939
2017-07-02 13:50:09.813967 EDT | AverageAction               0.41637
2017-07-02 13:50:09.814206 EDT | PolicyRegParamNorm         51.4165
2017-07-02 13:50:09.814407 EDT | QFunRegParamNorm           53.9371
2017-07-02 13:50:09.814623 EDT | -----------------------  ------------
2017-07-02 13:50:09.814943 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #328 | Training started
2017-07-02 13:50:19.519111 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #328 | Training finished
2017-07-02 13:50:19.519714 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #328 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 13:50:19.519898 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #328 | Collecting samples for evaluation
2017-07-02 13:50:25.558354 EDT | -----------------------  ------------
2017-07-02 13:50:25.558557 EDT | Epoch                     328
2017-07-02 13:50:25.558717 EDT | Iteration                 328
2017-07-02 13:50:25.558829 EDT | AverageReturn            1000
2017-07-02 13:50:25.558952 EDT | StdReturn                   0
2017-07-02 13:50:25.559112 EDT | MaxReturn                1000
2017-07-02 13:50:25.559243 EDT | MinReturn                1000
2017-07-02 13:50:25.559374 EDT | AverageEsReturn            27.3514
2017-07-02 13:50:25.559484 EDT | StdEsReturn                26.1133
2017-07-02 13:50:25.559598 EDT | MaxEsReturn               147
2017-07-02 13:50:25.559809 EDT | MinEsReturn                 5
2017-07-02 13:50:25.560019 EDT | AverageDiscountedReturn    99.9957
2017-07-02 13:50:25.560163 EDT | AverageQLoss                0.0213905
2017-07-02 13:50:25.560288 EDT | AveragePolicySurr          -2.59265
2017-07-02 13:50:25.560425 EDT | AverageQ                    2.43566
2017-07-02 13:50:25.560574 EDT | AverageAbsQ                 2.4429
2017-07-02 13:50:25.560675 EDT | AverageY                    2.43564
2017-07-02 13:50:25.560811 EDT | AverageAbsY                 2.43661
2017-07-02 13:50:25.560943 EDT | AverageAbsQYDiff            0.043203
2017-07-02 13:50:25.561046 EDT | AverageAction               0.35213
2017-07-02 13:50:25.561147 EDT | PolicyRegParamNorm         51.486
2017-07-02 13:50:25.561277 EDT | QFunRegParamNorm           53.9541
2017-07-02 13:50:25.561397 EDT | -----------------------  ------------
2017-07-02 13:50:25.561660 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #329 | Training started
2017-07-02 13:50:35.113221 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #329 | Training finished
2017-07-02 13:50:35.114108 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #329 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 13:50:35.114374 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #329 | Collecting samples for evaluation
2017-07-02 13:50:40.781408 EDT | -----------------------  ------------
2017-07-02 13:50:40.781641 EDT | Epoch                     329
2017-07-02 13:50:40.781933 EDT | Iteration                 329
2017-07-02 13:50:40.782167 EDT | AverageReturn            1000
2017-07-02 13:50:40.782313 EDT | StdReturn                   0
2017-07-02 13:50:40.782459 EDT | MaxReturn                1000
2017-07-02 13:50:40.782571 EDT | MinReturn                1000
2017-07-02 13:50:40.782793 EDT | AverageEsReturn            25.4872
2017-07-02 13:50:40.783003 EDT | StdEsReturn                19.2579
2017-07-02 13:50:40.783236 EDT | MaxEsReturn                84
2017-07-02 13:50:40.783461 EDT | MinEsReturn                 3
2017-07-02 13:50:40.783694 EDT | AverageDiscountedReturn    99.9957
2017-07-02 13:50:40.783920 EDT | AverageQLoss                0.0218763
2017-07-02 13:50:40.784142 EDT | AveragePolicySurr          -2.58386
2017-07-02 13:50:40.784355 EDT | AverageQ                    2.43776
2017-07-02 13:50:40.784471 EDT | AverageAbsQ                 2.44538
2017-07-02 13:50:40.784657 EDT | AverageY                    2.43772
2017-07-02 13:50:40.784888 EDT | AverageAbsY                 2.43921
2017-07-02 13:50:40.785005 EDT | AverageAbsQYDiff            0.0440046
2017-07-02 13:50:40.785114 EDT | AverageAction               0.357782
2017-07-02 13:50:40.785221 EDT | PolicyRegParamNorm         51.515
2017-07-02 13:50:40.785329 EDT | QFunRegParamNorm           53.995
2017-07-02 13:50:40.785522 EDT | -----------------------  ------------
2017-07-02 13:50:40.785851 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #330 | Training started
2017-07-02 13:50:50.389599 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #330 | Training finished
2017-07-02 13:50:50.390180 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #330 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 13:50:50.390348 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #330 | Collecting samples for evaluation
2017-07-02 13:50:56.075070 EDT | -----------------------  ------------
2017-07-02 13:50:56.075388 EDT | Epoch                     330
2017-07-02 13:50:56.075615 EDT | Iteration                 330
2017-07-02 13:50:56.075825 EDT | AverageReturn            1000
2017-07-02 13:50:56.076047 EDT | StdReturn                   0
2017-07-02 13:50:56.076270 EDT | MaxReturn                1000
2017-07-02 13:50:56.076471 EDT | MinReturn                1000
2017-07-02 13:50:56.076613 EDT | AverageEsReturn            37.8889
2017-07-02 13:50:56.076773 EDT | StdEsReturn                30.4842
2017-07-02 13:50:56.076989 EDT | MaxEsReturn               139
2017-07-02 13:50:56.077139 EDT | MinEsReturn                 3
2017-07-02 13:50:56.077362 EDT | AverageDiscountedReturn    99.9957
2017-07-02 13:50:56.077615 EDT | AverageQLoss                0.0218969
2017-07-02 13:50:56.077843 EDT | AveragePolicySurr          -2.57005
2017-07-02 13:50:56.078068 EDT | AverageQ                    2.41615
2017-07-02 13:50:56.078289 EDT | AverageAbsQ                 2.42307
2017-07-02 13:50:56.078507 EDT | AverageY                    2.41602
2017-07-02 13:50:56.078707 EDT | AverageAbsY                 2.41748
2017-07-02 13:50:56.078904 EDT | AverageAbsQYDiff            0.0446793
2017-07-02 13:50:56.079119 EDT | AverageAction               0.48046
2017-07-02 13:50:56.079304 EDT | PolicyRegParamNorm         51.5497
2017-07-02 13:50:56.079533 EDT | QFunRegParamNorm           54.0611
2017-07-02 13:50:56.079754 EDT | -----------------------  ------------
2017-07-02 13:50:56.080076 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #331 | Training started
2017-07-02 13:51:05.692460 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #331 | Training finished
2017-07-02 13:51:05.692959 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #331 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 13:51:05.693123 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #331 | Collecting samples for evaluation
2017-07-02 13:51:11.368934 EDT | -----------------------  ------------
2017-07-02 13:51:11.369125 EDT | Epoch                     331
2017-07-02 13:51:11.369281 EDT | Iteration                 331
2017-07-02 13:51:11.369413 EDT | AverageReturn            1000
2017-07-02 13:51:11.369625 EDT | StdReturn                   0
2017-07-02 13:51:11.369765 EDT | MaxReturn                1000
2017-07-02 13:51:11.369895 EDT | MinReturn                1000
2017-07-02 13:51:11.370052 EDT | AverageEsReturn            39.0833
2017-07-02 13:51:11.370183 EDT | StdEsReturn                26.7191
2017-07-02 13:51:11.370293 EDT | MaxEsReturn                93
2017-07-02 13:51:11.370400 EDT | MinEsReturn                 3
2017-07-02 13:51:11.370579 EDT | AverageDiscountedReturn    99.9957
2017-07-02 13:51:11.370823 EDT | AverageQLoss                0.0211799
2017-07-02 13:51:11.371056 EDT | AveragePolicySurr          -2.55569
2017-07-02 13:51:11.371296 EDT | AverageQ                    2.40689
2017-07-02 13:51:11.371535 EDT | AverageAbsQ                 2.41425
2017-07-02 13:51:11.371766 EDT | AverageY                    2.40684
2017-07-02 13:51:11.372068 EDT | AverageAbsY                 2.40746
2017-07-02 13:51:11.372370 EDT | AverageAbsQYDiff            0.044693
2017-07-02 13:51:11.372585 EDT | AverageAction               0.534409
2017-07-02 13:51:11.372825 EDT | PolicyRegParamNorm         51.5965
2017-07-02 13:51:11.373058 EDT | QFunRegParamNorm           54.0934
2017-07-02 13:51:11.373255 EDT | -----------------------  ------------
2017-07-02 13:51:11.373594 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #332 | Training started
2017-07-02 13:51:20.943626 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #332 | Training finished
2017-07-02 13:51:20.944257 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #332 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 13:51:20.944505 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #332 | Collecting samples for evaluation
2017-07-02 13:51:26.581654 EDT | -----------------------  ------------
2017-07-02 13:51:26.581968 EDT | Epoch                     332
2017-07-02 13:51:26.582185 EDT | Iteration                 332
2017-07-02 13:51:26.582420 EDT | AverageReturn            1000
2017-07-02 13:51:26.582648 EDT | StdReturn                   0
2017-07-02 13:51:26.582829 EDT | MaxReturn                1000
2017-07-02 13:51:26.582949 EDT | MinReturn                1000
2017-07-02 13:51:26.583095 EDT | AverageEsReturn            43.6667
2017-07-02 13:51:26.583240 EDT | StdEsReturn                31.9174
2017-07-02 13:51:26.583394 EDT | MaxEsReturn               121
2017-07-02 13:51:26.583545 EDT | MinEsReturn                 6
2017-07-02 13:51:26.583649 EDT | AverageDiscountedReturn    99.9957
2017-07-02 13:51:26.583751 EDT | AverageQLoss                0.0240528
2017-07-02 13:51:26.583914 EDT | AveragePolicySurr          -2.53709
2017-07-02 13:51:26.584045 EDT | AverageQ                    2.38619
2017-07-02 13:51:26.584146 EDT | AverageAbsQ                 2.39332
2017-07-02 13:51:26.584266 EDT | AverageY                    2.3861
2017-07-02 13:51:26.584407 EDT | AverageAbsY                 2.38682
2017-07-02 13:51:26.584600 EDT | AverageAbsQYDiff            0.044617
2017-07-02 13:51:26.584721 EDT | AverageAction               0.303767
2017-07-02 13:51:26.584873 EDT | PolicyRegParamNorm         51.573
2017-07-02 13:51:26.584989 EDT | QFunRegParamNorm           54.132
2017-07-02 13:51:26.585197 EDT | -----------------------  ------------
2017-07-02 13:51:26.585436 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #333 | Training started
2017-07-02 13:51:36.192735 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #333 | Training finished
2017-07-02 13:51:36.193322 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #333 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 13:51:36.193610 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #333 | Collecting samples for evaluation
2017-07-02 13:51:41.817671 EDT | -----------------------  ------------
2017-07-02 13:51:41.817904 EDT | Epoch                     333
2017-07-02 13:51:41.818016 EDT | Iteration                 333
2017-07-02 13:51:41.818122 EDT | AverageReturn            1000
2017-07-02 13:51:41.818307 EDT | StdReturn                   0
2017-07-02 13:51:41.818413 EDT | MaxReturn                1000
2017-07-02 13:51:41.818515 EDT | MinReturn                1000
2017-07-02 13:51:41.818667 EDT | AverageEsReturn            26.6
2017-07-02 13:51:41.818771 EDT | StdEsReturn                18.7924
2017-07-02 13:51:41.818882 EDT | MaxEsReturn                89
2017-07-02 13:51:41.819018 EDT | MinEsReturn                 4
2017-07-02 13:51:41.819121 EDT | AverageDiscountedReturn    99.9957
2017-07-02 13:51:41.819221 EDT | AverageQLoss                0.022032
2017-07-02 13:51:41.819372 EDT | AveragePolicySurr          -2.52554
2017-07-02 13:51:41.819502 EDT | AverageQ                    2.37667
2017-07-02 13:51:41.819604 EDT | AverageAbsQ                 2.38353
2017-07-02 13:51:41.819787 EDT | AverageY                    2.37664
2017-07-02 13:51:41.820018 EDT | AverageAbsY                 2.3772
2017-07-02 13:51:41.820230 EDT | AverageAbsQYDiff            0.0433041
2017-07-02 13:51:41.820338 EDT | AverageAction               0.545671
2017-07-02 13:51:41.820440 EDT | PolicyRegParamNorm         51.6239
2017-07-02 13:51:41.820604 EDT | QFunRegParamNorm           54.2108
2017-07-02 13:51:41.820831 EDT | -----------------------  ------------
2017-07-02 13:51:41.821147 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #334 | Training started
2017-07-02 13:51:51.450953 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #334 | Training finished
2017-07-02 13:51:51.451581 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #334 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 13:51:51.451809 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #334 | Collecting samples for evaluation
2017-07-02 13:51:57.101677 EDT | -----------------------  ------------
2017-07-02 13:51:57.101867 EDT | Epoch                     334
2017-07-02 13:51:57.102021 EDT | Iteration                 334
2017-07-02 13:51:57.102252 EDT | AverageReturn            1000
2017-07-02 13:51:57.102433 EDT | StdReturn                   0
2017-07-02 13:51:57.102658 EDT | MaxReturn                1000
2017-07-02 13:51:57.102857 EDT | MinReturn                1000
2017-07-02 13:51:57.103089 EDT | AverageEsReturn            29.0857
2017-07-02 13:51:57.103315 EDT | StdEsReturn                22.2292
2017-07-02 13:51:57.103537 EDT | MaxEsReturn                89
2017-07-02 13:51:57.103758 EDT | MinEsReturn                 5
2017-07-02 13:51:57.103958 EDT | AverageDiscountedReturn    99.9957
2017-07-02 13:51:57.104139 EDT | AverageQLoss                0.0223145
2017-07-02 13:51:57.104355 EDT | AveragePolicySurr          -2.51139
2017-07-02 13:51:57.104542 EDT | AverageQ                    2.36347
2017-07-02 13:51:57.104778 EDT | AverageAbsQ                 2.37063
2017-07-02 13:51:57.105000 EDT | AverageY                    2.36345
2017-07-02 13:51:57.105220 EDT | AverageAbsY                 2.36421
2017-07-02 13:51:57.105434 EDT | AverageAbsQYDiff            0.0452329
2017-07-02 13:51:57.105607 EDT | AverageAction               0.26463
2017-07-02 13:51:57.105839 EDT | PolicyRegParamNorm         51.6567
2017-07-02 13:51:57.106062 EDT | QFunRegParamNorm           54.2812
2017-07-02 13:51:57.106283 EDT | -----------------------  ------------
2017-07-02 13:51:57.106614 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #335 | Training started
2017-07-02 13:52:06.775762 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #335 | Training finished
2017-07-02 13:52:06.776351 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #335 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 13:52:06.776500 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #335 | Collecting samples for evaluation
2017-07-02 13:52:12.452863 EDT | -----------------------  ------------
2017-07-02 13:52:12.453102 EDT | Epoch                     335
2017-07-02 13:52:12.453272 EDT | Iteration                 335
2017-07-02 13:52:12.453438 EDT | AverageReturn            1000
2017-07-02 13:52:12.453657 EDT | StdReturn                   0
2017-07-02 13:52:12.453886 EDT | MaxReturn                1000
2017-07-02 13:52:12.454106 EDT | MinReturn                1000
2017-07-02 13:52:12.454332 EDT | AverageEsReturn            23.4091
2017-07-02 13:52:12.454537 EDT | StdEsReturn                21.6504
2017-07-02 13:52:12.454763 EDT | MaxEsReturn               122
2017-07-02 13:52:12.454993 EDT | MinEsReturn                 3
2017-07-02 13:52:12.455218 EDT | AverageDiscountedReturn    99.9957
2017-07-02 13:52:12.455399 EDT | AverageQLoss                0.021979
2017-07-02 13:52:12.455506 EDT | AveragePolicySurr          -2.49431
2017-07-02 13:52:12.455630 EDT | AverageQ                    2.34063
2017-07-02 13:52:12.455846 EDT | AverageAbsQ                 2.34797
2017-07-02 13:52:12.456042 EDT | AverageY                    2.34047
2017-07-02 13:52:12.456265 EDT | AverageAbsY                 2.34105
2017-07-02 13:52:12.456471 EDT | AverageAbsQYDiff            0.0443437
2017-07-02 13:52:12.456686 EDT | AverageAction               0.44238
2017-07-02 13:52:12.456913 EDT | PolicyRegParamNorm         51.7177
2017-07-02 13:52:12.457132 EDT | QFunRegParamNorm           54.3366
2017-07-02 13:52:12.457349 EDT | -----------------------  ------------
2017-07-02 13:52:12.457683 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #336 | Training started
2017-07-02 13:52:22.121055 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #336 | Training finished
2017-07-02 13:52:22.121663 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #336 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 13:52:22.121921 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #336 | Collecting samples for evaluation
2017-07-02 13:52:27.780503 EDT | -----------------------  ------------
2017-07-02 13:52:27.780822 EDT | Epoch                     336
2017-07-02 13:52:27.780993 EDT | Iteration                 336
2017-07-02 13:52:27.781226 EDT | AverageReturn            1000
2017-07-02 13:52:27.781447 EDT | StdReturn                   0
2017-07-02 13:52:27.781675 EDT | MaxReturn                1000
2017-07-02 13:52:27.781822 EDT | MinReturn                1000
2017-07-02 13:52:27.782048 EDT | AverageEsReturn            30.7273
2017-07-02 13:52:27.782167 EDT | StdEsReturn                27.1921
2017-07-02 13:52:27.782344 EDT | MaxEsReturn               153
2017-07-02 13:52:27.782571 EDT | MinEsReturn                 5
2017-07-02 13:52:27.782742 EDT | AverageDiscountedReturn    99.9957
2017-07-02 13:52:27.782878 EDT | AverageQLoss                0.022439
2017-07-02 13:52:27.783040 EDT | AveragePolicySurr          -2.47299
2017-07-02 13:52:27.783255 EDT | AverageQ                    2.32884
2017-07-02 13:52:27.783461 EDT | AverageAbsQ                 2.33565
2017-07-02 13:52:27.783672 EDT | AverageY                    2.32903
2017-07-02 13:52:27.783891 EDT | AverageAbsY                 2.33012
2017-07-02 13:52:27.784119 EDT | AverageAbsQYDiff            0.0432687
2017-07-02 13:52:27.784341 EDT | AverageAction               0.568424
2017-07-02 13:52:27.784558 EDT | PolicyRegParamNorm         51.7945
2017-07-02 13:52:27.784766 EDT | QFunRegParamNorm           54.4255
2017-07-02 13:52:27.784981 EDT | -----------------------  ------------
2017-07-02 13:52:27.785177 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #337 | Training started
2017-07-02 13:52:37.401725 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #337 | Training finished
2017-07-02 13:52:37.402449 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #337 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 13:52:37.402626 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #337 | Collecting samples for evaluation
2017-07-02 13:52:43.110963 EDT | -----------------------  ------------
2017-07-02 13:52:43.111280 EDT | Epoch                     337
2017-07-02 13:52:43.111487 EDT | Iteration                 337
2017-07-02 13:52:43.111719 EDT | AverageReturn            1000
2017-07-02 13:52:43.111931 EDT | StdReturn                   0
2017-07-02 13:52:43.112164 EDT | MaxReturn                1000
2017-07-02 13:52:43.112378 EDT | MinReturn                1000
2017-07-02 13:52:43.112544 EDT | AverageEsReturn            30.2121
2017-07-02 13:52:43.112774 EDT | StdEsReturn                30.0452
2017-07-02 13:52:43.112990 EDT | MaxEsReturn               112
2017-07-02 13:52:43.113193 EDT | MinEsReturn                 3
2017-07-02 13:52:43.113421 EDT | AverageDiscountedReturn    99.9957
2017-07-02 13:52:43.113635 EDT | AverageQLoss                0.0243071
2017-07-02 13:52:43.113813 EDT | AveragePolicySurr          -2.46245
2017-07-02 13:52:43.113919 EDT | AverageQ                    2.31444
2017-07-02 13:52:43.114068 EDT | AverageAbsQ                 2.32166
2017-07-02 13:52:43.114248 EDT | AverageY                    2.31435
2017-07-02 13:52:43.114412 EDT | AverageAbsY                 2.31535
2017-07-02 13:52:43.114634 EDT | AverageAbsQYDiff            0.0463361
2017-07-02 13:52:43.114862 EDT | AverageAction               0.685261
2017-07-02 13:52:43.115046 EDT | PolicyRegParamNorm         51.9199
2017-07-02 13:52:43.115281 EDT | QFunRegParamNorm           54.4739
2017-07-02 13:52:43.115501 EDT | -----------------------  ------------
2017-07-02 13:52:43.115817 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #338 | Training started
2017-07-02 13:52:52.611032 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #338 | Training finished
2017-07-02 13:52:52.611658 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #338 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 13:52:52.611914 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #338 | Collecting samples for evaluation
2017-07-02 13:52:58.381724 EDT | -----------------------  ------------
2017-07-02 13:52:58.382047 EDT | Epoch                     338
2017-07-02 13:52:58.382262 EDT | Iteration                 338
2017-07-02 13:52:58.382495 EDT | AverageReturn            1000
2017-07-02 13:52:58.382725 EDT | StdReturn                   0
2017-07-02 13:52:58.382841 EDT | MaxReturn                1000
2017-07-02 13:52:58.382945 EDT | MinReturn                1000
2017-07-02 13:52:58.383048 EDT | AverageEsReturn            42.3636
2017-07-02 13:52:58.383194 EDT | StdEsReturn                47.9475
2017-07-02 13:52:58.383429 EDT | MaxEsReturn               211
2017-07-02 13:52:58.383630 EDT | MinEsReturn                 6
2017-07-02 13:52:58.383861 EDT | AverageDiscountedReturn    99.9957
2017-07-02 13:52:58.384086 EDT | AverageQLoss                0.0200285
2017-07-02 13:52:58.384234 EDT | AveragePolicySurr          -2.44884
2017-07-02 13:52:58.384469 EDT | AverageQ                    2.30632
2017-07-02 13:52:58.384672 EDT | AverageAbsQ                 2.31369
2017-07-02 13:52:58.384882 EDT | AverageY                    2.30626
2017-07-02 13:52:58.385115 EDT | AverageAbsY                 2.30701
2017-07-02 13:52:58.385279 EDT | AverageAbsQYDiff            0.0442303
2017-07-02 13:52:58.385384 EDT | AverageAction               0.152589
2017-07-02 13:52:58.385595 EDT | PolicyRegParamNorm         51.9783
2017-07-02 13:52:58.385829 EDT | QFunRegParamNorm           54.5811
2017-07-02 13:52:58.385998 EDT | -----------------------  ------------
2017-07-02 13:52:58.386332 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #339 | Training started
2017-07-02 13:53:07.878141 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #339 | Training finished
2017-07-02 13:53:07.878747 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #339 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 13:53:07.878926 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #339 | Collecting samples for evaluation
2017-07-02 13:53:13.617244 EDT | -----------------------  ------------
2017-07-02 13:53:13.617508 EDT | Epoch                     339
2017-07-02 13:53:13.617660 EDT | Iteration                 339
2017-07-02 13:53:13.617769 EDT | AverageReturn            1000
2017-07-02 13:53:13.617871 EDT | StdReturn                   0
2017-07-02 13:53:13.617970 EDT | MaxReturn                1000
2017-07-02 13:53:13.618130 EDT | MinReturn                1000
2017-07-02 13:53:13.618281 EDT | AverageEsReturn            54.75
2017-07-02 13:53:13.618403 EDT | StdEsReturn                48.4457
2017-07-02 13:53:13.618510 EDT | MaxEsReturn               218
2017-07-02 13:53:13.618642 EDT | MinEsReturn                 4
2017-07-02 13:53:13.618787 EDT | AverageDiscountedReturn    99.9957
2017-07-02 13:53:13.618909 EDT | AverageQLoss                0.0222158
2017-07-02 13:53:13.619014 EDT | AveragePolicySurr          -2.44423
2017-07-02 13:53:13.619112 EDT | AverageQ                    2.30399
2017-07-02 13:53:13.619262 EDT | AverageAbsQ                 2.31059
2017-07-02 13:53:13.619473 EDT | AverageY                    2.30403
2017-07-02 13:53:13.619672 EDT | AverageAbsY                 2.30471
2017-07-02 13:53:13.619855 EDT | AverageAbsQYDiff            0.0431338
2017-07-02 13:53:13.619968 EDT | AverageAction               0.599975
2017-07-02 13:53:13.620067 EDT | PolicyRegParamNorm         52.0359
2017-07-02 13:53:13.620202 EDT | QFunRegParamNorm           54.6332
2017-07-02 13:53:13.620384 EDT | -----------------------  ------------
2017-07-02 13:53:13.620580 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #340 | Training started
2017-07-02 13:53:23.119814 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #340 | Training finished
2017-07-02 13:53:23.120432 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #340 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 13:53:23.120712 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #340 | Collecting samples for evaluation
2017-07-02 13:53:28.901217 EDT | -----------------------  ------------
2017-07-02 13:53:28.901452 EDT | Epoch                     340
2017-07-02 13:53:28.901682 EDT | Iteration                 340
2017-07-02 13:53:28.901914 EDT | AverageReturn            1000
2017-07-02 13:53:28.902099 EDT | StdReturn                   0
2017-07-02 13:53:28.902207 EDT | MaxReturn                1000
2017-07-02 13:53:28.902311 EDT | MinReturn                1000
2017-07-02 13:53:28.902413 EDT | AverageEsReturn            49.8
2017-07-02 13:53:28.902514 EDT | StdEsReturn                42.8271
2017-07-02 13:53:28.902614 EDT | MaxEsReturn               173
2017-07-02 13:53:28.902764 EDT | MinEsReturn                 3
2017-07-02 13:53:28.902941 EDT | AverageDiscountedReturn    99.9957
2017-07-02 13:53:28.903068 EDT | AverageQLoss                0.0215923
2017-07-02 13:53:28.903177 EDT | AveragePolicySurr          -2.42879
2017-07-02 13:53:28.903279 EDT | AverageQ                    2.28571
2017-07-02 13:53:28.903380 EDT | AverageAbsQ                 2.29303
2017-07-02 13:53:28.903497 EDT | AverageY                    2.2855
2017-07-02 13:53:28.903598 EDT | AverageAbsY                 2.28662
2017-07-02 13:53:28.903696 EDT | AverageAbsQYDiff            0.0431583
2017-07-02 13:53:28.903794 EDT | AverageAction               0.456041
2017-07-02 13:53:28.903911 EDT | PolicyRegParamNorm         52.1132
2017-07-02 13:53:28.904014 EDT | QFunRegParamNorm           54.6304
2017-07-02 13:53:28.904116 EDT | -----------------------  ------------
2017-07-02 13:53:28.904278 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #341 | Training started
2017-07-02 13:53:38.530310 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #341 | Training finished
2017-07-02 13:53:38.530830 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #341 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 13:53:38.531014 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #341 | Collecting samples for evaluation
2017-07-02 13:53:44.155499 EDT | -----------------------  ------------
2017-07-02 13:53:44.155705 EDT | Epoch                     341
2017-07-02 13:53:44.155859 EDT | Iteration                 341
2017-07-02 13:53:44.156020 EDT | AverageReturn            1000
2017-07-02 13:53:44.156222 EDT | StdReturn                   0
2017-07-02 13:53:44.156401 EDT | MaxReturn                1000
2017-07-02 13:53:44.156520 EDT | MinReturn                1000
2017-07-02 13:53:44.156668 EDT | AverageEsReturn            39.8696
2017-07-02 13:53:44.156858 EDT | StdEsReturn                21.0926
2017-07-02 13:53:44.157054 EDT | MaxEsReturn                85
2017-07-02 13:53:44.157163 EDT | MinEsReturn                 7
2017-07-02 13:53:44.157289 EDT | AverageDiscountedReturn    99.9957
2017-07-02 13:53:44.157505 EDT | AverageQLoss                0.0206502
2017-07-02 13:53:44.157614 EDT | AveragePolicySurr          -2.40961
2017-07-02 13:53:44.157738 EDT | AverageQ                    2.27662
2017-07-02 13:53:44.157879 EDT | AverageAbsQ                 2.2839
2017-07-02 13:53:44.158003 EDT | AverageY                    2.27659
2017-07-02 13:53:44.158153 EDT | AverageAbsY                 2.27743
2017-07-02 13:53:44.158268 EDT | AverageAbsQYDiff            0.0430682
2017-07-02 13:53:44.158373 EDT | AverageAction               0.0238816
2017-07-02 13:53:44.158505 EDT | PolicyRegParamNorm         52.1905
2017-07-02 13:53:44.158605 EDT | QFunRegParamNorm           54.6671
2017-07-02 13:53:44.158743 EDT | -----------------------  ------------
2017-07-02 13:53:44.158930 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #342 | Training started
2017-07-02 13:53:53.894190 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #342 | Training finished
2017-07-02 13:53:53.894805 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #342 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 13:53:53.894965 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #342 | Collecting samples for evaluation
2017-07-02 13:53:59.596479 EDT | -----------------------  ------------
2017-07-02 13:53:59.596805 EDT | Epoch                     342
2017-07-02 13:53:59.597045 EDT | Iteration                 342
2017-07-02 13:53:59.597285 EDT | AverageReturn             731.357
2017-07-02 13:53:59.597553 EDT | StdReturn                 424.768
2017-07-02 13:53:59.597768 EDT | MaxReturn                1000
2017-07-02 13:53:59.598007 EDT | MinReturn                  54
2017-07-02 13:53:59.598246 EDT | AverageEsReturn            29.3243
2017-07-02 13:53:59.598478 EDT | StdEsReturn                23.9188
2017-07-02 13:53:59.598714 EDT | MaxEsReturn                90
2017-07-02 13:53:59.598919 EDT | MinEsReturn                 4
2017-07-02 13:53:59.599124 EDT | AverageDiscountedReturn    84.3102
2017-07-02 13:53:59.599360 EDT | AverageQLoss                0.0170207
2017-07-02 13:53:59.599562 EDT | AveragePolicySurr          -2.39683
2017-07-02 13:53:59.599755 EDT | AverageQ                    2.25297
2017-07-02 13:53:59.599965 EDT | AverageAbsQ                 2.25923
2017-07-02 13:53:59.600167 EDT | AverageY                    2.25302
2017-07-02 13:53:59.600401 EDT | AverageAbsY                 2.25376
2017-07-02 13:53:59.600632 EDT | AverageAbsQYDiff            0.0393705
2017-07-02 13:53:59.600858 EDT | AverageAction               0.395039
2017-07-02 13:53:59.601063 EDT | PolicyRegParamNorm         52.2228
2017-07-02 13:53:59.601275 EDT | QFunRegParamNorm           54.7234
2017-07-02 13:53:59.601628 EDT | -----------------------  ------------
2017-07-02 13:53:59.601954 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #343 | Training started
2017-07-02 13:54:09.297599 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #343 | Training finished
2017-07-02 13:54:09.298203 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #343 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 13:54:09.298338 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #343 | Collecting samples for evaluation
2017-07-02 13:54:14.956201 EDT | -----------------------  ------------
2017-07-02 13:54:14.956539 EDT | Epoch                     343
2017-07-02 13:54:14.956764 EDT | Iteration                 343
2017-07-02 13:54:14.956997 EDT | AverageReturn            1000
2017-07-02 13:54:14.957222 EDT | StdReturn                   0
2017-07-02 13:54:14.957428 EDT | MaxReturn                1000
2017-07-02 13:54:14.957610 EDT | MinReturn                1000
2017-07-02 13:54:14.957807 EDT | AverageEsReturn            26.2162
2017-07-02 13:54:14.957927 EDT | StdEsReturn                23.3645
2017-07-02 13:54:14.958032 EDT | MaxEsReturn               112
2017-07-02 13:54:14.958173 EDT | MinEsReturn                 3
2017-07-02 13:54:14.958276 EDT | AverageDiscountedReturn    99.9957
2017-07-02 13:54:14.958378 EDT | AverageQLoss                0.020536
2017-07-02 13:54:14.958524 EDT | AveragePolicySurr          -2.38705
2017-07-02 13:54:14.958636 EDT | AverageQ                    2.25048
2017-07-02 13:54:14.958744 EDT | AverageAbsQ                 2.25675
2017-07-02 13:54:14.958851 EDT | AverageY                    2.25039
2017-07-02 13:54:14.958956 EDT | AverageAbsY                 2.25126
2017-07-02 13:54:14.959091 EDT | AverageAbsQYDiff            0.0424986
2017-07-02 13:54:14.959200 EDT | AverageAction               0.469294
2017-07-02 13:54:14.959330 EDT | PolicyRegParamNorm         52.1845
2017-07-02 13:54:14.959443 EDT | QFunRegParamNorm           54.7718
2017-07-02 13:54:14.959570 EDT | -----------------------  ------------
2017-07-02 13:54:14.959742 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #344 | Training started
2017-07-02 13:54:24.619856 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #344 | Training finished
2017-07-02 13:54:24.620459 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #344 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 13:54:24.620603 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #344 | Collecting samples for evaluation
2017-07-02 13:54:30.285829 EDT | -----------------------  ------------
2017-07-02 13:54:30.286045 EDT | Epoch                     344
2017-07-02 13:54:30.286203 EDT | Iteration                 344
2017-07-02 13:54:30.286311 EDT | AverageReturn            1000
2017-07-02 13:54:30.286476 EDT | StdReturn                   0
2017-07-02 13:54:30.286587 EDT | MaxReturn                1000
2017-07-02 13:54:30.286690 EDT | MinReturn                1000
2017-07-02 13:54:30.286809 EDT | AverageEsReturn            21.9787
2017-07-02 13:54:30.286928 EDT | StdEsReturn                15.4582
2017-07-02 13:54:30.287040 EDT | MaxEsReturn                53
2017-07-02 13:54:30.287179 EDT | MinEsReturn                 3
2017-07-02 13:54:30.287295 EDT | AverageDiscountedReturn    99.9957
2017-07-02 13:54:30.287435 EDT | AverageQLoss                0.0217234
2017-07-02 13:54:30.287619 EDT | AveragePolicySurr          -2.37227
2017-07-02 13:54:30.287849 EDT | AverageQ                    2.23839
2017-07-02 13:54:30.288072 EDT | AverageAbsQ                 2.24618
2017-07-02 13:54:30.288260 EDT | AverageY                    2.23832
2017-07-02 13:54:30.288425 EDT | AverageAbsY                 2.23951
2017-07-02 13:54:30.288559 EDT | AverageAbsQYDiff            0.0443117
2017-07-02 13:54:30.289241 EDT | AverageAction               0.405388
2017-07-02 13:54:30.289369 EDT | PolicyRegParamNorm         52.2053
2017-07-02 13:54:30.289477 EDT | QFunRegParamNorm           54.8068
2017-07-02 13:54:30.289665 EDT | -----------------------  ------------
2017-07-02 13:54:30.289930 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #345 | Training started
2017-07-02 13:54:39.945968 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #345 | Training finished
2017-07-02 13:54:39.946581 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #345 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 13:54:39.946840 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #345 | Collecting samples for evaluation
2017-07-02 13:54:45.611005 EDT | -----------------------  ------------
2017-07-02 13:54:45.611248 EDT | Epoch                     345
2017-07-02 13:54:45.611414 EDT | Iteration                 345
2017-07-02 13:54:45.611566 EDT | AverageReturn            1000
2017-07-02 13:54:45.611692 EDT | StdReturn                   0
2017-07-02 13:54:45.611802 EDT | MaxReturn                1000
2017-07-02 13:54:45.611928 EDT | MinReturn                1000
2017-07-02 13:54:45.612068 EDT | AverageEsReturn            19.66
2017-07-02 13:54:45.612176 EDT | StdEsReturn                20.1709
2017-07-02 13:54:45.612299 EDT | MaxEsReturn               102
2017-07-02 13:54:45.612406 EDT | MinEsReturn                 2
2017-07-02 13:54:45.612512 EDT | AverageDiscountedReturn    99.9957
2017-07-02 13:54:45.612617 EDT | AverageQLoss                0.0189229
2017-07-02 13:54:45.612810 EDT | AveragePolicySurr          -2.35518
2017-07-02 13:54:45.612964 EDT | AverageQ                    2.22312
2017-07-02 13:54:45.613174 EDT | AverageAbsQ                 2.22986
2017-07-02 13:54:45.613330 EDT | AverageY                    2.22317
2017-07-02 13:54:45.613442 EDT | AverageAbsY                 2.22388
2017-07-02 13:54:45.613623 EDT | AverageAbsQYDiff            0.0392158
2017-07-02 13:54:45.613828 EDT | AverageAction               0.32143
2017-07-02 13:54:45.613983 EDT | PolicyRegParamNorm         52.2051
2017-07-02 13:54:45.614163 EDT | QFunRegParamNorm           54.881
2017-07-02 13:54:45.614272 EDT | -----------------------  ------------
2017-07-02 13:54:45.614484 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #346 | Training started
2017-07-02 13:54:55.182505 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #346 | Training finished
2017-07-02 13:54:55.183297 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #346 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 13:54:55.183566 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #346 | Collecting samples for evaluation
2017-07-02 13:55:00.855189 EDT | -----------------------  ------------
2017-07-02 13:55:00.855384 EDT | Epoch                     346
2017-07-02 13:55:00.855496 EDT | Iteration                 346
2017-07-02 13:55:00.855600 EDT | AverageReturn            1000
2017-07-02 13:55:00.855740 EDT | StdReturn                   0
2017-07-02 13:55:00.855964 EDT | MaxReturn                1000
2017-07-02 13:55:00.856148 EDT | MinReturn                1000
2017-07-02 13:55:00.856368 EDT | AverageEsReturn            27.7222
2017-07-02 13:55:00.856605 EDT | StdEsReturn                20.153
2017-07-02 13:55:00.856833 EDT | MaxEsReturn                70
2017-07-02 13:55:00.857062 EDT | MinEsReturn                 6
2017-07-02 13:55:00.857277 EDT | AverageDiscountedReturn    99.9957
2017-07-02 13:55:00.857393 EDT | AverageQLoss                0.0184422
2017-07-02 13:55:00.857643 EDT | AveragePolicySurr          -2.33841
2017-07-02 13:55:00.857854 EDT | AverageQ                    2.20603
2017-07-02 13:55:00.858080 EDT | AverageAbsQ                 2.21234
2017-07-02 13:55:00.858296 EDT | AverageY                    2.20605
2017-07-02 13:55:00.858472 EDT | AverageAbsY                 2.20707
2017-07-02 13:55:00.858639 EDT | AverageAbsQYDiff            0.0399606
2017-07-02 13:55:00.858894 EDT | AverageAction               0.276315
2017-07-02 13:55:00.859066 EDT | PolicyRegParamNorm         52.2329
2017-07-02 13:55:00.859198 EDT | QFunRegParamNorm           54.9289
2017-07-02 13:55:00.859324 EDT | -----------------------  ------------
2017-07-02 13:55:00.859576 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #347 | Training started
2017-07-02 13:55:10.444797 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #347 | Training finished
2017-07-02 13:55:10.445399 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #347 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 13:55:10.445609 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #347 | Collecting samples for evaluation
2017-07-02 13:55:16.113915 EDT | -----------------------  ------------
2017-07-02 13:55:16.114140 EDT | Epoch                     347
2017-07-02 13:55:16.114288 EDT | Iteration                 347
2017-07-02 13:55:16.114441 EDT | AverageReturn            1000
2017-07-02 13:55:16.114585 EDT | StdReturn                   0
2017-07-02 13:55:16.114725 EDT | MaxReturn                1000
2017-07-02 13:55:16.114911 EDT | MinReturn                1000
2017-07-02 13:55:16.115078 EDT | AverageEsReturn            26.7632
2017-07-02 13:55:16.115263 EDT | StdEsReturn                20.5547
2017-07-02 13:55:16.115424 EDT | MaxEsReturn                92
2017-07-02 13:55:16.115599 EDT | MinEsReturn                 5
2017-07-02 13:55:16.115758 EDT | AverageDiscountedReturn    99.9957
2017-07-02 13:55:16.115915 EDT | AverageQLoss                0.0162871
2017-07-02 13:55:16.116085 EDT | AveragePolicySurr          -2.32482
2017-07-02 13:55:16.116188 EDT | AverageQ                    2.18988
2017-07-02 13:55:16.116357 EDT | AverageAbsQ                 2.19633
2017-07-02 13:55:16.116524 EDT | AverageY                    2.18978
2017-07-02 13:55:16.116684 EDT | AverageAbsY                 2.19084
2017-07-02 13:55:16.116904 EDT | AverageAbsQYDiff            0.0366572
2017-07-02 13:55:16.117124 EDT | AverageAction               0.476737
2017-07-02 13:55:16.117251 EDT | PolicyRegParamNorm         52.2379
2017-07-02 13:55:16.117374 EDT | QFunRegParamNorm           54.9929
2017-07-02 13:55:16.117615 EDT | -----------------------  ------------
2017-07-02 13:55:16.117846 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #348 | Training started
2017-07-02 13:55:26.213340 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #348 | Training finished
2017-07-02 13:55:26.213880 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #348 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 13:55:26.214086 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #348 | Collecting samples for evaluation
2017-07-02 13:55:32.002590 EDT | -----------------------  ------------
2017-07-02 13:55:32.002826 EDT | Epoch                     348
2017-07-02 13:55:32.003014 EDT | Iteration                 348
2017-07-02 13:55:32.003146 EDT | AverageReturn            1000
2017-07-02 13:55:32.003364 EDT | StdReturn                   0
2017-07-02 13:55:32.003561 EDT | MaxReturn                1000
2017-07-02 13:55:32.003700 EDT | MinReturn                1000
2017-07-02 13:55:32.003829 EDT | AverageEsReturn            29.2059
2017-07-02 13:55:32.003956 EDT | StdEsReturn                27.507
2017-07-02 13:55:32.004122 EDT | MaxEsReturn               160
2017-07-02 13:55:32.004257 EDT | MinEsReturn                 4
2017-07-02 13:55:32.004392 EDT | AverageDiscountedReturn    99.9957
2017-07-02 13:55:32.004534 EDT | AverageQLoss                0.018297
2017-07-02 13:55:32.004663 EDT | AveragePolicySurr          -2.31843
2017-07-02 13:55:32.004785 EDT | AverageQ                    2.17886
2017-07-02 13:55:32.004892 EDT | AverageAbsQ                 2.18481
2017-07-02 13:55:32.005023 EDT | AverageY                    2.17877
2017-07-02 13:55:32.005133 EDT | AverageAbsY                 2.1797
2017-07-02 13:55:32.005287 EDT | AverageAbsQYDiff            0.0396015
2017-07-02 13:55:32.005402 EDT | AverageAction               0.747887
2017-07-02 13:55:32.005667 EDT | PolicyRegParamNorm         52.2961
2017-07-02 13:55:32.005772 EDT | QFunRegParamNorm           54.9839
2017-07-02 13:55:32.005932 EDT | -----------------------  ------------
2017-07-02 13:55:32.006173 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #349 | Training started
2017-07-02 13:55:41.628622 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #349 | Training finished
2017-07-02 13:55:41.629184 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #349 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 13:55:41.629660 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #349 | Collecting samples for evaluation
2017-07-02 13:55:47.343026 EDT | -----------------------  ------------
2017-07-02 13:55:47.343340 EDT | Epoch                     349
2017-07-02 13:55:47.343575 EDT | Iteration                 349
2017-07-02 13:55:47.343787 EDT | AverageReturn            1000
2017-07-02 13:55:47.344019 EDT | StdReturn                   0
2017-07-02 13:55:47.344241 EDT | MaxReturn                1000
2017-07-02 13:55:47.344468 EDT | MinReturn                1000
2017-07-02 13:55:47.344683 EDT | AverageEsReturn            36.2222
2017-07-02 13:55:47.344913 EDT | StdEsReturn                31.5376
2017-07-02 13:55:47.345112 EDT | MaxEsReturn               129
2017-07-02 13:55:47.345316 EDT | MinEsReturn                 3
2017-07-02 13:55:47.345780 EDT | AverageDiscountedReturn    99.9957
2017-07-02 13:55:47.346018 EDT | AverageQLoss                0.0166228
2017-07-02 13:55:47.346200 EDT | AveragePolicySurr          -2.30539
2017-07-02 13:55:47.346430 EDT | AverageQ                    2.1737
2017-07-02 13:55:47.346642 EDT | AverageAbsQ                 2.17979
2017-07-02 13:55:47.346872 EDT | AverageY                    2.17361
2017-07-02 13:55:47.347094 EDT | AverageAbsY                 2.17435
2017-07-02 13:55:47.347332 EDT | AverageAbsQYDiff            0.0391717
2017-07-02 13:55:47.347560 EDT | AverageAction               0.764269
2017-07-02 13:55:47.347786 EDT | PolicyRegParamNorm         52.3165
2017-07-02 13:55:47.348006 EDT | QFunRegParamNorm           55.0333
2017-07-02 13:55:47.348224 EDT | -----------------------  ------------
2017-07-02 13:55:47.348539 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #350 | Training started
2017-07-02 13:55:56.867694 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #350 | Training finished
2017-07-02 13:55:56.868205 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #350 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 13:55:56.868345 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #350 | Collecting samples for evaluation
2017-07-02 13:56:02.612975 EDT | -----------------------  ------------
2017-07-02 13:56:02.613295 EDT | Epoch                     350
2017-07-02 13:56:02.613556 EDT | Iteration                 350
2017-07-02 13:56:02.613777 EDT | AverageReturn            1000
2017-07-02 13:56:02.614016 EDT | StdReturn                   0
2017-07-02 13:56:02.614235 EDT | MaxReturn                1000
2017-07-02 13:56:02.614389 EDT | MinReturn                1000
2017-07-02 13:56:02.614624 EDT | AverageEsReturn            45.7273
2017-07-02 13:56:02.614856 EDT | StdEsReturn                40.7723
2017-07-02 13:56:02.615080 EDT | MaxEsReturn               170
2017-07-02 13:56:02.615313 EDT | MinEsReturn                 4
2017-07-02 13:56:02.615519 EDT | AverageDiscountedReturn    99.9957
2017-07-02 13:56:02.615754 EDT | AverageQLoss                0.0180665
2017-07-02 13:56:02.615954 EDT | AveragePolicySurr          -2.29338
2017-07-02 13:56:02.616063 EDT | AverageQ                    2.16453
2017-07-02 13:56:02.616167 EDT | AverageAbsQ                 2.17142
2017-07-02 13:56:02.616295 EDT | AverageY                    2.16458
2017-07-02 13:56:02.616424 EDT | AverageAbsY                 2.16516
2017-07-02 13:56:02.616527 EDT | AverageAbsQYDiff            0.0398382
2017-07-02 13:56:02.616628 EDT | AverageAction               0.504662
2017-07-02 13:56:02.616729 EDT | PolicyRegParamNorm         52.382
2017-07-02 13:56:02.616860 EDT | QFunRegParamNorm           55.0357
2017-07-02 13:56:02.616964 EDT | -----------------------  ------------
2017-07-02 13:56:02.617131 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #351 | Training started
2017-07-02 13:56:12.037456 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #351 | Training finished
2017-07-02 13:56:12.037997 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #351 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 13:56:12.038255 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #351 | Collecting samples for evaluation
2017-07-02 13:56:17.788875 EDT | -----------------------  ------------
2017-07-02 13:56:17.789072 EDT | Epoch                     351
2017-07-02 13:56:17.789242 EDT | Iteration                 351
2017-07-02 13:56:17.789392 EDT | AverageReturn            1000
2017-07-02 13:56:17.789521 EDT | StdReturn                   0
2017-07-02 13:56:17.789663 EDT | MaxReturn                1000
2017-07-02 13:56:17.789808 EDT | MinReturn                1000
2017-07-02 13:56:17.790044 EDT | AverageEsReturn            32.1935
2017-07-02 13:56:17.790361 EDT | StdEsReturn                17.8062
2017-07-02 13:56:17.790490 EDT | MaxEsReturn                76
2017-07-02 13:56:17.790618 EDT | MinEsReturn                 5
2017-07-02 13:56:17.790739 EDT | AverageDiscountedReturn    99.9957
2017-07-02 13:56:17.790935 EDT | AverageQLoss                0.0194738
2017-07-02 13:56:17.791138 EDT | AveragePolicySurr          -2.28037
2017-07-02 13:56:17.791287 EDT | AverageQ                    2.15147
2017-07-02 13:56:17.791402 EDT | AverageAbsQ                 2.1583
2017-07-02 13:56:17.791607 EDT | AverageY                    2.15161
2017-07-02 13:56:17.791759 EDT | AverageAbsY                 2.15231
2017-07-02 13:56:17.791864 EDT | AverageAbsQYDiff            0.0404359
2017-07-02 13:56:17.791965 EDT | AverageAction               0.621491
2017-07-02 13:56:17.792065 EDT | PolicyRegParamNorm         52.458
2017-07-02 13:56:17.792195 EDT | QFunRegParamNorm           55.0954
2017-07-02 13:56:17.792345 EDT | -----------------------  ------------
2017-07-02 13:56:17.792538 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #352 | Training started
2017-07-02 13:56:27.296477 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #352 | Training finished
2017-07-02 13:56:27.296979 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #352 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 13:56:27.297139 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #352 | Collecting samples for evaluation
2017-07-02 13:56:33.008350 EDT | -----------------------  ------------
2017-07-02 13:56:33.008675 EDT | Epoch                     352
2017-07-02 13:56:33.008833 EDT | Iteration                 352
2017-07-02 13:56:33.008940 EDT | AverageReturn            1000
2017-07-02 13:56:33.009102 EDT | StdReturn                   0
2017-07-02 13:56:33.009245 EDT | MaxReturn                1000
2017-07-02 13:56:33.009349 EDT | MinReturn                1000
2017-07-02 13:56:33.009484 EDT | AverageEsReturn            31.75
2017-07-02 13:56:33.009610 EDT | StdEsReturn                23.8236
2017-07-02 13:56:33.009712 EDT | MaxEsReturn               105
2017-07-02 13:56:33.009813 EDT | MinEsReturn                 4
2017-07-02 13:56:33.009948 EDT | AverageDiscountedReturn    99.9957
2017-07-02 13:56:33.010050 EDT | AverageQLoss                0.0160495
2017-07-02 13:56:33.010150 EDT | AveragePolicySurr          -2.25978
2017-07-02 13:56:33.010249 EDT | AverageQ                    2.13459
2017-07-02 13:56:33.010368 EDT | AverageAbsQ                 2.14018
2017-07-02 13:56:33.010538 EDT | AverageY                    2.13439
2017-07-02 13:56:33.010772 EDT | AverageAbsY                 2.13504
2017-07-02 13:56:33.010998 EDT | AverageAbsQYDiff            0.0365267
2017-07-02 13:56:33.011199 EDT | AverageAction               0.696268
2017-07-02 13:56:33.011386 EDT | PolicyRegParamNorm         52.546
2017-07-02 13:56:33.011492 EDT | QFunRegParamNorm           55.149
2017-07-02 13:56:33.011593 EDT | -----------------------  ------------
2017-07-02 13:56:33.011780 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #353 | Training started
2017-07-02 13:56:42.550220 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #353 | Training finished
2017-07-02 13:56:42.550816 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #353 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 13:56:42.550971 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #353 | Collecting samples for evaluation
2017-07-02 13:56:48.253743 EDT | -----------------------  ------------
2017-07-02 13:56:48.253950 EDT | Epoch                     353
2017-07-02 13:56:48.254118 EDT | Iteration                 353
2017-07-02 13:56:48.254231 EDT | AverageReturn            1000
2017-07-02 13:56:48.254340 EDT | StdReturn                   0
2017-07-02 13:56:48.254449 EDT | MaxReturn                1000
2017-07-02 13:56:48.254562 EDT | MinReturn                1000
2017-07-02 13:56:48.254695 EDT | AverageEsReturn            48.75
2017-07-02 13:56:48.254819 EDT | StdEsReturn                40.213
2017-07-02 13:56:48.254928 EDT | MaxEsReturn               177
2017-07-02 13:56:48.255036 EDT | MinEsReturn                 6
2017-07-02 13:56:48.255143 EDT | AverageDiscountedReturn    99.9957
2017-07-02 13:56:48.255295 EDT | AverageQLoss                0.0191533
2017-07-02 13:56:48.255405 EDT | AveragePolicySurr          -2.25166
2017-07-02 13:56:48.255512 EDT | AverageQ                    2.1162
2017-07-02 13:56:48.255650 EDT | AverageAbsQ                 2.12333
2017-07-02 13:56:48.255820 EDT | AverageY                    2.11616
2017-07-02 13:56:48.256023 EDT | AverageAbsY                 2.11694
2017-07-02 13:56:48.256210 EDT | AverageAbsQYDiff            0.0407635
2017-07-02 13:56:48.256412 EDT | AverageAction               0.618666
2017-07-02 13:56:48.256593 EDT | PolicyRegParamNorm         52.5581
2017-07-02 13:56:48.256723 EDT | QFunRegParamNorm           55.2217
2017-07-02 13:56:48.256881 EDT | -----------------------  ------------
2017-07-02 13:56:48.257076 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #354 | Training started
2017-07-02 13:56:57.875212 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #354 | Training finished
2017-07-02 13:56:57.875782 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #354 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 13:56:57.876000 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #354 | Collecting samples for evaluation
2017-07-02 13:57:03.581816 EDT | -----------------------  ------------
2017-07-02 13:57:03.582038 EDT | Epoch                     354
2017-07-02 13:57:03.582275 EDT | Iteration                 354
2017-07-02 13:57:03.582511 EDT | AverageReturn            1000
2017-07-02 13:57:03.582728 EDT | StdReturn                   0
2017-07-02 13:57:03.582924 EDT | MaxReturn                1000
2017-07-02 13:57:03.583109 EDT | MinReturn                1000
2017-07-02 13:57:03.583333 EDT | AverageEsReturn            35.6897
2017-07-02 13:57:03.583545 EDT | StdEsReturn                26.8817
2017-07-02 13:57:03.583696 EDT | MaxEsReturn               109
2017-07-02 13:57:03.583824 EDT | MinEsReturn                 5
2017-07-02 13:57:03.583959 EDT | AverageDiscountedReturn    99.9957
2017-07-02 13:57:03.584070 EDT | AverageQLoss                0.019113
2017-07-02 13:57:03.584252 EDT | AveragePolicySurr          -2.24341
2017-07-02 13:57:03.584381 EDT | AverageQ                    2.11638
2017-07-02 13:57:03.584514 EDT | AverageAbsQ                 2.12329
2017-07-02 13:57:03.584643 EDT | AverageY                    2.11631
2017-07-02 13:57:03.584770 EDT | AverageAbsY                 2.11688
2017-07-02 13:57:03.584925 EDT | AverageAbsQYDiff            0.0410563
2017-07-02 13:57:03.585050 EDT | AverageAction               0.0135037
2017-07-02 13:57:03.585183 EDT | PolicyRegParamNorm         52.6359
2017-07-02 13:57:03.585292 EDT | QFunRegParamNorm           55.2416
2017-07-02 13:57:03.585410 EDT | -----------------------  ------------
2017-07-02 13:57:03.585676 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #355 | Training started
2017-07-02 13:57:13.161840 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #355 | Training finished
2017-07-02 13:57:13.162389 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #355 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 13:57:13.162538 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #355 | Collecting samples for evaluation
2017-07-02 13:57:18.940952 EDT | -----------------------  ------------
2017-07-02 13:57:18.941157 EDT | Epoch                     355
2017-07-02 13:57:18.941290 EDT | Iteration                 355
2017-07-02 13:57:18.941397 EDT | AverageReturn            1000
2017-07-02 13:57:18.941540 EDT | StdReturn                   0
2017-07-02 13:57:18.941681 EDT | MaxReturn                1000
2017-07-02 13:57:18.941800 EDT | MinReturn                1000
2017-07-02 13:57:18.941922 EDT | AverageEsReturn            33.3333
2017-07-02 13:57:18.942026 EDT | StdEsReturn                23.1334
2017-07-02 13:57:18.942138 EDT | MaxEsReturn               117
2017-07-02 13:57:18.942260 EDT | MinEsReturn                 3
2017-07-02 13:57:18.942416 EDT | AverageDiscountedReturn    99.9957
2017-07-02 13:57:18.942522 EDT | AverageQLoss                0.0170166
2017-07-02 13:57:18.942623 EDT | AveragePolicySurr          -2.23016
2017-07-02 13:57:18.942724 EDT | AverageQ                    2.10378
2017-07-02 13:57:18.942835 EDT | AverageAbsQ                 2.10894
2017-07-02 13:57:18.942997 EDT | AverageY                    2.10375
2017-07-02 13:57:18.943100 EDT | AverageAbsY                 2.10435
2017-07-02 13:57:18.943201 EDT | AverageAbsQYDiff            0.0380464
2017-07-02 13:57:18.943324 EDT | AverageAction               0.650132
2017-07-02 13:57:18.943433 EDT | PolicyRegParamNorm         52.7169
2017-07-02 13:57:18.943555 EDT | QFunRegParamNorm           55.3018
2017-07-02 13:57:18.943658 EDT | -----------------------  ------------
2017-07-02 13:57:18.943819 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #356 | Training started
2017-07-02 13:57:28.416833 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #356 | Training finished
2017-07-02 13:57:28.417457 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #356 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 13:57:28.417713 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #356 | Collecting samples for evaluation
2017-07-02 13:57:34.157172 EDT | -----------------------  ------------
2017-07-02 13:57:34.157385 EDT | Epoch                     356
2017-07-02 13:57:34.157526 EDT | Iteration                 356
2017-07-02 13:57:34.157642 EDT | AverageReturn            1000
2017-07-02 13:57:34.157793 EDT | StdReturn                   0
2017-07-02 13:57:34.157928 EDT | MaxReturn                1000
2017-07-02 13:57:34.158067 EDT | MinReturn                1000
2017-07-02 13:57:34.158267 EDT | AverageEsReturn            29.1765
2017-07-02 13:57:34.158412 EDT | StdEsReturn                21.7951
2017-07-02 13:57:34.158554 EDT | MaxEsReturn                80
2017-07-02 13:57:34.158759 EDT | MinEsReturn                 3
2017-07-02 13:57:34.159031 EDT | AverageDiscountedReturn    99.9957
2017-07-02 13:57:34.159161 EDT | AverageQLoss                0.0156249
2017-07-02 13:57:34.159268 EDT | AveragePolicySurr          -2.22124
2017-07-02 13:57:34.159371 EDT | AverageQ                    2.09295
2017-07-02 13:57:34.159501 EDT | AverageAbsQ                 2.09954
2017-07-02 13:57:34.159604 EDT | AverageY                    2.09289
2017-07-02 13:57:34.159714 EDT | AverageAbsY                 2.09358
2017-07-02 13:57:34.159828 EDT | AverageAbsQYDiff            0.037572
2017-07-02 13:57:34.159945 EDT | AverageAction               0.470481
2017-07-02 13:57:34.160085 EDT | PolicyRegParamNorm         52.8176
2017-07-02 13:57:34.160196 EDT | QFunRegParamNorm           55.3328
2017-07-02 13:57:34.160298 EDT | -----------------------  ------------
2017-07-02 13:57:34.160464 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #357 | Training started
2017-07-02 13:57:43.546077 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #357 | Training finished
2017-07-02 13:57:43.546634 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #357 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 13:57:43.546778 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #357 | Collecting samples for evaluation
2017-07-02 13:57:49.310111 EDT | -----------------------  ------------
2017-07-02 13:57:49.310438 EDT | Epoch                     357
2017-07-02 13:57:49.310669 EDT | Iteration                 357
2017-07-02 13:57:49.310884 EDT | AverageReturn            1000
2017-07-02 13:57:49.311112 EDT | StdReturn                   0
2017-07-02 13:57:49.311229 EDT | MaxReturn                1000
2017-07-02 13:57:49.311334 EDT | MinReturn                1000
2017-07-02 13:57:49.311437 EDT | AverageEsReturn            35.7143
2017-07-02 13:57:49.311551 EDT | StdEsReturn                31.3572
2017-07-02 13:57:49.311668 EDT | MaxEsReturn               131
2017-07-02 13:57:49.311770 EDT | MinEsReturn                 3
2017-07-02 13:57:49.311869 EDT | AverageDiscountedReturn    99.9957
2017-07-02 13:57:49.312026 EDT | AverageQLoss                0.0158184
2017-07-02 13:57:49.312245 EDT | AveragePolicySurr          -2.21653
2017-07-02 13:57:49.312435 EDT | AverageQ                    2.09092
2017-07-02 13:57:49.312663 EDT | AverageAbsQ                 2.09579
2017-07-02 13:57:49.312871 EDT | AverageY                    2.09095
2017-07-02 13:57:49.313101 EDT | AverageAbsY                 2.09149
2017-07-02 13:57:49.313329 EDT | AverageAbsQYDiff            0.0351913
2017-07-02 13:57:49.313708 EDT | AverageAction               0.610794
2017-07-02 13:57:49.313931 EDT | PolicyRegParamNorm         52.8944
2017-07-02 13:57:49.314079 EDT | QFunRegParamNorm           55.3581
2017-07-02 13:57:49.314301 EDT | -----------------------  ------------
2017-07-02 13:57:49.314575 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #358 | Training started
2017-07-02 13:57:58.854813 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #358 | Training finished
2017-07-02 13:57:58.855389 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #358 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 13:57:58.855598 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #358 | Collecting samples for evaluation
2017-07-02 13:58:04.664633 EDT | -----------------------  ------------
2017-07-02 13:58:04.664903 EDT | Epoch                     358
2017-07-02 13:58:04.665048 EDT | Iteration                 358
2017-07-02 13:58:04.665194 EDT | AverageReturn            1000
2017-07-02 13:58:04.665402 EDT | StdReturn                   0
2017-07-02 13:58:04.665622 EDT | MaxReturn                1000
2017-07-02 13:58:04.665739 EDT | MinReturn                1000
2017-07-02 13:58:04.665844 EDT | AverageEsReturn            33.2
2017-07-02 13:58:04.666013 EDT | StdEsReturn                24.7136
2017-07-02 13:58:04.666117 EDT | MaxEsReturn                99
2017-07-02 13:58:04.666219 EDT | MinEsReturn                 4
2017-07-02 13:58:04.666353 EDT | AverageDiscountedReturn    99.9957
2017-07-02 13:58:04.666536 EDT | AverageQLoss                0.0170085
2017-07-02 13:58:04.666741 EDT | AveragePolicySurr          -2.2014
2017-07-02 13:58:04.666849 EDT | AverageQ                    2.07569
2017-07-02 13:58:04.667021 EDT | AverageAbsQ                 2.08191
2017-07-02 13:58:04.667171 EDT | AverageY                    2.07576
2017-07-02 13:58:04.667276 EDT | AverageAbsY                 2.07649
2017-07-02 13:58:04.667436 EDT | AverageAbsQYDiff            0.0388376
2017-07-02 13:58:04.667559 EDT | AverageAction               0.501421
2017-07-02 13:58:04.667759 EDT | PolicyRegParamNorm         52.9157
2017-07-02 13:58:04.667955 EDT | QFunRegParamNorm           55.3885
2017-07-02 13:58:04.668074 EDT | -----------------------  ------------
2017-07-02 13:58:04.668257 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #359 | Training started
2017-07-02 13:58:14.208383 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #359 | Training finished
2017-07-02 13:58:14.208904 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #359 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 13:58:14.209171 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #359 | Collecting samples for evaluation
2017-07-02 13:58:19.908758 EDT | -----------------------  ------------
2017-07-02 13:58:19.908977 EDT | Epoch                     359
2017-07-02 13:58:19.909108 EDT | Iteration                 359
2017-07-02 13:58:19.909251 EDT | AverageReturn            1000
2017-07-02 13:58:19.909365 EDT | StdReturn                   0
2017-07-02 13:58:19.909517 EDT | MaxReturn                1000
2017-07-02 13:58:19.909624 EDT | MinReturn                1000
2017-07-02 13:58:19.909728 EDT | AverageEsReturn            37.6667
2017-07-02 13:58:19.909865 EDT | StdEsReturn                33.4386
2017-07-02 13:58:19.909977 EDT | MaxEsReturn               145
2017-07-02 13:58:19.910095 EDT | MinEsReturn                 3
2017-07-02 13:58:19.910250 EDT | AverageDiscountedReturn    99.9957
2017-07-02 13:58:19.910354 EDT | AverageQLoss                0.0195267
2017-07-02 13:58:19.910472 EDT | AveragePolicySurr          -2.19254
2017-07-02 13:58:19.910594 EDT | AverageQ                    2.06031
2017-07-02 13:58:19.910715 EDT | AverageAbsQ                 2.06653
2017-07-02 13:58:19.910817 EDT | AverageY                    2.06028
2017-07-02 13:58:19.910918 EDT | AverageAbsY                 2.06087
2017-07-02 13:58:19.911062 EDT | AverageAbsQYDiff            0.0401081
2017-07-02 13:58:19.911165 EDT | AverageAction               0.543384
2017-07-02 13:58:19.911265 EDT | PolicyRegParamNorm         52.9815
2017-07-02 13:58:19.911366 EDT | QFunRegParamNorm           55.4071
2017-07-02 13:58:19.911466 EDT | -----------------------  ------------
2017-07-02 13:58:19.911638 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #360 | Training started
2017-07-02 13:58:29.615430 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #360 | Training finished
2017-07-02 13:58:29.632491 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #360 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 13:58:29.632783 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #360 | Collecting samples for evaluation
2017-07-02 13:58:35.285583 EDT | -----------------------  ------------
2017-07-02 13:58:35.285795 EDT | Epoch                     360
2017-07-02 13:58:35.285911 EDT | Iteration                 360
2017-07-02 13:58:35.286029 EDT | AverageReturn            1000
2017-07-02 13:58:35.286218 EDT | StdReturn                   0
2017-07-02 13:58:35.286424 EDT | MaxReturn                1000
2017-07-02 13:58:35.286560 EDT | MinReturn                1000
2017-07-02 13:58:35.286678 EDT | AverageEsReturn            45.5417
2017-07-02 13:58:35.286808 EDT | StdEsReturn                37.7304
2017-07-02 13:58:35.286910 EDT | MaxEsReturn               156
2017-07-02 13:58:35.287011 EDT | MinEsReturn                 6
2017-07-02 13:58:35.287112 EDT | AverageDiscountedReturn    99.9957
2017-07-02 13:58:35.287210 EDT | AverageQLoss                0.0201638
2017-07-02 13:58:35.287336 EDT | AveragePolicySurr          -2.18305
2017-07-02 13:58:35.287435 EDT | AverageQ                    2.05706
2017-07-02 13:58:35.287532 EDT | AverageAbsQ                 2.06324
2017-07-02 13:58:35.287634 EDT | AverageY                    2.05713
2017-07-02 13:58:35.287751 EDT | AverageAbsY                 2.05767
2017-07-02 13:58:35.287852 EDT | AverageAbsQYDiff            0.0416365
2017-07-02 13:58:35.287951 EDT | AverageAction               0.200785
2017-07-02 13:58:35.288051 EDT | PolicyRegParamNorm         53.0942
2017-07-02 13:58:35.288149 EDT | QFunRegParamNorm           55.3984
2017-07-02 13:58:35.288283 EDT | -----------------------  ------------
2017-07-02 13:58:35.288447 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #361 | Training started
2017-07-02 13:58:44.816652 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #361 | Training finished
2017-07-02 13:58:44.817190 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #361 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 13:58:44.817354 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #361 | Collecting samples for evaluation
2017-07-02 13:58:50.573121 EDT | -----------------------  ------------
2017-07-02 13:58:50.573622 EDT | Epoch                     361
2017-07-02 13:58:50.573752 EDT | Iteration                 361
2017-07-02 13:58:50.573881 EDT | AverageReturn            1000
2017-07-02 13:58:50.574019 EDT | StdReturn                   0
2017-07-02 13:58:50.574212 EDT | MaxReturn                1000
2017-07-02 13:58:50.574445 EDT | MinReturn                1000
2017-07-02 13:58:50.574673 EDT | AverageEsReturn            35.7857
2017-07-02 13:58:50.574903 EDT | StdEsReturn                34.9023
2017-07-02 13:58:50.575136 EDT | MaxEsReturn               139
2017-07-02 13:58:50.575331 EDT | MinEsReturn                 3
2017-07-02 13:58:50.575512 EDT | AverageDiscountedReturn    99.9957
2017-07-02 13:58:50.575627 EDT | AverageQLoss                0.0183325
2017-07-02 13:58:50.575731 EDT | AveragePolicySurr          -2.1765
2017-07-02 13:58:50.575833 EDT | AverageQ                    2.05212
2017-07-02 13:58:50.575934 EDT | AverageAbsQ                 2.05761
2017-07-02 13:58:50.576074 EDT | AverageY                    2.05199
2017-07-02 13:58:50.576236 EDT | AverageAbsY                 2.05257
2017-07-02 13:58:50.576340 EDT | AverageAbsQYDiff            0.0396409
2017-07-02 13:58:50.576442 EDT | AverageAction               0.298612
2017-07-02 13:58:50.576544 EDT | PolicyRegParamNorm         53.1605
2017-07-02 13:58:50.576696 EDT | QFunRegParamNorm           55.415
2017-07-02 13:58:50.576800 EDT | -----------------------  ------------
2017-07-02 13:58:50.577010 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #362 | Training started
2017-07-02 13:59:00.154419 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #362 | Training finished
2017-07-02 13:59:00.155781 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #362 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 13:59:00.155945 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #362 | Collecting samples for evaluation
2017-07-02 13:59:05.880778 EDT | -----------------------  ------------
2017-07-02 13:59:05.881097 EDT | Epoch                     362
2017-07-02 13:59:05.881305 EDT | Iteration                 362
2017-07-02 13:59:05.881539 EDT | AverageReturn            1000
2017-07-02 13:59:05.881771 EDT | StdReturn                   0
2017-07-02 13:59:05.881946 EDT | MaxReturn                1000
2017-07-02 13:59:05.882177 EDT | MinReturn                1000
2017-07-02 13:59:05.882356 EDT | AverageEsReturn            26.5789
2017-07-02 13:59:05.882466 EDT | StdEsReturn                18.6585
2017-07-02 13:59:05.882569 EDT | MaxEsReturn                75
2017-07-02 13:59:05.882670 EDT | MinEsReturn                 4
2017-07-02 13:59:05.882815 EDT | AverageDiscountedReturn    99.9957
2017-07-02 13:59:05.882918 EDT | AverageQLoss                0.016598
2017-07-02 13:59:05.883019 EDT | AveragePolicySurr          -2.16344
2017-07-02 13:59:05.883119 EDT | AverageQ                    2.03615
2017-07-02 13:59:05.883259 EDT | AverageAbsQ                 2.04164
2017-07-02 13:59:05.883362 EDT | AverageY                    2.03628
2017-07-02 13:59:05.883463 EDT | AverageAbsY                 2.03671
2017-07-02 13:59:05.883563 EDT | AverageAbsQYDiff            0.0371517
2017-07-02 13:59:05.883687 EDT | AverageAction               0.343792
2017-07-02 13:59:05.883787 EDT | PolicyRegParamNorm         53.15
2017-07-02 13:59:05.883886 EDT | QFunRegParamNorm           55.4331
2017-07-02 13:59:05.884005 EDT | -----------------------  ------------
2017-07-02 13:59:05.884194 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #363 | Training started
2017-07-02 13:59:15.292140 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #363 | Training finished
2017-07-02 13:59:15.292682 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #363 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 13:59:15.292846 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #363 | Collecting samples for evaluation
2017-07-02 13:59:21.056314 EDT | -----------------------  ------------
2017-07-02 13:59:21.056523 EDT | Epoch                     363
2017-07-02 13:59:21.056649 EDT | Iteration                 363
2017-07-02 13:59:21.056790 EDT | AverageReturn            1000
2017-07-02 13:59:21.056932 EDT | StdReturn                   0
2017-07-02 13:59:21.057061 EDT | MaxReturn                1000
2017-07-02 13:59:21.057169 EDT | MinReturn                1000
2017-07-02 13:59:21.057274 EDT | AverageEsReturn            31.0625
2017-07-02 13:59:21.057404 EDT | StdEsReturn                27.6427
2017-07-02 13:59:21.057560 EDT | MaxEsReturn               115
2017-07-02 13:59:21.057798 EDT | MinEsReturn                 6
2017-07-02 13:59:21.058035 EDT | AverageDiscountedReturn    99.9957
2017-07-02 13:59:21.058215 EDT | AverageQLoss                0.0160004
2017-07-02 13:59:21.058392 EDT | AveragePolicySurr          -2.15162
2017-07-02 13:59:21.058511 EDT | AverageQ                    2.03039
2017-07-02 13:59:21.058614 EDT | AverageAbsQ                 2.03647
2017-07-02 13:59:21.058715 EDT | AverageY                    2.03031
2017-07-02 13:59:21.058815 EDT | AverageAbsY                 2.03068
2017-07-02 13:59:21.058915 EDT | AverageAbsQYDiff            0.0368708
2017-07-02 13:59:21.059015 EDT | AverageAction               0.415948
2017-07-02 13:59:21.059120 EDT | PolicyRegParamNorm         53.1635
2017-07-02 13:59:21.059231 EDT | QFunRegParamNorm           55.4672
2017-07-02 13:59:21.059343 EDT | -----------------------  ------------
2017-07-02 13:59:21.059536 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #364 | Training started
2017-07-02 13:59:30.494439 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #364 | Training finished
2017-07-02 13:59:30.495009 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #364 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 13:59:30.495183 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #364 | Collecting samples for evaluation
2017-07-02 13:59:36.775104 EDT | -----------------------  ------------
2017-07-02 13:59:36.776070 EDT | Epoch                     364
2017-07-02 13:59:36.776212 EDT | Iteration                 364
2017-07-02 13:59:36.776370 EDT | AverageReturn             438.2
2017-07-02 13:59:36.776578 EDT | StdReturn                 458.719
2017-07-02 13:59:36.776743 EDT | MaxReturn                1000
2017-07-02 13:59:36.776924 EDT | MinReturn                  58
2017-07-02 13:59:36.777029 EDT | AverageEsReturn            35
2017-07-02 13:59:36.777180 EDT | StdEsReturn                28.3901
2017-07-02 13:59:36.777373 EDT | MaxEsReturn               129
2017-07-02 13:59:36.777578 EDT | MinEsReturn                 3
2017-07-02 13:59:36.777776 EDT | AverageDiscountedReturn    68.3298
2017-07-02 13:59:36.777975 EDT | AverageQLoss                0.0154414
2017-07-02 13:59:36.778106 EDT | AveragePolicySurr          -2.14049
2017-07-02 13:59:36.778237 EDT | AverageQ                    2.01921
2017-07-02 13:59:36.778346 EDT | AverageAbsQ                 2.02504
2017-07-02 13:59:36.778503 EDT | AverageY                    2.01923
2017-07-02 13:59:36.778604 EDT | AverageAbsY                 2.01976
2017-07-02 13:59:36.778751 EDT | AverageAbsQYDiff            0.0366954
2017-07-02 13:59:36.778878 EDT | AverageAction               0.465837
2017-07-02 13:59:36.778981 EDT | PolicyRegParamNorm         53.2355
2017-07-02 13:59:36.779083 EDT | QFunRegParamNorm           55.4941
2017-07-02 13:59:36.779184 EDT | -----------------------  ------------
2017-07-02 13:59:36.779383 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #365 | Training started
2017-07-02 13:59:46.470156 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #365 | Training finished
2017-07-02 13:59:46.470725 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #365 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 13:59:46.471125 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #365 | Collecting samples for evaluation
2017-07-02 13:59:52.089394 EDT | -----------------------  ------------
2017-07-02 13:59:52.089617 EDT | Epoch                     365
2017-07-02 13:59:52.089734 EDT | Iteration                 365
2017-07-02 13:59:52.089854 EDT | AverageReturn            1000
2017-07-02 13:59:52.090044 EDT | StdReturn                   0
2017-07-02 13:59:52.090192 EDT | MaxReturn                1000
2017-07-02 13:59:52.090396 EDT | MinReturn                1000
2017-07-02 13:59:52.090598 EDT | AverageEsReturn            27.7297
2017-07-02 13:59:52.090816 EDT | StdEsReturn                25.3874
2017-07-02 13:59:52.091032 EDT | MaxEsReturn               115
2017-07-02 13:59:52.091222 EDT | MinEsReturn                 3
2017-07-02 13:59:52.091380 EDT | AverageDiscountedReturn    99.9957
2017-07-02 13:59:52.091574 EDT | AverageQLoss                0.0163827
2017-07-02 13:59:52.091795 EDT | AveragePolicySurr          -2.13714
2017-07-02 13:59:52.092010 EDT | AverageQ                    2.0091
2017-07-02 13:59:52.092235 EDT | AverageAbsQ                 2.01557
2017-07-02 13:59:52.092378 EDT | AverageY                    2.00914
2017-07-02 13:59:52.092488 EDT | AverageAbsY                 2.00959
2017-07-02 13:59:52.092625 EDT | AverageAbsQYDiff            0.0388678
2017-07-02 13:59:52.092729 EDT | AverageAction               0.360871
2017-07-02 13:59:52.092865 EDT | PolicyRegParamNorm         53.3251
2017-07-02 13:59:52.093016 EDT | QFunRegParamNorm           55.5242
2017-07-02 13:59:52.093140 EDT | -----------------------  ------------
2017-07-02 13:59:52.093309 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #366 | Training started
2017-07-02 14:00:01.775029 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #366 | Training finished
2017-07-02 14:00:01.776448 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #366 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 14:00:01.776593 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #366 | Collecting samples for evaluation
2017-07-02 14:00:07.425850 EDT | -----------------------  ------------
2017-07-02 14:00:07.426681 EDT | Epoch                     366
2017-07-02 14:00:07.426934 EDT | Iteration                 366
2017-07-02 14:00:07.427163 EDT | AverageReturn            1000
2017-07-02 14:00:07.427364 EDT | StdReturn                   0
2017-07-02 14:00:07.427594 EDT | MaxReturn                1000
2017-07-02 14:00:07.427777 EDT | MinReturn                1000
2017-07-02 14:00:07.427891 EDT | AverageEsReturn            22.878
2017-07-02 14:00:07.428005 EDT | StdEsReturn                22.1031
2017-07-02 14:00:07.428164 EDT | MaxEsReturn                90
2017-07-02 14:00:07.428296 EDT | MinEsReturn                 3
2017-07-02 14:00:07.428436 EDT | AverageDiscountedReturn    99.9957
2017-07-02 14:00:07.428570 EDT | AverageQLoss                0.0153864
2017-07-02 14:00:07.428796 EDT | AveragePolicySurr          -2.12308
2017-07-02 14:00:07.429013 EDT | AverageQ                    2.00232
2017-07-02 14:00:07.429234 EDT | AverageAbsQ                 2.00769
2017-07-02 14:00:07.429454 EDT | AverageY                    2.00222
2017-07-02 14:00:07.429664 EDT | AverageAbsY                 2.00277
2017-07-02 14:00:07.429902 EDT | AverageAbsQYDiff            0.0356174
2017-07-02 14:00:07.430127 EDT | AverageAction               0.634372
2017-07-02 14:00:07.430353 EDT | PolicyRegParamNorm         53.3102
2017-07-02 14:00:07.430573 EDT | QFunRegParamNorm           55.5574
2017-07-02 14:00:07.430749 EDT | -----------------------  ------------
2017-07-02 14:00:07.430964 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #367 | Training started
2017-07-02 14:00:17.131284 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #367 | Training finished
2017-07-02 14:00:17.132272 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #367 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 14:00:17.132515 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #367 | Collecting samples for evaluation
2017-07-02 14:00:23.281633 EDT | -----------------------  ------------
2017-07-02 14:00:23.281942 EDT | Epoch                     367
2017-07-02 14:00:23.282183 EDT | Iteration                 367
2017-07-02 14:00:23.282416 EDT | AverageReturn            1000
2017-07-02 14:00:23.282645 EDT | StdReturn                   0
2017-07-02 14:00:23.282870 EDT | MaxReturn                1000
2017-07-02 14:00:23.282995 EDT | MinReturn                1000
2017-07-02 14:00:23.283124 EDT | AverageEsReturn            34.9333
2017-07-02 14:00:23.283239 EDT | StdEsReturn                27.8184
2017-07-02 14:00:23.283465 EDT | MaxEsReturn               110
2017-07-02 14:00:23.283640 EDT | MinEsReturn                 3
2017-07-02 14:00:23.283748 EDT | AverageDiscountedReturn    99.9957
2017-07-02 14:00:23.283858 EDT | AverageQLoss                0.0140881
2017-07-02 14:00:23.284002 EDT | AveragePolicySurr          -2.11722
2017-07-02 14:00:23.284106 EDT | AverageQ                    1.99986
2017-07-02 14:00:23.284208 EDT | AverageAbsQ                 2.00578
2017-07-02 14:00:23.284309 EDT | AverageY                    1.99984
2017-07-02 14:00:23.284435 EDT | AverageAbsY                 2.00025
2017-07-02 14:00:23.284656 EDT | AverageAbsQYDiff            0.0339314
2017-07-02 14:00:23.284867 EDT | AverageAction               0.709713
2017-07-02 14:00:23.285094 EDT | PolicyRegParamNorm         53.3167
2017-07-02 14:00:23.285317 EDT | QFunRegParamNorm           55.6019
2017-07-02 14:00:23.285709 EDT | -----------------------  ------------
2017-07-02 14:00:23.286042 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #368 | Training started
2017-07-02 14:00:32.891417 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #368 | Training finished
2017-07-02 14:00:32.896012 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #368 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 14:00:32.896219 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #368 | Collecting samples for evaluation
2017-07-02 14:00:38.492990 EDT | -----------------------  ------------
2017-07-02 14:00:38.493602 EDT | Epoch                     368
2017-07-02 14:00:38.493745 EDT | Iteration                 368
2017-07-02 14:00:38.493931 EDT | AverageReturn            1000
2017-07-02 14:00:38.494127 EDT | StdReturn                   0
2017-07-02 14:00:38.494243 EDT | MaxReturn                1000
2017-07-02 14:00:38.494443 EDT | MinReturn                1000
2017-07-02 14:00:38.494585 EDT | AverageEsReturn            31.5806
2017-07-02 14:00:38.494707 EDT | StdEsReturn                26.3656
2017-07-02 14:00:38.494835 EDT | MaxEsReturn               103
2017-07-02 14:00:38.494974 EDT | MinEsReturn                 3
2017-07-02 14:00:38.495094 EDT | AverageDiscountedReturn    99.9957
2017-07-02 14:00:38.495233 EDT | AverageQLoss                0.0146348
2017-07-02 14:00:38.495383 EDT | AveragePolicySurr          -2.10129
2017-07-02 14:00:38.495588 EDT | AverageQ                    1.98121
2017-07-02 14:00:38.495696 EDT | AverageAbsQ                 1.98703
2017-07-02 14:00:38.495799 EDT | AverageY                    1.98119
2017-07-02 14:00:38.495951 EDT | AverageAbsY                 1.98177
2017-07-02 14:00:38.496149 EDT | AverageAbsQYDiff            0.0352096
2017-07-02 14:00:38.496317 EDT | AverageAction               0.57153
2017-07-02 14:00:38.496425 EDT | PolicyRegParamNorm         53.3648
2017-07-02 14:00:38.496570 EDT | QFunRegParamNorm           55.6148
2017-07-02 14:00:38.496724 EDT | -----------------------  ------------
2017-07-02 14:00:38.496918 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #369 | Training started
2017-07-02 14:00:48.110908 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #369 | Training finished
2017-07-02 14:00:48.111489 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #369 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 14:00:48.111755 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #369 | Collecting samples for evaluation
2017-07-02 14:00:53.799041 EDT | -----------------------  ------------
2017-07-02 14:00:53.799274 EDT | Epoch                     369
2017-07-02 14:00:53.799443 EDT | Iteration                 369
2017-07-02 14:00:53.799611 EDT | AverageReturn            1000
2017-07-02 14:00:53.799762 EDT | StdReturn                   0
2017-07-02 14:00:53.799944 EDT | MaxReturn                1000
2017-07-02 14:00:53.800074 EDT | MinReturn                1000
2017-07-02 14:00:53.800227 EDT | AverageEsReturn            37.56
2017-07-02 14:00:53.800377 EDT | StdEsReturn                28.4985
2017-07-02 14:00:53.800496 EDT | MaxEsReturn               139
2017-07-02 14:00:53.800681 EDT | MinEsReturn                 6
2017-07-02 14:00:53.800849 EDT | AverageDiscountedReturn    99.9957
2017-07-02 14:00:53.801023 EDT | AverageQLoss                0.0151791
2017-07-02 14:00:53.801136 EDT | AveragePolicySurr          -2.09379
2017-07-02 14:00:53.801306 EDT | AverageQ                    1.97536
2017-07-02 14:00:53.801468 EDT | AverageAbsQ                 1.98072
2017-07-02 14:00:53.801669 EDT | AverageY                    1.9753
2017-07-02 14:00:53.801841 EDT | AverageAbsY                 1.97586
2017-07-02 14:00:53.801977 EDT | AverageAbsQYDiff            0.0349145
2017-07-02 14:00:53.802165 EDT | AverageAction               0.716008
2017-07-02 14:00:53.802358 EDT | PolicyRegParamNorm         53.4629
2017-07-02 14:00:53.802552 EDT | QFunRegParamNorm           55.6529
2017-07-02 14:00:53.802717 EDT | -----------------------  ------------
2017-07-02 14:00:53.802918 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #370 | Training started
2017-07-02 14:01:03.466912 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #370 | Training finished
2017-07-02 14:01:03.467491 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #370 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 14:01:03.467748 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #370 | Collecting samples for evaluation
2017-07-02 14:01:09.031735 EDT | -----------------------  ------------
2017-07-02 14:01:09.032297 EDT | Epoch                     370
2017-07-02 14:01:09.032461 EDT | Iteration                 370
2017-07-02 14:01:09.032612 EDT | AverageReturn            1000
2017-07-02 14:01:09.032810 EDT | StdReturn                   0
2017-07-02 14:01:09.032976 EDT | MaxReturn                1000
2017-07-02 14:01:09.033115 EDT | MinReturn                1000
2017-07-02 14:01:09.033328 EDT | AverageEsReturn            31.8125
2017-07-02 14:01:09.033518 EDT | StdEsReturn                26.1288
2017-07-02 14:01:09.033742 EDT | MaxEsReturn               102
2017-07-02 14:01:09.033978 EDT | MinEsReturn                 3
2017-07-02 14:01:09.034206 EDT | AverageDiscountedReturn    99.9957
2017-07-02 14:01:09.034439 EDT | AverageQLoss                0.0175131
2017-07-02 14:01:09.034667 EDT | AveragePolicySurr          -2.08702
2017-07-02 14:01:09.034868 EDT | AverageQ                    1.96743
2017-07-02 14:01:09.035102 EDT | AverageAbsQ                 1.97348
2017-07-02 14:01:09.035322 EDT | AverageY                    1.96742
2017-07-02 14:01:09.035556 EDT | AverageAbsY                 1.96777
2017-07-02 14:01:09.035848 EDT | AverageAbsQYDiff            0.0378253
2017-07-02 14:01:09.036133 EDT | AverageAction               0.7333
2017-07-02 14:01:09.036359 EDT | PolicyRegParamNorm         53.5439
2017-07-02 14:01:09.036598 EDT | QFunRegParamNorm           55.6682
2017-07-02 14:01:09.036842 EDT | -----------------------  ------------
2017-07-02 14:01:09.037132 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #371 | Training started
2017-07-02 14:01:18.754069 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #371 | Training finished
2017-07-02 14:01:18.754810 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #371 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 14:01:18.755051 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #371 | Collecting samples for evaluation
2017-07-02 14:01:24.352977 EDT | -----------------------  ------------
2017-07-02 14:01:24.353159 EDT | Epoch                     371
2017-07-02 14:01:24.353297 EDT | Iteration                 371
2017-07-02 14:01:24.353461 EDT | AverageReturn            1000
2017-07-02 14:01:24.353606 EDT | StdReturn                   0
2017-07-02 14:01:24.353711 EDT | MaxReturn                1000
2017-07-02 14:01:24.353814 EDT | MinReturn                1000
2017-07-02 14:01:24.353962 EDT | AverageEsReturn            35.6923
2017-07-02 14:01:24.354065 EDT | StdEsReturn                27.0424
2017-07-02 14:01:24.354199 EDT | MaxEsReturn               103
2017-07-02 14:01:24.354304 EDT | MinEsReturn                 3
2017-07-02 14:01:24.354440 EDT | AverageDiscountedReturn    99.9957
2017-07-02 14:01:24.354592 EDT | AverageQLoss                0.0163009
2017-07-02 14:01:24.354783 EDT | AveragePolicySurr          -2.07303
2017-07-02 14:01:24.354988 EDT | AverageQ                    1.95277
2017-07-02 14:01:24.355098 EDT | AverageAbsQ                 1.9591
2017-07-02 14:01:24.355264 EDT | AverageY                    1.95276
2017-07-02 14:01:24.355402 EDT | AverageAbsY                 1.95312
2017-07-02 14:01:24.355504 EDT | AverageAbsQYDiff            0.0386179
2017-07-02 14:01:24.355659 EDT | AverageAction               0.83452
2017-07-02 14:01:24.355798 EDT | PolicyRegParamNorm         53.5957
2017-07-02 14:01:24.355972 EDT | QFunRegParamNorm           55.6906
2017-07-02 14:01:24.356075 EDT | -----------------------  ------------
2017-07-02 14:01:24.356274 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #372 | Training started
2017-07-02 14:01:34.029053 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #372 | Training finished
2017-07-02 14:01:34.029901 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #372 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 14:01:34.030083 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #372 | Collecting samples for evaluation
2017-07-02 14:01:39.706191 EDT | -----------------------  ------------
2017-07-02 14:01:39.707315 EDT | Epoch                     372
2017-07-02 14:01:39.707461 EDT | Iteration                 372
2017-07-02 14:01:39.707627 EDT | AverageReturn            1000
2017-07-02 14:01:39.707796 EDT | StdReturn                   0
2017-07-02 14:01:39.707915 EDT | MaxReturn                1000
2017-07-02 14:01:39.708038 EDT | MinReturn                1000
2017-07-02 14:01:39.708232 EDT | AverageEsReturn            36.0968
2017-07-02 14:01:39.708359 EDT | StdEsReturn                31.0934
2017-07-02 14:01:39.708467 EDT | MaxEsReturn               156
2017-07-02 14:01:39.708619 EDT | MinEsReturn                 5
2017-07-02 14:01:39.708735 EDT | AverageDiscountedReturn    99.9957
2017-07-02 14:01:39.708862 EDT | AverageQLoss                0.0145971
2017-07-02 14:01:39.708971 EDT | AveragePolicySurr          -2.06394
2017-07-02 14:01:39.709131 EDT | AverageQ                    1.95142
2017-07-02 14:01:39.709245 EDT | AverageAbsQ                 1.95773
2017-07-02 14:01:39.709346 EDT | AverageY                    1.95137
2017-07-02 14:01:39.709447 EDT | AverageAbsY                 1.95187
2017-07-02 14:01:39.709605 EDT | AverageAbsQYDiff            0.0352244
2017-07-02 14:01:39.709814 EDT | AverageAction               0.767022
2017-07-02 14:01:39.710047 EDT | PolicyRegParamNorm         53.5769
2017-07-02 14:01:39.710250 EDT | QFunRegParamNorm           55.6753
2017-07-02 14:01:39.710468 EDT | -----------------------  ------------
2017-07-02 14:01:39.710724 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #373 | Training started
2017-07-02 14:01:49.369028 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #373 | Training finished
2017-07-02 14:01:49.369584 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #373 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 14:01:49.369853 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #373 | Collecting samples for evaluation
2017-07-02 14:01:55.049105 EDT | -----------------------  ------------
2017-07-02 14:01:55.049304 EDT | Epoch                     373
2017-07-02 14:01:55.049457 EDT | Iteration                 373
2017-07-02 14:01:55.049647 EDT | AverageReturn            1000
2017-07-02 14:01:55.049788 EDT | StdReturn                   0
2017-07-02 14:01:55.049988 EDT | MaxReturn                1000
2017-07-02 14:01:55.050132 EDT | MinReturn                1000
2017-07-02 14:01:55.050278 EDT | AverageEsReturn            37.5556
2017-07-02 14:01:55.050382 EDT | StdEsReturn                30.5036
2017-07-02 14:01:55.050545 EDT | MaxEsReturn               161
2017-07-02 14:01:55.050660 EDT | MinEsReturn                 3
2017-07-02 14:01:55.050770 EDT | AverageDiscountedReturn    99.9957
2017-07-02 14:01:55.050904 EDT | AverageQLoss                0.0150307
2017-07-02 14:01:55.051056 EDT | AveragePolicySurr          -2.04893
2017-07-02 14:01:55.051159 EDT | AverageQ                    1.93328
2017-07-02 14:01:55.051270 EDT | AverageAbsQ                 1.93969
2017-07-02 14:01:55.051371 EDT | AverageY                    1.93316
2017-07-02 14:01:55.051499 EDT | AverageAbsY                 1.93378
2017-07-02 14:01:55.051602 EDT | AverageAbsQYDiff            0.0362421
2017-07-02 14:01:55.051703 EDT | AverageAction               0.344508
2017-07-02 14:01:55.051803 EDT | PolicyRegParamNorm         53.5801
2017-07-02 14:01:55.051902 EDT | QFunRegParamNorm           55.7519
2017-07-02 14:01:55.052054 EDT | -----------------------  ------------
2017-07-02 14:01:55.052248 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #374 | Training started
2017-07-02 14:02:04.531564 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #374 | Training finished
2017-07-02 14:02:04.532217 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #374 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 14:02:04.532441 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #374 | Collecting samples for evaluation
2017-07-02 14:02:10.273859 EDT | -----------------------  ------------
2017-07-02 14:02:10.274341 EDT | Epoch                     374
2017-07-02 14:02:10.274606 EDT | Iteration                 374
2017-07-02 14:02:10.274815 EDT | AverageReturn            1000
2017-07-02 14:02:10.274962 EDT | StdReturn                   0
2017-07-02 14:02:10.275068 EDT | MaxReturn                1000
2017-07-02 14:02:10.275172 EDT | MinReturn                1000
2017-07-02 14:02:10.275302 EDT | AverageEsReturn            31.5
2017-07-02 14:02:10.275411 EDT | StdEsReturn                27.7759
2017-07-02 14:02:10.275548 EDT | MaxEsReturn               107
2017-07-02 14:02:10.275653 EDT | MinEsReturn                 4
2017-07-02 14:02:10.275785 EDT | AverageDiscountedReturn    99.9957
2017-07-02 14:02:10.275972 EDT | AverageQLoss                0.0140795
2017-07-02 14:02:10.276083 EDT | AveragePolicySurr          -2.04328
2017-07-02 14:02:10.276186 EDT | AverageQ                    1.92931
2017-07-02 14:02:10.276364 EDT | AverageAbsQ                 1.93481
2017-07-02 14:02:10.276491 EDT | AverageY                    1.92934
2017-07-02 14:02:10.276683 EDT | AverageAbsY                 1.92982
2017-07-02 14:02:10.276833 EDT | AverageAbsQYDiff            0.034226
2017-07-02 14:02:10.276938 EDT | AverageAction               0.0551315
2017-07-02 14:02:10.277045 EDT | PolicyRegParamNorm         53.5786
2017-07-02 14:02:10.277173 EDT | QFunRegParamNorm           55.7555
2017-07-02 14:02:10.277322 EDT | -----------------------  ------------
2017-07-02 14:02:10.277617 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #375 | Training started
2017-07-02 14:02:19.838636 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #375 | Training finished
2017-07-02 14:02:19.839186 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #375 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 14:02:19.839499 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #375 | Collecting samples for evaluation
2017-07-02 14:02:25.489370 EDT | -----------------------  ------------
2017-07-02 14:02:25.489632 EDT | Epoch                     375
2017-07-02 14:02:25.489783 EDT | Iteration                 375
2017-07-02 14:02:25.489905 EDT | AverageReturn            1000
2017-07-02 14:02:25.490005 EDT | StdReturn                   0
2017-07-02 14:02:25.490103 EDT | MaxReturn                1000
2017-07-02 14:02:25.490217 EDT | MinReturn                1000
2017-07-02 14:02:25.490354 EDT | AverageEsReturn            25.4872
2017-07-02 14:02:25.490459 EDT | StdEsReturn                17.3735
2017-07-02 14:02:25.490558 EDT | MaxEsReturn                65
2017-07-02 14:02:25.490655 EDT | MinEsReturn                 3
2017-07-02 14:02:25.490754 EDT | AverageDiscountedReturn    99.9957
2017-07-02 14:02:25.490969 EDT | AverageQLoss                0.0159245
2017-07-02 14:02:25.491195 EDT | AveragePolicySurr          -2.03062
2017-07-02 14:02:25.491404 EDT | AverageQ                    1.92067
2017-07-02 14:02:25.491634 EDT | AverageAbsQ                 1.92686
2017-07-02 14:02:25.491853 EDT | AverageY                    1.92067
2017-07-02 14:02:25.492073 EDT | AverageAbsY                 1.92136
2017-07-02 14:02:25.492298 EDT | AverageAbsQYDiff            0.0378008
2017-07-02 14:02:25.492432 EDT | AverageAction               0.573243
2017-07-02 14:02:25.492568 EDT | PolicyRegParamNorm         53.5556
2017-07-02 14:02:25.492796 EDT | QFunRegParamNorm           55.8075
2017-07-02 14:02:25.493001 EDT | -----------------------  ------------
2017-07-02 14:02:25.493322 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #376 | Training started
2017-07-02 14:02:35.128404 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #376 | Training finished
2017-07-02 14:02:35.128926 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #376 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 14:02:35.129077 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #376 | Collecting samples for evaluation
2017-07-02 14:02:41.218904 EDT | -----------------------  ------------
2017-07-02 14:02:41.219480 EDT | Epoch                     376
2017-07-02 14:02:41.219657 EDT | Iteration                 376
2017-07-02 14:02:41.219819 EDT | AverageReturn             512.286
2017-07-02 14:02:41.219955 EDT | StdReturn                 465.054
2017-07-02 14:02:41.220121 EDT | MaxReturn                1000
2017-07-02 14:02:41.220286 EDT | MinReturn                  57
2017-07-02 14:02:41.220435 EDT | AverageEsReturn            28.1111
2017-07-02 14:02:41.220550 EDT | StdEsReturn                23.485
2017-07-02 14:02:41.220684 EDT | MaxEsReturn                90
2017-07-02 14:02:41.220810 EDT | MinEsReturn                 3
2017-07-02 14:02:41.220917 EDT | AverageDiscountedReturn    73.7066
2017-07-02 14:02:41.221023 EDT | AverageQLoss                0.0144972
2017-07-02 14:02:41.221219 EDT | AveragePolicySurr          -2.02221
2017-07-02 14:02:41.221374 EDT | AverageQ                    1.90899
2017-07-02 14:02:41.221483 EDT | AverageAbsQ                 1.91448
2017-07-02 14:02:41.221628 EDT | AverageY                    1.90892
2017-07-02 14:02:41.221824 EDT | AverageAbsY                 1.90964
2017-07-02 14:02:41.221938 EDT | AverageAbsQYDiff            0.0353871
2017-07-02 14:02:41.222137 EDT | AverageAction               0.713707
2017-07-02 14:02:41.222335 EDT | PolicyRegParamNorm         53.5882
2017-07-02 14:02:41.222461 EDT | QFunRegParamNorm           55.8479
2017-07-02 14:02:41.222584 EDT | -----------------------  ------------
2017-07-02 14:02:41.222798 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #377 | Training started
2017-07-02 14:02:50.952576 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #377 | Training finished
2017-07-02 14:02:50.953087 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #377 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 14:02:50.953234 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #377 | Collecting samples for evaluation
2017-07-02 14:02:56.659996 EDT | -----------------------  ------------
2017-07-02 14:02:56.660188 EDT | Epoch                     377
2017-07-02 14:02:56.660352 EDT | Iteration                 377
2017-07-02 14:02:56.660554 EDT | AverageReturn            1000
2017-07-02 14:02:56.660752 EDT | StdReturn                   0
2017-07-02 14:02:56.660902 EDT | MaxReturn                1000
2017-07-02 14:02:56.661013 EDT | MinReturn                1000
2017-07-02 14:02:56.661121 EDT | AverageEsReturn            34.5172
2017-07-02 14:02:56.661280 EDT | StdEsReturn                29.5058
2017-07-02 14:02:56.661398 EDT | MaxEsReturn               114
2017-07-02 14:02:56.661516 EDT | MinEsReturn                 3
2017-07-02 14:02:56.661670 EDT | AverageDiscountedReturn    99.9957
2017-07-02 14:02:56.661774 EDT | AverageQLoss                0.0160505
2017-07-02 14:02:56.661899 EDT | AveragePolicySurr          -2.01335
2017-07-02 14:02:56.662004 EDT | AverageQ                    1.90099
2017-07-02 14:02:56.662171 EDT | AverageAbsQ                 1.9077
2017-07-02 14:02:56.662274 EDT | AverageY                    1.90118
2017-07-02 14:02:56.662375 EDT | AverageAbsY                 1.90189
2017-07-02 14:02:56.662507 EDT | AverageAbsQYDiff            0.0377352
2017-07-02 14:02:56.662615 EDT | AverageAction               0.604815
2017-07-02 14:02:56.662722 EDT | PolicyRegParamNorm         53.5947
2017-07-02 14:02:56.662829 EDT | QFunRegParamNorm           55.8395
2017-07-02 14:02:56.662935 EDT | -----------------------  ------------
2017-07-02 14:02:56.663145 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #378 | Training started
2017-07-02 14:03:06.410065 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #378 | Training finished
2017-07-02 14:03:06.410674 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #378 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 14:03:06.410891 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #378 | Collecting samples for evaluation
2017-07-02 14:03:11.988958 EDT | -----------------------  ------------
2017-07-02 14:03:11.989544 EDT | Epoch                     378
2017-07-02 14:03:11.989721 EDT | Iteration                 378
2017-07-02 14:03:11.989837 EDT | AverageReturn            1000
2017-07-02 14:03:11.990005 EDT | StdReturn                   0
2017-07-02 14:03:11.990171 EDT | MaxReturn                1000
2017-07-02 14:03:11.990303 EDT | MinReturn                1000
2017-07-02 14:03:11.990471 EDT | AverageEsReturn            28.6286
2017-07-02 14:03:11.990615 EDT | StdEsReturn                27.8415
2017-07-02 14:03:11.990724 EDT | MaxEsReturn               114
2017-07-02 14:03:11.990832 EDT | MinEsReturn                 3
2017-07-02 14:03:11.990969 EDT | AverageDiscountedReturn    99.9957
2017-07-02 14:03:11.991100 EDT | AverageQLoss                0.015709
2017-07-02 14:03:11.991207 EDT | AveragePolicySurr          -2.00559
2017-07-02 14:03:11.991313 EDT | AverageQ                    1.89718
2017-07-02 14:03:11.991482 EDT | AverageAbsQ                 1.90278
2017-07-02 14:03:11.991591 EDT | AverageY                    1.89701
2017-07-02 14:03:11.991700 EDT | AverageAbsY                 1.8976
2017-07-02 14:03:11.991806 EDT | AverageAbsQYDiff            0.0369024
2017-07-02 14:03:11.991988 EDT | AverageAction               0.0226101
2017-07-02 14:03:11.992186 EDT | PolicyRegParamNorm         53.6409
2017-07-02 14:03:11.992365 EDT | QFunRegParamNorm           55.8699
2017-07-02 14:03:11.992528 EDT | -----------------------  ------------
2017-07-02 14:03:11.992702 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #379 | Training started
2017-07-02 14:03:21.661010 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #379 | Training finished
2017-07-02 14:03:21.661550 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #379 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 14:03:21.661697 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #379 | Collecting samples for evaluation
2017-07-02 14:03:27.360570 EDT | -----------------------  ------------
2017-07-02 14:03:27.360864 EDT | Epoch                     379
2017-07-02 14:03:27.361088 EDT | Iteration                 379
2017-07-02 14:03:27.361271 EDT | AverageReturn            1000
2017-07-02 14:03:27.361376 EDT | StdReturn                   0
2017-07-02 14:03:27.361475 EDT | MaxReturn                1000
2017-07-02 14:03:27.361643 EDT | MinReturn                1000
2017-07-02 14:03:27.361747 EDT | AverageEsReturn            17.1321
2017-07-02 14:03:27.361845 EDT | StdEsReturn                12.9193
2017-07-02 14:03:27.361949 EDT | MaxEsReturn                58
2017-07-02 14:03:27.362086 EDT | MinEsReturn                 3
2017-07-02 14:03:27.362225 EDT | AverageDiscountedReturn    99.9957
2017-07-02 14:03:27.362325 EDT | AverageQLoss                0.0152322
2017-07-02 14:03:27.362463 EDT | AveragePolicySurr          -1.98989
2017-07-02 14:03:27.362564 EDT | AverageQ                    1.88074
2017-07-02 14:03:27.362660 EDT | AverageAbsQ                 1.88693
2017-07-02 14:03:27.362756 EDT | AverageY                    1.88084
2017-07-02 14:03:27.362852 EDT | AverageAbsY                 1.88169
2017-07-02 14:03:27.362990 EDT | AverageAbsQYDiff            0.0353551
2017-07-02 14:03:27.363106 EDT | AverageAction               0.501147
2017-07-02 14:03:27.363204 EDT | PolicyRegParamNorm         53.6799
2017-07-02 14:03:27.363301 EDT | QFunRegParamNorm           55.9249
2017-07-02 14:03:27.363409 EDT | -----------------------  ------------
2017-07-02 14:03:27.363603 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #380 | Training started
2017-07-02 14:03:36.951052 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #380 | Training finished
2017-07-02 14:03:36.951617 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #380 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 14:03:36.951895 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #380 | Collecting samples for evaluation
2017-07-02 14:03:42.618234 EDT | -----------------------  ------------
2017-07-02 14:03:42.618750 EDT | Epoch                     380
2017-07-02 14:03:42.618980 EDT | Iteration                 380
2017-07-02 14:03:42.619172 EDT | AverageReturn            1000
2017-07-02 14:03:42.619324 EDT | StdReturn                   0
2017-07-02 14:03:42.619460 EDT | MaxReturn                1000
2017-07-02 14:03:42.619566 EDT | MinReturn                1000
2017-07-02 14:03:42.619684 EDT | AverageEsReturn            20.2037
2017-07-02 14:03:42.619810 EDT | StdEsReturn                20.1792
2017-07-02 14:03:42.619933 EDT | MaxEsReturn                98
2017-07-02 14:03:42.620052 EDT | MinEsReturn                 3
2017-07-02 14:03:42.620198 EDT | AverageDiscountedReturn    99.9957
2017-07-02 14:03:42.620314 EDT | AverageQLoss                0.011525
2017-07-02 14:03:42.620439 EDT | AveragePolicySurr          -1.9861
2017-07-02 14:03:42.620551 EDT | AverageQ                    1.87487
2017-07-02 14:03:42.620783 EDT | AverageAbsQ                 1.8799
2017-07-02 14:03:42.621020 EDT | AverageY                    1.87485
2017-07-02 14:03:42.621228 EDT | AverageAbsY                 1.87579
2017-07-02 14:03:42.621401 EDT | AverageAbsQYDiff            0.0312753
2017-07-02 14:03:42.621590 EDT | AverageAction               0.0150786
2017-07-02 14:03:42.621697 EDT | PolicyRegParamNorm         53.7255
2017-07-02 14:03:42.621799 EDT | QFunRegParamNorm           55.9417
2017-07-02 14:03:42.621963 EDT | -----------------------  ------------
2017-07-02 14:03:42.622176 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #381 | Training started
2017-07-02 14:03:52.173104 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #381 | Training finished
2017-07-02 14:03:52.175528 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #381 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 14:03:52.175757 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #381 | Collecting samples for evaluation
2017-07-02 14:03:57.888946 EDT | -----------------------  ------------
2017-07-02 14:03:57.889280 EDT | Epoch                     381
2017-07-02 14:03:57.889460 EDT | Iteration                 381
2017-07-02 14:03:57.889722 EDT | AverageReturn            1000
2017-07-02 14:03:57.889932 EDT | StdReturn                   0
2017-07-02 14:03:57.890133 EDT | MaxReturn                1000
2017-07-02 14:03:57.890369 EDT | MinReturn                1000
2017-07-02 14:03:57.890554 EDT | AverageEsReturn            18.1273
2017-07-02 14:03:57.890791 EDT | StdEsReturn                19.6349
2017-07-02 14:03:57.890983 EDT | MaxEsReturn                96
2017-07-02 14:03:57.891219 EDT | MinEsReturn                 3
2017-07-02 14:03:57.891443 EDT | AverageDiscountedReturn    99.9957
2017-07-02 14:03:57.891641 EDT | AverageQLoss                0.0120979
2017-07-02 14:03:57.891877 EDT | AveragePolicySurr          -1.97616
2017-07-02 14:03:57.892064 EDT | AverageQ                    1.86464
2017-07-02 14:03:57.892299 EDT | AverageAbsQ                 1.87034
2017-07-02 14:03:57.892495 EDT | AverageY                    1.86451
2017-07-02 14:03:57.892728 EDT | AverageAbsY                 1.86524
2017-07-02 14:03:57.892954 EDT | AverageAbsQYDiff            0.0324286
2017-07-02 14:03:57.893144 EDT | AverageAction               0.331183
2017-07-02 14:03:57.893379 EDT | PolicyRegParamNorm         53.7467
2017-07-02 14:03:57.893641 EDT | QFunRegParamNorm           55.9966
2017-07-02 14:03:57.893879 EDT | -----------------------  ------------
2017-07-02 14:03:57.894162 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #382 | Training started
2017-07-02 14:04:07.469716 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #382 | Training finished
2017-07-02 14:04:07.470432 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #382 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 14:04:07.470677 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #382 | Collecting samples for evaluation
2017-07-02 14:04:13.213807 EDT | -----------------------  ------------
2017-07-02 14:04:13.214097 EDT | Epoch                     382
2017-07-02 14:04:13.214333 EDT | Iteration                 382
2017-07-02 14:04:13.214557 EDT | AverageReturn            1000
2017-07-02 14:04:13.214777 EDT | StdReturn                   0
2017-07-02 14:04:13.214990 EDT | MaxReturn                1000
2017-07-02 14:04:13.215136 EDT | MinReturn                1000
2017-07-02 14:04:13.215265 EDT | AverageEsReturn            26.2105
2017-07-02 14:04:13.215431 EDT | StdEsReturn                27.8087
2017-07-02 14:04:13.215649 EDT | MaxEsReturn               124
2017-07-02 14:04:13.215811 EDT | MinEsReturn                 3
2017-07-02 14:04:13.216031 EDT | AverageDiscountedReturn    99.9957
2017-07-02 14:04:13.216257 EDT | AverageQLoss                0.0134044
2017-07-02 14:04:13.216475 EDT | AveragePolicySurr          -1.96264
2017-07-02 14:04:13.216692 EDT | AverageQ                    1.85671
2017-07-02 14:04:13.216901 EDT | AverageAbsQ                 1.86262
2017-07-02 14:04:13.217091 EDT | AverageY                    1.85679
2017-07-02 14:04:13.217317 EDT | AverageAbsY                 1.85761
2017-07-02 14:04:13.217465 EDT | AverageAbsQYDiff            0.0326511
2017-07-02 14:04:13.217645 EDT | AverageAction               0.214466
2017-07-02 14:04:13.217849 EDT | PolicyRegParamNorm         53.7993
2017-07-02 14:04:13.218061 EDT | QFunRegParamNorm           56.0199
2017-07-02 14:04:13.218260 EDT | -----------------------  ------------
2017-07-02 14:04:13.218557 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #383 | Training started
2017-07-02 14:04:22.759444 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #383 | Training finished
2017-07-02 14:04:22.759995 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #383 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 14:04:22.760242 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #383 | Collecting samples for evaluation
2017-07-02 14:04:28.423826 EDT | -----------------------  ------------
2017-07-02 14:04:28.424118 EDT | Epoch                     383
2017-07-02 14:04:28.424355 EDT | Iteration                 383
2017-07-02 14:04:28.424577 EDT | AverageReturn            1000
2017-07-02 14:04:28.424799 EDT | StdReturn                   0
2017-07-02 14:04:28.425011 EDT | MaxReturn                1000
2017-07-02 14:04:28.425189 EDT | MinReturn                1000
2017-07-02 14:04:28.425413 EDT | AverageEsReturn            24.0476
2017-07-02 14:04:28.425621 EDT | StdEsReturn                15.197
2017-07-02 14:04:28.425811 EDT | MaxEsReturn                67
2017-07-02 14:04:28.425919 EDT | MinEsReturn                 4
2017-07-02 14:04:28.426023 EDT | AverageDiscountedReturn    99.9957
2017-07-02 14:04:28.426131 EDT | AverageQLoss                0.0123966
2017-07-02 14:04:28.426262 EDT | AveragePolicySurr          -1.95419
2017-07-02 14:04:28.426364 EDT | AverageQ                    1.85008
2017-07-02 14:04:28.426466 EDT | AverageAbsQ                 1.85477
2017-07-02 14:04:28.426567 EDT | AverageY                    1.85014
2017-07-02 14:04:28.426667 EDT | AverageAbsY                 1.85077
2017-07-02 14:04:28.426787 EDT | AverageAbsQYDiff            0.0314051
2017-07-02 14:04:28.426890 EDT | AverageAction               0.119995
2017-07-02 14:04:28.426989 EDT | PolicyRegParamNorm         53.8386
2017-07-02 14:04:28.427089 EDT | QFunRegParamNorm           56.084
2017-07-02 14:04:28.427189 EDT | -----------------------  ------------
2017-07-02 14:04:28.427453 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #384 | Training started
2017-07-02 14:04:37.971195 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #384 | Training finished
2017-07-02 14:04:37.971757 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #384 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 14:04:37.971978 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #384 | Collecting samples for evaluation
2017-07-02 14:04:43.946221 EDT | -----------------------  ------------
2017-07-02 14:04:43.946410 EDT | Epoch                     384
2017-07-02 14:04:43.946522 EDT | Iteration                 384
2017-07-02 14:04:43.946671 EDT | AverageReturn             843.833
2017-07-02 14:04:43.946810 EDT | StdReturn                 275.693
2017-07-02 14:04:43.946940 EDT | MaxReturn                1000
2017-07-02 14:04:43.947042 EDT | MinReturn                 242
2017-07-02 14:04:43.947164 EDT | AverageEsReturn            38.2917
2017-07-02 14:04:43.947267 EDT | StdEsReturn                27.6352
2017-07-02 14:04:43.947368 EDT | MaxEsReturn               103
2017-07-02 14:04:43.947545 EDT | MinEsReturn                 4
2017-07-02 14:04:43.947655 EDT | AverageDiscountedReturn    99.0305
2017-07-02 14:04:43.947757 EDT | AverageQLoss                0.0132615
2017-07-02 14:04:43.947858 EDT | AveragePolicySurr          -1.94665
2017-07-02 14:04:43.947979 EDT | AverageQ                    1.84983
2017-07-02 14:04:43.948119 EDT | AverageAbsQ                 1.85488
2017-07-02 14:04:43.948290 EDT | AverageY                    1.84963
2017-07-02 14:04:43.948437 EDT | AverageAbsY                 1.84999
2017-07-02 14:04:43.948564 EDT | AverageAbsQYDiff            0.033592
2017-07-02 14:04:43.948666 EDT | AverageAction               0.177792
2017-07-02 14:04:43.948767 EDT | PolicyRegParamNorm         53.8376
2017-07-02 14:04:43.948867 EDT | QFunRegParamNorm           56.1199
2017-07-02 14:04:43.948998 EDT | -----------------------  ------------
2017-07-02 14:04:43.949163 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #385 | Training started
2017-07-02 14:04:53.471154 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #385 | Training finished
2017-07-02 14:04:53.471684 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #385 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 14:04:53.471913 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #385 | Collecting samples for evaluation
2017-07-02 14:04:59.182848 EDT | -----------------------  ------------
2017-07-02 14:04:59.183030 EDT | Epoch                     385
2017-07-02 14:04:59.183145 EDT | Iteration                 385
2017-07-02 14:04:59.183340 EDT | AverageReturn            1000
2017-07-02 14:04:59.183470 EDT | StdReturn                   0
2017-07-02 14:04:59.183575 EDT | MaxReturn                1000
2017-07-02 14:04:59.183778 EDT | MinReturn                1000
2017-07-02 14:04:59.183959 EDT | AverageEsReturn            35.1
2017-07-02 14:04:59.184137 EDT | StdEsReturn                29.521
2017-07-02 14:04:59.184318 EDT | MaxEsReturn               111
2017-07-02 14:04:59.184461 EDT | MinEsReturn                 3
2017-07-02 14:04:59.184682 EDT | AverageDiscountedReturn    99.9957
2017-07-02 14:04:59.184912 EDT | AverageQLoss                0.0131235
2017-07-02 14:04:59.185108 EDT | AveragePolicySurr          -1.93879
2017-07-02 14:04:59.185219 EDT | AverageQ                    1.83108
2017-07-02 14:04:59.185397 EDT | AverageAbsQ                 1.83671
2017-07-02 14:04:59.185667 EDT | AverageY                    1.83124
2017-07-02 14:04:59.185898 EDT | AverageAbsY                 1.83171
2017-07-02 14:04:59.186127 EDT | AverageAbsQYDiff            0.0325923
2017-07-02 14:04:59.186302 EDT | AverageAction               0.787771
2017-07-02 14:04:59.186479 EDT | PolicyRegParamNorm         53.8849
2017-07-02 14:04:59.186656 EDT | QFunRegParamNorm           56.1482
2017-07-02 14:04:59.186853 EDT | -----------------------  ------------
2017-07-02 14:04:59.187070 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #386 | Training started
2017-07-02 14:05:08.676972 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #386 | Training finished
2017-07-02 14:05:08.677481 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #386 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 14:05:08.677707 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #386 | Collecting samples for evaluation
2017-07-02 14:05:14.424757 EDT | -----------------------  ------------
2017-07-02 14:05:14.425049 EDT | Epoch                     386
2017-07-02 14:05:14.425270 EDT | Iteration                 386
2017-07-02 14:05:14.425538 EDT | AverageReturn            1000
2017-07-02 14:05:14.425753 EDT | StdReturn                   0
2017-07-02 14:05:14.425987 EDT | MaxReturn                1000
2017-07-02 14:05:14.426220 EDT | MinReturn                1000
2017-07-02 14:05:14.426352 EDT | AverageEsReturn            24.4595
2017-07-02 14:05:14.426585 EDT | StdEsReturn                19.9006
2017-07-02 14:05:14.426806 EDT | MaxEsReturn                90
2017-07-02 14:05:14.426919 EDT | MinEsReturn                 3
2017-07-02 14:05:14.427081 EDT | AverageDiscountedReturn    99.9957
2017-07-02 14:05:14.427313 EDT | AverageQLoss                0.013624
2017-07-02 14:05:14.427490 EDT | AveragePolicySurr          -1.92208
2017-07-02 14:05:14.427604 EDT | AverageQ                    1.81905
2017-07-02 14:05:14.427744 EDT | AverageAbsQ                 1.82364
2017-07-02 14:05:14.427977 EDT | AverageY                    1.81885
2017-07-02 14:05:14.428185 EDT | AverageAbsY                 1.81913
2017-07-02 14:05:14.428299 EDT | AverageAbsQYDiff            0.0329309
2017-07-02 14:05:14.428456 EDT | AverageAction               0.691853
2017-07-02 14:05:14.428688 EDT | PolicyRegParamNorm         53.9242
2017-07-02 14:05:14.428880 EDT | QFunRegParamNorm           56.1505
2017-07-02 14:05:14.428993 EDT | -----------------------  ------------
2017-07-02 14:05:14.429168 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #387 | Training started
2017-07-02 14:05:24.484856 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #387 | Training finished
2017-07-02 14:05:24.485464 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #387 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 14:05:24.485745 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #387 | Collecting samples for evaluation
2017-07-02 14:05:30.140329 EDT | -----------------------  ------------
2017-07-02 14:05:30.140522 EDT | Epoch                     387
2017-07-02 14:05:30.140649 EDT | Iteration                 387
2017-07-02 14:05:30.140770 EDT | AverageReturn            1000
2017-07-02 14:05:30.140958 EDT | StdReturn                   0
2017-07-02 14:05:30.141079 EDT | MaxReturn                1000
2017-07-02 14:05:30.141311 EDT | MinReturn                1000
2017-07-02 14:05:30.141561 EDT | AverageEsReturn            31.2222
2017-07-02 14:05:30.141749 EDT | StdEsReturn                28.2981
2017-07-02 14:05:30.141957 EDT | MaxEsReturn               127
2017-07-02 14:05:30.142181 EDT | MinEsReturn                 3
2017-07-02 14:05:30.142415 EDT | AverageDiscountedReturn    99.9957
2017-07-02 14:05:30.142630 EDT | AverageQLoss                0.0122288
2017-07-02 14:05:30.142768 EDT | AveragePolicySurr          -1.91741
2017-07-02 14:05:30.142880 EDT | AverageQ                    1.81595
2017-07-02 14:05:30.142986 EDT | AverageAbsQ                 1.82149
2017-07-02 14:05:30.143086 EDT | AverageY                    1.81611
2017-07-02 14:05:30.143253 EDT | AverageAbsY                 1.81652
2017-07-02 14:05:30.143409 EDT | AverageAbsQYDiff            0.0318004
2017-07-02 14:05:30.143554 EDT | AverageAction               0.598441
2017-07-02 14:05:30.143658 EDT | PolicyRegParamNorm         53.9593
2017-07-02 14:05:30.143759 EDT | QFunRegParamNorm           56.1503
2017-07-02 14:05:30.143884 EDT | -----------------------  ------------
2017-07-02 14:05:30.144176 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #388 | Training started
2017-07-02 14:05:39.773070 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #388 | Training finished
2017-07-02 14:05:39.773703 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #388 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 14:05:39.773964 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #388 | Collecting samples for evaluation
2017-07-02 14:05:45.402320 EDT | -----------------------  ------------
2017-07-02 14:05:45.402590 EDT | Epoch                     388
2017-07-02 14:05:45.402787 EDT | Iteration                 388
2017-07-02 14:05:45.402997 EDT | AverageReturn            1000
2017-07-02 14:05:45.403174 EDT | StdReturn                   0
2017-07-02 14:05:45.403364 EDT | MaxReturn                1000
2017-07-02 14:05:45.403480 EDT | MinReturn                1000
2017-07-02 14:05:45.403598 EDT | AverageEsReturn            22.1364
2017-07-02 14:05:45.403937 EDT | StdEsReturn                16.485
2017-07-02 14:05:45.404191 EDT | MaxEsReturn                66
2017-07-02 14:05:45.404406 EDT | MinEsReturn                 3
2017-07-02 14:05:45.404563 EDT | AverageDiscountedReturn    99.9957
2017-07-02 14:05:45.404710 EDT | AverageQLoss                0.0136774
2017-07-02 14:05:45.404824 EDT | AveragePolicySurr          -1.90926
2017-07-02 14:05:45.404957 EDT | AverageQ                    1.80334
2017-07-02 14:05:45.405062 EDT | AverageAbsQ                 1.80946
2017-07-02 14:05:45.405210 EDT | AverageY                    1.80325
2017-07-02 14:05:45.405320 EDT | AverageAbsY                 1.80364
2017-07-02 14:05:45.405422 EDT | AverageAbsQYDiff            0.0359112
2017-07-02 14:05:45.405586 EDT | AverageAction               0.333444
2017-07-02 14:05:45.405709 EDT | PolicyRegParamNorm         54.0377
2017-07-02 14:05:45.405812 EDT | QFunRegParamNorm           56.2137
2017-07-02 14:05:45.405951 EDT | -----------------------  ------------
2017-07-02 14:05:45.406250 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #389 | Training started
2017-07-02 14:05:55.072699 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #389 | Training finished
2017-07-02 14:05:55.073317 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #389 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 14:05:55.073485 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #389 | Collecting samples for evaluation
2017-07-02 14:06:00.762394 EDT | -----------------------  ------------
2017-07-02 14:06:00.762719 EDT | Epoch                     389
2017-07-02 14:06:00.762956 EDT | Iteration                 389
2017-07-02 14:06:00.763181 EDT | AverageReturn            1000
2017-07-02 14:06:00.763416 EDT | StdReturn                   0
2017-07-02 14:06:00.763621 EDT | MaxReturn                1000
2017-07-02 14:06:00.763847 EDT | MinReturn                1000
2017-07-02 14:06:00.764075 EDT | AverageEsReturn            31.125
2017-07-02 14:06:00.764310 EDT | StdEsReturn                19.9198
2017-07-02 14:06:00.764546 EDT | MaxEsReturn                88
2017-07-02 14:06:00.764759 EDT | MinEsReturn                 3
2017-07-02 14:06:00.764995 EDT | AverageDiscountedReturn    99.9957
2017-07-02 14:06:00.765206 EDT | AverageQLoss                0.0119991
2017-07-02 14:06:00.765432 EDT | AveragePolicySurr          -1.90108
2017-07-02 14:06:00.765721 EDT | AverageQ                    1.79269
2017-07-02 14:06:00.765928 EDT | AverageAbsQ                 1.79805
2017-07-02 14:06:00.766047 EDT | AverageY                    1.79275
2017-07-02 14:06:00.766171 EDT | AverageAbsY                 1.79308
2017-07-02 14:06:00.766273 EDT | AverageAbsQYDiff            0.032019
2017-07-02 14:06:00.766397 EDT | AverageAction               0.338849
2017-07-02 14:06:00.766498 EDT | PolicyRegParamNorm         54.1111
2017-07-02 14:06:00.766599 EDT | QFunRegParamNorm           56.2397
2017-07-02 14:06:00.766706 EDT | -----------------------  ------------
2017-07-02 14:06:00.766889 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #390 | Training started
2017-07-02 14:06:10.347394 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #390 | Training finished
2017-07-02 14:06:10.347953 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #390 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 14:06:10.348202 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #390 | Collecting samples for evaluation
2017-07-02 14:06:16.139977 EDT | -----------------------  ------------
2017-07-02 14:06:16.140180 EDT | Epoch                     390
2017-07-02 14:06:16.140407 EDT | Iteration                 390
2017-07-02 14:06:16.140637 EDT | AverageReturn            1000
2017-07-02 14:06:16.140850 EDT | StdReturn                   0
2017-07-02 14:06:16.141075 EDT | MaxReturn                1000
2017-07-02 14:06:16.141307 EDT | MinReturn                1000
2017-07-02 14:06:16.141543 EDT | AverageEsReturn            28.9118
2017-07-02 14:06:16.141776 EDT | StdEsReturn                31.0478
2017-07-02 14:06:16.141979 EDT | MaxEsReturn               140
2017-07-02 14:06:16.142106 EDT | MinEsReturn                 3
2017-07-02 14:06:16.142210 EDT | AverageDiscountedReturn    99.9957
2017-07-02 14:06:16.142357 EDT | AverageQLoss                0.0123603
2017-07-02 14:06:16.142494 EDT | AveragePolicySurr          -1.89114
2017-07-02 14:06:16.142597 EDT | AverageQ                    1.7858
2017-07-02 14:06:16.142697 EDT | AverageAbsQ                 1.79103
2017-07-02 14:06:16.142798 EDT | AverageY                    1.78581
2017-07-02 14:06:16.142897 EDT | AverageAbsY                 1.78623
2017-07-02 14:06:16.143016 EDT | AverageAbsQYDiff            0.0323204
2017-07-02 14:06:16.143131 EDT | AverageAction               0.543078
2017-07-02 14:06:16.143255 EDT | PolicyRegParamNorm         54.1145
2017-07-02 14:06:16.143379 EDT | QFunRegParamNorm           56.2907
2017-07-02 14:06:16.143581 EDT | -----------------------  ------------
2017-07-02 14:06:16.143841 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #391 | Training started
2017-07-02 14:06:25.545077 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #391 | Training finished
2017-07-02 14:06:25.545857 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #391 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 14:06:25.546112 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #391 | Collecting samples for evaluation
2017-07-02 14:06:31.356791 EDT | -----------------------  ------------
2017-07-02 14:06:31.356990 EDT | Epoch                     391
2017-07-02 14:06:31.357124 EDT | Iteration                 391
2017-07-02 14:06:31.357231 EDT | AverageReturn            1000
2017-07-02 14:06:31.357336 EDT | StdReturn                   0
2017-07-02 14:06:31.357451 EDT | MaxReturn                1000
2017-07-02 14:06:31.357619 EDT | MinReturn                1000
2017-07-02 14:06:31.357722 EDT | AverageEsReturn            24.6667
2017-07-02 14:06:31.357822 EDT | StdEsReturn                25.463
2017-07-02 14:06:31.357961 EDT | MaxEsReturn               153
2017-07-02 14:06:31.358106 EDT | MinEsReturn                 3
2017-07-02 14:06:31.358214 EDT | AverageDiscountedReturn    99.9957
2017-07-02 14:06:31.358319 EDT | AverageQLoss                0.0125709
2017-07-02 14:06:31.358453 EDT | AveragePolicySurr          -1.88157
2017-07-02 14:06:31.358565 EDT | AverageQ                    1.77652
2017-07-02 14:06:31.358718 EDT | AverageAbsQ                 1.7817
2017-07-02 14:06:31.358886 EDT | AverageY                    1.77644
2017-07-02 14:06:31.359012 EDT | AverageAbsY                 1.777
2017-07-02 14:06:31.359121 EDT | AverageAbsQYDiff            0.0320607
2017-07-02 14:06:31.359252 EDT | AverageAction               0.3608
2017-07-02 14:06:31.359401 EDT | PolicyRegParamNorm         54.1361
2017-07-02 14:06:31.359529 EDT | QFunRegParamNorm           56.3404
2017-07-02 14:06:31.359637 EDT | -----------------------  ------------
2017-07-02 14:06:31.359809 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #392 | Training started
2017-07-02 14:06:40.607452 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #392 | Training finished
2017-07-02 14:06:40.608034 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #392 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 14:06:40.608389 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #392 | Collecting samples for evaluation
2017-07-02 14:06:46.412425 EDT | -----------------------  ------------
2017-07-02 14:06:46.412734 EDT | Epoch                     392
2017-07-02 14:06:46.412955 EDT | Iteration                 392
2017-07-02 14:06:46.413185 EDT | AverageReturn            1000
2017-07-02 14:06:46.413421 EDT | StdReturn                   0
2017-07-02 14:06:46.413672 EDT | MaxReturn                1000
2017-07-02 14:06:46.413897 EDT | MinReturn                1000
2017-07-02 14:06:46.414087 EDT | AverageEsReturn            19.0755
2017-07-02 14:06:46.414269 EDT | StdEsReturn                15.7945
2017-07-02 14:06:46.414496 EDT | MaxEsReturn                79
2017-07-02 14:06:46.414610 EDT | MinEsReturn                 3
2017-07-02 14:06:46.414715 EDT | AverageDiscountedReturn    99.9957
2017-07-02 14:06:46.414841 EDT | AverageQLoss                0.014127
2017-07-02 14:06:46.414978 EDT | AveragePolicySurr          -1.87152
2017-07-02 14:06:46.415209 EDT | AverageQ                    1.76793
2017-07-02 14:06:46.415438 EDT | AverageAbsQ                 1.77333
2017-07-02 14:06:46.415669 EDT | AverageY                    1.76811
2017-07-02 14:06:46.415887 EDT | AverageAbsY                 1.76868
2017-07-02 14:06:46.416116 EDT | AverageAbsQYDiff            0.0339289
2017-07-02 14:06:46.416335 EDT | AverageAction               0.283601
2017-07-02 14:06:46.416542 EDT | PolicyRegParamNorm         54.0734
2017-07-02 14:06:46.416772 EDT | QFunRegParamNorm           56.3446
2017-07-02 14:06:46.417009 EDT | -----------------------  ------------
2017-07-02 14:06:46.417340 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #393 | Training started
2017-07-02 14:06:55.834394 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #393 | Training finished
2017-07-02 14:06:55.834909 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #393 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 14:06:55.835186 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #393 | Collecting samples for evaluation
2017-07-02 14:07:01.684835 EDT | -----------------------  ------------
2017-07-02 14:07:01.685112 EDT | Epoch                     393
2017-07-02 14:07:01.685232 EDT | Iteration                 393
2017-07-02 14:07:01.685341 EDT | AverageReturn            1000
2017-07-02 14:07:01.685445 EDT | StdReturn                   0
2017-07-02 14:07:01.685608 EDT | MaxReturn                1000
2017-07-02 14:07:01.685723 EDT | MinReturn                1000
2017-07-02 14:07:01.685912 EDT | AverageEsReturn            21.5217
2017-07-02 14:07:01.686118 EDT | StdEsReturn                19.8842
2017-07-02 14:07:01.686270 EDT | MaxEsReturn                92
2017-07-02 14:07:01.686376 EDT | MinEsReturn                 3
2017-07-02 14:07:01.686501 EDT | AverageDiscountedReturn    99.9957
2017-07-02 14:07:01.686630 EDT | AverageQLoss                0.010044
2017-07-02 14:07:01.686744 EDT | AveragePolicySurr          -1.8606
2017-07-02 14:07:01.686856 EDT | AverageQ                    1.76109
2017-07-02 14:07:01.687037 EDT | AverageAbsQ                 1.76586
2017-07-02 14:07:01.687208 EDT | AverageY                    1.76101
2017-07-02 14:07:01.687313 EDT | AverageAbsY                 1.76178
2017-07-02 14:07:01.687431 EDT | AverageAbsQYDiff            0.0287668
2017-07-02 14:07:01.687537 EDT | AverageAction               0.299348
2017-07-02 14:07:01.687638 EDT | PolicyRegParamNorm         54.1528
2017-07-02 14:07:01.687740 EDT | QFunRegParamNorm           56.3641
2017-07-02 14:07:01.687839 EDT | -----------------------  ------------
2017-07-02 14:07:01.688009 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #394 | Training started
2017-07-02 14:07:11.063768 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #394 | Training finished
2017-07-02 14:07:11.064406 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #394 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 14:07:11.064618 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #394 | Collecting samples for evaluation
2017-07-02 14:07:16.773316 EDT | -----------------------  ------------
2017-07-02 14:07:16.773535 EDT | Epoch                     394
2017-07-02 14:07:16.773694 EDT | Iteration                 394
2017-07-02 14:07:16.773821 EDT | AverageReturn            1000
2017-07-02 14:07:16.773932 EDT | StdReturn                   0
2017-07-02 14:07:16.774041 EDT | MaxReturn                1000
2017-07-02 14:07:16.774149 EDT | MinReturn                1000
2017-07-02 14:07:16.774269 EDT | AverageEsReturn            39.16
2017-07-02 14:07:16.774472 EDT | StdEsReturn                35.7051
2017-07-02 14:07:16.774624 EDT | MaxEsReturn               134
2017-07-02 14:07:16.774729 EDT | MinEsReturn                 4
2017-07-02 14:07:16.774880 EDT | AverageDiscountedReturn    99.9957
2017-07-02 14:07:16.774988 EDT | AverageQLoss                0.0119739
2017-07-02 14:07:16.775096 EDT | AveragePolicySurr          -1.85176
2017-07-02 14:07:16.775208 EDT | AverageQ                    1.75167
2017-07-02 14:07:16.775340 EDT | AverageAbsQ                 1.75701
2017-07-02 14:07:16.775448 EDT | AverageY                    1.75167
2017-07-02 14:07:16.775560 EDT | AverageAbsY                 1.75218
2017-07-02 14:07:16.775672 EDT | AverageAbsQYDiff            0.0320762
2017-07-02 14:07:16.775777 EDT | AverageAction               0.642433
2017-07-02 14:07:16.775882 EDT | PolicyRegParamNorm         54.1617
2017-07-02 14:07:16.775986 EDT | QFunRegParamNorm           56.3637
2017-07-02 14:07:16.776090 EDT | -----------------------  ------------
2017-07-02 14:07:16.776265 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #395 | Training started
2017-07-02 14:07:26.255561 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #395 | Training finished
2017-07-02 14:07:26.256432 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #395 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 14:07:26.256654 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #395 | Collecting samples for evaluation
2017-07-02 14:07:31.952394 EDT | -----------------------  ------------
2017-07-02 14:07:31.952731 EDT | Epoch                     395
2017-07-02 14:07:31.952887 EDT | Iteration                 395
2017-07-02 14:07:31.953072 EDT | AverageReturn            1000
2017-07-02 14:07:31.953242 EDT | StdReturn                   0
2017-07-02 14:07:31.953354 EDT | MaxReturn                1000
2017-07-02 14:07:31.953542 EDT | MinReturn                1000
2017-07-02 14:07:31.953744 EDT | AverageEsReturn            53.7895
2017-07-02 14:07:31.953930 EDT | StdEsReturn                51.7378
2017-07-02 14:07:31.954089 EDT | MaxEsReturn               182
2017-07-02 14:07:31.954231 EDT | MinEsReturn                 5
2017-07-02 14:07:31.954362 EDT | AverageDiscountedReturn    99.9957
2017-07-02 14:07:31.954469 EDT | AverageQLoss                0.0109038
2017-07-02 14:07:31.954597 EDT | AveragePolicySurr          -1.84226
2017-07-02 14:07:31.954724 EDT | AverageQ                    1.73956
2017-07-02 14:07:31.954853 EDT | AverageAbsQ                 1.74495
2017-07-02 14:07:31.954980 EDT | AverageY                    1.73957
2017-07-02 14:07:31.955091 EDT | AverageAbsY                 1.73996
2017-07-02 14:07:31.955215 EDT | AverageAbsQYDiff            0.0305075
2017-07-02 14:07:31.955327 EDT | AverageAction               0.580047
2017-07-02 14:07:31.955450 EDT | PolicyRegParamNorm         54.2176
2017-07-02 14:07:31.955593 EDT | QFunRegParamNorm           56.4118
2017-07-02 14:07:31.955695 EDT | -----------------------  ------------
2017-07-02 14:07:31.955890 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #396 | Training started
2017-07-02 14:07:41.509583 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #396 | Training finished
2017-07-02 14:07:41.510092 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #396 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 14:07:41.510356 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #396 | Collecting samples for evaluation
2017-07-02 14:07:47.205026 EDT | -----------------------  ------------
2017-07-02 14:07:47.205348 EDT | Epoch                     396
2017-07-02 14:07:47.205605 EDT | Iteration                 396
2017-07-02 14:07:47.205834 EDT | AverageReturn            1000
2017-07-02 14:07:47.206055 EDT | StdReturn                   0
2017-07-02 14:07:47.206263 EDT | MaxReturn                1000
2017-07-02 14:07:47.206440 EDT | MinReturn                1000
2017-07-02 14:07:47.206662 EDT | AverageEsReturn            30.75
2017-07-02 14:07:47.206877 EDT | StdEsReturn                20.7786
2017-07-02 14:07:47.207110 EDT | MaxEsReturn                76
2017-07-02 14:07:47.207330 EDT | MinEsReturn                 4
2017-07-02 14:07:47.207550 EDT | AverageDiscountedReturn    99.9957
2017-07-02 14:07:47.207766 EDT | AverageQLoss                0.0101406
2017-07-02 14:07:47.207956 EDT | AveragePolicySurr          -1.83272
2017-07-02 14:07:47.208063 EDT | AverageQ                    1.73187
2017-07-02 14:07:47.208183 EDT | AverageAbsQ                 1.73662
2017-07-02 14:07:47.208287 EDT | AverageY                    1.73184
2017-07-02 14:07:47.208388 EDT | AverageAbsY                 1.73228
2017-07-02 14:07:47.208491 EDT | AverageAbsQYDiff            0.0303298
2017-07-02 14:07:47.208635 EDT | AverageAction               0.685912
2017-07-02 14:07:47.208738 EDT | PolicyRegParamNorm         54.2139
2017-07-02 14:07:47.208849 EDT | QFunRegParamNorm           56.4246
2017-07-02 14:07:47.208953 EDT | -----------------------  ------------
2017-07-02 14:07:47.209193 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #397 | Training started
2017-07-02 14:07:56.733144 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #397 | Training finished
2017-07-02 14:07:56.733686 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #397 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 14:07:56.733822 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #397 | Collecting samples for evaluation
2017-07-02 14:08:02.490143 EDT | -----------------------  ------------
2017-07-02 14:08:02.490355 EDT | Epoch                     397
2017-07-02 14:08:02.490480 EDT | Iteration                 397
2017-07-02 14:08:02.490594 EDT | AverageReturn            1000
2017-07-02 14:08:02.490698 EDT | StdReturn                   0
2017-07-02 14:08:02.490800 EDT | MaxReturn                1000
2017-07-02 14:08:02.490966 EDT | MinReturn                1000
2017-07-02 14:08:02.491072 EDT | AverageEsReturn            44.087
2017-07-02 14:08:02.491394 EDT | StdEsReturn                34.9533
2017-07-02 14:08:02.491617 EDT | MaxEsReturn               133
2017-07-02 14:08:02.491834 EDT | MinEsReturn                 5
2017-07-02 14:08:02.492141 EDT | AverageDiscountedReturn    99.9957
2017-07-02 14:08:02.492403 EDT | AverageQLoss                0.0110522
2017-07-02 14:08:02.492546 EDT | AveragePolicySurr          -1.82116
2017-07-02 14:08:02.492690 EDT | AverageQ                    1.72017
2017-07-02 14:08:02.492844 EDT | AverageAbsQ                 1.72556
2017-07-02 14:08:02.493025 EDT | AverageY                    1.72011
2017-07-02 14:08:02.493256 EDT | AverageAbsY                 1.72064
2017-07-02 14:08:02.493475 EDT | AverageAbsQYDiff            0.0307225
2017-07-02 14:08:02.493683 EDT | AverageAction               0.618481
2017-07-02 14:08:02.493802 EDT | PolicyRegParamNorm         54.2804
2017-07-02 14:08:02.493906 EDT | QFunRegParamNorm           56.4325
2017-07-02 14:08:02.494027 EDT | -----------------------  ------------
2017-07-02 14:08:02.494262 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #398 | Training started
2017-07-02 14:08:12.005179 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #398 | Training finished
2017-07-02 14:08:12.005729 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #398 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 14:08:12.006072 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #398 | Collecting samples for evaluation
2017-07-02 14:08:17.925675 EDT | -----------------------  ------------
2017-07-02 14:08:17.925941 EDT | Epoch                     398
2017-07-02 14:08:17.926120 EDT | Iteration                 398
2017-07-02 14:08:17.926259 EDT | AverageReturn             637.25
2017-07-02 14:08:17.926373 EDT | StdReturn                 311.522
2017-07-02 14:08:17.926488 EDT | MaxReturn                1000
2017-07-02 14:08:17.926591 EDT | MinReturn                 176
2017-07-02 14:08:17.926789 EDT | AverageEsReturn            35.3929
2017-07-02 14:08:17.926972 EDT | StdEsReturn                19.36
2017-07-02 14:08:17.927159 EDT | MaxEsReturn                78
2017-07-02 14:08:17.927270 EDT | MinEsReturn                 6
2017-07-02 14:08:17.927402 EDT | AverageDiscountedReturn    97.2938
2017-07-02 14:08:17.927539 EDT | AverageQLoss                0.0126183
2017-07-02 14:08:17.927642 EDT | AveragePolicySurr          -1.81284
2017-07-02 14:08:17.927756 EDT | AverageQ                    1.71603
2017-07-02 14:08:17.927883 EDT | AverageAbsQ                 1.72176
2017-07-02 14:08:17.927985 EDT | AverageY                    1.71597
2017-07-02 14:08:17.928085 EDT | AverageAbsY                 1.71637
2017-07-02 14:08:17.928185 EDT | AverageAbsQYDiff            0.0333505
2017-07-02 14:08:17.928345 EDT | AverageAction               0.745612
2017-07-02 14:08:17.928459 EDT | PolicyRegParamNorm         54.3315
2017-07-02 14:08:17.928564 EDT | QFunRegParamNorm           56.4916
2017-07-02 14:08:17.928664 EDT | -----------------------  ------------
2017-07-02 14:08:17.928847 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #399 | Training started
2017-07-02 14:08:27.492096 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #399 | Training finished
2017-07-02 14:08:27.492718 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #399 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 14:08:27.492952 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #399 | Collecting samples for evaluation
2017-07-02 14:08:33.290539 EDT | -----------------------  -----------
2017-07-02 14:08:33.290848 EDT | Epoch                    399
2017-07-02 14:08:33.291997 EDT | Iteration                399
2017-07-02 14:08:33.292238 EDT | AverageReturn             82.9421
2017-07-02 14:08:33.292357 EDT | StdReturn                 15.8653
2017-07-02 14:08:33.292464 EDT | MaxReturn                106
2017-07-02 14:08:33.292645 EDT | MinReturn                 56
2017-07-02 14:08:33.292863 EDT | AverageEsReturn           25.2632
2017-07-02 14:08:33.293083 EDT | StdEsReturn               17.7181
2017-07-02 14:08:33.293306 EDT | MaxEsReturn               83
2017-07-02 14:08:33.293484 EDT | MinEsReturn                5
2017-07-02 14:08:33.293681 EDT | AverageDiscountedReturn   55.9891
2017-07-02 14:08:33.293881 EDT | AverageQLoss               0.0120359
2017-07-02 14:08:33.294068 EDT | AveragePolicySurr         -1.80698
2017-07-02 14:08:33.294288 EDT | AverageQ                   1.71115
2017-07-02 14:08:33.294447 EDT | AverageAbsQ                1.71567
2017-07-02 14:08:33.294555 EDT | AverageY                   1.71119
2017-07-02 14:08:33.294658 EDT | AverageAbsY                1.71158
2017-07-02 14:08:33.294761 EDT | AverageAbsQYDiff           0.0326786
2017-07-02 14:08:33.294864 EDT | AverageAction              0.548884
2017-07-02 14:08:33.294965 EDT | PolicyRegParamNorm        54.2915
2017-07-02 14:08:33.295065 EDT | QFunRegParamNorm          56.4733
2017-07-02 14:08:33.295169 EDT | -----------------------  -----------
2017-07-02 14:08:33.295482 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #400 | Training started
2017-07-02 14:08:42.937769 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #400 | Training finished
2017-07-02 14:08:42.957556 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #400 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 14:08:42.957787 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #400 | Collecting samples for evaluation
2017-07-02 14:08:48.774467 EDT | -----------------------  ------------
2017-07-02 14:08:48.774731 EDT | Epoch                     400
2017-07-02 14:08:48.774929 EDT | Iteration                 400
2017-07-02 14:08:48.775098 EDT | AverageReturn             928.636
2017-07-02 14:08:48.775262 EDT | StdReturn                 225.672
2017-07-02 14:08:48.775425 EDT | MaxReturn                1000
2017-07-02 14:08:48.775587 EDT | MinReturn                 215
2017-07-02 14:08:48.775759 EDT | AverageEsReturn            28.3784
2017-07-02 14:08:48.775861 EDT | StdEsReturn                18.014
2017-07-02 14:08:48.775962 EDT | MaxEsReturn                69
2017-07-02 14:08:48.776061 EDT | MinEsReturn                 3
2017-07-02 14:08:48.776161 EDT | AverageDiscountedReturn    98.9485
2017-07-02 14:08:48.776261 EDT | AverageQLoss                0.0119552
2017-07-02 14:08:48.776391 EDT | AveragePolicySurr          -1.80073
2017-07-02 14:08:48.776493 EDT | AverageQ                    1.70438
2017-07-02 14:08:48.776593 EDT | AverageAbsQ                 1.71011
2017-07-02 14:08:48.776693 EDT | AverageY                    1.70441
2017-07-02 14:08:48.776792 EDT | AverageAbsY                 1.70479
2017-07-02 14:08:48.776890 EDT | AverageAbsQYDiff            0.0332425
2017-07-02 14:08:48.777015 EDT | AverageAction               0.737469
2017-07-02 14:08:48.777115 EDT | PolicyRegParamNorm         54.2709
2017-07-02 14:08:48.777212 EDT | QFunRegParamNorm           56.5015
2017-07-02 14:08:48.777311 EDT | -----------------------  ------------
2017-07-02 14:08:48.777474 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #401 | Training started
2017-07-02 14:08:58.396558 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #401 | Training finished
2017-07-02 14:08:58.397128 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #401 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 14:08:58.397273 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #401 | Collecting samples for evaluation
2017-07-02 14:09:04.160763 EDT | -----------------------  ------------
2017-07-02 14:09:04.160991 EDT | Epoch                    401
2017-07-02 14:09:04.161161 EDT | Iteration                401
2017-07-02 14:09:04.161291 EDT | AverageReturn            365.107
2017-07-02 14:09:04.161413 EDT | StdReturn                 36.9134
2017-07-02 14:09:04.161559 EDT | MaxReturn                439
2017-07-02 14:09:04.161788 EDT | MinReturn                279
2017-07-02 14:09:04.161964 EDT | AverageEsReturn           42.2174
2017-07-02 14:09:04.162105 EDT | StdEsReturn               37.5916
2017-07-02 14:09:04.162336 EDT | MaxEsReturn              150
2017-07-02 14:09:04.162562 EDT | MinEsReturn                5
2017-07-02 14:09:04.162691 EDT | AverageDiscountedReturn   97.2641
2017-07-02 14:09:04.162797 EDT | AverageQLoss               0.00927914
2017-07-02 14:09:04.162898 EDT | AveragePolicySurr         -1.79395
2017-07-02 14:09:04.162999 EDT | AverageQ                   1.69991
2017-07-02 14:09:04.163137 EDT | AverageAbsQ                1.70409
2017-07-02 14:09:04.163318 EDT | AverageY                   1.69961
2017-07-02 14:09:04.163535 EDT | AverageAbsY                1.6999
2017-07-02 14:09:04.163661 EDT | AverageAbsQYDiff           0.0287116
2017-07-02 14:09:04.163848 EDT | AverageAction              0.753789
2017-07-02 14:09:04.164070 EDT | PolicyRegParamNorm        54.2842
2017-07-02 14:09:04.164292 EDT | QFunRegParamNorm          56.5362
2017-07-02 14:09:04.164528 EDT | -----------------------  ------------
2017-07-02 14:09:04.164855 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #402 | Training started
2017-07-02 14:09:13.764494 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #402 | Training finished
2017-07-02 14:09:13.765064 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #402 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 14:09:13.765230 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #402 | Collecting samples for evaluation
2017-07-02 14:09:19.514182 EDT | -----------------------  -------------
2017-07-02 14:09:19.514377 EDT | Epoch                     402
2017-07-02 14:09:19.514510 EDT | Iteration                 402
2017-07-02 14:09:19.514624 EDT | AverageReturn            1000
2017-07-02 14:09:19.514733 EDT | StdReturn                   0
2017-07-02 14:09:19.514844 EDT | MaxReturn                1000
2017-07-02 14:09:19.515001 EDT | MinReturn                1000
2017-07-02 14:09:19.515133 EDT | AverageEsReturn            39.4231
2017-07-02 14:09:19.515243 EDT | StdEsReturn                28.3809
2017-07-02 14:09:19.515354 EDT | MaxEsReturn               116
2017-07-02 14:09:19.515509 EDT | MinEsReturn                 4
2017-07-02 14:09:19.515705 EDT | AverageDiscountedReturn    99.9957
2017-07-02 14:09:19.515882 EDT | AverageQLoss                0.00973543
2017-07-02 14:09:19.516002 EDT | AveragePolicySurr          -1.78238
2017-07-02 14:09:19.516117 EDT | AverageQ                    1.68876
2017-07-02 14:09:19.516227 EDT | AverageAbsQ                 1.69322
2017-07-02 14:09:19.516341 EDT | AverageY                    1.68877
2017-07-02 14:09:19.516452 EDT | AverageAbsY                 1.68901
2017-07-02 14:09:19.516558 EDT | AverageAbsQYDiff            0.0295727
2017-07-02 14:09:19.516745 EDT | AverageAction               0.069536
2017-07-02 14:09:19.516926 EDT | PolicyRegParamNorm         54.2187
2017-07-02 14:09:19.517074 EDT | QFunRegParamNorm           56.4896
2017-07-02 14:09:19.517265 EDT | -----------------------  -------------
2017-07-02 14:09:19.517608 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #403 | Training started
2017-07-02 14:09:28.998438 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #403 | Training finished
2017-07-02 14:09:28.999048 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #403 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 14:09:28.999295 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #403 | Collecting samples for evaluation
2017-07-02 14:09:34.793278 EDT | -----------------------  ------------
2017-07-02 14:09:34.793565 EDT | Epoch                     403
2017-07-02 14:09:34.793683 EDT | Iteration                 403
2017-07-02 14:09:34.793789 EDT | AverageReturn            1000
2017-07-02 14:09:34.793923 EDT | StdReturn                   0
2017-07-02 14:09:34.794029 EDT | MaxReturn                1000
2017-07-02 14:09:34.794132 EDT | MinReturn                1000
2017-07-02 14:09:34.794233 EDT | AverageEsReturn            47.5238
2017-07-02 14:09:34.794362 EDT | StdEsReturn                31.6403
2017-07-02 14:09:34.794517 EDT | MaxEsReturn               113
2017-07-02 14:09:34.794628 EDT | MinEsReturn                 8
2017-07-02 14:09:34.794799 EDT | AverageDiscountedReturn    99.9957
2017-07-02 14:09:34.794905 EDT | AverageQLoss                0.0109437
2017-07-02 14:09:34.795007 EDT | AveragePolicySurr          -1.77908
2017-07-02 14:09:34.795108 EDT | AverageQ                    1.68258
2017-07-02 14:09:34.795209 EDT | AverageAbsQ                 1.68784
2017-07-02 14:09:34.795384 EDT | AverageY                    1.68255
2017-07-02 14:09:34.795602 EDT | AverageAbsY                 1.68272
2017-07-02 14:09:34.795834 EDT | AverageAbsQYDiff            0.0319274
2017-07-02 14:09:34.796053 EDT | AverageAction               0.04563
2017-07-02 14:09:34.796272 EDT | PolicyRegParamNorm         54.2109
2017-07-02 14:09:34.796485 EDT | QFunRegParamNorm           56.491
2017-07-02 14:09:34.796686 EDT | -----------------------  ------------
2017-07-02 14:09:34.797000 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #404 | Training started
2017-07-02 14:09:44.361114 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #404 | Training finished
2017-07-02 14:09:44.361691 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #404 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 14:09:44.361885 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #404 | Collecting samples for evaluation
2017-07-02 14:09:50.084383 EDT | -----------------------  ------------
2017-07-02 14:09:50.084605 EDT | Epoch                     404
2017-07-02 14:09:50.084786 EDT | Iteration                 404
2017-07-02 14:09:50.084911 EDT | AverageReturn            1000
2017-07-02 14:09:50.085083 EDT | StdReturn                   0
2017-07-02 14:09:50.085267 EDT | MaxReturn                1000
2017-07-02 14:09:50.085455 EDT | MinReturn                1000
2017-07-02 14:09:50.085739 EDT | AverageEsReturn            47.1429
2017-07-02 14:09:50.085963 EDT | StdEsReturn                34.795
2017-07-02 14:09:50.086177 EDT | MaxEsReturn               126
2017-07-02 14:09:50.086406 EDT | MinEsReturn                12
2017-07-02 14:09:50.086592 EDT | AverageDiscountedReturn    99.9957
2017-07-02 14:09:50.086798 EDT | AverageQLoss                0.0105746
2017-07-02 14:09:50.086970 EDT | AveragePolicySurr          -1.77236
2017-07-02 14:09:50.087236 EDT | AverageQ                    1.6725
2017-07-02 14:09:50.087354 EDT | AverageAbsQ                 1.67724
2017-07-02 14:09:50.087467 EDT | AverageY                    1.67256
2017-07-02 14:09:50.087692 EDT | AverageAbsY                 1.67266
2017-07-02 14:09:50.087918 EDT | AverageAbsQYDiff            0.0300247
2017-07-02 14:09:50.088148 EDT | AverageAction               0.067109
2017-07-02 14:09:50.088363 EDT | PolicyRegParamNorm         54.2368
2017-07-02 14:09:50.088574 EDT | QFunRegParamNorm           56.5102
2017-07-02 14:09:50.088808 EDT | -----------------------  ------------
2017-07-02 14:09:50.089134 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #405 | Training started
2017-07-02 14:09:59.618668 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #405 | Training finished
2017-07-02 14:09:59.619249 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #405 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 14:09:59.619503 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #405 | Collecting samples for evaluation
2017-07-02 14:10:05.501994 EDT | -----------------------  -----------
2017-07-02 14:10:05.502222 EDT | Epoch                    405
2017-07-02 14:10:05.502379 EDT | Iteration                405
2017-07-02 14:10:05.502486 EDT | AverageReturn            118.459
2017-07-02 14:10:05.502657 EDT | StdReturn                 21.0811
2017-07-02 14:10:05.502761 EDT | MaxReturn                170
2017-07-02 14:10:05.502863 EDT | MinReturn                 69
2017-07-02 14:10:05.502963 EDT | AverageEsReturn           41.8696
2017-07-02 14:10:05.503063 EDT | StdEsReturn               33.9889
2017-07-02 14:10:05.503174 EDT | MaxEsReturn              117
2017-07-02 14:10:05.503382 EDT | MinEsReturn                3
2017-07-02 14:10:05.503508 EDT | AverageDiscountedReturn   68.8977
2017-07-02 14:10:05.503704 EDT | AverageQLoss               0.0103262
2017-07-02 14:10:05.503899 EDT | AveragePolicySurr         -1.76211
2017-07-02 14:10:05.504098 EDT | AverageQ                   1.66637
2017-07-02 14:10:05.504292 EDT | AverageAbsQ                1.67136
2017-07-02 14:10:05.504477 EDT | AverageY                   1.66628
2017-07-02 14:10:05.504628 EDT | AverageAbsY                1.6666
2017-07-02 14:10:05.504733 EDT | AverageAbsQYDiff           0.0302703
2017-07-02 14:10:05.504835 EDT | AverageAction              0.456097
2017-07-02 14:10:05.504966 EDT | PolicyRegParamNorm        54.2795
2017-07-02 14:10:05.505068 EDT | QFunRegParamNorm          56.5281
2017-07-02 14:10:05.505170 EDT | -----------------------  -----------
2017-07-02 14:10:05.505402 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #406 | Training started
2017-07-02 14:10:15.174984 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #406 | Training finished
2017-07-02 14:10:15.357954 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #406 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 14:10:15.358285 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #406 | Collecting samples for evaluation
2017-07-02 14:10:21.324195 EDT | -----------------------  ------------
2017-07-02 14:10:21.324520 EDT | Epoch                     406
2017-07-02 14:10:21.324682 EDT | Iteration                 406
2017-07-02 14:10:21.324790 EDT | AverageReturn            1000
2017-07-02 14:10:21.324953 EDT | StdReturn                   0
2017-07-02 14:10:21.325179 EDT | MaxReturn                1000
2017-07-02 14:10:21.325392 EDT | MinReturn                1000
2017-07-02 14:10:21.325651 EDT | AverageEsReturn            35.3
2017-07-02 14:10:21.325844 EDT | StdEsReturn                34.4414
2017-07-02 14:10:21.326035 EDT | MaxEsReturn               156
2017-07-02 14:10:21.326261 EDT | MinEsReturn                 3
2017-07-02 14:10:21.326475 EDT | AverageDiscountedReturn    99.9957
2017-07-02 14:10:21.326708 EDT | AverageQLoss                0.0116229
2017-07-02 14:10:21.326926 EDT | AveragePolicySurr          -1.75602
2017-07-02 14:10:21.327155 EDT | AverageQ                    1.66294
2017-07-02 14:10:21.327370 EDT | AverageAbsQ                 1.66884
2017-07-02 14:10:21.327604 EDT | AverageY                    1.66287
2017-07-02 14:10:21.327808 EDT | AverageAbsY                 1.66314
2017-07-02 14:10:21.327993 EDT | AverageAbsQYDiff            0.0324417
2017-07-02 14:10:21.328208 EDT | AverageAction               0.146138
2017-07-02 14:10:21.328436 EDT | PolicyRegParamNorm         54.3598
2017-07-02 14:10:21.328650 EDT | QFunRegParamNorm           56.5349
2017-07-02 14:10:21.328771 EDT | -----------------------  ------------
2017-07-02 14:10:21.329097 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #407 | Training started
2017-07-02 14:10:31.250410 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #407 | Training finished
2017-07-02 14:10:31.251051 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #407 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 14:10:31.251383 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #407 | Collecting samples for evaluation
2017-07-02 14:10:36.844936 EDT | -----------------------  -------------
2017-07-02 14:10:36.845167 EDT | Epoch                     407
2017-07-02 14:10:36.845279 EDT | Iteration                 407
2017-07-02 14:10:36.845384 EDT | AverageReturn            1000
2017-07-02 14:10:36.845576 EDT | StdReturn                   0
2017-07-02 14:10:36.845681 EDT | MaxReturn                1000
2017-07-02 14:10:36.845816 EDT | MinReturn                1000
2017-07-02 14:10:36.845923 EDT | AverageEsReturn            29.6061
2017-07-02 14:10:36.846049 EDT | StdEsReturn                24.3297
2017-07-02 14:10:36.846193 EDT | MaxEsReturn               105
2017-07-02 14:10:36.846377 EDT | MinEsReturn                 5
2017-07-02 14:10:36.846577 EDT | AverageDiscountedReturn    99.9957
2017-07-02 14:10:36.846719 EDT | AverageQLoss                0.00995265
2017-07-02 14:10:36.846871 EDT | AveragePolicySurr          -1.75129
2017-07-02 14:10:36.847056 EDT | AverageQ                    1.65304
2017-07-02 14:10:36.847237 EDT | AverageAbsQ                 1.6568
2017-07-02 14:10:36.847346 EDT | AverageY                    1.65308
2017-07-02 14:10:36.847453 EDT | AverageAbsY                 1.65332
2017-07-02 14:10:36.847584 EDT | AverageAbsQYDiff            0.0292955
2017-07-02 14:10:36.847716 EDT | AverageAction               0.204006
2017-07-02 14:10:36.847848 EDT | PolicyRegParamNorm         54.3806
2017-07-02 14:10:36.848090 EDT | QFunRegParamNorm           56.5521
2017-07-02 14:10:36.848307 EDT | -----------------------  -------------
2017-07-02 14:10:36.848641 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #408 | Training started
2017-07-02 14:10:46.523006 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #408 | Training finished
2017-07-02 14:10:46.523725 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #408 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 14:10:46.523874 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #408 | Collecting samples for evaluation
2017-07-02 14:10:52.203342 EDT | -----------------------  -------------
2017-07-02 14:10:52.203538 EDT | Epoch                     408
2017-07-02 14:10:52.203677 EDT | Iteration                 408
2017-07-02 14:10:52.203883 EDT | AverageReturn            1000
2017-07-02 14:10:52.204007 EDT | StdReturn                   0
2017-07-02 14:10:52.204110 EDT | MaxReturn                1000
2017-07-02 14:10:52.204224 EDT | MinReturn                1000
2017-07-02 14:10:52.204343 EDT | AverageEsReturn            25.225
2017-07-02 14:10:52.204447 EDT | StdEsReturn                19.9154
2017-07-02 14:10:52.204552 EDT | MaxEsReturn                68
2017-07-02 14:10:52.204675 EDT | MinEsReturn                 3
2017-07-02 14:10:52.204778 EDT | AverageDiscountedReturn    99.9957
2017-07-02 14:10:52.204921 EDT | AverageQLoss                0.00987648
2017-07-02 14:10:52.205042 EDT | AveragePolicySurr          -1.74968
2017-07-02 14:10:52.205143 EDT | AverageQ                    1.65299
2017-07-02 14:10:52.205242 EDT | AverageAbsQ                 1.65798
2017-07-02 14:10:52.205347 EDT | AverageY                    1.65305
2017-07-02 14:10:52.205601 EDT | AverageAbsY                 1.65324
2017-07-02 14:10:52.205743 EDT | AverageAbsQYDiff            0.0302853
2017-07-02 14:10:52.205951 EDT | AverageAction               0.121288
2017-07-02 14:10:52.206091 EDT | PolicyRegParamNorm         54.404
2017-07-02 14:10:52.206272 EDT | QFunRegParamNorm           56.5581
2017-07-02 14:10:52.206382 EDT | -----------------------  -------------
2017-07-02 14:10:52.206556 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #409 | Training started
2017-07-02 14:11:01.803448 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #409 | Training finished
2017-07-02 14:11:01.803949 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #409 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 14:11:01.804100 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #409 | Collecting samples for evaluation
2017-07-02 14:11:07.551694 EDT | -----------------------  ------------
2017-07-02 14:11:07.551926 EDT | Epoch                     409
2017-07-02 14:11:07.552151 EDT | Iteration                 409
2017-07-02 14:11:07.552379 EDT | AverageReturn            1000
2017-07-02 14:11:07.552597 EDT | StdReturn                   0
2017-07-02 14:11:07.552772 EDT | MaxReturn                1000
2017-07-02 14:11:07.552878 EDT | MinReturn                1000
2017-07-02 14:11:07.552980 EDT | AverageEsReturn            25.9444
2017-07-02 14:11:07.553081 EDT | StdEsReturn                22.8387
2017-07-02 14:11:07.553197 EDT | MaxEsReturn                95
2017-07-02 14:11:07.553421 EDT | MinEsReturn                 4
2017-07-02 14:11:07.553660 EDT | AverageDiscountedReturn    99.9957
2017-07-02 14:11:07.553877 EDT | AverageQLoss                0.0115078
2017-07-02 14:11:07.554098 EDT | AveragePolicySurr          -1.74887
2017-07-02 14:11:07.554309 EDT | AverageQ                    1.64867
2017-07-02 14:11:07.554517 EDT | AverageAbsQ                 1.65402
2017-07-02 14:11:07.554752 EDT | AverageY                    1.6485
2017-07-02 14:11:07.554973 EDT | AverageAbsY                 1.64873
2017-07-02 14:11:07.555193 EDT | AverageAbsQYDiff            0.033505
2017-07-02 14:11:07.555410 EDT | AverageAction               0.0287448
2017-07-02 14:11:07.555627 EDT | PolicyRegParamNorm         54.3264
2017-07-02 14:11:07.555851 EDT | QFunRegParamNorm           56.5594
2017-07-02 14:11:07.556060 EDT | -----------------------  ------------
2017-07-02 14:11:07.556299 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #410 | Training started
2017-07-02 14:11:17.120694 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #410 | Training finished
2017-07-02 14:11:17.121288 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #410 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 14:11:17.121542 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #410 | Collecting samples for evaluation
2017-07-02 14:11:23.083836 EDT | -----------------------  -----------
2017-07-02 14:11:23.084135 EDT | Epoch                    410
2017-07-02 14:11:23.084285 EDT | Iteration                410
2017-07-02 14:11:23.084486 EDT | AverageReturn             43.5826
2017-07-02 14:11:23.084685 EDT | StdReturn                  9.07934
2017-07-02 14:11:23.084877 EDT | MaxReturn                 59
2017-07-02 14:11:23.085067 EDT | MinReturn                 30
2017-07-02 14:11:23.085268 EDT | AverageEsReturn           24.9024
2017-07-02 14:11:23.085442 EDT | StdEsReturn               23.3226
2017-07-02 14:11:23.085614 EDT | MaxEsReturn              108
2017-07-02 14:11:23.085785 EDT | MinEsReturn                4
2017-07-02 14:11:23.086011 EDT | AverageDiscountedReturn   35.1976
2017-07-02 14:11:23.086234 EDT | AverageQLoss               0.0109043
2017-07-02 14:11:23.086420 EDT | AveragePolicySurr         -1.74824
2017-07-02 14:11:23.086540 EDT | AverageQ                   1.64959
2017-07-02 14:11:23.086710 EDT | AverageAbsQ                1.65428
2017-07-02 14:11:23.086817 EDT | AverageY                   1.64974
2017-07-02 14:11:23.086959 EDT | AverageAbsY                1.64993
2017-07-02 14:11:23.087088 EDT | AverageAbsQYDiff           0.0316675
2017-07-02 14:11:23.087191 EDT | AverageAction              0.730121
2017-07-02 14:11:23.087293 EDT | PolicyRegParamNorm        54.2454
2017-07-02 14:11:23.087429 EDT | QFunRegParamNorm          56.5919
2017-07-02 14:11:23.087567 EDT | -----------------------  -----------
2017-07-02 14:11:23.087836 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #411 | Training started
2017-07-02 14:11:32.527477 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #411 | Training finished
2017-07-02 14:11:32.528029 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #411 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 14:11:32.528242 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #411 | Collecting samples for evaluation
2017-07-02 14:11:38.252016 EDT | -----------------------  ------------
2017-07-02 14:11:38.252340 EDT | Epoch                     411
2017-07-02 14:11:38.252566 EDT | Iteration                 411
2017-07-02 14:11:38.252775 EDT | AverageReturn            1000
2017-07-02 14:11:38.252985 EDT | StdReturn                   0
2017-07-02 14:11:38.253212 EDT | MaxReturn                1000
2017-07-02 14:11:38.253429 EDT | MinReturn                1000
2017-07-02 14:11:38.253659 EDT | AverageEsReturn            24.1136
2017-07-02 14:11:38.253877 EDT | StdEsReturn                23.4028
2017-07-02 14:11:38.254094 EDT | MaxEsReturn               117
2017-07-02 14:11:38.254306 EDT | MinEsReturn                 4
2017-07-02 14:11:38.254486 EDT | AverageDiscountedReturn    99.9957
2017-07-02 14:11:38.254709 EDT | AverageQLoss                0.0112387
2017-07-02 14:11:38.254882 EDT | AveragePolicySurr          -1.74418
2017-07-02 14:11:38.254988 EDT | AverageQ                    1.64746
2017-07-02 14:11:38.255116 EDT | AverageAbsQ                 1.65182
2017-07-02 14:11:38.255218 EDT | AverageY                    1.64724
2017-07-02 14:11:38.255318 EDT | AverageAbsY                 1.64739
2017-07-02 14:11:38.255416 EDT | AverageAbsQYDiff            0.0321207
2017-07-02 14:11:38.255515 EDT | AverageAction               0.036
2017-07-02 14:11:38.255653 EDT | PolicyRegParamNorm         54.302
2017-07-02 14:11:38.255785 EDT | QFunRegParamNorm           56.5942
2017-07-02 14:11:38.255922 EDT | -----------------------  ------------
2017-07-02 14:11:38.256133 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #412 | Training started
2017-07-02 14:11:47.795027 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #412 | Training finished
2017-07-02 14:11:47.795649 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #412 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 14:11:47.795829 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #412 | Collecting samples for evaluation
2017-07-02 14:11:53.505711 EDT | -----------------------  -------------
2017-07-02 14:11:53.505919 EDT | Epoch                     412
2017-07-02 14:11:53.506099 EDT | Iteration                 412
2017-07-02 14:11:53.506215 EDT | AverageReturn            1000
2017-07-02 14:11:53.506349 EDT | StdReturn                   0
2017-07-02 14:11:53.506542 EDT | MaxReturn                1000
2017-07-02 14:11:53.506688 EDT | MinReturn                1000
2017-07-02 14:11:53.506842 EDT | AverageEsReturn            22.7727
2017-07-02 14:11:53.506946 EDT | StdEsReturn                16.0409
2017-07-02 14:11:53.507103 EDT | MaxEsReturn                61
2017-07-02 14:11:53.507205 EDT | MinEsReturn                 3
2017-07-02 14:11:53.507305 EDT | AverageDiscountedReturn    99.9957
2017-07-02 14:11:53.507405 EDT | AverageQLoss                0.00872807
2017-07-02 14:11:53.507564 EDT | AveragePolicySurr          -1.74434
2017-07-02 14:11:53.507708 EDT | AverageQ                    1.64749
2017-07-02 14:11:53.507811 EDT | AverageAbsQ                 1.6522
2017-07-02 14:11:53.507912 EDT | AverageY                    1.64766
2017-07-02 14:11:53.508082 EDT | AverageAbsY                 1.64824
2017-07-02 14:11:53.508238 EDT | AverageAbsQYDiff            0.0295237
2017-07-02 14:11:53.508423 EDT | AverageAction               0.0289947
2017-07-02 14:11:53.508596 EDT | PolicyRegParamNorm         54.3251
2017-07-02 14:11:53.508733 EDT | QFunRegParamNorm           56.6034
2017-07-02 14:11:53.508901 EDT | -----------------------  -------------
2017-07-02 14:11:53.509134 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #413 | Training started
2017-07-02 14:12:03.100663 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #413 | Training finished
2017-07-02 14:12:03.101222 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #413 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 14:12:03.101901 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #413 | Collecting samples for evaluation
2017-07-02 14:12:08.988076 EDT | -----------------------  ------------
2017-07-02 14:12:08.988294 EDT | Epoch                     413
2017-07-02 14:12:08.988436 EDT | Iteration                 413
2017-07-02 14:12:08.988642 EDT | AverageReturn              61.6626
2017-07-02 14:12:08.988841 EDT | StdReturn                  73.8584
2017-07-02 14:12:08.989039 EDT | MaxReturn                1000
2017-07-02 14:12:08.989163 EDT | MinReturn                  49
2017-07-02 14:12:08.989266 EDT | AverageEsReturn            19.7755
2017-07-02 14:12:08.989367 EDT | StdEsReturn                15.8903
2017-07-02 14:12:08.989511 EDT | MaxEsReturn                59
2017-07-02 14:12:08.989789 EDT | MinEsReturn                 3
2017-07-02 14:12:08.990060 EDT | AverageDiscountedReturn    43.2596
2017-07-02 14:12:08.990269 EDT | AverageQLoss                0.0109868
2017-07-02 14:12:08.990431 EDT | AveragePolicySurr          -1.74527
2017-07-02 14:12:08.990612 EDT | AverageQ                    1.64484
2017-07-02 14:12:08.990767 EDT | AverageAbsQ                 1.64998
2017-07-02 14:12:08.990973 EDT | AverageY                    1.64474
2017-07-02 14:12:08.991168 EDT | AverageAbsY                 1.64542
2017-07-02 14:12:08.991337 EDT | AverageAbsQYDiff            0.0320013
2017-07-02 14:12:08.991509 EDT | AverageAction               0.399513
2017-07-02 14:12:08.991707 EDT | PolicyRegParamNorm         54.3749
2017-07-02 14:12:08.991889 EDT | QFunRegParamNorm           56.628
2017-07-02 14:12:08.992039 EDT | -----------------------  ------------
2017-07-02 14:12:08.992236 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #414 | Training started
2017-07-02 14:12:18.537337 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #414 | Training finished
2017-07-02 14:12:18.537923 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #414 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 14:12:18.538072 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #414 | Collecting samples for evaluation
2017-07-02 14:12:24.269144 EDT | -----------------------  ------------
2017-07-02 14:12:24.269424 EDT | Epoch                     414
2017-07-02 14:12:24.269648 EDT | Iteration                 414
2017-07-02 14:12:24.269810 EDT | AverageReturn            1000
2017-07-02 14:12:24.270019 EDT | StdReturn                   0
2017-07-02 14:12:24.270138 EDT | MaxReturn                1000
2017-07-02 14:12:24.270243 EDT | MinReturn                1000
2017-07-02 14:12:24.270381 EDT | AverageEsReturn            22.8864
2017-07-02 14:12:24.270534 EDT | StdEsReturn                21.2027
2017-07-02 14:12:24.270701 EDT | MaxEsReturn                96
2017-07-02 14:12:24.270902 EDT | MinEsReturn                 3
2017-07-02 14:12:24.271015 EDT | AverageDiscountedReturn    99.9957
2017-07-02 14:12:24.271130 EDT | AverageQLoss                0.0106653
2017-07-02 14:12:24.271243 EDT | AveragePolicySurr          -1.73839
2017-07-02 14:12:24.271354 EDT | AverageQ                    1.63892
2017-07-02 14:12:24.271475 EDT | AverageAbsQ                 1.64406
2017-07-02 14:12:24.271576 EDT | AverageY                    1.63898
2017-07-02 14:12:24.271678 EDT | AverageAbsY                 1.63991
2017-07-02 14:12:24.271873 EDT | AverageAbsQYDiff            0.0316343
2017-07-02 14:12:24.272081 EDT | AverageAction               0.372958
2017-07-02 14:12:24.272219 EDT | PolicyRegParamNorm         54.4241
2017-07-02 14:12:24.272398 EDT | QFunRegParamNorm           56.6386
2017-07-02 14:12:24.272505 EDT | -----------------------  ------------
2017-07-02 14:12:24.272693 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #415 | Training started
2017-07-02 14:12:33.782212 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #415 | Training finished
2017-07-02 14:12:33.783075 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #415 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 14:12:33.783216 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #415 | Collecting samples for evaluation
2017-07-02 14:12:39.589142 EDT | -----------------------  ------------
2017-07-02 14:12:39.589347 EDT | Epoch                     415
2017-07-02 14:12:39.589518 EDT | Iteration                 415
2017-07-02 14:12:39.589680 EDT | AverageReturn            1000
2017-07-02 14:12:39.589829 EDT | StdReturn                   0
2017-07-02 14:12:39.589945 EDT | MaxReturn                1000
2017-07-02 14:12:39.590116 EDT | MinReturn                1000
2017-07-02 14:12:39.590258 EDT | AverageEsReturn            16.4194
2017-07-02 14:12:39.590424 EDT | StdEsReturn                13.4818
2017-07-02 14:12:39.590628 EDT | MaxEsReturn                58
2017-07-02 14:12:39.590823 EDT | MinEsReturn                 3
2017-07-02 14:12:39.591029 EDT | AverageDiscountedReturn    99.9957
2017-07-02 14:12:39.591194 EDT | AverageQLoss                0.0112869
2017-07-02 14:12:39.591375 EDT | AveragePolicySurr          -1.73757
2017-07-02 14:12:39.591481 EDT | AverageQ                    1.63602
2017-07-02 14:12:39.591583 EDT | AverageAbsQ                 1.6425
2017-07-02 14:12:39.591696 EDT | AverageY                    1.636
2017-07-02 14:12:39.591897 EDT | AverageAbsY                 1.63733
2017-07-02 14:12:39.592026 EDT | AverageAbsQYDiff            0.0336064
2017-07-02 14:12:39.592128 EDT | AverageAction               0.0176092
2017-07-02 14:12:39.592242 EDT | PolicyRegParamNorm         54.427
2017-07-02 14:12:39.592376 EDT | QFunRegParamNorm           56.6649
2017-07-02 14:12:39.592499 EDT | -----------------------  ------------
2017-07-02 14:12:39.592674 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #416 | Training started
2017-07-02 14:12:49.076452 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #416 | Training finished
2017-07-02 14:12:49.077205 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #416 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 14:12:49.077579 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #416 | Collecting samples for evaluation
2017-07-02 14:12:54.783601 EDT | -----------------------  -------------
2017-07-02 14:12:54.783910 EDT | Epoch                     416
2017-07-02 14:12:54.784137 EDT | Iteration                 416
2017-07-02 14:12:54.784342 EDT | AverageReturn            1000
2017-07-02 14:12:54.784578 EDT | StdReturn                   0
2017-07-02 14:12:54.784801 EDT | MaxReturn                1000
2017-07-02 14:12:54.785021 EDT | MinReturn                1000
2017-07-02 14:12:54.785234 EDT | AverageEsReturn            24.5122
2017-07-02 14:12:54.785438 EDT | StdEsReturn                29.0988
2017-07-02 14:12:54.785681 EDT | MaxEsReturn               172
2017-07-02 14:12:54.785845 EDT | MinEsReturn                 4
2017-07-02 14:12:54.786065 EDT | AverageDiscountedReturn    99.9957
2017-07-02 14:12:54.786288 EDT | AverageQLoss                0.00968773
2017-07-02 14:12:54.786509 EDT | AveragePolicySurr          -1.74571
2017-07-02 14:12:54.786730 EDT | AverageQ                    1.64364
2017-07-02 14:12:54.786938 EDT | AverageAbsQ                 1.64946
2017-07-02 14:12:54.787160 EDT | AverageY                    1.6436
2017-07-02 14:12:54.787296 EDT | AverageAbsY                 1.64528
2017-07-02 14:12:54.787510 EDT | AverageAbsQYDiff            0.0308955
2017-07-02 14:12:54.787729 EDT | AverageAction               0.0143372
2017-07-02 14:12:54.787869 EDT | PolicyRegParamNorm         54.4717
2017-07-02 14:12:54.787975 EDT | QFunRegParamNorm           56.6817
2017-07-02 14:12:54.788075 EDT | -----------------------  -------------
2017-07-02 14:12:54.788242 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #417 | Training started
2017-07-02 14:13:04.341228 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #417 | Training finished
2017-07-02 14:13:04.341755 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #417 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 14:13:04.342010 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #417 | Collecting samples for evaluation
2017-07-02 14:13:10.031369 EDT | -----------------------  -------------
2017-07-02 14:13:10.031578 EDT | Epoch                     417
2017-07-02 14:13:10.031690 EDT | Iteration                 417
2017-07-02 14:13:10.031868 EDT | AverageReturn            1000
2017-07-02 14:13:10.031999 EDT | StdReturn                   0
2017-07-02 14:13:10.032146 EDT | MaxReturn                1000
2017-07-02 14:13:10.032305 EDT | MinReturn                1000
2017-07-02 14:13:10.032435 EDT | AverageEsReturn            22.3953
2017-07-02 14:13:10.032567 EDT | StdEsReturn                23.4582
2017-07-02 14:13:10.032675 EDT | MaxEsReturn               117
2017-07-02 14:13:10.032779 EDT | MinEsReturn                 4
2017-07-02 14:13:10.032967 EDT | AverageDiscountedReturn    99.9957
2017-07-02 14:13:10.033107 EDT | AverageQLoss                0.0105775
2017-07-02 14:13:10.033253 EDT | AveragePolicySurr          -1.74555
2017-07-02 14:13:10.033420 EDT | AverageQ                    1.64096
2017-07-02 14:13:10.033634 EDT | AverageAbsQ                 1.64744
2017-07-02 14:13:10.033745 EDT | AverageY                    1.64102
2017-07-02 14:13:10.033930 EDT | AverageAbsY                 1.64288
2017-07-02 14:13:10.034127 EDT | AverageAbsQYDiff            0.0340986
2017-07-02 14:13:10.034326 EDT | AverageAction               0.00928342
2017-07-02 14:13:10.034470 EDT | PolicyRegParamNorm         54.4967
2017-07-02 14:13:10.034576 EDT | QFunRegParamNorm           56.6976
2017-07-02 14:13:10.034697 EDT | -----------------------  -------------
2017-07-02 14:13:10.034863 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #418 | Training started
2017-07-02 14:13:19.623256 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #418 | Training finished
2017-07-02 14:13:19.623781 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #418 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 14:13:19.623917 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #418 | Collecting samples for evaluation
2017-07-02 14:13:25.337052 EDT | -----------------------  ------------
2017-07-02 14:13:25.337353 EDT | Epoch                     418
2017-07-02 14:13:25.337542 EDT | Iteration                 418
2017-07-02 14:13:25.337732 EDT | AverageReturn            1000
2017-07-02 14:13:25.337919 EDT | StdReturn                   0
2017-07-02 14:13:25.338111 EDT | MaxReturn                1000
2017-07-02 14:13:25.338306 EDT | MinReturn                1000
2017-07-02 14:13:25.338433 EDT | AverageEsReturn            23.2273
2017-07-02 14:13:25.338593 EDT | StdEsReturn                21.2527
2017-07-02 14:13:25.338755 EDT | MaxEsReturn                92
2017-07-02 14:13:25.338925 EDT | MinEsReturn                 3
2017-07-02 14:13:25.339062 EDT | AverageDiscountedReturn    99.9957
2017-07-02 14:13:25.339209 EDT | AverageQLoss                0.0099804
2017-07-02 14:13:25.339315 EDT | AveragePolicySurr          -1.76143
2017-07-02 14:13:25.339435 EDT | AverageQ                    1.6532
2017-07-02 14:13:25.339543 EDT | AverageAbsQ                 1.65955
2017-07-02 14:13:25.339704 EDT | AverageY                    1.65306
2017-07-02 14:13:25.339882 EDT | AverageAbsY                 1.655
2017-07-02 14:13:25.340028 EDT | AverageAbsQYDiff            0.0324665
2017-07-02 14:13:25.340149 EDT | AverageAction               0.03992
2017-07-02 14:13:25.340251 EDT | PolicyRegParamNorm         54.5108
2017-07-02 14:13:25.340385 EDT | QFunRegParamNorm           56.7154
2017-07-02 14:13:25.340552 EDT | -----------------------  ------------
2017-07-02 14:13:25.340732 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #419 | Training started
2017-07-02 14:13:35.029106 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #419 | Training finished
2017-07-02 14:13:35.029618 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #419 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 14:13:35.029833 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #419 | Collecting samples for evaluation
2017-07-02 14:13:40.712869 EDT | -----------------------  ------------
2017-07-02 14:13:40.713077 EDT | Epoch                     419
2017-07-02 14:13:40.713205 EDT | Iteration                 419
2017-07-02 14:13:40.713317 EDT | AverageReturn            1000
2017-07-02 14:13:40.713421 EDT | StdReturn                   0
2017-07-02 14:13:40.713562 EDT | MaxReturn                1000
2017-07-02 14:13:40.713770 EDT | MinReturn                1000
2017-07-02 14:13:40.713919 EDT | AverageEsReturn            17.5789
2017-07-02 14:13:40.714083 EDT | StdEsReturn                20.0665
2017-07-02 14:13:40.714192 EDT | MaxEsReturn               105
2017-07-02 14:13:40.714310 EDT | MinEsReturn                 3
2017-07-02 14:13:40.714429 EDT | AverageDiscountedReturn    99.9957
2017-07-02 14:13:40.714564 EDT | AverageQLoss                0.0120257
2017-07-02 14:13:40.714675 EDT | AveragePolicySurr          -1.76845
2017-07-02 14:13:40.714828 EDT | AverageQ                    1.657
2017-07-02 14:13:40.714932 EDT | AverageAbsQ                 1.66278
2017-07-02 14:13:40.715033 EDT | AverageY                    1.65702
2017-07-02 14:13:40.715132 EDT | AverageAbsY                 1.65864
2017-07-02 14:13:40.715232 EDT | AverageAbsQYDiff            0.0343761
2017-07-02 14:13:40.715382 EDT | AverageAction               0.197743
2017-07-02 14:13:40.715516 EDT | PolicyRegParamNorm         54.5517
2017-07-02 14:13:40.715616 EDT | QFunRegParamNorm           56.7518
2017-07-02 14:13:40.715713 EDT | -----------------------  ------------
2017-07-02 14:13:40.715875 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #420 | Training started
2017-07-02 14:13:50.311754 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #420 | Training finished
2017-07-02 14:13:50.312133 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #420 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 14:13:50.312369 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #420 | Collecting samples for evaluation
2017-07-02 14:13:56.087937 EDT | -----------------------  ------------
2017-07-02 14:13:56.088487 EDT | Epoch                     420
2017-07-02 14:13:56.088618 EDT | Iteration                 420
2017-07-02 14:13:56.088796 EDT | AverageReturn            1000
2017-07-02 14:13:56.088909 EDT | StdReturn                   0
2017-07-02 14:13:56.089054 EDT | MaxReturn                1000
2017-07-02 14:13:56.089163 EDT | MinReturn                1000
2017-07-02 14:13:56.089288 EDT | AverageEsReturn            24.5854
2017-07-02 14:13:56.089390 EDT | StdEsReturn                42.8463
2017-07-02 14:13:56.089503 EDT | MaxEsReturn               220
2017-07-02 14:13:56.089709 EDT | MinEsReturn                 3
2017-07-02 14:13:56.089890 EDT | AverageDiscountedReturn    99.9957
2017-07-02 14:13:56.090047 EDT | AverageQLoss                0.0112353
2017-07-02 14:13:56.090195 EDT | AveragePolicySurr          -1.78898
2017-07-02 14:13:56.090448 EDT | AverageQ                    1.67717
2017-07-02 14:13:56.090577 EDT | AverageAbsQ                 1.68291
2017-07-02 14:13:56.090710 EDT | AverageY                    1.67727
2017-07-02 14:13:56.090836 EDT | AverageAbsY                 1.6784
2017-07-02 14:13:56.091009 EDT | AverageAbsQYDiff            0.0353935
2017-07-02 14:13:56.091115 EDT | AverageAction               0.289137
2017-07-02 14:13:56.091215 EDT | PolicyRegParamNorm         54.599
2017-07-02 14:13:56.091386 EDT | QFunRegParamNorm           56.7507
2017-07-02 14:13:56.091560 EDT | -----------------------  ------------
2017-07-02 14:13:56.091831 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #421 | Training started
2017-07-02 14:14:05.635076 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #421 | Training finished
2017-07-02 14:14:05.635622 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #421 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 14:14:05.635886 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #421 | Collecting samples for evaluation
2017-07-02 14:14:11.436469 EDT | -----------------------  ------------
2017-07-02 14:14:11.436774 EDT | Epoch                     421
2017-07-02 14:14:11.436981 EDT | Iteration                 421
2017-07-02 14:14:11.437186 EDT | AverageReturn            1000
2017-07-02 14:14:11.437363 EDT | StdReturn                   0
2017-07-02 14:14:11.437470 EDT | MaxReturn                1000
2017-07-02 14:14:11.437613 EDT | MinReturn                1000
2017-07-02 14:14:11.437778 EDT | AverageEsReturn            19.3654
2017-07-02 14:14:11.437884 EDT | StdEsReturn                23.4906
2017-07-02 14:14:11.438000 EDT | MaxEsReturn                99
2017-07-02 14:14:11.438127 EDT | MinEsReturn                 4
2017-07-02 14:14:11.438229 EDT | AverageDiscountedReturn    99.9957
2017-07-02 14:14:11.438329 EDT | AverageQLoss                0.0137532
2017-07-02 14:14:11.438452 EDT | AveragePolicySurr          -1.79817
2017-07-02 14:14:11.438595 EDT | AverageQ                    1.68103
2017-07-02 14:14:11.438745 EDT | AverageAbsQ                 1.68668
2017-07-02 14:14:11.438864 EDT | AverageY                    1.68101
2017-07-02 14:14:11.439053 EDT | AverageAbsY                 1.68192
2017-07-02 14:14:11.439218 EDT | AverageAbsQYDiff            0.0379708
2017-07-02 14:14:11.439330 EDT | AverageAction               0.376065
2017-07-02 14:14:11.439522 EDT | PolicyRegParamNorm         54.6741
2017-07-02 14:14:11.439711 EDT | QFunRegParamNorm           56.7889
2017-07-02 14:14:11.439900 EDT | -----------------------  ------------
2017-07-02 14:14:11.440145 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #422 | Training started
2017-07-02 14:14:20.877072 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #422 | Training finished
2017-07-02 14:14:20.877597 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #422 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 14:14:20.877875 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #422 | Collecting samples for evaluation
2017-07-02 14:14:26.607623 EDT | -----------------------  -------------
2017-07-02 14:14:26.608136 EDT | Epoch                     422
2017-07-02 14:14:26.608399 EDT | Iteration                 422
2017-07-02 14:14:26.608625 EDT | AverageReturn            1000
2017-07-02 14:14:26.608848 EDT | StdReturn                   0
2017-07-02 14:14:26.609066 EDT | MaxReturn                1000
2017-07-02 14:14:26.609276 EDT | MinReturn                1000
2017-07-02 14:14:26.609390 EDT | AverageEsReturn            22.9535
2017-07-02 14:14:26.609520 EDT | StdEsReturn                28.2258
2017-07-02 14:14:26.609719 EDT | MaxEsReturn               142
2017-07-02 14:14:26.609870 EDT | MinEsReturn                 2
2017-07-02 14:14:26.610004 EDT | AverageDiscountedReturn    99.9957
2017-07-02 14:14:26.610150 EDT | AverageQLoss                0.0125143
2017-07-02 14:14:26.610274 EDT | AveragePolicySurr          -1.81477
2017-07-02 14:14:26.610382 EDT | AverageQ                    1.70057
2017-07-02 14:14:26.610488 EDT | AverageAbsQ                 1.70572
2017-07-02 14:14:26.610607 EDT | AverageY                    1.70071
2017-07-02 14:14:26.610713 EDT | AverageAbsY                 1.70158
2017-07-02 14:14:26.610823 EDT | AverageAbsQYDiff            0.037051
2017-07-02 14:14:26.610967 EDT | AverageAction               0.00964306
2017-07-02 14:14:26.611104 EDT | PolicyRegParamNorm         54.7811
2017-07-02 14:14:26.611210 EDT | QFunRegParamNorm           56.7881
2017-07-02 14:14:26.611314 EDT | -----------------------  -------------
2017-07-02 14:14:26.611551 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #423 | Training started
2017-07-02 14:14:36.155812 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #423 | Training finished
2017-07-02 14:14:36.156458 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #423 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 14:14:36.156713 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #423 | Collecting samples for evaluation
2017-07-02 14:14:41.906349 EDT | -----------------------  ------------
2017-07-02 14:14:41.906578 EDT | Epoch                     423
2017-07-02 14:14:41.906707 EDT | Iteration                 423
2017-07-02 14:14:41.906817 EDT | AverageReturn            1000
2017-07-02 14:14:41.906936 EDT | StdReturn                   0
2017-07-02 14:14:41.907110 EDT | MaxReturn                1000
2017-07-02 14:14:41.907219 EDT | MinReturn                1000
2017-07-02 14:14:41.907741 EDT | AverageEsReturn            23.7381
2017-07-02 14:14:41.907913 EDT | StdEsReturn                31.2517
2017-07-02 14:14:41.908047 EDT | MaxEsReturn               166
2017-07-02 14:14:41.908181 EDT | MinEsReturn                 3
2017-07-02 14:14:41.908320 EDT | AverageDiscountedReturn    99.9957
2017-07-02 14:14:41.908453 EDT | AverageQLoss                0.0129476
2017-07-02 14:14:41.908581 EDT | AveragePolicySurr          -1.83599
2017-07-02 14:14:41.908707 EDT | AverageQ                    1.72105
2017-07-02 14:14:41.908867 EDT | AverageAbsQ                 1.72701
2017-07-02 14:14:41.909036 EDT | AverageY                    1.72113
2017-07-02 14:14:41.909164 EDT | AverageAbsY                 1.72174
2017-07-02 14:14:41.909355 EDT | AverageAbsQYDiff            0.0381772
2017-07-02 14:14:41.909580 EDT | AverageAction               0.18196
2017-07-02 14:14:41.909772 EDT | PolicyRegParamNorm         54.854
2017-07-02 14:14:41.909969 EDT | QFunRegParamNorm           56.7753
2017-07-02 14:14:41.910178 EDT | -----------------------  ------------
2017-07-02 14:14:41.910425 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #424 | Training started
2017-07-02 14:14:51.584469 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #424 | Training finished
2017-07-02 14:14:51.585041 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #424 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 14:14:51.585294 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #424 | Collecting samples for evaluation
2017-07-02 14:14:57.210089 EDT | -----------------------  ------------
2017-07-02 14:14:57.210705 EDT | Epoch                     424
2017-07-02 14:14:57.210926 EDT | Iteration                 424
2017-07-02 14:14:57.211069 EDT | AverageReturn            1000
2017-07-02 14:14:57.211255 EDT | StdReturn                   0
2017-07-02 14:14:57.211410 EDT | MaxReturn                1000
2017-07-02 14:14:57.211524 EDT | MinReturn                1000
2017-07-02 14:14:57.211665 EDT | AverageEsReturn            15.5781
2017-07-02 14:14:57.211799 EDT | StdEsReturn                16.2892
2017-07-02 14:14:57.211960 EDT | MaxEsReturn                76
2017-07-02 14:14:57.212119 EDT | MinEsReturn                 3
2017-07-02 14:14:57.212279 EDT | AverageDiscountedReturn    99.9957
2017-07-02 14:14:57.212438 EDT | AverageQLoss                0.0120006
2017-07-02 14:14:57.212633 EDT | AveragePolicySurr          -1.84906
2017-07-02 14:14:57.212795 EDT | AverageQ                    1.72882
2017-07-02 14:14:57.212927 EDT | AverageAbsQ                 1.73362
2017-07-02 14:14:57.213033 EDT | AverageY                    1.72872
2017-07-02 14:14:57.213134 EDT | AverageAbsY                 1.72934
2017-07-02 14:14:57.213235 EDT | AverageAbsQYDiff            0.036059
2017-07-02 14:14:57.213409 EDT | AverageAction               0.459071
2017-07-02 14:14:57.213604 EDT | PolicyRegParamNorm         54.889
2017-07-02 14:14:57.213783 EDT | QFunRegParamNorm           56.776
2017-07-02 14:14:57.213917 EDT | -----------------------  ------------
2017-07-02 14:14:57.214143 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #425 | Training started
2017-07-02 14:15:06.965988 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #425 | Training finished
2017-07-02 14:15:06.966616 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #425 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 14:15:06.966783 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #425 | Collecting samples for evaluation
2017-07-02 14:15:12.611492 EDT | -----------------------  ------------
2017-07-02 14:15:12.611776 EDT | Epoch                     425
2017-07-02 14:15:12.611895 EDT | Iteration                 425
2017-07-02 14:15:12.612026 EDT | AverageReturn            1000
2017-07-02 14:15:12.612219 EDT | StdReturn                   0
2017-07-02 14:15:12.612419 EDT | MaxReturn                1000
2017-07-02 14:15:12.612580 EDT | MinReturn                1000
2017-07-02 14:15:12.612740 EDT | AverageEsReturn            14.9706
2017-07-02 14:15:12.612858 EDT | StdEsReturn                23.0492
2017-07-02 14:15:12.613021 EDT | MaxEsReturn               144
2017-07-02 14:15:12.613161 EDT | MinEsReturn                 3
2017-07-02 14:15:12.613266 EDT | AverageDiscountedReturn    99.9957
2017-07-02 14:15:12.613369 EDT | AverageQLoss                0.0136729
2017-07-02 14:15:12.613530 EDT | AveragePolicySurr          -1.87162
2017-07-02 14:15:12.613721 EDT | AverageQ                    1.75004
2017-07-02 14:15:12.613955 EDT | AverageAbsQ                 1.75539
2017-07-02 14:15:12.614176 EDT | AverageY                    1.75021
2017-07-02 14:15:12.614303 EDT | AverageAbsY                 1.75071
2017-07-02 14:15:12.614451 EDT | AverageAbsQYDiff            0.0395736
2017-07-02 14:15:12.614639 EDT | AverageAction               0.887984
2017-07-02 14:15:12.614825 EDT | PolicyRegParamNorm         54.9865
2017-07-02 14:15:12.614967 EDT | QFunRegParamNorm           56.8031
2017-07-02 14:15:12.615070 EDT | -----------------------  ------------
2017-07-02 14:15:12.615233 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #426 | Training started
2017-07-02 14:15:22.806393 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #426 | Training finished
2017-07-02 14:15:22.806908 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #426 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 14:15:22.807145 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #426 | Collecting samples for evaluation
2017-07-02 14:15:28.517445 EDT | -----------------------  -------------
2017-07-02 14:15:28.518056 EDT | Epoch                     426
2017-07-02 14:15:28.518301 EDT | Iteration                 426
2017-07-02 14:15:28.518536 EDT | AverageReturn            1000
2017-07-02 14:15:28.518764 EDT | StdReturn                   0
2017-07-02 14:15:28.518898 EDT | MaxReturn                1000
2017-07-02 14:15:28.519099 EDT | MinReturn                1000
2017-07-02 14:15:28.519329 EDT | AverageEsReturn            18.8491
2017-07-02 14:15:28.519547 EDT | StdEsReturn                30.8749
2017-07-02 14:15:28.519770 EDT | MaxEsReturn               189
2017-07-02 14:15:28.519954 EDT | MinEsReturn                 3
2017-07-02 14:15:28.520168 EDT | AverageDiscountedReturn    99.9957
2017-07-02 14:15:28.520297 EDT | AverageQLoss                0.00981562
2017-07-02 14:15:28.520448 EDT | AveragePolicySurr          -1.88824
2017-07-02 14:15:28.520669 EDT | AverageQ                    1.76372
2017-07-02 14:15:28.520879 EDT | AverageAbsQ                 1.76873
2017-07-02 14:15:28.520987 EDT | AverageY                    1.76389
2017-07-02 14:15:28.521094 EDT | AverageAbsY                 1.76451
2017-07-02 14:15:28.521233 EDT | AverageAbsQYDiff            0.0352185
2017-07-02 14:15:28.521373 EDT | AverageAction               0.622369
2017-07-02 14:15:28.521659 EDT | PolicyRegParamNorm         55.099
2017-07-02 14:15:28.521886 EDT | QFunRegParamNorm           56.7771
2017-07-02 14:15:28.522099 EDT | -----------------------  -------------
2017-07-02 14:15:28.522406 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #427 | Training started
2017-07-02 14:15:38.151599 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #427 | Training finished
2017-07-02 14:15:38.152259 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #427 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 14:15:38.152532 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #427 | Collecting samples for evaluation
2017-07-02 14:15:43.850867 EDT | -----------------------  ------------
2017-07-02 14:15:43.851104 EDT | Epoch                     427
2017-07-02 14:15:43.851231 EDT | Iteration                 427
2017-07-02 14:15:43.851344 EDT | AverageReturn            1000
2017-07-02 14:15:43.851467 EDT | StdReturn                   0
2017-07-02 14:15:43.851601 EDT | MaxReturn                1000
2017-07-02 14:15:43.851704 EDT | MinReturn                1000
2017-07-02 14:15:43.851874 EDT | AverageEsReturn            22.2667
2017-07-02 14:15:43.851991 EDT | StdEsReturn                24.8394
2017-07-02 14:15:43.852104 EDT | MaxEsReturn               113
2017-07-02 14:15:43.852215 EDT | MinEsReturn                 3
2017-07-02 14:15:43.852372 EDT | AverageDiscountedReturn    99.9957
2017-07-02 14:15:43.852499 EDT | AverageQLoss                0.0144802
2017-07-02 14:15:43.852617 EDT | AveragePolicySurr          -1.90692
2017-07-02 14:15:43.852749 EDT | AverageQ                    1.78217
2017-07-02 14:15:43.852857 EDT | AverageAbsQ                 1.78817
2017-07-02 14:15:43.853003 EDT | AverageY                    1.7822
2017-07-02 14:15:43.853158 EDT | AverageAbsY                 1.78271
2017-07-02 14:15:43.853397 EDT | AverageAbsQYDiff            0.0415504
2017-07-02 14:15:43.853822 EDT | AverageAction               0.888621
2017-07-02 14:15:43.854054 EDT | PolicyRegParamNorm         55.1361
2017-07-02 14:15:43.854233 EDT | QFunRegParamNorm           56.7993
2017-07-02 14:15:43.854340 EDT | -----------------------  ------------
2017-07-02 14:15:43.854504 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #428 | Training started
2017-07-02 14:15:53.366164 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #428 | Training finished
2017-07-02 14:15:53.366828 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #428 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 14:15:53.367017 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #428 | Collecting samples for evaluation
2017-07-02 14:15:59.118494 EDT | -----------------------  ------------
2017-07-02 14:15:59.119018 EDT | Epoch                     428
2017-07-02 14:15:59.119174 EDT | Iteration                 428
2017-07-02 14:15:59.119327 EDT | AverageReturn            1000
2017-07-02 14:15:59.119466 EDT | StdReturn                   0
2017-07-02 14:15:59.119582 EDT | MaxReturn                1000
2017-07-02 14:15:59.119721 EDT | MinReturn                1000
2017-07-02 14:15:59.119828 EDT | AverageEsReturn            16.6333
2017-07-02 14:15:59.119961 EDT | StdEsReturn                25.827
2017-07-02 14:15:59.120258 EDT | MaxEsReturn               133
2017-07-02 14:15:59.120568 EDT | MinEsReturn                 2
2017-07-02 14:15:59.120876 EDT | AverageDiscountedReturn    99.9957
2017-07-02 14:15:59.121147 EDT | AverageQLoss                0.0132811
2017-07-02 14:15:59.121451 EDT | AveragePolicySurr          -1.92577
2017-07-02 14:15:59.121744 EDT | AverageQ                    1.79853
2017-07-02 14:15:59.121936 EDT | AverageAbsQ                 1.80468
2017-07-02 14:15:59.122064 EDT | AverageY                    1.79848
2017-07-02 14:15:59.122187 EDT | AverageAbsY                 1.7988
2017-07-02 14:15:59.122316 EDT | AverageAbsQYDiff            0.0398746
2017-07-02 14:15:59.122442 EDT | AverageAction               0.869109
2017-07-02 14:15:59.122559 EDT | PolicyRegParamNorm         55.1564
2017-07-02 14:15:59.122667 EDT | QFunRegParamNorm           56.841
2017-07-02 14:15:59.122825 EDT | -----------------------  ------------
2017-07-02 14:15:59.123001 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #429 | Training started
2017-07-02 14:16:08.698615 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #429 | Training finished
2017-07-02 14:16:08.699236 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #429 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 14:16:08.699557 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #429 | Collecting samples for evaluation
2017-07-02 14:16:14.349984 EDT | -----------------------  ------------
2017-07-02 14:16:14.350175 EDT | Epoch                     429
2017-07-02 14:16:14.350309 EDT | Iteration                 429
2017-07-02 14:16:14.350451 EDT | AverageReturn            1000
2017-07-02 14:16:14.350554 EDT | StdReturn                   0
2017-07-02 14:16:14.350698 EDT | MaxReturn                1000
2017-07-02 14:16:14.350858 EDT | MinReturn                1000
2017-07-02 14:16:14.351003 EDT | AverageEsReturn            20.02
2017-07-02 14:16:14.351154 EDT | StdEsReturn                27.1017
2017-07-02 14:16:14.351259 EDT | MaxEsReturn               118
2017-07-02 14:16:14.351400 EDT | MinEsReturn                 3
2017-07-02 14:16:14.351505 EDT | AverageDiscountedReturn    99.9957
2017-07-02 14:16:14.351714 EDT | AverageQLoss                0.0126438
2017-07-02 14:16:14.351946 EDT | AveragePolicySurr          -1.95418
2017-07-02 14:16:14.352145 EDT | AverageQ                    1.82335
2017-07-02 14:16:14.352376 EDT | AverageAbsQ                 1.82898
2017-07-02 14:16:14.352602 EDT | AverageY                    1.82356
2017-07-02 14:16:14.352807 EDT | AverageAbsY                 1.82406
2017-07-02 14:16:14.353039 EDT | AverageAbsQYDiff            0.0389231
2017-07-02 14:16:14.353248 EDT | AverageAction               0.874993
2017-07-02 14:16:14.353466 EDT | PolicyRegParamNorm         55.1849
2017-07-02 14:16:14.353706 EDT | QFunRegParamNorm           56.8358
2017-07-02 14:16:14.353883 EDT | -----------------------  ------------
2017-07-02 14:16:14.354213 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #430 | Training started
2017-07-02 14:16:23.974992 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #430 | Training finished
2017-07-02 14:16:23.975612 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #430 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 14:16:23.975863 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #430 | Collecting samples for evaluation
2017-07-02 14:16:29.606381 EDT | -----------------------  ------------
2017-07-02 14:16:29.606867 EDT | Epoch                     430
2017-07-02 14:16:29.607007 EDT | Iteration                 430
2017-07-02 14:16:29.607144 EDT | AverageReturn            1000
2017-07-02 14:16:29.607273 EDT | StdReturn                   0
2017-07-02 14:16:29.607425 EDT | MaxReturn                1000
2017-07-02 14:16:29.607624 EDT | MinReturn                1000
2017-07-02 14:16:29.607788 EDT | AverageEsReturn            25.2308
2017-07-02 14:16:29.607910 EDT | StdEsReturn                31.6847
2017-07-02 14:16:29.608095 EDT | MaxEsReturn               123
2017-07-02 14:16:29.608214 EDT | MinEsReturn                 3
2017-07-02 14:16:29.608317 EDT | AverageDiscountedReturn    99.9957
2017-07-02 14:16:29.608417 EDT | AverageQLoss                0.0142018
2017-07-02 14:16:29.608592 EDT | AveragePolicySurr          -1.96845
2017-07-02 14:16:29.608796 EDT | AverageQ                    1.83635
2017-07-02 14:16:29.608935 EDT | AverageAbsQ                 1.84203
2017-07-02 14:16:29.609063 EDT | AverageY                    1.83634
2017-07-02 14:16:29.609207 EDT | AverageAbsY                 1.83691
2017-07-02 14:16:29.609441 EDT | AverageAbsQYDiff            0.0396969
2017-07-02 14:16:29.609663 EDT | AverageAction               0.808507
2017-07-02 14:16:29.609861 EDT | PolicyRegParamNorm         55.2534
2017-07-02 14:16:29.610041 EDT | QFunRegParamNorm           56.8617
2017-07-02 14:16:29.610168 EDT | -----------------------  ------------
2017-07-02 14:16:29.610429 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #431 | Training started
2017-07-02 14:16:39.307530 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #431 | Training finished
2017-07-02 14:16:39.308279 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #431 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 14:16:39.308456 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #431 | Collecting samples for evaluation
2017-07-02 14:16:45.078265 EDT | -----------------------  ------------
2017-07-02 14:16:45.078514 EDT | Epoch                     431
2017-07-02 14:16:45.078815 EDT | Iteration                 431
2017-07-02 14:16:45.079047 EDT | AverageReturn            1000
2017-07-02 14:16:45.079258 EDT | StdReturn                   0
2017-07-02 14:16:45.079492 EDT | MaxReturn                1000
2017-07-02 14:16:45.079691 EDT | MinReturn                1000
2017-07-02 14:16:45.079924 EDT | AverageEsReturn            25.5385
2017-07-02 14:16:45.080145 EDT | StdEsReturn                33.7083
2017-07-02 14:16:45.080377 EDT | MaxEsReturn               131
2017-07-02 14:16:45.080603 EDT | MinEsReturn                 3
2017-07-02 14:16:45.080816 EDT | AverageDiscountedReturn    99.9957
2017-07-02 14:16:45.081045 EDT | AverageQLoss                0.0140909
2017-07-02 14:16:45.081274 EDT | AveragePolicySurr          -1.99111
2017-07-02 14:16:45.081522 EDT | AverageQ                    1.85149
2017-07-02 14:16:45.081731 EDT | AverageAbsQ                 1.85737
2017-07-02 14:16:45.081891 EDT | AverageY                    1.85153
2017-07-02 14:16:45.082122 EDT | AverageAbsY                 1.85204
2017-07-02 14:16:45.082349 EDT | AverageAbsQYDiff            0.0397088
2017-07-02 14:16:45.082472 EDT | AverageAction               0.895675
2017-07-02 14:16:45.082700 EDT | PolicyRegParamNorm         55.3523
2017-07-02 14:16:45.082926 EDT | QFunRegParamNorm           56.8846
2017-07-02 14:16:45.083074 EDT | -----------------------  ------------
2017-07-02 14:16:45.083401 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #432 | Training started
2017-07-02 14:16:54.819140 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #432 | Training finished
2017-07-02 14:16:54.819617 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #432 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 14:16:54.819750 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #432 | Collecting samples for evaluation
2017-07-02 14:17:00.504114 EDT | -----------------------  ------------
2017-07-02 14:17:00.504608 EDT | Epoch                     432
2017-07-02 14:17:00.504794 EDT | Iteration                 432
2017-07-02 14:17:00.504989 EDT | AverageReturn            1000
2017-07-02 14:17:00.505186 EDT | StdReturn                   0
2017-07-02 14:17:00.505373 EDT | MaxReturn                1000
2017-07-02 14:17:00.505658 EDT | MinReturn                1000
2017-07-02 14:17:00.505920 EDT | AverageEsReturn            16.1429
2017-07-02 14:17:00.506072 EDT | StdEsReturn                21.8268
2017-07-02 14:17:00.506202 EDT | MaxEsReturn               110
2017-07-02 14:17:00.506313 EDT | MinEsReturn                 3
2017-07-02 14:17:00.506420 EDT | AverageDiscountedReturn    99.9957
2017-07-02 14:17:00.506525 EDT | AverageQLoss                0.0138455
2017-07-02 14:17:00.506631 EDT | AveragePolicySurr          -2.00549
2017-07-02 14:17:00.506742 EDT | AverageQ                    1.8688
2017-07-02 14:17:00.506890 EDT | AverageAbsQ                 1.87428
2017-07-02 14:17:00.506997 EDT | AverageY                    1.86893
2017-07-02 14:17:00.507108 EDT | AverageAbsY                 1.86952
2017-07-02 14:17:00.507240 EDT | AverageAbsQYDiff            0.0406476
2017-07-02 14:17:00.507390 EDT | AverageAction               0.859387
2017-07-02 14:17:00.507498 EDT | PolicyRegParamNorm         55.4102
2017-07-02 14:17:00.507634 EDT | QFunRegParamNorm           56.9053
2017-07-02 14:17:00.507805 EDT | -----------------------  ------------
2017-07-02 14:17:00.508025 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #433 | Training started
2017-07-02 14:17:10.199961 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #433 | Training finished
2017-07-02 14:17:10.200592 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #433 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 14:17:10.200847 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #433 | Collecting samples for evaluation
2017-07-02 14:17:15.936966 EDT | -----------------------  ------------
2017-07-02 14:17:15.937273 EDT | Epoch                     433
2017-07-02 14:17:15.937432 EDT | Iteration                 433
2017-07-02 14:17:15.937683 EDT | AverageReturn            1000
2017-07-02 14:17:15.937904 EDT | StdReturn                   0
2017-07-02 14:17:15.938134 EDT | MaxReturn                1000
2017-07-02 14:17:15.938362 EDT | MinReturn                1000
2017-07-02 14:17:15.938582 EDT | AverageEsReturn            18.4151
2017-07-02 14:17:15.938809 EDT | StdEsReturn                30.7144
2017-07-02 14:17:15.939022 EDT | MaxEsReturn               151
2017-07-02 14:17:15.939244 EDT | MinEsReturn                 3
2017-07-02 14:17:15.939462 EDT | AverageDiscountedReturn    99.9957
2017-07-02 14:17:15.939690 EDT | AverageQLoss                0.0133593
2017-07-02 14:17:15.939872 EDT | AveragePolicySurr          -2.02591
2017-07-02 14:17:15.940101 EDT | AverageQ                    1.88294
2017-07-02 14:17:15.940320 EDT | AverageAbsQ                 1.88875
2017-07-02 14:17:15.940548 EDT | AverageY                    1.88306
2017-07-02 14:17:15.940754 EDT | AverageAbsY                 1.88381
2017-07-02 14:17:15.940977 EDT | AverageAbsQYDiff            0.0389996
2017-07-02 14:17:15.941201 EDT | AverageAction               0.882444
2017-07-02 14:17:15.941429 EDT | PolicyRegParamNorm         55.5073
2017-07-02 14:17:15.941907 EDT | QFunRegParamNorm           56.9239
2017-07-02 14:17:15.942137 EDT | -----------------------  ------------
2017-07-02 14:17:15.942465 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #434 | Training started
2017-07-02 14:17:25.563419 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #434 | Training finished
2017-07-02 14:17:25.564182 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #434 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 14:17:25.564365 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #434 | Collecting samples for evaluation
2017-07-02 14:17:31.270317 EDT | -----------------------  ------------
2017-07-02 14:17:31.270998 EDT | Epoch                     434
2017-07-02 14:17:31.271242 EDT | Iteration                 434
2017-07-02 14:17:31.271475 EDT | AverageReturn            1000
2017-07-02 14:17:31.271693 EDT | StdReturn                   0
2017-07-02 14:17:31.271927 EDT | MaxReturn                1000
2017-07-02 14:17:31.272162 EDT | MinReturn                1000
2017-07-02 14:17:31.272376 EDT | AverageEsReturn            29.2857
2017-07-02 14:17:31.272610 EDT | StdEsReturn                40.278
2017-07-02 14:17:31.272834 EDT | MaxEsReturn               224
2017-07-02 14:17:31.273060 EDT | MinEsReturn                 3
2017-07-02 14:17:31.273282 EDT | AverageDiscountedReturn    99.9957
2017-07-02 14:17:31.273576 EDT | AverageQLoss                0.0153944
2017-07-02 14:17:31.273798 EDT | AveragePolicySurr          -2.04488
2017-07-02 14:17:31.274033 EDT | AverageQ                    1.90612
2017-07-02 14:17:31.274239 EDT | AverageAbsQ                 1.91162
2017-07-02 14:17:31.274457 EDT | AverageY                    1.90618
2017-07-02 14:17:31.274681 EDT | AverageAbsY                 1.90677
2017-07-02 14:17:31.274912 EDT | AverageAbsQYDiff            0.041642
2017-07-02 14:17:31.275142 EDT | AverageAction               0.921966
2017-07-02 14:17:31.275357 EDT | PolicyRegParamNorm         55.5525
2017-07-02 14:17:31.275591 EDT | QFunRegParamNorm           56.9362
2017-07-02 14:17:31.275822 EDT | -----------------------  ------------
2017-07-02 14:17:31.276134 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #435 | Training started
2017-07-02 14:17:40.828751 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #435 | Training finished
2017-07-02 14:17:40.829584 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #435 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 14:17:40.829729 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #435 | Collecting samples for evaluation
2017-07-02 14:17:46.548718 EDT | -----------------------  ------------
2017-07-02 14:17:46.549022 EDT | Epoch                     435
2017-07-02 14:17:46.549236 EDT | Iteration                 435
2017-07-02 14:17:46.549343 EDT | AverageReturn            1000
2017-07-02 14:17:46.549446 EDT | StdReturn                   0
2017-07-02 14:17:46.549718 EDT | MaxReturn                1000
2017-07-02 14:17:46.549935 EDT | MinReturn                1000
2017-07-02 14:17:46.550168 EDT | AverageEsReturn            29.1212
2017-07-02 14:17:46.550393 EDT | StdEsReturn                45.1722
2017-07-02 14:17:46.550610 EDT | MaxEsReturn               232
2017-07-02 14:17:46.550824 EDT | MinEsReturn                 3
2017-07-02 14:17:46.551045 EDT | AverageDiscountedReturn    99.9957
2017-07-02 14:17:46.551261 EDT | AverageQLoss                0.0152609
2017-07-02 14:17:46.551460 EDT | AveragePolicySurr          -2.06133
2017-07-02 14:17:46.551694 EDT | AverageQ                    1.92256
2017-07-02 14:17:46.551923 EDT | AverageAbsQ                 1.92847
2017-07-02 14:17:46.552152 EDT | AverageY                    1.92284
2017-07-02 14:17:46.552374 EDT | AverageAbsY                 1.92363
2017-07-02 14:17:46.552536 EDT | AverageAbsQYDiff            0.0407644
2017-07-02 14:17:46.552754 EDT | AverageAction               0.926299
2017-07-02 14:17:46.552974 EDT | PolicyRegParamNorm         55.6344
2017-07-02 14:17:46.553123 EDT | QFunRegParamNorm           56.9303
2017-07-02 14:17:46.553235 EDT | -----------------------  ------------
2017-07-02 14:17:46.553542 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #436 | Training started
2017-07-02 14:17:56.198888 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #436 | Training finished
2017-07-02 14:17:56.199422 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #436 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 14:17:56.199776 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #436 | Collecting samples for evaluation
2017-07-02 14:18:01.923387 EDT | -----------------------  ------------
2017-07-02 14:18:01.923892 EDT | Epoch                     436
2017-07-02 14:18:01.924116 EDT | Iteration                 436
2017-07-02 14:18:01.924227 EDT | AverageReturn            1000
2017-07-02 14:18:01.924385 EDT | StdReturn                   0
2017-07-02 14:18:01.924501 EDT | MaxReturn                1000
2017-07-02 14:18:01.924722 EDT | MinReturn                1000
2017-07-02 14:18:01.924916 EDT | AverageEsReturn            17.4068
2017-07-02 14:18:01.925143 EDT | StdEsReturn                30.4487
2017-07-02 14:18:01.925343 EDT | MaxEsReturn               160
2017-07-02 14:18:01.925602 EDT | MinEsReturn                 3
2017-07-02 14:18:01.925824 EDT | AverageDiscountedReturn    99.9957
2017-07-02 14:18:01.926043 EDT | AverageQLoss                0.0137849
2017-07-02 14:18:01.926250 EDT | AveragePolicySurr          -2.07518
2017-07-02 14:18:01.926440 EDT | AverageQ                    1.94018
2017-07-02 14:18:01.926655 EDT | AverageAbsQ                 1.94539
2017-07-02 14:18:01.926766 EDT | AverageY                    1.94003
2017-07-02 14:18:01.926869 EDT | AverageAbsY                 1.94048
2017-07-02 14:18:01.926971 EDT | AverageAbsQYDiff            0.0378523
2017-07-02 14:18:01.927071 EDT | AverageAction               0.839202
2017-07-02 14:18:01.927171 EDT | PolicyRegParamNorm         55.7523
2017-07-02 14:18:01.927270 EDT | QFunRegParamNorm           57.0026
2017-07-02 14:18:01.927469 EDT | -----------------------  ------------
2017-07-02 14:18:01.927736 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #437 | Training started
2017-07-02 14:18:11.846811 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #437 | Training finished
2017-07-02 14:18:11.847398 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #437 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 14:18:11.847560 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #437 | Collecting samples for evaluation
2017-07-02 14:18:17.547653 EDT | -----------------------  ------------
2017-07-02 14:18:17.547870 EDT | Epoch                     437
2017-07-02 14:18:17.548051 EDT | Iteration                 437
2017-07-02 14:18:17.548182 EDT | AverageReturn            1000
2017-07-02 14:18:17.548323 EDT | StdReturn                   0
2017-07-02 14:18:17.548473 EDT | MaxReturn                1000
2017-07-02 14:18:17.548602 EDT | MinReturn                1000
2017-07-02 14:18:17.548729 EDT | AverageEsReturn            28.3235
2017-07-02 14:18:17.548847 EDT | StdEsReturn                34.7713
2017-07-02 14:18:17.548985 EDT | MaxEsReturn               167
2017-07-02 14:18:17.549107 EDT | MinEsReturn                 3
2017-07-02 14:18:17.549219 EDT | AverageDiscountedReturn    99.9957
2017-07-02 14:18:17.549446 EDT | AverageQLoss                0.0145287
2017-07-02 14:18:17.549679 EDT | AveragePolicySurr          -2.08612
2017-07-02 14:18:17.549880 EDT | AverageQ                    1.94863
2017-07-02 14:18:17.550136 EDT | AverageAbsQ                 1.95437
2017-07-02 14:18:17.550382 EDT | AverageY                    1.94879
2017-07-02 14:18:17.550620 EDT | AverageAbsY                 1.94956
2017-07-02 14:18:17.550833 EDT | AverageAbsQYDiff            0.0380342
2017-07-02 14:18:17.551067 EDT | AverageAction               0.841076
2017-07-02 14:18:17.551297 EDT | PolicyRegParamNorm         55.817
2017-07-02 14:18:17.551529 EDT | QFunRegParamNorm           57.0374
2017-07-02 14:18:17.551754 EDT | -----------------------  ------------
2017-07-02 14:18:17.552082 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #438 | Training started
2017-07-02 14:18:27.110031 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #438 | Training finished
2017-07-02 14:18:27.110616 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #438 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 14:18:27.110783 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #438 | Collecting samples for evaluation
2017-07-02 14:18:32.854027 EDT | -----------------------  ------------
2017-07-02 14:18:32.854520 EDT | Epoch                     438
2017-07-02 14:18:32.854667 EDT | Iteration                 438
2017-07-02 14:18:32.854789 EDT | AverageReturn            1000
2017-07-02 14:18:32.854908 EDT | StdReturn                   0
2017-07-02 14:18:32.855019 EDT | MaxReturn                1000
2017-07-02 14:18:32.855178 EDT | MinReturn                1000
2017-07-02 14:18:32.855300 EDT | AverageEsReturn            16.9153
2017-07-02 14:18:32.855462 EDT | StdEsReturn                23.7803
2017-07-02 14:18:32.855575 EDT | MaxEsReturn               105
2017-07-02 14:18:32.855690 EDT | MinEsReturn                 2
2017-07-02 14:18:32.855837 EDT | AverageDiscountedReturn    99.9957
2017-07-02 14:18:32.855968 EDT | AverageQLoss                0.014128
2017-07-02 14:18:32.856071 EDT | AveragePolicySurr          -2.10099
2017-07-02 14:18:32.856277 EDT | AverageQ                    1.96047
2017-07-02 14:18:32.856402 EDT | AverageAbsQ                 1.96608
2017-07-02 14:18:32.856510 EDT | AverageY                    1.96054
2017-07-02 14:18:32.856612 EDT | AverageAbsY                 1.96147
2017-07-02 14:18:32.856811 EDT | AverageAbsQYDiff            0.0389353
2017-07-02 14:18:32.857049 EDT | AverageAction               0.865224
2017-07-02 14:18:32.857283 EDT | PolicyRegParamNorm         55.8748
2017-07-02 14:18:32.857472 EDT | QFunRegParamNorm           57.0947
2017-07-02 14:18:32.857630 EDT | -----------------------  ------------
2017-07-02 14:18:32.857862 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #439 | Training started
2017-07-02 14:18:42.387569 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #439 | Training finished
2017-07-02 14:18:42.388267 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #439 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 14:18:42.388519 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #439 | Collecting samples for evaluation
2017-07-02 14:18:48.149850 EDT | -----------------------  ------------
2017-07-02 14:18:48.150043 EDT | Epoch                     439
2017-07-02 14:18:48.150195 EDT | Iteration                 439
2017-07-02 14:18:48.150305 EDT | AverageReturn            1000
2017-07-02 14:18:48.150418 EDT | StdReturn                   0
2017-07-02 14:18:48.150641 EDT | MaxReturn                1000
2017-07-02 14:18:48.150820 EDT | MinReturn                1000
2017-07-02 14:18:48.151008 EDT | AverageEsReturn            22.2391
2017-07-02 14:18:48.151189 EDT | StdEsReturn                27.9559
2017-07-02 14:18:48.151317 EDT | MaxEsReturn               136
2017-07-02 14:18:48.151467 EDT | MinEsReturn                 3
2017-07-02 14:18:48.151569 EDT | AverageDiscountedReturn    99.9957
2017-07-02 14:18:48.151669 EDT | AverageQLoss                0.0148124
2017-07-02 14:18:48.151798 EDT | AveragePolicySurr          -2.11557
2017-07-02 14:18:48.151938 EDT | AverageQ                    1.97619
2017-07-02 14:18:48.152040 EDT | AverageAbsQ                 1.98263
2017-07-02 14:18:48.152142 EDT | AverageY                    1.97623
2017-07-02 14:18:48.152242 EDT | AverageAbsY                 1.97728
2017-07-02 14:18:48.152369 EDT | AverageAbsQYDiff            0.0398795
2017-07-02 14:18:48.152497 EDT | AverageAction               0.736259
2017-07-02 14:18:48.152600 EDT | PolicyRegParamNorm         55.959
2017-07-02 14:18:48.152770 EDT | QFunRegParamNorm           57.1368
2017-07-02 14:18:48.152909 EDT | -----------------------  ------------
2017-07-02 14:18:48.153099 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #440 | Training started
2017-07-02 14:18:57.567210 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #440 | Training finished
2017-07-02 14:18:57.568372 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #440 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 14:18:57.568531 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #440 | Collecting samples for evaluation
2017-07-02 14:19:03.332025 EDT | -----------------------  ------------
2017-07-02 14:19:03.332249 EDT | Epoch                     440
2017-07-02 14:19:03.332359 EDT | Iteration                 440
2017-07-02 14:19:03.332463 EDT | AverageReturn            1000
2017-07-02 14:19:03.332566 EDT | StdReturn                   0
2017-07-02 14:19:03.332684 EDT | MaxReturn                1000
2017-07-02 14:19:03.332786 EDT | MinReturn                1000
2017-07-02 14:19:03.332886 EDT | AverageEsReturn            29.3143
2017-07-02 14:19:03.332987 EDT | StdEsReturn                46.6273
2017-07-02 14:19:03.333128 EDT | MaxEsReturn               225
2017-07-02 14:19:03.333245 EDT | MinEsReturn                 3
2017-07-02 14:19:03.333370 EDT | AverageDiscountedReturn    99.9957
2017-07-02 14:19:03.333503 EDT | AverageQLoss                0.0133489
2017-07-02 14:19:03.333609 EDT | AveragePolicySurr          -2.13461
2017-07-02 14:19:03.333742 EDT | AverageQ                    1.99371
2017-07-02 14:19:03.333856 EDT | AverageAbsQ                 1.99909
2017-07-02 14:19:03.333961 EDT | AverageY                    1.9938
2017-07-02 14:19:03.334062 EDT | AverageAbsY                 1.99466
2017-07-02 14:19:03.334175 EDT | AverageAbsQYDiff            0.03669
2017-07-02 14:19:03.334299 EDT | AverageAction               0.791508
2017-07-02 14:19:03.334401 EDT | PolicyRegParamNorm         56.024
2017-07-02 14:19:03.334513 EDT | QFunRegParamNorm           57.1287
2017-07-02 14:19:03.334617 EDT | -----------------------  ------------
2017-07-02 14:19:03.334806 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #441 | Training started
2017-07-02 14:19:12.810920 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #441 | Training finished
2017-07-02 14:19:12.811405 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #441 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 14:19:12.811535 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #441 | Collecting samples for evaluation
2017-07-02 14:19:18.585163 EDT | -----------------------  ------------
2017-07-02 14:19:18.585463 EDT | Epoch                     441
2017-07-02 14:19:18.585711 EDT | Iteration                 441
2017-07-02 14:19:18.585934 EDT | AverageReturn            1000
2017-07-02 14:19:18.586156 EDT | StdReturn                   0
2017-07-02 14:19:18.586343 EDT | MaxReturn                1000
2017-07-02 14:19:18.586539 EDT | MinReturn                1000
2017-07-02 14:19:18.586740 EDT | AverageEsReturn            21.2955
2017-07-02 14:19:18.586847 EDT | StdEsReturn                37.8055
2017-07-02 14:19:18.587056 EDT | MaxEsReturn               227
2017-07-02 14:19:18.587278 EDT | MinEsReturn                 3
2017-07-02 14:19:18.587420 EDT | AverageDiscountedReturn    99.9957
2017-07-02 14:19:18.587528 EDT | AverageQLoss                0.0156997
2017-07-02 14:19:18.587630 EDT | AveragePolicySurr          -2.14698
2017-07-02 14:19:18.587732 EDT | AverageQ                    2.00963
2017-07-02 14:19:18.587834 EDT | AverageAbsQ                 2.01547
2017-07-02 14:19:18.587934 EDT | AverageY                    2.0096
2017-07-02 14:19:18.588034 EDT | AverageAbsY                 2.01034
2017-07-02 14:19:18.588133 EDT | AverageAbsQYDiff            0.0397602
2017-07-02 14:19:18.588233 EDT | AverageAction               0.0225932
2017-07-02 14:19:18.588333 EDT | PolicyRegParamNorm         56.1236
2017-07-02 14:19:18.588451 EDT | QFunRegParamNorm           57.1521
2017-07-02 14:19:18.588581 EDT | -----------------------  ------------
2017-07-02 14:19:18.588895 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #442 | Training started
2017-07-02 14:19:28.092828 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #442 | Training finished
2017-07-02 14:19:28.093714 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #442 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 14:19:28.093876 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #442 | Collecting samples for evaluation
2017-07-02 14:19:33.760520 EDT | -----------------------  ------------
2017-07-02 14:19:33.760807 EDT | Epoch                     442
2017-07-02 14:19:33.761003 EDT | Iteration                 442
2017-07-02 14:19:33.761114 EDT | AverageReturn            1000
2017-07-02 14:19:33.761289 EDT | StdReturn                   0
2017-07-02 14:19:33.761421 EDT | MaxReturn                1000
2017-07-02 14:19:33.761572 EDT | MinReturn                1000
2017-07-02 14:19:33.761761 EDT | AverageEsReturn            26.7179
2017-07-02 14:19:33.761867 EDT | StdEsReturn                37.3397
2017-07-02 14:19:33.762019 EDT | MaxEsReturn               161
2017-07-02 14:19:33.762164 EDT | MinEsReturn                 3
2017-07-02 14:19:33.762268 EDT | AverageDiscountedReturn    99.9957
2017-07-02 14:19:33.762393 EDT | AverageQLoss                0.0155529
2017-07-02 14:19:33.762539 EDT | AveragePolicySurr          -2.15924
2017-07-02 14:19:33.762656 EDT | AverageQ                    2.01628
2017-07-02 14:19:33.762771 EDT | AverageAbsQ                 2.0223
2017-07-02 14:19:33.762959 EDT | AverageY                    2.01637
2017-07-02 14:19:33.763137 EDT | AverageAbsY                 2.0171
2017-07-02 14:19:33.763330 EDT | AverageAbsQYDiff            0.0398127
2017-07-02 14:19:33.763534 EDT | AverageAction               0.808289
2017-07-02 14:19:33.763722 EDT | PolicyRegParamNorm         56.1263
2017-07-02 14:19:33.763867 EDT | QFunRegParamNorm           57.1805
2017-07-02 14:19:33.764074 EDT | -----------------------  ------------
2017-07-02 14:19:33.764355 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #443 | Training started
2017-07-02 14:19:43.492880 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #443 | Training finished
2017-07-02 14:19:43.493502 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #443 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 14:19:43.493689 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #443 | Collecting samples for evaluation
2017-07-02 14:19:49.218793 EDT | -----------------------  ------------
2017-07-02 14:19:49.219064 EDT | Epoch                     443
2017-07-02 14:19:49.219243 EDT | Iteration                 443
2017-07-02 14:19:49.219378 EDT | AverageReturn            1000
2017-07-02 14:19:49.219585 EDT | StdReturn                   0
2017-07-02 14:19:49.219741 EDT | MaxReturn                1000
2017-07-02 14:19:49.219930 EDT | MinReturn                1000
2017-07-02 14:19:49.220038 EDT | AverageEsReturn            22.7778
2017-07-02 14:19:49.220189 EDT | StdEsReturn                34.8845
2017-07-02 14:19:49.220324 EDT | MaxEsReturn               179
2017-07-02 14:19:49.220429 EDT | MinEsReturn                 3
2017-07-02 14:19:49.220558 EDT | AverageDiscountedReturn    99.9957
2017-07-02 14:19:49.220703 EDT | AverageQLoss                0.0166443
2017-07-02 14:19:49.220807 EDT | AveragePolicySurr          -2.16813
2017-07-02 14:19:49.220906 EDT | AverageQ                    2.02882
2017-07-02 14:19:49.221003 EDT | AverageAbsQ                 2.03495
2017-07-02 14:19:49.221100 EDT | AverageY                    2.02884
2017-07-02 14:19:49.221215 EDT | AverageAbsY                 2.02924
2017-07-02 14:19:49.221329 EDT | AverageAbsQYDiff            0.0426129
2017-07-02 14:19:49.221441 EDT | AverageAction               0.797516
2017-07-02 14:19:49.221639 EDT | PolicyRegParamNorm         56.1312
2017-07-02 14:19:49.221742 EDT | QFunRegParamNorm           57.2152
2017-07-02 14:19:49.221839 EDT | -----------------------  ------------
2017-07-02 14:19:49.222027 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #444 | Training started
2017-07-02 14:19:58.771188 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #444 | Training finished
2017-07-02 14:19:58.771698 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #444 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 14:19:58.771900 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #444 | Collecting samples for evaluation
2017-07-02 14:20:04.483142 EDT | -----------------------  ------------
2017-07-02 14:20:04.483430 EDT | Epoch                     444
2017-07-02 14:20:04.483631 EDT | Iteration                 444
2017-07-02 14:20:04.483847 EDT | AverageReturn            1000
2017-07-02 14:20:04.484076 EDT | StdReturn                   0
2017-07-02 14:20:04.484220 EDT | MaxReturn                1000
2017-07-02 14:20:04.484367 EDT | MinReturn                1000
2017-07-02 14:20:04.484473 EDT | AverageEsReturn            25.9459
2017-07-02 14:20:04.484657 EDT | StdEsReturn                33.9618
2017-07-02 14:20:04.484849 EDT | MaxEsReturn               152
2017-07-02 14:20:04.485010 EDT | MinEsReturn                 3
2017-07-02 14:20:04.485139 EDT | AverageDiscountedReturn    99.9957
2017-07-02 14:20:04.485243 EDT | AverageQLoss                0.0173851
2017-07-02 14:20:04.485373 EDT | AveragePolicySurr          -2.18182
2017-07-02 14:20:04.485611 EDT | AverageQ                    2.03936
2017-07-02 14:20:04.485769 EDT | AverageAbsQ                 2.04489
2017-07-02 14:20:04.485889 EDT | AverageY                    2.03956
2017-07-02 14:20:04.486000 EDT | AverageAbsY                 2.03975
2017-07-02 14:20:04.486110 EDT | AverageAbsQYDiff            0.0398043
2017-07-02 14:20:04.486210 EDT | AverageAction               0.854669
2017-07-02 14:20:04.486310 EDT | PolicyRegParamNorm         56.1842
2017-07-02 14:20:04.486409 EDT | QFunRegParamNorm           57.2348
2017-07-02 14:20:04.486508 EDT | -----------------------  ------------
2017-07-02 14:20:04.486742 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #445 | Training started
2017-07-02 14:20:13.944747 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #445 | Training finished
2017-07-02 14:20:13.945258 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #445 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 14:20:13.945450 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #445 | Collecting samples for evaluation
2017-07-02 14:20:19.949701 EDT | -----------------------  ------------
2017-07-02 14:20:19.949952 EDT | Epoch                     445
2017-07-02 14:20:19.950123 EDT | Iteration                 445
2017-07-02 14:20:19.950335 EDT | AverageReturn            1000
2017-07-02 14:20:19.950534 EDT | StdReturn                   0
2017-07-02 14:20:19.950655 EDT | MaxReturn                1000
2017-07-02 14:20:19.950780 EDT | MinReturn                1000
2017-07-02 14:20:19.950890 EDT | AverageEsReturn            16.8772
2017-07-02 14:20:19.950993 EDT | StdEsReturn                20.6407
2017-07-02 14:20:19.951122 EDT | MaxEsReturn                81
2017-07-02 14:20:19.951230 EDT | MinEsReturn                 3
2017-07-02 14:20:19.951331 EDT | AverageDiscountedReturn    99.9957
2017-07-02 14:20:19.951431 EDT | AverageQLoss                0.0169411
2017-07-02 14:20:19.951530 EDT | AveragePolicySurr          -2.18942
2017-07-02 14:20:19.951633 EDT | AverageQ                    2.04743
2017-07-02 14:20:19.951778 EDT | AverageAbsQ                 2.05368
2017-07-02 14:20:19.951900 EDT | AverageY                    2.04746
2017-07-02 14:20:19.952037 EDT | AverageAbsY                 2.04775
2017-07-02 14:20:19.952239 EDT | AverageAbsQYDiff            0.0417539
2017-07-02 14:20:19.952440 EDT | AverageAction               0.872598
2017-07-02 14:20:19.952640 EDT | PolicyRegParamNorm         56.2342
2017-07-02 14:20:19.952841 EDT | QFunRegParamNorm           57.2269
2017-07-02 14:20:19.952994 EDT | -----------------------  ------------
2017-07-02 14:20:19.953284 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #446 | Training started
2017-07-02 14:20:29.696620 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #446 | Training finished
2017-07-02 14:20:29.697195 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #446 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 14:20:29.697333 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #446 | Collecting samples for evaluation
2017-07-02 14:20:35.443922 EDT | -----------------------  ------------
2017-07-02 14:20:35.444130 EDT | Epoch                     446
2017-07-02 14:20:35.444257 EDT | Iteration                 446
2017-07-02 14:20:35.444400 EDT | AverageReturn            1000
2017-07-02 14:20:35.444589 EDT | StdReturn                   0
2017-07-02 14:20:35.444757 EDT | MaxReturn                1000
2017-07-02 14:20:35.444940 EDT | MinReturn                1000
2017-07-02 14:20:35.445113 EDT | AverageEsReturn            19.3774
2017-07-02 14:20:35.445305 EDT | StdEsReturn                29.6401
2017-07-02 14:20:35.445475 EDT | MaxEsReturn               165
2017-07-02 14:20:35.445670 EDT | MinEsReturn                 3
2017-07-02 14:20:35.445839 EDT | AverageDiscountedReturn    99.9957
2017-07-02 14:20:35.446014 EDT | AverageQLoss                0.0172342
2017-07-02 14:20:35.446211 EDT | AveragePolicySurr          -2.19903
2017-07-02 14:20:35.446402 EDT | AverageQ                    2.0554
2017-07-02 14:20:35.446604 EDT | AverageAbsQ                 2.06117
2017-07-02 14:20:35.446736 EDT | AverageY                    2.05544
2017-07-02 14:20:35.446898 EDT | AverageAbsY                 2.05572
2017-07-02 14:20:35.447001 EDT | AverageAbsQYDiff            0.0409249
2017-07-02 14:20:35.447122 EDT | AverageAction               0.875248
2017-07-02 14:20:35.447223 EDT | PolicyRegParamNorm         56.2792
2017-07-02 14:20:35.447325 EDT | QFunRegParamNorm           57.2566
2017-07-02 14:20:35.447439 EDT | -----------------------  ------------
2017-07-02 14:20:35.447678 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #447 | Training started
2017-07-02 14:20:44.842277 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #447 | Training finished
2017-07-02 14:20:44.843022 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #447 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 14:20:44.843287 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #447 | Collecting samples for evaluation
2017-07-02 14:20:50.623497 EDT | -----------------------  ------------
2017-07-02 14:20:50.623780 EDT | Epoch                     447
2017-07-02 14:20:50.624013 EDT | Iteration                 447
2017-07-02 14:20:50.624243 EDT | AverageReturn            1000
2017-07-02 14:20:50.624465 EDT | StdReturn                   0
2017-07-02 14:20:50.624688 EDT | MaxReturn                1000
2017-07-02 14:20:50.624906 EDT | MinReturn                1000
2017-07-02 14:20:50.625079 EDT | AverageEsReturn            23.1111
2017-07-02 14:20:50.625300 EDT | StdEsReturn                29.8129
2017-07-02 14:20:50.625475 EDT | MaxEsReturn               173
2017-07-02 14:20:50.625726 EDT | MinEsReturn                 3
2017-07-02 14:20:50.625951 EDT | AverageDiscountedReturn    99.9957
2017-07-02 14:20:50.626171 EDT | AverageQLoss                0.0174419
2017-07-02 14:20:50.626390 EDT | AveragePolicySurr          -2.2088
2017-07-02 14:20:50.626591 EDT | AverageQ                    2.06612
2017-07-02 14:20:50.626781 EDT | AverageAbsQ                 2.07137
2017-07-02 14:20:50.627003 EDT | AverageY                    2.06626
2017-07-02 14:20:50.627174 EDT | AverageAbsY                 2.06663
2017-07-02 14:20:50.627390 EDT | AverageAbsQYDiff            0.0403861
2017-07-02 14:20:50.627604 EDT | AverageAction               0.874588
2017-07-02 14:20:50.627830 EDT | PolicyRegParamNorm         56.3783
2017-07-02 14:20:50.627974 EDT | QFunRegParamNorm           57.2718
2017-07-02 14:20:50.628169 EDT | -----------------------  ------------
2017-07-02 14:20:50.628435 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #448 | Training started
2017-07-02 14:21:00.116781 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #448 | Training finished
2017-07-02 14:21:00.117326 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #448 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 14:21:00.117480 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #448 | Collecting samples for evaluation
2017-07-02 14:21:05.860182 EDT | -----------------------  ------------
2017-07-02 14:21:05.860478 EDT | Epoch                     448
2017-07-02 14:21:05.860727 EDT | Iteration                 448
2017-07-02 14:21:05.860959 EDT | AverageReturn            1000
2017-07-02 14:21:05.861188 EDT | StdReturn                   0
2017-07-02 14:21:05.861399 EDT | MaxReturn                1000
2017-07-02 14:21:05.861644 EDT | MinReturn                1000
2017-07-02 14:21:05.861831 EDT | AverageEsReturn            26
2017-07-02 14:21:05.861939 EDT | StdEsReturn                39.4562
2017-07-02 14:21:05.862043 EDT | MaxEsReturn               192
2017-07-02 14:21:05.862146 EDT | MinEsReturn                 3
2017-07-02 14:21:05.862248 EDT | AverageDiscountedReturn    99.9957
2017-07-02 14:21:05.862348 EDT | AverageQLoss                0.0165282
2017-07-02 14:21:05.862447 EDT | AveragePolicySurr          -2.21926
2017-07-02 14:21:05.862545 EDT | AverageQ                    2.07968
2017-07-02 14:21:05.862753 EDT | AverageAbsQ                 2.08475
2017-07-02 14:21:05.862957 EDT | AverageY                    2.07974
2017-07-02 14:21:05.863063 EDT | AverageAbsY                 2.08013
2017-07-02 14:21:05.863197 EDT | AverageAbsQYDiff            0.0390162
2017-07-02 14:21:05.863424 EDT | AverageAction               0.865196
2017-07-02 14:21:05.863631 EDT | PolicyRegParamNorm         56.4405
2017-07-02 14:21:05.863850 EDT | QFunRegParamNorm           57.2983
2017-07-02 14:21:05.864084 EDT | -----------------------  ------------
2017-07-02 14:21:05.864409 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #449 | Training started
2017-07-02 14:21:15.343751 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #449 | Training finished
2017-07-02 14:21:15.344252 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #449 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 14:21:15.344452 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #449 | Collecting samples for evaluation
2017-07-02 14:21:21.058578 EDT | -----------------------  ------------
2017-07-02 14:21:21.058904 EDT | Epoch                     449
2017-07-02 14:21:21.059138 EDT | Iteration                 449
2017-07-02 14:21:21.059354 EDT | AverageReturn            1000
2017-07-02 14:21:21.059470 EDT | StdReturn                   0
2017-07-02 14:21:21.059586 EDT | MaxReturn                1000
2017-07-02 14:21:21.059722 EDT | MinReturn                1000
2017-07-02 14:21:21.059832 EDT | AverageEsReturn            33.7333
2017-07-02 14:21:21.059935 EDT | StdEsReturn                43.2573
2017-07-02 14:21:21.060037 EDT | MaxEsReturn               223
2017-07-02 14:21:21.060137 EDT | MinEsReturn                 3
2017-07-02 14:21:21.060908 EDT | AverageDiscountedReturn    99.9957
2017-07-02 14:21:21.061057 EDT | AverageQLoss                0.0197023
2017-07-02 14:21:21.061166 EDT | AveragePolicySurr          -2.22731
2017-07-02 14:21:21.061271 EDT | AverageQ                    2.08718
2017-07-02 14:21:21.061444 EDT | AverageAbsQ                 2.09317
2017-07-02 14:21:21.061669 EDT | AverageY                    2.08728
2017-07-02 14:21:21.061884 EDT | AverageAbsY                 2.08748
2017-07-02 14:21:21.062110 EDT | AverageAbsQYDiff            0.0430577
2017-07-02 14:21:21.062319 EDT | AverageAction               0.943596
2017-07-02 14:21:21.062545 EDT | PolicyRegParamNorm         56.502
2017-07-02 14:21:21.062772 EDT | QFunRegParamNorm           57.3316
2017-07-02 14:21:21.062995 EDT | -----------------------  ------------
2017-07-02 14:21:21.063297 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #450 | Training started
2017-07-02 14:21:30.531351 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #450 | Training finished
2017-07-02 14:21:30.531890 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #450 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 14:21:30.532166 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #450 | Collecting samples for evaluation
2017-07-02 14:21:36.345049 EDT | -----------------------  ------------
2017-07-02 14:21:36.345317 EDT | Epoch                     450
2017-07-02 14:21:36.345429 EDT | Iteration                 450
2017-07-02 14:21:36.345558 EDT | AverageReturn            1000
2017-07-02 14:21:36.345687 EDT | StdReturn                   0
2017-07-02 14:21:36.345792 EDT | MaxReturn                1000
2017-07-02 14:21:36.345894 EDT | MinReturn                1000
2017-07-02 14:21:36.345996 EDT | AverageEsReturn            16.3115
2017-07-02 14:21:36.346111 EDT | StdEsReturn                16.2889
2017-07-02 14:21:36.346304 EDT | MaxEsReturn                71
2017-07-02 14:21:36.346433 EDT | MinEsReturn                 3
2017-07-02 14:21:36.346600 EDT | AverageDiscountedReturn    99.9957
2017-07-02 14:21:36.346805 EDT | AverageQLoss                0.0147781
2017-07-02 14:21:36.346963 EDT | AveragePolicySurr          -2.23392
2017-07-02 14:21:36.347131 EDT | AverageQ                    2.09372
2017-07-02 14:21:36.347318 EDT | AverageAbsQ                 2.09816
2017-07-02 14:21:36.347424 EDT | AverageY                    2.09384
2017-07-02 14:21:36.347527 EDT | AverageAbsY                 2.09404
2017-07-02 14:21:36.347686 EDT | AverageAbsQYDiff            0.037284
2017-07-02 14:21:36.347914 EDT | AverageAction               0.858935
2017-07-02 14:21:36.348129 EDT | PolicyRegParamNorm         56.5698
2017-07-02 14:21:36.348356 EDT | QFunRegParamNorm           57.3431
2017-07-02 14:21:36.348581 EDT | -----------------------  ------------
2017-07-02 14:21:36.348902 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #451 | Training started
2017-07-02 14:21:45.833137 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #451 | Training finished
2017-07-02 14:21:45.843286 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #451 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 14:21:45.843514 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #451 | Collecting samples for evaluation
2017-07-02 14:21:51.639142 EDT | -----------------------  ------------
2017-07-02 14:21:51.639350 EDT | Epoch                     451
2017-07-02 14:21:51.639462 EDT | Iteration                 451
2017-07-02 14:21:51.639655 EDT | AverageReturn            1000
2017-07-02 14:21:51.639864 EDT | StdReturn                   0
2017-07-02 14:21:51.640061 EDT | MaxReturn                1000
2017-07-02 14:21:51.640237 EDT | MinReturn                1000
2017-07-02 14:21:51.640363 EDT | AverageEsReturn            15.3939
2017-07-02 14:21:51.640563 EDT | StdEsReturn                22.2103
2017-07-02 14:21:51.640686 EDT | MaxEsReturn               123
2017-07-02 14:21:51.640800 EDT | MinEsReturn                 3
2017-07-02 14:21:51.640918 EDT | AverageDiscountedReturn    99.9957
2017-07-02 14:21:51.641043 EDT | AverageQLoss                0.0159355
2017-07-02 14:21:51.641190 EDT | AveragePolicySurr          -2.24293
2017-07-02 14:21:51.641293 EDT | AverageQ                    2.10525
2017-07-02 14:21:51.641394 EDT | AverageAbsQ                 2.11
2017-07-02 14:21:51.641518 EDT | AverageY                    2.10524
2017-07-02 14:21:51.641687 EDT | AverageAbsY                 2.1055
2017-07-02 14:21:51.641790 EDT | AverageAbsQYDiff            0.0381526
2017-07-02 14:21:51.641903 EDT | AverageAction               0.868621
2017-07-02 14:21:51.642082 EDT | PolicyRegParamNorm         56.6322
2017-07-02 14:21:51.642228 EDT | QFunRegParamNorm           57.3923
2017-07-02 14:21:51.642333 EDT | -----------------------  ------------
2017-07-02 14:21:51.642500 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #452 | Training started
2017-07-02 14:22:01.093787 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #452 | Training finished
2017-07-02 14:22:01.094334 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #452 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 14:22:01.094476 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #452 | Collecting samples for evaluation
2017-07-02 14:22:06.811058 EDT | -----------------------  ------------
2017-07-02 14:22:06.811273 EDT | Epoch                     452
2017-07-02 14:22:06.811501 EDT | Iteration                 452
2017-07-02 14:22:06.811692 EDT | AverageReturn            1000
2017-07-02 14:22:06.811917 EDT | StdReturn                   0
2017-07-02 14:22:06.812115 EDT | MaxReturn                1000
2017-07-02 14:22:06.812350 EDT | MinReturn                1000
2017-07-02 14:22:06.812576 EDT | AverageEsReturn            32.0667
2017-07-02 14:22:06.812797 EDT | StdEsReturn                34.917
2017-07-02 14:22:06.812989 EDT | MaxEsReturn               146
2017-07-02 14:22:06.813205 EDT | MinEsReturn                 3
2017-07-02 14:22:06.813398 EDT | AverageDiscountedReturn    99.9957
2017-07-02 14:22:06.813520 EDT | AverageQLoss                0.0159311
2017-07-02 14:22:06.813626 EDT | AveragePolicySurr          -2.2483
2017-07-02 14:22:06.813730 EDT | AverageQ                    2.10771
2017-07-02 14:22:06.813833 EDT | AverageAbsQ                 2.11301
2017-07-02 14:22:06.813934 EDT | AverageY                    2.10783
2017-07-02 14:22:06.814033 EDT | AverageAbsY                 2.10811
2017-07-02 14:22:06.814133 EDT | AverageAbsQYDiff            0.0389811
2017-07-02 14:22:06.814233 EDT | AverageAction               0.947978
2017-07-02 14:22:06.814390 EDT | PolicyRegParamNorm         56.662
2017-07-02 14:22:06.814603 EDT | QFunRegParamNorm           57.4252
2017-07-02 14:22:06.814784 EDT | -----------------------  ------------
2017-07-02 14:22:06.815105 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #453 | Training started
2017-07-02 14:22:16.393469 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #453 | Training finished
2017-07-02 14:22:16.394179 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #453 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 14:22:16.394485 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #453 | Collecting samples for evaluation
2017-07-02 14:22:22.109081 EDT | -----------------------  ------------
2017-07-02 14:22:22.109399 EDT | Epoch                     453
2017-07-02 14:22:22.109646 EDT | Iteration                 453
2017-07-02 14:22:22.109875 EDT | AverageReturn            1000
2017-07-02 14:22:22.110023 EDT | StdReturn                   0
2017-07-02 14:22:22.110244 EDT | MaxReturn                1000
2017-07-02 14:22:22.110417 EDT | MinReturn                1000
2017-07-02 14:22:22.110524 EDT | AverageEsReturn            37.9259
2017-07-02 14:22:22.110665 EDT | StdEsReturn                39.7641
2017-07-02 14:22:22.110843 EDT | MaxEsReturn               200
2017-07-02 14:22:22.111065 EDT | MinEsReturn                 4
2017-07-02 14:22:22.111290 EDT | AverageDiscountedReturn    99.9957
2017-07-02 14:22:22.111408 EDT | AverageQLoss                0.0170965
2017-07-02 14:22:22.111513 EDT | AveragePolicySurr          -2.25183
2017-07-02 14:22:22.111621 EDT | AverageQ                    2.11363
2017-07-02 14:22:22.111729 EDT | AverageAbsQ                 2.11894
2017-07-02 14:22:22.111836 EDT | AverageY                    2.11357
2017-07-02 14:22:22.111949 EDT | AverageAbsY                 2.11392
2017-07-02 14:22:22.112168 EDT | AverageAbsQYDiff            0.0393056
2017-07-02 14:22:22.112376 EDT | AverageAction               0.954364
2017-07-02 14:22:22.112607 EDT | PolicyRegParamNorm         56.6956
2017-07-02 14:22:22.112814 EDT | QFunRegParamNorm           57.4447
2017-07-02 14:22:22.113042 EDT | -----------------------  ------------
2017-07-02 14:22:22.113362 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #454 | Training started
2017-07-02 14:22:31.648829 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #454 | Training finished
2017-07-02 14:22:31.649450 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #454 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 14:22:31.649714 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #454 | Collecting samples for evaluation
2017-07-02 14:22:37.309898 EDT | -----------------------  ------------
2017-07-02 14:22:37.310213 EDT | Epoch                     454
2017-07-02 14:22:37.310451 EDT | Iteration                 454
2017-07-02 14:22:37.310646 EDT | AverageReturn            1000
2017-07-02 14:22:37.310880 EDT | StdReturn                   0
2017-07-02 14:22:37.311102 EDT | MaxReturn                1000
2017-07-02 14:22:37.311213 EDT | MinReturn                1000
2017-07-02 14:22:37.311314 EDT | AverageEsReturn            35.2857
2017-07-02 14:22:37.311417 EDT | StdEsReturn                35.114
2017-07-02 14:22:37.311519 EDT | MaxEsReturn               120
2017-07-02 14:22:37.311621 EDT | MinEsReturn                 3
2017-07-02 14:22:37.311739 EDT | AverageDiscountedReturn    99.9957
2017-07-02 14:22:37.311859 EDT | AverageQLoss                0.0177098
2017-07-02 14:22:37.311961 EDT | AveragePolicySurr          -2.25286
2017-07-02 14:22:37.312110 EDT | AverageQ                    2.11186
2017-07-02 14:22:37.312299 EDT | AverageAbsQ                 2.11677
2017-07-02 14:22:37.312406 EDT | AverageY                    2.11198
2017-07-02 14:22:37.312586 EDT | AverageAbsY                 2.11235
2017-07-02 14:22:37.312766 EDT | AverageAbsQYDiff            0.0399013
2017-07-02 14:22:37.312911 EDT | AverageAction               0.953899
2017-07-02 14:22:37.313014 EDT | PolicyRegParamNorm         56.6984
2017-07-02 14:22:37.313115 EDT | QFunRegParamNorm           57.4615
2017-07-02 14:22:37.313251 EDT | -----------------------  ------------
2017-07-02 14:22:37.313431 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #455 | Training started
2017-07-02 14:22:46.897220 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #455 | Training finished
2017-07-02 14:22:46.897805 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #455 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 14:22:46.898079 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #455 | Collecting samples for evaluation
2017-07-02 14:22:52.699604 EDT | -----------------------  ------------
2017-07-02 14:22:52.699795 EDT | Epoch                     455
2017-07-02 14:22:52.699910 EDT | Iteration                 455
2017-07-02 14:22:52.700038 EDT | AverageReturn            1000
2017-07-02 14:22:52.700141 EDT | StdReturn                   0
2017-07-02 14:22:52.700241 EDT | MaxReturn                1000
2017-07-02 14:22:52.700459 EDT | MinReturn                1000
2017-07-02 14:22:52.700676 EDT | AverageEsReturn            23.5814
2017-07-02 14:22:52.700912 EDT | StdEsReturn                21.2047
2017-07-02 14:22:52.701133 EDT | MaxEsReturn               102
2017-07-02 14:22:52.701294 EDT | MinEsReturn                 3
2017-07-02 14:22:52.701401 EDT | AverageDiscountedReturn    99.9957
2017-07-02 14:22:52.701531 EDT | AverageQLoss                0.0184762
2017-07-02 14:22:52.701644 EDT | AveragePolicySurr          -2.25388
2017-07-02 14:22:52.701812 EDT | AverageQ                    2.11675
2017-07-02 14:22:52.701949 EDT | AverageAbsQ                 2.12244
2017-07-02 14:22:52.702134 EDT | AverageY                    2.11678
2017-07-02 14:22:52.702254 EDT | AverageAbsY                 2.11724
2017-07-02 14:22:52.702357 EDT | AverageAbsQYDiff            0.0416186
2017-07-02 14:22:52.702460 EDT | AverageAction               0.911309
2017-07-02 14:22:52.702611 EDT | PolicyRegParamNorm         56.8244
2017-07-02 14:22:52.702715 EDT | QFunRegParamNorm           57.4636
2017-07-02 14:22:52.702838 EDT | -----------------------  ------------
2017-07-02 14:22:52.703005 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #456 | Training started
2017-07-02 14:23:02.137918 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #456 | Training finished
2017-07-02 14:23:02.138449 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #456 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 14:23:02.138650 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #456 | Collecting samples for evaluation
2017-07-02 14:23:07.901576 EDT | -----------------------  ------------
2017-07-02 14:23:07.901825 EDT | Epoch                     456
2017-07-02 14:23:07.901937 EDT | Iteration                 456
2017-07-02 14:23:07.902085 EDT | AverageReturn            1000
2017-07-02 14:23:07.902219 EDT | StdReturn                   0
2017-07-02 14:23:07.902365 EDT | MaxReturn                1000
2017-07-02 14:23:07.902553 EDT | MinReturn                1000
2017-07-02 14:23:07.902736 EDT | AverageEsReturn            36.3704
2017-07-02 14:23:07.902850 EDT | StdEsReturn                52.6464
2017-07-02 14:23:07.902953 EDT | MaxEsReturn               204
2017-07-02 14:23:07.903057 EDT | MinEsReturn                 4
2017-07-02 14:23:07.903192 EDT | AverageDiscountedReturn    99.9957
2017-07-02 14:23:07.903342 EDT | AverageQLoss                0.0171413
2017-07-02 14:23:07.903459 EDT | AveragePolicySurr          -2.26283
2017-07-02 14:23:07.903563 EDT | AverageQ                    2.12485
2017-07-02 14:23:07.903694 EDT | AverageAbsQ                 2.13021
2017-07-02 14:23:07.903823 EDT | AverageY                    2.12502
2017-07-02 14:23:07.903965 EDT | AverageAbsY                 2.12565
2017-07-02 14:23:07.904068 EDT | AverageAbsQYDiff            0.0398653
2017-07-02 14:23:07.904175 EDT | AverageAction               0.914652
2017-07-02 14:23:07.904321 EDT | PolicyRegParamNorm         56.8734
2017-07-02 14:23:07.904451 EDT | QFunRegParamNorm           57.4811
2017-07-02 14:23:07.904567 EDT | -----------------------  ------------
2017-07-02 14:23:07.904847 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #457 | Training started
2017-07-02 14:23:17.287553 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #457 | Training finished
2017-07-02 14:23:17.288155 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #457 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 14:23:17.288333 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #457 | Collecting samples for evaluation
2017-07-02 14:23:23.015225 EDT | -----------------------  ------------
2017-07-02 14:23:23.015448 EDT | Epoch                     457
2017-07-02 14:23:23.015634 EDT | Iteration                 457
2017-07-02 14:23:23.015772 EDT | AverageReturn            1000
2017-07-02 14:23:23.015932 EDT | StdReturn                   0
2017-07-02 14:23:23.016100 EDT | MaxReturn                1000
2017-07-02 14:23:23.016231 EDT | MinReturn                1000
2017-07-02 14:23:23.016412 EDT | AverageEsReturn            26.8158
2017-07-02 14:23:23.016545 EDT | StdEsReturn                31.541
2017-07-02 14:23:23.017366 EDT | MaxEsReturn               143
2017-07-02 14:23:23.017574 EDT | MinEsReturn                 4
2017-07-02 14:23:23.017706 EDT | AverageDiscountedReturn    99.9957
2017-07-02 14:23:23.017844 EDT | AverageQLoss                0.0186683
2017-07-02 14:23:23.017990 EDT | AveragePolicySurr          -2.26247
2017-07-02 14:23:23.018116 EDT | AverageQ                    2.12312
2017-07-02 14:23:23.018249 EDT | AverageAbsQ                 2.12924
2017-07-02 14:23:23.018358 EDT | AverageY                    2.12308
2017-07-02 14:23:23.018490 EDT | AverageAbsY                 2.12379
2017-07-02 14:23:23.018651 EDT | AverageAbsQYDiff            0.0420741
2017-07-02 14:23:23.018759 EDT | AverageAction               0.945854
2017-07-02 14:23:23.018884 EDT | PolicyRegParamNorm         56.924
2017-07-02 14:23:23.019092 EDT | QFunRegParamNorm           57.5195
2017-07-02 14:23:23.019292 EDT | -----------------------  ------------
2017-07-02 14:23:23.019471 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #458 | Training started
2017-07-02 14:23:32.378526 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #458 | Training finished
2017-07-02 14:23:32.379162 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #458 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 14:23:32.379418 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #458 | Collecting samples for evaluation
2017-07-02 14:23:38.160097 EDT | -----------------------  ------------
2017-07-02 14:23:38.160416 EDT | Epoch                     458
2017-07-02 14:23:38.160604 EDT | Iteration                 458
2017-07-02 14:23:38.160835 EDT | AverageReturn            1000
2017-07-02 14:23:38.161041 EDT | StdReturn                   0
2017-07-02 14:23:38.161150 EDT | MaxReturn                1000
2017-07-02 14:23:38.161287 EDT | MinReturn                1000
2017-07-02 14:23:38.161540 EDT | AverageEsReturn            36.8148
2017-07-02 14:23:38.161770 EDT | StdEsReturn                35.4109
2017-07-02 14:23:38.162056 EDT | MaxEsReturn               162
2017-07-02 14:23:38.162284 EDT | MinEsReturn                 6
2017-07-02 14:23:38.162480 EDT | AverageDiscountedReturn    99.9957
2017-07-02 14:23:38.162588 EDT | AverageQLoss                0.0158264
2017-07-02 14:23:38.162735 EDT | AveragePolicySurr          -2.26513
2017-07-02 14:23:38.162976 EDT | AverageQ                    2.12714
2017-07-02 14:23:38.163202 EDT | AverageAbsQ                 2.13195
2017-07-02 14:23:38.163394 EDT | AverageY                    2.12718
2017-07-02 14:23:38.163627 EDT | AverageAbsY                 2.12835
2017-07-02 14:23:38.163855 EDT | AverageAbsQYDiff            0.0387455
2017-07-02 14:23:38.164081 EDT | AverageAction               0.908136
2017-07-02 14:23:38.164304 EDT | PolicyRegParamNorm         57.011
2017-07-02 14:23:38.164524 EDT | QFunRegParamNorm           57.5436
2017-07-02 14:23:38.164729 EDT | -----------------------  ------------
2017-07-02 14:23:38.165024 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #459 | Training started
2017-07-02 14:23:47.697604 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #459 | Training finished
2017-07-02 14:23:47.697769 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #459 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 14:23:47.697886 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #459 | Collecting samples for evaluation
2017-07-02 14:23:53.371889 EDT | -----------------------  ------------
2017-07-02 14:23:53.372484 EDT | Epoch                     459
2017-07-02 14:23:53.372664 EDT | Iteration                 459
2017-07-02 14:23:53.372848 EDT | AverageReturn            1000
2017-07-02 14:23:53.372979 EDT | StdReturn                   0
2017-07-02 14:23:53.373109 EDT | MaxReturn                1000
2017-07-02 14:23:53.373257 EDT | MinReturn                1000
2017-07-02 14:23:53.373383 EDT | AverageEsReturn            36
2017-07-02 14:23:53.373530 EDT | StdEsReturn                36.2097
2017-07-02 14:23:53.373691 EDT | MaxEsReturn               146
2017-07-02 14:23:53.373801 EDT | MinEsReturn                 3
2017-07-02 14:23:53.373901 EDT | AverageDiscountedReturn    99.9957
2017-07-02 14:23:53.374057 EDT | AverageQLoss                0.0203122
2017-07-02 14:23:53.374222 EDT | AveragePolicySurr          -2.27288
2017-07-02 14:23:53.374334 EDT | AverageQ                    2.13028
2017-07-02 14:23:53.374475 EDT | AverageAbsQ                 2.1369
2017-07-02 14:23:53.374617 EDT | AverageY                    2.13032
2017-07-02 14:23:53.374813 EDT | AverageAbsY                 2.13141
2017-07-02 14:23:53.374962 EDT | AverageAbsQYDiff            0.0441712
2017-07-02 14:23:53.375065 EDT | AverageAction               0.89585
2017-07-02 14:23:53.375170 EDT | PolicyRegParamNorm         57.1424
2017-07-02 14:23:53.375305 EDT | QFunRegParamNorm           57.5753
2017-07-02 14:23:53.375433 EDT | -----------------------  ------------
2017-07-02 14:23:53.375657 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #460 | Training started
2017-07-02 14:24:02.924337 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #460 | Training finished
2017-07-02 14:24:02.924993 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #460 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 14:24:02.925244 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #460 | Collecting samples for evaluation
2017-07-02 14:24:08.613578 EDT | -----------------------  ------------
2017-07-02 14:24:08.613987 EDT | Epoch                     460
2017-07-02 14:24:08.614225 EDT | Iteration                 460
2017-07-02 14:24:08.614425 EDT | AverageReturn            1000
2017-07-02 14:24:08.614606 EDT | StdReturn                   0
2017-07-02 14:24:08.614735 EDT | MaxReturn                1000
2017-07-02 14:24:08.614852 EDT | MinReturn                1000
2017-07-02 14:24:08.614955 EDT | AverageEsReturn            31.5862
2017-07-02 14:24:08.615101 EDT | StdEsReturn                36.0713
2017-07-02 14:24:08.615207 EDT | MaxEsReturn               161
2017-07-02 14:24:08.615325 EDT | MinEsReturn                 3
2017-07-02 14:24:08.615500 EDT | AverageDiscountedReturn    99.9957
2017-07-02 14:24:08.615640 EDT | AverageQLoss                0.01518
2017-07-02 14:24:08.615774 EDT | AveragePolicySurr          -2.2761
2017-07-02 14:24:08.615998 EDT | AverageQ                    2.1412
2017-07-02 14:24:08.616307 EDT | AverageAbsQ                 2.14658
2017-07-02 14:24:08.616437 EDT | AverageY                    2.14132
2017-07-02 14:24:08.616646 EDT | AverageAbsY                 2.14236
2017-07-02 14:24:08.616865 EDT | AverageAbsQYDiff            0.0381708
2017-07-02 14:24:08.617018 EDT | AverageAction               0.906586
2017-07-02 14:24:08.617180 EDT | PolicyRegParamNorm         57.1623
2017-07-02 14:24:08.617364 EDT | QFunRegParamNorm           57.5906
2017-07-02 14:24:08.617501 EDT | -----------------------  ------------
2017-07-02 14:24:08.617708 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #461 | Training started
2017-07-02 14:24:18.387652 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #461 | Training finished
2017-07-02 14:24:18.388220 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #461 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 14:24:18.388354 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #461 | Collecting samples for evaluation
2017-07-02 14:24:24.050238 EDT | -----------------------  ------------
2017-07-02 14:24:24.051116 EDT | Epoch                     461
2017-07-02 14:24:24.051533 EDT | Iteration                 461
2017-07-02 14:24:24.051710 EDT | AverageReturn            1000
2017-07-02 14:24:24.051838 EDT | StdReturn                   0
2017-07-02 14:24:24.051955 EDT | MaxReturn                1000
2017-07-02 14:24:24.052138 EDT | MinReturn                1000
2017-07-02 14:24:24.052267 EDT | AverageEsReturn            33.6875
2017-07-02 14:24:24.052391 EDT | StdEsReturn                35.2982
2017-07-02 14:24:24.052551 EDT | MaxEsReturn               131
2017-07-02 14:24:24.052657 EDT | MinEsReturn                 3
2017-07-02 14:24:24.053019 EDT | AverageDiscountedReturn    99.9957
2017-07-02 14:24:24.053140 EDT | AverageQLoss                0.0163914
2017-07-02 14:24:24.053247 EDT | AveragePolicySurr          -2.27409
2017-07-02 14:24:24.053383 EDT | AverageQ                    2.13741
2017-07-02 14:24:24.053539 EDT | AverageAbsQ                 2.14246
2017-07-02 14:24:24.053644 EDT | AverageY                    2.13745
2017-07-02 14:24:24.053748 EDT | AverageAbsY                 2.13817
2017-07-02 14:24:24.053882 EDT | AverageAbsQYDiff            0.0387376
2017-07-02 14:24:24.053985 EDT | AverageAction               0.91322
2017-07-02 14:24:24.054120 EDT | PolicyRegParamNorm         57.196
2017-07-02 14:24:24.054252 EDT | QFunRegParamNorm           57.6136
2017-07-02 14:24:24.054409 EDT | -----------------------  ------------
2017-07-02 14:24:24.054626 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #462 | Training started
2017-07-02 14:24:33.732478 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #462 | Training finished
2017-07-02 14:24:33.732988 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #462 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 14:24:33.733223 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #462 | Collecting samples for evaluation
2017-07-02 14:24:39.478942 EDT | -----------------------  ------------
2017-07-02 14:24:39.479190 EDT | Epoch                     462
2017-07-02 14:24:39.479310 EDT | Iteration                 462
2017-07-02 14:24:39.479417 EDT | AverageReturn            1000
2017-07-02 14:24:39.479554 EDT | StdReturn                   0
2017-07-02 14:24:39.479687 EDT | MaxReturn                1000
2017-07-02 14:24:39.479858 EDT | MinReturn                1000
2017-07-02 14:24:39.479977 EDT | AverageEsReturn            28.9429
2017-07-02 14:24:39.480130 EDT | StdEsReturn                47.8318
2017-07-02 14:24:39.480259 EDT | MaxEsReturn               224
2017-07-02 14:24:39.480407 EDT | MinEsReturn                 3
2017-07-02 14:24:39.480610 EDT | AverageDiscountedReturn    99.9957
2017-07-02 14:24:39.480783 EDT | AverageQLoss                0.0205229
2017-07-02 14:24:39.480963 EDT | AveragePolicySurr          -2.27217
2017-07-02 14:24:39.481166 EDT | AverageQ                    2.12901
2017-07-02 14:24:39.481293 EDT | AverageAbsQ                 2.13503
2017-07-02 14:24:39.481417 EDT | AverageY                    2.12908
2017-07-02 14:24:39.482143 EDT | AverageAbsY                 2.12968
2017-07-02 14:24:39.482324 EDT | AverageAbsQYDiff            0.0432762
2017-07-02 14:24:39.482436 EDT | AverageAction               0.89189
2017-07-02 14:24:39.482542 EDT | PolicyRegParamNorm         57.3096
2017-07-02 14:24:39.482677 EDT | QFunRegParamNorm           57.6359
2017-07-02 14:24:39.482872 EDT | -----------------------  ------------
2017-07-02 14:24:39.483046 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #463 | Training started
2017-07-02 14:24:49.119958 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #463 | Training finished
2017-07-02 14:24:49.120566 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #463 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 14:24:49.120754 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #463 | Collecting samples for evaluation
2017-07-02 14:24:54.843559 EDT | -----------------------  ------------
2017-07-02 14:24:54.844046 EDT | Epoch                     463
2017-07-02 14:24:54.844214 EDT | Iteration                 463
2017-07-02 14:24:54.844340 EDT | AverageReturn            1000
2017-07-02 14:24:54.844514 EDT | StdReturn                   0
2017-07-02 14:24:54.844670 EDT | MaxReturn                1000
2017-07-02 14:24:54.844875 EDT | MinReturn                1000
2017-07-02 14:24:54.845051 EDT | AverageEsReturn            29.4848
2017-07-02 14:24:54.845199 EDT | StdEsReturn                24.9838
2017-07-02 14:24:54.845391 EDT | MaxEsReturn               106
2017-07-02 14:24:54.845541 EDT | MinEsReturn                 3
2017-07-02 14:24:54.845713 EDT | AverageDiscountedReturn    99.9957
2017-07-02 14:24:54.845890 EDT | AverageQLoss                0.0181601
2017-07-02 14:24:54.846032 EDT | AveragePolicySurr          -2.27365
2017-07-02 14:24:54.846202 EDT | AverageQ                    2.13881
2017-07-02 14:24:54.846342 EDT | AverageAbsQ                 2.14474
2017-07-02 14:24:54.846445 EDT | AverageY                    2.13887
2017-07-02 14:24:54.846567 EDT | AverageAbsY                 2.13955
2017-07-02 14:24:54.846709 EDT | AverageAbsQYDiff            0.0407363
2017-07-02 14:24:54.846980 EDT | AverageAction               0.899802
2017-07-02 14:24:54.847103 EDT | PolicyRegParamNorm         57.3599
2017-07-02 14:24:54.847258 EDT | QFunRegParamNorm           57.6636
2017-07-02 14:24:54.847473 EDT | -----------------------  ------------
2017-07-02 14:24:54.847771 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #464 | Training started
2017-07-02 14:25:04.407914 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #464 | Training finished
2017-07-02 14:25:04.408507 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #464 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 14:25:04.408767 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #464 | Collecting samples for evaluation
2017-07-02 14:25:10.089896 EDT | -----------------------  ------------
2017-07-02 14:25:10.090167 EDT | Epoch                     464
2017-07-02 14:25:10.090406 EDT | Iteration                 464
2017-07-02 14:25:10.090579 EDT | AverageReturn            1000
2017-07-02 14:25:10.090815 EDT | StdReturn                   0
2017-07-02 14:25:10.091029 EDT | MaxReturn                1000
2017-07-02 14:25:10.091215 EDT | MinReturn                1000
2017-07-02 14:25:10.091449 EDT | AverageEsReturn            30.5161
2017-07-02 14:25:10.091668 EDT | StdEsReturn                35.4782
2017-07-02 14:25:10.091900 EDT | MaxEsReturn               188
2017-07-02 14:25:10.092122 EDT | MinEsReturn                 3
2017-07-02 14:25:10.092321 EDT | AverageDiscountedReturn    99.9957
2017-07-02 14:25:10.092552 EDT | AverageQLoss                0.0179817
2017-07-02 14:25:10.092708 EDT | AveragePolicySurr          -2.27013
2017-07-02 14:25:10.092939 EDT | AverageQ                    2.14107
2017-07-02 14:25:10.093158 EDT | AverageAbsQ                 2.14643
2017-07-02 14:25:10.093376 EDT | AverageY                    2.14106
2017-07-02 14:25:10.093613 EDT | AverageAbsY                 2.14184
2017-07-02 14:25:10.093802 EDT | AverageAbsQYDiff            0.0411879
2017-07-02 14:25:10.094033 EDT | AverageAction               0.909697
2017-07-02 14:25:10.094200 EDT | PolicyRegParamNorm         57.4463
2017-07-02 14:25:10.094433 EDT | QFunRegParamNorm           57.6903
2017-07-02 14:25:10.094650 EDT | -----------------------  ------------
2017-07-02 14:25:10.094978 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #465 | Training started
2017-07-02 14:25:20.028572 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #465 | Training finished
2017-07-02 14:25:20.028760 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #465 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 14:25:20.028900 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #465 | Collecting samples for evaluation
2017-07-02 14:25:25.909956 EDT | -----------------------  ------------
2017-07-02 14:25:25.910557 EDT | Epoch                     465
2017-07-02 14:25:25.910692 EDT | Iteration                 465
2017-07-02 14:25:25.910844 EDT | AverageReturn            1000
2017-07-02 14:25:25.910962 EDT | StdReturn                   0
2017-07-02 14:25:25.911074 EDT | MaxReturn                1000
2017-07-02 14:25:25.911182 EDT | MinReturn                1000
2017-07-02 14:25:25.911323 EDT | AverageEsReturn            30.7429
2017-07-02 14:25:25.911432 EDT | StdEsReturn                31.2587
2017-07-02 14:25:25.911539 EDT | MaxEsReturn               148
2017-07-02 14:25:25.911645 EDT | MinEsReturn                 3
2017-07-02 14:25:25.911855 EDT | AverageDiscountedReturn    99.9957
2017-07-02 14:25:25.912055 EDT | AverageQLoss                0.0178297
2017-07-02 14:25:25.912178 EDT | AveragePolicySurr          -2.26625
2017-07-02 14:25:25.912403 EDT | AverageQ                    2.13126
2017-07-02 14:25:25.912625 EDT | AverageAbsQ                 2.13664
2017-07-02 14:25:25.912801 EDT | AverageY                    2.13125
2017-07-02 14:25:25.912906 EDT | AverageAbsY                 2.13201
2017-07-02 14:25:25.913006 EDT | AverageAbsQYDiff            0.0390564
2017-07-02 14:25:25.913128 EDT | AverageAction               0.911873
2017-07-02 14:25:25.913274 EDT | PolicyRegParamNorm         57.5018
2017-07-02 14:25:25.913382 EDT | QFunRegParamNorm           57.7205
2017-07-02 14:25:25.913622 EDT | -----------------------  ------------
2017-07-02 14:25:25.913934 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #466 | Training started
2017-07-02 14:25:35.543480 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #466 | Training finished
2017-07-02 14:25:35.544187 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #466 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 14:25:35.545151 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #466 | Collecting samples for evaluation
2017-07-02 14:25:41.242618 EDT | -----------------------  ------------
2017-07-02 14:25:41.242874 EDT | Epoch                     466
2017-07-02 14:25:41.243059 EDT | Iteration                 466
2017-07-02 14:25:41.243287 EDT | AverageReturn            1000
2017-07-02 14:25:41.243493 EDT | StdReturn                   0
2017-07-02 14:25:41.243719 EDT | MaxReturn                1000
2017-07-02 14:25:41.243942 EDT | MinReturn                1000
2017-07-02 14:25:41.244116 EDT | AverageEsReturn            27
2017-07-02 14:25:41.244299 EDT | StdEsReturn                26.2894
2017-07-02 14:25:41.244462 EDT | MaxEsReturn               114
2017-07-02 14:25:41.244670 EDT | MinEsReturn                 3
2017-07-02 14:25:41.244887 EDT | AverageDiscountedReturn    99.9957
2017-07-02 14:25:41.245073 EDT | AverageQLoss                0.0181673
2017-07-02 14:25:41.245239 EDT | AveragePolicySurr          -2.26881
2017-07-02 14:25:41.245440 EDT | AverageQ                    2.13637
2017-07-02 14:25:41.245795 EDT | AverageAbsQ                 2.14239
2017-07-02 14:25:41.246029 EDT | AverageY                    2.13649
2017-07-02 14:25:41.246254 EDT | AverageAbsY                 2.13742
2017-07-02 14:25:41.246479 EDT | AverageAbsQYDiff            0.0412008
2017-07-02 14:25:41.246698 EDT | AverageAction               0.956807
2017-07-02 14:25:41.246847 EDT | PolicyRegParamNorm         57.5736
2017-07-02 14:25:41.246954 EDT | QFunRegParamNorm           57.7476
2017-07-02 14:25:41.247077 EDT | -----------------------  ------------
2017-07-02 14:25:41.247314 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #467 | Training started
2017-07-02 14:25:50.917925 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #467 | Training finished
2017-07-02 14:25:50.918131 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #467 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 14:25:50.918267 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #467 | Collecting samples for evaluation
2017-07-02 14:25:56.570637 EDT | -----------------------  ------------
2017-07-02 14:25:56.577867 EDT | Epoch                     467
2017-07-02 14:25:56.578150 EDT | Iteration                 467
2017-07-02 14:25:56.578374 EDT | AverageReturn            1000
2017-07-02 14:25:56.578607 EDT | StdReturn                   0
2017-07-02 14:25:56.578807 EDT | MaxReturn                1000
2017-07-02 14:25:56.579048 EDT | MinReturn                1000
2017-07-02 14:25:56.579278 EDT | AverageEsReturn            36.3704
2017-07-02 14:25:56.579505 EDT | StdEsReturn                42.519
2017-07-02 14:25:56.579708 EDT | MaxEsReturn               182
2017-07-02 14:25:56.579909 EDT | MinEsReturn                 3
2017-07-02 14:25:56.580119 EDT | AverageDiscountedReturn    99.9957
2017-07-02 14:25:56.580345 EDT | AverageQLoss                0.0184322
2017-07-02 14:25:56.580574 EDT | AveragePolicySurr          -2.26134
2017-07-02 14:25:56.580798 EDT | AverageQ                    2.13358
2017-07-02 14:25:56.581014 EDT | AverageAbsQ                 2.13928
2017-07-02 14:25:56.581160 EDT | AverageY                    2.13364
2017-07-02 14:25:56.581382 EDT | AverageAbsY                 2.13434
2017-07-02 14:25:56.581759 EDT | AverageAbsQYDiff            0.0402548
2017-07-02 14:25:56.581973 EDT | AverageAction               0.951138
2017-07-02 14:25:56.582200 EDT | PolicyRegParamNorm         57.7029
2017-07-02 14:25:56.582418 EDT | QFunRegParamNorm           57.7628
2017-07-02 14:25:56.582641 EDT | -----------------------  ------------
2017-07-02 14:25:56.582893 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #468 | Training started
2017-07-02 14:26:06.199589 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #468 | Training finished
2017-07-02 14:26:06.200123 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #468 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 14:26:06.200303 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #468 | Collecting samples for evaluation
2017-07-02 14:26:11.842752 EDT | -----------------------  ------------
2017-07-02 14:26:11.842955 EDT | Epoch                     468
2017-07-02 14:26:11.843067 EDT | Iteration                 468
2017-07-02 14:26:11.843212 EDT | AverageReturn            1000
2017-07-02 14:26:11.843350 EDT | StdReturn                   0
2017-07-02 14:26:11.843507 EDT | MaxReturn                1000
2017-07-02 14:26:11.843687 EDT | MinReturn                1000
2017-07-02 14:26:11.843825 EDT | AverageEsReturn            37.4815
2017-07-02 14:26:11.843929 EDT | StdEsReturn                30.7202
2017-07-02 14:26:11.844031 EDT | MaxEsReturn               109
2017-07-02 14:26:11.844177 EDT | MinEsReturn                 7
2017-07-02 14:26:11.844364 EDT | AverageDiscountedReturn    99.9957
2017-07-02 14:26:11.844502 EDT | AverageQLoss                0.0179728
2017-07-02 14:26:11.844606 EDT | AveragePolicySurr          -2.26618
2017-07-02 14:26:11.844761 EDT | AverageQ                    2.13177
2017-07-02 14:26:11.844864 EDT | AverageAbsQ                 2.13777
2017-07-02 14:26:11.844966 EDT | AverageY                    2.13189
2017-07-02 14:26:11.845085 EDT | AverageAbsY                 2.13262
2017-07-02 14:26:11.845228 EDT | AverageAbsQYDiff            0.0409145
2017-07-02 14:26:11.845351 EDT | AverageAction               0.941656
2017-07-02 14:26:11.845580 EDT | PolicyRegParamNorm         57.7736
2017-07-02 14:26:11.845740 EDT | QFunRegParamNorm           57.8027
2017-07-02 14:26:11.845871 EDT | -----------------------  ------------
2017-07-02 14:26:11.846119 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #469 | Training started
2017-07-02 14:26:21.422187 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #469 | Training finished
2017-07-02 14:26:21.422465 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #469 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 14:26:21.422691 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #469 | Collecting samples for evaluation
2017-07-02 14:26:27.106999 EDT | -----------------------  ------------
2017-07-02 14:26:27.107526 EDT | Epoch                     469
2017-07-02 14:26:27.107700 EDT | Iteration                 469
2017-07-02 14:26:27.107824 EDT | AverageReturn            1000
2017-07-02 14:26:27.107984 EDT | StdReturn                   0
2017-07-02 14:26:27.108155 EDT | MaxReturn                1000
2017-07-02 14:26:27.108325 EDT | MinReturn                1000
2017-07-02 14:26:27.108461 EDT | AverageEsReturn            28.8
2017-07-02 14:26:27.108580 EDT | StdEsReturn                24.5191
2017-07-02 14:26:27.108727 EDT | MaxEsReturn               111
2017-07-02 14:26:27.108853 EDT | MinEsReturn                 3
2017-07-02 14:26:27.109022 EDT | AverageDiscountedReturn    99.9957
2017-07-02 14:26:27.109189 EDT | AverageQLoss                0.0166696
2017-07-02 14:26:27.109402 EDT | AveragePolicySurr          -2.25959
2017-07-02 14:26:27.109595 EDT | AverageQ                    2.13472
2017-07-02 14:26:27.109737 EDT | AverageAbsQ                 2.13951
2017-07-02 14:26:27.109877 EDT | AverageY                    2.13478
2017-07-02 14:26:27.109982 EDT | AverageAbsY                 2.13534
2017-07-02 14:26:27.110084 EDT | AverageAbsQYDiff            0.0383987
2017-07-02 14:26:27.110196 EDT | AverageAction               0.910067
2017-07-02 14:26:27.110313 EDT | PolicyRegParamNorm         57.87
2017-07-02 14:26:27.110454 EDT | QFunRegParamNorm           57.8521
2017-07-02 14:26:27.110616 EDT | -----------------------  ------------
2017-07-02 14:26:27.110808 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #470 | Training started
2017-07-02 14:26:36.689425 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #470 | Training finished
2017-07-02 14:26:36.690234 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #470 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 14:26:36.690843 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #470 | Collecting samples for evaluation
2017-07-02 14:26:42.411463 EDT | -----------------------  ------------
2017-07-02 14:26:42.411714 EDT | Epoch                     470
2017-07-02 14:26:42.411837 EDT | Iteration                 470
2017-07-02 14:26:42.412012 EDT | AverageReturn            1000
2017-07-02 14:26:42.412118 EDT | StdReturn                   0
2017-07-02 14:26:42.412220 EDT | MaxReturn                1000
2017-07-02 14:26:42.412320 EDT | MinReturn                1000
2017-07-02 14:26:42.412498 EDT | AverageEsReturn            42.087
2017-07-02 14:26:42.412706 EDT | StdEsReturn                39.1051
2017-07-02 14:26:42.412862 EDT | MaxEsReturn               151
2017-07-02 14:26:42.412966 EDT | MinEsReturn                 6
2017-07-02 14:26:42.413117 EDT | AverageDiscountedReturn    99.9957
2017-07-02 14:26:42.413291 EDT | AverageQLoss                0.0183516
2017-07-02 14:26:42.413693 EDT | AveragePolicySurr          -2.24642
2017-07-02 14:26:42.413885 EDT | AverageQ                    2.11766
2017-07-02 14:26:42.414075 EDT | AverageAbsQ                 2.1242
2017-07-02 14:26:42.414281 EDT | AverageY                    2.11763
2017-07-02 14:26:42.414483 EDT | AverageAbsY                 2.1182
2017-07-02 14:26:42.414678 EDT | AverageAbsQYDiff            0.0416684
2017-07-02 14:26:42.414870 EDT | AverageAction               0.900185
2017-07-02 14:26:42.414992 EDT | PolicyRegParamNorm         57.9107
2017-07-02 14:26:42.415096 EDT | QFunRegParamNorm           57.8785
2017-07-02 14:26:42.415209 EDT | -----------------------  ------------
2017-07-02 14:26:42.415435 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #471 | Training started
2017-07-02 14:26:52.075463 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #471 | Training finished
2017-07-02 14:26:52.075670 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #471 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 14:26:52.075793 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #471 | Collecting samples for evaluation
2017-07-02 14:26:57.710660 EDT | -----------------------  ------------
2017-07-02 14:26:57.712109 EDT | Epoch                     471
2017-07-02 14:26:57.712350 EDT | Iteration                 471
2017-07-02 14:26:57.712502 EDT | AverageReturn            1000
2017-07-02 14:26:57.712725 EDT | StdReturn                   0
2017-07-02 14:26:57.712941 EDT | MaxReturn                1000
2017-07-02 14:26:57.713163 EDT | MinReturn                1000
2017-07-02 14:26:57.713374 EDT | AverageEsReturn            47.381
2017-07-02 14:26:57.713756 EDT | StdEsReturn                51.2403
2017-07-02 14:26:57.713987 EDT | MaxEsReturn               176
2017-07-02 14:26:57.714201 EDT | MinEsReturn                 3
2017-07-02 14:26:57.714315 EDT | AverageDiscountedReturn    99.9957
2017-07-02 14:26:57.714481 EDT | AverageQLoss                0.0150051
2017-07-02 14:26:57.714704 EDT | AveragePolicySurr          -2.2438
2017-07-02 14:26:57.714819 EDT | AverageQ                    2.11938
2017-07-02 14:26:57.714960 EDT | AverageAbsQ                 2.12388
2017-07-02 14:26:57.715092 EDT | AverageY                    2.11932
2017-07-02 14:26:57.715220 EDT | AverageAbsY                 2.12003
2017-07-02 14:26:57.715329 EDT | AverageAbsQYDiff            0.0355894
2017-07-02 14:26:57.715436 EDT | AverageAction               0.880608
2017-07-02 14:26:57.715551 EDT | PolicyRegParamNorm         58.0693
2017-07-02 14:26:57.715767 EDT | QFunRegParamNorm           57.8818
2017-07-02 14:26:57.715957 EDT | -----------------------  ------------
2017-07-02 14:26:57.716275 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #472 | Training started
2017-07-02 14:27:07.423877 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #472 | Training finished
2017-07-02 14:27:07.424637 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #472 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 14:27:07.424841 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #472 | Collecting samples for evaluation
2017-07-02 14:27:13.191468 EDT | -----------------------  ------------
2017-07-02 14:27:13.191679 EDT | Epoch                     472
2017-07-02 14:27:13.191848 EDT | Iteration                 472
2017-07-02 14:27:13.191972 EDT | AverageReturn            1000
2017-07-02 14:27:13.192124 EDT | StdReturn                   0
2017-07-02 14:27:13.192228 EDT | MaxReturn                1000
2017-07-02 14:27:13.192330 EDT | MinReturn                1000
2017-07-02 14:27:13.192471 EDT | AverageEsReturn            27.8108
2017-07-02 14:27:13.192612 EDT | StdEsReturn                30.8246
2017-07-02 14:27:13.192714 EDT | MaxEsReturn               152
2017-07-02 14:27:13.192962 EDT | MinEsReturn                 3
2017-07-02 14:27:13.193078 EDT | AverageDiscountedReturn    99.9957
2017-07-02 14:27:13.193191 EDT | AverageQLoss                0.0153944
2017-07-02 14:27:13.193307 EDT | AveragePolicySurr          -2.23606
2017-07-02 14:27:13.193430 EDT | AverageQ                    2.11119
2017-07-02 14:27:13.193574 EDT | AverageAbsQ                 2.1175
2017-07-02 14:27:13.193688 EDT | AverageY                    2.11129
2017-07-02 14:27:13.193802 EDT | AverageAbsY                 2.11225
2017-07-02 14:27:13.193968 EDT | AverageAbsQYDiff            0.0372867
2017-07-02 14:27:13.194097 EDT | AverageAction               0.863584
2017-07-02 14:27:13.194207 EDT | PolicyRegParamNorm         58.1055
2017-07-02 14:27:13.194344 EDT | QFunRegParamNorm           57.9223
2017-07-02 14:27:13.194544 EDT | -----------------------  ------------
2017-07-02 14:27:13.194870 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #473 | Training started
2017-07-02 14:27:22.893078 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #473 | Training finished
2017-07-02 14:27:22.893318 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #473 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 14:27:22.893436 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #473 | Collecting samples for evaluation
2017-07-02 14:27:28.530089 EDT | -----------------------  ------------
2017-07-02 14:27:28.530689 EDT | Epoch                     473
2017-07-02 14:27:28.530927 EDT | Iteration                 473
2017-07-02 14:27:28.531210 EDT | AverageReturn            1000
2017-07-02 14:27:28.531440 EDT | StdReturn                   0
2017-07-02 14:27:28.531663 EDT | MaxReturn                1000
2017-07-02 14:27:28.531883 EDT | MinReturn                1000
2017-07-02 14:27:28.532063 EDT | AverageEsReturn            30.25
2017-07-02 14:27:28.532277 EDT | StdEsReturn                30.0208
2017-07-02 14:27:28.532472 EDT | MaxEsReturn               116
2017-07-02 14:27:28.532703 EDT | MinEsReturn                 4
2017-07-02 14:27:28.532927 EDT | AverageDiscountedReturn    99.9957
2017-07-02 14:27:28.533150 EDT | AverageQLoss                0.0168147
2017-07-02 14:27:28.533308 EDT | AveragePolicySurr          -2.23104
2017-07-02 14:27:28.533454 EDT | AverageQ                    2.10356
2017-07-02 14:27:28.533690 EDT | AverageAbsQ                 2.11006
2017-07-02 14:27:28.533812 EDT | AverageY                    2.10352
2017-07-02 14:27:28.533943 EDT | AverageAbsY                 2.10455
2017-07-02 14:27:28.534417 EDT | AverageAbsQYDiff            0.0398993
2017-07-02 14:27:28.534554 EDT | AverageAction               0.875366
2017-07-02 14:27:28.534700 EDT | PolicyRegParamNorm         58.183
2017-07-02 14:27:28.534936 EDT | QFunRegParamNorm           58.0019
2017-07-02 14:27:28.535163 EDT | -----------------------  ------------
2017-07-02 14:27:28.535488 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #474 | Training started
2017-07-02 14:27:38.113036 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #474 | Training finished
2017-07-02 14:27:38.113544 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #474 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 14:27:38.113786 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #474 | Collecting samples for evaluation
2017-07-02 14:27:43.827846 EDT | -----------------------  ------------
2017-07-02 14:27:43.828127 EDT | Epoch                     474
2017-07-02 14:27:43.828340 EDT | Iteration                 474
2017-07-02 14:27:43.828462 EDT | AverageReturn            1000
2017-07-02 14:27:43.828683 EDT | StdReturn                   0
2017-07-02 14:27:43.828899 EDT | MaxReturn                1000
2017-07-02 14:27:43.829125 EDT | MinReturn                1000
2017-07-02 14:27:43.829322 EDT | AverageEsReturn            43.5217
2017-07-02 14:27:43.829580 EDT | StdEsReturn                40.4495
2017-07-02 14:27:43.829806 EDT | MaxEsReturn               141
2017-07-02 14:27:43.830027 EDT | MinEsReturn                 3
2017-07-02 14:27:43.830239 EDT | AverageDiscountedReturn    99.9957
2017-07-02 14:27:43.830431 EDT | AverageQLoss                0.0140665
2017-07-02 14:27:43.830648 EDT | AveragePolicySurr          -2.22833
2017-07-02 14:27:43.830760 EDT | AverageQ                    2.10791
2017-07-02 14:27:43.830864 EDT | AverageAbsQ                 2.11329
2017-07-02 14:27:43.830971 EDT | AverageY                    2.10803
2017-07-02 14:27:43.831106 EDT | AverageAbsY                 2.1089
2017-07-02 14:27:43.831209 EDT | AverageAbsQYDiff            0.0353895
2017-07-02 14:27:43.831391 EDT | AverageAction               0.886975
2017-07-02 14:27:43.831602 EDT | PolicyRegParamNorm         58.2865
2017-07-02 14:27:43.831774 EDT | QFunRegParamNorm           58.0456
2017-07-02 14:27:43.831996 EDT | -----------------------  ------------
2017-07-02 14:27:43.832311 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #475 | Training started
2017-07-02 14:27:53.382805 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #475 | Training finished
2017-07-02 14:27:53.383599 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #475 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 14:27:53.383800 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #475 | Collecting samples for evaluation
2017-07-02 14:27:59.175067 EDT | -----------------------  ------------
2017-07-02 14:27:59.175551 EDT | Epoch                     475
2017-07-02 14:27:59.175744 EDT | Iteration                 475
2017-07-02 14:27:59.175913 EDT | AverageReturn            1000
2017-07-02 14:27:59.176073 EDT | StdReturn                   0
2017-07-02 14:27:59.176232 EDT | MaxReturn                1000
2017-07-02 14:27:59.176397 EDT | MinReturn                1000
2017-07-02 14:27:59.176557 EDT | AverageEsReturn            34.7333
2017-07-02 14:27:59.176714 EDT | StdEsReturn                34.4315
2017-07-02 14:27:59.176893 EDT | MaxEsReturn               185
2017-07-02 14:27:59.177053 EDT | MinEsReturn                 4
2017-07-02 14:27:59.177212 EDT | AverageDiscountedReturn    99.9957
2017-07-02 14:27:59.177371 EDT | AverageQLoss                0.0174746
2017-07-02 14:27:59.177580 EDT | AveragePolicySurr          -2.21822
2017-07-02 14:27:59.177759 EDT | AverageQ                    2.09014
2017-07-02 14:27:59.177964 EDT | AverageAbsQ                 2.09673
2017-07-02 14:27:59.178181 EDT | AverageY                    2.09011
2017-07-02 14:27:59.178388 EDT | AverageAbsY                 2.09093
2017-07-02 14:27:59.178610 EDT | AverageAbsQYDiff            0.0400095
2017-07-02 14:27:59.178820 EDT | AverageAction               0.910466
2017-07-02 14:27:59.178993 EDT | PolicyRegParamNorm         58.3705
2017-07-02 14:27:59.179153 EDT | QFunRegParamNorm           58.0777
2017-07-02 14:27:59.179310 EDT | -----------------------  ------------
2017-07-02 14:27:59.179554 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #476 | Training started
2017-07-02 14:28:08.745079 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #476 | Training finished
2017-07-02 14:28:08.745602 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #476 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 14:28:08.745761 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #476 | Collecting samples for evaluation
2017-07-02 14:28:14.479135 EDT | -----------------------  ------------
2017-07-02 14:28:14.479345 EDT | Epoch                     476
2017-07-02 14:28:14.479559 EDT | Iteration                 476
2017-07-02 14:28:14.479782 EDT | AverageReturn            1000
2017-07-02 14:28:14.479990 EDT | StdReturn                   0
2017-07-02 14:28:14.480180 EDT | MaxReturn                1000
2017-07-02 14:28:14.480288 EDT | MinReturn                1000
2017-07-02 14:28:14.480458 EDT | AverageEsReturn            34.4286
2017-07-02 14:28:14.480592 EDT | StdEsReturn                26.3336
2017-07-02 14:28:14.480733 EDT | MaxEsReturn                93
2017-07-02 14:28:14.480900 EDT | MinEsReturn                 4
2017-07-02 14:28:14.481012 EDT | AverageDiscountedReturn    99.9957
2017-07-02 14:28:14.481152 EDT | AverageQLoss                0.0164385
2017-07-02 14:28:14.481262 EDT | AveragePolicySurr          -2.21517
2017-07-02 14:28:14.481369 EDT | AverageQ                    2.09125
2017-07-02 14:28:14.481521 EDT | AverageAbsQ                 2.09695
2017-07-02 14:28:14.481654 EDT | AverageY                    2.09136
2017-07-02 14:28:14.481818 EDT | AverageAbsY                 2.09193
2017-07-02 14:28:14.481942 EDT | AverageAbsQYDiff            0.0369741
2017-07-02 14:28:14.482110 EDT | AverageAction               0.911314
2017-07-02 14:28:14.482217 EDT | PolicyRegParamNorm         58.4437
2017-07-02 14:28:14.482349 EDT | QFunRegParamNorm           58.0934
2017-07-02 14:28:14.482524 EDT | -----------------------  ------------
2017-07-02 14:28:14.482696 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #477 | Training started
2017-07-02 14:28:24.080934 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #477 | Training finished
2017-07-02 14:28:24.081482 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #477 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 14:28:24.081718 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #477 | Collecting samples for evaluation
2017-07-02 14:28:29.777782 EDT | -----------------------  ------------
2017-07-02 14:28:29.778365 EDT | Epoch                     477
2017-07-02 14:28:29.778498 EDT | Iteration                 477
2017-07-02 14:28:29.778608 EDT | AverageReturn            1000
2017-07-02 14:28:29.778885 EDT | StdReturn                   0
2017-07-02 14:28:29.779073 EDT | MaxReturn                1000
2017-07-02 14:28:29.779207 EDT | MinReturn                1000
2017-07-02 14:28:29.779334 EDT | AverageEsReturn            29.9706
2017-07-02 14:28:29.779460 EDT | StdEsReturn                33.82
2017-07-02 14:28:29.779586 EDT | MaxEsReturn               142
2017-07-02 14:28:29.779708 EDT | MinEsReturn                 3
2017-07-02 14:28:29.779817 EDT | AverageDiscountedReturn    99.9957
2017-07-02 14:28:29.779926 EDT | AverageQLoss                0.0168127
2017-07-02 14:28:29.780034 EDT | AveragePolicySurr          -2.20371
2017-07-02 14:28:29.780141 EDT | AverageQ                    2.07769
2017-07-02 14:28:29.780247 EDT | AverageAbsQ                 2.08334
2017-07-02 14:28:29.780354 EDT | AverageY                    2.07771
2017-07-02 14:28:29.780460 EDT | AverageAbsY                 2.07842
2017-07-02 14:28:29.780594 EDT | AverageAbsQYDiff            0.0372942
2017-07-02 14:28:29.780701 EDT | AverageAction               0.923188
2017-07-02 14:28:29.780812 EDT | PolicyRegParamNorm         58.5234
2017-07-02 14:28:29.780939 EDT | QFunRegParamNorm           58.0991
2017-07-02 14:28:29.781046 EDT | -----------------------  ------------
2017-07-02 14:28:29.781250 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #478 | Training started
2017-07-02 14:28:39.397149 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #478 | Training finished
2017-07-02 14:28:39.397665 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #478 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 14:28:39.397814 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #478 | Collecting samples for evaluation
2017-07-02 14:28:45.082608 EDT | -----------------------  ------------
2017-07-02 14:28:45.082874 EDT | Epoch                     478
2017-07-02 14:28:45.083039 EDT | Iteration                 478
2017-07-02 14:28:45.083182 EDT | AverageReturn            1000
2017-07-02 14:28:45.083311 EDT | StdReturn                   0
2017-07-02 14:28:45.083465 EDT | MaxReturn                1000
2017-07-02 14:28:45.083606 EDT | MinReturn                1000
2017-07-02 14:28:45.083732 EDT | AverageEsReturn            38.1154
2017-07-02 14:28:45.083947 EDT | StdEsReturn                30.4648
2017-07-02 14:28:45.084166 EDT | MaxEsReturn                99
2017-07-02 14:28:45.084389 EDT | MinEsReturn                 3
2017-07-02 14:28:45.084617 EDT | AverageDiscountedReturn    99.9957
2017-07-02 14:28:45.084825 EDT | AverageQLoss                0.0160788
2017-07-02 14:28:45.085040 EDT | AveragePolicySurr          -2.19657
2017-07-02 14:28:45.085263 EDT | AverageQ                    2.07511
2017-07-02 14:28:45.085481 EDT | AverageAbsQ                 2.08036
2017-07-02 14:28:45.086052 EDT | AverageY                    2.07521
2017-07-02 14:28:45.086269 EDT | AverageAbsY                 2.07579
2017-07-02 14:28:45.086498 EDT | AverageAbsQYDiff            0.035484
2017-07-02 14:28:45.086720 EDT | AverageAction               0.933665
2017-07-02 14:28:45.086951 EDT | PolicyRegParamNorm         58.6554
2017-07-02 14:28:45.087161 EDT | QFunRegParamNorm           58.1553
2017-07-02 14:28:45.087391 EDT | -----------------------  ------------
2017-07-02 14:28:45.087611 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #479 | Training started
2017-07-02 14:28:54.826779 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #479 | Training finished
2017-07-02 14:28:54.827374 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #479 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 14:28:54.827543 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #479 | Collecting samples for evaluation
2017-07-02 14:29:00.401291 EDT | -----------------------  ------------
2017-07-02 14:29:00.401517 EDT | Epoch                     479
2017-07-02 14:29:00.401673 EDT | Iteration                 479
2017-07-02 14:29:00.401811 EDT | AverageReturn            1000
2017-07-02 14:29:00.401941 EDT | StdReturn                   0
2017-07-02 14:29:00.402068 EDT | MaxReturn                1000
2017-07-02 14:29:00.402197 EDT | MinReturn                1000
2017-07-02 14:29:00.402324 EDT | AverageEsReturn            32.0968
2017-07-02 14:29:00.402463 EDT | StdEsReturn                26.9041
2017-07-02 14:29:00.402606 EDT | MaxEsReturn               121
2017-07-02 14:29:00.402737 EDT | MinEsReturn                 5
2017-07-02 14:29:00.402863 EDT | AverageDiscountedReturn    99.9957
2017-07-02 14:29:00.402985 EDT | AverageQLoss                0.0173325
2017-07-02 14:29:00.403159 EDT | AveragePolicySurr          -2.18334
2017-07-02 14:29:00.403327 EDT | AverageQ                    2.06635
2017-07-02 14:29:00.403445 EDT | AverageAbsQ                 2.07133
2017-07-02 14:29:00.403730 EDT | AverageY                    2.06632
2017-07-02 14:29:00.403947 EDT | AverageAbsY                 2.06682
2017-07-02 14:29:00.404179 EDT | AverageAbsQYDiff            0.0378392
2017-07-02 14:29:00.404385 EDT | AverageAction               0.934781
2017-07-02 14:29:00.404536 EDT | PolicyRegParamNorm         58.7259
2017-07-02 14:29:00.404711 EDT | QFunRegParamNorm           58.1818
2017-07-02 14:29:00.404894 EDT | -----------------------  ------------
2017-07-02 14:29:00.405167 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #480 | Training started
2017-07-02 14:29:10.049419 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #480 | Training finished
2017-07-02 14:29:10.050055 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #480 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 14:29:10.050214 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #480 | Collecting samples for evaluation
2017-07-02 14:29:15.821112 EDT | -----------------------  ------------
2017-07-02 14:29:15.821337 EDT | Epoch                     480
2017-07-02 14:29:15.821556 EDT | Iteration                 480
2017-07-02 14:29:15.821691 EDT | AverageReturn            1000
2017-07-02 14:29:15.821856 EDT | StdReturn                   0
2017-07-02 14:29:15.822133 EDT | MaxReturn                1000
2017-07-02 14:29:15.822258 EDT | MinReturn                1000
2017-07-02 14:29:15.822364 EDT | AverageEsReturn            35.4483
2017-07-02 14:29:15.822557 EDT | StdEsReturn                24.4985
2017-07-02 14:29:15.822782 EDT | MaxEsReturn               100
2017-07-02 14:29:15.822996 EDT | MinEsReturn                 3
2017-07-02 14:29:15.823232 EDT | AverageDiscountedReturn    99.9957
2017-07-02 14:29:15.823457 EDT | AverageQLoss                0.0143254
2017-07-02 14:29:15.823679 EDT | AveragePolicySurr          -2.17894
2017-07-02 14:29:15.823898 EDT | AverageQ                    2.06151
2017-07-02 14:29:15.824123 EDT | AverageAbsQ                 2.06681
2017-07-02 14:29:15.824272 EDT | AverageY                    2.06144
2017-07-02 14:29:15.824424 EDT | AverageAbsY                 2.06196
2017-07-02 14:29:15.824529 EDT | AverageAbsQYDiff            0.0342615
2017-07-02 14:29:15.824667 EDT | AverageAction               0.953341
2017-07-02 14:29:15.824777 EDT | PolicyRegParamNorm         58.7496
2017-07-02 14:29:15.824995 EDT | QFunRegParamNorm           58.2151
2017-07-02 14:29:15.825206 EDT | -----------------------  ------------
2017-07-02 14:29:15.825511 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #481 | Training started
2017-07-02 14:29:25.330952 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #481 | Training finished
2017-07-02 14:29:25.331885 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #481 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 14:29:25.332129 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #481 | Collecting samples for evaluation
2017-07-02 14:29:31.070869 EDT | -----------------------  ------------
2017-07-02 14:29:31.071094 EDT | Epoch                     481
2017-07-02 14:29:31.071215 EDT | Iteration                 481
2017-07-02 14:29:31.071320 EDT | AverageReturn            1000
2017-07-02 14:29:31.071470 EDT | StdReturn                   0
2017-07-02 14:29:31.071695 EDT | MaxReturn                1000
2017-07-02 14:29:31.071909 EDT | MinReturn                1000
2017-07-02 14:29:31.072090 EDT | AverageEsReturn            31.375
2017-07-02 14:29:31.072291 EDT | StdEsReturn                25.3251
2017-07-02 14:29:31.072457 EDT | MaxEsReturn               126
2017-07-02 14:29:31.072617 EDT | MinEsReturn                 3
2017-07-02 14:29:31.072724 EDT | AverageDiscountedReturn    99.9957
2017-07-02 14:29:31.072916 EDT | AverageQLoss                0.0167274
2017-07-02 14:29:31.073024 EDT | AveragePolicySurr          -2.16931
2017-07-02 14:29:31.073125 EDT | AverageQ                    2.05518
2017-07-02 14:29:31.073281 EDT | AverageAbsQ                 2.06055
2017-07-02 14:29:31.073481 EDT | AverageY                    2.05539
2017-07-02 14:29:31.073705 EDT | AverageAbsY                 2.05584
2017-07-02 14:29:31.073875 EDT | AverageAbsQYDiff            0.0375444
2017-07-02 14:29:31.073983 EDT | AverageAction               0.912988
2017-07-02 14:29:31.074085 EDT | PolicyRegParamNorm         58.8122
2017-07-02 14:29:31.074239 EDT | QFunRegParamNorm           58.2321
2017-07-02 14:29:31.074416 EDT | -----------------------  ------------
2017-07-02 14:29:31.074598 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #482 | Training started
2017-07-02 14:29:40.726318 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #482 | Training finished
2017-07-02 14:29:40.726829 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #482 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 14:29:40.727065 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #482 | Collecting samples for evaluation
2017-07-02 14:29:46.571322 EDT | -----------------------  ------------
2017-07-02 14:29:46.571615 EDT | Epoch                     482
2017-07-02 14:29:46.571829 EDT | Iteration                 482
2017-07-02 14:29:46.572032 EDT | AverageReturn            1000
2017-07-02 14:29:46.572269 EDT | StdReturn                   0
2017-07-02 14:29:46.572486 EDT | MaxReturn                1000
2017-07-02 14:29:46.572691 EDT | MinReturn                1000
2017-07-02 14:29:46.572917 EDT | AverageEsReturn            33.4
2017-07-02 14:29:46.573129 EDT | StdEsReturn                26.0482
2017-07-02 14:29:46.573365 EDT | MaxEsReturn               111
2017-07-02 14:29:46.573595 EDT | MinEsReturn                 5
2017-07-02 14:29:46.573714 EDT | AverageDiscountedReturn    99.9957
2017-07-02 14:29:46.573944 EDT | AverageQLoss                0.0149199
2017-07-02 14:29:46.574156 EDT | AveragePolicySurr          -2.16233
2017-07-02 14:29:46.574392 EDT | AverageQ                    2.0483
2017-07-02 14:29:46.574620 EDT | AverageAbsQ                 2.05368
2017-07-02 14:29:46.574854 EDT | AverageY                    2.0482
2017-07-02 14:29:46.575068 EDT | AverageAbsY                 2.04878
2017-07-02 14:29:46.575301 EDT | AverageAbsQYDiff            0.0347709
2017-07-02 14:29:46.575521 EDT | AverageAction               0.946395
2017-07-02 14:29:46.575762 EDT | PolicyRegParamNorm         58.8513
2017-07-02 14:29:46.575987 EDT | QFunRegParamNorm           58.2296
2017-07-02 14:29:46.576217 EDT | -----------------------  ------------
2017-07-02 14:29:46.576591 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #483 | Training started
2017-07-02 14:29:56.025955 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #483 | Training finished
2017-07-02 14:29:56.026465 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #483 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 14:29:56.026598 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #483 | Collecting samples for evaluation
2017-07-02 14:30:01.735791 EDT | -----------------------  ------------
2017-07-02 14:30:01.736034 EDT | Epoch                     483
2017-07-02 14:30:01.736198 EDT | Iteration                 483
2017-07-02 14:30:01.736314 EDT | AverageReturn            1000
2017-07-02 14:30:01.736446 EDT | StdReturn                   0
2017-07-02 14:30:01.736615 EDT | MaxReturn                1000
2017-07-02 14:30:01.736721 EDT | MinReturn                1000
2017-07-02 14:30:01.736824 EDT | AverageEsReturn            39.9167
2017-07-02 14:30:01.736928 EDT | StdEsReturn                38.5367
2017-07-02 14:30:01.737028 EDT | MaxEsReturn               159
2017-07-02 14:30:01.737148 EDT | MinEsReturn                 3
2017-07-02 14:30:01.737248 EDT | AverageDiscountedReturn    99.9957
2017-07-02 14:30:01.737346 EDT | AverageQLoss                0.0146762
2017-07-02 14:30:01.737442 EDT | AveragePolicySurr          -2.15397
2017-07-02 14:30:01.737637 EDT | AverageQ                    2.03647
2017-07-02 14:30:01.737753 EDT | AverageAbsQ                 2.04211
2017-07-02 14:30:01.737855 EDT | AverageY                    2.03645
2017-07-02 14:30:01.737971 EDT | AverageAbsY                 2.03715
2017-07-02 14:30:01.738123 EDT | AverageAbsQYDiff            0.0345588
2017-07-02 14:30:01.738291 EDT | AverageAction               0.908154
2017-07-02 14:30:01.738403 EDT | PolicyRegParamNorm         58.9268
2017-07-02 14:30:01.738510 EDT | QFunRegParamNorm           58.2703
2017-07-02 14:30:01.738655 EDT | -----------------------  ------------
2017-07-02 14:30:01.738827 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #484 | Training started
2017-07-02 14:30:11.213473 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #484 | Training finished
2017-07-02 14:30:11.214246 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #484 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 14:30:11.214395 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #484 | Collecting samples for evaluation
2017-07-02 14:30:17.001819 EDT | -----------------------  ------------
2017-07-02 14:30:17.002119 EDT | Epoch                     484
2017-07-02 14:30:17.002293 EDT | Iteration                 484
2017-07-02 14:30:17.002444 EDT | AverageReturn            1000
2017-07-02 14:30:17.002549 EDT | StdReturn                   0
2017-07-02 14:30:17.002666 EDT | MaxReturn                1000
2017-07-02 14:30:17.002798 EDT | MinReturn                1000
2017-07-02 14:30:17.002903 EDT | AverageEsReturn            32.3871
2017-07-02 14:30:17.003046 EDT | StdEsReturn                33.1046
2017-07-02 14:30:17.003152 EDT | MaxEsReturn               130
2017-07-02 14:30:17.003254 EDT | MinEsReturn                 3
2017-07-02 14:30:17.003386 EDT | AverageDiscountedReturn    99.9957
2017-07-02 14:30:17.003617 EDT | AverageQLoss                0.0155273
2017-07-02 14:30:17.003852 EDT | AveragePolicySurr          -2.14746
2017-07-02 14:30:17.004069 EDT | AverageQ                    2.03008
2017-07-02 14:30:17.004258 EDT | AverageAbsQ                 2.03519
2017-07-02 14:30:17.004467 EDT | AverageY                    2.02993
2017-07-02 14:30:17.004587 EDT | AverageAbsY                 2.0306
2017-07-02 14:30:17.004700 EDT | AverageAbsQYDiff            0.0351277
2017-07-02 14:30:17.004811 EDT | AverageAction               0.913
2017-07-02 14:30:17.004947 EDT | PolicyRegParamNorm         58.9149
2017-07-02 14:30:17.005050 EDT | QFunRegParamNorm           58.3097
2017-07-02 14:30:17.005167 EDT | -----------------------  ------------
2017-07-02 14:30:17.005340 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #485 | Training started
2017-07-02 14:30:27.064743 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #485 | Training finished
2017-07-02 14:30:27.065379 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #485 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 14:30:27.065654 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #485 | Collecting samples for evaluation
2017-07-02 14:30:32.884670 EDT | -----------------------  ------------
2017-07-02 14:30:32.884856 EDT | Epoch                     485
2017-07-02 14:30:32.884968 EDT | Iteration                 485
2017-07-02 14:30:32.885098 EDT | AverageReturn            1000
2017-07-02 14:30:32.885209 EDT | StdReturn                   0
2017-07-02 14:30:32.885311 EDT | MaxReturn                1000
2017-07-02 14:30:32.885413 EDT | MinReturn                1000
2017-07-02 14:30:32.885533 EDT | AverageEsReturn            32.2258
2017-07-02 14:30:32.885673 EDT | StdEsReturn                27.4787
2017-07-02 14:30:32.885869 EDT | MaxEsReturn               129
2017-07-02 14:30:32.886084 EDT | MinEsReturn                 3
2017-07-02 14:30:32.886289 EDT | AverageDiscountedReturn    99.9957
2017-07-02 14:30:32.886501 EDT | AverageQLoss                0.0157307
2017-07-02 14:30:32.886639 EDT | AveragePolicySurr          -2.1385
2017-07-02 14:30:32.886773 EDT | AverageQ                    2.02852
2017-07-02 14:30:32.886895 EDT | AverageAbsQ                 2.03377
2017-07-02 14:30:32.887021 EDT | AverageY                    2.0285
2017-07-02 14:30:32.887145 EDT | AverageAbsY                 2.02905
2017-07-02 14:30:32.887261 EDT | AverageAbsQYDiff            0.0348245
2017-07-02 14:30:32.887392 EDT | AverageAction               0.952283
2017-07-02 14:30:32.887494 EDT | PolicyRegParamNorm         58.9377
2017-07-02 14:30:32.887595 EDT | QFunRegParamNorm           58.3141
2017-07-02 14:30:32.887724 EDT | -----------------------  ------------
2017-07-02 14:30:32.887945 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #486 | Training started
2017-07-02 14:30:42.342167 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #486 | Training finished
2017-07-02 14:30:42.342663 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #486 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 14:30:42.342794 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #486 | Collecting samples for evaluation
2017-07-02 14:30:48.169775 EDT | -----------------------  ------------
2017-07-02 14:30:48.169981 EDT | Epoch                     486
2017-07-02 14:30:48.170258 EDT | Iteration                 486
2017-07-02 14:30:48.170428 EDT | AverageReturn            1000
2017-07-02 14:30:48.170567 EDT | StdReturn                   0
2017-07-02 14:30:48.170684 EDT | MaxReturn                1000
2017-07-02 14:30:48.170816 EDT | MinReturn                1000
2017-07-02 14:30:48.170942 EDT | AverageEsReturn            34.6897
2017-07-02 14:30:48.171055 EDT | StdEsReturn                24.6969
2017-07-02 14:30:48.171194 EDT | MaxEsReturn                94
2017-07-02 14:30:48.171390 EDT | MinEsReturn                 3
2017-07-02 14:30:48.171557 EDT | AverageDiscountedReturn    99.9957
2017-07-02 14:30:48.171683 EDT | AverageQLoss                0.0155834
2017-07-02 14:30:48.171815 EDT | AveragePolicySurr          -2.12628
2017-07-02 14:30:48.171943 EDT | AverageQ                    2.01102
2017-07-02 14:30:48.172050 EDT | AverageAbsQ                 2.01631
2017-07-02 14:30:48.172163 EDT | AverageY                    2.01105
2017-07-02 14:30:48.172306 EDT | AverageAbsY                 2.0115
2017-07-02 14:30:48.172459 EDT | AverageAbsQYDiff            0.0362173
2017-07-02 14:30:48.172626 EDT | AverageAction               0.954608
2017-07-02 14:30:48.172761 EDT | PolicyRegParamNorm         59.0251
2017-07-02 14:30:48.172915 EDT | QFunRegParamNorm           58.3611
2017-07-02 14:30:48.173039 EDT | -----------------------  ------------
2017-07-02 14:30:48.173286 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #487 | Training started
2017-07-02 14:30:57.613111 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #487 | Training finished
2017-07-02 14:30:57.620494 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #487 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 14:30:57.620715 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #487 | Collecting samples for evaluation
2017-07-02 14:31:03.432700 EDT | -----------------------  ------------
2017-07-02 14:31:03.433016 EDT | Epoch                     487
2017-07-02 14:31:03.433212 EDT | Iteration                 487
2017-07-02 14:31:03.433321 EDT | AverageReturn            1000
2017-07-02 14:31:03.433425 EDT | StdReturn                   0
2017-07-02 14:31:03.433623 EDT | MaxReturn                1000
2017-07-02 14:31:03.433843 EDT | MinReturn                1000
2017-07-02 14:31:03.434055 EDT | AverageEsReturn            41.12
2017-07-02 14:31:03.434267 EDT | StdEsReturn                30.059
2017-07-02 14:31:03.434493 EDT | MaxEsReturn               126
2017-07-02 14:31:03.434714 EDT | MinEsReturn                 7
2017-07-02 14:31:03.434927 EDT | AverageDiscountedReturn    99.9957
2017-07-02 14:31:03.435146 EDT | AverageQLoss                0.0146649
2017-07-02 14:31:03.435363 EDT | AveragePolicySurr          -2.11753
2017-07-02 14:31:03.435560 EDT | AverageQ                    2.0024
2017-07-02 14:31:03.435696 EDT | AverageAbsQ                 2.00845
2017-07-02 14:31:03.435916 EDT | AverageY                    2.00228
2017-07-02 14:31:03.436045 EDT | AverageAbsY                 2.00295
2017-07-02 14:31:03.436230 EDT | AverageAbsQYDiff            0.0351397
2017-07-02 14:31:03.436452 EDT | AverageAction               0.912799
2017-07-02 14:31:03.436607 EDT | PolicyRegParamNorm         59.0504
2017-07-02 14:31:03.436714 EDT | QFunRegParamNorm           58.395
2017-07-02 14:31:03.436816 EDT | -----------------------  ------------
2017-07-02 14:31:03.436978 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #488 | Training started
2017-07-02 14:31:12.884783 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #488 | Training finished
2017-07-02 14:31:12.885389 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #488 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 14:31:12.885625 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #488 | Collecting samples for evaluation
2017-07-02 14:31:18.621323 EDT | -----------------------  ------------
2017-07-02 14:31:18.621653 EDT | Epoch                     488
2017-07-02 14:31:18.621887 EDT | Iteration                 488
2017-07-02 14:31:18.622114 EDT | AverageReturn            1000
2017-07-02 14:31:18.622359 EDT | StdReturn                   0
2017-07-02 14:31:18.622581 EDT | MaxReturn                1000
2017-07-02 14:31:18.622807 EDT | MinReturn                1000
2017-07-02 14:31:18.623022 EDT | AverageEsReturn            33.5
2017-07-02 14:31:18.623191 EDT | StdEsReturn                33.2473
2017-07-02 14:31:18.623410 EDT | MaxEsReturn               177
2017-07-02 14:31:18.623610 EDT | MinEsReturn                 5
2017-07-02 14:31:18.623767 EDT | AverageDiscountedReturn    99.9957
2017-07-02 14:31:18.623985 EDT | AverageQLoss                0.0145728
2017-07-02 14:31:18.624197 EDT | AveragePolicySurr          -2.10153
2017-07-02 14:31:18.624415 EDT | AverageQ                    1.98488
2017-07-02 14:31:18.624630 EDT | AverageAbsQ                 1.99039
2017-07-02 14:31:18.624853 EDT | AverageY                    1.98489
2017-07-02 14:31:18.625032 EDT | AverageAbsY                 1.9854
2017-07-02 14:31:18.625255 EDT | AverageAbsQYDiff            0.0355457
2017-07-02 14:31:18.625431 EDT | AverageAction               0.883736
2017-07-02 14:31:18.625654 EDT | PolicyRegParamNorm         59.0823
2017-07-02 14:31:18.625876 EDT | QFunRegParamNorm           58.4187
2017-07-02 14:31:18.626013 EDT | -----------------------  ------------
2017-07-02 14:31:18.626183 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #489 | Training started
2017-07-02 14:31:28.172033 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #489 | Training finished
2017-07-02 14:31:28.172537 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #489 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 14:31:28.172719 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #489 | Collecting samples for evaluation
2017-07-02 14:31:33.851388 EDT | -----------------------  ------------
2017-07-02 14:31:33.851708 EDT | Epoch                     489
2017-07-02 14:31:33.851886 EDT | Iteration                 489
2017-07-02 14:31:33.852017 EDT | AverageReturn            1000
2017-07-02 14:31:33.852148 EDT | StdReturn                   0
2017-07-02 14:31:33.852275 EDT | MaxReturn                1000
2017-07-02 14:31:33.852405 EDT | MinReturn                1000
2017-07-02 14:31:33.852534 EDT | AverageEsReturn            25.6842
2017-07-02 14:31:33.852643 EDT | StdEsReturn                25.3129
2017-07-02 14:31:33.852839 EDT | MaxEsReturn               127
2017-07-02 14:31:33.853033 EDT | MinEsReturn                 3
2017-07-02 14:31:33.853154 EDT | AverageDiscountedReturn    99.9957
2017-07-02 14:31:33.853285 EDT | AverageQLoss                0.0151825
2017-07-02 14:31:33.853408 EDT | AveragePolicySurr          -2.09731
2017-07-02 14:31:33.853535 EDT | AverageQ                    1.98422
2017-07-02 14:31:33.853654 EDT | AverageAbsQ                 1.98984
2017-07-02 14:31:33.853784 EDT | AverageY                    1.98427
2017-07-02 14:31:33.853888 EDT | AverageAbsY                 1.98482
2017-07-02 14:31:33.853988 EDT | AverageAbsQYDiff            0.0351224
2017-07-02 14:31:33.854106 EDT | AverageAction               0.9181
2017-07-02 14:31:33.854334 EDT | PolicyRegParamNorm         59.1587
2017-07-02 14:31:33.854565 EDT | QFunRegParamNorm           58.4569
2017-07-02 14:31:33.854751 EDT | -----------------------  ------------
2017-07-02 14:31:33.855083 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #490 | Training started
2017-07-02 14:31:43.457400 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #490 | Training finished
2017-07-02 14:31:43.465589 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #490 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 14:31:43.465841 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #490 | Collecting samples for evaluation
2017-07-02 14:31:49.184047 EDT | -----------------------  ------------
2017-07-02 14:31:49.184311 EDT | Epoch                     490
2017-07-02 14:31:49.184505 EDT | Iteration                 490
2017-07-02 14:31:49.184673 EDT | AverageReturn            1000
2017-07-02 14:31:49.184840 EDT | StdReturn                   0
2017-07-02 14:31:49.185042 EDT | MaxReturn                1000
2017-07-02 14:31:49.185241 EDT | MinReturn                1000
2017-07-02 14:31:49.185367 EDT | AverageEsReturn            28.0278
2017-07-02 14:31:49.185469 EDT | StdEsReturn                21.36
2017-07-02 14:31:49.185645 EDT | MaxEsReturn                99
2017-07-02 14:31:49.185806 EDT | MinEsReturn                 4
2017-07-02 14:31:49.185911 EDT | AverageDiscountedReturn    99.9957
2017-07-02 14:31:49.186077 EDT | AverageQLoss                0.0127121
2017-07-02 14:31:49.186310 EDT | AveragePolicySurr          -2.09189
2017-07-02 14:31:49.186530 EDT | AverageQ                    1.98433
2017-07-02 14:31:49.186762 EDT | AverageAbsQ                 1.98996
2017-07-02 14:31:49.186990 EDT | AverageY                    1.98432
2017-07-02 14:31:49.187153 EDT | AverageAbsY                 1.98499
2017-07-02 14:31:49.187335 EDT | AverageAbsQYDiff            0.0333993
2017-07-02 14:31:49.187528 EDT | AverageAction               0.896258
2017-07-02 14:31:49.187725 EDT | PolicyRegParamNorm         59.2462
2017-07-02 14:31:49.187914 EDT | QFunRegParamNorm           58.4722
2017-07-02 14:31:49.188045 EDT | -----------------------  ------------
2017-07-02 14:31:49.188233 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #491 | Training started
2017-07-02 14:31:58.797349 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #491 | Training finished
2017-07-02 14:31:58.797865 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #491 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 14:31:58.798307 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #491 | Collecting samples for evaluation
2017-07-02 14:32:04.512995 EDT | -----------------------  ------------
2017-07-02 14:32:04.513301 EDT | Epoch                     491
2017-07-02 14:32:04.513549 EDT | Iteration                 491
2017-07-02 14:32:04.513780 EDT | AverageReturn            1000
2017-07-02 14:32:04.514008 EDT | StdReturn                   0
2017-07-02 14:32:04.514237 EDT | MaxReturn                1000
2017-07-02 14:32:04.514447 EDT | MinReturn                1000
2017-07-02 14:32:04.514681 EDT | AverageEsReturn            29.2121
2017-07-02 14:32:04.514896 EDT | StdEsReturn                22.1096
2017-07-02 14:32:04.515118 EDT | MaxEsReturn                90
2017-07-02 14:32:04.515337 EDT | MinEsReturn                 4
2017-07-02 14:32:04.515569 EDT | AverageDiscountedReturn    99.9957
2017-07-02 14:32:04.515807 EDT | AverageQLoss                0.0147477
2017-07-02 14:32:04.516016 EDT | AveragePolicySurr          -2.08061
2017-07-02 14:32:04.516248 EDT | AverageQ                    1.96909
2017-07-02 14:32:04.516468 EDT | AverageAbsQ                 1.97499
2017-07-02 14:32:04.516693 EDT | AverageY                    1.9692
2017-07-02 14:32:04.516906 EDT | AverageAbsY                 1.9699
2017-07-02 14:32:04.517139 EDT | AverageAbsQYDiff            0.0340751
2017-07-02 14:32:04.517372 EDT | AverageAction               0.907097
2017-07-02 14:32:04.517616 EDT | PolicyRegParamNorm         59.3365
2017-07-02 14:32:04.517847 EDT | QFunRegParamNorm           58.4881
2017-07-02 14:32:04.518042 EDT | -----------------------  ------------
2017-07-02 14:32:04.518248 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #492 | Training started
2017-07-02 14:32:14.069567 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #492 | Training finished
2017-07-02 14:32:14.070189 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #492 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 14:32:14.070371 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #492 | Collecting samples for evaluation
2017-07-02 14:32:19.845376 EDT | -----------------------  ------------
2017-07-02 14:32:19.845610 EDT | Epoch                     492
2017-07-02 14:32:19.845749 EDT | Iteration                 492
2017-07-02 14:32:19.845958 EDT | AverageReturn            1000
2017-07-02 14:32:19.846171 EDT | StdReturn                   0
2017-07-02 14:32:19.846312 EDT | MaxReturn                1000
2017-07-02 14:32:19.846454 EDT | MinReturn                1000
2017-07-02 14:32:19.846586 EDT | AverageEsReturn            31.2727
2017-07-02 14:32:19.846708 EDT | StdEsReturn                25.1508
2017-07-02 14:32:19.846811 EDT | MaxEsReturn               113
2017-07-02 14:32:19.846983 EDT | MinEsReturn                 5
2017-07-02 14:32:19.847155 EDT | AverageDiscountedReturn    99.9957
2017-07-02 14:32:19.847350 EDT | AverageQLoss                0.0134325
2017-07-02 14:32:19.847518 EDT | AveragePolicySurr          -2.07282
2017-07-02 14:32:19.847674 EDT | AverageQ                    1.96229
2017-07-02 14:32:19.847848 EDT | AverageAbsQ                 1.96747
2017-07-02 14:32:19.848042 EDT | AverageY                    1.96231
2017-07-02 14:32:19.848226 EDT | AverageAbsY                 1.96288
2017-07-02 14:32:19.848528 EDT | AverageAbsQYDiff            0.0331215
2017-07-02 14:32:19.848734 EDT | AverageAction               0.902405
2017-07-02 14:32:19.848932 EDT | PolicyRegParamNorm         59.4128
2017-07-02 14:32:19.849118 EDT | QFunRegParamNorm           58.5142
2017-07-02 14:32:19.849234 EDT | -----------------------  ------------
2017-07-02 14:32:19.849419 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #493 | Training started
2017-07-02 14:32:29.233827 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #493 | Training finished
2017-07-02 14:32:29.234465 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #493 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 14:32:29.234841 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #493 | Collecting samples for evaluation
2017-07-02 14:32:35.067578 EDT | -----------------------  ------------
2017-07-02 14:32:35.067852 EDT | Epoch                     493
2017-07-02 14:32:35.068008 EDT | Iteration                 493
2017-07-02 14:32:35.068122 EDT | AverageReturn            1000
2017-07-02 14:32:35.068255 EDT | StdReturn                   0
2017-07-02 14:32:35.068358 EDT | MaxReturn                1000
2017-07-02 14:32:35.068469 EDT | MinReturn                1000
2017-07-02 14:32:35.068580 EDT | AverageEsReturn            33.8667
2017-07-02 14:32:35.068766 EDT | StdEsReturn                22.2017
2017-07-02 14:32:35.068898 EDT | MaxEsReturn                88
2017-07-02 14:32:35.069061 EDT | MinEsReturn                 3
2017-07-02 14:32:35.069166 EDT | AverageDiscountedReturn    99.9957
2017-07-02 14:32:35.069267 EDT | AverageQLoss                0.0158461
2017-07-02 14:32:35.069414 EDT | AveragePolicySurr          -2.06445
2017-07-02 14:32:35.069563 EDT | AverageQ                    1.95871
2017-07-02 14:32:35.069776 EDT | AverageAbsQ                 1.96398
2017-07-02 14:32:35.069954 EDT | AverageY                    1.95844
2017-07-02 14:32:35.070129 EDT | AverageAbsY                 1.95893
2017-07-02 14:32:35.070235 EDT | AverageAbsQYDiff            0.0346126
2017-07-02 14:32:35.070360 EDT | AverageAction               0.85924
2017-07-02 14:32:35.070497 EDT | PolicyRegParamNorm         59.4186
2017-07-02 14:32:35.070698 EDT | QFunRegParamNorm           58.5267
2017-07-02 14:32:35.070860 EDT | -----------------------  ------------
2017-07-02 14:32:35.071097 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #494 | Training started
2017-07-02 14:32:44.469722 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #494 | Training finished
2017-07-02 14:32:44.470576 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #494 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 14:32:44.470838 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #494 | Collecting samples for evaluation
2017-07-02 14:32:50.339228 EDT | -----------------------  ------------
2017-07-02 14:32:50.339445 EDT | Epoch                     494
2017-07-02 14:32:50.339645 EDT | Iteration                 494
2017-07-02 14:32:50.339839 EDT | AverageReturn            1000
2017-07-02 14:32:50.340029 EDT | StdReturn                   0
2017-07-02 14:32:50.340221 EDT | MaxReturn                1000
2017-07-02 14:32:50.340426 EDT | MinReturn                1000
2017-07-02 14:32:50.340609 EDT | AverageEsReturn            29.1471
2017-07-02 14:32:50.340716 EDT | StdEsReturn                29.1992
2017-07-02 14:32:50.340819 EDT | MaxEsReturn               168
2017-07-02 14:32:50.340997 EDT | MinEsReturn                 3
2017-07-02 14:32:50.341139 EDT | AverageDiscountedReturn    99.9957
2017-07-02 14:32:50.341279 EDT | AverageQLoss                0.0136742
2017-07-02 14:32:50.341416 EDT | AveragePolicySurr          -2.05233
2017-07-02 14:32:50.341622 EDT | AverageQ                    1.94739
2017-07-02 14:32:50.341728 EDT | AverageAbsQ                 1.95286
2017-07-02 14:32:50.341879 EDT | AverageY                    1.9476
2017-07-02 14:32:50.342001 EDT | AverageAbsY                 1.94812
2017-07-02 14:32:50.342122 EDT | AverageAbsQYDiff            0.032712
2017-07-02 14:32:50.342233 EDT | AverageAction               0.873009
2017-07-02 14:32:50.342447 EDT | PolicyRegParamNorm         59.4554
2017-07-02 14:32:50.342637 EDT | QFunRegParamNorm           58.5736
2017-07-02 14:32:50.342799 EDT | -----------------------  ------------
2017-07-02 14:32:50.343084 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #495 | Training started
2017-07-02 14:32:59.845807 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #495 | Training finished
2017-07-02 14:32:59.846341 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #495 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 14:32:59.846580 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #495 | Collecting samples for evaluation
2017-07-02 14:33:05.609628 EDT | -----------------------  ------------
2017-07-02 14:33:05.609821 EDT | Epoch                     495
2017-07-02 14:33:05.610000 EDT | Iteration                 495
2017-07-02 14:33:05.610186 EDT | AverageReturn            1000
2017-07-02 14:33:05.610388 EDT | StdReturn                   0
2017-07-02 14:33:05.610505 EDT | MaxReturn                1000
2017-07-02 14:33:05.610637 EDT | MinReturn                1000
2017-07-02 14:33:05.610803 EDT | AverageEsReturn            28.5714
2017-07-02 14:33:05.610978 EDT | StdEsReturn                28.524
2017-07-02 14:33:05.611169 EDT | MaxEsReturn               147
2017-07-02 14:33:05.611359 EDT | MinEsReturn                 3
2017-07-02 14:33:05.611532 EDT | AverageDiscountedReturn    99.9957
2017-07-02 14:33:05.611707 EDT | AverageQLoss                0.0133082
2017-07-02 14:33:05.611869 EDT | AveragePolicySurr          -2.0458
2017-07-02 14:33:05.611998 EDT | AverageQ                    1.94013
2017-07-02 14:33:05.612190 EDT | AverageAbsQ                 1.94448
2017-07-02 14:33:05.612366 EDT | AverageY                    1.94016
2017-07-02 14:33:05.612592 EDT | AverageAbsY                 1.94064
2017-07-02 14:33:05.612821 EDT | AverageAbsQYDiff            0.0322534
2017-07-02 14:33:05.613037 EDT | AverageAction               0.72858
2017-07-02 14:33:05.613277 EDT | PolicyRegParamNorm         59.5118
2017-07-02 14:33:05.613710 EDT | QFunRegParamNorm           58.6065
2017-07-02 14:33:05.613954 EDT | -----------------------  ------------
2017-07-02 14:33:05.614258 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #496 | Training started
2017-07-02 14:33:15.218300 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #496 | Training finished
2017-07-02 14:33:15.251351 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #496 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 14:33:15.251580 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #496 | Collecting samples for evaluation
2017-07-02 14:33:20.957225 EDT | -----------------------  ------------
2017-07-02 14:33:20.957526 EDT | Epoch                     496
2017-07-02 14:33:20.957717 EDT | Iteration                 496
2017-07-02 14:33:20.957888 EDT | AverageReturn            1000
2017-07-02 14:33:20.958080 EDT | StdReturn                   0
2017-07-02 14:33:20.958306 EDT | MaxReturn                1000
2017-07-02 14:33:20.958515 EDT | MinReturn                1000
2017-07-02 14:33:20.958727 EDT | AverageEsReturn            27.2778
2017-07-02 14:33:20.958951 EDT | StdEsReturn                23.2864
2017-07-02 14:33:20.959168 EDT | MaxEsReturn                89
2017-07-02 14:33:20.959355 EDT | MinEsReturn                 3
2017-07-02 14:33:20.959543 EDT | AverageDiscountedReturn    99.9957
2017-07-02 14:33:20.959707 EDT | AverageQLoss                0.0119044
2017-07-02 14:33:20.959812 EDT | AveragePolicySurr          -2.03114
2017-07-02 14:33:20.959945 EDT | AverageQ                    1.92947
2017-07-02 14:33:20.960150 EDT | AverageAbsQ                 1.9343
2017-07-02 14:33:20.960368 EDT | AverageY                    1.9294
2017-07-02 14:33:20.960555 EDT | AverageAbsY                 1.92987
2017-07-02 14:33:20.960718 EDT | AverageAbsQYDiff            0.0297295
2017-07-02 14:33:20.960823 EDT | AverageAction               0.779027
2017-07-02 14:33:20.960924 EDT | PolicyRegParamNorm         59.539
2017-07-02 14:33:20.961024 EDT | QFunRegParamNorm           58.6837
2017-07-02 14:33:20.961122 EDT | -----------------------  ------------
2017-07-02 14:33:20.961336 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #497 | Training started
2017-07-02 14:33:30.630880 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #497 | Training finished
2017-07-02 14:33:30.631419 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #497 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 14:33:30.631547 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #497 | Collecting samples for evaluation
2017-07-02 14:33:36.259272 EDT | -----------------------  ------------
2017-07-02 14:33:36.259582 EDT | Epoch                     497
2017-07-02 14:33:36.259814 EDT | Iteration                 497
2017-07-02 14:33:36.260042 EDT | AverageReturn            1000
2017-07-02 14:33:36.260273 EDT | StdReturn                   0
2017-07-02 14:33:36.260485 EDT | MaxReturn                1000
2017-07-02 14:33:36.260715 EDT | MinReturn                1000
2017-07-02 14:33:36.260943 EDT | AverageEsReturn            39.52
2017-07-02 14:33:36.261173 EDT | StdEsReturn                37.6671
2017-07-02 14:33:36.261391 EDT | MaxEsReturn               143
2017-07-02 14:33:36.261846 EDT | MinEsReturn                 5
2017-07-02 14:33:36.262030 EDT | AverageDiscountedReturn    99.9957
2017-07-02 14:33:36.262157 EDT | AverageQLoss                0.015155
2017-07-02 14:33:36.262277 EDT | AveragePolicySurr          -2.02287
2017-07-02 14:33:36.262415 EDT | AverageQ                    1.91659
2017-07-02 14:33:36.262518 EDT | AverageAbsQ                 1.92186
2017-07-02 14:33:36.262659 EDT | AverageY                    1.91656
2017-07-02 14:33:36.262777 EDT | AverageAbsY                 1.9171
2017-07-02 14:33:36.262880 EDT | AverageAbsQYDiff            0.0335507
2017-07-02 14:33:36.262992 EDT | AverageAction               0.850073
2017-07-02 14:33:36.263139 EDT | PolicyRegParamNorm         59.5948
2017-07-02 14:33:36.263242 EDT | QFunRegParamNorm           58.7062
2017-07-02 14:33:36.263374 EDT | -----------------------  ------------
2017-07-02 14:33:36.263608 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #498 | Training started
2017-07-02 14:33:45.893890 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #498 | Training finished
2017-07-02 14:33:45.894477 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #498 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 14:33:45.894723 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #498 | Collecting samples for evaluation
2017-07-02 14:33:51.574578 EDT | -----------------------  ------------
2017-07-02 14:33:51.575169 EDT | Epoch                     498
2017-07-02 14:33:51.575320 EDT | Iteration                 498
2017-07-02 14:33:51.575498 EDT | AverageReturn            1000
2017-07-02 14:33:51.575621 EDT | StdReturn                   0
2017-07-02 14:33:51.575737 EDT | MaxReturn                1000
2017-07-02 14:33:51.575885 EDT | MinReturn                1000
2017-07-02 14:33:51.576001 EDT | AverageEsReturn            38.5556
2017-07-02 14:33:51.576125 EDT | StdEsReturn                35.4216
2017-07-02 14:33:51.576228 EDT | MaxEsReturn               176
2017-07-02 14:33:51.576391 EDT | MinEsReturn                 4
2017-07-02 14:33:51.576582 EDT | AverageDiscountedReturn    99.9957
2017-07-02 14:33:51.576741 EDT | AverageQLoss                0.0128218
2017-07-02 14:33:51.576884 EDT | AveragePolicySurr          -2.01299
2017-07-02 14:33:51.576988 EDT | AverageQ                    1.91274
2017-07-02 14:33:51.577143 EDT | AverageAbsQ                 1.91856
2017-07-02 14:33:51.577272 EDT | AverageY                    1.91254
2017-07-02 14:33:51.577378 EDT | AverageAbsY                 1.91307
2017-07-02 14:33:51.577544 EDT | AverageAbsQYDiff            0.0316012
2017-07-02 14:33:51.577719 EDT | AverageAction               0.70352
2017-07-02 14:33:51.577880 EDT | PolicyRegParamNorm         59.6296
2017-07-02 14:33:51.578062 EDT | QFunRegParamNorm           58.7648
2017-07-02 14:33:51.578234 EDT | -----------------------  ------------
2017-07-02 14:33:51.578411 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #499 | Training started
2017-07-02 14:34:01.076014 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #499 | Training finished
2017-07-02 14:34:01.076593 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #499 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 14:34:01.076862 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #499 | Collecting samples for evaluation
2017-07-02 14:34:06.806049 EDT | -----------------------  ------------
2017-07-02 14:34:06.806301 EDT | Epoch                     499
2017-07-02 14:34:06.806413 EDT | Iteration                 499
2017-07-02 14:34:06.806518 EDT | AverageReturn            1000
2017-07-02 14:34:06.806664 EDT | StdReturn                   0
2017-07-02 14:34:06.806767 EDT | MaxReturn                1000
2017-07-02 14:34:06.806868 EDT | MinReturn                1000
2017-07-02 14:34:06.807029 EDT | AverageEsReturn            39.92
2017-07-02 14:34:06.807225 EDT | StdEsReturn                37.4282
2017-07-02 14:34:06.807415 EDT | MaxEsReturn               138
2017-07-02 14:34:06.807543 EDT | MinEsReturn                 4
2017-07-02 14:34:06.807655 EDT | AverageDiscountedReturn    99.9957
2017-07-02 14:34:06.807857 EDT | AverageQLoss                0.0120782
2017-07-02 14:34:06.808001 EDT | AveragePolicySurr          -2.00472
2017-07-02 14:34:06.808376 EDT | AverageQ                    1.90016
2017-07-02 14:34:06.808590 EDT | AverageAbsQ                 1.90536
2017-07-02 14:34:06.808753 EDT | AverageY                    1.90024
2017-07-02 14:34:06.808915 EDT | AverageAbsY                 1.90085
2017-07-02 14:34:06.809081 EDT | AverageAbsQYDiff            0.0299854
2017-07-02 14:34:06.809306 EDT | AverageAction               0.765975
2017-07-02 14:34:06.809602 EDT | PolicyRegParamNorm         59.6529
2017-07-02 14:34:06.809838 EDT | QFunRegParamNorm           58.7921
2017-07-02 14:34:06.810045 EDT | -----------------------  ------------
2017-07-02 14:34:06.810270 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #500 | Training started
2017-07-02 14:34:16.301546 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #500 | Training finished
2017-07-02 14:34:16.302099 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #500 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 14:34:16.302428 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #500 | Collecting samples for evaluation
2017-07-02 14:34:21.938410 EDT | -----------------------  ------------
2017-07-02 14:34:21.938615 EDT | Epoch                     500
2017-07-02 14:34:21.938769 EDT | Iteration                 500
2017-07-02 14:34:21.938966 EDT | AverageReturn            1000
2017-07-02 14:34:21.939153 EDT | StdReturn                   0
2017-07-02 14:34:21.939306 EDT | MaxReturn                1000
2017-07-02 14:34:21.939427 EDT | MinReturn                1000
2017-07-02 14:34:21.939570 EDT | AverageEsReturn            43.1739
2017-07-02 14:34:21.939677 EDT | StdEsReturn                41.7307
2017-07-02 14:34:21.939795 EDT | MaxEsReturn               179
2017-07-02 14:34:21.939919 EDT | MinEsReturn                 3
2017-07-02 14:34:21.940117 EDT | AverageDiscountedReturn    99.9957
2017-07-02 14:34:21.940303 EDT | AverageQLoss                0.0144331
2017-07-02 14:34:21.940407 EDT | AveragePolicySurr          -1.99433
2017-07-02 14:34:21.940569 EDT | AverageQ                    1.8903
2017-07-02 14:34:21.940732 EDT | AverageAbsQ                 1.89614
2017-07-02 14:34:21.940851 EDT | AverageY                    1.89032
2017-07-02 14:34:21.941021 EDT | AverageAbsY                 1.89103
2017-07-02 14:34:21.941178 EDT | AverageAbsQYDiff            0.0331295
2017-07-02 14:34:21.941366 EDT | AverageAction               0.758984
2017-07-02 14:34:21.941743 EDT | PolicyRegParamNorm         59.6654
2017-07-02 14:34:21.941885 EDT | QFunRegParamNorm           58.8268
2017-07-02 14:34:21.942057 EDT | -----------------------  ------------
2017-07-02 14:34:21.942232 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #501 | Training started
2017-07-02 14:34:31.449412 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #501 | Training finished
2017-07-02 14:34:31.450187 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #501 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 14:34:31.450484 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #501 | Collecting samples for evaluation
2017-07-02 14:34:37.203556 EDT | -----------------------  ------------
2017-07-02 14:34:37.203764 EDT | Epoch                     501
2017-07-02 14:34:37.203894 EDT | Iteration                 501
2017-07-02 14:34:37.204032 EDT | AverageReturn            1000
2017-07-02 14:34:37.204206 EDT | StdReturn                   0
2017-07-02 14:34:37.204412 EDT | MaxReturn                1000
2017-07-02 14:34:37.204619 EDT | MinReturn                1000
2017-07-02 14:34:37.204811 EDT | AverageEsReturn            47.4762
2017-07-02 14:34:37.204997 EDT | StdEsReturn                41.7904
2017-07-02 14:34:37.205113 EDT | MaxEsReturn               153
2017-07-02 14:34:37.205267 EDT | MinEsReturn                 6
2017-07-02 14:34:37.205388 EDT | AverageDiscountedReturn    99.9957
2017-07-02 14:34:37.205524 EDT | AverageQLoss                0.0129192
2017-07-02 14:34:37.205638 EDT | AveragePolicySurr          -1.98282
2017-07-02 14:34:37.205746 EDT | AverageQ                    1.8788
2017-07-02 14:34:37.205848 EDT | AverageAbsQ                 1.88378
2017-07-02 14:34:37.205948 EDT | AverageY                    1.87871
2017-07-02 14:34:37.206049 EDT | AverageAbsY                 1.87935
2017-07-02 14:34:37.206149 EDT | AverageAbsQYDiff            0.0309622
2017-07-02 14:34:37.206323 EDT | AverageAction               0.906811
2017-07-02 14:34:37.206516 EDT | PolicyRegParamNorm         59.6029
2017-07-02 14:34:37.206718 EDT | QFunRegParamNorm           58.8355
2017-07-02 14:34:37.206855 EDT | -----------------------  ------------
2017-07-02 14:34:37.207075 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #502 | Training started
2017-07-02 14:34:46.974565 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #502 | Training finished
2017-07-02 14:34:46.975092 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #502 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 14:34:46.975240 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #502 | Collecting samples for evaluation
2017-07-02 14:34:52.735842 EDT | -----------------------  ------------
2017-07-02 14:34:52.736127 EDT | Epoch                     502
2017-07-02 14:34:52.736353 EDT | Iteration                 502
2017-07-02 14:34:52.736470 EDT | AverageReturn            1000
2017-07-02 14:34:52.736586 EDT | StdReturn                   0
2017-07-02 14:34:52.736724 EDT | MaxReturn                1000
2017-07-02 14:34:52.736904 EDT | MinReturn                1000
2017-07-02 14:34:52.737011 EDT | AverageEsReturn            34.6207
2017-07-02 14:34:52.737114 EDT | StdEsReturn                36.4525
2017-07-02 14:34:52.737241 EDT | MaxEsReturn               149
2017-07-02 14:34:52.737342 EDT | MinEsReturn                 3
2017-07-02 14:34:52.737442 EDT | AverageDiscountedReturn    99.9957
2017-07-02 14:34:52.737607 EDT | AverageQLoss                0.0120661
2017-07-02 14:34:52.737750 EDT | AveragePolicySurr          -1.97766
2017-07-02 14:34:52.737871 EDT | AverageQ                    1.87611
2017-07-02 14:34:52.737972 EDT | AverageAbsQ                 1.88096
2017-07-02 14:34:52.738072 EDT | AverageY                    1.87608
2017-07-02 14:34:52.738208 EDT | AverageAbsY                 1.87661
2017-07-02 14:34:52.738313 EDT | AverageAbsQYDiff            0.0296474
2017-07-02 14:34:52.738414 EDT | AverageAction               0.560994
2017-07-02 14:34:52.738527 EDT | PolicyRegParamNorm         59.6703
2017-07-02 14:34:52.738728 EDT | QFunRegParamNorm           58.8761
2017-07-02 14:34:52.738911 EDT | -----------------------  ------------
2017-07-02 14:34:52.739083 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #503 | Training started
2017-07-02 14:35:02.327166 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #503 | Training finished
2017-07-02 14:35:02.327777 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #503 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 14:35:02.328028 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #503 | Collecting samples for evaluation
2017-07-02 14:35:08.078012 EDT | -----------------------  ------------
2017-07-02 14:35:08.078257 EDT | Epoch                     503
2017-07-02 14:35:08.078378 EDT | Iteration                 503
2017-07-02 14:35:08.078545 EDT | AverageReturn            1000
2017-07-02 14:35:08.078649 EDT | StdReturn                   0
2017-07-02 14:35:08.078756 EDT | MaxReturn                1000
2017-07-02 14:35:08.078967 EDT | MinReturn                1000
2017-07-02 14:35:08.079152 EDT | AverageEsReturn            29.5294
2017-07-02 14:35:08.079347 EDT | StdEsReturn                25.8004
2017-07-02 14:35:08.079541 EDT | MaxEsReturn               125
2017-07-02 14:35:08.079663 EDT | MinEsReturn                 3
2017-07-02 14:35:08.079846 EDT | AverageDiscountedReturn    99.9957
2017-07-02 14:35:08.080026 EDT | AverageQLoss                0.0130448
2017-07-02 14:35:08.080132 EDT | AveragePolicySurr          -1.96595
2017-07-02 14:35:08.080233 EDT | AverageQ                    1.86275
2017-07-02 14:35:08.080333 EDT | AverageAbsQ                 1.86778
2017-07-02 14:35:08.080490 EDT | AverageY                    1.86276
2017-07-02 14:35:08.080611 EDT | AverageAbsY                 1.86338
2017-07-02 14:35:08.080713 EDT | AverageAbsQYDiff            0.0313993
2017-07-02 14:35:08.080881 EDT | AverageAction               0.503712
2017-07-02 14:35:08.081076 EDT | PolicyRegParamNorm         59.7603
2017-07-02 14:35:08.081275 EDT | QFunRegParamNorm           58.9047
2017-07-02 14:35:08.081447 EDT | -----------------------  ------------
2017-07-02 14:35:08.081733 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #504 | Training started
2017-07-02 14:35:17.577632 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #504 | Training finished
2017-07-02 14:35:17.578269 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #504 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 14:35:17.578503 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #504 | Collecting samples for evaluation
2017-07-02 14:35:23.863105 EDT | -----------------------  ------------
2017-07-02 14:35:23.863317 EDT | Epoch                     504
2017-07-02 14:35:23.863445 EDT | Iteration                 504
2017-07-02 14:35:23.863610 EDT | AverageReturn            1000
2017-07-02 14:35:23.863801 EDT | StdReturn                   0
2017-07-02 14:35:23.863980 EDT | MaxReturn                1000
2017-07-02 14:35:23.864187 EDT | MinReturn                1000
2017-07-02 14:35:23.864322 EDT | AverageEsReturn            28.6
2017-07-02 14:35:23.864440 EDT | StdEsReturn                25.4852
2017-07-02 14:35:23.864541 EDT | MaxEsReturn                99
2017-07-02 14:35:23.864642 EDT | MinEsReturn                 3
2017-07-02 14:35:23.864764 EDT | AverageDiscountedReturn    99.9957
2017-07-02 14:35:23.864865 EDT | AverageQLoss                0.0130212
2017-07-02 14:35:23.864987 EDT | AveragePolicySurr          -1.95924
2017-07-02 14:35:23.865131 EDT | AverageQ                    1.8596
2017-07-02 14:35:23.865233 EDT | AverageAbsQ                 1.86514
2017-07-02 14:35:23.865352 EDT | AverageY                    1.85952
2017-07-02 14:35:23.865544 EDT | AverageAbsY                 1.86002
2017-07-02 14:35:23.865655 EDT | AverageAbsQYDiff            0.0312876
2017-07-02 14:35:23.865793 EDT | AverageAction               0.710386
2017-07-02 14:35:23.865895 EDT | PolicyRegParamNorm         59.7339
2017-07-02 14:35:23.865995 EDT | QFunRegParamNorm           58.9259
2017-07-02 14:35:23.866164 EDT | -----------------------  ------------
2017-07-02 14:35:23.866427 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #505 | Training started
2017-07-02 14:35:33.352637 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #505 | Training finished
2017-07-02 14:35:33.353349 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #505 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 14:35:33.353623 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #505 | Collecting samples for evaluation
2017-07-02 14:35:39.124415 EDT | -----------------------  ------------
2017-07-02 14:35:39.124724 EDT | Epoch                     505
2017-07-02 14:35:39.124961 EDT | Iteration                 505
2017-07-02 14:35:39.125171 EDT | AverageReturn            1000
2017-07-02 14:35:39.125413 EDT | StdReturn                   0
2017-07-02 14:35:39.125668 EDT | MaxReturn                1000
2017-07-02 14:35:39.125900 EDT | MinReturn                1000
2017-07-02 14:35:39.126113 EDT | AverageEsReturn            30.2188
2017-07-02 14:35:39.126328 EDT | StdEsReturn                26.5138
2017-07-02 14:35:39.126562 EDT | MaxEsReturn               123
2017-07-02 14:35:39.126767 EDT | MinEsReturn                 3
2017-07-02 14:35:39.126927 EDT | AverageDiscountedReturn    99.9957
2017-07-02 14:35:39.127112 EDT | AverageQLoss                0.0134799
2017-07-02 14:35:39.127219 EDT | AveragePolicySurr          -1.9506
2017-07-02 14:35:39.127321 EDT | AverageQ                    1.85098
2017-07-02 14:35:39.127456 EDT | AverageAbsQ                 1.8557
2017-07-02 14:35:39.127676 EDT | AverageY                    1.85083
2017-07-02 14:35:39.127892 EDT | AverageAbsY                 1.85121
2017-07-02 14:35:39.128119 EDT | AverageAbsQYDiff            0.0314096
2017-07-02 14:35:39.128330 EDT | AverageAction               0.853505
2017-07-02 14:35:39.128538 EDT | PolicyRegParamNorm         59.7756
2017-07-02 14:35:39.128771 EDT | QFunRegParamNorm           58.9524
2017-07-02 14:35:39.128998 EDT | -----------------------  ------------
2017-07-02 14:35:39.129331 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #506 | Training started
2017-07-02 14:35:48.641716 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #506 | Training finished
2017-07-02 14:35:48.642338 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #506 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 14:35:48.642602 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #506 | Collecting samples for evaluation
2017-07-02 14:35:54.370994 EDT | -----------------------  ------------
2017-07-02 14:35:54.371251 EDT | Epoch                     506
2017-07-02 14:35:54.371455 EDT | Iteration                 506
2017-07-02 14:35:54.371586 EDT | AverageReturn            1000
2017-07-02 14:35:54.371726 EDT | StdReturn                   0
2017-07-02 14:35:54.371829 EDT | MaxReturn                1000
2017-07-02 14:35:54.371965 EDT | MinReturn                1000
2017-07-02 14:35:54.372106 EDT | AverageEsReturn            29.0303
2017-07-02 14:35:54.372240 EDT | StdEsReturn                25.2364
2017-07-02 14:35:54.372341 EDT | MaxEsReturn               131
2017-07-02 14:35:54.372458 EDT | MinEsReturn                 6
2017-07-02 14:35:54.372600 EDT | AverageDiscountedReturn    99.9957
2017-07-02 14:35:54.372700 EDT | AverageQLoss                0.0134709
2017-07-02 14:35:54.372819 EDT | AveragePolicySurr          -1.94209
2017-07-02 14:35:54.372954 EDT | AverageQ                    1.84396
2017-07-02 14:35:54.373063 EDT | AverageAbsQ                 1.84919
2017-07-02 14:35:54.373166 EDT | AverageY                    1.84408
2017-07-02 14:35:54.373309 EDT | AverageAbsY                 1.8447
2017-07-02 14:35:54.373576 EDT | AverageAbsQYDiff            0.0311952
2017-07-02 14:35:54.373777 EDT | AverageAction               0.926909
2017-07-02 14:35:54.374007 EDT | PolicyRegParamNorm         59.7836
2017-07-02 14:35:54.374157 EDT | QFunRegParamNorm           58.9613
2017-07-02 14:35:54.374352 EDT | -----------------------  ------------
2017-07-02 14:35:54.374580 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #507 | Training started
2017-07-02 14:36:03.936571 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #507 | Training finished
2017-07-02 14:36:03.937099 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #507 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 14:36:03.937266 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #507 | Collecting samples for evaluation
2017-07-02 14:36:09.679243 EDT | -----------------------  ------------
2017-07-02 14:36:09.679561 EDT | Epoch                     507
2017-07-02 14:36:09.679789 EDT | Iteration                 507
2017-07-02 14:36:09.679982 EDT | AverageReturn            1000
2017-07-02 14:36:09.680152 EDT | StdReturn                   0
2017-07-02 14:36:09.680371 EDT | MaxReturn                1000
2017-07-02 14:36:09.680483 EDT | MinReturn                1000
2017-07-02 14:36:09.680618 EDT | AverageEsReturn            30.7941
2017-07-02 14:36:09.680842 EDT | StdEsReturn                28.6056
2017-07-02 14:36:09.681053 EDT | MaxEsReturn               126
2017-07-02 14:36:09.681160 EDT | MinEsReturn                 3
2017-07-02 14:36:09.681260 EDT | AverageDiscountedReturn    99.9957
2017-07-02 14:36:09.681359 EDT | AverageQLoss                0.0104902
2017-07-02 14:36:09.681457 EDT | AveragePolicySurr          -1.93175
2017-07-02 14:36:09.681948 EDT | AverageQ                    1.83387
2017-07-02 14:36:09.682179 EDT | AverageAbsQ                 1.83884
2017-07-02 14:36:09.682405 EDT | AverageY                    1.83372
2017-07-02 14:36:09.682584 EDT | AverageAbsY                 1.83431
2017-07-02 14:36:09.682728 EDT | AverageAbsQYDiff            0.0281712
2017-07-02 14:36:09.682961 EDT | AverageAction               0.868216
2017-07-02 14:36:09.683198 EDT | PolicyRegParamNorm         59.8429
2017-07-02 14:36:09.683424 EDT | QFunRegParamNorm           58.9873
2017-07-02 14:36:09.683650 EDT | -----------------------  ------------
2017-07-02 14:36:09.683964 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #508 | Training started
2017-07-02 14:36:19.324657 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #508 | Training finished
2017-07-02 14:36:19.325205 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #508 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 14:36:19.325416 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #508 | Collecting samples for evaluation
2017-07-02 14:36:24.968457 EDT | -----------------------  ------------
2017-07-02 14:36:24.968659 EDT | Epoch                     508
2017-07-02 14:36:24.968790 EDT | Iteration                 508
2017-07-02 14:36:24.968898 EDT | AverageReturn            1000
2017-07-02 14:36:24.969002 EDT | StdReturn                   0
2017-07-02 14:36:24.969143 EDT | MaxReturn                1000
2017-07-02 14:36:24.969246 EDT | MinReturn                1000
2017-07-02 14:36:24.969347 EDT | AverageEsReturn            35.5517
2017-07-02 14:36:24.969460 EDT | StdEsReturn                27.4862
2017-07-02 14:36:24.969644 EDT | MaxEsReturn               119
2017-07-02 14:36:24.969760 EDT | MinEsReturn                 3
2017-07-02 14:36:24.969864 EDT | AverageDiscountedReturn    99.9957
2017-07-02 14:36:24.970069 EDT | AverageQLoss                0.0113704
2017-07-02 14:36:24.970218 EDT | AveragePolicySurr          -1.91943
2017-07-02 14:36:24.970320 EDT | AverageQ                    1.82521
2017-07-02 14:36:24.970443 EDT | AverageAbsQ                 1.83032
2017-07-02 14:36:24.970547 EDT | AverageY                    1.82522
2017-07-02 14:36:24.970678 EDT | AverageAbsY                 1.82561
2017-07-02 14:36:24.970817 EDT | AverageAbsQYDiff            0.0291072
2017-07-02 14:36:24.970953 EDT | AverageAction               0.800035
2017-07-02 14:36:24.971149 EDT | PolicyRegParamNorm         59.9474
2017-07-02 14:36:24.971318 EDT | QFunRegParamNorm           59.0188
2017-07-02 14:36:24.971510 EDT | -----------------------  ------------
2017-07-02 14:36:24.971679 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #509 | Training started
2017-07-02 14:36:34.537650 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #509 | Training finished
2017-07-02 14:36:34.538202 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #509 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 14:36:34.538463 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #509 | Collecting samples for evaluation
2017-07-02 14:36:40.248649 EDT | -----------------------  ------------
2017-07-02 14:36:40.248880 EDT | Epoch                     509
2017-07-02 14:36:40.248997 EDT | Iteration                 509
2017-07-02 14:36:40.249115 EDT | AverageReturn            1000
2017-07-02 14:36:40.249228 EDT | StdReturn                   0
2017-07-02 14:36:40.249391 EDT | MaxReturn                1000
2017-07-02 14:36:40.249573 EDT | MinReturn                1000
2017-07-02 14:36:40.249781 EDT | AverageEsReturn            25.4054
2017-07-02 14:36:40.249932 EDT | StdEsReturn                20.2811
2017-07-02 14:36:40.250079 EDT | MaxEsReturn                82
2017-07-02 14:36:40.250186 EDT | MinEsReturn                 3
2017-07-02 14:36:40.250308 EDT | AverageDiscountedReturn    99.9957
2017-07-02 14:36:40.250435 EDT | AverageQLoss                0.0117067
2017-07-02 14:36:40.250561 EDT | AveragePolicySurr          -1.91241
2017-07-02 14:36:40.250699 EDT | AverageQ                    1.81298
2017-07-02 14:36:40.250905 EDT | AverageAbsQ                 1.81792
2017-07-02 14:36:40.251090 EDT | AverageY                    1.81294
2017-07-02 14:36:40.251234 EDT | AverageAbsY                 1.81342
2017-07-02 14:36:40.251337 EDT | AverageAbsQYDiff            0.02922
2017-07-02 14:36:40.251440 EDT | AverageAction               0.561717
2017-07-02 14:36:40.251598 EDT | PolicyRegParamNorm         59.957
2017-07-02 14:36:40.251752 EDT | QFunRegParamNorm           59.0658
2017-07-02 14:36:40.251866 EDT | -----------------------  ------------
2017-07-02 14:36:40.252136 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #510 | Training started
2017-07-02 14:36:49.720375 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #510 | Training finished
2017-07-02 14:36:49.721000 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #510 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 14:36:49.721240 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #510 | Collecting samples for evaluation
2017-07-02 14:36:55.513409 EDT | -----------------------  ------------
2017-07-02 14:36:55.513673 EDT | Epoch                     510
2017-07-02 14:36:55.513875 EDT | Iteration                 510
2017-07-02 14:36:55.514075 EDT | AverageReturn            1000
2017-07-02 14:36:55.514214 EDT | StdReturn                   0
2017-07-02 14:36:55.514393 EDT | MaxReturn                1000
2017-07-02 14:36:55.514587 EDT | MinReturn                1000
2017-07-02 14:36:55.514803 EDT | AverageEsReturn            32.0909
2017-07-02 14:36:55.515015 EDT | StdEsReturn                40.4373
2017-07-02 14:36:55.515237 EDT | MaxEsReturn               182
2017-07-02 14:36:55.515460 EDT | MinEsReturn                 3
2017-07-02 14:36:55.515667 EDT | AverageDiscountedReturn    99.9957
2017-07-02 14:36:55.515814 EDT | AverageQLoss                0.0129587
2017-07-02 14:36:55.516007 EDT | AveragePolicySurr          -1.89976
2017-07-02 14:36:55.516216 EDT | AverageQ                    1.80776
2017-07-02 14:36:55.516432 EDT | AverageAbsQ                 1.8131
2017-07-02 14:36:55.516628 EDT | AverageY                    1.8077
2017-07-02 14:36:55.516852 EDT | AverageAbsY                 1.80832
2017-07-02 14:36:55.517069 EDT | AverageAbsQYDiff            0.0315506
2017-07-02 14:36:55.517297 EDT | AverageAction               0.663814
2017-07-02 14:36:55.517923 EDT | PolicyRegParamNorm         60.0241
2017-07-02 14:36:55.518136 EDT | QFunRegParamNorm           59.1219
2017-07-02 14:36:55.518365 EDT | -----------------------  ------------
2017-07-02 14:36:55.518553 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #511 | Training started
2017-07-02 14:37:04.961072 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #511 | Training finished
2017-07-02 14:37:04.961576 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #511 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 14:37:04.961737 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #511 | Collecting samples for evaluation
2017-07-02 14:37:10.715705 EDT | -----------------------  ------------
2017-07-02 14:37:10.715983 EDT | Epoch                     511
2017-07-02 14:37:10.716121 EDT | Iteration                 511
2017-07-02 14:37:10.716256 EDT | AverageReturn            1000
2017-07-02 14:37:10.716390 EDT | StdReturn                   0
2017-07-02 14:37:10.716495 EDT | MaxReturn                1000
2017-07-02 14:37:10.716620 EDT | MinReturn                1000
2017-07-02 14:37:10.716762 EDT | AverageEsReturn            19.96
2017-07-02 14:37:10.716866 EDT | StdEsReturn                17.1347
2017-07-02 14:37:10.716968 EDT | MaxEsReturn                95
2017-07-02 14:37:10.717112 EDT | MinEsReturn                 3
2017-07-02 14:37:10.717220 EDT | AverageDiscountedReturn    99.9957
2017-07-02 14:37:10.717332 EDT | AverageQLoss                0.0109487
2017-07-02 14:37:10.717481 EDT | AveragePolicySurr          -1.89452
2017-07-02 14:37:10.717690 EDT | AverageQ                    1.8001
2017-07-02 14:37:10.717911 EDT | AverageAbsQ                 1.80433
2017-07-02 14:37:10.718211 EDT | AverageY                    1.80012
2017-07-02 14:37:10.718450 EDT | AverageAbsY                 1.80049
2017-07-02 14:37:10.718681 EDT | AverageAbsQYDiff            0.0284274
2017-07-02 14:37:10.718889 EDT | AverageAction               0.754587
2017-07-02 14:37:10.719121 EDT | PolicyRegParamNorm         60.092
2017-07-02 14:37:10.719336 EDT | QFunRegParamNorm           59.1548
2017-07-02 14:37:10.719458 EDT | -----------------------  ------------
2017-07-02 14:37:10.719788 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #512 | Training started
2017-07-02 14:37:20.239377 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #512 | Training finished
2017-07-02 14:37:20.240265 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #512 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 14:37:20.240489 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #512 | Collecting samples for evaluation
2017-07-02 14:37:25.993622 EDT | -----------------------  ------------
2017-07-02 14:37:25.993905 EDT | Epoch                     512
2017-07-02 14:37:25.994017 EDT | Iteration                 512
2017-07-02 14:37:25.994123 EDT | AverageReturn            1000
2017-07-02 14:37:25.994226 EDT | StdReturn                   0
2017-07-02 14:37:25.994328 EDT | MaxReturn                1000
2017-07-02 14:37:25.994430 EDT | MinReturn                1000
2017-07-02 14:37:25.994594 EDT | AverageEsReturn            27.6944
2017-07-02 14:37:25.994738 EDT | StdEsReturn                19.7707
2017-07-02 14:37:25.994842 EDT | MaxEsReturn                79
2017-07-02 14:37:25.994954 EDT | MinEsReturn                 3
2017-07-02 14:37:25.995059 EDT | AverageDiscountedReturn    99.9957
2017-07-02 14:37:25.995166 EDT | AverageQLoss                0.0107484
2017-07-02 14:37:25.995269 EDT | AveragePolicySurr          -1.8845
2017-07-02 14:37:25.995369 EDT | AverageQ                    1.79154
2017-07-02 14:37:25.995470 EDT | AverageAbsQ                 1.79617
2017-07-02 14:37:25.995588 EDT | AverageY                    1.79149
2017-07-02 14:37:25.995691 EDT | AverageAbsY                 1.7919
2017-07-02 14:37:25.995791 EDT | AverageAbsQYDiff            0.0285873
2017-07-02 14:37:25.995891 EDT | AverageAction               0.693191
2017-07-02 14:37:25.995990 EDT | PolicyRegParamNorm         60.1088
2017-07-02 14:37:25.996088 EDT | QFunRegParamNorm           59.1876
2017-07-02 14:37:25.996187 EDT | -----------------------  ------------
2017-07-02 14:37:25.996367 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #513 | Training started
2017-07-02 14:37:35.638985 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #513 | Training finished
2017-07-02 14:37:35.639292 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #513 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 14:37:35.639467 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #513 | Collecting samples for evaluation
2017-07-02 14:37:41.304761 EDT | -----------------------  ------------
2017-07-02 14:37:41.305284 EDT | Epoch                     513
2017-07-02 14:37:41.305429 EDT | Iteration                 513
2017-07-02 14:37:41.305624 EDT | AverageReturn            1000
2017-07-02 14:37:41.305834 EDT | StdReturn                   0
2017-07-02 14:37:41.305948 EDT | MaxReturn                1000
2017-07-02 14:37:41.306054 EDT | MinReturn                1000
2017-07-02 14:37:41.306192 EDT | AverageEsReturn            28.6857
2017-07-02 14:37:41.306326 EDT | StdEsReturn                24.1197
2017-07-02 14:37:41.306448 EDT | MaxEsReturn               110
2017-07-02 14:37:41.306584 EDT | MinEsReturn                 3
2017-07-02 14:37:41.306688 EDT | AverageDiscountedReturn    99.9957
2017-07-02 14:37:41.306790 EDT | AverageQLoss                0.0116896
2017-07-02 14:37:41.306896 EDT | AveragePolicySurr          -1.87546
2017-07-02 14:37:41.307018 EDT | AverageQ                    1.78168
2017-07-02 14:37:41.307153 EDT | AverageAbsQ                 1.78665
2017-07-02 14:37:41.307292 EDT | AverageY                    1.78154
2017-07-02 14:37:41.307395 EDT | AverageAbsY                 1.7821
2017-07-02 14:37:41.307497 EDT | AverageAbsQYDiff            0.0301427
2017-07-02 14:37:41.307678 EDT | AverageAction               0.746984
2017-07-02 14:37:41.307851 EDT | PolicyRegParamNorm         60.1519
2017-07-02 14:37:41.308054 EDT | QFunRegParamNorm           59.2253
2017-07-02 14:37:41.308235 EDT | -----------------------  ------------
2017-07-02 14:37:41.308493 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #514 | Training started
2017-07-02 14:37:50.997817 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #514 | Training finished
2017-07-02 14:37:50.998117 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #514 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 14:37:50.998364 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #514 | Collecting samples for evaluation
2017-07-02 14:37:56.684721 EDT | -----------------------  ------------
2017-07-02 14:37:56.685334 EDT | Epoch                     514
2017-07-02 14:37:56.685601 EDT | Iteration                 514
2017-07-02 14:37:56.685808 EDT | AverageReturn            1000
2017-07-02 14:37:56.686010 EDT | StdReturn                   0
2017-07-02 14:37:56.686242 EDT | MaxReturn                1000
2017-07-02 14:37:56.686464 EDT | MinReturn                1000
2017-07-02 14:37:56.686693 EDT | AverageEsReturn            24.4146
2017-07-02 14:37:56.686913 EDT | StdEsReturn                25.699
2017-07-02 14:37:56.687096 EDT | MaxEsReturn               117
2017-07-02 14:37:56.687314 EDT | MinEsReturn                 3
2017-07-02 14:37:56.687515 EDT | AverageDiscountedReturn    99.9957
2017-07-02 14:37:56.687724 EDT | AverageQLoss                0.0123304
2017-07-02 14:37:56.687941 EDT | AveragePolicySurr          -1.86881
2017-07-02 14:37:56.688157 EDT | AverageQ                    1.77344
2017-07-02 14:37:56.688374 EDT | AverageAbsQ                 1.77767
2017-07-02 14:37:56.688597 EDT | AverageY                    1.7735
2017-07-02 14:37:56.688782 EDT | AverageAbsY                 1.77399
2017-07-02 14:37:56.688938 EDT | AverageAbsQYDiff            0.0295583
2017-07-02 14:37:56.689159 EDT | AverageAction               0.655698
2017-07-02 14:37:56.689370 EDT | PolicyRegParamNorm         60.1785
2017-07-02 14:37:56.689550 EDT | QFunRegParamNorm           59.2881
2017-07-02 14:37:56.689671 EDT | -----------------------  ------------
2017-07-02 14:37:56.689847 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #515 | Training started
2017-07-02 14:38:06.313756 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #515 | Training finished
2017-07-02 14:38:06.314300 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #515 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 14:38:06.314459 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #515 | Collecting samples for evaluation
2017-07-02 14:38:12.021815 EDT | -----------------------  ------------
2017-07-02 14:38:12.022183 EDT | Epoch                     515
2017-07-02 14:38:12.022398 EDT | Iteration                 515
2017-07-02 14:38:12.022572 EDT | AverageReturn            1000
2017-07-02 14:38:12.022747 EDT | StdReturn                   0
2017-07-02 14:38:12.022919 EDT | MaxReturn                1000
2017-07-02 14:38:12.023079 EDT | MinReturn                1000
2017-07-02 14:38:12.023192 EDT | AverageEsReturn            24.05
2017-07-02 14:38:12.023343 EDT | StdEsReturn                17.1668
2017-07-02 14:38:12.023452 EDT | MaxEsReturn                72
2017-07-02 14:38:12.023558 EDT | MinEsReturn                 3
2017-07-02 14:38:12.023662 EDT | AverageDiscountedReturn    99.9957
2017-07-02 14:38:12.023767 EDT | AverageQLoss                0.0109488
2017-07-02 14:38:12.023871 EDT | AveragePolicySurr          -1.85872
2017-07-02 14:38:12.023975 EDT | AverageQ                    1.76386
2017-07-02 14:38:12.024079 EDT | AverageAbsQ                 1.76834
2017-07-02 14:38:12.024183 EDT | AverageY                    1.76385
2017-07-02 14:38:12.024287 EDT | AverageAbsY                 1.76417
2017-07-02 14:38:12.024391 EDT | AverageAbsQYDiff            0.0277734
2017-07-02 14:38:12.024495 EDT | AverageAction               0.670372
2017-07-02 14:38:12.024598 EDT | PolicyRegParamNorm         60.1757
2017-07-02 14:38:12.024701 EDT | QFunRegParamNorm           59.2982
2017-07-02 14:38:12.024850 EDT | -----------------------  ------------
2017-07-02 14:38:12.025034 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #516 | Training started
2017-07-02 14:38:21.587330 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #516 | Training finished
2017-07-02 14:38:21.588067 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #516 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 14:38:21.588239 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #516 | Collecting samples for evaluation
2017-07-02 14:38:27.329756 EDT | -----------------------  ------------
2017-07-02 14:38:27.330329 EDT | Epoch                     516
2017-07-02 14:38:27.330567 EDT | Iteration                 516
2017-07-02 14:38:27.330780 EDT | AverageReturn             916.545
2017-07-02 14:38:27.331001 EDT | StdReturn                 263.906
2017-07-02 14:38:27.331229 EDT | MaxReturn                1000
2017-07-02 14:38:27.331419 EDT | MinReturn                  82
2017-07-02 14:38:27.331631 EDT | AverageEsReturn            29.0286
2017-07-02 14:38:27.331844 EDT | StdEsReturn                32.515
2017-07-02 14:38:27.332074 EDT | MaxEsReturn               147
2017-07-02 14:38:27.332277 EDT | MinEsReturn                 3
2017-07-02 14:38:27.332501 EDT | AverageDiscountedReturn    96.0086
2017-07-02 14:38:27.332708 EDT | AverageQLoss                0.0109285
2017-07-02 14:38:27.332928 EDT | AveragePolicySurr          -1.84845
2017-07-02 14:38:27.333153 EDT | AverageQ                    1.75536
2017-07-02 14:38:27.333366 EDT | AverageAbsQ                 1.76058
2017-07-02 14:38:27.333929 EDT | AverageY                    1.75538
2017-07-02 14:38:27.334138 EDT | AverageAbsY                 1.75563
2017-07-02 14:38:27.334372 EDT | AverageAbsQYDiff            0.0282533
2017-07-02 14:38:27.334932 EDT | AverageAction               0.59813
2017-07-02 14:38:27.335170 EDT | PolicyRegParamNorm         60.2261
2017-07-02 14:38:27.335439 EDT | QFunRegParamNorm           59.3498
2017-07-02 14:38:27.335680 EDT | -----------------------  ------------
2017-07-02 14:38:27.336027 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #517 | Training started
2017-07-02 14:38:36.828079 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #517 | Training finished
2017-07-02 14:38:36.828718 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #517 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 14:38:36.828883 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #517 | Collecting samples for evaluation
2017-07-02 14:38:42.520302 EDT | -----------------------  -------------
2017-07-02 14:38:42.520519 EDT | Epoch                     517
2017-07-02 14:38:42.520642 EDT | Iteration                 517
2017-07-02 14:38:42.520840 EDT | AverageReturn            1000
2017-07-02 14:38:42.520979 EDT | StdReturn                   0
2017-07-02 14:38:42.521101 EDT | MaxReturn                1000
2017-07-02 14:38:42.521243 EDT | MinReturn                1000
2017-07-02 14:38:42.521421 EDT | AverageEsReturn            22
2017-07-02 14:38:42.521658 EDT | StdEsReturn                14.2797
2017-07-02 14:38:42.521876 EDT | MaxEsReturn                65
2017-07-02 14:38:42.521992 EDT | MinEsReturn                 4
2017-07-02 14:38:42.522096 EDT | AverageDiscountedReturn    99.9957
2017-07-02 14:38:42.522248 EDT | AverageQLoss                0.00971852
2017-07-02 14:38:42.522471 EDT | AveragePolicySurr          -1.83771
2017-07-02 14:38:42.522695 EDT | AverageQ                    1.74378
2017-07-02 14:38:42.522936 EDT | AverageAbsQ                 1.74896
2017-07-02 14:38:42.523159 EDT | AverageY                    1.74378
2017-07-02 14:38:42.523377 EDT | AverageAbsY                 1.74427
2017-07-02 14:38:42.523592 EDT | AverageAbsQYDiff            0.0271734
2017-07-02 14:38:42.523797 EDT | AverageAction               0.60549
2017-07-02 14:38:42.524018 EDT | PolicyRegParamNorm         60.2895
2017-07-02 14:38:42.524146 EDT | QFunRegParamNorm           59.4016
2017-07-02 14:38:42.524284 EDT | -----------------------  -------------
2017-07-02 14:38:42.524490 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #518 | Training started
2017-07-02 14:38:52.092367 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #518 | Training finished
2017-07-02 14:38:52.092885 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #518 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 14:38:52.093065 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #518 | Collecting samples for evaluation
2017-07-02 14:38:58.140831 EDT | -----------------------  ------------
2017-07-02 14:38:58.141383 EDT | Epoch                     518
2017-07-02 14:38:58.141597 EDT | Iteration                 518
2017-07-02 14:38:58.141777 EDT | AverageReturn             364.379
2017-07-02 14:38:58.141944 EDT | StdReturn                 275.971
2017-07-02 14:38:58.142106 EDT | MaxReturn                1000
2017-07-02 14:38:58.142236 EDT | MinReturn                  62
2017-07-02 14:38:58.142403 EDT | AverageEsReturn            21.1042
2017-07-02 14:38:58.142578 EDT | StdEsReturn                21.6152
2017-07-02 14:38:58.142682 EDT | MaxEsReturn               103
2017-07-02 14:38:58.142826 EDT | MinEsReturn                 3
2017-07-02 14:38:58.142951 EDT | AverageDiscountedReturn    82.8799
2017-07-02 14:38:58.143073 EDT | AverageQLoss                0.0114294
2017-07-02 14:38:58.143175 EDT | AveragePolicySurr          -1.83025
2017-07-02 14:38:58.143283 EDT | AverageQ                    1.73227
2017-07-02 14:38:58.143510 EDT | AverageAbsQ                 1.73703
2017-07-02 14:38:58.143722 EDT | AverageY                    1.73228
2017-07-02 14:38:58.143955 EDT | AverageAbsY                 1.73258
2017-07-02 14:38:58.144208 EDT | AverageAbsQYDiff            0.0288744
2017-07-02 14:38:58.144320 EDT | AverageAction               0.70276
2017-07-02 14:38:58.144486 EDT | PolicyRegParamNorm         60.3296
2017-07-02 14:38:58.144596 EDT | QFunRegParamNorm           59.4397
2017-07-02 14:38:58.144739 EDT | -----------------------  ------------
2017-07-02 14:38:58.145068 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #519 | Training started
2017-07-02 14:39:07.717967 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #519 | Training finished
2017-07-02 14:39:07.718142 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #519 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 14:39:07.718279 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #519 | Collecting samples for evaluation
2017-07-02 14:39:13.398907 EDT | -----------------------  ------------
2017-07-02 14:39:13.406491 EDT | Epoch                     519
2017-07-02 14:39:13.406770 EDT | Iteration                 519
2017-07-02 14:39:13.406934 EDT | AverageReturn            1000
2017-07-02 14:39:13.407102 EDT | StdReturn                   0
2017-07-02 14:39:13.407255 EDT | MaxReturn                1000
2017-07-02 14:39:13.407387 EDT | MinReturn                1000
2017-07-02 14:39:13.407518 EDT | AverageEsReturn            27.25
2017-07-02 14:39:13.407708 EDT | StdEsReturn                21.758
2017-07-02 14:39:13.407914 EDT | MaxEsReturn                81
2017-07-02 14:39:13.408119 EDT | MinEsReturn                 3
2017-07-02 14:39:13.408246 EDT | AverageDiscountedReturn    99.9957
2017-07-02 14:39:13.408397 EDT | AverageQLoss                0.0107538
2017-07-02 14:39:13.408568 EDT | AveragePolicySurr          -1.82568
2017-07-02 14:39:13.408699 EDT | AverageQ                    1.73358
2017-07-02 14:39:13.408862 EDT | AverageAbsQ                 1.73791
2017-07-02 14:39:13.408970 EDT | AverageY                    1.73343
2017-07-02 14:39:13.409071 EDT | AverageAbsY                 1.73371
2017-07-02 14:39:13.409172 EDT | AverageAbsQYDiff            0.0277856
2017-07-02 14:39:13.409271 EDT | AverageAction               0.603248
2017-07-02 14:39:13.409370 EDT | PolicyRegParamNorm         60.3302
2017-07-02 14:39:13.409468 EDT | QFunRegParamNorm           59.4841
2017-07-02 14:39:13.409633 EDT | -----------------------  ------------
2017-07-02 14:39:13.409862 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #520 | Training started
2017-07-02 14:39:23.035224 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #520 | Training finished
2017-07-02 14:39:23.035462 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #520 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 14:39:23.035590 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #520 | Collecting samples for evaluation
2017-07-02 14:39:28.622042 EDT | -----------------------  ------------
2017-07-02 14:39:28.622592 EDT | Epoch                     520
2017-07-02 14:39:28.622828 EDT | Iteration                 520
2017-07-02 14:39:28.623062 EDT | AverageReturn            1000
2017-07-02 14:39:28.623267 EDT | StdReturn                   0
2017-07-02 14:39:28.623501 EDT | MaxReturn                1000
2017-07-02 14:39:28.623716 EDT | MinReturn                1000
2017-07-02 14:39:28.623947 EDT | AverageEsReturn            25.1463
2017-07-02 14:39:28.624170 EDT | StdEsReturn                21.2724
2017-07-02 14:39:28.624370 EDT | MaxEsReturn                84
2017-07-02 14:39:28.624603 EDT | MinEsReturn                 3
2017-07-02 14:39:28.624756 EDT | AverageDiscountedReturn    99.9957
2017-07-02 14:39:28.624916 EDT | AverageQLoss                0.0103685
2017-07-02 14:39:28.625090 EDT | AveragePolicySurr          -1.81433
2017-07-02 14:39:28.625322 EDT | AverageQ                    1.72316
2017-07-02 14:39:28.625500 EDT | AverageAbsQ                 1.7275
2017-07-02 14:39:28.625609 EDT | AverageY                    1.72324
2017-07-02 14:39:28.625714 EDT | AverageAbsY                 1.72354
2017-07-02 14:39:28.625835 EDT | AverageAbsQYDiff            0.0279825
2017-07-02 14:39:28.626065 EDT | AverageAction               0.830733
2017-07-02 14:39:28.626276 EDT | PolicyRegParamNorm         60.3696
2017-07-02 14:39:28.626502 EDT | QFunRegParamNorm           59.5483
2017-07-02 14:39:28.626726 EDT | -----------------------  ------------
2017-07-02 14:39:28.626905 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #521 | Training started
2017-07-02 14:39:38.218953 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #521 | Training finished
2017-07-02 14:39:38.219537 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #521 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 14:39:38.219796 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #521 | Collecting samples for evaluation
2017-07-02 14:39:44.020994 EDT | -----------------------  ------------
2017-07-02 14:39:44.021417 EDT | Epoch                     521
2017-07-02 14:39:44.021698 EDT | Iteration                 521
2017-07-02 14:39:44.021866 EDT | AverageReturn            1000
2017-07-02 14:39:44.021974 EDT | StdReturn                   0
2017-07-02 14:39:44.022157 EDT | MaxReturn                1000
2017-07-02 14:39:44.022386 EDT | MinReturn                1000
2017-07-02 14:39:44.022559 EDT | AverageEsReturn            34.7407
2017-07-02 14:39:44.022666 EDT | StdEsReturn                27.2146
2017-07-02 14:39:44.022819 EDT | MaxEsReturn               111
2017-07-02 14:39:44.023016 EDT | MinEsReturn                 6
2017-07-02 14:39:44.023219 EDT | AverageDiscountedReturn    99.9957
2017-07-02 14:39:44.023436 EDT | AverageQLoss                0.0105033
2017-07-02 14:39:44.023691 EDT | AveragePolicySurr          -1.80471
2017-07-02 14:39:44.023880 EDT | AverageQ                    1.71237
2017-07-02 14:39:44.024119 EDT | AverageAbsQ                 1.71732
2017-07-02 14:39:44.024346 EDT | AverageY                    1.71227
2017-07-02 14:39:44.024572 EDT | AverageAbsY                 1.71269
2017-07-02 14:39:44.024786 EDT | AverageAbsQYDiff            0.0276541
2017-07-02 14:39:44.025004 EDT | AverageAction               0.593246
2017-07-02 14:39:44.025226 EDT | PolicyRegParamNorm         60.3945
2017-07-02 14:39:44.025342 EDT | QFunRegParamNorm           59.6067
2017-07-02 14:39:44.025447 EDT | -----------------------  ------------
2017-07-02 14:39:44.025711 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #522 | Training started
2017-07-02 14:39:53.606327 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #522 | Training finished
2017-07-02 14:39:53.606895 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #522 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 14:39:53.607090 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #522 | Collecting samples for evaluation
2017-07-02 14:39:59.279155 EDT | -----------------------  -------------
2017-07-02 14:39:59.279749 EDT | Epoch                     522
2017-07-02 14:39:59.279885 EDT | Iteration                 522
2017-07-02 14:39:59.280119 EDT | AverageReturn            1000
2017-07-02 14:39:59.280362 EDT | StdReturn                   0
2017-07-02 14:39:59.280656 EDT | MaxReturn                1000
2017-07-02 14:39:59.280903 EDT | MinReturn                1000
2017-07-02 14:39:59.281053 EDT | AverageEsReturn            33.1562
2017-07-02 14:39:59.281167 EDT | StdEsReturn                33.9992
2017-07-02 14:39:59.281320 EDT | MaxEsReturn               159
2017-07-02 14:39:59.281447 EDT | MinEsReturn                 4
2017-07-02 14:39:59.281609 EDT | AverageDiscountedReturn    99.9957
2017-07-02 14:39:59.281832 EDT | AverageQLoss                0.00931931
2017-07-02 14:39:59.282063 EDT | AveragePolicySurr          -1.79945
2017-07-02 14:39:59.282274 EDT | AverageQ                    1.70803
2017-07-02 14:39:59.282507 EDT | AverageAbsQ                 1.71303
2017-07-02 14:39:59.282713 EDT | AverageY                    1.70805
2017-07-02 14:39:59.282823 EDT | AverageAbsY                 1.70846
2017-07-02 14:39:59.282961 EDT | AverageAbsQYDiff            0.0269678
2017-07-02 14:39:59.283190 EDT | AverageAction               0.927856
2017-07-02 14:39:59.283417 EDT | PolicyRegParamNorm         60.4555
2017-07-02 14:39:59.283651 EDT | QFunRegParamNorm           59.6293
2017-07-02 14:39:59.283878 EDT | -----------------------  -------------
2017-07-02 14:39:59.284236 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #523 | Training started
2017-07-02 14:40:08.901252 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #523 | Training finished
2017-07-02 14:40:08.901901 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #523 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 14:40:08.902149 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #523 | Collecting samples for evaluation
2017-07-02 14:40:14.546805 EDT | -----------------------  -------------
2017-07-02 14:40:14.547096 EDT | Epoch                     523
2017-07-02 14:40:14.547333 EDT | Iteration                 523
2017-07-02 14:40:14.547459 EDT | AverageReturn            1000
2017-07-02 14:40:14.547623 EDT | StdReturn                   0
2017-07-02 14:40:14.547755 EDT | MaxReturn                1000
2017-07-02 14:40:14.547879 EDT | MinReturn                1000
2017-07-02 14:40:14.547989 EDT | AverageEsReturn            28.8857
2017-07-02 14:40:14.548096 EDT | StdEsReturn                33.0729
2017-07-02 14:40:14.548203 EDT | MaxEsReturn               162
2017-07-02 14:40:14.548368 EDT | MinEsReturn                 3
2017-07-02 14:40:14.548477 EDT | AverageDiscountedReturn    99.9957
2017-07-02 14:40:14.548584 EDT | AverageQLoss                0.00920639
2017-07-02 14:40:14.548711 EDT | AveragePolicySurr          -1.79015
2017-07-02 14:40:14.548819 EDT | AverageQ                    1.70119
2017-07-02 14:40:14.548926 EDT | AverageAbsQ                 1.70549
2017-07-02 14:40:14.549037 EDT | AverageY                    1.70119
2017-07-02 14:40:14.549144 EDT | AverageAbsY                 1.70143
2017-07-02 14:40:14.549276 EDT | AverageAbsQYDiff            0.026193
2017-07-02 14:40:14.549383 EDT | AverageAction               0.573892
2017-07-02 14:40:14.549496 EDT | PolicyRegParamNorm         60.4878
2017-07-02 14:40:14.549675 EDT | QFunRegParamNorm           59.6584
2017-07-02 14:40:14.549804 EDT | -----------------------  -------------
2017-07-02 14:40:14.549976 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #524 | Training started
2017-07-02 14:40:24.809651 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #524 | Training finished
2017-07-02 14:40:24.810192 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #524 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 14:40:24.810446 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #524 | Collecting samples for evaluation
2017-07-02 14:40:30.462881 EDT | -----------------------  ------------
2017-07-02 14:40:30.463520 EDT | Epoch                     524
2017-07-02 14:40:30.463691 EDT | Iteration                 524
2017-07-02 14:40:30.463827 EDT | AverageReturn            1000
2017-07-02 14:40:30.463956 EDT | StdReturn                   0
2017-07-02 14:40:30.464164 EDT | MaxReturn                1000
2017-07-02 14:40:30.464385 EDT | MinReturn                1000
2017-07-02 14:40:30.464602 EDT | AverageEsReturn            24.9
2017-07-02 14:40:30.464798 EDT | StdEsReturn                18.5011
2017-07-02 14:40:30.465029 EDT | MaxEsReturn                73
2017-07-02 14:40:30.465256 EDT | MinEsReturn                 2
2017-07-02 14:40:30.465440 EDT | AverageDiscountedReturn    99.9957
2017-07-02 14:40:30.465639 EDT | AverageQLoss                0.0114878
2017-07-02 14:40:30.465840 EDT | AveragePolicySurr          -1.783
2017-07-02 14:40:30.466073 EDT | AverageQ                    1.69638
2017-07-02 14:40:30.466302 EDT | AverageAbsQ                 1.70092
2017-07-02 14:40:30.466527 EDT | AverageY                    1.69633
2017-07-02 14:40:30.466749 EDT | AverageAbsY                 1.69664
2017-07-02 14:40:30.466968 EDT | AverageAbsQYDiff            0.0294819
2017-07-02 14:40:30.467161 EDT | AverageAction               0.827904
2017-07-02 14:40:30.467329 EDT | PolicyRegParamNorm         60.5458
2017-07-02 14:40:30.467554 EDT | QFunRegParamNorm           59.6963
2017-07-02 14:40:30.467771 EDT | -----------------------  ------------
2017-07-02 14:40:30.468059 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #525 | Training started
2017-07-02 14:40:40.113782 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #525 | Training finished
2017-07-02 14:40:40.114286 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #525 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 14:40:40.114455 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #525 | Collecting samples for evaluation
2017-07-02 14:40:45.698105 EDT | -----------------------  ------------
2017-07-02 14:40:45.698335 EDT | Epoch                     525
2017-07-02 14:40:45.698490 EDT | Iteration                 525
2017-07-02 14:40:45.698619 EDT | AverageReturn            1000
2017-07-02 14:40:45.698746 EDT | StdReturn                   0
2017-07-02 14:40:45.698892 EDT | MaxReturn                1000
2017-07-02 14:40:45.699019 EDT | MinReturn                1000
2017-07-02 14:40:45.699164 EDT | AverageEsReturn            30.2424
2017-07-02 14:40:45.699316 EDT | StdEsReturn                31.1429
2017-07-02 14:40:45.699457 EDT | MaxEsReturn               158
2017-07-02 14:40:45.699592 EDT | MinEsReturn                 4
2017-07-02 14:40:45.699746 EDT | AverageDiscountedReturn    99.9957
2017-07-02 14:40:45.699880 EDT | AverageQLoss                0.010111
2017-07-02 14:40:45.700030 EDT | AveragePolicySurr          -1.77422
2017-07-02 14:40:45.700179 EDT | AverageQ                    1.68632
2017-07-02 14:40:45.700307 EDT | AverageAbsQ                 1.69118
2017-07-02 14:40:45.700467 EDT | AverageY                    1.68621
2017-07-02 14:40:45.700698 EDT | AverageAbsY                 1.68671
2017-07-02 14:40:45.700899 EDT | AverageAbsQYDiff            0.0276074
2017-07-02 14:40:45.701097 EDT | AverageAction               0.566013
2017-07-02 14:40:45.701328 EDT | PolicyRegParamNorm         60.5571
2017-07-02 14:40:45.701654 EDT | QFunRegParamNorm           59.741
2017-07-02 14:40:45.701764 EDT | -----------------------  ------------
2017-07-02 14:40:45.701985 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #526 | Training started
2017-07-02 14:40:55.266860 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #526 | Training finished
2017-07-02 14:40:55.267958 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #526 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 14:40:55.268156 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #526 | Collecting samples for evaluation
2017-07-02 14:41:00.851007 EDT | -----------------------  -------------
2017-07-02 14:41:00.851745 EDT | Epoch                     526
2017-07-02 14:41:00.851950 EDT | Iteration                 526
2017-07-02 14:41:00.852149 EDT | AverageReturn            1000
2017-07-02 14:41:00.852330 EDT | StdReturn                   0
2017-07-02 14:41:00.852541 EDT | MaxReturn                1000
2017-07-02 14:41:00.852743 EDT | MinReturn                1000
2017-07-02 14:41:00.852963 EDT | AverageEsReturn            32.9
2017-07-02 14:41:00.853135 EDT | StdEsReturn                25.8809
2017-07-02 14:41:00.853367 EDT | MaxEsReturn               128
2017-07-02 14:41:00.853608 EDT | MinEsReturn                 5
2017-07-02 14:41:00.853903 EDT | AverageDiscountedReturn    99.9957
2017-07-02 14:41:00.854120 EDT | AverageQLoss                0.00989252
2017-07-02 14:41:00.854346 EDT | AveragePolicySurr          -1.76782
2017-07-02 14:41:00.854497 EDT | AverageQ                    1.68237
2017-07-02 14:41:00.854607 EDT | AverageAbsQ                 1.68684
2017-07-02 14:41:00.854715 EDT | AverageY                    1.68244
2017-07-02 14:41:00.854826 EDT | AverageAbsY                 1.68289
2017-07-02 14:41:00.855002 EDT | AverageAbsQYDiff            0.026727
2017-07-02 14:41:00.855221 EDT | AverageAction               0.55461
2017-07-02 14:41:00.855425 EDT | PolicyRegParamNorm         60.5692
2017-07-02 14:41:00.855642 EDT | QFunRegParamNorm           59.7598
2017-07-02 14:41:00.855869 EDT | -----------------------  -------------
2017-07-02 14:41:00.856150 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #527 | Training started
2017-07-02 14:41:10.221846 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #527 | Training finished
2017-07-02 14:41:10.222411 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #527 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 14:41:10.222748 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #527 | Collecting samples for evaluation
2017-07-02 14:41:15.855615 EDT | -----------------------  -------------
2017-07-02 14:41:15.855923 EDT | Epoch                     527
2017-07-02 14:41:15.856171 EDT | Iteration                 527
2017-07-02 14:41:15.856394 EDT | AverageReturn            1000
2017-07-02 14:41:15.856528 EDT | StdReturn                   0
2017-07-02 14:41:15.856634 EDT | MaxReturn                1000
2017-07-02 14:41:15.856736 EDT | MinReturn                1000
2017-07-02 14:41:15.856843 EDT | AverageEsReturn            23.0476
2017-07-02 14:41:15.856954 EDT | StdEsReturn                25.2737
2017-07-02 14:41:15.857101 EDT | MaxEsReturn               110
2017-07-02 14:41:15.857224 EDT | MinEsReturn                 3
2017-07-02 14:41:15.857331 EDT | AverageDiscountedReturn    99.9957
2017-07-02 14:41:15.857436 EDT | AverageQLoss                0.00995403
2017-07-02 14:41:15.857596 EDT | AveragePolicySurr          -1.75822
2017-07-02 14:41:15.857710 EDT | AverageQ                    1.67352
2017-07-02 14:41:15.857817 EDT | AverageAbsQ                 1.6781
2017-07-02 14:41:15.857923 EDT | AverageY                    1.67353
2017-07-02 14:41:15.858033 EDT | AverageAbsY                 1.67396
2017-07-02 14:41:15.858175 EDT | AverageAbsQYDiff            0.0283261
2017-07-02 14:41:15.858281 EDT | AverageAction               0.626374
2017-07-02 14:41:15.858386 EDT | PolicyRegParamNorm         60.6076
2017-07-02 14:41:15.858490 EDT | QFunRegParamNorm           59.7776
2017-07-02 14:41:15.858594 EDT | -----------------------  -------------
2017-07-02 14:41:15.858776 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #528 | Training started
2017-07-02 14:41:25.072566 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #528 | Training finished
2017-07-02 14:41:25.073419 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #528 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 14:41:25.073691 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #528 | Collecting samples for evaluation
2017-07-02 14:41:30.712961 EDT | -----------------------  ------------
2017-07-02 14:41:30.713575 EDT | Epoch                     528
2017-07-02 14:41:30.713818 EDT | Iteration                 528
2017-07-02 14:41:30.713984 EDT | AverageReturn            1000
2017-07-02 14:41:30.714154 EDT | StdReturn                   0
2017-07-02 14:41:30.714357 EDT | MaxReturn                1000
2017-07-02 14:41:30.714502 EDT | MinReturn                1000
2017-07-02 14:41:30.714603 EDT | AverageEsReturn            33.8387
2017-07-02 14:41:30.714778 EDT | StdEsReturn                45.9425
2017-07-02 14:41:30.714879 EDT | MaxEsReturn               245
2017-07-02 14:41:30.714995 EDT | MinEsReturn                 3
2017-07-02 14:41:30.715093 EDT | AverageDiscountedReturn    99.9957
2017-07-02 14:41:30.715190 EDT | AverageQLoss                0.0112123
2017-07-02 14:41:30.715299 EDT | AveragePolicySurr          -1.74988
2017-07-02 14:41:30.715436 EDT | AverageQ                    1.65962
2017-07-02 14:41:30.715575 EDT | AverageAbsQ                 1.66496
2017-07-02 14:41:30.715675 EDT | AverageY                    1.6594
2017-07-02 14:41:30.715794 EDT | AverageAbsY                 1.65974
2017-07-02 14:41:30.715893 EDT | AverageAbsQYDiff            0.0287303
2017-07-02 14:41:30.715989 EDT | AverageAction               0.703068
2017-07-02 14:41:30.716137 EDT | PolicyRegParamNorm         60.6214
2017-07-02 14:41:30.716245 EDT | QFunRegParamNorm           59.8204
2017-07-02 14:41:30.716344 EDT | -----------------------  ------------
2017-07-02 14:41:30.716589 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #529 | Training started
2017-07-02 14:41:39.843876 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #529 | Training finished
2017-07-02 14:41:39.844456 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #529 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 14:41:39.844711 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #529 | Collecting samples for evaluation
2017-07-02 14:41:45.509855 EDT | -----------------------  ------------
2017-07-02 14:41:45.510136 EDT | Epoch                     529
2017-07-02 14:41:45.510256 EDT | Iteration                 529
2017-07-02 14:41:45.510362 EDT | AverageReturn            1000
2017-07-02 14:41:45.510490 EDT | StdReturn                   0
2017-07-02 14:41:45.510667 EDT | MaxReturn                1000
2017-07-02 14:41:45.510860 EDT | MinReturn                1000
2017-07-02 14:41:45.511059 EDT | AverageEsReturn            40.5833
2017-07-02 14:41:45.511177 EDT | StdEsReturn                30.5327
2017-07-02 14:41:45.511313 EDT | MaxEsReturn               106
2017-07-02 14:41:45.511469 EDT | MinEsReturn                 4
2017-07-02 14:41:45.511593 EDT | AverageDiscountedReturn    99.9957
2017-07-02 14:41:45.511722 EDT | AverageQLoss                0.0105817
2017-07-02 14:41:45.511899 EDT | AveragePolicySurr          -1.74193
2017-07-02 14:41:45.512020 EDT | AverageQ                    1.65613
2017-07-02 14:41:45.512127 EDT | AverageAbsQ                 1.66097
2017-07-02 14:41:45.512231 EDT | AverageY                    1.65622
2017-07-02 14:41:45.512335 EDT | AverageAbsY                 1.6567
2017-07-02 14:41:45.512493 EDT | AverageAbsQYDiff            0.0280146
2017-07-02 14:41:45.512599 EDT | AverageAction               0.688676
2017-07-02 14:41:45.512743 EDT | PolicyRegParamNorm         60.6764
2017-07-02 14:41:45.512848 EDT | QFunRegParamNorm           59.8271
2017-07-02 14:41:45.512951 EDT | -----------------------  ------------
2017-07-02 14:41:45.513115 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #530 | Training started
2017-07-02 14:41:54.811871 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #530 | Training finished
2017-07-02 14:41:54.812380 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #530 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 14:41:54.812524 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #530 | Collecting samples for evaluation
2017-07-02 14:42:00.531207 EDT | -----------------------  ------------
2017-07-02 14:42:00.531687 EDT | Epoch                     530
2017-07-02 14:42:00.531943 EDT | Iteration                 530
2017-07-02 14:42:00.532171 EDT | AverageReturn             407.2
2017-07-02 14:42:00.532400 EDT | StdReturn                 320.255
2017-07-02 14:42:00.532528 EDT | MaxReturn                1000
2017-07-02 14:42:00.532754 EDT | MinReturn                  48
2017-07-02 14:42:00.532977 EDT | AverageEsReturn            27.7576
2017-07-02 14:42:00.533119 EDT | StdEsReturn                20.6867
2017-07-02 14:42:00.533347 EDT | MaxEsReturn                82
2017-07-02 14:42:00.533649 EDT | MinEsReturn                 4
2017-07-02 14:42:00.533885 EDT | AverageDiscountedReturn    80.3617
2017-07-02 14:42:00.534085 EDT | AverageQLoss                0.0106648
2017-07-02 14:42:00.534192 EDT | AveragePolicySurr          -1.73612
2017-07-02 14:42:00.534305 EDT | AverageQ                    1.64941
2017-07-02 14:42:00.534530 EDT | AverageAbsQ                 1.65386
2017-07-02 14:42:00.534756 EDT | AverageY                    1.64942
2017-07-02 14:42:00.534978 EDT | AverageAbsY                 1.64985
2017-07-02 14:42:00.535208 EDT | AverageAbsQYDiff            0.0275595
2017-07-02 14:42:00.535400 EDT | AverageAction               0.742466
2017-07-02 14:42:00.535616 EDT | PolicyRegParamNorm         60.7169
2017-07-02 14:42:00.535847 EDT | QFunRegParamNorm           59.843
2017-07-02 14:42:00.536071 EDT | -----------------------  ------------
2017-07-02 14:42:00.536393 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #531 | Training started
2017-07-02 14:42:09.940241 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #531 | Training finished
2017-07-02 14:42:09.940757 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #531 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 14:42:09.940999 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #531 | Collecting samples for evaluation
2017-07-02 14:42:15.649594 EDT | -----------------------  -------------
2017-07-02 14:42:15.649778 EDT | Epoch                     531
2017-07-02 14:42:15.649892 EDT | Iteration                 531
2017-07-02 14:42:15.650011 EDT | AverageReturn             650.75
2017-07-02 14:42:15.650116 EDT | StdReturn                 450.931
2017-07-02 14:42:15.650218 EDT | MaxReturn                1000
2017-07-02 14:42:15.650319 EDT | MinReturn                  62
2017-07-02 14:42:15.650419 EDT | AverageEsReturn            28.3514
2017-07-02 14:42:15.650516 EDT | StdEsReturn                25.0505
2017-07-02 14:42:15.650612 EDT | MaxEsReturn               114
2017-07-02 14:42:15.650708 EDT | MinEsReturn                 3
2017-07-02 14:42:15.650806 EDT | AverageDiscountedReturn    81.0792
2017-07-02 14:42:15.650905 EDT | AverageQLoss                0.00878692
2017-07-02 14:42:15.651013 EDT | AveragePolicySurr          -1.7277
2017-07-02 14:42:15.651148 EDT | AverageQ                    1.6454
2017-07-02 14:42:15.651249 EDT | AverageAbsQ                 1.65001
2017-07-02 14:42:15.651349 EDT | AverageY                    1.6453
2017-07-02 14:42:15.651470 EDT | AverageAbsY                 1.64571
2017-07-02 14:42:15.651657 EDT | AverageAbsQYDiff            0.0257727
2017-07-02 14:42:15.651807 EDT | AverageAction               0.676433
2017-07-02 14:42:15.651953 EDT | PolicyRegParamNorm         60.7522
2017-07-02 14:42:15.652114 EDT | QFunRegParamNorm           59.8539
2017-07-02 14:42:15.652215 EDT | -----------------------  -------------
2017-07-02 14:42:15.652377 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #532 | Training started
2017-07-02 14:42:25.095298 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #532 | Training finished
2017-07-02 14:42:25.101246 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #532 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 14:42:25.101534 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #532 | Collecting samples for evaluation
2017-07-02 14:42:30.621976 EDT | -----------------------  -------------
2017-07-02 14:42:30.622273 EDT | Epoch                     532
2017-07-02 14:42:30.622448 EDT | Iteration                 532
2017-07-02 14:42:30.622580 EDT | AverageReturn            1000
2017-07-02 14:42:30.622800 EDT | StdReturn                   0
2017-07-02 14:42:30.622973 EDT | MaxReturn                1000
2017-07-02 14:42:30.623153 EDT | MinReturn                1000
2017-07-02 14:42:30.623301 EDT | AverageEsReturn            24.2093
2017-07-02 14:42:30.623410 EDT | StdEsReturn                22.998
2017-07-02 14:42:30.623568 EDT | MaxEsReturn               102
2017-07-02 14:42:30.623690 EDT | MinEsReturn                 3
2017-07-02 14:42:30.623847 EDT | AverageDiscountedReturn    99.9957
2017-07-02 14:42:30.624024 EDT | AverageQLoss                0.00866646
2017-07-02 14:42:30.624173 EDT | AveragePolicySurr          -1.71816
2017-07-02 14:42:30.624276 EDT | AverageQ                    1.63425
2017-07-02 14:42:30.624374 EDT | AverageAbsQ                 1.63901
2017-07-02 14:42:30.624494 EDT | AverageY                    1.63422
2017-07-02 14:42:30.624607 EDT | AverageAbsY                 1.63458
2017-07-02 14:42:30.624743 EDT | AverageAbsQYDiff            0.0256592
2017-07-02 14:42:30.624844 EDT | AverageAction               0.604418
2017-07-02 14:42:30.625002 EDT | PolicyRegParamNorm         60.7993
2017-07-02 14:42:30.625147 EDT | QFunRegParamNorm           59.8641
2017-07-02 14:42:30.625244 EDT | -----------------------  -------------
2017-07-02 14:42:30.625402 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #533 | Training started
2017-07-02 14:42:40.042688 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #533 | Training finished
2017-07-02 14:42:40.043470 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #533 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 14:42:40.043723 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #533 | Collecting samples for evaluation
2017-07-02 14:42:45.577136 EDT | -----------------------  -------------
2017-07-02 14:42:45.577372 EDT | Epoch                     533
2017-07-02 14:42:45.577576 EDT | Iteration                 533
2017-07-02 14:42:45.577684 EDT | AverageReturn            1000
2017-07-02 14:42:45.577787 EDT | StdReturn                   0
2017-07-02 14:42:45.577903 EDT | MaxReturn                1000
2017-07-02 14:42:45.578102 EDT | MinReturn                1000
2017-07-02 14:42:45.578220 EDT | AverageEsReturn            21.4255
2017-07-02 14:42:45.578321 EDT | StdEsReturn                16.3105
2017-07-02 14:42:45.578473 EDT | MaxEsReturn                86
2017-07-02 14:42:45.578584 EDT | MinEsReturn                 4
2017-07-02 14:42:45.578686 EDT | AverageDiscountedReturn    99.9957
2017-07-02 14:42:45.578786 EDT | AverageQLoss                0.00905818
2017-07-02 14:42:45.578885 EDT | AveragePolicySurr          -1.71295
2017-07-02 14:42:45.579045 EDT | AverageQ                    1.62462
2017-07-02 14:42:45.579241 EDT | AverageAbsQ                 1.6293
2017-07-02 14:42:45.579436 EDT | AverageY                    1.62462
2017-07-02 14:42:45.579622 EDT | AverageAbsY                 1.62502
2017-07-02 14:42:45.579731 EDT | AverageAbsQYDiff            0.0260235
2017-07-02 14:42:45.579912 EDT | AverageAction               0.660542
2017-07-02 14:42:45.580045 EDT | PolicyRegParamNorm         60.8493
2017-07-02 14:42:45.580147 EDT | QFunRegParamNorm           59.8684
2017-07-02 14:42:45.580247 EDT | -----------------------  -------------
2017-07-02 14:42:45.580411 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #534 | Training started
2017-07-02 14:42:54.945390 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #534 | Training finished
2017-07-02 14:42:54.946001 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #534 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 14:42:54.946262 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #534 | Collecting samples for evaluation
2017-07-02 14:43:00.466709 EDT | -----------------------  -------------
2017-07-02 14:43:00.467032 EDT | Epoch                     534
2017-07-02 14:43:00.467249 EDT | Iteration                 534
2017-07-02 14:43:00.467483 EDT | AverageReturn            1000
2017-07-02 14:43:00.467669 EDT | StdReturn                   0
2017-07-02 14:43:00.467899 EDT | MaxReturn                1000
2017-07-02 14:43:00.468118 EDT | MinReturn                1000
2017-07-02 14:43:00.468316 EDT | AverageEsReturn            25.6579
2017-07-02 14:43:00.468545 EDT | StdEsReturn                31.3178
2017-07-02 14:43:00.468732 EDT | MaxEsReturn               171
2017-07-02 14:43:00.468962 EDT | MinEsReturn                 3
2017-07-02 14:43:00.469139 EDT | AverageDiscountedReturn    99.9957
2017-07-02 14:43:00.469257 EDT | AverageQLoss                0.00999639
2017-07-02 14:43:00.469818 EDT | AveragePolicySurr          -1.70294
2017-07-02 14:43:00.470070 EDT | AverageQ                    1.61948
2017-07-02 14:43:00.470289 EDT | AverageAbsQ                 1.62412
2017-07-02 14:43:00.470522 EDT | AverageY                    1.61941
2017-07-02 14:43:00.470728 EDT | AverageAbsY                 1.61981
2017-07-02 14:43:00.470924 EDT | AverageAbsQYDiff            0.0276073
2017-07-02 14:43:00.471152 EDT | AverageAction               0.738894
2017-07-02 14:43:00.471354 EDT | PolicyRegParamNorm         60.8966
2017-07-02 14:43:00.471591 EDT | QFunRegParamNorm           59.8949
2017-07-02 14:43:00.471771 EDT | -----------------------  -------------
2017-07-02 14:43:00.471963 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #535 | Training started
2017-07-02 14:43:09.882020 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #535 | Training finished
2017-07-02 14:43:09.882648 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #535 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 14:43:09.882827 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #535 | Collecting samples for evaluation
2017-07-02 14:43:15.476041 EDT | -----------------------  -------------
2017-07-02 14:43:15.476236 EDT | Epoch                     535
2017-07-02 14:43:15.476351 EDT | Iteration                 535
2017-07-02 14:43:15.476456 EDT | AverageReturn            1000
2017-07-02 14:43:15.476560 EDT | StdReturn                   0
2017-07-02 14:43:15.476754 EDT | MaxReturn                1000
2017-07-02 14:43:15.476889 EDT | MinReturn                1000
2017-07-02 14:43:15.476990 EDT | AverageEsReturn            32.5161
2017-07-02 14:43:15.477113 EDT | StdEsReturn                34.9062
2017-07-02 14:43:15.477254 EDT | MaxEsReturn               175
2017-07-02 14:43:15.477360 EDT | MinEsReturn                 3
2017-07-02 14:43:15.477460 EDT | AverageDiscountedReturn    99.9957
2017-07-02 14:43:15.477644 EDT | AverageQLoss                0.00956417
2017-07-02 14:43:15.477797 EDT | AveragePolicySurr          -1.69693
2017-07-02 14:43:15.477896 EDT | AverageQ                    1.6166
2017-07-02 14:43:15.478052 EDT | AverageAbsQ                 1.6213
2017-07-02 14:43:15.478172 EDT | AverageY                    1.61649
2017-07-02 14:43:15.478301 EDT | AverageAbsY                 1.61704
2017-07-02 14:43:15.478453 EDT | AverageAbsQYDiff            0.0274404
2017-07-02 14:43:15.478588 EDT | AverageAction               0.656115
2017-07-02 14:43:15.478712 EDT | PolicyRegParamNorm         60.9451
2017-07-02 14:43:15.478829 EDT | QFunRegParamNorm           59.9173
2017-07-02 14:43:15.479024 EDT | -----------------------  -------------
2017-07-02 14:43:15.479201 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #536 | Training started
2017-07-02 14:43:24.874915 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #536 | Training finished
2017-07-02 14:43:24.875444 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #536 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 14:43:24.875609 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #536 | Collecting samples for evaluation
2017-07-02 14:43:30.341946 EDT | -----------------------  ------------
2017-07-02 14:43:30.342144 EDT | Epoch                     536
2017-07-02 14:43:30.342296 EDT | Iteration                 536
2017-07-02 14:43:30.342434 EDT | AverageReturn            1000
2017-07-02 14:43:30.342543 EDT | StdReturn                   0
2017-07-02 14:43:30.342649 EDT | MaxReturn                1000
2017-07-02 14:43:30.342759 EDT | MinReturn                1000
2017-07-02 14:43:30.342943 EDT | AverageEsReturn            33.7931
2017-07-02 14:43:30.343133 EDT | StdEsReturn                32.593
2017-07-02 14:43:30.343343 EDT | MaxEsReturn               121
2017-07-02 14:43:30.343537 EDT | MinEsReturn                 4
2017-07-02 14:43:30.343699 EDT | AverageDiscountedReturn    99.9957
2017-07-02 14:43:30.343852 EDT | AverageQLoss                0.0106394
2017-07-02 14:43:30.343961 EDT | AveragePolicySurr          -1.68666
2017-07-02 14:43:30.344070 EDT | AverageQ                    1.60118
2017-07-02 14:43:30.344198 EDT | AverageAbsQ                 1.60585
2017-07-02 14:43:30.344309 EDT | AverageY                    1.60125
2017-07-02 14:43:30.344415 EDT | AverageAbsY                 1.6019
2017-07-02 14:43:30.344526 EDT | AverageAbsQYDiff            0.0290439
2017-07-02 14:43:30.344671 EDT | AverageAction               0.89901
2017-07-02 14:43:30.344775 EDT | PolicyRegParamNorm         60.9568
2017-07-02 14:43:30.344878 EDT | QFunRegParamNorm           59.9375
2017-07-02 14:43:30.344981 EDT | -----------------------  ------------
2017-07-02 14:43:30.345146 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #537 | Training started
2017-07-02 14:43:39.708676 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #537 | Training finished
2017-07-02 14:43:39.709388 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #537 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 14:43:39.709668 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #537 | Collecting samples for evaluation
2017-07-02 14:43:45.152447 EDT | -----------------------  -------------
2017-07-02 14:43:45.152682 EDT | Epoch                     537
2017-07-02 14:43:45.152811 EDT | Iteration                 537
2017-07-02 14:43:45.152918 EDT | AverageReturn            1000
2017-07-02 14:43:45.153021 EDT | StdReturn                   0
2017-07-02 14:43:45.153128 EDT | MaxReturn                1000
2017-07-02 14:43:45.153312 EDT | MinReturn                1000
2017-07-02 14:43:45.153415 EDT | AverageEsReturn            59.7059
2017-07-02 14:43:45.153567 EDT | StdEsReturn                46.7695
2017-07-02 14:43:45.153671 EDT | MaxEsReturn               211
2017-07-02 14:43:45.153789 EDT | MinEsReturn                 5
2017-07-02 14:43:45.153893 EDT | AverageDiscountedReturn    99.9957
2017-07-02 14:43:45.153993 EDT | AverageQLoss                0.00992755
2017-07-02 14:43:45.154094 EDT | AveragePolicySurr          -1.67464
2017-07-02 14:43:45.154193 EDT | AverageQ                    1.59379
2017-07-02 14:43:45.154333 EDT | AverageAbsQ                 1.599
2017-07-02 14:43:45.154434 EDT | AverageY                    1.59358
2017-07-02 14:43:45.154534 EDT | AverageAbsY                 1.59417
2017-07-02 14:43:45.154632 EDT | AverageAbsQYDiff            0.0283735
2017-07-02 14:43:45.154730 EDT | AverageAction               0.183321
2017-07-02 14:43:45.154828 EDT | PolicyRegParamNorm         60.9981
2017-07-02 14:43:45.154994 EDT | QFunRegParamNorm           59.9799
2017-07-02 14:43:45.155096 EDT | -----------------------  -------------
2017-07-02 14:43:45.155292 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #538 | Training started
2017-07-02 14:43:54.486409 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #538 | Training finished
2017-07-02 14:43:54.487035 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #538 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 14:43:54.487321 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #538 | Collecting samples for evaluation
2017-07-02 14:43:59.974148 EDT | -----------------------  -------------
2017-07-02 14:43:59.974461 EDT | Epoch                     538
2017-07-02 14:43:59.974946 EDT | Iteration                 538
2017-07-02 14:43:59.975186 EDT | AverageReturn            1000
2017-07-02 14:43:59.975822 EDT | StdReturn                   0
2017-07-02 14:43:59.976115 EDT | MaxReturn                1000
2017-07-02 14:43:59.976348 EDT | MinReturn                1000
2017-07-02 14:43:59.976568 EDT | AverageEsReturn            60.1765
2017-07-02 14:43:59.976750 EDT | StdEsReturn                56.7349
2017-07-02 14:43:59.976961 EDT | MaxEsReturn               254
2017-07-02 14:43:59.977178 EDT | MinEsReturn                 5
2017-07-02 14:43:59.977355 EDT | AverageDiscountedReturn    99.9957
2017-07-02 14:43:59.977579 EDT | AverageQLoss                0.00866749
2017-07-02 14:43:59.977813 EDT | AveragePolicySurr          -1.66817
2017-07-02 14:43:59.978037 EDT | AverageQ                    1.58817
2017-07-02 14:43:59.979314 EDT | AverageAbsQ                 1.59232
2017-07-02 14:43:59.979557 EDT | AverageY                    1.58823
2017-07-02 14:43:59.979776 EDT | AverageAbsY                 1.5888
2017-07-02 14:43:59.980007 EDT | AverageAbsQYDiff            0.0241763
2017-07-02 14:43:59.980262 EDT | AverageAction               0.489586
2017-07-02 14:43:59.980439 EDT | PolicyRegParamNorm         61.0706
2017-07-02 14:43:59.980665 EDT | QFunRegParamNorm           59.9899
2017-07-02 14:43:59.980863 EDT | -----------------------  -------------
2017-07-02 14:43:59.981148 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #539 | Training started
2017-07-02 14:44:09.242966 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #539 | Training finished
2017-07-02 14:44:09.243563 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #539 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 14:44:09.243809 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #539 | Collecting samples for evaluation
2017-07-02 14:44:14.791022 EDT | -----------------------  -------------
2017-07-02 14:44:14.791285 EDT | Epoch                     539
2017-07-02 14:44:14.791624 EDT | Iteration                 539
2017-07-02 14:44:14.791846 EDT | AverageReturn            1000
2017-07-02 14:44:14.792035 EDT | StdReturn                   0
2017-07-02 14:44:14.792179 EDT | MaxReturn                1000
2017-07-02 14:44:14.792290 EDT | MinReturn                1000
2017-07-02 14:44:14.792402 EDT | AverageEsReturn            31.6452
2017-07-02 14:44:14.792623 EDT | StdEsReturn                22.9832
2017-07-02 14:44:14.793272 EDT | MaxEsReturn               111
2017-07-02 14:44:14.793525 EDT | MinEsReturn                 5
2017-07-02 14:44:14.793772 EDT | AverageDiscountedReturn    99.9957
2017-07-02 14:44:14.793999 EDT | AverageQLoss                0.00934688
2017-07-02 14:44:14.794223 EDT | AveragePolicySurr          -1.66201
2017-07-02 14:44:14.794440 EDT | AverageQ                    1.58034
2017-07-02 14:44:14.794645 EDT | AverageAbsQ                 1.58538
2017-07-02 14:44:14.794866 EDT | AverageY                    1.58033
2017-07-02 14:44:14.795025 EDT | AverageAbsY                 1.58088
2017-07-02 14:44:14.795197 EDT | AverageAbsQYDiff            0.0266187
2017-07-02 14:44:14.795363 EDT | AverageAction               0.942464
2017-07-02 14:44:14.795572 EDT | PolicyRegParamNorm         61.1288
2017-07-02 14:44:14.795784 EDT | QFunRegParamNorm           60.0052
2017-07-02 14:44:14.796011 EDT | -----------------------  -------------
2017-07-02 14:44:14.796321 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #540 | Training started
2017-07-02 14:44:24.156645 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #540 | Training finished
2017-07-02 14:44:24.157254 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #540 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 14:44:24.157435 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #540 | Collecting samples for evaluation
2017-07-02 14:44:29.602155 EDT | -----------------------  -------------
2017-07-02 14:44:29.602455 EDT | Epoch                     540
2017-07-02 14:44:29.602685 EDT | Iteration                 540
2017-07-02 14:44:29.602864 EDT | AverageReturn            1000
2017-07-02 14:44:29.603096 EDT | StdReturn                   0
2017-07-02 14:44:29.603314 EDT | MaxReturn                1000
2017-07-02 14:44:29.603535 EDT | MinReturn                1000
2017-07-02 14:44:29.603766 EDT | AverageEsReturn            46.5
2017-07-02 14:44:29.603987 EDT | StdEsReturn                33.2467
2017-07-02 14:44:29.604212 EDT | MaxEsReturn               141
2017-07-02 14:44:29.604431 EDT | MinEsReturn                 3
2017-07-02 14:44:29.604577 EDT | AverageDiscountedReturn    99.9957
2017-07-02 14:44:29.604807 EDT | AverageQLoss                0.00786474
2017-07-02 14:44:29.605033 EDT | AveragePolicySurr          -1.65306
2017-07-02 14:44:29.605247 EDT | AverageQ                    1.57062
2017-07-02 14:44:29.605480 EDT | AverageAbsQ                 1.57488
2017-07-02 14:44:29.605816 EDT | AverageY                    1.57057
2017-07-02 14:44:29.606048 EDT | AverageAbsY                 1.57106
2017-07-02 14:44:29.606245 EDT | AverageAbsQYDiff            0.0228697
2017-07-02 14:44:29.606476 EDT | AverageAction               0.759083
2017-07-02 14:44:29.606701 EDT | PolicyRegParamNorm         61.156
2017-07-02 14:44:29.606910 EDT | QFunRegParamNorm           60.0251
2017-07-02 14:44:29.607137 EDT | -----------------------  -------------
2017-07-02 14:44:29.607425 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #541 | Training started
2017-07-02 14:44:39.215886 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #541 | Training finished
2017-07-02 14:44:39.216763 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #541 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 14:44:39.216935 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #541 | Collecting samples for evaluation
2017-07-02 14:44:44.677205 EDT | -----------------------  -------------
2017-07-02 14:44:44.677402 EDT | Epoch                     541
2017-07-02 14:44:44.677577 EDT | Iteration                 541
2017-07-02 14:44:44.677707 EDT | AverageReturn            1000
2017-07-02 14:44:44.677834 EDT | StdReturn                   0
2017-07-02 14:44:44.677960 EDT | MaxReturn                1000
2017-07-02 14:44:44.678084 EDT | MinReturn                1000
2017-07-02 14:44:44.678310 EDT | AverageEsReturn            42.0417
2017-07-02 14:44:44.678516 EDT | StdEsReturn                31.7549
2017-07-02 14:44:44.678736 EDT | MaxEsReturn               114
2017-07-02 14:44:44.678961 EDT | MinEsReturn                 4
2017-07-02 14:44:44.679152 EDT | AverageDiscountedReturn    99.9957
2017-07-02 14:44:44.679393 EDT | AverageQLoss                0.00903869
2017-07-02 14:44:44.679620 EDT | AveragePolicySurr          -1.64461
2017-07-02 14:44:44.679856 EDT | AverageQ                    1.56326
2017-07-02 14:44:44.680082 EDT | AverageAbsQ                 1.56759
2017-07-02 14:44:44.680293 EDT | AverageY                    1.56335
2017-07-02 14:44:44.680466 EDT | AverageAbsY                 1.56383
2017-07-02 14:44:44.680690 EDT | AverageAbsQYDiff            0.0253226
2017-07-02 14:44:44.680870 EDT | AverageAction               0.970839
2017-07-02 14:44:44.681073 EDT | PolicyRegParamNorm         61.157
2017-07-02 14:44:44.681301 EDT | QFunRegParamNorm           60.0303
2017-07-02 14:44:44.681975 EDT | -----------------------  -------------
2017-07-02 14:44:44.682558 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #542 | Training started
2017-07-02 14:44:54.167409 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #542 | Training finished
2017-07-02 14:44:54.168326 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #542 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 14:44:54.168472 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #542 | Collecting samples for evaluation
2017-07-02 14:44:59.557656 EDT | -----------------------  -------------
2017-07-02 14:44:59.557969 EDT | Epoch                     542
2017-07-02 14:44:59.558222 EDT | Iteration                 542
2017-07-02 14:44:59.558433 EDT | AverageReturn            1000
2017-07-02 14:44:59.558707 EDT | StdReturn                   0
2017-07-02 14:44:59.558957 EDT | MaxReturn                1000
2017-07-02 14:44:59.559184 EDT | MinReturn                1000
2017-07-02 14:44:59.559404 EDT | AverageEsReturn            29.0882
2017-07-02 14:44:59.559618 EDT | StdEsReturn                20.737
2017-07-02 14:44:59.559851 EDT | MaxEsReturn                84
2017-07-02 14:44:59.560048 EDT | MinEsReturn                 3
2017-07-02 14:44:59.560265 EDT | AverageDiscountedReturn    99.9957
2017-07-02 14:44:59.560488 EDT | AverageQLoss                0.00823683
2017-07-02 14:44:59.560711 EDT | AveragePolicySurr          -1.63868
2017-07-02 14:44:59.560833 EDT | AverageQ                    1.55651
2017-07-02 14:44:59.561063 EDT | AverageAbsQ                 1.56085
2017-07-02 14:44:59.561272 EDT | AverageY                    1.55648
2017-07-02 14:44:59.561520 EDT | AverageAbsY                 1.55704
2017-07-02 14:44:59.561742 EDT | AverageAbsQYDiff            0.024369
2017-07-02 14:44:59.561961 EDT | AverageAction               0.629295
2017-07-02 14:44:59.562189 EDT | PolicyRegParamNorm         61.1787
2017-07-02 14:44:59.562417 EDT | QFunRegParamNorm           60.0507
2017-07-02 14:44:59.562612 EDT | -----------------------  -------------
2017-07-02 14:44:59.562935 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #543 | Training started
2017-07-02 14:45:08.909065 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #543 | Training finished
2017-07-02 14:45:08.909673 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #543 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 14:45:08.909908 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #543 | Collecting samples for evaluation
2017-07-02 14:45:14.380958 EDT | -----------------------  -------------
2017-07-02 14:45:14.381273 EDT | Epoch                     543
2017-07-02 14:45:14.381483 EDT | Iteration                 543
2017-07-02 14:45:14.381721 EDT | AverageReturn            1000
2017-07-02 14:45:14.381928 EDT | StdReturn                   0
2017-07-02 14:45:14.382128 EDT | MaxReturn                1000
2017-07-02 14:45:14.382362 EDT | MinReturn                1000
2017-07-02 14:45:14.382521 EDT | AverageEsReturn            30.8438
2017-07-02 14:45:14.382742 EDT | StdEsReturn                23.6935
2017-07-02 14:45:14.382943 EDT | MaxEsReturn                94
2017-07-02 14:45:14.383143 EDT | MinEsReturn                 3
2017-07-02 14:45:14.383380 EDT | AverageDiscountedReturn    99.9957
2017-07-02 14:45:14.383605 EDT | AverageQLoss                0.00945227
2017-07-02 14:45:14.383821 EDT | AveragePolicySurr          -1.63013
2017-07-02 14:45:14.384023 EDT | AverageQ                    1.54985
2017-07-02 14:45:14.384251 EDT | AverageAbsQ                 1.55394
2017-07-02 14:45:14.384475 EDT | AverageY                    1.54981
2017-07-02 14:45:14.384704 EDT | AverageAbsY                 1.55018
2017-07-02 14:45:14.384906 EDT | AverageAbsQYDiff            0.0266567
2017-07-02 14:45:14.385113 EDT | AverageAction               0.576307
2017-07-02 14:45:14.385346 EDT | PolicyRegParamNorm         61.241
2017-07-02 14:45:14.385463 EDT | QFunRegParamNorm           60.0751
2017-07-02 14:45:14.385701 EDT | -----------------------  -------------
2017-07-02 14:45:14.386002 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #544 | Training started
2017-07-02 14:45:24.196878 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #544 | Training finished
2017-07-02 14:45:24.197412 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #544 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 14:45:24.197728 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #544 | Collecting samples for evaluation
2017-07-02 14:45:29.763499 EDT | -----------------------  -------------
2017-07-02 14:45:29.763803 EDT | Epoch                     544
2017-07-02 14:45:29.764036 EDT | Iteration                 544
2017-07-02 14:45:29.764258 EDT | AverageReturn            1000
2017-07-02 14:45:29.764477 EDT | StdReturn                   0
2017-07-02 14:45:29.764690 EDT | MaxReturn                1000
2017-07-02 14:45:29.764911 EDT | MinReturn                1000
2017-07-02 14:45:29.765048 EDT | AverageEsReturn            34.1333
2017-07-02 14:45:29.765154 EDT | StdEsReturn                31.4332
2017-07-02 14:45:29.765255 EDT | MaxEsReturn               130
2017-07-02 14:45:29.765378 EDT | MinEsReturn                 5
2017-07-02 14:45:29.765481 EDT | AverageDiscountedReturn    99.9957
2017-07-02 14:45:29.765851 EDT | AverageQLoss                0.00821366
2017-07-02 14:45:29.766065 EDT | AveragePolicySurr          -1.62304
2017-07-02 14:45:29.766287 EDT | AverageQ                    1.54297
2017-07-02 14:45:29.766487 EDT | AverageAbsQ                 1.54767
2017-07-02 14:45:29.766660 EDT | AverageY                    1.54292
2017-07-02 14:45:29.766893 EDT | AverageAbsY                 1.54318
2017-07-02 14:45:29.767111 EDT | AverageAbsQYDiff            0.0243924
2017-07-02 14:45:29.767327 EDT | AverageAction               0.538391
2017-07-02 14:45:29.767538 EDT | PolicyRegParamNorm         61.2547
2017-07-02 14:45:29.767702 EDT | QFunRegParamNorm           60.0692
2017-07-02 14:45:29.767843 EDT | -----------------------  -------------
2017-07-02 14:45:29.768151 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #545 | Training started
2017-07-02 14:45:39.117107 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #545 | Training finished
2017-07-02 14:45:39.117659 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #545 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 14:45:39.117810 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #545 | Collecting samples for evaluation
2017-07-02 14:45:44.571064 EDT | -----------------------  -------------
2017-07-02 14:45:44.571342 EDT | Epoch                     545
2017-07-02 14:45:44.571530 EDT | Iteration                 545
2017-07-02 14:45:44.571734 EDT | AverageReturn            1000
2017-07-02 14:45:44.571884 EDT | StdReturn                   0
2017-07-02 14:45:44.572001 EDT | MaxReturn                1000
2017-07-02 14:45:44.572172 EDT | MinReturn                1000
2017-07-02 14:45:44.572306 EDT | AverageEsReturn            20.587
2017-07-02 14:45:44.572417 EDT | StdEsReturn                18.5667
2017-07-02 14:45:44.572518 EDT | MaxEsReturn                98
2017-07-02 14:45:44.572618 EDT | MinEsReturn                 3
2017-07-02 14:45:44.572721 EDT | AverageDiscountedReturn    99.9957
2017-07-02 14:45:44.572853 EDT | AverageQLoss                0.00768322
2017-07-02 14:45:44.572990 EDT | AveragePolicySurr          -1.61747
2017-07-02 14:45:44.573091 EDT | AverageQ                    1.54166
2017-07-02 14:45:44.573219 EDT | AverageAbsQ                 1.54608
2017-07-02 14:45:44.573356 EDT | AverageY                    1.54164
2017-07-02 14:45:44.573458 EDT | AverageAbsY                 1.54193
2017-07-02 14:45:44.573705 EDT | AverageAbsQYDiff            0.0244861
2017-07-02 14:45:44.573819 EDT | AverageAction               0.0242254
2017-07-02 14:45:44.573920 EDT | PolicyRegParamNorm         61.3035
2017-07-02 14:45:44.574070 EDT | QFunRegParamNorm           60.0928
2017-07-02 14:45:44.574173 EDT | -----------------------  -------------
2017-07-02 14:45:44.574361 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #546 | Training started
2017-07-02 14:45:53.910358 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #546 | Training finished
2017-07-02 14:45:53.910897 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #546 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 14:45:53.911304 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #546 | Collecting samples for evaluation
2017-07-02 14:45:59.377242 EDT | -----------------------  -------------
2017-07-02 14:45:59.377561 EDT | Epoch                     546
2017-07-02 14:45:59.377794 EDT | Iteration                 546
2017-07-02 14:45:59.377995 EDT | AverageReturn            1000
2017-07-02 14:45:59.378226 EDT | StdReturn                   0
2017-07-02 14:45:59.378441 EDT | MaxReturn                1000
2017-07-02 14:45:59.378672 EDT | MinReturn                1000
2017-07-02 14:45:59.378889 EDT | AverageEsReturn            31.871
2017-07-02 14:45:59.379118 EDT | StdEsReturn                27.5783
2017-07-02 14:45:59.379344 EDT | MaxEsReturn               124
2017-07-02 14:45:59.379561 EDT | MinEsReturn                 3
2017-07-02 14:45:59.379787 EDT | AverageDiscountedReturn    99.9957
2017-07-02 14:45:59.379966 EDT | AverageQLoss                0.00881753
2017-07-02 14:45:59.380197 EDT | AveragePolicySurr          -1.60618
2017-07-02 14:45:59.380375 EDT | AverageQ                    1.53102
2017-07-02 14:45:59.380555 EDT | AverageAbsQ                 1.53521
2017-07-02 14:45:59.380781 EDT | AverageY                    1.53102
2017-07-02 14:45:59.380948 EDT | AverageAbsY                 1.53123
2017-07-02 14:45:59.381174 EDT | AverageAbsQYDiff            0.0253732
2017-07-02 14:45:59.381391 EDT | AverageAction               0.553572
2017-07-02 14:45:59.381601 EDT | PolicyRegParamNorm         61.3179
2017-07-02 14:45:59.381831 EDT | QFunRegParamNorm           60.1061
2017-07-02 14:45:59.382022 EDT | -----------------------  -------------
2017-07-02 14:45:59.382343 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #547 | Training started
2017-07-02 14:46:08.873212 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #547 | Training finished
2017-07-02 14:46:08.873732 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #547 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 14:46:08.873914 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #547 | Collecting samples for evaluation
2017-07-02 14:46:14.282769 EDT | -----------------------  -------------
2017-07-02 14:46:14.283292 EDT | Epoch                     547
2017-07-02 14:46:14.283448 EDT | Iteration                 547
2017-07-02 14:46:14.283619 EDT | AverageReturn            1000
2017-07-02 14:46:14.283811 EDT | StdReturn                   0
2017-07-02 14:46:14.284033 EDT | MaxReturn                1000
2017-07-02 14:46:14.284268 EDT | MinReturn                1000
2017-07-02 14:46:14.284496 EDT | AverageEsReturn            30.1176
2017-07-02 14:46:14.284680 EDT | StdEsReturn                29.8986
2017-07-02 14:46:14.284867 EDT | MaxEsReturn               130
2017-07-02 14:46:14.285052 EDT | MinEsReturn                 3
2017-07-02 14:46:14.285234 EDT | AverageDiscountedReturn    99.9957
2017-07-02 14:46:14.285400 EDT | AverageQLoss                0.00850445
2017-07-02 14:46:14.285583 EDT | AveragePolicySurr          -1.59828
2017-07-02 14:46:14.285753 EDT | AverageQ                    1.51854
2017-07-02 14:46:14.285917 EDT | AverageAbsQ                 1.52296
2017-07-02 14:46:14.286079 EDT | AverageY                    1.51855
2017-07-02 14:46:14.286241 EDT | AverageAbsY                 1.51892
2017-07-02 14:46:14.286405 EDT | AverageAbsQYDiff            0.0242739
2017-07-02 14:46:14.286568 EDT | AverageAction               0.647227
2017-07-02 14:46:14.286731 EDT | PolicyRegParamNorm         61.3764
2017-07-02 14:46:14.286899 EDT | QFunRegParamNorm           60.1079
2017-07-02 14:46:14.287064 EDT | -----------------------  -------------
2017-07-02 14:46:14.287310 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #548 | Training started
2017-07-02 14:46:23.708957 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #548 | Training finished
2017-07-02 14:46:23.709652 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #548 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 14:46:23.709872 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #548 | Collecting samples for evaluation
2017-07-02 14:46:29.218726 EDT | -----------------------  -------------
2017-07-02 14:46:29.218921 EDT | Epoch                     548
2017-07-02 14:46:29.219063 EDT | Iteration                 548
2017-07-02 14:46:29.219231 EDT | AverageReturn            1000
2017-07-02 14:46:29.219369 EDT | StdReturn                   0
2017-07-02 14:46:29.219515 EDT | MaxReturn                1000
2017-07-02 14:46:29.219633 EDT | MinReturn                1000
2017-07-02 14:46:29.219803 EDT | AverageEsReturn            32.9677
2017-07-02 14:46:29.220035 EDT | StdEsReturn                22.3513
2017-07-02 14:46:29.220264 EDT | MaxEsReturn                89
2017-07-02 14:46:29.220463 EDT | MinEsReturn                 3
2017-07-02 14:46:29.220691 EDT | AverageDiscountedReturn    99.9957
2017-07-02 14:46:29.220895 EDT | AverageQLoss                0.00792082
2017-07-02 14:46:29.221126 EDT | AveragePolicySurr          -1.59418
2017-07-02 14:46:29.221341 EDT | AverageQ                    1.51827
2017-07-02 14:46:29.221588 EDT | AverageAbsQ                 1.52202
2017-07-02 14:46:29.221816 EDT | AverageY                    1.51817
2017-07-02 14:46:29.222009 EDT | AverageAbsY                 1.51862
2017-07-02 14:46:29.222238 EDT | AverageAbsQYDiff            0.0237265
2017-07-02 14:46:29.222455 EDT | AverageAction               0.806055
2017-07-02 14:46:29.222675 EDT | PolicyRegParamNorm         61.4088
2017-07-02 14:46:29.222901 EDT | QFunRegParamNorm           60.1285
2017-07-02 14:46:29.223122 EDT | -----------------------  -------------
2017-07-02 14:46:29.223446 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #549 | Training started
2017-07-02 14:46:38.467313 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #549 | Training finished
2017-07-02 14:46:38.468260 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #549 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 14:46:38.468518 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #549 | Collecting samples for evaluation
2017-07-02 14:46:44.094153 EDT | -----------------------  -------------
2017-07-02 14:46:44.094459 EDT | Epoch                     549
2017-07-02 14:46:44.094677 EDT | Iteration                 549
2017-07-02 14:46:44.094913 EDT | AverageReturn             921.636
2017-07-02 14:46:44.095112 EDT | StdReturn                 247.808
2017-07-02 14:46:44.095218 EDT | MaxReturn                1000
2017-07-02 14:46:44.095320 EDT | MinReturn                 138
2017-07-02 14:46:44.095501 EDT | AverageEsReturn            40.56
2017-07-02 14:46:44.095724 EDT | StdEsReturn                35.5112
2017-07-02 14:46:44.095945 EDT | MaxEsReturn               143
2017-07-02 14:46:44.096177 EDT | MinEsReturn                 5
2017-07-02 14:46:44.096400 EDT | AverageDiscountedReturn    97.7248
2017-07-02 14:46:44.096610 EDT | AverageQLoss                0.00769771
2017-07-02 14:46:44.096842 EDT | AveragePolicySurr          -1.58684
2017-07-02 14:46:44.097067 EDT | AverageQ                    1.50746
2017-07-02 14:46:44.097286 EDT | AverageAbsQ                 1.51151
2017-07-02 14:46:44.097514 EDT | AverageY                    1.50745
2017-07-02 14:46:44.097747 EDT | AverageAbsY                 1.50779
2017-07-02 14:46:44.097976 EDT | AverageAbsQYDiff            0.0243501
2017-07-02 14:46:44.098183 EDT | AverageAction               0.931701
2017-07-02 14:46:44.098410 EDT | PolicyRegParamNorm         61.4309
2017-07-02 14:46:44.098619 EDT | QFunRegParamNorm           60.1689
2017-07-02 14:46:44.098848 EDT | -----------------------  -------------
2017-07-02 14:46:44.099152 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #550 | Training started
2017-07-02 14:46:53.378511 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #550 | Training finished
2017-07-02 14:46:53.379057 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #550 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 14:46:53.379215 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #550 | Collecting samples for evaluation
2017-07-02 14:46:58.899176 EDT | -----------------------  -------------
2017-07-02 14:46:58.899407 EDT | Epoch                     550
2017-07-02 14:46:58.899589 EDT | Iteration                 550
2017-07-02 14:46:58.899722 EDT | AverageReturn            1000
2017-07-02 14:46:58.899889 EDT | StdReturn                   0
2017-07-02 14:46:58.900021 EDT | MaxReturn                1000
2017-07-02 14:46:58.900174 EDT | MinReturn                1000
2017-07-02 14:46:58.900293 EDT | AverageEsReturn            41.5417
2017-07-02 14:46:58.900399 EDT | StdEsReturn                43.5
2017-07-02 14:46:58.900555 EDT | MaxEsReturn               196
2017-07-02 14:46:58.900703 EDT | MinEsReturn                 3
2017-07-02 14:46:58.900834 EDT | AverageDiscountedReturn    99.9957
2017-07-02 14:46:58.900968 EDT | AverageQLoss                0.00885608
2017-07-02 14:46:58.901100 EDT | AveragePolicySurr          -1.57659
2017-07-02 14:46:58.901222 EDT | AverageQ                    1.49798
2017-07-02 14:46:58.901396 EDT | AverageAbsQ                 1.50237
2017-07-02 14:46:58.901579 EDT | AverageY                    1.4979
2017-07-02 14:46:58.901765 EDT | AverageAbsY                 1.49846
2017-07-02 14:46:58.901931 EDT | AverageAbsQYDiff            0.0257763
2017-07-02 14:46:58.902042 EDT | AverageAction               0.912268
2017-07-02 14:46:58.902160 EDT | PolicyRegParamNorm         61.4729
2017-07-02 14:46:58.902283 EDT | QFunRegParamNorm           60.2201
2017-07-02 14:46:58.902434 EDT | -----------------------  -------------
2017-07-02 14:46:58.902592 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #551 | Training started
2017-07-02 14:47:08.243603 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #551 | Training finished
2017-07-02 14:47:08.244139 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #551 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 14:47:08.244287 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #551 | Collecting samples for evaluation
2017-07-02 14:47:13.757131 EDT | -----------------------  -------------
2017-07-02 14:47:13.757546 EDT | Epoch                     551
2017-07-02 14:47:13.757785 EDT | Iteration                 551
2017-07-02 14:47:13.757954 EDT | AverageReturn            1000
2017-07-02 14:47:13.758182 EDT | StdReturn                   0
2017-07-02 14:47:13.758403 EDT | MaxReturn                1000
2017-07-02 14:47:13.758516 EDT | MinReturn                1000
2017-07-02 14:47:13.758618 EDT | AverageEsReturn            40.9583
2017-07-02 14:47:13.758793 EDT | StdEsReturn                39.5553
2017-07-02 14:47:13.759020 EDT | MaxEsReturn               159
2017-07-02 14:47:13.759199 EDT | MinEsReturn                 4
2017-07-02 14:47:13.759432 EDT | AverageDiscountedReturn    99.9957
2017-07-02 14:47:13.759653 EDT | AverageQLoss                0.00811019
2017-07-02 14:47:13.759869 EDT | AveragePolicySurr          -1.57142
2017-07-02 14:47:13.760094 EDT | AverageQ                    1.49632
2017-07-02 14:47:13.760252 EDT | AverageAbsQ                 1.50018
2017-07-02 14:47:13.760358 EDT | AverageY                    1.4963
2017-07-02 14:47:13.760460 EDT | AverageAbsY                 1.49675
2017-07-02 14:47:13.760559 EDT | AverageAbsQYDiff            0.0243316
2017-07-02 14:47:13.760658 EDT | AverageAction               0.940107
2017-07-02 14:47:13.760794 EDT | PolicyRegParamNorm         61.5523
2017-07-02 14:47:13.760893 EDT | QFunRegParamNorm           60.2556
2017-07-02 14:47:13.760992 EDT | -----------------------  -------------
2017-07-02 14:47:13.761193 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #552 | Training started
2017-07-02 14:47:23.092646 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #552 | Training finished
2017-07-02 14:47:23.093194 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #552 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 14:47:23.093426 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #552 | Collecting samples for evaluation
2017-07-02 14:47:28.619423 EDT | -----------------------  ------------
2017-07-02 14:47:28.619682 EDT | Epoch                     552
2017-07-02 14:47:28.619805 EDT | Iteration                 552
2017-07-02 14:47:28.619943 EDT | AverageReturn            1000
2017-07-02 14:47:28.620059 EDT | StdReturn                   0
2017-07-02 14:47:28.620201 EDT | MaxReturn                1000
2017-07-02 14:47:28.620358 EDT | MinReturn                1000
2017-07-02 14:47:28.620479 EDT | AverageEsReturn            34.9655
2017-07-02 14:47:28.620627 EDT | StdEsReturn                22.8209
2017-07-02 14:47:28.620771 EDT | MaxEsReturn               100
2017-07-02 14:47:28.620877 EDT | MinEsReturn                 8
2017-07-02 14:47:28.621005 EDT | AverageDiscountedReturn    99.9957
2017-07-02 14:47:28.621144 EDT | AverageQLoss                0.0080338
2017-07-02 14:47:28.621284 EDT | AveragePolicySurr          -1.56539
2017-07-02 14:47:28.621402 EDT | AverageQ                    1.48722
2017-07-02 14:47:28.621520 EDT | AverageAbsQ                 1.4911
2017-07-02 14:47:28.621672 EDT | AverageY                    1.48708
2017-07-02 14:47:28.621790 EDT | AverageAbsY                 1.48752
2017-07-02 14:47:28.621994 EDT | AverageAbsQYDiff            0.0239109
2017-07-02 14:47:28.622219 EDT | AverageAction               0.757632
2017-07-02 14:47:28.622443 EDT | PolicyRegParamNorm         61.5551
2017-07-02 14:47:28.622681 EDT | QFunRegParamNorm           60.2874
2017-07-02 14:47:28.622910 EDT | -----------------------  ------------
2017-07-02 14:47:28.623203 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #553 | Training started
2017-07-02 14:47:37.939038 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #553 | Training finished
2017-07-02 14:47:37.939848 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #553 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 14:47:37.940117 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #553 | Collecting samples for evaluation
2017-07-02 14:47:43.481164 EDT | -----------------------  -------------
2017-07-02 14:47:43.481353 EDT | Epoch                     553
2017-07-02 14:47:43.481468 EDT | Iteration                 553
2017-07-02 14:47:43.481638 EDT | AverageReturn            1000
2017-07-02 14:47:43.481792 EDT | StdReturn                   0
2017-07-02 14:47:43.481893 EDT | MaxReturn                1000
2017-07-02 14:47:43.482001 EDT | MinReturn                1000
2017-07-02 14:47:43.482132 EDT | AverageEsReturn            28.0588
2017-07-02 14:47:43.482233 EDT | StdEsReturn                23.6195
2017-07-02 14:47:43.482333 EDT | MaxEsReturn               136
2017-07-02 14:47:43.482453 EDT | MinEsReturn                 3
2017-07-02 14:47:43.482558 EDT | AverageDiscountedReturn    99.9957
2017-07-02 14:47:43.482669 EDT | AverageQLoss                0.00852351
2017-07-02 14:47:43.482770 EDT | AveragePolicySurr          -1.56086
2017-07-02 14:47:43.482887 EDT | AverageQ                    1.48182
2017-07-02 14:47:43.482987 EDT | AverageAbsQ                 1.48593
2017-07-02 14:47:43.483105 EDT | AverageY                    1.48184
2017-07-02 14:47:43.483243 EDT | AverageAbsY                 1.48235
2017-07-02 14:47:43.483345 EDT | AverageAbsQYDiff            0.02513
2017-07-02 14:47:43.483444 EDT | AverageAction               0.893661
2017-07-02 14:47:43.483542 EDT | PolicyRegParamNorm         61.5552
2017-07-02 14:47:43.483678 EDT | QFunRegParamNorm           60.2944
2017-07-02 14:47:43.483855 EDT | -----------------------  -------------
2017-07-02 14:47:43.484134 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #554 | Training started
2017-07-02 14:47:52.729798 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #554 | Training finished
2017-07-02 14:47:52.730409 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #554 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 14:47:52.730633 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #554 | Collecting samples for evaluation
2017-07-02 14:47:58.284846 EDT | -----------------------  -------------
2017-07-02 14:47:58.285066 EDT | Epoch                     554
2017-07-02 14:47:58.285253 EDT | Iteration                 554
2017-07-02 14:47:58.285450 EDT | AverageReturn            1000
2017-07-02 14:47:58.285655 EDT | StdReturn                   0
2017-07-02 14:47:58.285834 EDT | MaxReturn                1000
2017-07-02 14:47:58.286018 EDT | MinReturn                1000
2017-07-02 14:47:58.286184 EDT | AverageEsReturn            39.7692
2017-07-02 14:47:58.286363 EDT | StdEsReturn                26.4245
2017-07-02 14:47:58.286484 EDT | MaxEsReturn               101
2017-07-02 14:47:58.286588 EDT | MinEsReturn                 4
2017-07-02 14:47:58.286727 EDT | AverageDiscountedReturn    99.9957
2017-07-02 14:47:58.286844 EDT | AverageQLoss                0.00850253
2017-07-02 14:47:58.286943 EDT | AveragePolicySurr          -1.55084
2017-07-02 14:47:58.287101 EDT | AverageQ                    1.47395
2017-07-02 14:47:58.287209 EDT | AverageAbsQ                 1.47905
2017-07-02 14:47:58.287311 EDT | AverageY                    1.47386
2017-07-02 14:47:58.287441 EDT | AverageAbsY                 1.47464
2017-07-02 14:47:58.287634 EDT | AverageAbsQYDiff            0.0258078
2017-07-02 14:47:58.287781 EDT | AverageAction               0.978711
2017-07-02 14:47:58.287909 EDT | PolicyRegParamNorm         61.5275
2017-07-02 14:47:58.288042 EDT | QFunRegParamNorm           60.2929
2017-07-02 14:47:58.288236 EDT | -----------------------  -------------
2017-07-02 14:47:58.288475 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #555 | Training started
2017-07-02 14:48:07.744083 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #555 | Training finished
2017-07-02 14:48:07.744718 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #555 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 14:48:07.744953 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #555 | Collecting samples for evaluation
2017-07-02 14:48:13.435909 EDT | -----------------------  -------------
2017-07-02 14:48:13.436136 EDT | Epoch                     555
2017-07-02 14:48:13.436298 EDT | Iteration                 555
2017-07-02 14:48:13.436434 EDT | AverageReturn            1000
2017-07-02 14:48:13.436567 EDT | StdReturn                   0
2017-07-02 14:48:13.436771 EDT | MaxReturn                1000
2017-07-02 14:48:13.436919 EDT | MinReturn                1000
2017-07-02 14:48:13.437151 EDT | AverageEsReturn            29.0857
2017-07-02 14:48:13.437376 EDT | StdEsReturn                23.4294
2017-07-02 14:48:13.437593 EDT | MaxEsReturn               100
2017-07-02 14:48:13.437800 EDT | MinEsReturn                 4
2017-07-02 14:48:13.438108 EDT | AverageDiscountedReturn    99.9957
2017-07-02 14:48:13.438398 EDT | AverageQLoss                0.00755244
2017-07-02 14:48:13.438832 EDT | AveragePolicySurr          -1.54546
2017-07-02 14:48:13.439058 EDT | AverageQ                    1.46815
2017-07-02 14:48:13.439363 EDT | AverageAbsQ                 1.47235
2017-07-02 14:48:13.439582 EDT | AverageY                    1.46821
2017-07-02 14:48:13.439762 EDT | AverageAbsY                 1.46893
2017-07-02 14:48:13.439991 EDT | AverageAbsQYDiff            0.0237023
2017-07-02 14:48:13.440198 EDT | AverageAction               0.942286
2017-07-02 14:48:13.440440 EDT | PolicyRegParamNorm         61.5638
2017-07-02 14:48:13.440669 EDT | QFunRegParamNorm           60.3225
2017-07-02 14:48:13.440969 EDT | -----------------------  -------------
2017-07-02 14:48:13.441291 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #556 | Training started
2017-07-02 14:48:22.797637 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #556 | Training finished
2017-07-02 14:48:22.798340 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #556 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 14:48:22.798532 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #556 | Collecting samples for evaluation
2017-07-02 14:48:28.304470 EDT | -----------------------  -------------
2017-07-02 14:48:28.304667 EDT | Epoch                     556
2017-07-02 14:48:28.304788 EDT | Iteration                 556
2017-07-02 14:48:28.304916 EDT | AverageReturn            1000
2017-07-02 14:48:28.305043 EDT | StdReturn                   0
2017-07-02 14:48:28.305185 EDT | MaxReturn                1000
2017-07-02 14:48:28.305350 EDT | MinReturn                1000
2017-07-02 14:48:28.305455 EDT | AverageEsReturn            31.1562
2017-07-02 14:48:28.305571 EDT | StdEsReturn                44.1836
2017-07-02 14:48:28.305716 EDT | MaxEsReturn               219
2017-07-02 14:48:28.305868 EDT | MinEsReturn                 3
2017-07-02 14:48:28.305988 EDT | AverageDiscountedReturn    99.9957
2017-07-02 14:48:28.306089 EDT | AverageQLoss                0.00761718
2017-07-02 14:48:28.306268 EDT | AveragePolicySurr          -1.54133
2017-07-02 14:48:28.306498 EDT | AverageQ                    1.46358
2017-07-02 14:48:28.306719 EDT | AverageAbsQ                 1.46775
2017-07-02 14:48:28.306952 EDT | AverageY                    1.46351
2017-07-02 14:48:28.307173 EDT | AverageAbsY                 1.46395
2017-07-02 14:48:28.307388 EDT | AverageAbsQYDiff            0.0238649
2017-07-02 14:48:28.307616 EDT | AverageAction               0.0382267
2017-07-02 14:48:28.307816 EDT | PolicyRegParamNorm         61.5658
2017-07-02 14:48:28.308041 EDT | QFunRegParamNorm           60.35
2017-07-02 14:48:28.308261 EDT | -----------------------  -------------
2017-07-02 14:48:28.308585 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #557 | Training started
2017-07-02 14:48:37.692447 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #557 | Training finished
2017-07-02 14:48:37.692981 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #557 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 14:48:37.693132 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #557 | Collecting samples for evaluation
2017-07-02 14:48:43.201756 EDT | -----------------------  -------------
2017-07-02 14:48:43.201961 EDT | Epoch                     557
2017-07-02 14:48:43.202078 EDT | Iteration                 557
2017-07-02 14:48:43.202340 EDT | AverageReturn            1000
2017-07-02 14:48:43.202536 EDT | StdReturn                   0
2017-07-02 14:48:43.202741 EDT | MaxReturn                1000
2017-07-02 14:48:43.202887 EDT | MinReturn                1000
2017-07-02 14:48:43.203057 EDT | AverageEsReturn            22.0444
2017-07-02 14:48:43.203162 EDT | StdEsReturn                25.434
2017-07-02 14:48:43.203326 EDT | MaxEsReturn               140
2017-07-02 14:48:43.203432 EDT | MinEsReturn                 3
2017-07-02 14:48:43.203556 EDT | AverageDiscountedReturn    99.9957
2017-07-02 14:48:43.203728 EDT | AverageQLoss                0.00871677
2017-07-02 14:48:43.203924 EDT | AveragePolicySurr          -1.53489
2017-07-02 14:48:43.204157 EDT | AverageQ                    1.45988
2017-07-02 14:48:43.204374 EDT | AverageAbsQ                 1.46413
2017-07-02 14:48:43.204572 EDT | AverageY                    1.45992
2017-07-02 14:48:43.204769 EDT | AverageAbsY                 1.46022
2017-07-02 14:48:43.205010 EDT | AverageAbsQYDiff            0.0248567
2017-07-02 14:48:43.205234 EDT | AverageAction               0.930562
2017-07-02 14:48:43.205446 EDT | PolicyRegParamNorm         61.5857
2017-07-02 14:48:43.205694 EDT | QFunRegParamNorm           60.4044
2017-07-02 14:48:43.205891 EDT | -----------------------  -------------
2017-07-02 14:48:43.206181 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #558 | Training started
2017-07-02 14:48:52.386915 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #558 | Training finished
2017-07-02 14:48:52.387420 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #558 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 14:48:52.387679 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #558 | Collecting samples for evaluation
2017-07-02 14:48:58.019219 EDT | -----------------------  -------------
2017-07-02 14:48:58.019427 EDT | Epoch                     558
2017-07-02 14:48:58.019546 EDT | Iteration                 558
2017-07-02 14:48:58.019663 EDT | AverageReturn            1000
2017-07-02 14:48:58.019777 EDT | StdReturn                   0
2017-07-02 14:48:58.019919 EDT | MaxReturn                1000
2017-07-02 14:48:58.020027 EDT | MinReturn                1000
2017-07-02 14:48:58.020124 EDT | AverageEsReturn            35.0357
2017-07-02 14:48:58.020229 EDT | StdEsReturn                35.7716
2017-07-02 14:48:58.020338 EDT | MaxEsReturn               123
2017-07-02 14:48:58.020443 EDT | MinEsReturn                 3
2017-07-02 14:48:58.020545 EDT | AverageDiscountedReturn    99.9957
2017-07-02 14:48:58.020643 EDT | AverageQLoss                0.00774078
2017-07-02 14:48:58.020739 EDT | AveragePolicySurr          -1.53157
2017-07-02 14:48:58.020843 EDT | AverageQ                    1.45488
2017-07-02 14:48:58.020944 EDT | AverageAbsQ                 1.45911
2017-07-02 14:48:58.021039 EDT | AverageY                    1.45475
2017-07-02 14:48:58.021157 EDT | AverageAbsY                 1.45508
2017-07-02 14:48:58.021253 EDT | AverageAbsQYDiff            0.0235256
2017-07-02 14:48:58.021349 EDT | AverageAction               0.59163
2017-07-02 14:48:58.021445 EDT | PolicyRegParamNorm         61.5573
2017-07-02 14:48:58.021800 EDT | QFunRegParamNorm           60.4041
2017-07-02 14:48:58.021971 EDT | -----------------------  -------------
2017-07-02 14:48:58.022251 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #559 | Training started
2017-07-02 14:49:07.151449 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #559 | Training finished
2017-07-02 14:49:07.151948 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #559 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 14:49:07.152414 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #559 | Collecting samples for evaluation
2017-07-02 14:49:12.772771 EDT | -----------------------  -------------
2017-07-02 14:49:12.773075 EDT | Epoch                     559
2017-07-02 14:49:12.773316 EDT | Iteration                 559
2017-07-02 14:49:12.773556 EDT | AverageReturn            1000
2017-07-02 14:49:12.773777 EDT | StdReturn                   0
2017-07-02 14:49:12.773989 EDT | MaxReturn                1000
2017-07-02 14:49:12.774191 EDT | MinReturn                1000
2017-07-02 14:49:12.774393 EDT | AverageEsReturn            32
2017-07-02 14:49:12.774610 EDT | StdEsReturn                47.2679
2017-07-02 14:49:12.774835 EDT | MaxEsReturn               268
2017-07-02 14:49:12.775057 EDT | MinEsReturn                 3
2017-07-02 14:49:12.775272 EDT | AverageDiscountedReturn    99.9957
2017-07-02 14:49:12.775484 EDT | AverageQLoss                0.00776228
2017-07-02 14:49:12.775703 EDT | AveragePolicySurr          -1.52368
2017-07-02 14:49:12.775921 EDT | AverageQ                    1.449
2017-07-02 14:49:12.776142 EDT | AverageAbsQ                 1.4529
2017-07-02 14:49:12.776253 EDT | AverageY                    1.44908
2017-07-02 14:49:12.776391 EDT | AverageAbsY                 1.4495
2017-07-02 14:49:12.776611 EDT | AverageAbsQYDiff            0.0245185
2017-07-02 14:49:12.776780 EDT | AverageAction               0.669733
2017-07-02 14:49:12.776919 EDT | PolicyRegParamNorm         61.5589
2017-07-02 14:49:12.777140 EDT | QFunRegParamNorm           60.4222
2017-07-02 14:49:12.777344 EDT | -----------------------  -------------
2017-07-02 14:49:12.777983 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #560 | Training started
2017-07-02 14:49:22.009502 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #560 | Training finished
2017-07-02 14:49:22.009993 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #560 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 14:49:22.010167 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #560 | Collecting samples for evaluation
2017-07-02 14:49:27.505525 EDT | -----------------------  -------------
2017-07-02 14:49:27.506022 EDT | Epoch                     560
2017-07-02 14:49:27.506167 EDT | Iteration                 560
2017-07-02 14:49:27.506344 EDT | AverageReturn            1000
2017-07-02 14:49:27.506577 EDT | StdReturn                   0
2017-07-02 14:49:27.506798 EDT | MaxReturn                1000
2017-07-02 14:49:27.507016 EDT | MinReturn                1000
2017-07-02 14:49:27.507232 EDT | AverageEsReturn            37.8462
2017-07-02 14:49:27.507353 EDT | StdEsReturn                41.2224
2017-07-02 14:49:27.507579 EDT | MaxEsReturn               152
2017-07-02 14:49:27.507760 EDT | MinEsReturn                 3
2017-07-02 14:49:27.507871 EDT | AverageDiscountedReturn    99.9957
2017-07-02 14:49:27.508099 EDT | AverageQLoss                0.00670858
2017-07-02 14:49:27.508326 EDT | AveragePolicySurr          -1.51481
2017-07-02 14:49:27.508443 EDT | AverageQ                    1.44526
2017-07-02 14:49:27.508545 EDT | AverageAbsQ                 1.44899
2017-07-02 14:49:27.508643 EDT | AverageY                    1.44519
2017-07-02 14:49:27.508740 EDT | AverageAbsY                 1.44547
2017-07-02 14:49:27.508839 EDT | AverageAbsQYDiff            0.0226569
2017-07-02 14:49:27.509021 EDT | AverageAction               0.343031
2017-07-02 14:49:27.509241 EDT | PolicyRegParamNorm         61.5419
2017-07-02 14:49:27.509353 EDT | QFunRegParamNorm           60.4426
2017-07-02 14:49:27.509456 EDT | -----------------------  -------------
2017-07-02 14:49:27.509743 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #561 | Training started
2017-07-02 14:49:36.836209 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #561 | Training finished
2017-07-02 14:49:36.836831 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #561 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 14:49:36.837095 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #561 | Collecting samples for evaluation
2017-07-02 14:49:42.465933 EDT | -----------------------  -------------
2017-07-02 14:49:42.466255 EDT | Epoch                     561
2017-07-02 14:49:42.466559 EDT | Iteration                 561
2017-07-02 14:49:42.466821 EDT | AverageReturn            1000
2017-07-02 14:49:42.466947 EDT | StdReturn                   0
2017-07-02 14:49:42.467078 EDT | MaxReturn                1000
2017-07-02 14:49:42.467263 EDT | MinReturn                1000
2017-07-02 14:49:42.467373 EDT | AverageEsReturn            22.1905
2017-07-02 14:49:42.467481 EDT | StdEsReturn                18.1321
2017-07-02 14:49:42.467587 EDT | MaxEsReturn                86
2017-07-02 14:49:42.467718 EDT | MinEsReturn                 4
2017-07-02 14:49:42.467824 EDT | AverageDiscountedReturn    99.9957
2017-07-02 14:49:42.467934 EDT | AverageQLoss                0.00898585
2017-07-02 14:49:42.468134 EDT | AveragePolicySurr          -1.51132
2017-07-02 14:49:42.468276 EDT | AverageQ                    1.43766
2017-07-02 14:49:42.468384 EDT | AverageAbsQ                 1.44178
2017-07-02 14:49:42.468489 EDT | AverageY                    1.4376
2017-07-02 14:49:42.468595 EDT | AverageAbsY                 1.43796
2017-07-02 14:49:42.468700 EDT | AverageAbsQYDiff            0.0265249
2017-07-02 14:49:42.468810 EDT | AverageAction               0.570782
2017-07-02 14:49:42.468958 EDT | PolicyRegParamNorm         61.5919
2017-07-02 14:49:42.469080 EDT | QFunRegParamNorm           60.4464
2017-07-02 14:49:42.469186 EDT | -----------------------  -------------
2017-07-02 14:49:42.469354 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #562 | Training started
2017-07-02 14:49:51.901598 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #562 | Training finished
2017-07-02 14:49:51.902217 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #562 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 14:49:51.902448 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #562 | Collecting samples for evaluation
2017-07-02 14:49:57.393064 EDT | -----------------------  -------------
2017-07-02 14:49:57.393384 EDT | Epoch                     562
2017-07-02 14:49:57.393631 EDT | Iteration                 562
2017-07-02 14:49:57.393851 EDT | AverageReturn            1000
2017-07-02 14:49:57.394021 EDT | StdReturn                   0
2017-07-02 14:49:57.394241 EDT | MaxReturn                1000
2017-07-02 14:49:57.394424 EDT | MinReturn                1000
2017-07-02 14:49:57.394568 EDT | AverageEsReturn            27.8718
2017-07-02 14:49:57.394677 EDT | StdEsReturn                30.9128
2017-07-02 14:49:57.394846 EDT | MaxEsReturn               167
2017-07-02 14:49:57.395062 EDT | MinEsReturn                 3
2017-07-02 14:49:57.395267 EDT | AverageDiscountedReturn    99.9957
2017-07-02 14:49:57.395484 EDT | AverageQLoss                0.00694389
2017-07-02 14:49:57.395697 EDT | AveragePolicySurr          -1.50508
2017-07-02 14:49:57.395928 EDT | AverageQ                    1.43168
2017-07-02 14:49:57.396148 EDT | AverageAbsQ                 1.43551
2017-07-02 14:49:57.396371 EDT | AverageY                    1.4316
2017-07-02 14:49:57.396531 EDT | AverageAbsY                 1.432
2017-07-02 14:49:57.396731 EDT | AverageAbsQYDiff            0.0220602
2017-07-02 14:49:57.396928 EDT | AverageAction               0.738644
2017-07-02 14:49:57.397147 EDT | PolicyRegParamNorm         61.6627
2017-07-02 14:49:57.397367 EDT | QFunRegParamNorm           60.4745
2017-07-02 14:49:57.397642 EDT | -----------------------  -------------
2017-07-02 14:49:57.397918 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #563 | Training started
2017-07-02 14:50:06.739220 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #563 | Training finished
2017-07-02 14:50:06.739831 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #563 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 14:50:06.740080 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #563 | Collecting samples for evaluation
2017-07-02 14:50:12.301192 EDT | -----------------------  -------------
2017-07-02 14:50:12.301590 EDT | Epoch                     563
2017-07-02 14:50:12.301831 EDT | Iteration                 563
2017-07-02 14:50:12.302048 EDT | AverageReturn             843.167
2017-07-02 14:50:12.302265 EDT | StdReturn                 350.692
2017-07-02 14:50:12.302494 EDT | MaxReturn                1000
2017-07-02 14:50:12.302660 EDT | MinReturn                  56
2017-07-02 14:50:12.302892 EDT | AverageEsReturn            26.9167
2017-07-02 14:50:12.303069 EDT | StdEsReturn                18.624
2017-07-02 14:50:12.303174 EDT | MaxEsReturn                65
2017-07-02 14:50:12.303276 EDT | MinEsReturn                 3
2017-07-02 14:50:12.303376 EDT | AverageDiscountedReturn    90.7808
2017-07-02 14:50:12.303477 EDT | AverageQLoss                0.00915774
2017-07-02 14:50:12.303699 EDT | AveragePolicySurr          -1.50099
2017-07-02 14:50:12.303919 EDT | AverageQ                    1.42777
2017-07-02 14:50:12.304062 EDT | AverageAbsQ                 1.43204
2017-07-02 14:50:12.304291 EDT | AverageY                    1.42775
2017-07-02 14:50:12.304487 EDT | AverageAbsY                 1.42794
2017-07-02 14:50:12.304593 EDT | AverageAbsQYDiff            0.0253843
2017-07-02 14:50:12.304694 EDT | AverageAction               0.690604
2017-07-02 14:50:12.304794 EDT | PolicyRegParamNorm         61.6766
2017-07-02 14:50:12.304894 EDT | QFunRegParamNorm           60.504
2017-07-02 14:50:12.304993 EDT | -----------------------  -------------
2017-07-02 14:50:12.305152 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #564 | Training started
2017-07-02 14:50:21.981408 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #564 | Training finished
2017-07-02 14:50:21.982254 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #564 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 14:50:21.982639 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #564 | Collecting samples for evaluation
2017-07-02 14:50:27.615511 EDT | -----------------------  -------------
2017-07-02 14:50:27.615704 EDT | Epoch                     564
2017-07-02 14:50:27.615817 EDT | Iteration                 564
2017-07-02 14:50:27.615979 EDT | AverageReturn            1000
2017-07-02 14:50:27.616084 EDT | StdReturn                   0
2017-07-02 14:50:27.616185 EDT | MaxReturn                1000
2017-07-02 14:50:27.616286 EDT | MinReturn                1000
2017-07-02 14:50:27.616386 EDT | AverageEsReturn            23.9231
2017-07-02 14:50:27.616530 EDT | StdEsReturn                17.5183
2017-07-02 14:50:27.616665 EDT | MaxEsReturn                78
2017-07-02 14:50:27.616776 EDT | MinEsReturn                 5
2017-07-02 14:50:27.616907 EDT | AverageDiscountedReturn    99.9957
2017-07-02 14:50:27.617030 EDT | AverageQLoss                0.00715331
2017-07-02 14:50:27.617149 EDT | AveragePolicySurr          -1.493
2017-07-02 14:50:27.617257 EDT | AverageQ                    1.4185
2017-07-02 14:50:27.617357 EDT | AverageAbsQ                 1.42243
2017-07-02 14:50:27.617478 EDT | AverageY                    1.41844
2017-07-02 14:50:27.617675 EDT | AverageAbsY                 1.41877
2017-07-02 14:50:27.617777 EDT | AverageAbsQYDiff            0.0235853
2017-07-02 14:50:27.617877 EDT | AverageAction               0.696719
2017-07-02 14:50:27.618077 EDT | PolicyRegParamNorm         61.7394
2017-07-02 14:50:27.618241 EDT | QFunRegParamNorm           60.5413
2017-07-02 14:50:27.618440 EDT | -----------------------  -------------
2017-07-02 14:50:27.618644 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #565 | Training started
2017-07-02 14:50:36.956608 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #565 | Training finished
2017-07-02 14:50:36.957124 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #565 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 14:50:36.957392 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #565 | Collecting samples for evaluation
2017-07-02 14:50:42.467335 EDT | -----------------------  -------------
2017-07-02 14:50:42.467633 EDT | Epoch                     565
2017-07-02 14:50:42.467869 EDT | Iteration                 565
2017-07-02 14:50:42.468219 EDT | AverageReturn            1000
2017-07-02 14:50:42.468460 EDT | StdReturn                   0
2017-07-02 14:50:42.468693 EDT | MaxReturn                1000
2017-07-02 14:50:42.468926 EDT | MinReturn                1000
2017-07-02 14:50:42.469152 EDT | AverageEsReturn            32.1176
2017-07-02 14:50:42.469387 EDT | StdEsReturn                27.737
2017-07-02 14:50:42.469627 EDT | MaxEsReturn               109
2017-07-02 14:50:42.469850 EDT | MinEsReturn                 4
2017-07-02 14:50:42.470075 EDT | AverageDiscountedReturn    99.9957
2017-07-02 14:50:42.470305 EDT | AverageQLoss                0.00846223
2017-07-02 14:50:42.470534 EDT | AveragePolicySurr          -1.48847
2017-07-02 14:50:42.470763 EDT | AverageQ                    1.41695
2017-07-02 14:50:42.470991 EDT | AverageAbsQ                 1.42116
2017-07-02 14:50:42.471219 EDT | AverageY                    1.41702
2017-07-02 14:50:42.471447 EDT | AverageAbsY                 1.41729
2017-07-02 14:50:42.471675 EDT | AverageAbsQYDiff            0.0244419
2017-07-02 14:50:42.471904 EDT | AverageAction               0.739141
2017-07-02 14:50:42.472381 EDT | PolicyRegParamNorm         61.7241
2017-07-02 14:50:42.472608 EDT | QFunRegParamNorm           60.5437
2017-07-02 14:50:42.472830 EDT | -----------------------  -------------
2017-07-02 14:50:42.473225 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #566 | Training started
2017-07-02 14:50:51.809050 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #566 | Training finished
2017-07-02 14:50:51.809601 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #566 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 14:50:51.809844 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #566 | Collecting samples for evaluation
2017-07-02 14:50:57.384454 EDT | -----------------------  -------------
2017-07-02 14:50:57.384732 EDT | Epoch                     566
2017-07-02 14:50:57.385024 EDT | Iteration                 566
2017-07-02 14:50:57.385323 EDT | AverageReturn              85.8462
2017-07-02 14:50:57.385580 EDT | StdReturn                 161.259
2017-07-02 14:50:57.385723 EDT | MaxReturn                1000
2017-07-02 14:50:57.385967 EDT | MinReturn                  43
2017-07-02 14:50:57.386175 EDT | AverageEsReturn            31.4062
2017-07-02 14:50:57.386317 EDT | StdEsReturn                22.8676
2017-07-02 14:50:57.386553 EDT | MaxEsReturn               102
2017-07-02 14:50:57.386773 EDT | MinEsReturn                 3
2017-07-02 14:50:57.386898 EDT | AverageDiscountedReturn    43.9209
2017-07-02 14:50:57.387028 EDT | AverageQLoss                0.00670802
2017-07-02 14:50:57.387209 EDT | AveragePolicySurr          -1.48022
2017-07-02 14:50:57.387362 EDT | AverageQ                    1.40797
2017-07-02 14:50:57.387489 EDT | AverageAbsQ                 1.41122
2017-07-02 14:50:57.387613 EDT | AverageY                    1.408
2017-07-02 14:50:57.387743 EDT | AverageAbsY                 1.40835
2017-07-02 14:50:57.387891 EDT | AverageAbsQYDiff            0.0211232
2017-07-02 14:50:57.388011 EDT | AverageAction               0.759461
2017-07-02 14:50:57.388117 EDT | PolicyRegParamNorm         61.696
2017-07-02 14:50:57.388222 EDT | QFunRegParamNorm           60.585
2017-07-02 14:50:57.388326 EDT | -----------------------  -------------
2017-07-02 14:50:57.388490 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #567 | Training started
2017-07-02 14:51:06.791867 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #567 | Training finished
2017-07-02 14:51:06.792421 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #567 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 14:51:06.792660 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #567 | Collecting samples for evaluation
2017-07-02 14:51:12.564644 EDT | -----------------------  -------------
2017-07-02 14:51:12.564941 EDT | Epoch                     567
2017-07-02 14:51:12.565181 EDT | Iteration                 567
2017-07-02 14:51:12.565382 EDT | AverageReturn             808.462
2017-07-02 14:51:12.565633 EDT | StdReturn                 250.489
2017-07-02 14:51:12.565866 EDT | MaxReturn                1000
2017-07-02 14:51:12.566001 EDT | MinReturn                 204
2017-07-02 14:51:12.566237 EDT | AverageEsReturn            23.3953
2017-07-02 14:51:12.566459 EDT | StdEsReturn                13.1753
2017-07-02 14:51:12.566694 EDT | MaxEsReturn                53
2017-07-02 14:51:12.566925 EDT | MinEsReturn                 3
2017-07-02 14:51:12.567102 EDT | AverageDiscountedReturn    98.8828
2017-07-02 14:51:12.567336 EDT | AverageQLoss                0.00609458
2017-07-02 14:51:12.567533 EDT | AveragePolicySurr          -1.47235
2017-07-02 14:51:12.567747 EDT | AverageQ                    1.4001
2017-07-02 14:51:12.567979 EDT | AverageAbsQ                 1.40374
2017-07-02 14:51:12.568114 EDT | AverageY                    1.40004
2017-07-02 14:51:12.568219 EDT | AverageAbsY                 1.4004
2017-07-02 14:51:12.568321 EDT | AverageAbsQYDiff            0.0211436
2017-07-02 14:51:12.568427 EDT | AverageAction               0.810276
2017-07-02 14:51:12.568602 EDT | PolicyRegParamNorm         61.7181
2017-07-02 14:51:12.568836 EDT | QFunRegParamNorm           60.5949
2017-07-02 14:51:12.569035 EDT | -----------------------  -------------
2017-07-02 14:51:12.569358 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #568 | Training started
2017-07-02 14:51:21.942008 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #568 | Training finished
2017-07-02 14:51:21.945922 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #568 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 14:51:21.946144 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #568 | Collecting samples for evaluation
2017-07-02 14:51:27.783624 EDT | -----------------------  ------------
2017-07-02 14:51:27.783815 EDT | Epoch                     568
2017-07-02 14:51:27.783929 EDT | Iteration                 568
2017-07-02 14:51:27.784047 EDT | AverageReturn             626.294
2017-07-02 14:51:27.784197 EDT | StdReturn                 280.705
2017-07-02 14:51:27.784300 EDT | MaxReturn                1000
2017-07-02 14:51:27.784402 EDT | MinReturn                 217
2017-07-02 14:51:27.784519 EDT | AverageEsReturn            26.2632
2017-07-02 14:51:27.784673 EDT | StdEsReturn                18.0506
2017-07-02 14:51:27.784777 EDT | MaxEsReturn                72
2017-07-02 14:51:27.784877 EDT | MinEsReturn                 3
2017-07-02 14:51:27.784977 EDT | AverageDiscountedReturn    98.0016
2017-07-02 14:51:27.785111 EDT | AverageQLoss                0.0063166
2017-07-02 14:51:27.785340 EDT | AveragePolicySurr          -1.4747
2017-07-02 14:51:27.785583 EDT | AverageQ                    1.40732
2017-07-02 14:51:27.785805 EDT | AverageAbsQ                 1.4107
2017-07-02 14:51:27.786032 EDT | AverageY                    1.40737
2017-07-02 14:51:27.786232 EDT | AverageAbsY                 1.40756
2017-07-02 14:51:27.786460 EDT | AverageAbsQYDiff            0.0213937
2017-07-02 14:51:27.786648 EDT | AverageAction               0.778273
2017-07-02 14:51:27.786878 EDT | PolicyRegParamNorm         61.7425
2017-07-02 14:51:27.787090 EDT | QFunRegParamNorm           60.6113
2017-07-02 14:51:27.787305 EDT | -----------------------  ------------
2017-07-02 14:51:27.787598 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #569 | Training started
2017-07-02 14:51:37.171015 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #569 | Training finished
2017-07-02 14:51:37.171606 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #569 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 14:51:37.171837 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #569 | Collecting samples for evaluation
2017-07-02 14:51:42.910962 EDT | -----------------------  -------------
2017-07-02 14:51:42.911269 EDT | Epoch                     569
2017-07-02 14:51:42.911385 EDT | Iteration                 569
2017-07-02 14:51:42.911503 EDT | AverageReturn             873.667
2017-07-02 14:51:42.911730 EDT | StdReturn                 282.721
2017-07-02 14:51:42.911952 EDT | MaxReturn                1000
2017-07-02 14:51:42.912178 EDT | MinReturn                 214
2017-07-02 14:51:42.912375 EDT | AverageEsReturn            23.0714
2017-07-02 14:51:42.912611 EDT | StdEsReturn                17.0816
2017-07-02 14:51:42.912841 EDT | MaxEsReturn                88
2017-07-02 14:51:42.913067 EDT | MinEsReturn                 5
2017-07-02 14:51:42.913281 EDT | AverageDiscountedReturn    98.474
2017-07-02 14:51:42.913486 EDT | AverageQLoss                0.00705257
2017-07-02 14:51:42.914046 EDT | AveragePolicySurr          -1.46391
2017-07-02 14:51:42.914272 EDT | AverageQ                    1.39569
2017-07-02 14:51:42.914459 EDT | AverageAbsQ                 1.39952
2017-07-02 14:51:42.914685 EDT | AverageY                    1.3957
2017-07-02 14:51:42.914893 EDT | AverageAbsY                 1.3959
2017-07-02 14:51:42.915036 EDT | AverageAbsQYDiff            0.0226222
2017-07-02 14:51:42.915166 EDT | AverageAction               0.787334
2017-07-02 14:51:42.915269 EDT | PolicyRegParamNorm         61.7556
2017-07-02 14:51:42.915370 EDT | QFunRegParamNorm           60.6489
2017-07-02 14:51:42.915469 EDT | -----------------------  -------------
2017-07-02 14:51:42.915667 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #570 | Training started
2017-07-02 14:51:52.301684 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #570 | Training finished
2017-07-02 14:51:52.302272 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #570 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 14:51:52.302515 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #570 | Collecting samples for evaluation
2017-07-02 14:51:57.694703 EDT | -----------------------  -------------
2017-07-02 14:51:57.695021 EDT | Epoch                     570
2017-07-02 14:51:57.695258 EDT | Iteration                 570
2017-07-02 14:51:57.695489 EDT | AverageReturn            1000
2017-07-02 14:51:57.695712 EDT | StdReturn                   0
2017-07-02 14:51:57.695939 EDT | MaxReturn                1000
2017-07-02 14:51:57.696145 EDT | MinReturn                1000
2017-07-02 14:51:57.696378 EDT | AverageEsReturn            30.3824
2017-07-02 14:51:57.696602 EDT | StdEsReturn                20.1917
2017-07-02 14:51:57.696822 EDT | MaxEsReturn                75
2017-07-02 14:51:57.697039 EDT | MinEsReturn                 3
2017-07-02 14:51:57.697241 EDT | AverageDiscountedReturn    99.9957
2017-07-02 14:51:57.697463 EDT | AverageQLoss                0.00634826
2017-07-02 14:51:57.697799 EDT | AveragePolicySurr          -1.46143
2017-07-02 14:51:57.697907 EDT | AverageQ                    1.39095
2017-07-02 14:51:57.698107 EDT | AverageAbsQ                 1.39512
2017-07-02 14:51:57.698279 EDT | AverageY                    1.39096
2017-07-02 14:51:57.698387 EDT | AverageAbsY                 1.39109
2017-07-02 14:51:57.698598 EDT | AverageAbsQYDiff            0.0215762
2017-07-02 14:51:57.698811 EDT | AverageAction               0.86305
2017-07-02 14:51:57.699006 EDT | PolicyRegParamNorm         61.7534
2017-07-02 14:51:57.699125 EDT | QFunRegParamNorm           60.6482
2017-07-02 14:51:57.699228 EDT | -----------------------  -------------
2017-07-02 14:51:57.699495 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #571 | Training started
2017-07-02 14:52:07.123263 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #571 | Training finished
2017-07-02 14:52:07.123792 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #571 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 14:52:07.124006 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #571 | Collecting samples for evaluation
2017-07-02 14:52:12.600065 EDT | -----------------------  ------------
2017-07-02 14:52:12.600365 EDT | Epoch                     571
2017-07-02 14:52:12.600596 EDT | Iteration                 571
2017-07-02 14:52:12.600730 EDT | AverageReturn            1000
2017-07-02 14:52:12.600833 EDT | StdReturn                   0
2017-07-02 14:52:12.600944 EDT | MaxReturn                1000
2017-07-02 14:52:12.601050 EDT | MinReturn                1000
2017-07-02 14:52:12.601150 EDT | AverageEsReturn            49.5789
2017-07-02 14:52:12.601250 EDT | StdEsReturn                36.5763
2017-07-02 14:52:12.601349 EDT | MaxEsReturn               143
2017-07-02 14:52:12.601447 EDT | MinEsReturn                 4
2017-07-02 14:52:12.601588 EDT | AverageDiscountedReturn    99.9957
2017-07-02 14:52:12.601690 EDT | AverageQLoss                0.0070153
2017-07-02 14:52:12.601788 EDT | AveragePolicySurr          -1.45202
2017-07-02 14:52:12.601937 EDT | AverageQ                    1.38052
2017-07-02 14:52:12.602062 EDT | AverageAbsQ                 1.38509
2017-07-02 14:52:12.602168 EDT | AverageY                    1.38049
2017-07-02 14:52:12.602272 EDT | AverageAbsY                 1.38069
2017-07-02 14:52:12.602453 EDT | AverageAbsQYDiff            0.0232114
2017-07-02 14:52:12.602595 EDT | AverageAction               0.770161
2017-07-02 14:52:12.602776 EDT | PolicyRegParamNorm         61.7512
2017-07-02 14:52:12.602912 EDT | QFunRegParamNorm           60.6775
2017-07-02 14:52:12.603095 EDT | -----------------------  ------------
2017-07-02 14:52:12.603376 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #572 | Training started
2017-07-02 14:52:22.101666 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #572 | Training finished
2017-07-02 14:52:22.102462 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #572 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 14:52:22.102689 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #572 | Collecting samples for evaluation
2017-07-02 14:52:27.894811 EDT | -----------------------  ------------
2017-07-02 14:52:27.895029 EDT | Epoch                     572
2017-07-02 14:52:27.895197 EDT | Iteration                 572
2017-07-02 14:52:27.895304 EDT | AverageReturn             531.8
2017-07-02 14:52:27.895406 EDT | StdReturn                 409.676
2017-07-02 14:52:27.895510 EDT | MaxReturn                1000
2017-07-02 14:52:27.895698 EDT | MinReturn                  37
2017-07-02 14:52:27.895854 EDT | AverageEsReturn            29.4444
2017-07-02 14:52:27.895958 EDT | StdEsReturn                20.6713
2017-07-02 14:52:27.896058 EDT | MaxEsReturn                81
2017-07-02 14:52:27.896335 EDT | MinEsReturn                 3
2017-07-02 14:52:27.896457 EDT | AverageDiscountedReturn    81.9694
2017-07-02 14:52:27.896589 EDT | AverageQLoss                0.0068958
2017-07-02 14:52:27.896726 EDT | AveragePolicySurr          -1.45084
2017-07-02 14:52:27.896839 EDT | AverageQ                    1.38099
2017-07-02 14:52:27.897035 EDT | AverageAbsQ                 1.38461
2017-07-02 14:52:27.897140 EDT | AverageY                    1.38086
2017-07-02 14:52:27.897275 EDT | AverageAbsY                 1.3811
2017-07-02 14:52:27.897401 EDT | AverageAbsQYDiff            0.0230778
2017-07-02 14:52:27.897535 EDT | AverageAction               0.798345
2017-07-02 14:52:27.897695 EDT | PolicyRegParamNorm         61.8133
2017-07-02 14:52:27.897919 EDT | QFunRegParamNorm           60.7077
2017-07-02 14:52:27.898143 EDT | -----------------------  ------------
2017-07-02 14:52:27.898341 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #573 | Training started
2017-07-02 14:52:37.190766 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #573 | Training finished
2017-07-02 14:52:37.191261 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #573 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 14:52:37.191523 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #573 | Collecting samples for evaluation
2017-07-02 14:52:42.718758 EDT | -----------------------  -------------
2017-07-02 14:52:42.719007 EDT | Epoch                     573
2017-07-02 14:52:42.719131 EDT | Iteration                 573
2017-07-02 14:52:42.719293 EDT | AverageReturn            1000
2017-07-02 14:52:42.719453 EDT | StdReturn                   0
2017-07-02 14:52:42.719591 EDT | MaxReturn                1000
2017-07-02 14:52:42.719734 EDT | MinReturn                1000
2017-07-02 14:52:42.719836 EDT | AverageEsReturn            29.3235
2017-07-02 14:52:42.719952 EDT | StdEsReturn                25.634
2017-07-02 14:52:42.720134 EDT | MaxEsReturn               109
2017-07-02 14:52:42.720255 EDT | MinEsReturn                 4
2017-07-02 14:52:42.720382 EDT | AverageDiscountedReturn    99.9957
2017-07-02 14:52:42.720502 EDT | AverageQLoss                0.00591995
2017-07-02 14:52:42.720643 EDT | AveragePolicySurr          -1.44445
2017-07-02 14:52:42.720759 EDT | AverageQ                    1.37835
2017-07-02 14:52:42.720871 EDT | AverageAbsQ                 1.382
2017-07-02 14:52:42.720981 EDT | AverageY                    1.37827
2017-07-02 14:52:42.721113 EDT | AverageAbsY                 1.3786
2017-07-02 14:52:42.721298 EDT | AverageAbsQYDiff            0.0207456
2017-07-02 14:52:42.721408 EDT | AverageAction               0.702613
2017-07-02 14:52:42.721674 EDT | PolicyRegParamNorm         61.8506
2017-07-02 14:52:42.721853 EDT | QFunRegParamNorm           60.7296
2017-07-02 14:52:42.721986 EDT | -----------------------  -------------
2017-07-02 14:52:42.722147 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #574 | Training started
2017-07-02 14:52:51.902940 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #574 | Training finished
2017-07-02 14:52:51.903597 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #574 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 14:52:51.903854 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #574 | Collecting samples for evaluation
2017-07-02 14:52:57.593514 EDT | -----------------------  -------------
2017-07-02 14:52:57.593750 EDT | Epoch                     574
2017-07-02 14:52:57.593869 EDT | Iteration                 574
2017-07-02 14:52:57.593975 EDT | AverageReturn            1000
2017-07-02 14:52:57.594084 EDT | StdReturn                   0
2017-07-02 14:52:57.594284 EDT | MaxReturn                1000
2017-07-02 14:52:57.594483 EDT | MinReturn                1000
2017-07-02 14:52:57.594652 EDT | AverageEsReturn            37.1852
2017-07-02 14:52:57.594780 EDT | StdEsReturn                34.6849
2017-07-02 14:52:57.594928 EDT | MaxEsReturn               185
2017-07-02 14:52:57.595049 EDT | MinEsReturn                 6
2017-07-02 14:52:57.595150 EDT | AverageDiscountedReturn    99.9957
2017-07-02 14:52:57.595266 EDT | AverageQLoss                0.00649469
2017-07-02 14:52:57.595432 EDT | AveragePolicySurr          -1.43665
2017-07-02 14:52:57.595538 EDT | AverageQ                    1.371
2017-07-02 14:52:57.595665 EDT | AverageAbsQ                 1.37483
2017-07-02 14:52:57.595779 EDT | AverageY                    1.37095
2017-07-02 14:52:57.595968 EDT | AverageAbsY                 1.3714
2017-07-02 14:52:57.596158 EDT | AverageAbsQYDiff            0.0221022
2017-07-02 14:52:57.596340 EDT | AverageAction               0.678918
2017-07-02 14:52:57.596520 EDT | PolicyRegParamNorm         61.84
2017-07-02 14:52:57.596646 EDT | QFunRegParamNorm           60.765
2017-07-02 14:52:57.596765 EDT | -----------------------  -------------
2017-07-02 14:52:57.596940 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #575 | Training started
2017-07-02 14:53:06.745532 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #575 | Training finished
2017-07-02 14:53:06.746160 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #575 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 14:53:06.746395 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #575 | Collecting samples for evaluation
2017-07-02 14:53:12.325563 EDT | -----------------------  -------------
2017-07-02 14:53:12.325874 EDT | Epoch                     575
2017-07-02 14:53:12.326065 EDT | Iteration                 575
2017-07-02 14:53:12.326179 EDT | AverageReturn            1000
2017-07-02 14:53:12.326368 EDT | StdReturn                   0
2017-07-02 14:53:12.326598 EDT | MaxReturn                1000
2017-07-02 14:53:12.326779 EDT | MinReturn                1000
2017-07-02 14:53:12.326999 EDT | AverageEsReturn            46.4762
2017-07-02 14:53:12.327226 EDT | StdEsReturn                36.4739
2017-07-02 14:53:12.327398 EDT | MaxEsReturn               109
2017-07-02 14:53:12.327626 EDT | MinEsReturn                 3
2017-07-02 14:53:12.327841 EDT | AverageDiscountedReturn    99.9957
2017-07-02 14:53:12.328072 EDT | AverageQLoss                0.00667157
2017-07-02 14:53:12.328295 EDT | AveragePolicySurr          -1.43409
2017-07-02 14:53:12.328518 EDT | AverageQ                    1.36753
2017-07-02 14:53:12.328753 EDT | AverageAbsQ                 1.37101
2017-07-02 14:53:12.328931 EDT | AverageY                    1.36741
2017-07-02 14:53:12.329159 EDT | AverageAbsY                 1.36773
2017-07-02 14:53:12.329330 EDT | AverageAbsQYDiff            0.0227468
2017-07-02 14:53:12.329747 EDT | AverageAction               0.723187
2017-07-02 14:53:12.329933 EDT | PolicyRegParamNorm         61.8491
2017-07-02 14:53:12.330162 EDT | QFunRegParamNorm           60.7746
2017-07-02 14:53:12.330346 EDT | -----------------------  -------------
2017-07-02 14:53:12.330674 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #576 | Training started
2017-07-02 14:53:21.586828 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #576 | Training finished
2017-07-02 14:53:21.587347 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #576 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 14:53:21.587522 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #576 | Collecting samples for evaluation
2017-07-02 14:53:27.089769 EDT | -----------------------  -------------
2017-07-02 14:53:27.089958 EDT | Epoch                     576
2017-07-02 14:53:27.090070 EDT | Iteration                 576
2017-07-02 14:53:27.090175 EDT | AverageReturn            1000
2017-07-02 14:53:27.090278 EDT | StdReturn                   0
2017-07-02 14:53:27.090379 EDT | MaxReturn                1000
2017-07-02 14:53:27.090530 EDT | MinReturn                1000
2017-07-02 14:53:27.090634 EDT | AverageEsReturn            37.0741
2017-07-02 14:53:27.090735 EDT | StdEsReturn                34.2982
2017-07-02 14:53:27.090836 EDT | MaxEsReturn               151
2017-07-02 14:53:27.090989 EDT | MinEsReturn                 3
2017-07-02 14:53:27.091091 EDT | AverageDiscountedReturn    99.9957
2017-07-02 14:53:27.091191 EDT | AverageQLoss                0.00730091
2017-07-02 14:53:27.091291 EDT | AveragePolicySurr          -1.42616
2017-07-02 14:53:27.091415 EDT | AverageQ                    1.36012
2017-07-02 14:53:27.091570 EDT | AverageAbsQ                 1.36425
2017-07-02 14:53:27.091672 EDT | AverageY                    1.36009
2017-07-02 14:53:27.091773 EDT | AverageAbsY                 1.36031
2017-07-02 14:53:27.091873 EDT | AverageAbsQYDiff            0.0229982
2017-07-02 14:53:27.092008 EDT | AverageAction               0.892896
2017-07-02 14:53:27.092109 EDT | PolicyRegParamNorm         61.9176
2017-07-02 14:53:27.092208 EDT | QFunRegParamNorm           60.7994
2017-07-02 14:53:27.092305 EDT | -----------------------  -------------
2017-07-02 14:53:27.092463 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #577 | Training started
2017-07-02 14:53:36.434470 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #577 | Training finished
2017-07-02 14:53:36.435085 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #577 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 14:53:36.435233 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #577 | Collecting samples for evaluation
2017-07-02 14:53:41.910309 EDT | -----------------------  -------------
2017-07-02 14:53:41.910630 EDT | Epoch                     577
2017-07-02 14:53:41.910857 EDT | Iteration                 577
2017-07-02 14:53:41.911159 EDT | AverageReturn            1000
2017-07-02 14:53:41.911381 EDT | StdReturn                   0
2017-07-02 14:53:41.911600 EDT | MaxReturn                1000
2017-07-02 14:53:41.911812 EDT | MinReturn                1000
2017-07-02 14:53:41.912047 EDT | AverageEsReturn            39.28
2017-07-02 14:53:41.912265 EDT | StdEsReturn                27.239
2017-07-02 14:53:41.912494 EDT | MaxEsReturn               120
2017-07-02 14:53:41.912711 EDT | MinEsReturn                 4
2017-07-02 14:53:41.912922 EDT | AverageDiscountedReturn    99.9957
2017-07-02 14:53:41.913144 EDT | AverageQLoss                0.00608937
2017-07-02 14:53:41.913363 EDT | AveragePolicySurr          -1.42336
2017-07-02 14:53:41.913588 EDT | AverageQ                    1.35517
2017-07-02 14:53:41.913774 EDT | AverageAbsQ                 1.35885
2017-07-02 14:53:41.913880 EDT | AverageY                    1.35526
2017-07-02 14:53:41.913982 EDT | AverageAbsY                 1.35541
2017-07-02 14:53:41.914098 EDT | AverageAbsQYDiff            0.0219207
2017-07-02 14:53:41.914315 EDT | AverageAction               0.831615
2017-07-02 14:53:41.914526 EDT | PolicyRegParamNorm         61.9217
2017-07-02 14:53:41.914750 EDT | QFunRegParamNorm           60.8311
2017-07-02 14:53:41.914968 EDT | -----------------------  -------------
2017-07-02 14:53:41.915173 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #578 | Training started
2017-07-02 14:53:51.215505 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #578 | Training finished
2017-07-02 14:53:51.216327 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #578 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 14:53:51.216582 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #578 | Collecting samples for evaluation
2017-07-02 14:53:56.811344 EDT | -----------------------  -------------
2017-07-02 14:53:56.811560 EDT | Epoch                     578
2017-07-02 14:53:56.811676 EDT | Iteration                 578
2017-07-02 14:53:56.811791 EDT | AverageReturn            1000
2017-07-02 14:53:56.811935 EDT | StdReturn                   0
2017-07-02 14:53:56.812085 EDT | MaxReturn                1000
2017-07-02 14:53:56.812217 EDT | MinReturn                1000
2017-07-02 14:53:56.812373 EDT | AverageEsReturn            35.5556
2017-07-02 14:53:56.812541 EDT | StdEsReturn                33.9916
2017-07-02 14:53:56.812668 EDT | MaxEsReturn               154
2017-07-02 14:53:56.812807 EDT | MinEsReturn                 4
2017-07-02 14:53:56.812933 EDT | AverageDiscountedReturn    99.9957
2017-07-02 14:53:56.813069 EDT | AverageQLoss                0.00622935
2017-07-02 14:53:56.813192 EDT | AveragePolicySurr          -1.41716
2017-07-02 14:53:56.813324 EDT | AverageQ                    1.34818
2017-07-02 14:53:56.813424 EDT | AverageAbsQ                 1.3512
2017-07-02 14:53:56.813538 EDT | AverageY                    1.34803
2017-07-02 14:53:56.813651 EDT | AverageAbsY                 1.34823
2017-07-02 14:53:56.813781 EDT | AverageAbsQYDiff            0.0205089
2017-07-02 14:53:56.813938 EDT | AverageAction               0.805602
2017-07-02 14:53:56.814079 EDT | PolicyRegParamNorm         61.9125
2017-07-02 14:53:56.814190 EDT | QFunRegParamNorm           60.848
2017-07-02 14:53:56.814313 EDT | -----------------------  -------------
2017-07-02 14:53:56.814554 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #579 | Training started
2017-07-02 14:54:06.132929 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #579 | Training finished
2017-07-02 14:54:06.133589 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #579 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 14:54:06.133961 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #579 | Collecting samples for evaluation
2017-07-02 14:54:11.643572 EDT | -----------------------  -------------
2017-07-02 14:54:11.643808 EDT | Epoch                     579
2017-07-02 14:54:11.643937 EDT | Iteration                 579
2017-07-02 14:54:11.644052 EDT | AverageReturn            1000
2017-07-02 14:54:11.644160 EDT | StdReturn                   0
2017-07-02 14:54:11.644263 EDT | MaxReturn                1000
2017-07-02 14:54:11.644369 EDT | MinReturn                1000
2017-07-02 14:54:11.644478 EDT | AverageEsReturn            36.8276
2017-07-02 14:54:11.644637 EDT | StdEsReturn                29.9587
2017-07-02 14:54:11.644745 EDT | MaxEsReturn               119
2017-07-02 14:54:11.644847 EDT | MinEsReturn                 8
2017-07-02 14:54:11.644947 EDT | AverageDiscountedReturn    99.9957
2017-07-02 14:54:11.645046 EDT | AverageQLoss                0.00663644
2017-07-02 14:54:11.645189 EDT | AveragePolicySurr          -1.41511
2017-07-02 14:54:11.645299 EDT | AverageQ                    1.34636
2017-07-02 14:54:11.645416 EDT | AverageAbsQ                 1.35049
2017-07-02 14:54:11.645541 EDT | AverageY                    1.34643
2017-07-02 14:54:11.645695 EDT | AverageAbsY                 1.34669
2017-07-02 14:54:11.645814 EDT | AverageAbsQYDiff            0.022073
2017-07-02 14:54:11.645914 EDT | AverageAction               0.872379
2017-07-02 14:54:11.646041 EDT | PolicyRegParamNorm         61.9846
2017-07-02 14:54:11.646165 EDT | QFunRegParamNorm           60.8895
2017-07-02 14:54:11.646266 EDT | -----------------------  -------------
2017-07-02 14:54:11.646427 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #580 | Training started
2017-07-02 14:54:20.891443 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #580 | Training finished
2017-07-02 14:54:20.892049 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #580 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 14:54:20.892227 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #580 | Collecting samples for evaluation
2017-07-02 14:54:26.393619 EDT | -----------------------  -------------
2017-07-02 14:54:26.393861 EDT | Epoch                     580
2017-07-02 14:54:26.393975 EDT | Iteration                 580
2017-07-02 14:54:26.394080 EDT | AverageReturn            1000
2017-07-02 14:54:26.394235 EDT | StdReturn                   0
2017-07-02 14:54:26.394338 EDT | MaxReturn                1000
2017-07-02 14:54:26.394454 EDT | MinReturn                1000
2017-07-02 14:54:26.394558 EDT | AverageEsReturn            50.25
2017-07-02 14:54:26.394699 EDT | StdEsReturn                45.7863
2017-07-02 14:54:26.394801 EDT | MaxEsReturn               201
2017-07-02 14:54:26.394972 EDT | MinEsReturn                 3
2017-07-02 14:54:26.395160 EDT | AverageDiscountedReturn    99.9957
2017-07-02 14:54:26.395340 EDT | AverageQLoss                0.00809997
2017-07-02 14:54:26.395449 EDT | AveragePolicySurr          -1.40837
2017-07-02 14:54:26.395630 EDT | AverageQ                    1.33801
2017-07-02 14:54:26.395755 EDT | AverageAbsQ                 1.34178
2017-07-02 14:54:26.395913 EDT | AverageY                    1.33812
2017-07-02 14:54:26.396110 EDT | AverageAbsY                 1.33824
2017-07-02 14:54:26.396216 EDT | AverageAbsQYDiff            0.0242052
2017-07-02 14:54:26.396314 EDT | AverageAction               0.91254
2017-07-02 14:54:26.396413 EDT | PolicyRegParamNorm         61.9926
2017-07-02 14:54:26.396516 EDT | QFunRegParamNorm           60.9332
2017-07-02 14:54:26.396677 EDT | -----------------------  -------------
2017-07-02 14:54:26.396841 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #581 | Training started
2017-07-02 14:54:35.699751 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #581 | Training finished
2017-07-02 14:54:35.700323 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #581 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 14:54:35.700504 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #581 | Collecting samples for evaluation
2017-07-02 14:54:41.335007 EDT | -----------------------  -------------
2017-07-02 14:54:41.335330 EDT | Epoch                     581
2017-07-02 14:54:41.335531 EDT | Iteration                 581
2017-07-02 14:54:41.335765 EDT | AverageReturn            1000
2017-07-02 14:54:41.335949 EDT | StdReturn                   0
2017-07-02 14:54:41.336147 EDT | MaxReturn                1000
2017-07-02 14:54:41.336379 EDT | MinReturn                1000
2017-07-02 14:54:41.336557 EDT | AverageEsReturn            36.3333
2017-07-02 14:54:41.336693 EDT | StdEsReturn                30.2875
2017-07-02 14:54:41.336923 EDT | MaxEsReturn               109
2017-07-02 14:54:41.337135 EDT | MinEsReturn                 8
2017-07-02 14:54:41.337325 EDT | AverageDiscountedReturn    99.9957
2017-07-02 14:54:41.337453 EDT | AverageQLoss                0.00652961
2017-07-02 14:54:41.337704 EDT | AveragePolicySurr          -1.40353
2017-07-02 14:54:41.337910 EDT | AverageQ                    1.3354
2017-07-02 14:54:41.338095 EDT | AverageAbsQ                 1.3384
2017-07-02 14:54:41.338325 EDT | AverageY                    1.33542
2017-07-02 14:54:41.338482 EDT | AverageAbsY                 1.33548
2017-07-02 14:54:41.338676 EDT | AverageAbsQYDiff            0.0210876
2017-07-02 14:54:41.338903 EDT | AverageAction               0.898948
2017-07-02 14:54:41.339078 EDT | PolicyRegParamNorm         62.0431
2017-07-02 14:54:41.339307 EDT | QFunRegParamNorm           60.9449
2017-07-02 14:54:41.339509 EDT | -----------------------  -------------
2017-07-02 14:54:41.339829 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #582 | Training started
2017-07-02 14:54:50.669936 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #582 | Training finished
2017-07-02 14:54:50.670665 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #582 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 14:54:50.670988 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #582 | Collecting samples for evaluation
2017-07-02 14:54:56.125888 EDT | -----------------------  -------------
2017-07-02 14:54:56.126320 EDT | Epoch                     582
2017-07-02 14:54:56.126504 EDT | Iteration                 582
2017-07-02 14:54:56.126696 EDT | AverageReturn            1000
2017-07-02 14:54:56.126802 EDT | StdReturn                   0
2017-07-02 14:54:56.126904 EDT | MaxReturn                1000
2017-07-02 14:54:56.127068 EDT | MinReturn                1000
2017-07-02 14:54:56.127171 EDT | AverageEsReturn            54.7778
2017-07-02 14:54:56.127324 EDT | StdEsReturn                52.3721
2017-07-02 14:54:56.127432 EDT | MaxEsReturn               196
2017-07-02 14:54:56.127532 EDT | MinEsReturn                 4
2017-07-02 14:54:56.127633 EDT | AverageDiscountedReturn    99.9957
2017-07-02 14:54:56.127792 EDT | AverageQLoss                0.00774232
2017-07-02 14:54:56.127898 EDT | AveragePolicySurr          -1.39935
2017-07-02 14:54:56.128038 EDT | AverageQ                    1.33405
2017-07-02 14:54:56.128141 EDT | AverageAbsQ                 1.33786
2017-07-02 14:54:56.128298 EDT | AverageY                    1.33397
2017-07-02 14:54:56.128444 EDT | AverageAbsY                 1.334
2017-07-02 14:54:56.128546 EDT | AverageAbsQYDiff            0.0240833
2017-07-02 14:54:56.128648 EDT | AverageAction               0.851149
2017-07-02 14:54:56.128749 EDT | PolicyRegParamNorm         62.0976
2017-07-02 14:54:56.128907 EDT | QFunRegParamNorm           60.9596
2017-07-02 14:54:56.129014 EDT | -----------------------  -------------
2017-07-02 14:54:56.129192 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #583 | Training started
2017-07-02 14:55:05.471673 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #583 | Training finished
2017-07-02 14:55:05.472326 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #583 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 14:55:05.472500 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #583 | Collecting samples for evaluation
2017-07-02 14:55:10.968956 EDT | -----------------------  -------------
2017-07-02 14:55:10.969212 EDT | Epoch                     583
2017-07-02 14:55:10.969415 EDT | Iteration                 583
2017-07-02 14:55:10.969617 EDT | AverageReturn            1000
2017-07-02 14:55:10.969725 EDT | StdReturn                   0
2017-07-02 14:55:10.969837 EDT | MaxReturn                1000
2017-07-02 14:55:10.969944 EDT | MinReturn                1000
2017-07-02 14:55:10.970055 EDT | AverageEsReturn            49.35
2017-07-02 14:55:10.970235 EDT | StdEsReturn                34.9017
2017-07-02 14:55:10.970365 EDT | MaxEsReturn               122
2017-07-02 14:55:10.970466 EDT | MinEsReturn                10
2017-07-02 14:55:10.970684 EDT | AverageDiscountedReturn    99.9957
2017-07-02 14:55:10.970923 EDT | AverageQLoss                0.00687079
2017-07-02 14:55:10.971151 EDT | AveragePolicySurr          -1.3928
2017-07-02 14:55:10.971378 EDT | AverageQ                    1.32574
2017-07-02 14:55:10.971577 EDT | AverageAbsQ                 1.3293
2017-07-02 14:55:10.971699 EDT | AverageY                    1.32585
2017-07-02 14:55:10.971802 EDT | AverageAbsY                 1.32593
2017-07-02 14:55:10.971912 EDT | AverageAbsQYDiff            0.0223452
2017-07-02 14:55:10.972030 EDT | AverageAction               0.876039
2017-07-02 14:55:10.972130 EDT | PolicyRegParamNorm         62.1284
2017-07-02 14:55:10.972227 EDT | QFunRegParamNorm           60.9934
2017-07-02 14:55:10.972424 EDT | -----------------------  -------------
2017-07-02 14:55:10.972689 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #584 | Training started
2017-07-02 14:55:20.662486 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #584 | Training finished
2017-07-02 14:55:20.663099 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #584 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 14:55:20.663346 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #584 | Collecting samples for evaluation
2017-07-02 14:55:26.364994 EDT | -----------------------  -------------
2017-07-02 14:55:26.365185 EDT | Epoch                     584
2017-07-02 14:55:26.365330 EDT | Iteration                 584
2017-07-02 14:55:26.365441 EDT | AverageReturn            1000
2017-07-02 14:55:26.365565 EDT | StdReturn                   0
2017-07-02 14:55:26.365694 EDT | MaxReturn                1000
2017-07-02 14:55:26.365806 EDT | MinReturn                1000
2017-07-02 14:55:26.365975 EDT | AverageEsReturn            37.9259
2017-07-02 14:55:26.366136 EDT | StdEsReturn                32.3647
2017-07-02 14:55:26.366323 EDT | MaxEsReturn               165
2017-07-02 14:55:26.366450 EDT | MinEsReturn                 4
2017-07-02 14:55:26.366642 EDT | AverageDiscountedReturn    99.9957
2017-07-02 14:55:26.366833 EDT | AverageQLoss                0.00621102
2017-07-02 14:55:26.367018 EDT | AveragePolicySurr          -1.38666
2017-07-02 14:55:26.367126 EDT | AverageQ                    1.32214
2017-07-02 14:55:26.367256 EDT | AverageAbsQ                 1.32593
2017-07-02 14:55:26.367408 EDT | AverageY                    1.32212
2017-07-02 14:55:26.367576 EDT | AverageAbsY                 1.32217
2017-07-02 14:55:26.367679 EDT | AverageAbsQYDiff            0.0214499
2017-07-02 14:55:26.367817 EDT | AverageAction               0.918409
2017-07-02 14:55:26.367933 EDT | PolicyRegParamNorm         62.1205
2017-07-02 14:55:26.368034 EDT | QFunRegParamNorm           61.0122
2017-07-02 14:55:26.368169 EDT | -----------------------  -------------
2017-07-02 14:55:26.368376 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #585 | Training started
2017-07-02 14:55:35.795288 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #585 | Training finished
2017-07-02 14:55:35.795964 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #585 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 14:55:35.796210 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #585 | Collecting samples for evaluation
2017-07-02 14:55:41.276783 EDT | -----------------------  -------------
2017-07-02 14:55:41.276985 EDT | Epoch                     585
2017-07-02 14:55:41.277097 EDT | Iteration                 585
2017-07-02 14:55:41.277222 EDT | AverageReturn            1000
2017-07-02 14:55:41.277406 EDT | StdReturn                   0
2017-07-02 14:55:41.277578 EDT | MaxReturn                1000
2017-07-02 14:55:41.277770 EDT | MinReturn                1000
2017-07-02 14:55:41.277961 EDT | AverageEsReturn            28.5833
2017-07-02 14:55:41.278124 EDT | StdEsReturn                24.8007
2017-07-02 14:55:41.278304 EDT | MaxEsReturn                94
2017-07-02 14:55:41.278447 EDT | MinEsReturn                 3
2017-07-02 14:55:41.278623 EDT | AverageDiscountedReturn    99.9957
2017-07-02 14:55:41.278840 EDT | AverageQLoss                0.00621777
2017-07-02 14:55:41.278971 EDT | AveragePolicySurr          -1.38506
2017-07-02 14:55:41.279126 EDT | AverageQ                    1.32036
2017-07-02 14:55:41.279248 EDT | AverageAbsQ                 1.32361
2017-07-02 14:55:41.279348 EDT | AverageY                    1.32039
2017-07-02 14:55:41.279448 EDT | AverageAbsY                 1.32047
2017-07-02 14:55:41.279547 EDT | AverageAbsQYDiff            0.0206445
2017-07-02 14:55:41.279645 EDT | AverageAction               0.90418
2017-07-02 14:55:41.279802 EDT | PolicyRegParamNorm         62.1581
2017-07-02 14:55:41.279985 EDT | QFunRegParamNorm           61.0458
2017-07-02 14:55:41.280108 EDT | -----------------------  -------------
2017-07-02 14:55:41.280313 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #586 | Training started
2017-07-02 14:55:50.787842 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #586 | Training finished
2017-07-02 14:55:50.788393 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #586 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 14:55:50.788635 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #586 | Collecting samples for evaluation
2017-07-02 14:55:56.230582 EDT | -----------------------  -------------
2017-07-02 14:55:56.230870 EDT | Epoch                     586
2017-07-02 14:55:56.231089 EDT | Iteration                 586
2017-07-02 14:55:56.231284 EDT | AverageReturn            1000
2017-07-02 14:55:56.231514 EDT | StdReturn                   0
2017-07-02 14:55:56.231735 EDT | MaxReturn                1000
2017-07-02 14:55:56.231950 EDT | MinReturn                1000
2017-07-02 14:55:56.232129 EDT | AverageEsReturn            28.3143
2017-07-02 14:55:56.232348 EDT | StdEsReturn                27.0626
2017-07-02 14:55:56.232546 EDT | MaxEsReturn               101
2017-07-02 14:55:56.232776 EDT | MinEsReturn                 3
2017-07-02 14:55:56.232994 EDT | AverageDiscountedReturn    99.9957
2017-07-02 14:55:56.233212 EDT | AverageQLoss                0.00624473
2017-07-02 14:55:56.233374 EDT | AveragePolicySurr          -1.38224
2017-07-02 14:55:56.233597 EDT | AverageQ                    1.31746
2017-07-02 14:55:56.233789 EDT | AverageAbsQ                 1.32041
2017-07-02 14:55:56.234005 EDT | AverageY                    1.31745
2017-07-02 14:55:56.234226 EDT | AverageAbsY                 1.31757
2017-07-02 14:55:56.234445 EDT | AverageAbsQYDiff            0.0209333
2017-07-02 14:55:56.234605 EDT | AverageAction               0.942951
2017-07-02 14:55:56.234824 EDT | PolicyRegParamNorm         62.1632
2017-07-02 14:55:56.234994 EDT | QFunRegParamNorm           61.0716
2017-07-02 14:55:56.235184 EDT | -----------------------  -------------
2017-07-02 14:55:56.235488 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #587 | Training started
2017-07-02 14:56:05.758098 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #587 | Training finished
2017-07-02 14:56:05.758780 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #587 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 14:56:05.758963 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #587 | Collecting samples for evaluation
2017-07-02 14:56:11.177339 EDT | -----------------------  -------------
2017-07-02 14:56:11.177569 EDT | Epoch                     587
2017-07-02 14:56:11.177773 EDT | Iteration                 587
2017-07-02 14:56:11.177954 EDT | AverageReturn            1000
2017-07-02 14:56:11.178221 EDT | StdReturn                   0
2017-07-02 14:56:11.178384 EDT | MaxReturn                1000
2017-07-02 14:56:11.178510 EDT | MinReturn                1000
2017-07-02 14:56:11.178638 EDT | AverageEsReturn            39.9565
2017-07-02 14:56:11.178773 EDT | StdEsReturn                38.3457
2017-07-02 14:56:11.178934 EDT | MaxEsReturn               200
2017-07-02 14:56:11.179042 EDT | MinEsReturn                 4
2017-07-02 14:56:11.179147 EDT | AverageDiscountedReturn    99.9957
2017-07-02 14:56:11.179257 EDT | AverageQLoss                0.00656917
2017-07-02 14:56:11.179406 EDT | AveragePolicySurr          -1.37464
2017-07-02 14:56:11.179556 EDT | AverageQ                    1.30778
2017-07-02 14:56:11.179742 EDT | AverageAbsQ                 1.31149
2017-07-02 14:56:11.179967 EDT | AverageY                    1.30788
2017-07-02 14:56:11.180087 EDT | AverageAbsY                 1.30793
2017-07-02 14:56:11.180240 EDT | AverageAbsQYDiff            0.0218
2017-07-02 14:56:11.180386 EDT | AverageAction               0.161824
2017-07-02 14:56:11.180513 EDT | PolicyRegParamNorm         62.1556
2017-07-02 14:56:11.180678 EDT | QFunRegParamNorm           61.0837
2017-07-02 14:56:11.180843 EDT | -----------------------  -------------
2017-07-02 14:56:11.181013 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #588 | Training started
2017-07-02 14:56:20.579196 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #588 | Training finished
2017-07-02 14:56:20.580476 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #588 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 14:56:20.580743 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #588 | Collecting samples for evaluation
2017-07-02 14:56:26.129977 EDT | -----------------------  -------------
2017-07-02 14:56:26.130160 EDT | Epoch                     588
2017-07-02 14:56:26.130306 EDT | Iteration                 588
2017-07-02 14:56:26.130429 EDT | AverageReturn             931.091
2017-07-02 14:56:26.130558 EDT | StdReturn                 217.91
2017-07-02 14:56:26.130660 EDT | MaxReturn                1000
2017-07-02 14:56:26.130760 EDT | MinReturn                 242
2017-07-02 14:56:26.130907 EDT | AverageEsReturn            45.3043
2017-07-02 14:56:26.131038 EDT | StdEsReturn                31.7016
2017-07-02 14:56:26.131140 EDT | MaxEsReturn                96
2017-07-02 14:56:26.131258 EDT | MinEsReturn                 3
2017-07-02 14:56:26.131358 EDT | AverageDiscountedReturn    99.1975
2017-07-02 14:56:26.131479 EDT | AverageQLoss                0.00565765
2017-07-02 14:56:26.131629 EDT | AveragePolicySurr          -1.36855
2017-07-02 14:56:26.131737 EDT | AverageQ                    1.30277
2017-07-02 14:56:26.131876 EDT | AverageAbsQ                 1.30575
2017-07-02 14:56:26.131990 EDT | AverageY                    1.30272
2017-07-02 14:56:26.132091 EDT | AverageAbsY                 1.30283
2017-07-02 14:56:26.132191 EDT | AverageAbsQYDiff            0.0202397
2017-07-02 14:56:26.132319 EDT | AverageAction               0.0980876
2017-07-02 14:56:26.132469 EDT | PolicyRegParamNorm         62.1553
2017-07-02 14:56:26.132574 EDT | QFunRegParamNorm           61.0982
2017-07-02 14:56:26.132673 EDT | -----------------------  -------------
2017-07-02 14:56:26.132860 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #589 | Training started
2017-07-02 14:56:35.504680 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #589 | Training finished
2017-07-02 14:56:35.505469 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #589 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 14:56:35.505757 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #589 | Collecting samples for evaluation
2017-07-02 14:56:41.036248 EDT | -----------------------  -------------
2017-07-02 14:56:41.036553 EDT | Epoch                     589
2017-07-02 14:56:41.036780 EDT | Iteration                 589
2017-07-02 14:56:41.037010 EDT | AverageReturn            1000
2017-07-02 14:56:41.037206 EDT | StdReturn                   0
2017-07-02 14:56:41.037378 EDT | MaxReturn                1000
2017-07-02 14:56:41.037621 EDT | MinReturn                1000
2017-07-02 14:56:41.037834 EDT | AverageEsReturn            39.32
2017-07-02 14:56:41.038065 EDT | StdEsReturn                32.8922
2017-07-02 14:56:41.038292 EDT | MaxEsReturn               131
2017-07-02 14:56:41.038515 EDT | MinEsReturn                 6
2017-07-02 14:56:41.038736 EDT | AverageDiscountedReturn    99.9957
2017-07-02 14:56:41.038959 EDT | AverageQLoss                0.00769159
2017-07-02 14:56:41.039109 EDT | AveragePolicySurr          -1.36383
2017-07-02 14:56:41.039336 EDT | AverageQ                    1.29838
2017-07-02 14:56:41.039552 EDT | AverageAbsQ                 1.30238
2017-07-02 14:56:41.039778 EDT | AverageY                    1.29834
2017-07-02 14:56:41.040007 EDT | AverageAbsY                 1.29837
2017-07-02 14:56:41.040227 EDT | AverageAbsQYDiff            0.0240294
2017-07-02 14:56:41.040453 EDT | AverageAction               0.0781066
2017-07-02 14:56:41.040675 EDT | PolicyRegParamNorm         62.1923
2017-07-02 14:56:41.040895 EDT | QFunRegParamNorm           61.0985
2017-07-02 14:56:41.041113 EDT | -----------------------  -------------
2017-07-02 14:56:41.041431 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #590 | Training started
2017-07-02 14:56:50.251719 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #590 | Training finished
2017-07-02 14:56:50.252261 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #590 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 14:56:50.252510 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #590 | Collecting samples for evaluation
2017-07-02 14:56:55.864603 EDT | -----------------------  -------------
2017-07-02 14:56:55.864923 EDT | Epoch                     590
2017-07-02 14:56:55.865150 EDT | Iteration                 590
2017-07-02 14:56:55.865372 EDT | AverageReturn            1000
2017-07-02 14:56:55.865580 EDT | StdReturn                   0
2017-07-02 14:56:55.865687 EDT | MaxReturn                1000
2017-07-02 14:56:55.865789 EDT | MinReturn                1000
2017-07-02 14:56:55.865898 EDT | AverageEsReturn            33.9355
2017-07-02 14:56:55.866172 EDT | StdEsReturn                30.9994
2017-07-02 14:56:55.866376 EDT | MaxEsReturn               154
2017-07-02 14:56:55.866612 EDT | MinEsReturn                 3
2017-07-02 14:56:55.866833 EDT | AverageDiscountedReturn    99.9957
2017-07-02 14:56:55.867052 EDT | AverageQLoss                0.00602555
2017-07-02 14:56:55.867244 EDT | AveragePolicySurr          -1.36144
2017-07-02 14:56:55.867460 EDT | AverageQ                    1.29795
2017-07-02 14:56:55.867641 EDT | AverageAbsQ                 1.30085
2017-07-02 14:56:55.867858 EDT | AverageY                    1.29795
2017-07-02 14:56:55.868074 EDT | AverageAbsY                 1.29814
2017-07-02 14:56:55.868289 EDT | AverageAbsQYDiff            0.0199504
2017-07-02 14:56:55.868456 EDT | AverageAction               0.655809
2017-07-02 14:56:55.868561 EDT | PolicyRegParamNorm         62.2477
2017-07-02 14:56:55.868662 EDT | QFunRegParamNorm           61.0935
2017-07-02 14:56:55.868763 EDT | -----------------------  -------------
2017-07-02 14:56:55.869092 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #591 | Training started
2017-07-02 14:57:05.106627 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #591 | Training finished
2017-07-02 14:57:05.107232 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #591 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 14:57:05.107418 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #591 | Collecting samples for evaluation
2017-07-02 14:57:10.625550 EDT | -----------------------  -------------
2017-07-02 14:57:10.625790 EDT | Epoch                     591
2017-07-02 14:57:10.625914 EDT | Iteration                 591
2017-07-02 14:57:10.626059 EDT | AverageReturn            1000
2017-07-02 14:57:10.626199 EDT | StdReturn                   0
2017-07-02 14:57:10.626330 EDT | MaxReturn                1000
2017-07-02 14:57:10.626513 EDT | MinReturn                1000
2017-07-02 14:57:10.626639 EDT | AverageEsReturn            47.2632
2017-07-02 14:57:10.626799 EDT | StdEsReturn                33.5321
2017-07-02 14:57:10.626908 EDT | MaxEsReturn               155
2017-07-02 14:57:10.627015 EDT | MinEsReturn                 4
2017-07-02 14:57:10.627120 EDT | AverageDiscountedReturn    99.9957
2017-07-02 14:57:10.627309 EDT | AverageQLoss                0.00623444
2017-07-02 14:57:10.627525 EDT | AveragePolicySurr          -1.35386
2017-07-02 14:57:10.627684 EDT | AverageQ                    1.29071
2017-07-02 14:57:10.627874 EDT | AverageAbsQ                 1.29505
2017-07-02 14:57:10.628099 EDT | AverageY                    1.29072
2017-07-02 14:57:10.628314 EDT | AverageAbsY                 1.2909
2017-07-02 14:57:10.628525 EDT | AverageAbsQYDiff            0.0216659
2017-07-02 14:57:10.628711 EDT | AverageAction               0.852998
2017-07-02 14:57:10.628929 EDT | PolicyRegParamNorm         62.3491
2017-07-02 14:57:10.629154 EDT | QFunRegParamNorm           61.1109
2017-07-02 14:57:10.629378 EDT | -----------------------  -------------
2017-07-02 14:57:10.629756 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #592 | Training started
2017-07-02 14:57:20.008764 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #592 | Training finished
2017-07-02 14:57:20.009254 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #592 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 14:57:20.009394 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #592 | Collecting samples for evaluation
2017-07-02 14:57:25.428189 EDT | -----------------------  -------------
2017-07-02 14:57:25.428445 EDT | Epoch                     592
2017-07-02 14:57:25.428655 EDT | Iteration                 592
2017-07-02 14:57:25.428853 EDT | AverageReturn            1000
2017-07-02 14:57:25.429058 EDT | StdReturn                   0
2017-07-02 14:57:25.429291 EDT | MaxReturn                1000
2017-07-02 14:57:25.429430 EDT | MinReturn                1000
2017-07-02 14:57:25.429578 EDT | AverageEsReturn            34.3226
2017-07-02 14:57:25.429687 EDT | StdEsReturn                28.2356
2017-07-02 14:57:25.429841 EDT | MaxEsReturn               119
2017-07-02 14:57:25.429965 EDT | MinEsReturn                 4
2017-07-02 14:57:25.430068 EDT | AverageDiscountedReturn    99.9957
2017-07-02 14:57:25.430168 EDT | AverageQLoss                0.00588768
2017-07-02 14:57:25.430314 EDT | AveragePolicySurr          -1.34847
2017-07-02 14:57:25.430443 EDT | AverageQ                    1.28436
2017-07-02 14:57:25.430543 EDT | AverageAbsQ                 1.2875
2017-07-02 14:57:25.430642 EDT | AverageY                    1.28433
2017-07-02 14:57:25.430786 EDT | AverageAbsY                 1.28454
2017-07-02 14:57:25.430978 EDT | AverageAbsQYDiff            0.02129
2017-07-02 14:57:25.431163 EDT | AverageAction               0.158385
2017-07-02 14:57:25.431289 EDT | PolicyRegParamNorm         62.3647
2017-07-02 14:57:25.431390 EDT | QFunRegParamNorm           61.1402
2017-07-02 14:57:25.431525 EDT | -----------------------  -------------
2017-07-02 14:57:25.431699 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #593 | Training started
2017-07-02 14:57:34.777711 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #593 | Training finished
2017-07-02 14:57:34.778318 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #593 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 14:57:34.778458 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #593 | Collecting samples for evaluation
2017-07-02 14:57:40.202454 EDT | -----------------------  -------------
2017-07-02 14:57:40.202639 EDT | Epoch                     593
2017-07-02 14:57:40.202790 EDT | Iteration                 593
2017-07-02 14:57:40.202923 EDT | AverageReturn            1000
2017-07-02 14:57:40.203027 EDT | StdReturn                   0
2017-07-02 14:57:40.203136 EDT | MaxReturn                1000
2017-07-02 14:57:40.203241 EDT | MinReturn                1000
2017-07-02 14:57:40.203341 EDT | AverageEsReturn            33.9677
2017-07-02 14:57:40.203440 EDT | StdEsReturn                24.9612
2017-07-02 14:57:40.203567 EDT | MaxEsReturn                91
2017-07-02 14:57:40.203756 EDT | MinEsReturn                 3
2017-07-02 14:57:40.203860 EDT | AverageDiscountedReturn    99.9957
2017-07-02 14:57:40.203960 EDT | AverageQLoss                0.00572335
2017-07-02 14:57:40.204060 EDT | AveragePolicySurr          -1.34469
2017-07-02 14:57:40.204219 EDT | AverageQ                    1.28355
2017-07-02 14:57:40.204321 EDT | AverageAbsQ                 1.2869
2017-07-02 14:57:40.204422 EDT | AverageY                    1.28354
2017-07-02 14:57:40.204549 EDT | AverageAbsY                 1.28372
2017-07-02 14:57:40.204668 EDT | AverageAbsQYDiff            0.02003
2017-07-02 14:57:40.204768 EDT | AverageAction               0.228055
2017-07-02 14:57:40.204868 EDT | PolicyRegParamNorm         62.4508
2017-07-02 14:57:40.204971 EDT | QFunRegParamNorm           61.1679
2017-07-02 14:57:40.205080 EDT | -----------------------  -------------
2017-07-02 14:57:40.205235 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #594 | Training started
2017-07-02 14:57:49.584952 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #594 | Training finished
2017-07-02 14:57:49.585758 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #594 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 14:57:49.586017 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #594 | Collecting samples for evaluation
2017-07-02 14:57:55.100282 EDT | -----------------------  -------------
2017-07-02 14:57:55.100556 EDT | Epoch                     594
2017-07-02 14:57:55.100786 EDT | Iteration                 594
2017-07-02 14:57:55.100946 EDT | AverageReturn            1000
2017-07-02 14:57:55.101174 EDT | StdReturn                   0
2017-07-02 14:57:55.101394 EDT | MaxReturn                1000
2017-07-02 14:57:55.101597 EDT | MinReturn                1000
2017-07-02 14:57:55.101812 EDT | AverageEsReturn            38.0385
2017-07-02 14:57:55.102030 EDT | StdEsReturn                23.4693
2017-07-02 14:57:55.102253 EDT | MaxEsReturn                87
2017-07-02 14:57:55.102476 EDT | MinEsReturn                 2
2017-07-02 14:57:55.102694 EDT | AverageDiscountedReturn    99.9957
2017-07-02 14:57:55.102927 EDT | AverageQLoss                0.00610141
2017-07-02 14:57:55.103149 EDT | AveragePolicySurr          -1.34069
2017-07-02 14:57:55.103291 EDT | AverageQ                    1.27593
2017-07-02 14:57:55.103518 EDT | AverageAbsQ                 1.27972
2017-07-02 14:57:55.103741 EDT | AverageY                    1.2759
2017-07-02 14:57:55.103962 EDT | AverageAbsY                 1.276
2017-07-02 14:57:55.104172 EDT | AverageAbsQYDiff            0.0205728
2017-07-02 14:57:55.104333 EDT | AverageAction               0.847633
2017-07-02 14:57:55.104557 EDT | PolicyRegParamNorm         62.4519
2017-07-02 14:57:55.104680 EDT | QFunRegParamNorm           61.1765
2017-07-02 14:57:55.104790 EDT | -----------------------  -------------
2017-07-02 14:57:55.104981 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #595 | Training started
2017-07-02 14:58:04.326081 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #595 | Training finished
2017-07-02 14:58:04.326817 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #595 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 14:58:04.327076 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #595 | Collecting samples for evaluation
2017-07-02 14:58:09.844629 EDT | -----------------------  -------------
2017-07-02 14:58:09.844948 EDT | Epoch                     595
2017-07-02 14:58:09.845182 EDT | Iteration                 595
2017-07-02 14:58:09.845424 EDT | AverageReturn            1000
2017-07-02 14:58:09.845754 EDT | StdReturn                   0
2017-07-02 14:58:09.845990 EDT | MaxReturn                1000
2017-07-02 14:58:09.846222 EDT | MinReturn                1000
2017-07-02 14:58:09.846451 EDT | AverageEsReturn            34.3929
2017-07-02 14:58:09.846642 EDT | StdEsReturn                34.5712
2017-07-02 14:58:09.846872 EDT | MaxEsReturn               171
2017-07-02 14:58:09.847073 EDT | MinEsReturn                 3
2017-07-02 14:58:09.847299 EDT | AverageDiscountedReturn    99.9957
2017-07-02 14:58:09.847523 EDT | AverageQLoss                0.00518784
2017-07-02 14:58:09.847639 EDT | AveragePolicySurr          -1.33493
2017-07-02 14:58:09.847743 EDT | AverageQ                    1.27231
2017-07-02 14:58:09.847844 EDT | AverageAbsQ                 1.2764
2017-07-02 14:58:09.848031 EDT | AverageY                    1.27231
2017-07-02 14:58:09.848268 EDT | AverageAbsY                 1.27247
2017-07-02 14:58:09.848431 EDT | AverageAbsQYDiff            0.0196548
2017-07-02 14:58:09.848661 EDT | AverageAction               0.774882
2017-07-02 14:58:09.848874 EDT | PolicyRegParamNorm         62.4752
2017-07-02 14:58:09.849015 EDT | QFunRegParamNorm           61.1967
2017-07-02 14:58:09.849245 EDT | -----------------------  -------------
2017-07-02 14:58:09.849513 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #596 | Training started
2017-07-02 14:58:19.057814 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #596 | Training finished
2017-07-02 14:58:19.058536 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #596 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 14:58:19.058719 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #596 | Collecting samples for evaluation
2017-07-02 14:58:24.489518 EDT | -----------------------  -------------
2017-07-02 14:58:24.489830 EDT | Epoch                     596
2017-07-02 14:58:24.490032 EDT | Iteration                 596
2017-07-02 14:58:24.490261 EDT | AverageReturn            1000
2017-07-02 14:58:24.490485 EDT | StdReturn                   0
2017-07-02 14:58:24.490693 EDT | MaxReturn                1000
2017-07-02 14:58:24.490921 EDT | MinReturn                1000
2017-07-02 14:58:24.491100 EDT | AverageEsReturn            33.8065
2017-07-02 14:58:24.491329 EDT | StdEsReturn                22.0796
2017-07-02 14:58:24.491551 EDT | MaxEsReturn                92
2017-07-02 14:58:24.491774 EDT | MinEsReturn                 3
2017-07-02 14:58:24.492004 EDT | AverageDiscountedReturn    99.9957
2017-07-02 14:58:24.492205 EDT | AverageQLoss                0.00644495
2017-07-02 14:58:24.492435 EDT | AveragePolicySurr          -1.33299
2017-07-02 14:58:24.492630 EDT | AverageQ                    1.27106
2017-07-02 14:58:24.492845 EDT | AverageAbsQ                 1.27474
2017-07-02 14:58:24.493071 EDT | AverageY                    1.27101
2017-07-02 14:58:24.493361 EDT | AverageAbsY                 1.2712
2017-07-02 14:58:24.493600 EDT | AverageAbsQYDiff            0.0218066
2017-07-02 14:58:24.493717 EDT | AverageAction               0.124957
2017-07-02 14:58:24.493820 EDT | PolicyRegParamNorm         62.5334
2017-07-02 14:58:24.493921 EDT | QFunRegParamNorm           61.2139
2017-07-02 14:58:24.494020 EDT | -----------------------  -------------
2017-07-02 14:58:24.494187 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #597 | Training started
2017-07-02 14:58:33.793783 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #597 | Training finished
2017-07-02 14:58:33.794272 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #597 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 14:58:33.794464 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #597 | Collecting samples for evaluation
2017-07-02 14:58:39.306905 EDT | -----------------------  ------------
2017-07-02 14:58:39.307095 EDT | Epoch                     597
2017-07-02 14:58:39.307229 EDT | Iteration                 597
2017-07-02 14:58:39.307334 EDT | AverageReturn            1000
2017-07-02 14:58:39.307446 EDT | StdReturn                   0
2017-07-02 14:58:39.307612 EDT | MaxReturn                1000
2017-07-02 14:58:39.307805 EDT | MinReturn                1000
2017-07-02 14:58:39.307935 EDT | AverageEsReturn            33.2069
2017-07-02 14:58:39.308048 EDT | StdEsReturn                22.8222
2017-07-02 14:58:39.308172 EDT | MaxEsReturn                78
2017-07-02 14:58:39.308315 EDT | MinEsReturn                 2
2017-07-02 14:58:39.308543 EDT | AverageDiscountedReturn    99.9957
2017-07-02 14:58:39.308768 EDT | AverageQLoss                0.0064472
2017-07-02 14:58:39.308919 EDT | AveragePolicySurr          -1.32551
2017-07-02 14:58:39.309148 EDT | AverageQ                    1.26191
2017-07-02 14:58:39.309378 EDT | AverageAbsQ                 1.26623
2017-07-02 14:58:39.309632 EDT | AverageY                    1.26177
2017-07-02 14:58:39.309857 EDT | AverageAbsY                 1.26202
2017-07-02 14:58:39.310062 EDT | AverageAbsQYDiff            0.0216716
2017-07-02 14:58:39.310291 EDT | AverageAction               0.823714
2017-07-02 14:58:39.310508 EDT | PolicyRegParamNorm         62.5537
2017-07-02 14:58:39.310726 EDT | QFunRegParamNorm           61.2412
2017-07-02 14:58:39.310950 EDT | -----------------------  ------------
2017-07-02 14:58:39.311254 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #598 | Training started
2017-07-02 14:58:48.593192 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #598 | Training finished
2017-07-02 14:58:48.593361 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #598 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 14:58:48.593886 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #598 | Collecting samples for evaluation
2017-07-02 14:58:54.334147 EDT | -----------------------  -------------
2017-07-02 14:58:54.348817 EDT | Epoch                     598
2017-07-02 14:58:54.349019 EDT | Iteration                 598
2017-07-02 14:58:54.349200 EDT | AverageReturn             492.619
2017-07-02 14:58:54.349323 EDT | StdReturn                 399.279
2017-07-02 14:58:54.349526 EDT | MaxReturn                1000
2017-07-02 14:58:54.349639 EDT | MinReturn                 111
2017-07-02 14:58:54.349770 EDT | AverageEsReturn            36.4643
2017-07-02 14:58:54.349998 EDT | StdEsReturn                23.2017
2017-07-02 14:58:54.350222 EDT | MaxEsReturn                98
2017-07-02 14:58:54.350409 EDT | MinEsReturn                 3
2017-07-02 14:58:54.350634 EDT | AverageDiscountedReturn    85.9556
2017-07-02 14:58:54.350861 EDT | AverageQLoss                0.00583261
2017-07-02 14:58:54.351071 EDT | AveragePolicySurr          -1.32222
2017-07-02 14:58:54.351301 EDT | AverageQ                    1.26032
2017-07-02 14:58:54.351463 EDT | AverageAbsQ                 1.26397
2017-07-02 14:58:54.351568 EDT | AverageY                    1.2603
2017-07-02 14:58:54.351768 EDT | AverageAbsY                 1.26074
2017-07-02 14:58:54.351994 EDT | AverageAbsQYDiff            0.0207206
2017-07-02 14:58:54.352196 EDT | AverageAction               0.363467
2017-07-02 14:58:54.352417 EDT | PolicyRegParamNorm         62.5823
2017-07-02 14:58:54.352644 EDT | QFunRegParamNorm           61.2553
2017-07-02 14:58:54.352780 EDT | -----------------------  -------------
2017-07-02 14:58:54.352967 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #599 | Training started
2017-07-02 14:59:03.668912 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #599 | Training finished
2017-07-02 14:59:03.669779 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #599 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 14:59:03.669933 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #599 | Collecting samples for evaluation
2017-07-02 14:59:09.198035 EDT | -----------------------  -------------
2017-07-02 14:59:09.198313 EDT | Epoch                     599
2017-07-02 14:59:09.198632 EDT | Iteration                 599
2017-07-02 14:59:09.198752 EDT | AverageReturn            1000
2017-07-02 14:59:09.198911 EDT | StdReturn                   0
2017-07-02 14:59:09.199029 EDT | MaxReturn                1000
2017-07-02 14:59:09.199139 EDT | MinReturn                1000
2017-07-02 14:59:09.199289 EDT | AverageEsReturn            49.2
2017-07-02 14:59:09.199397 EDT | StdEsReturn                43.4449
2017-07-02 14:59:09.199503 EDT | MaxEsReturn               172
2017-07-02 14:59:09.199626 EDT | MinEsReturn                 7
2017-07-02 14:59:09.199735 EDT | AverageDiscountedReturn    99.9957
2017-07-02 14:59:09.199859 EDT | AverageQLoss                0.00666165
2017-07-02 14:59:09.199969 EDT | AveragePolicySurr          -1.31844
2017-07-02 14:59:09.200069 EDT | AverageQ                    1.25699
2017-07-02 14:59:09.200186 EDT | AverageAbsQ                 1.26119
2017-07-02 14:59:09.200285 EDT | AverageY                    1.25698
2017-07-02 14:59:09.200384 EDT | AverageAbsY                 1.25739
2017-07-02 14:59:09.200516 EDT | AverageAbsQYDiff            0.0223874
2017-07-02 14:59:09.200650 EDT | AverageAction               0.820481
2017-07-02 14:59:09.200826 EDT | PolicyRegParamNorm         62.6562
2017-07-02 14:59:09.200936 EDT | QFunRegParamNorm           61.2757
2017-07-02 14:59:09.201061 EDT | -----------------------  -------------
2017-07-02 14:59:09.201237 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #600 | Training started
2017-07-02 14:59:18.478261 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #600 | Training finished
2017-07-02 14:59:18.478845 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #600 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 14:59:18.479004 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #600 | Collecting samples for evaluation
2017-07-02 14:59:24.027357 EDT | -----------------------  -------------
2017-07-02 14:59:24.027595 EDT | Epoch                     600
2017-07-02 14:59:24.027769 EDT | Iteration                 600
2017-07-02 14:59:24.027977 EDT | AverageReturn            1000
2017-07-02 14:59:24.028191 EDT | StdReturn                   0
2017-07-02 14:59:24.028418 EDT | MaxReturn                1000
2017-07-02 14:59:24.028638 EDT | MinReturn                1000
2017-07-02 14:59:24.028793 EDT | AverageEsReturn            33.2258
2017-07-02 14:59:24.029006 EDT | StdEsReturn                20.8601
2017-07-02 14:59:24.029243 EDT | MaxEsReturn                79
2017-07-02 14:59:24.029469 EDT | MinEsReturn                 5
2017-07-02 14:59:24.029715 EDT | AverageDiscountedReturn    99.9957
2017-07-02 14:59:24.029898 EDT | AverageQLoss                0.00586094
2017-07-02 14:59:24.030068 EDT | AveragePolicySurr          -1.31091
2017-07-02 14:59:24.030296 EDT | AverageQ                    1.25025
2017-07-02 14:59:24.030416 EDT | AverageAbsQ                 1.25395
2017-07-02 14:59:24.030517 EDT | AverageY                    1.25026
2017-07-02 14:59:24.030619 EDT | AverageAbsY                 1.25079
2017-07-02 14:59:24.030720 EDT | AverageAbsQYDiff            0.0199748
2017-07-02 14:59:24.030819 EDT | AverageAction               0.28968
2017-07-02 14:59:24.030918 EDT | PolicyRegParamNorm         62.7133
2017-07-02 14:59:24.031016 EDT | QFunRegParamNorm           61.3078
2017-07-02 14:59:24.031117 EDT | -----------------------  -------------
2017-07-02 14:59:24.031430 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #601 | Training started
2017-07-02 14:59:33.366695 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #601 | Training finished
2017-07-02 14:59:33.366913 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #601 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 14:59:33.367074 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #601 | Collecting samples for evaluation
2017-07-02 14:59:38.848582 EDT | -----------------------  -------------
2017-07-02 14:59:38.849131 EDT | Epoch                     601
2017-07-02 14:59:38.849261 EDT | Iteration                 601
2017-07-02 14:59:38.849371 EDT | AverageReturn            1000
2017-07-02 14:59:38.849560 EDT | StdReturn                   0
2017-07-02 14:59:38.849673 EDT | MaxReturn                1000
2017-07-02 14:59:38.849880 EDT | MinReturn                1000
2017-07-02 14:59:38.850025 EDT | AverageEsReturn            40.913
2017-07-02 14:59:38.850131 EDT | StdEsReturn                31.4282
2017-07-02 14:59:38.850285 EDT | MaxEsReturn               145
2017-07-02 14:59:38.850464 EDT | MinEsReturn                 4
2017-07-02 14:59:38.850639 EDT | AverageDiscountedReturn    99.9957
2017-07-02 14:59:38.850817 EDT | AverageQLoss                0.00550919
2017-07-02 14:59:38.850928 EDT | AveragePolicySurr          -1.31007
2017-07-02 14:59:38.851041 EDT | AverageQ                    1.24885
2017-07-02 14:59:38.851193 EDT | AverageAbsQ                 1.25326
2017-07-02 14:59:38.851354 EDT | AverageY                    1.2488
2017-07-02 14:59:38.851468 EDT | AverageAbsY                 1.24923
2017-07-02 14:59:38.851599 EDT | AverageAbsQYDiff            0.0203832
2017-07-02 14:59:38.851730 EDT | AverageAction               0.267007
2017-07-02 14:59:38.851832 EDT | PolicyRegParamNorm         62.7655
2017-07-02 14:59:38.851958 EDT | QFunRegParamNorm           61.2992
2017-07-02 14:59:38.852065 EDT | -----------------------  -------------
2017-07-02 14:59:38.852243 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #602 | Training started
2017-07-02 14:59:48.311846 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #602 | Training finished
2017-07-02 14:59:48.312851 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #602 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 14:59:48.313119 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #602 | Collecting samples for evaluation
2017-07-02 14:59:53.644682 EDT | -----------------------  -------------
2017-07-02 14:59:53.644912 EDT | Epoch                     602
2017-07-02 14:59:53.645121 EDT | Iteration                 602
2017-07-02 14:59:53.645297 EDT | AverageReturn            1000
2017-07-02 14:59:53.645543 EDT | StdReturn                   0
2017-07-02 14:59:53.645767 EDT | MaxReturn                1000
2017-07-02 14:59:53.645881 EDT | MinReturn                1000
2017-07-02 14:59:53.645984 EDT | AverageEsReturn            31.5152
2017-07-02 14:59:53.646117 EDT | StdEsReturn                30.3136
2017-07-02 14:59:53.646219 EDT | MaxEsReturn               123
2017-07-02 14:59:53.646319 EDT | MinEsReturn                 3
2017-07-02 14:59:53.646417 EDT | AverageDiscountedReturn    99.9957
2017-07-02 14:59:53.646516 EDT | AverageQLoss                0.00669819
2017-07-02 14:59:53.646615 EDT | AveragePolicySurr          -1.30263
2017-07-02 14:59:53.646713 EDT | AverageQ                    1.24397
2017-07-02 14:59:53.646811 EDT | AverageAbsQ                 1.24849
2017-07-02 14:59:53.646908 EDT | AverageY                    1.24384
2017-07-02 14:59:53.647038 EDT | AverageAbsY                 1.24424
2017-07-02 14:59:53.647139 EDT | AverageAbsQYDiff            0.0221066
2017-07-02 14:59:53.647237 EDT | AverageAction               0.886257
2017-07-02 14:59:53.647335 EDT | PolicyRegParamNorm         62.7668
2017-07-02 14:59:53.647433 EDT | QFunRegParamNorm           61.3351
2017-07-02 14:59:53.647532 EDT | -----------------------  -------------
2017-07-02 14:59:53.647689 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #603 | Training started
2017-07-02 15:00:03.046225 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #603 | Training finished
2017-07-02 15:00:03.054622 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #603 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 15:00:03.054892 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #603 | Collecting samples for evaluation
2017-07-02 15:00:08.540226 EDT | -----------------------  -------------
2017-07-02 15:00:08.540424 EDT | Epoch                     603
2017-07-02 15:00:08.540547 EDT | Iteration                 603
2017-07-02 15:00:08.540684 EDT | AverageReturn            1000
2017-07-02 15:00:08.540830 EDT | StdReturn                   0
2017-07-02 15:00:08.540956 EDT | MaxReturn                1000
2017-07-02 15:00:08.541065 EDT | MinReturn                1000
2017-07-02 15:00:08.541205 EDT | AverageEsReturn            29.9118
2017-07-02 15:00:08.541312 EDT | StdEsReturn                19.0454
2017-07-02 15:00:08.541416 EDT | MaxEsReturn                60
2017-07-02 15:00:08.541572 EDT | MinEsReturn                 3
2017-07-02 15:00:08.541683 EDT | AverageDiscountedReturn    99.9957
2017-07-02 15:00:08.541789 EDT | AverageQLoss                0.00554089
2017-07-02 15:00:08.541894 EDT | AveragePolicySurr          -1.29846
2017-07-02 15:00:08.542021 EDT | AverageQ                    1.23869
2017-07-02 15:00:08.542165 EDT | AverageAbsQ                 1.24235
2017-07-02 15:00:08.542291 EDT | AverageY                    1.23877
2017-07-02 15:00:08.542415 EDT | AverageAbsY                 1.23958
2017-07-02 15:00:08.542560 EDT | AverageAbsQYDiff            0.0202576
2017-07-02 15:00:08.542742 EDT | AverageAction               0.773045
2017-07-02 15:00:08.542867 EDT | PolicyRegParamNorm         62.8466
2017-07-02 15:00:08.542986 EDT | QFunRegParamNorm           61.3477
2017-07-02 15:00:08.543119 EDT | -----------------------  -------------
2017-07-02 15:00:08.543303 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #604 | Training started
2017-07-02 15:00:17.885127 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #604 | Training finished
2017-07-02 15:00:17.885943 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #604 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 15:00:17.886170 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #604 | Collecting samples for evaluation
2017-07-02 15:00:23.898860 EDT | -----------------------  -------------
2017-07-02 15:00:23.899104 EDT | Epoch                     604
2017-07-02 15:00:23.899344 EDT | Iteration                 604
2017-07-02 15:00:23.899525 EDT | AverageReturn            1000
2017-07-02 15:00:23.899734 EDT | StdReturn                   0
2017-07-02 15:00:23.899960 EDT | MaxReturn                1000
2017-07-02 15:00:23.900130 EDT | MinReturn                1000
2017-07-02 15:00:23.900362 EDT | AverageEsReturn            31
2017-07-02 15:00:23.900553 EDT | StdEsReturn                29.5878
2017-07-02 15:00:23.900777 EDT | MaxEsReturn               126
2017-07-02 15:00:23.901003 EDT | MinEsReturn                 3
2017-07-02 15:00:23.901182 EDT | AverageDiscountedReturn    99.9957
2017-07-02 15:00:23.901411 EDT | AverageQLoss                0.00617782
2017-07-02 15:00:23.901635 EDT | AveragePolicySurr          -1.29452
2017-07-02 15:00:23.901860 EDT | AverageQ                    1.23303
2017-07-02 15:00:23.902088 EDT | AverageAbsQ                 1.23679
2017-07-02 15:00:23.902262 EDT | AverageY                    1.233
2017-07-02 15:00:23.902492 EDT | AverageAbsY                 1.23339
2017-07-02 15:00:23.902684 EDT | AverageAbsQYDiff            0.0212847
2017-07-02 15:00:23.902901 EDT | AverageAction               0.577293
2017-07-02 15:00:23.903134 EDT | PolicyRegParamNorm         62.878
2017-07-02 15:00:23.903327 EDT | QFunRegParamNorm           61.348
2017-07-02 15:00:23.903465 EDT | -----------------------  -------------
2017-07-02 15:00:23.903797 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #605 | Training started
2017-07-02 15:00:33.149433 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #605 | Training finished
2017-07-02 15:00:33.150040 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #605 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 15:00:33.150259 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #605 | Collecting samples for evaluation
2017-07-02 15:00:38.716193 EDT | -----------------------  -------------
2017-07-02 15:00:38.716395 EDT | Epoch                     605
2017-07-02 15:00:38.716539 EDT | Iteration                 605
2017-07-02 15:00:38.716674 EDT | AverageReturn            1000
2017-07-02 15:00:38.716849 EDT | StdReturn                   0
2017-07-02 15:00:38.717035 EDT | MaxReturn                1000
2017-07-02 15:00:38.717296 EDT | MinReturn                1000
2017-07-02 15:00:38.717458 EDT | AverageEsReturn            32.5161
2017-07-02 15:00:38.717615 EDT | StdEsReturn                26.0209
2017-07-02 15:00:38.717768 EDT | MaxEsReturn               118
2017-07-02 15:00:38.717929 EDT | MinEsReturn                 3
2017-07-02 15:00:38.718032 EDT | AverageDiscountedReturn    99.9957
2017-07-02 15:00:38.718133 EDT | AverageQLoss                0.00598824
2017-07-02 15:00:38.718273 EDT | AveragePolicySurr          -1.28794
2017-07-02 15:00:38.718375 EDT | AverageQ                    1.2316
2017-07-02 15:00:38.718475 EDT | AverageAbsQ                 1.23516
2017-07-02 15:00:38.718574 EDT | AverageY                    1.2315
2017-07-02 15:00:38.718673 EDT | AverageAbsY                 1.23188
2017-07-02 15:00:38.718805 EDT | AverageAbsQYDiff            0.0192332
2017-07-02 15:00:38.718970 EDT | AverageAction               0.75934
2017-07-02 15:00:38.719074 EDT | PolicyRegParamNorm         62.9149
2017-07-02 15:00:38.719204 EDT | QFunRegParamNorm           61.4023
2017-07-02 15:00:38.719390 EDT | -----------------------  -------------
2017-07-02 15:00:38.719586 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #606 | Training started
2017-07-02 15:00:48.049436 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #606 | Training finished
2017-07-02 15:00:48.050005 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #606 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 15:00:48.050177 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #606 | Collecting samples for evaluation
2017-07-02 15:00:53.498916 EDT | -----------------------  -------------
2017-07-02 15:00:53.499238 EDT | Epoch                     606
2017-07-02 15:00:53.499474 EDT | Iteration                 606
2017-07-02 15:00:53.499701 EDT | AverageReturn            1000
2017-07-02 15:00:53.499901 EDT | StdReturn                   0
2017-07-02 15:00:53.500132 EDT | MaxReturn                1000
2017-07-02 15:00:53.500262 EDT | MinReturn                1000
2017-07-02 15:00:53.500367 EDT | AverageEsReturn            34.1071
2017-07-02 15:00:53.500476 EDT | StdEsReturn                29.4538
2017-07-02 15:00:53.500613 EDT | MaxEsReturn               120
2017-07-02 15:00:53.500739 EDT | MinEsReturn                 4
2017-07-02 15:00:53.500860 EDT | AverageDiscountedReturn    99.9957
2017-07-02 15:00:53.500966 EDT | AverageQLoss                0.00488572
2017-07-02 15:00:53.501100 EDT | AveragePolicySurr          -1.28422
2017-07-02 15:00:53.501318 EDT | AverageQ                    1.22489
2017-07-02 15:00:53.501543 EDT | AverageAbsQ                 1.22811
2017-07-02 15:00:53.501771 EDT | AverageY                    1.22489
2017-07-02 15:00:53.501976 EDT | AverageAbsY                 1.22516
2017-07-02 15:00:53.502203 EDT | AverageAbsQYDiff            0.0175061
2017-07-02 15:00:53.502432 EDT | AverageAction               0.760793
2017-07-02 15:00:53.502654 EDT | PolicyRegParamNorm         62.9506
2017-07-02 15:00:53.502878 EDT | QFunRegParamNorm           61.4446
2017-07-02 15:00:53.503089 EDT | -----------------------  -------------
2017-07-02 15:00:53.503262 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #607 | Training started
2017-07-02 15:01:02.962175 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #607 | Training finished
2017-07-02 15:01:02.962746 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #607 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 15:01:02.962996 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #607 | Collecting samples for evaluation
2017-07-02 15:01:08.466798 EDT | -----------------------  -------------
2017-07-02 15:01:08.467036 EDT | Epoch                     607
2017-07-02 15:01:08.467273 EDT | Iteration                 607
2017-07-02 15:01:08.467499 EDT | AverageReturn            1000
2017-07-02 15:01:08.467688 EDT | StdReturn                   0
2017-07-02 15:01:08.467920 EDT | MaxReturn                1000
2017-07-02 15:01:08.468140 EDT | MinReturn                1000
2017-07-02 15:01:08.468356 EDT | AverageEsReturn            38.2963
2017-07-02 15:01:08.468587 EDT | StdEsReturn                32.6302
2017-07-02 15:01:08.468768 EDT | MaxEsReturn               131
2017-07-02 15:01:08.468999 EDT | MinEsReturn                 5
2017-07-02 15:01:08.469224 EDT | AverageDiscountedReturn    99.9957
2017-07-02 15:01:08.469422 EDT | AverageQLoss                0.00429246
2017-07-02 15:01:08.469824 EDT | AveragePolicySurr          -1.281
2017-07-02 15:01:08.469947 EDT | AverageQ                    1.2255
2017-07-02 15:01:08.470052 EDT | AverageAbsQ                 1.22867
2017-07-02 15:01:08.470154 EDT | AverageY                    1.22554
2017-07-02 15:01:08.470254 EDT | AverageAbsY                 1.22584
2017-07-02 15:01:08.470369 EDT | AverageAbsQYDiff            0.0177536
2017-07-02 15:01:08.470486 EDT | AverageAction               0.850874
2017-07-02 15:01:08.470587 EDT | PolicyRegParamNorm         62.9716
2017-07-02 15:01:08.470686 EDT | QFunRegParamNorm           61.4694
2017-07-02 15:01:08.470786 EDT | -----------------------  -------------
2017-07-02 15:01:08.470945 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #608 | Training started
2017-07-02 15:01:17.923364 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #608 | Training finished
2017-07-02 15:01:17.923947 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #608 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 15:01:17.924093 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #608 | Collecting samples for evaluation
2017-07-02 15:01:23.365549 EDT | -----------------------  -------------
2017-07-02 15:01:23.365748 EDT | Epoch                     608
2017-07-02 15:01:23.365945 EDT | Iteration                 608
2017-07-02 15:01:23.366173 EDT | AverageReturn            1000
2017-07-02 15:01:23.366398 EDT | StdReturn                   0
2017-07-02 15:01:23.366613 EDT | MaxReturn                1000
2017-07-02 15:01:23.366810 EDT | MinReturn                1000
2017-07-02 15:01:23.367039 EDT | AverageEsReturn            28.8125
2017-07-02 15:01:23.367266 EDT | StdEsReturn                26.432
2017-07-02 15:01:23.367455 EDT | MaxEsReturn               115
2017-07-02 15:01:23.367673 EDT | MinEsReturn                 3
2017-07-02 15:01:23.367875 EDT | AverageDiscountedReturn    99.9957
2017-07-02 15:01:23.368101 EDT | AverageQLoss                0.00553053
2017-07-02 15:01:23.368312 EDT | AveragePolicySurr          -1.27925
2017-07-02 15:01:23.368541 EDT | AverageQ                    1.22034
2017-07-02 15:01:23.368762 EDT | AverageAbsQ                 1.2239
2017-07-02 15:01:23.368930 EDT | AverageY                    1.22022
2017-07-02 15:01:23.369158 EDT | AverageAbsY                 1.2205
2017-07-02 15:01:23.369377 EDT | AverageAbsQYDiff            0.0197491
2017-07-02 15:01:23.369637 EDT | AverageAction               0.802909
2017-07-02 15:01:23.369868 EDT | PolicyRegParamNorm         62.9658
2017-07-02 15:01:23.370087 EDT | QFunRegParamNorm           61.4835
2017-07-02 15:01:23.370318 EDT | -----------------------  -------------
2017-07-02 15:01:23.370634 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #609 | Training started
2017-07-02 15:01:32.792010 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #609 | Training finished
2017-07-02 15:01:32.796432 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #609 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 15:01:32.796618 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #609 | Collecting samples for evaluation
2017-07-02 15:01:38.474384 EDT | -----------------------  ------------
2017-07-02 15:01:38.474699 EDT | Epoch                     609
2017-07-02 15:01:38.474927 EDT | Iteration                 609
2017-07-02 15:01:38.475148 EDT | AverageReturn             358.931
2017-07-02 15:01:38.475365 EDT | StdReturn                 321.528
2017-07-02 15:01:38.475584 EDT | MaxReturn                1000
2017-07-02 15:01:38.475796 EDT | MinReturn                  52
2017-07-02 15:01:38.475989 EDT | AverageEsReturn            24.6364
2017-07-02 15:01:38.476177 EDT | StdEsReturn                21.6534
2017-07-02 15:01:38.476302 EDT | MaxEsReturn                95
2017-07-02 15:01:38.476448 EDT | MinEsReturn                 3
2017-07-02 15:01:38.476583 EDT | AverageDiscountedReturn    81.2723
2017-07-02 15:01:38.476702 EDT | AverageQLoss                0.0049241
2017-07-02 15:01:38.476843 EDT | AveragePolicySurr          -1.27304
2017-07-02 15:01:38.476961 EDT | AverageQ                    1.21299
2017-07-02 15:01:38.477146 EDT | AverageAbsQ                 1.21708
2017-07-02 15:01:38.477296 EDT | AverageY                    1.21313
2017-07-02 15:01:38.477398 EDT | AverageAbsY                 1.21349
2017-07-02 15:01:38.477667 EDT | AverageAbsQYDiff            0.0200013
2017-07-02 15:01:38.477815 EDT | AverageAction               0.628475
2017-07-02 15:01:38.477950 EDT | PolicyRegParamNorm         62.9826
2017-07-02 15:01:38.478052 EDT | QFunRegParamNorm           61.5164
2017-07-02 15:01:38.478237 EDT | -----------------------  ------------
2017-07-02 15:01:38.478544 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #610 | Training started
2017-07-02 15:01:47.835713 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #610 | Training finished
2017-07-02 15:01:47.836292 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #610 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 15:01:47.836434 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #610 | Collecting samples for evaluation
2017-07-02 15:01:53.367880 EDT | -----------------------  -------------
2017-07-02 15:01:53.368073 EDT | Epoch                     610
2017-07-02 15:01:53.368188 EDT | Iteration                 610
2017-07-02 15:01:53.368291 EDT | AverageReturn            1000
2017-07-02 15:01:53.368401 EDT | StdReturn                   0
2017-07-02 15:01:53.368529 EDT | MaxReturn                1000
2017-07-02 15:01:53.368691 EDT | MinReturn                1000
2017-07-02 15:01:53.368791 EDT | AverageEsReturn            26.8056
2017-07-02 15:01:53.368907 EDT | StdEsReturn                27.1517
2017-07-02 15:01:53.369092 EDT | MaxEsReturn               133
2017-07-02 15:01:53.369256 EDT | MinEsReturn                 3
2017-07-02 15:01:53.369413 EDT | AverageDiscountedReturn    99.9957
2017-07-02 15:01:53.369599 EDT | AverageQLoss                0.00511761
2017-07-02 15:01:53.369748 EDT | AveragePolicySurr          -1.27165
2017-07-02 15:01:53.369861 EDT | AverageQ                    1.21002
2017-07-02 15:01:53.369961 EDT | AverageAbsQ                 1.21344
2017-07-02 15:01:53.370058 EDT | AverageY                    1.20996
2017-07-02 15:01:53.370191 EDT | AverageAbsY                 1.21039
2017-07-02 15:01:53.370302 EDT | AverageAbsQYDiff            0.0188699
2017-07-02 15:01:53.370456 EDT | AverageAction               0.801547
2017-07-02 15:01:53.370555 EDT | PolicyRegParamNorm         62.9826
2017-07-02 15:01:53.370651 EDT | QFunRegParamNorm           61.5692
2017-07-02 15:01:53.370800 EDT | -----------------------  -------------
2017-07-02 15:01:53.370997 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #611 | Training started
2017-07-02 15:02:02.728532 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #611 | Training finished
2017-07-02 15:02:02.729321 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #611 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 15:02:02.729479 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #611 | Collecting samples for evaluation
2017-07-02 15:02:08.232361 EDT | -----------------------  ------------
2017-07-02 15:02:08.232665 EDT | Epoch                     611
2017-07-02 15:02:08.232895 EDT | Iteration                 611
2017-07-02 15:02:08.233115 EDT | AverageReturn            1000
2017-07-02 15:02:08.233283 EDT | StdReturn                   0
2017-07-02 15:02:08.233435 EDT | MaxReturn                1000
2017-07-02 15:02:08.233674 EDT | MinReturn                1000
2017-07-02 15:02:08.233790 EDT | AverageEsReturn            44.1739
2017-07-02 15:02:08.233919 EDT | StdEsReturn                36.5033
2017-07-02 15:02:08.234142 EDT | MaxEsReturn               131
2017-07-02 15:02:08.234346 EDT | MinEsReturn                 4
2017-07-02 15:02:08.234454 EDT | AverageDiscountedReturn    99.9957
2017-07-02 15:02:08.234556 EDT | AverageQLoss                0.0045701
2017-07-02 15:02:08.234657 EDT | AveragePolicySurr          -1.26841
2017-07-02 15:02:08.234757 EDT | AverageQ                    1.21085
2017-07-02 15:02:08.234857 EDT | AverageAbsQ                 1.21438
2017-07-02 15:02:08.234956 EDT | AverageY                    1.21084
2017-07-02 15:02:08.235115 EDT | AverageAbsY                 1.21117
2017-07-02 15:02:08.235330 EDT | AverageAbsQYDiff            0.0179476
2017-07-02 15:02:08.235529 EDT | AverageAction               0.61104
2017-07-02 15:02:08.235744 EDT | PolicyRegParamNorm         62.983
2017-07-02 15:02:08.235943 EDT | QFunRegParamNorm           61.5769
2017-07-02 15:02:08.236174 EDT | -----------------------  ------------
2017-07-02 15:02:08.236487 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #612 | Training started
2017-07-02 15:02:17.640592 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #612 | Training finished
2017-07-02 15:02:17.641344 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #612 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 15:02:17.641605 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #612 | Collecting samples for evaluation
2017-07-02 15:02:23.126506 EDT | -----------------------  -------------
2017-07-02 15:02:23.126775 EDT | Epoch                     612
2017-07-02 15:02:23.127019 EDT | Iteration                 612
2017-07-02 15:02:23.127211 EDT | AverageReturn            1000
2017-07-02 15:02:23.127439 EDT | StdReturn                   0
2017-07-02 15:02:23.127660 EDT | MaxReturn                1000
2017-07-02 15:02:23.127868 EDT | MinReturn                1000
2017-07-02 15:02:23.128102 EDT | AverageEsReturn            20.8367
2017-07-02 15:02:23.128273 EDT | StdEsReturn                15.4871
2017-07-02 15:02:23.128452 EDT | MaxEsReturn                73
2017-07-02 15:02:23.128679 EDT | MinEsReturn                 3
2017-07-02 15:02:23.128866 EDT | AverageDiscountedReturn    99.9957
2017-07-02 15:02:23.128971 EDT | AverageQLoss                0.00543258
2017-07-02 15:02:23.129096 EDT | AveragePolicySurr          -1.26416
2017-07-02 15:02:23.129289 EDT | AverageQ                    1.20725
2017-07-02 15:02:23.129529 EDT | AverageAbsQ                 1.21084
2017-07-02 15:02:23.129698 EDT | AverageY                    1.20723
2017-07-02 15:02:23.129929 EDT | AverageAbsY                 1.20754
2017-07-02 15:02:23.130141 EDT | AverageAbsQYDiff            0.0196547
2017-07-02 15:02:23.130357 EDT | AverageAction               0.731993
2017-07-02 15:02:23.130584 EDT | PolicyRegParamNorm         63.0253
2017-07-02 15:02:23.130795 EDT | QFunRegParamNorm           61.5881
2017-07-02 15:02:23.131023 EDT | -----------------------  -------------
2017-07-02 15:02:23.131248 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #613 | Training started
2017-07-02 15:02:32.570036 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #613 | Training finished
2017-07-02 15:02:32.570575 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #613 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 15:02:32.570710 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #613 | Collecting samples for evaluation
2017-07-02 15:02:38.065258 EDT | -----------------------  -------------
2017-07-02 15:02:38.065497 EDT | Epoch                     613
2017-07-02 15:02:38.065708 EDT | Iteration                 613
2017-07-02 15:02:38.065910 EDT | AverageReturn            1000
2017-07-02 15:02:38.066033 EDT | StdReturn                   0
2017-07-02 15:02:38.066133 EDT | MaxReturn                1000
2017-07-02 15:02:38.066307 EDT | MinReturn                1000
2017-07-02 15:02:38.066439 EDT | AverageEsReturn            29.1515
2017-07-02 15:02:38.066556 EDT | StdEsReturn                28.5096
2017-07-02 15:02:38.066683 EDT | MaxEsReturn               152
2017-07-02 15:02:38.066838 EDT | MinEsReturn                 4
2017-07-02 15:02:38.066958 EDT | AverageDiscountedReturn    99.9957
2017-07-02 15:02:38.067092 EDT | AverageQLoss                0.00595033
2017-07-02 15:02:38.067194 EDT | AveragePolicySurr          -1.25999
2017-07-02 15:02:38.067340 EDT | AverageQ                    1.19954
2017-07-02 15:02:38.067454 EDT | AverageAbsQ                 1.20345
2017-07-02 15:02:38.067629 EDT | AverageY                    1.19952
2017-07-02 15:02:38.067763 EDT | AverageAbsY                 1.19993
2017-07-02 15:02:38.067913 EDT | AverageAbsQYDiff            0.0201263
2017-07-02 15:02:38.068045 EDT | AverageAction               0.800517
2017-07-02 15:02:38.068142 EDT | PolicyRegParamNorm         63.0702
2017-07-02 15:02:38.068274 EDT | QFunRegParamNorm           61.62
2017-07-02 15:02:38.068453 EDT | -----------------------  -------------
2017-07-02 15:02:38.068704 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #614 | Training started
2017-07-02 15:02:47.302302 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #614 | Training finished
2017-07-02 15:02:47.302806 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #614 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 15:02:47.303051 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #614 | Collecting samples for evaluation
2017-07-02 15:02:52.879133 EDT | -----------------------  -------------
2017-07-02 15:02:52.879329 EDT | Epoch                     614
2017-07-02 15:02:52.879440 EDT | Iteration                 614
2017-07-02 15:02:52.879544 EDT | AverageReturn            1000
2017-07-02 15:02:52.879653 EDT | StdReturn                   0
2017-07-02 15:02:52.879787 EDT | MaxReturn                1000
2017-07-02 15:02:52.879939 EDT | MinReturn                1000
2017-07-02 15:02:52.880061 EDT | AverageEsReturn            30.5758
2017-07-02 15:02:52.880213 EDT | StdEsReturn                31.2401
2017-07-02 15:02:52.880399 EDT | MaxEsReturn               139
2017-07-02 15:02:52.880508 EDT | MinEsReturn                 3
2017-07-02 15:02:52.880617 EDT | AverageDiscountedReturn    99.9957
2017-07-02 15:02:52.880732 EDT | AverageQLoss                0.00467848
2017-07-02 15:02:52.880857 EDT | AveragePolicySurr          -1.25773
2017-07-02 15:02:52.880958 EDT | AverageQ                    1.20137
2017-07-02 15:02:52.881065 EDT | AverageAbsQ                 1.20457
2017-07-02 15:02:52.881175 EDT | AverageY                    1.20134
2017-07-02 15:02:52.881288 EDT | AverageAbsY                 1.20167
2017-07-02 15:02:52.881387 EDT | AverageAbsQYDiff            0.0173009
2017-07-02 15:02:52.881506 EDT | AverageAction               0.792527
2017-07-02 15:02:52.881640 EDT | PolicyRegParamNorm         63.0472
2017-07-02 15:02:52.881748 EDT | QFunRegParamNorm           61.6199
2017-07-02 15:02:52.881853 EDT | -----------------------  -------------
2017-07-02 15:02:52.882019 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #615 | Training started
2017-07-02 15:03:02.090618 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #615 | Training finished
2017-07-02 15:03:02.091103 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #615 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 15:03:02.091249 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #615 | Collecting samples for evaluation
2017-07-02 15:03:07.778611 EDT | -----------------------  -------------
2017-07-02 15:03:07.778788 EDT | Epoch                     615
2017-07-02 15:03:07.778901 EDT | Iteration                 615
2017-07-02 15:03:07.779053 EDT | AverageReturn             852.167
2017-07-02 15:03:07.779183 EDT | StdReturn                 271.505
2017-07-02 15:03:07.779354 EDT | MaxReturn                1000
2017-07-02 15:03:07.779488 EDT | MinReturn                 278
2017-07-02 15:03:07.779591 EDT | AverageEsReturn            64.625
2017-07-02 15:03:07.779724 EDT | StdEsReturn                59.5377
2017-07-02 15:03:07.779829 EDT | MaxEsReturn               232
2017-07-02 15:03:07.779930 EDT | MinEsReturn                 6
2017-07-02 15:03:07.780031 EDT | AverageDiscountedReturn    98.9965
2017-07-02 15:03:07.780178 EDT | AverageQLoss                0.00507315
2017-07-02 15:03:07.780285 EDT | AveragePolicySurr          -1.25115
2017-07-02 15:03:07.780432 EDT | AverageQ                    1.19155
2017-07-02 15:03:07.780566 EDT | AverageAbsQ                 1.19532
2017-07-02 15:03:07.780720 EDT | AverageY                    1.19158
2017-07-02 15:03:07.780830 EDT | AverageAbsY                 1.19207
2017-07-02 15:03:07.780956 EDT | AverageAbsQYDiff            0.0190541
2017-07-02 15:03:07.781057 EDT | AverageAction               0.731407
2017-07-02 15:03:07.781203 EDT | PolicyRegParamNorm         63.1025
2017-07-02 15:03:07.781308 EDT | QFunRegParamNorm           61.6406
2017-07-02 15:03:07.781467 EDT | -----------------------  -------------
2017-07-02 15:03:07.781732 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #616 | Training started
2017-07-02 15:03:17.137782 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #616 | Training finished
2017-07-02 15:03:17.138422 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #616 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 15:03:17.138680 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #616 | Collecting samples for evaluation
2017-07-02 15:03:22.633223 EDT | -----------------------  -------------
2017-07-02 15:03:22.633434 EDT | Epoch                     616
2017-07-02 15:03:22.633577 EDT | Iteration                 616
2017-07-02 15:03:22.633720 EDT | AverageReturn            1000
2017-07-02 15:03:22.633908 EDT | StdReturn                   0
2017-07-02 15:03:22.634068 EDT | MaxReturn                1000
2017-07-02 15:03:22.634264 EDT | MinReturn                1000
2017-07-02 15:03:22.634461 EDT | AverageEsReturn            27.8824
2017-07-02 15:03:22.634635 EDT | StdEsReturn                22.7696
2017-07-02 15:03:22.634790 EDT | MaxEsReturn               100
2017-07-02 15:03:22.634961 EDT | MinEsReturn                 3
2017-07-02 15:03:22.635180 EDT | AverageDiscountedReturn    99.9957
2017-07-02 15:03:22.635393 EDT | AverageQLoss                0.00525279
2017-07-02 15:03:22.635601 EDT | AveragePolicySurr          -1.24727
2017-07-02 15:03:22.635820 EDT | AverageQ                    1.19235
2017-07-02 15:03:22.636021 EDT | AverageAbsQ                 1.19642
2017-07-02 15:03:22.636248 EDT | AverageY                    1.19229
2017-07-02 15:03:22.636471 EDT | AverageAbsY                 1.19308
2017-07-02 15:03:22.636690 EDT | AverageAbsQYDiff            0.0192969
2017-07-02 15:03:22.636910 EDT | AverageAction               0.711945
2017-07-02 15:03:22.637122 EDT | PolicyRegParamNorm         63.0999
2017-07-02 15:03:22.637328 EDT | QFunRegParamNorm           61.6699
2017-07-02 15:03:22.638025 EDT | -----------------------  -------------
2017-07-02 15:03:22.638411 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #617 | Training started
2017-07-02 15:03:32.096375 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #617 | Training finished
2017-07-02 15:03:32.096984 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #617 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 15:03:32.097231 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #617 | Collecting samples for evaluation
2017-07-02 15:03:37.507980 EDT | -----------------------  -------------
2017-07-02 15:03:37.508298 EDT | Epoch                     617
2017-07-02 15:03:37.508465 EDT | Iteration                 617
2017-07-02 15:03:37.508572 EDT | AverageReturn            1000
2017-07-02 15:03:37.508673 EDT | StdReturn                   0
2017-07-02 15:03:37.508772 EDT | MaxReturn                1000
2017-07-02 15:03:37.508894 EDT | MinReturn                1000
2017-07-02 15:03:37.509026 EDT | AverageEsReturn            32.9062
2017-07-02 15:03:37.509130 EDT | StdEsReturn                20.5964
2017-07-02 15:03:37.509233 EDT | MaxEsReturn               107
2017-07-02 15:03:37.509364 EDT | MinEsReturn                 3
2017-07-02 15:03:37.509470 EDT | AverageDiscountedReturn    99.9957
2017-07-02 15:03:37.509594 EDT | AverageQLoss                0.00609133
2017-07-02 15:03:37.509719 EDT | AveragePolicySurr          -1.24741
2017-07-02 15:03:37.509867 EDT | AverageQ                    1.18877
2017-07-02 15:03:37.509978 EDT | AverageAbsQ                 1.19316
2017-07-02 15:03:37.510190 EDT | AverageY                    1.18874
2017-07-02 15:03:37.510476 EDT | AverageAbsY                 1.1894
2017-07-02 15:03:37.510697 EDT | AverageAbsQYDiff            0.0212063
2017-07-02 15:03:37.510911 EDT | AverageAction               0.833537
2017-07-02 15:03:37.511294 EDT | PolicyRegParamNorm         63.1137
2017-07-02 15:03:37.511518 EDT | QFunRegParamNorm           61.7082
2017-07-02 15:03:37.511693 EDT | -----------------------  -------------
2017-07-02 15:03:37.511960 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #618 | Training started
2017-07-02 15:03:46.918577 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #618 | Training finished
2017-07-02 15:03:46.919185 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #618 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 15:03:46.919389 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #618 | Collecting samples for evaluation
2017-07-02 15:03:52.436944 EDT | -----------------------  -------------
2017-07-02 15:03:52.437510 EDT | Epoch                     618
2017-07-02 15:03:52.437757 EDT | Iteration                 618
2017-07-02 15:03:52.437931 EDT | AverageReturn            1000
2017-07-02 15:03:52.438162 EDT | StdReturn                   0
2017-07-02 15:03:52.438389 EDT | MaxReturn                1000
2017-07-02 15:03:52.438613 EDT | MinReturn                1000
2017-07-02 15:03:52.439004 EDT | AverageEsReturn            26.8611
2017-07-02 15:03:52.439243 EDT | StdEsReturn                20.6332
2017-07-02 15:03:52.439480 EDT | MaxEsReturn                77
2017-07-02 15:03:52.439801 EDT | MinEsReturn                 3
2017-07-02 15:03:52.439911 EDT | AverageDiscountedReturn    99.9957
2017-07-02 15:03:52.440015 EDT | AverageQLoss                0.00437753
2017-07-02 15:03:52.440116 EDT | AveragePolicySurr          -1.24168
2017-07-02 15:03:52.440215 EDT | AverageQ                    1.18444
2017-07-02 15:03:52.440314 EDT | AverageAbsQ                 1.18825
2017-07-02 15:03:52.440465 EDT | AverageY                    1.18449
2017-07-02 15:03:52.440682 EDT | AverageAbsY                 1.18515
2017-07-02 15:03:52.440907 EDT | AverageAbsQYDiff            0.0179794
2017-07-02 15:03:52.441085 EDT | AverageAction               0.807641
2017-07-02 15:03:52.441228 EDT | PolicyRegParamNorm         63.156
2017-07-02 15:03:52.441444 EDT | QFunRegParamNorm           61.7416
2017-07-02 15:03:52.441698 EDT | -----------------------  -------------
2017-07-02 15:03:52.441963 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #619 | Training started
2017-07-02 15:04:01.821022 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #619 | Training finished
2017-07-02 15:04:01.821640 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #619 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 15:04:01.821868 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #619 | Collecting samples for evaluation
2017-07-02 15:04:07.365453 EDT | -----------------------  -------------
2017-07-02 15:04:07.365720 EDT | Epoch                     619
2017-07-02 15:04:07.365891 EDT | Iteration                 619
2017-07-02 15:04:07.366073 EDT | AverageReturn            1000
2017-07-02 15:04:07.366271 EDT | StdReturn                   0
2017-07-02 15:04:07.366402 EDT | MaxReturn                1000
2017-07-02 15:04:07.366515 EDT | MinReturn                1000
2017-07-02 15:04:07.366627 EDT | AverageEsReturn            36.2963
2017-07-02 15:04:07.366738 EDT | StdEsReturn                23.2965
2017-07-02 15:04:07.366844 EDT | MaxEsReturn                99
2017-07-02 15:04:07.366961 EDT | MinEsReturn                 3
2017-07-02 15:04:07.367079 EDT | AverageDiscountedReturn    99.9957
2017-07-02 15:04:07.367212 EDT | AverageQLoss                0.00430674
2017-07-02 15:04:07.367328 EDT | AveragePolicySurr          -1.23742
2017-07-02 15:04:07.367445 EDT | AverageQ                    1.18008
2017-07-02 15:04:07.367565 EDT | AverageAbsQ                 1.18365
2017-07-02 15:04:07.367665 EDT | AverageY                    1.18
2017-07-02 15:04:07.367795 EDT | AverageAbsY                 1.1806
2017-07-02 15:04:07.367918 EDT | AverageAbsQYDiff            0.0178299
2017-07-02 15:04:07.368019 EDT | AverageAction               0.740234
2017-07-02 15:04:07.368161 EDT | PolicyRegParamNorm         63.2584
2017-07-02 15:04:07.368307 EDT | QFunRegParamNorm           61.7507
2017-07-02 15:04:07.368476 EDT | -----------------------  -------------
2017-07-02 15:04:07.368689 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #620 | Training started
2017-07-02 15:04:16.590488 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #620 | Training finished
2017-07-02 15:04:16.590989 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #620 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 15:04:16.591168 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #620 | Collecting samples for evaluation
2017-07-02 15:04:22.169043 EDT | -----------------------  -------------
2017-07-02 15:04:22.169364 EDT | Epoch                     620
2017-07-02 15:04:22.169610 EDT | Iteration                 620
2017-07-02 15:04:22.169829 EDT | AverageReturn            1000
2017-07-02 15:04:22.170040 EDT | StdReturn                   0
2017-07-02 15:04:22.170171 EDT | MaxReturn                1000
2017-07-02 15:04:22.170321 EDT | MinReturn                1000
2017-07-02 15:04:22.170428 EDT | AverageEsReturn            37.4074
2017-07-02 15:04:22.170545 EDT | StdEsReturn                32.3525
2017-07-02 15:04:22.170645 EDT | MaxEsReturn               146
2017-07-02 15:04:22.170745 EDT | MinEsReturn                 3
2017-07-02 15:04:22.170868 EDT | AverageDiscountedReturn    99.9957
2017-07-02 15:04:22.170969 EDT | AverageQLoss                0.00507591
2017-07-02 15:04:22.171165 EDT | AveragePolicySurr          -1.23523
2017-07-02 15:04:22.171386 EDT | AverageQ                    1.17813
2017-07-02 15:04:22.171584 EDT | AverageAbsQ                 1.18134
2017-07-02 15:04:22.171800 EDT | AverageY                    1.17802
2017-07-02 15:04:22.172012 EDT | AverageAbsY                 1.17853
2017-07-02 15:04:22.172236 EDT | AverageAbsQYDiff            0.0188656
2017-07-02 15:04:22.172408 EDT | AverageAction               0.755919
2017-07-02 15:04:22.172627 EDT | PolicyRegParamNorm         63.2707
2017-07-02 15:04:22.172762 EDT | QFunRegParamNorm           61.7549
2017-07-02 15:04:22.172983 EDT | -----------------------  -------------
2017-07-02 15:04:22.173255 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #621 | Training started
2017-07-02 15:04:31.465958 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #621 | Training finished
2017-07-02 15:04:31.466456 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #621 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 15:04:31.466598 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #621 | Collecting samples for evaluation
2017-07-02 15:04:37.015118 EDT | -----------------------  -------------
2017-07-02 15:04:37.015435 EDT | Epoch                     621
2017-07-02 15:04:37.015611 EDT | Iteration                 621
2017-07-02 15:04:37.015839 EDT | AverageReturn            1000
2017-07-02 15:04:37.016057 EDT | StdReturn                   0
2017-07-02 15:04:37.016274 EDT | MaxReturn                1000
2017-07-02 15:04:37.016567 EDT | MinReturn                1000
2017-07-02 15:04:37.016782 EDT | AverageEsReturn            38.6923
2017-07-02 15:04:37.017010 EDT | StdEsReturn                32.3393
2017-07-02 15:04:37.017238 EDT | MaxEsReturn               142
2017-07-02 15:04:37.017447 EDT | MinEsReturn                 3
2017-07-02 15:04:37.017700 EDT | AverageDiscountedReturn    99.9957
2017-07-02 15:04:37.017856 EDT | AverageQLoss                0.00515449
2017-07-02 15:04:37.017971 EDT | AveragePolicySurr          -1.23181
2017-07-02 15:04:37.018206 EDT | AverageQ                    1.17858
2017-07-02 15:04:37.018362 EDT | AverageAbsQ                 1.18203
2017-07-02 15:04:37.018474 EDT | AverageY                    1.17857
2017-07-02 15:04:37.018669 EDT | AverageAbsY                 1.17903
2017-07-02 15:04:37.018891 EDT | AverageAbsQYDiff            0.0195012
2017-07-02 15:04:37.019055 EDT | AverageAction               0.763315
2017-07-02 15:04:37.019169 EDT | PolicyRegParamNorm         63.2971
2017-07-02 15:04:37.019302 EDT | QFunRegParamNorm           61.792
2017-07-02 15:04:37.019427 EDT | -----------------------  -------------
2017-07-02 15:04:37.019625 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #622 | Training started
2017-07-02 15:04:46.415437 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #622 | Training finished
2017-07-02 15:04:46.415922 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #622 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 15:04:46.416074 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #622 | Collecting samples for evaluation
2017-07-02 15:04:51.961113 EDT | -----------------------  -------------
2017-07-02 15:04:51.961431 EDT | Epoch                     622
2017-07-02 15:04:51.961921 EDT | Iteration                 622
2017-07-02 15:04:51.962605 EDT | AverageReturn            1000
2017-07-02 15:04:51.962842 EDT | StdReturn                   0
2017-07-02 15:04:51.963073 EDT | MaxReturn                1000
2017-07-02 15:04:51.963250 EDT | MinReturn                1000
2017-07-02 15:04:51.963469 EDT | AverageEsReturn            33.4667
2017-07-02 15:04:51.963630 EDT | StdEsReturn                28.6365
2017-07-02 15:04:51.963856 EDT | MaxEsReturn               129
2017-07-02 15:04:51.964049 EDT | MinEsReturn                 3
2017-07-02 15:04:51.964155 EDT | AverageDiscountedReturn    99.9957
2017-07-02 15:04:51.964256 EDT | AverageQLoss                0.00528812
2017-07-02 15:04:51.964357 EDT | AveragePolicySurr          -1.22698
2017-07-02 15:04:51.964503 EDT | AverageQ                    1.16881
2017-07-02 15:04:51.964720 EDT | AverageAbsQ                 1.17223
2017-07-02 15:04:51.964912 EDT | AverageY                    1.16877
2017-07-02 15:04:51.965077 EDT | AverageAbsY                 1.16912
2017-07-02 15:04:51.965250 EDT | AverageAbsQYDiff            0.0192141
2017-07-02 15:04:51.965373 EDT | AverageAction               0.767193
2017-07-02 15:04:51.965475 EDT | PolicyRegParamNorm         63.3508
2017-07-02 15:04:51.965613 EDT | QFunRegParamNorm           61.7988
2017-07-02 15:04:51.965743 EDT | -----------------------  -------------
2017-07-02 15:04:51.965919 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #623 | Training started
2017-07-02 15:05:01.243108 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #623 | Training finished
2017-07-02 15:05:01.243959 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #623 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 15:05:01.244172 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #623 | Collecting samples for evaluation
2017-07-02 15:05:06.758801 EDT | -----------------------  -------------
2017-07-02 15:05:06.758993 EDT | Epoch                     623
2017-07-02 15:05:06.759106 EDT | Iteration                 623
2017-07-02 15:05:06.759210 EDT | AverageReturn            1000
2017-07-02 15:05:06.759363 EDT | StdReturn                   0
2017-07-02 15:05:06.759509 EDT | MaxReturn                1000
2017-07-02 15:05:06.759613 EDT | MinReturn                1000
2017-07-02 15:05:06.759715 EDT | AverageEsReturn            37.7778
2017-07-02 15:05:06.759847 EDT | StdEsReturn                30.7912
2017-07-02 15:05:06.760043 EDT | MaxEsReturn               150
2017-07-02 15:05:06.760240 EDT | MinEsReturn                 4
2017-07-02 15:05:06.760351 EDT | AverageDiscountedReturn    99.9957
2017-07-02 15:05:06.760458 EDT | AverageQLoss                0.00540792
2017-07-02 15:05:06.760615 EDT | AveragePolicySurr          -1.22326
2017-07-02 15:05:06.760750 EDT | AverageQ                    1.16844
2017-07-02 15:05:06.760855 EDT | AverageAbsQ                 1.17246
2017-07-02 15:05:06.760959 EDT | AverageY                    1.16845
2017-07-02 15:05:06.761063 EDT | AverageAbsY                 1.16898
2017-07-02 15:05:06.761167 EDT | AverageAbsQYDiff            0.0201364
2017-07-02 15:05:06.761270 EDT | AverageAction               0.662431
2017-07-02 15:05:06.761374 EDT | PolicyRegParamNorm         63.3525
2017-07-02 15:05:06.761477 EDT | QFunRegParamNorm           61.8212
2017-07-02 15:05:06.761704 EDT | -----------------------  -------------
2017-07-02 15:05:06.762024 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #624 | Training started
2017-07-02 15:05:16.076080 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #624 | Training finished
2017-07-02 15:05:16.076594 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #624 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 15:05:16.076959 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #624 | Collecting samples for evaluation
2017-07-02 15:05:22.018636 EDT | -----------------------  -------------
2017-07-02 15:05:22.018925 EDT | Epoch                     624
2017-07-02 15:05:22.019112 EDT | Iteration                 624
2017-07-02 15:05:22.019268 EDT | AverageReturn            1000
2017-07-02 15:05:22.019470 EDT | StdReturn                   0
2017-07-02 15:05:22.019615 EDT | MaxReturn                1000
2017-07-02 15:05:22.019719 EDT | MinReturn                1000
2017-07-02 15:05:22.019884 EDT | AverageEsReturn            35.9643
2017-07-02 15:05:22.020046 EDT | StdEsReturn                26.6652
2017-07-02 15:05:22.020195 EDT | MaxEsReturn               107
2017-07-02 15:05:22.020295 EDT | MinEsReturn                 3
2017-07-02 15:05:22.020391 EDT | AverageDiscountedReturn    99.9957
2017-07-02 15:05:22.020499 EDT | AverageQLoss                0.00484603
2017-07-02 15:05:22.020627 EDT | AveragePolicySurr          -1.21888
2017-07-02 15:05:22.020766 EDT | AverageQ                    1.16368
2017-07-02 15:05:22.020905 EDT | AverageAbsQ                 1.16745
2017-07-02 15:05:22.021008 EDT | AverageY                    1.1637
2017-07-02 15:05:22.021107 EDT | AverageAbsY                 1.1644
2017-07-02 15:05:22.021206 EDT | AverageAbsQYDiff            0.0183654
2017-07-02 15:05:22.021304 EDT | AverageAction               0.754099
2017-07-02 15:05:22.021435 EDT | PolicyRegParamNorm         63.3835
2017-07-02 15:05:22.021706 EDT | QFunRegParamNorm           61.8528
2017-07-02 15:05:22.021978 EDT | -----------------------  -------------
2017-07-02 15:05:22.022954 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #625 | Training started
2017-07-02 15:05:31.346733 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #625 | Training finished
2017-07-02 15:05:31.347814 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #625 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 15:05:31.348061 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #625 | Collecting samples for evaluation
2017-07-02 15:05:36.874276 EDT | -----------------------  -------------
2017-07-02 15:05:36.874467 EDT | Epoch                     625
2017-07-02 15:05:36.874578 EDT | Iteration                 625
2017-07-02 15:05:36.874682 EDT | AverageReturn            1000
2017-07-02 15:05:36.874813 EDT | StdReturn                   0
2017-07-02 15:05:36.874915 EDT | MaxReturn                1000
2017-07-02 15:05:36.875024 EDT | MinReturn                1000
2017-07-02 15:05:36.875124 EDT | AverageEsReturn            33.2
2017-07-02 15:05:36.875224 EDT | StdEsReturn                21.1241
2017-07-02 15:05:36.875324 EDT | MaxEsReturn                97
2017-07-02 15:05:36.875424 EDT | MinEsReturn                 4
2017-07-02 15:05:36.875573 EDT | AverageDiscountedReturn    99.9957
2017-07-02 15:05:36.875674 EDT | AverageQLoss                0.00462487
2017-07-02 15:05:36.875800 EDT | AveragePolicySurr          -1.21883
2017-07-02 15:05:36.875902 EDT | AverageQ                    1.16173
2017-07-02 15:05:36.876002 EDT | AverageAbsQ                 1.16518
2017-07-02 15:05:36.876102 EDT | AverageY                    1.16161
2017-07-02 15:05:36.876202 EDT | AverageAbsY                 1.16228
2017-07-02 15:05:36.876313 EDT | AverageAbsQYDiff            0.0180441
2017-07-02 15:05:36.876491 EDT | AverageAction               0.781581
2017-07-02 15:05:36.876671 EDT | PolicyRegParamNorm         63.3917
2017-07-02 15:05:36.876870 EDT | QFunRegParamNorm           61.8596
2017-07-02 15:05:36.876992 EDT | -----------------------  -------------
2017-07-02 15:05:36.877161 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #626 | Training started
2017-07-02 15:05:46.310198 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #626 | Training finished
2017-07-02 15:05:46.310742 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #626 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 15:05:46.310997 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #626 | Collecting samples for evaluation
2017-07-02 15:05:51.761245 EDT | -----------------------  -------------
2017-07-02 15:05:51.761568 EDT | Epoch                     626
2017-07-02 15:05:51.761809 EDT | Iteration                 626
2017-07-02 15:05:51.762022 EDT | AverageReturn            1000
2017-07-02 15:05:51.762253 EDT | StdReturn                   0
2017-07-02 15:05:51.762471 EDT | MaxReturn                1000
2017-07-02 15:05:51.762703 EDT | MinReturn                1000
2017-07-02 15:05:51.762906 EDT | AverageEsReturn            25.5128
2017-07-02 15:05:51.763118 EDT | StdEsReturn                26.8422
2017-07-02 15:05:51.763342 EDT | MaxEsReturn               110
2017-07-02 15:05:51.763530 EDT | MinEsReturn                 3
2017-07-02 15:05:51.763759 EDT | AverageDiscountedReturn    99.9957
2017-07-02 15:05:51.763950 EDT | AverageQLoss                0.00570525
2017-07-02 15:05:51.764163 EDT | AveragePolicySurr          -1.2121
2017-07-02 15:05:51.764388 EDT | AverageQ                    1.15466
2017-07-02 15:05:51.764566 EDT | AverageAbsQ                 1.15829
2017-07-02 15:05:51.764795 EDT | AverageY                    1.15463
2017-07-02 15:05:51.764966 EDT | AverageAbsY                 1.15536
2017-07-02 15:05:51.765175 EDT | AverageAbsQYDiff            0.0205707
2017-07-02 15:05:51.765400 EDT | AverageAction               0.633186
2017-07-02 15:05:51.765834 EDT | PolicyRegParamNorm         63.3749
2017-07-02 15:05:51.766034 EDT | QFunRegParamNorm           61.8664
2017-07-02 15:05:51.766265 EDT | -----------------------  -------------
2017-07-02 15:05:51.766582 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #627 | Training started
2017-07-02 15:06:01.179512 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #627 | Training finished
2017-07-02 15:06:01.180612 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #627 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 15:06:01.180847 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #627 | Collecting samples for evaluation
2017-07-02 15:06:06.628264 EDT | -----------------------  -------------
2017-07-02 15:06:06.628565 EDT | Epoch                     627
2017-07-02 15:06:06.628800 EDT | Iteration                 627
2017-07-02 15:06:06.629017 EDT | AverageReturn            1000
2017-07-02 15:06:06.629234 EDT | StdReturn                   0
2017-07-02 15:06:06.629463 EDT | MaxReturn                1000
2017-07-02 15:06:06.629689 EDT | MinReturn                1000
2017-07-02 15:06:06.629920 EDT | AverageEsReturn            24.0952
2017-07-02 15:06:06.630120 EDT | StdEsReturn                19.8108
2017-07-02 15:06:06.630344 EDT | MaxEsReturn                95
2017-07-02 15:06:06.630567 EDT | MinEsReturn                 3
2017-07-02 15:06:06.630728 EDT | AverageDiscountedReturn    99.9957
2017-07-02 15:06:06.630958 EDT | AverageQLoss                0.00428867
2017-07-02 15:06:06.631149 EDT | AveragePolicySurr          -1.20929
2017-07-02 15:06:06.631386 EDT | AverageQ                    1.15526
2017-07-02 15:06:06.631591 EDT | AverageAbsQ                 1.1591
2017-07-02 15:06:06.631792 EDT | AverageY                    1.15525
2017-07-02 15:06:06.632018 EDT | AverageAbsY                 1.15593
2017-07-02 15:06:06.632186 EDT | AverageAbsQYDiff            0.0175106
2017-07-02 15:06:06.632416 EDT | AverageAction               0.647507
2017-07-02 15:06:06.632612 EDT | PolicyRegParamNorm         63.3776
2017-07-02 15:06:06.632841 EDT | QFunRegParamNorm           61.8825
2017-07-02 15:06:06.633054 EDT | -----------------------  -------------
2017-07-02 15:06:06.633255 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #628 | Training started
2017-07-02 15:06:16.041221 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #628 | Training finished
2017-07-02 15:06:16.041847 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #628 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 15:06:16.042022 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #628 | Collecting samples for evaluation
2017-07-02 15:06:21.473434 EDT | -----------------------  -------------
2017-07-02 15:06:21.473713 EDT | Epoch                     628
2017-07-02 15:06:21.473884 EDT | Iteration                 628
2017-07-02 15:06:21.474058 EDT | AverageReturn            1000
2017-07-02 15:06:21.474223 EDT | StdReturn                   0
2017-07-02 15:06:21.474370 EDT | MaxReturn                1000
2017-07-02 15:06:21.474547 EDT | MinReturn                1000
2017-07-02 15:06:21.474708 EDT | AverageEsReturn            22.7045
2017-07-02 15:06:21.474915 EDT | StdEsReturn                21.0719
2017-07-02 15:06:21.475132 EDT | MaxEsReturn                93
2017-07-02 15:06:21.475341 EDT | MinEsReturn                 3
2017-07-02 15:06:21.475561 EDT | AverageDiscountedReturn    99.9957
2017-07-02 15:06:21.475781 EDT | AverageQLoss                0.00494321
2017-07-02 15:06:21.476012 EDT | AveragePolicySurr          -1.20994
2017-07-02 15:06:21.476233 EDT | AverageQ                    1.15343
2017-07-02 15:06:21.476449 EDT | AverageAbsQ                 1.15725
2017-07-02 15:06:21.476607 EDT | AverageY                    1.1534
2017-07-02 15:06:21.476770 EDT | AverageAbsY                 1.15407
2017-07-02 15:06:21.476991 EDT | AverageAbsQYDiff            0.0194682
2017-07-02 15:06:21.477106 EDT | AverageAction               0.529877
2017-07-02 15:06:21.477220 EDT | PolicyRegParamNorm         63.4191
2017-07-02 15:06:21.477351 EDT | QFunRegParamNorm           61.9119
2017-07-02 15:06:21.477503 EDT | -----------------------  -------------
2017-07-02 15:06:21.477731 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #629 | Training started
2017-07-02 15:06:30.832604 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #629 | Training finished
2017-07-02 15:06:30.833118 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #629 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 15:06:30.833314 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #629 | Collecting samples for evaluation
2017-07-02 15:06:36.362003 EDT | -----------------------  -------------
2017-07-02 15:06:36.362256 EDT | Epoch                     629
2017-07-02 15:06:36.362412 EDT | Iteration                 629
2017-07-02 15:06:36.362580 EDT | AverageReturn            1000
2017-07-02 15:06:36.362753 EDT | StdReturn                   0
2017-07-02 15:06:36.362885 EDT | MaxReturn                1000
2017-07-02 15:06:36.362989 EDT | MinReturn                1000
2017-07-02 15:06:36.363131 EDT | AverageEsReturn            24.675
2017-07-02 15:06:36.363235 EDT | StdEsReturn                18.822
2017-07-02 15:06:36.363340 EDT | MaxEsReturn                90
2017-07-02 15:06:36.363483 EDT | MinEsReturn                 3
2017-07-02 15:06:36.363620 EDT | AverageDiscountedReturn    99.9957
2017-07-02 15:06:36.363743 EDT | AverageQLoss                0.00456744
2017-07-02 15:06:36.363845 EDT | AveragePolicySurr          -1.20457
2017-07-02 15:06:36.363952 EDT | AverageQ                    1.14798
2017-07-02 15:06:36.364080 EDT | AverageAbsQ                 1.15158
2017-07-02 15:06:36.364185 EDT | AverageY                    1.14802
2017-07-02 15:06:36.364301 EDT | AverageAbsY                 1.14864
2017-07-02 15:06:36.364445 EDT | AverageAbsQYDiff            0.01799
2017-07-02 15:06:36.364592 EDT | AverageAction               0.40635
2017-07-02 15:06:36.364734 EDT | PolicyRegParamNorm         63.4548
2017-07-02 15:06:36.364846 EDT | QFunRegParamNorm           61.928
2017-07-02 15:06:36.364952 EDT | -----------------------  -------------
2017-07-02 15:06:36.365110 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #630 | Training started
2017-07-02 15:06:45.617831 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #630 | Training finished
2017-07-02 15:06:45.618436 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #630 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 15:06:45.618578 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #630 | Collecting samples for evaluation
2017-07-02 15:06:51.131234 EDT | -----------------------  -------------
2017-07-02 15:06:51.131538 EDT | Epoch                     630
2017-07-02 15:06:51.131776 EDT | Iteration                 630
2017-07-02 15:06:51.132003 EDT | AverageReturn            1000
2017-07-02 15:06:51.132228 EDT | StdReturn                   0
2017-07-02 15:06:51.132444 EDT | MaxReturn                1000
2017-07-02 15:06:51.132650 EDT | MinReturn                1000
2017-07-02 15:06:51.132877 EDT | AverageEsReturn            25.3077
2017-07-02 15:06:51.133023 EDT | StdEsReturn                25.2537
2017-07-02 15:06:51.133198 EDT | MaxEsReturn                88
2017-07-02 15:06:51.133303 EDT | MinEsReturn                 3
2017-07-02 15:06:51.133460 EDT | AverageDiscountedReturn    99.9957
2017-07-02 15:06:51.133801 EDT | AverageQLoss                0.00546224
2017-07-02 15:06:51.134029 EDT | AveragePolicySurr          -1.20104
2017-07-02 15:06:51.134224 EDT | AverageQ                    1.14718
2017-07-02 15:06:51.134455 EDT | AverageAbsQ                 1.15105
2017-07-02 15:06:51.134679 EDT | AverageY                    1.14711
2017-07-02 15:06:51.134902 EDT | AverageAbsY                 1.14775
2017-07-02 15:06:51.135119 EDT | AverageAbsQYDiff            0.0199885
2017-07-02 15:06:51.135329 EDT | AverageAction               0.69812
2017-07-02 15:06:51.135550 EDT | PolicyRegParamNorm         63.488
2017-07-02 15:06:51.135689 EDT | QFunRegParamNorm           61.9377
2017-07-02 15:06:51.135921 EDT | -----------------------  -------------
2017-07-02 15:06:51.136243 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #631 | Training started
2017-07-02 15:07:00.419780 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #631 | Training finished
2017-07-02 15:07:00.420315 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #631 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 15:07:00.420498 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #631 | Collecting samples for evaluation
2017-07-02 15:07:05.874223 EDT | -----------------------  -------------
2017-07-02 15:07:05.874578 EDT | Epoch                     631
2017-07-02 15:07:05.874902 EDT | Iteration                 631
2017-07-02 15:07:05.875125 EDT | AverageReturn            1000
2017-07-02 15:07:05.875357 EDT | StdReturn                   0
2017-07-02 15:07:05.875600 EDT | MaxReturn                1000
2017-07-02 15:07:05.875836 EDT | MinReturn                1000
2017-07-02 15:07:05.876079 EDT | AverageEsReturn            33.0968
2017-07-02 15:07:05.876239 EDT | StdEsReturn                26.7899
2017-07-02 15:07:05.876353 EDT | MaxEsReturn               107
2017-07-02 15:07:05.876590 EDT | MinEsReturn                 3
2017-07-02 15:07:05.876820 EDT | AverageDiscountedReturn    99.9957
2017-07-02 15:07:05.877025 EDT | AverageQLoss                0.00554655
2017-07-02 15:07:05.877269 EDT | AveragePolicySurr          -1.19832
2017-07-02 15:07:05.877502 EDT | AverageQ                    1.14167
2017-07-02 15:07:05.877697 EDT | AverageAbsQ                 1.14533
2017-07-02 15:07:05.877930 EDT | AverageY                    1.1417
2017-07-02 15:07:05.878151 EDT | AverageAbsY                 1.14236
2017-07-02 15:07:05.878327 EDT | AverageAbsQYDiff            0.020446
2017-07-02 15:07:05.878570 EDT | AverageAction               0.445226
2017-07-02 15:07:05.878806 EDT | PolicyRegParamNorm         63.4772
2017-07-02 15:07:05.878993 EDT | QFunRegParamNorm           61.9794
2017-07-02 15:07:05.879231 EDT | -----------------------  -------------
2017-07-02 15:07:05.879540 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #632 | Training started
2017-07-02 15:07:15.232057 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #632 | Training finished
2017-07-02 15:07:15.232760 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #632 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 15:07:15.233168 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #632 | Collecting samples for evaluation
2017-07-02 15:07:20.657471 EDT | -----------------------  ------------
2017-07-02 15:07:20.657692 EDT | Epoch                     632
2017-07-02 15:07:20.657804 EDT | Iteration                 632
2017-07-02 15:07:20.657972 EDT | AverageReturn            1000
2017-07-02 15:07:20.658125 EDT | StdReturn                   0
2017-07-02 15:07:20.658274 EDT | MaxReturn                1000
2017-07-02 15:07:20.658424 EDT | MinReturn                1000
2017-07-02 15:07:20.658594 EDT | AverageEsReturn            22.75
2017-07-02 15:07:20.658761 EDT | StdEsReturn                23.7249
2017-07-02 15:07:20.658864 EDT | MaxEsReturn               122
2017-07-02 15:07:20.659051 EDT | MinEsReturn                 3
2017-07-02 15:07:20.659184 EDT | AverageDiscountedReturn    99.9957
2017-07-02 15:07:20.659286 EDT | AverageQLoss                0.0057212
2017-07-02 15:07:20.659387 EDT | AveragePolicySurr          -1.19326
2017-07-02 15:07:20.659521 EDT | AverageQ                    1.13557
2017-07-02 15:07:20.659621 EDT | AverageAbsQ                 1.13964
2017-07-02 15:07:20.659764 EDT | AverageY                    1.13555
2017-07-02 15:07:20.659911 EDT | AverageAbsY                 1.13596
2017-07-02 15:07:20.660076 EDT | AverageAbsQYDiff            0.0215196
2017-07-02 15:07:20.660182 EDT | AverageAction               0.329166
2017-07-02 15:07:20.660284 EDT | PolicyRegParamNorm         63.4817
2017-07-02 15:07:20.660408 EDT | QFunRegParamNorm           62.0067
2017-07-02 15:07:20.660509 EDT | -----------------------  ------------
2017-07-02 15:07:20.660690 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #633 | Training started
2017-07-02 15:07:30.169391 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #633 | Training finished
2017-07-02 15:07:30.170203 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #633 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 15:07:30.170438 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #633 | Collecting samples for evaluation
2017-07-02 15:07:35.692141 EDT | -----------------------  -------------
2017-07-02 15:07:35.692379 EDT | Epoch                     633
2017-07-02 15:07:35.692508 EDT | Iteration                 633
2017-07-02 15:07:35.692614 EDT | AverageReturn            1000
2017-07-02 15:07:35.692715 EDT | StdReturn                   0
2017-07-02 15:07:35.692877 EDT | MaxReturn                1000
2017-07-02 15:07:35.693074 EDT | MinReturn                1000
2017-07-02 15:07:35.693195 EDT | AverageEsReturn            23.5238
2017-07-02 15:07:35.693396 EDT | StdEsReturn                19.7391
2017-07-02 15:07:35.693634 EDT | MaxEsReturn                72
2017-07-02 15:07:35.693861 EDT | MinEsReturn                 3
2017-07-02 15:07:35.694085 EDT | AverageDiscountedReturn    99.9957
2017-07-02 15:07:35.694314 EDT | AverageQLoss                0.00504892
2017-07-02 15:07:35.694525 EDT | AveragePolicySurr          -1.19514
2017-07-02 15:07:35.694757 EDT | AverageQ                    1.13831
2017-07-02 15:07:35.694969 EDT | AverageAbsQ                 1.14148
2017-07-02 15:07:35.695188 EDT | AverageY                    1.13836
2017-07-02 15:07:35.695396 EDT | AverageAbsY                 1.13885
2017-07-02 15:07:35.695628 EDT | AverageAbsQYDiff            0.0190878
2017-07-02 15:07:35.695816 EDT | AverageAction               0.180679
2017-07-02 15:07:35.696043 EDT | PolicyRegParamNorm         63.4722
2017-07-02 15:07:35.696259 EDT | QFunRegParamNorm           62.0352
2017-07-02 15:07:35.696544 EDT | -----------------------  -------------
2017-07-02 15:07:35.696868 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #634 | Training started
2017-07-02 15:07:45.108342 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #634 | Training finished
2017-07-02 15:07:45.108954 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #634 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 15:07:45.109195 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #634 | Collecting samples for evaluation
2017-07-02 15:07:50.628043 EDT | -----------------------  -------------
2017-07-02 15:07:50.628246 EDT | Epoch                     634
2017-07-02 15:07:50.628468 EDT | Iteration                 634
2017-07-02 15:07:50.628679 EDT | AverageReturn            1000
2017-07-02 15:07:50.628908 EDT | StdReturn                   0
2017-07-02 15:07:50.629134 EDT | MaxReturn                1000
2017-07-02 15:07:50.629365 EDT | MinReturn                1000
2017-07-02 15:07:50.629594 EDT | AverageEsReturn            17.4828
2017-07-02 15:07:50.629825 EDT | StdEsReturn                14.2759
2017-07-02 15:07:50.630037 EDT | MaxEsReturn                62
2017-07-02 15:07:50.630263 EDT | MinEsReturn                 3
2017-07-02 15:07:50.630479 EDT | AverageDiscountedReturn    99.9957
2017-07-02 15:07:50.630712 EDT | AverageQLoss                0.00473555
2017-07-02 15:07:50.630925 EDT | AveragePolicySurr          -1.19177
2017-07-02 15:07:50.631145 EDT | AverageQ                    1.1367
2017-07-02 15:07:50.631366 EDT | AverageAbsQ                 1.14055
2017-07-02 15:07:50.631594 EDT | AverageY                    1.13663
2017-07-02 15:07:50.631807 EDT | AverageAbsY                 1.13715
2017-07-02 15:07:50.632016 EDT | AverageAbsQYDiff            0.0186223
2017-07-02 15:07:50.632243 EDT | AverageAction               0.387915
2017-07-02 15:07:50.632468 EDT | PolicyRegParamNorm         63.4797
2017-07-02 15:07:50.632633 EDT | QFunRegParamNorm           62.0598
2017-07-02 15:07:50.632737 EDT | -----------------------  -------------
2017-07-02 15:07:50.632900 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #635 | Training started
2017-07-02 15:07:59.914589 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #635 | Training finished
2017-07-02 15:07:59.915111 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #635 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 15:07:59.915289 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #635 | Collecting samples for evaluation
2017-07-02 15:08:05.371484 EDT | -----------------------  -------------
2017-07-02 15:08:05.371726 EDT | Epoch                     635
2017-07-02 15:08:05.371838 EDT | Iteration                 635
2017-07-02 15:08:05.371944 EDT | AverageReturn            1000
2017-07-02 15:08:05.372105 EDT | StdReturn                   0
2017-07-02 15:08:05.372245 EDT | MaxReturn                1000
2017-07-02 15:08:05.372354 EDT | MinReturn                1000
2017-07-02 15:08:05.372457 EDT | AverageEsReturn            13.5479
2017-07-02 15:08:05.372555 EDT | StdEsReturn                10.2704
2017-07-02 15:08:05.372654 EDT | MaxEsReturn                44
2017-07-02 15:08:05.372769 EDT | MinEsReturn                 3
2017-07-02 15:08:05.372913 EDT | AverageDiscountedReturn    99.9957
2017-07-02 15:08:05.373014 EDT | AverageQLoss                0.00472017
2017-07-02 15:08:05.373113 EDT | AveragePolicySurr          -1.19039
2017-07-02 15:08:05.373222 EDT | AverageQ                    1.13277
2017-07-02 15:08:05.373381 EDT | AverageAbsQ                 1.13585
2017-07-02 15:08:05.373500 EDT | AverageY                    1.13282
2017-07-02 15:08:05.373605 EDT | AverageAbsY                 1.13336
2017-07-02 15:08:05.373774 EDT | AverageAbsQYDiff            0.0180174
2017-07-02 15:08:05.373962 EDT | AverageAction               0.481212
2017-07-02 15:08:05.374083 EDT | PolicyRegParamNorm         63.4942
2017-07-02 15:08:05.374184 EDT | QFunRegParamNorm           62.0818
2017-07-02 15:08:05.374284 EDT | -----------------------  -------------
2017-07-02 15:08:05.374494 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #636 | Training started
2017-07-02 15:08:14.712702 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #636 | Training finished
2017-07-02 15:08:14.713214 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #636 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 15:08:14.713466 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #636 | Collecting samples for evaluation
2017-07-02 15:08:20.244636 EDT | -----------------------  -------------
2017-07-02 15:08:20.244959 EDT | Epoch                     636
2017-07-02 15:08:20.245091 EDT | Iteration                 636
2017-07-02 15:08:20.245255 EDT | AverageReturn            1000
2017-07-02 15:08:20.245485 EDT | StdReturn                   0
2017-07-02 15:08:20.245691 EDT | MaxReturn                1000
2017-07-02 15:08:20.245830 EDT | MinReturn                1000
2017-07-02 15:08:20.246058 EDT | AverageEsReturn            20.5833
2017-07-02 15:08:20.246269 EDT | StdEsReturn                14.0888
2017-07-02 15:08:20.246472 EDT | MaxEsReturn                54
2017-07-02 15:08:20.246704 EDT | MinEsReturn                 3
2017-07-02 15:08:20.246920 EDT | AverageDiscountedReturn    99.9957
2017-07-02 15:08:20.247142 EDT | AverageQLoss                0.00487864
2017-07-02 15:08:20.247369 EDT | AveragePolicySurr          -1.19176
2017-07-02 15:08:20.247554 EDT | AverageQ                    1.13397
2017-07-02 15:08:20.247779 EDT | AverageAbsQ                 1.13722
2017-07-02 15:08:20.247950 EDT | AverageY                    1.13391
2017-07-02 15:08:20.248176 EDT | AverageAbsY                 1.13435
2017-07-02 15:08:20.248399 EDT | AverageAbsQYDiff            0.0185745
2017-07-02 15:08:20.248601 EDT | AverageAction               0.0466516
2017-07-02 15:08:20.248827 EDT | PolicyRegParamNorm         63.5293
2017-07-02 15:08:20.248984 EDT | QFunRegParamNorm           62.1152
2017-07-02 15:08:20.249211 EDT | -----------------------  -------------
2017-07-02 15:08:20.249595 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #637 | Training started
2017-07-02 15:08:29.573813 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #637 | Training finished
2017-07-02 15:08:29.574471 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #637 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 15:08:29.574747 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #637 | Collecting samples for evaluation
2017-07-02 15:08:35.090929 EDT | -----------------------  -------------
2017-07-02 15:08:35.091170 EDT | Epoch                     637
2017-07-02 15:08:35.091398 EDT | Iteration                 637
2017-07-02 15:08:35.091627 EDT | AverageReturn            1000
2017-07-02 15:08:35.091833 EDT | StdReturn                   0
2017-07-02 15:08:35.091956 EDT | MaxReturn                1000
2017-07-02 15:08:35.092060 EDT | MinReturn                1000
2017-07-02 15:08:35.092161 EDT | AverageEsReturn            16.1111
2017-07-02 15:08:35.092308 EDT | StdEsReturn                15.3738
2017-07-02 15:08:35.092438 EDT | MaxEsReturn                70
2017-07-02 15:08:35.092552 EDT | MinEsReturn                 3
2017-07-02 15:08:35.092679 EDT | AverageDiscountedReturn    99.9957
2017-07-02 15:08:35.092834 EDT | AverageQLoss                0.00506829
2017-07-02 15:08:35.092936 EDT | AveragePolicySurr          -1.18532
2017-07-02 15:08:35.093035 EDT | AverageQ                    1.12973
2017-07-02 15:08:35.093135 EDT | AverageAbsQ                 1.13322
2017-07-02 15:08:35.093232 EDT | AverageY                    1.12965
2017-07-02 15:08:35.093330 EDT | AverageAbsY                 1.1301
2017-07-02 15:08:35.093570 EDT | AverageAbsQYDiff            0.0201123
2017-07-02 15:08:35.093705 EDT | AverageAction               0.363121
2017-07-02 15:08:35.093831 EDT | PolicyRegParamNorm         63.5911
2017-07-02 15:08:35.093983 EDT | QFunRegParamNorm           62.1203
2017-07-02 15:08:35.094087 EDT | -----------------------  -------------
2017-07-02 15:08:35.094268 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #638 | Training started
2017-07-02 15:08:44.521915 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #638 | Training finished
2017-07-02 15:08:44.528415 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #638 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 15:08:44.528696 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #638 | Collecting samples for evaluation
2017-07-02 15:08:50.186283 EDT | -----------------------  ------------
2017-07-02 15:08:50.186499 EDT | Epoch                    638
2017-07-02 15:08:50.186733 EDT | Iteration                638
2017-07-02 15:08:50.186893 EDT | AverageReturn             49.5545
2017-07-02 15:08:50.187101 EDT | StdReturn                  2.57742
2017-07-02 15:08:50.187325 EDT | MaxReturn                 55
2017-07-02 15:08:50.187470 EDT | MinReturn                 45
2017-07-02 15:08:50.187574 EDT | AverageEsReturn           18.2963
2017-07-02 15:08:50.187675 EDT | StdEsReturn               13.3536
2017-07-02 15:08:50.187775 EDT | MaxEsReturn               54
2017-07-02 15:08:50.187876 EDT | MinEsReturn                3
2017-07-02 15:08:50.187991 EDT | AverageDiscountedReturn   39.2075
2017-07-02 15:08:50.188091 EDT | AverageQLoss               0.00441373
2017-07-02 15:08:50.188300 EDT | AveragePolicySurr         -1.18446
2017-07-02 15:08:50.188516 EDT | AverageQ                   1.12851
2017-07-02 15:08:50.188743 EDT | AverageAbsQ                1.13162
2017-07-02 15:08:50.188952 EDT | AverageY                   1.1285
2017-07-02 15:08:50.189131 EDT | AverageAbsY                1.12877
2017-07-02 15:08:50.189365 EDT | AverageAbsQYDiff           0.0180599
2017-07-02 15:08:50.189784 EDT | AverageAction              0.298481
2017-07-02 15:08:50.190013 EDT | PolicyRegParamNorm        63.623
2017-07-02 15:08:50.190230 EDT | QFunRegParamNorm          62.1675
2017-07-02 15:08:50.190457 EDT | -----------------------  ------------
2017-07-02 15:08:50.190678 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #639 | Training started
2017-07-02 15:08:59.501503 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #639 | Training finished
2017-07-02 15:08:59.502034 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #639 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 15:08:59.502165 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #639 | Collecting samples for evaluation
2017-07-02 15:09:04.974070 EDT | -----------------------  -------------
2017-07-02 15:09:04.974383 EDT | Epoch                     639
2017-07-02 15:09:04.974607 EDT | Iteration                 639
2017-07-02 15:09:04.974829 EDT | AverageReturn            1000
2017-07-02 15:09:04.974973 EDT | StdReturn                   0
2017-07-02 15:09:04.975184 EDT | MaxReturn                1000
2017-07-02 15:09:04.975398 EDT | MinReturn                1000
2017-07-02 15:09:04.975626 EDT | AverageEsReturn            16.0806
2017-07-02 15:09:04.975850 EDT | StdEsReturn                12.5458
2017-07-02 15:09:04.975991 EDT | MaxEsReturn                63
2017-07-02 15:09:04.976092 EDT | MinEsReturn                 3
2017-07-02 15:09:04.976285 EDT | AverageDiscountedReturn    99.9957
2017-07-02 15:09:04.976476 EDT | AverageQLoss                0.00482327
2017-07-02 15:09:04.976695 EDT | AveragePolicySurr          -1.18358
2017-07-02 15:09:04.976896 EDT | AverageQ                    1.12645
2017-07-02 15:09:04.977002 EDT | AverageAbsQ                 1.12969
2017-07-02 15:09:04.977102 EDT | AverageY                    1.12642
2017-07-02 15:09:04.977303 EDT | AverageAbsY                 1.12668
2017-07-02 15:09:04.978313 EDT | AverageAbsQYDiff            0.0190975
2017-07-02 15:09:04.978572 EDT | AverageAction               0.599459
2017-07-02 15:09:04.978802 EDT | PolicyRegParamNorm         63.664
2017-07-02 15:09:04.979033 EDT | QFunRegParamNorm           62.208
2017-07-02 15:09:04.979264 EDT | -----------------------  -------------
2017-07-02 15:09:04.979555 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #640 | Training started
2017-07-02 15:09:14.277629 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #640 | Training finished
2017-07-02 15:09:14.278236 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #640 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 15:09:14.278494 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #640 | Collecting samples for evaluation
2017-07-02 15:09:19.973388 EDT | -----------------------  -------------
2017-07-02 15:09:19.973724 EDT | Epoch                     640
2017-07-02 15:09:19.973918 EDT | Iteration                 640
2017-07-02 15:09:19.974058 EDT | AverageReturn             687.267
2017-07-02 15:09:19.974168 EDT | StdReturn                 442.293
2017-07-02 15:09:19.974275 EDT | MaxReturn                1000
2017-07-02 15:09:19.974380 EDT | MinReturn                  52
2017-07-02 15:09:19.974506 EDT | AverageEsReturn            21.8222
2017-07-02 15:09:19.974719 EDT | StdEsReturn                16.9211
2017-07-02 15:09:19.974926 EDT | MaxEsReturn                62
2017-07-02 15:09:19.975088 EDT | MinEsReturn                 3
2017-07-02 15:09:19.975319 EDT | AverageDiscountedReturn    82.0338
2017-07-02 15:09:19.975535 EDT | AverageQLoss                0.00515758
2017-07-02 15:09:19.975731 EDT | AveragePolicySurr          -1.17837
2017-07-02 15:09:19.975972 EDT | AverageQ                    1.12404
2017-07-02 15:09:19.976202 EDT | AverageAbsQ                 1.12723
2017-07-02 15:09:19.976427 EDT | AverageY                    1.1241
2017-07-02 15:09:19.976636 EDT | AverageAbsY                 1.12441
2017-07-02 15:09:19.976855 EDT | AverageAbsQYDiff            0.0191699
2017-07-02 15:09:19.977070 EDT | AverageAction               0.586065
2017-07-02 15:09:19.977178 EDT | PolicyRegParamNorm         63.6742
2017-07-02 15:09:19.977280 EDT | QFunRegParamNorm           62.2354
2017-07-02 15:09:19.977380 EDT | -----------------------  -------------
2017-07-02 15:09:19.977554 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #641 | Training started
2017-07-02 15:09:29.195669 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #641 | Training finished
2017-07-02 15:09:29.196175 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #641 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 15:09:29.196346 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #641 | Collecting samples for evaluation
2017-07-02 15:09:34.992592 EDT | -----------------------  -------------
2017-07-02 15:09:34.992797 EDT | Epoch                     641
2017-07-02 15:09:34.993014 EDT | Iteration                 641
2017-07-02 15:09:34.993245 EDT | AverageReturn             611.647
2017-07-02 15:09:34.993458 EDT | StdReturn                 464.176
2017-07-02 15:09:34.993695 EDT | MaxReturn                1000
2017-07-02 15:09:34.993920 EDT | MinReturn                  52
2017-07-02 15:09:34.994130 EDT | AverageEsReturn            26.075
2017-07-02 15:09:34.994355 EDT | StdEsReturn                15.499
2017-07-02 15:09:34.994525 EDT | MaxEsReturn                64
2017-07-02 15:09:34.994751 EDT | MinEsReturn                 4
2017-07-02 15:09:34.994972 EDT | AverageDiscountedReturn    76.7312
2017-07-02 15:09:34.995121 EDT | AverageQLoss                0.00497579
2017-07-02 15:09:34.995338 EDT | AveragePolicySurr          -1.17469
2017-07-02 15:09:34.995529 EDT | AverageQ                    1.11929
2017-07-02 15:09:34.995702 EDT | AverageAbsQ                 1.12263
2017-07-02 15:09:34.995871 EDT | AverageY                    1.11923
2017-07-02 15:09:34.996043 EDT | AverageAbsY                 1.11952
2017-07-02 15:09:34.996212 EDT | AverageAbsQYDiff            0.0190755
2017-07-02 15:09:34.996379 EDT | AverageAction               0.554207
2017-07-02 15:09:34.996546 EDT | PolicyRegParamNorm         63.6678
2017-07-02 15:09:34.996726 EDT | QFunRegParamNorm           62.2401
2017-07-02 15:09:34.996894 EDT | -----------------------  -------------
2017-07-02 15:09:34.997150 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #642 | Training started
2017-07-02 15:09:44.351836 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #642 | Training finished
2017-07-02 15:09:44.353088 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #642 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 15:09:44.353317 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #642 | Collecting samples for evaluation
2017-07-02 15:09:49.943049 EDT | -----------------------  -------------
2017-07-02 15:09:49.943242 EDT | Epoch                     642
2017-07-02 15:09:49.943366 EDT | Iteration                 642
2017-07-02 15:09:49.943520 EDT | AverageReturn            1000
2017-07-02 15:09:49.943629 EDT | StdReturn                   0
2017-07-02 15:09:49.943766 EDT | MaxReturn                1000
2017-07-02 15:09:49.943873 EDT | MinReturn                1000
2017-07-02 15:09:49.944024 EDT | AverageEsReturn            27.9143
2017-07-02 15:09:49.944126 EDT | StdEsReturn                23.9301
2017-07-02 15:09:49.944233 EDT | MaxEsReturn               123
2017-07-02 15:09:49.944338 EDT | MinEsReturn                 2
2017-07-02 15:09:49.944485 EDT | AverageDiscountedReturn    99.9957
2017-07-02 15:09:49.944588 EDT | AverageQLoss                0.00419071
2017-07-02 15:09:49.944685 EDT | AveragePolicySurr          -1.17077
2017-07-02 15:09:49.944813 EDT | AverageQ                    1.11881
2017-07-02 15:09:49.944969 EDT | AverageAbsQ                 1.12217
2017-07-02 15:09:49.945096 EDT | AverageY                    1.11881
2017-07-02 15:09:49.945217 EDT | AverageAbsY                 1.11917
2017-07-02 15:09:49.945324 EDT | AverageAbsQYDiff            0.0172988
2017-07-02 15:09:49.945463 EDT | AverageAction               0.784013
2017-07-02 15:09:49.945631 EDT | PolicyRegParamNorm         63.7331
2017-07-02 15:09:49.945739 EDT | QFunRegParamNorm           62.2629
2017-07-02 15:09:49.945845 EDT | -----------------------  -------------
2017-07-02 15:09:49.946010 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #643 | Training started
2017-07-02 15:09:59.255737 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #643 | Training finished
2017-07-02 15:09:59.256323 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #643 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 15:09:59.256586 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #643 | Collecting samples for evaluation
2017-07-02 15:10:04.752223 EDT | -----------------------  -------------
2017-07-02 15:10:04.752536 EDT | Epoch                     643
2017-07-02 15:10:04.752674 EDT | Iteration                 643
2017-07-02 15:10:04.752908 EDT | AverageReturn            1000
2017-07-02 15:10:04.753130 EDT | StdReturn                   0
2017-07-02 15:10:04.753353 EDT | MaxReturn                1000
2017-07-02 15:10:04.753586 EDT | MinReturn                1000
2017-07-02 15:10:04.753741 EDT | AverageEsReturn            28.7429
2017-07-02 15:10:04.753967 EDT | StdEsReturn                18.348
2017-07-02 15:10:04.754092 EDT | MaxEsReturn                74
2017-07-02 15:10:04.754196 EDT | MinEsReturn                 4
2017-07-02 15:10:04.754295 EDT | AverageDiscountedReturn    99.9957
2017-07-02 15:10:04.754397 EDT | AverageQLoss                0.00492248
2017-07-02 15:10:04.754498 EDT | AveragePolicySurr          -1.1687
2017-07-02 15:10:04.754598 EDT | AverageQ                    1.11716
2017-07-02 15:10:04.754772 EDT | AverageAbsQ                 1.12076
2017-07-02 15:10:04.754982 EDT | AverageY                    1.11718
2017-07-02 15:10:04.755158 EDT | AverageAbsY                 1.11759
2017-07-02 15:10:04.755376 EDT | AverageAbsQYDiff            0.0192888
2017-07-02 15:10:04.755560 EDT | AverageAction               0.936339
2017-07-02 15:10:04.755786 EDT | PolicyRegParamNorm         63.7629
2017-07-02 15:10:04.756005 EDT | QFunRegParamNorm           62.2602
2017-07-02 15:10:04.756222 EDT | -----------------------  -------------
2017-07-02 15:10:04.756528 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #644 | Training started
2017-07-02 15:10:14.042439 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #644 | Training finished
2017-07-02 15:10:14.042943 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #644 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 15:10:14.043081 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #644 | Collecting samples for evaluation
2017-07-02 15:10:20.221102 EDT | -----------------------  -------------
2017-07-02 15:10:20.221409 EDT | Epoch                     644
2017-07-02 15:10:20.221608 EDT | Iteration                 644
2017-07-02 15:10:20.221846 EDT | AverageReturn            1000
2017-07-02 15:10:20.222077 EDT | StdReturn                   0
2017-07-02 15:10:20.222303 EDT | MaxReturn                1000
2017-07-02 15:10:20.222525 EDT | MinReturn                1000
2017-07-02 15:10:20.222741 EDT | AverageEsReturn            33.9
2017-07-02 15:10:20.222969 EDT | StdEsReturn                25.8384
2017-07-02 15:10:20.223104 EDT | MaxEsReturn                97
2017-07-02 15:10:20.223210 EDT | MinEsReturn                 5
2017-07-02 15:10:20.223312 EDT | AverageDiscountedReturn    99.9957
2017-07-02 15:10:20.223413 EDT | AverageQLoss                0.00421238
2017-07-02 15:10:20.223512 EDT | AveragePolicySurr          -1.16785
2017-07-02 15:10:20.223611 EDT | AverageQ                    1.1146
2017-07-02 15:10:20.223711 EDT | AverageAbsQ                 1.11732
2017-07-02 15:10:20.223810 EDT | AverageY                    1.11456
2017-07-02 15:10:20.223909 EDT | AverageAbsY                 1.11493
2017-07-02 15:10:20.224033 EDT | AverageAbsQYDiff            0.0164336
2017-07-02 15:10:20.224248 EDT | AverageAction               0.608116
2017-07-02 15:10:20.224443 EDT | PolicyRegParamNorm         63.7741
2017-07-02 15:10:20.224663 EDT | QFunRegParamNorm           62.2946
2017-07-02 15:10:20.224883 EDT | -----------------------  -------------
2017-07-02 15:10:20.225161 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #645 | Training started
2017-07-02 15:10:29.902689 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #645 | Training finished
2017-07-02 15:10:29.903271 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #645 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 15:10:29.903490 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #645 | Collecting samples for evaluation
2017-07-02 15:10:35.439879 EDT | -----------------------  -------------
2017-07-02 15:10:35.440081 EDT | Epoch                     645
2017-07-02 15:10:35.440191 EDT | Iteration                 645
2017-07-02 15:10:35.440296 EDT | AverageReturn            1000
2017-07-02 15:10:35.440437 EDT | StdReturn                   0
2017-07-02 15:10:35.440543 EDT | MaxReturn                1000
2017-07-02 15:10:35.440655 EDT | MinReturn                1000
2017-07-02 15:10:35.440787 EDT | AverageEsReturn            29.7812
2017-07-02 15:10:35.440888 EDT | StdEsReturn                27.8093
2017-07-02 15:10:35.440987 EDT | MaxEsReturn               113
2017-07-02 15:10:35.441103 EDT | MinEsReturn                 2
2017-07-02 15:10:35.441201 EDT | AverageDiscountedReturn    99.9957
2017-07-02 15:10:35.441362 EDT | AverageQLoss                0.00508006
2017-07-02 15:10:35.441480 EDT | AveragePolicySurr          -1.16416
2017-07-02 15:10:35.441620 EDT | AverageQ                    1.10692
2017-07-02 15:10:35.441870 EDT | AverageAbsQ                 1.11108
2017-07-02 15:10:35.442136 EDT | AverageY                    1.10697
2017-07-02 15:10:35.442314 EDT | AverageAbsY                 1.10741
2017-07-02 15:10:35.442451 EDT | AverageAbsQYDiff            0.0208641
2017-07-02 15:10:35.442577 EDT | AverageAction               0.725146
2017-07-02 15:10:35.442700 EDT | PolicyRegParamNorm         63.8274
2017-07-02 15:10:35.442861 EDT | QFunRegParamNorm           62.3362
2017-07-02 15:10:35.442985 EDT | -----------------------  -------------
2017-07-02 15:10:35.443180 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #646 | Training started
2017-07-02 15:10:44.663436 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #646 | Training finished
2017-07-02 15:10:44.664027 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #646 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 15:10:44.664233 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #646 | Collecting samples for evaluation
2017-07-02 15:10:50.188490 EDT | -----------------------  -------------
2017-07-02 15:10:50.188806 EDT | Epoch                     646
2017-07-02 15:10:50.189003 EDT | Iteration                 646
2017-07-02 15:10:50.189232 EDT | AverageReturn            1000
2017-07-02 15:10:50.189383 EDT | StdReturn                   0
2017-07-02 15:10:50.189516 EDT | MaxReturn                1000
2017-07-02 15:10:50.189749 EDT | MinReturn                1000
2017-07-02 15:10:50.189971 EDT | AverageEsReturn            52.25
2017-07-02 15:10:50.190198 EDT | StdEsReturn                47.138
2017-07-02 15:10:50.190430 EDT | MaxEsReturn               187
2017-07-02 15:10:50.190607 EDT | MinEsReturn                 3
2017-07-02 15:10:50.190839 EDT | AverageDiscountedReturn    99.9957
2017-07-02 15:10:50.191047 EDT | AverageQLoss                0.00471379
2017-07-02 15:10:50.191238 EDT | AveragePolicySurr          -1.16342
2017-07-02 15:10:50.191464 EDT | AverageQ                    1.10868
2017-07-02 15:10:50.191615 EDT | AverageAbsQ                 1.11261
2017-07-02 15:10:50.191795 EDT | AverageY                    1.10864
2017-07-02 15:10:50.192025 EDT | AverageAbsY                 1.10912
2017-07-02 15:10:50.192203 EDT | AverageAbsQYDiff            0.0191638
2017-07-02 15:10:50.192434 EDT | AverageAction               0.749493
2017-07-02 15:10:50.192636 EDT | PolicyRegParamNorm         63.8874
2017-07-02 15:10:50.192847 EDT | QFunRegParamNorm           62.3657
2017-07-02 15:10:50.193073 EDT | -----------------------  -------------
2017-07-02 15:10:50.193353 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #647 | Training started
2017-07-02 15:10:59.494246 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #647 | Training finished
2017-07-02 15:10:59.494511 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #647 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 15:10:59.494642 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #647 | Collecting samples for evaluation
2017-07-02 15:11:04.937183 EDT | -----------------------  -------------
2017-07-02 15:11:04.938104 EDT | Epoch                     647
2017-07-02 15:11:04.938249 EDT | Iteration                 647
2017-07-02 15:11:04.938365 EDT | AverageReturn            1000
2017-07-02 15:11:04.938469 EDT | StdReturn                   0
2017-07-02 15:11:04.938571 EDT | MaxReturn                1000
2017-07-02 15:11:04.938714 EDT | MinReturn                1000
2017-07-02 15:11:04.938938 EDT | AverageEsReturn            38.76
2017-07-02 15:11:04.939165 EDT | StdEsReturn                41.393
2017-07-02 15:11:04.939322 EDT | MaxEsReturn               166
2017-07-02 15:11:04.939427 EDT | MinEsReturn                 4
2017-07-02 15:11:04.939528 EDT | AverageDiscountedReturn    99.9957
2017-07-02 15:11:04.939641 EDT | AverageQLoss                0.00406771
2017-07-02 15:11:04.939774 EDT | AveragePolicySurr          -1.15778
2017-07-02 15:11:04.939876 EDT | AverageQ                    1.10499
2017-07-02 15:11:04.939976 EDT | AverageAbsQ                 1.1085
2017-07-02 15:11:04.940074 EDT | AverageY                    1.10504
2017-07-02 15:11:04.940201 EDT | AverageAbsY                 1.10563
2017-07-02 15:11:04.940302 EDT | AverageAbsQYDiff            0.0175492
2017-07-02 15:11:04.940403 EDT | AverageAction               0.988172
2017-07-02 15:11:04.940502 EDT | PolicyRegParamNorm         63.9094
2017-07-02 15:11:04.940601 EDT | QFunRegParamNorm           62.4002
2017-07-02 15:11:04.940699 EDT | -----------------------  -------------
2017-07-02 15:11:04.940859 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #648 | Training started
2017-07-02 15:11:14.379488 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #648 | Training finished
2017-07-02 15:11:14.380105 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #648 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 15:11:14.380340 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #648 | Collecting samples for evaluation
2017-07-02 15:11:19.813288 EDT | -----------------------  ------------
2017-07-02 15:11:19.813514 EDT | Epoch                     648
2017-07-02 15:11:19.813671 EDT | Iteration                 648
2017-07-02 15:11:19.813776 EDT | AverageReturn            1000
2017-07-02 15:11:19.813877 EDT | StdReturn                   0
2017-07-02 15:11:19.813978 EDT | MaxReturn                1000
2017-07-02 15:11:19.814149 EDT | MinReturn                1000
2017-07-02 15:11:19.814329 EDT | AverageEsReturn            30.9677
2017-07-02 15:11:19.814435 EDT | StdEsReturn                22.6352
2017-07-02 15:11:19.814598 EDT | MaxEsReturn                92
2017-07-02 15:11:19.814776 EDT | MinEsReturn                 5
2017-07-02 15:11:19.814927 EDT | AverageDiscountedReturn    99.9957
2017-07-02 15:11:19.815037 EDT | AverageQLoss                0.0043572
2017-07-02 15:11:19.815168 EDT | AveragePolicySurr          -1.15562
2017-07-02 15:11:19.815363 EDT | AverageQ                    1.10399
2017-07-02 15:11:19.815547 EDT | AverageAbsQ                 1.10803
2017-07-02 15:11:19.815694 EDT | AverageY                    1.10391
2017-07-02 15:11:19.815816 EDT | AverageAbsY                 1.10459
2017-07-02 15:11:19.815965 EDT | AverageAbsQYDiff            0.0182421
2017-07-02 15:11:19.816144 EDT | AverageAction               0.959089
2017-07-02 15:11:19.816257 EDT | PolicyRegParamNorm         63.9106
2017-07-02 15:11:19.816378 EDT | QFunRegParamNorm           62.4486
2017-07-02 15:11:19.816533 EDT | -----------------------  ------------
2017-07-02 15:11:19.816696 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #649 | Training started
2017-07-02 15:11:29.314383 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #649 | Training finished
2017-07-02 15:11:29.314580 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #649 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 15:11:29.314695 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #649 | Collecting samples for evaluation
2017-07-02 15:11:34.773111 EDT | -----------------------  -------------
2017-07-02 15:11:34.773593 EDT | Epoch                     649
2017-07-02 15:11:34.773830 EDT | Iteration                 649
2017-07-02 15:11:34.774031 EDT | AverageReturn            1000
2017-07-02 15:11:34.774190 EDT | StdReturn                   0
2017-07-02 15:11:34.774334 EDT | MaxReturn                1000
2017-07-02 15:11:34.774460 EDT | MinReturn                1000
2017-07-02 15:11:34.774594 EDT | AverageEsReturn            43.913
2017-07-02 15:11:34.774719 EDT | StdEsReturn                40.5783
2017-07-02 15:11:34.774865 EDT | MaxEsReturn               119
2017-07-02 15:11:34.775005 EDT | MinEsReturn                 3
2017-07-02 15:11:34.775105 EDT | AverageDiscountedReturn    99.9957
2017-07-02 15:11:34.775259 EDT | AverageQLoss                0.00437002
2017-07-02 15:11:34.775375 EDT | AveragePolicySurr          -1.1521
2017-07-02 15:11:34.775502 EDT | AverageQ                    1.10102
2017-07-02 15:11:34.775613 EDT | AverageAbsQ                 1.10521
2017-07-02 15:11:34.775742 EDT | AverageY                    1.10109
2017-07-02 15:11:34.775912 EDT | AverageAbsY                 1.10164
2017-07-02 15:11:34.776061 EDT | AverageAbsQYDiff            0.0190649
2017-07-02 15:11:34.776241 EDT | AverageAction               0.961882
2017-07-02 15:11:34.776349 EDT | PolicyRegParamNorm         63.9285
2017-07-02 15:11:34.776447 EDT | QFunRegParamNorm           62.4794
2017-07-02 15:11:34.776555 EDT | -----------------------  -------------
2017-07-02 15:11:34.776779 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #650 | Training started
2017-07-02 15:11:44.207736 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #650 | Training finished
2017-07-02 15:11:44.208354 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #650 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 15:11:44.208587 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #650 | Collecting samples for evaluation
2017-07-02 15:11:49.655929 EDT | -----------------------  -------------
2017-07-02 15:11:49.656241 EDT | Epoch                     650
2017-07-02 15:11:49.656471 EDT | Iteration                 650
2017-07-02 15:11:49.656700 EDT | AverageReturn            1000
2017-07-02 15:11:49.656920 EDT | StdReturn                   0
2017-07-02 15:11:49.657132 EDT | MaxReturn                1000
2017-07-02 15:11:49.657363 EDT | MinReturn                1000
2017-07-02 15:11:49.657603 EDT | AverageEsReturn            44.0833
2017-07-02 15:11:49.657830 EDT | StdEsReturn                42.0614
2017-07-02 15:11:49.658045 EDT | MaxEsReturn               183
2017-07-02 15:11:49.658274 EDT | MinEsReturn                 3
2017-07-02 15:11:49.658492 EDT | AverageDiscountedReturn    99.9957
2017-07-02 15:11:49.658685 EDT | AverageQLoss                0.00398221
2017-07-02 15:11:49.658900 EDT | AveragePolicySurr          -1.1499
2017-07-02 15:11:49.659132 EDT | AverageQ                    1.09688
2017-07-02 15:11:49.659339 EDT | AverageAbsQ                 1.09995
2017-07-02 15:11:49.659446 EDT | AverageY                    1.09691
2017-07-02 15:11:49.659562 EDT | AverageAbsY                 1.09736
2017-07-02 15:11:49.659788 EDT | AverageAbsQYDiff            0.0167549
2017-07-02 15:11:49.659991 EDT | AverageAction               0.955535
2017-07-02 15:11:49.660221 EDT | PolicyRegParamNorm         63.9491
2017-07-02 15:11:49.660444 EDT | QFunRegParamNorm           62.4672
2017-07-02 15:11:49.660674 EDT | -----------------------  -------------
2017-07-02 15:11:49.660965 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #651 | Training started
2017-07-02 15:11:59.039845 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #651 | Training finished
2017-07-02 15:11:59.040047 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #651 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 15:11:59.040229 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #651 | Collecting samples for evaluation
2017-07-02 15:12:04.540425 EDT | -----------------------  ------------
2017-07-02 15:12:04.540896 EDT | Epoch                     651
2017-07-02 15:12:04.541056 EDT | Iteration                 651
2017-07-02 15:12:04.541204 EDT | AverageReturn            1000
2017-07-02 15:12:04.541324 EDT | StdReturn                   0
2017-07-02 15:12:04.541534 EDT | MaxReturn                1000
2017-07-02 15:12:04.541663 EDT | MinReturn                1000
2017-07-02 15:12:04.541866 EDT | AverageEsReturn            31.0312
2017-07-02 15:12:04.542070 EDT | StdEsReturn                32.2107
2017-07-02 15:12:04.542260 EDT | MaxEsReturn               134
2017-07-02 15:12:04.542452 EDT | MinEsReturn                 3
2017-07-02 15:12:04.542648 EDT | AverageDiscountedReturn    99.9957
2017-07-02 15:12:04.542759 EDT | AverageQLoss                0.0038314
2017-07-02 15:12:04.542868 EDT | AveragePolicySurr          -1.1502
2017-07-02 15:12:04.543052 EDT | AverageQ                    1.098
2017-07-02 15:12:04.543211 EDT | AverageAbsQ                 1.101
2017-07-02 15:12:04.543396 EDT | AverageY                    1.09803
2017-07-02 15:12:04.543560 EDT | AverageAbsY                 1.09822
2017-07-02 15:12:04.543672 EDT | AverageAbsQYDiff            0.0170965
2017-07-02 15:12:04.543835 EDT | AverageAction               0.960144
2017-07-02 15:12:04.543960 EDT | PolicyRegParamNorm         63.9831
2017-07-02 15:12:04.544080 EDT | QFunRegParamNorm           62.4886
2017-07-02 15:12:04.544186 EDT | -----------------------  ------------
2017-07-02 15:12:04.544415 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #652 | Training started
2017-07-02 15:12:13.773005 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #652 | Training finished
2017-07-02 15:12:13.773654 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #652 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 15:12:13.773903 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #652 | Collecting samples for evaluation
2017-07-02 15:12:19.283817 EDT | -----------------------  -------------
2017-07-02 15:12:19.284124 EDT | Epoch                     652
2017-07-02 15:12:19.284353 EDT | Iteration                 652
2017-07-02 15:12:19.284576 EDT | AverageReturn            1000
2017-07-02 15:12:19.284794 EDT | StdReturn                   0
2017-07-02 15:12:19.284976 EDT | MaxReturn                1000
2017-07-02 15:12:19.285202 EDT | MinReturn                1000
2017-07-02 15:12:19.285356 EDT | AverageEsReturn            40.44
2017-07-02 15:12:19.285461 EDT | StdEsReturn                55.8241
2017-07-02 15:12:19.285646 EDT | MaxEsReturn               231
2017-07-02 15:12:19.285781 EDT | MinEsReturn                 3
2017-07-02 15:12:19.285924 EDT | AverageDiscountedReturn    99.9957
2017-07-02 15:12:19.286140 EDT | AverageQLoss                0.00495824
2017-07-02 15:12:19.286340 EDT | AveragePolicySurr          -1.14582
2017-07-02 15:12:19.286562 EDT | AverageQ                    1.09261
2017-07-02 15:12:19.286779 EDT | AverageAbsQ                 1.09592
2017-07-02 15:12:19.286958 EDT | AverageY                    1.09252
2017-07-02 15:12:19.287195 EDT | AverageAbsY                 1.09276
2017-07-02 15:12:19.287413 EDT | AverageAbsQYDiff            0.0187238
2017-07-02 15:12:19.287630 EDT | AverageAction               0.134869
2017-07-02 15:12:19.287843 EDT | PolicyRegParamNorm         63.9857
2017-07-02 15:12:19.288045 EDT | QFunRegParamNorm           62.5308
2017-07-02 15:12:19.288261 EDT | -----------------------  -------------
2017-07-02 15:12:19.288541 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #653 | Training started
2017-07-02 15:12:28.649306 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #653 | Training finished
2017-07-02 15:12:28.649850 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #653 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 15:12:28.650208 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #653 | Collecting samples for evaluation
2017-07-02 15:12:34.115183 EDT | -----------------------  -------------
2017-07-02 15:12:34.122759 EDT | Epoch                     653
2017-07-02 15:12:34.122976 EDT | Iteration                 653
2017-07-02 15:12:34.123089 EDT | AverageReturn            1000
2017-07-02 15:12:34.123254 EDT | StdReturn                   0
2017-07-02 15:12:34.123451 EDT | MaxReturn                1000
2017-07-02 15:12:34.123585 EDT | MinReturn                1000
2017-07-02 15:12:34.123722 EDT | AverageEsReturn            24.7
2017-07-02 15:12:34.123920 EDT | StdEsReturn                32.2205
2017-07-02 15:12:34.124109 EDT | MaxEsReturn               174
2017-07-02 15:12:34.124248 EDT | MinEsReturn                 3
2017-07-02 15:12:34.124352 EDT | AverageDiscountedReturn    99.9957
2017-07-02 15:12:34.124489 EDT | AverageQLoss                0.00459258
2017-07-02 15:12:34.124672 EDT | AveragePolicySurr          -1.14346
2017-07-02 15:12:34.124829 EDT | AverageQ                    1.09153
2017-07-02 15:12:34.124955 EDT | AverageAbsQ                 1.09498
2017-07-02 15:12:34.125077 EDT | AverageY                    1.09149
2017-07-02 15:12:34.125179 EDT | AverageAbsY                 1.0918
2017-07-02 15:12:34.125309 EDT | AverageAbsQYDiff            0.0183374
2017-07-02 15:12:34.125425 EDT | AverageAction               0.570335
2017-07-02 15:12:34.125671 EDT | PolicyRegParamNorm         63.9809
2017-07-02 15:12:34.125898 EDT | QFunRegParamNorm           62.5663
2017-07-02 15:12:34.126063 EDT | -----------------------  -------------
2017-07-02 15:12:34.126358 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #654 | Training started
2017-07-02 15:12:43.569843 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #654 | Training finished
2017-07-02 15:12:43.570660 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #654 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 15:12:43.570876 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #654 | Collecting samples for evaluation
2017-07-02 15:12:48.955113 EDT | -----------------------  -------------
2017-07-02 15:12:48.955341 EDT | Epoch                     654
2017-07-02 15:12:48.955578 EDT | Iteration                 654
2017-07-02 15:12:48.955765 EDT | AverageReturn            1000
2017-07-02 15:12:48.955891 EDT | StdReturn                   0
2017-07-02 15:12:48.956122 EDT | MaxReturn                1000
2017-07-02 15:12:48.956344 EDT | MinReturn                1000
2017-07-02 15:12:48.956534 EDT | AverageEsReturn            25.9444
2017-07-02 15:12:48.956760 EDT | StdEsReturn                30.1514
2017-07-02 15:12:48.956985 EDT | MaxEsReturn               135
2017-07-02 15:12:48.957201 EDT | MinEsReturn                 4
2017-07-02 15:12:48.957428 EDT | AverageDiscountedReturn    99.9957
2017-07-02 15:12:48.957941 EDT | AverageQLoss                0.00420412
2017-07-02 15:12:48.958161 EDT | AveragePolicySurr          -1.14122
2017-07-02 15:12:48.958360 EDT | AverageQ                    1.08785
2017-07-02 15:12:48.958589 EDT | AverageAbsQ                 1.09119
2017-07-02 15:12:48.958813 EDT | AverageY                    1.08796
2017-07-02 15:12:48.959005 EDT | AverageAbsY                 1.08821
2017-07-02 15:12:48.959232 EDT | AverageAbsQYDiff            0.0178133
2017-07-02 15:12:48.959459 EDT | AverageAction               0.341525
2017-07-02 15:12:48.959641 EDT | PolicyRegParamNorm         64.0186
2017-07-02 15:12:48.959868 EDT | QFunRegParamNorm           62.5938
2017-07-02 15:12:48.960044 EDT | -----------------------  -------------
2017-07-02 15:12:48.960370 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #655 | Training started
2017-07-02 15:12:58.437770 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #655 | Training finished
2017-07-02 15:12:58.438362 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #655 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 15:12:58.438531 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #655 | Collecting samples for evaluation
2017-07-02 15:13:03.936142 EDT | -----------------------  -------------
2017-07-02 15:13:03.936737 EDT | Epoch                     655
2017-07-02 15:13:03.936928 EDT | Iteration                 655
2017-07-02 15:13:03.937082 EDT | AverageReturn            1000
2017-07-02 15:13:03.937280 EDT | StdReturn                   0
2017-07-02 15:13:03.937439 EDT | MaxReturn                1000
2017-07-02 15:13:03.937622 EDT | MinReturn                1000
2017-07-02 15:13:03.937738 EDT | AverageEsReturn            26.641
2017-07-02 15:13:03.937864 EDT | StdEsReturn                34.3858
2017-07-02 15:13:03.937990 EDT | MaxEsReturn               145
2017-07-02 15:13:03.938091 EDT | MinEsReturn                 4
2017-07-02 15:13:03.938209 EDT | AverageDiscountedReturn    99.9957
2017-07-02 15:13:03.938344 EDT | AverageQLoss                0.00445756
2017-07-02 15:13:03.938444 EDT | AveragePolicySurr          -1.13845
2017-07-02 15:13:03.938571 EDT | AverageQ                    1.08484
2017-07-02 15:13:03.938670 EDT | AverageAbsQ                 1.08801
2017-07-02 15:13:03.938767 EDT | AverageY                    1.08489
2017-07-02 15:13:03.938902 EDT | AverageAbsY                 1.08509
2017-07-02 15:13:03.939000 EDT | AverageAbsQYDiff            0.0178758
2017-07-02 15:13:03.939097 EDT | AverageAction               0.145868
2017-07-02 15:13:03.939192 EDT | PolicyRegParamNorm         64.0546
2017-07-02 15:13:03.939305 EDT | QFunRegParamNorm           62.5736
2017-07-02 15:13:03.939419 EDT | -----------------------  -------------
2017-07-02 15:13:03.939577 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #656 | Training started
2017-07-02 15:13:13.331291 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #656 | Training finished
2017-07-02 15:13:13.331787 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #656 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 15:13:13.331929 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #656 | Collecting samples for evaluation
2017-07-02 15:13:18.822192 EDT | -----------------------  -------------
2017-07-02 15:13:18.822436 EDT | Epoch                     656
2017-07-02 15:13:18.822614 EDT | Iteration                 656
2017-07-02 15:13:18.822853 EDT | AverageReturn            1000
2017-07-02 15:13:18.823077 EDT | StdReturn                   0
2017-07-02 15:13:18.823218 EDT | MaxReturn                1000
2017-07-02 15:13:18.823415 EDT | MinReturn                1000
2017-07-02 15:13:18.823592 EDT | AverageEsReturn            32.5806
2017-07-02 15:13:18.823747 EDT | StdEsReturn                29.7655
2017-07-02 15:13:18.823851 EDT | MaxEsReturn               113
2017-07-02 15:13:18.823951 EDT | MinEsReturn                 4
2017-07-02 15:13:18.824052 EDT | AverageDiscountedReturn    99.9957
2017-07-02 15:13:18.824152 EDT | AverageQLoss                0.00410973
2017-07-02 15:13:18.824251 EDT | AveragePolicySurr          -1.13881
2017-07-02 15:13:18.824349 EDT | AverageQ                    1.08917
2017-07-02 15:13:18.824447 EDT | AverageAbsQ                 1.09234
2017-07-02 15:13:18.824545 EDT | AverageY                    1.0891
2017-07-02 15:13:18.824644 EDT | AverageAbsY                 1.08934
2017-07-02 15:13:18.824741 EDT | AverageAbsQYDiff            0.0175335
2017-07-02 15:13:18.824838 EDT | AverageAction               0.791657
2017-07-02 15:13:18.824936 EDT | PolicyRegParamNorm         64.0489
2017-07-02 15:13:18.825035 EDT | QFunRegParamNorm           62.6038
2017-07-02 15:13:18.825134 EDT | -----------------------  -------------
2017-07-02 15:13:18.825296 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #657 | Training started
2017-07-02 15:13:27.966264 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #657 | Training finished
2017-07-02 15:13:27.966922 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #657 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 15:13:27.967108 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #657 | Collecting samples for evaluation
2017-07-02 15:13:33.524225 EDT | -----------------------  -------------
2017-07-02 15:13:33.524712 EDT | Epoch                     657
2017-07-02 15:13:33.524968 EDT | Iteration                 657
2017-07-02 15:13:33.525191 EDT | AverageReturn            1000
2017-07-02 15:13:33.525423 EDT | StdReturn                   0
2017-07-02 15:13:33.525745 EDT | MaxReturn                1000
2017-07-02 15:13:33.526096 EDT | MinReturn                1000
2017-07-02 15:13:33.526342 EDT | AverageEsReturn            22.3043
2017-07-02 15:13:33.526578 EDT | StdEsReturn                22.3216
2017-07-02 15:13:33.526862 EDT | MaxEsReturn               110
2017-07-02 15:13:33.527110 EDT | MinEsReturn                 3
2017-07-02 15:13:33.527355 EDT | AverageDiscountedReturn    99.9957
2017-07-02 15:13:33.527701 EDT | AverageQLoss                0.00375264
2017-07-02 15:13:33.527854 EDT | AveragePolicySurr          -1.13403
2017-07-02 15:13:33.528082 EDT | AverageQ                    1.08284
2017-07-02 15:13:33.528689 EDT | AverageAbsQ                 1.08619
2017-07-02 15:13:33.528957 EDT | AverageY                    1.08292
2017-07-02 15:13:33.529173 EDT | AverageAbsY                 1.0831
2017-07-02 15:13:33.530522 EDT | AverageAbsQYDiff            0.0164579
2017-07-02 15:13:33.530779 EDT | AverageAction               0.969262
2017-07-02 15:13:33.531024 EDT | PolicyRegParamNorm         64.0677
2017-07-02 15:13:33.531255 EDT | QFunRegParamNorm           62.6115
2017-07-02 15:13:33.531494 EDT | -----------------------  -------------
2017-07-02 15:13:33.531829 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #658 | Training started
2017-07-02 15:13:42.772383 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #658 | Training finished
2017-07-02 15:13:42.772985 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #658 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 15:13:42.773250 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #658 | Collecting samples for evaluation
2017-07-02 15:13:48.359636 EDT | -----------------------  -------------
2017-07-02 15:13:48.359899 EDT | Epoch                     658
2017-07-02 15:13:48.360071 EDT | Iteration                 658
2017-07-02 15:13:48.360264 EDT | AverageReturn            1000
2017-07-02 15:13:48.360438 EDT | StdReturn                   0
2017-07-02 15:13:48.360581 EDT | MaxReturn                1000
2017-07-02 15:13:48.360718 EDT | MinReturn                1000
2017-07-02 15:13:48.360884 EDT | AverageEsReturn            26.5946
2017-07-02 15:13:48.361069 EDT | StdEsReturn                32.0536
2017-07-02 15:13:48.361180 EDT | MaxEsReturn               168
2017-07-02 15:13:48.361278 EDT | MinEsReturn                 3
2017-07-02 15:13:48.361410 EDT | AverageDiscountedReturn    99.9957
2017-07-02 15:13:48.361535 EDT | AverageQLoss                0.00372492
2017-07-02 15:13:48.361699 EDT | AveragePolicySurr          -1.13128
2017-07-02 15:13:48.361888 EDT | AverageQ                    1.08035
2017-07-02 15:13:48.362032 EDT | AverageAbsQ                 1.08377
2017-07-02 15:13:48.362130 EDT | AverageY                    1.08027
2017-07-02 15:13:48.362227 EDT | AverageAbsY                 1.08041
2017-07-02 15:13:48.362329 EDT | AverageAbsQYDiff            0.0162872
2017-07-02 15:13:48.362447 EDT | AverageAction               0.777063
2017-07-02 15:13:48.362544 EDT | PolicyRegParamNorm         64.1051
2017-07-02 15:13:48.362684 EDT | QFunRegParamNorm           62.6577
2017-07-02 15:13:48.362807 EDT | -----------------------  -------------
2017-07-02 15:13:48.362970 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #659 | Training started
2017-07-02 15:13:57.603511 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #659 | Training finished
2017-07-02 15:13:57.604185 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #659 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 15:13:57.604440 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #659 | Collecting samples for evaluation
2017-07-02 15:14:03.102331 EDT | -----------------------  -------------
2017-07-02 15:14:03.102542 EDT | Epoch                     659
2017-07-02 15:14:03.102727 EDT | Iteration                 659
2017-07-02 15:14:03.102910 EDT | AverageReturn            1000
2017-07-02 15:14:03.103043 EDT | StdReturn                   0
2017-07-02 15:14:03.103155 EDT | MaxReturn                1000
2017-07-02 15:14:03.103257 EDT | MinReturn                1000
2017-07-02 15:14:03.103364 EDT | AverageEsReturn            47.7619
2017-07-02 15:14:03.103487 EDT | StdEsReturn                49.2775
2017-07-02 15:14:03.103607 EDT | MaxEsReturn               162
2017-07-02 15:14:03.103708 EDT | MinEsReturn                 3
2017-07-02 15:14:03.103850 EDT | AverageDiscountedReturn    99.9957
2017-07-02 15:14:03.104104 EDT | AverageQLoss                0.00435862
2017-07-02 15:14:03.104235 EDT | AveragePolicySurr          -1.12652
2017-07-02 15:14:03.104411 EDT | AverageQ                    1.07711
2017-07-02 15:14:03.104613 EDT | AverageAbsQ                 1.07998
2017-07-02 15:14:03.104820 EDT | AverageY                    1.07715
2017-07-02 15:14:03.105030 EDT | AverageAbsY                 1.07725
2017-07-02 15:14:03.105222 EDT | AverageAbsQYDiff            0.0167261
2017-07-02 15:14:03.105394 EDT | AverageAction               0.71892
2017-07-02 15:14:03.105605 EDT | PolicyRegParamNorm         64.1565
2017-07-02 15:14:03.105735 EDT | QFunRegParamNorm           62.6633
2017-07-02 15:14:03.105838 EDT | -----------------------  -------------
2017-07-02 15:14:03.106043 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #660 | Training started
2017-07-02 15:14:12.443375 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #660 | Training finished
2017-07-02 15:14:12.443930 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #660 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 15:14:12.444179 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #660 | Collecting samples for evaluation
2017-07-02 15:14:17.989635 EDT | -----------------------  -------------
2017-07-02 15:14:17.989855 EDT | Epoch                     660
2017-07-02 15:14:17.990055 EDT | Iteration                 660
2017-07-02 15:14:17.990367 EDT | AverageReturn            1000
2017-07-02 15:14:17.990756 EDT | StdReturn                   0
2017-07-02 15:14:17.990918 EDT | MaxReturn                1000
2017-07-02 15:14:17.991057 EDT | MinReturn                1000
2017-07-02 15:14:17.991189 EDT | AverageEsReturn            31.5484
2017-07-02 15:14:17.991316 EDT | StdEsReturn                30.8135
2017-07-02 15:14:17.991457 EDT | MaxEsReturn               120
2017-07-02 15:14:17.991609 EDT | MinEsReturn                 4
2017-07-02 15:14:17.991732 EDT | AverageDiscountedReturn    99.9957
2017-07-02 15:14:17.991868 EDT | AverageQLoss                0.00447088
2017-07-02 15:14:17.991989 EDT | AveragePolicySurr          -1.12627
2017-07-02 15:14:17.992102 EDT | AverageQ                    1.07261
2017-07-02 15:14:17.992208 EDT | AverageAbsQ                 1.07612
2017-07-02 15:14:17.992338 EDT | AverageY                    1.07254
2017-07-02 15:14:17.992454 EDT | AverageAbsY                 1.0727
2017-07-02 15:14:17.992605 EDT | AverageAbsQYDiff            0.0184498
2017-07-02 15:14:17.992735 EDT | AverageAction               0.178172
2017-07-02 15:14:17.992932 EDT | PolicyRegParamNorm         64.1664
2017-07-02 15:14:17.993061 EDT | QFunRegParamNorm           62.7017
2017-07-02 15:14:17.993194 EDT | -----------------------  -------------
2017-07-02 15:14:17.993441 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #661 | Training started
2017-07-02 15:14:27.238100 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #661 | Training finished
2017-07-02 15:14:27.238665 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #661 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 15:14:27.238918 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #661 | Collecting samples for evaluation
2017-07-02 15:14:32.846639 EDT | -----------------------  -------------
2017-07-02 15:14:32.846960 EDT | Epoch                     661
2017-07-02 15:14:32.847200 EDT | Iteration                 661
2017-07-02 15:14:32.847435 EDT | AverageReturn            1000
2017-07-02 15:14:32.847652 EDT | StdReturn                   0
2017-07-02 15:14:32.847872 EDT | MaxReturn                1000
2017-07-02 15:14:32.848096 EDT | MinReturn                1000
2017-07-02 15:14:32.848278 EDT | AverageEsReturn            32.25
2017-07-02 15:14:32.848496 EDT | StdEsReturn                25.3279
2017-07-02 15:14:32.848719 EDT | MaxEsReturn                98
2017-07-02 15:14:32.848946 EDT | MinEsReturn                 5
2017-07-02 15:14:32.849147 EDT | AverageDiscountedReturn    99.9957
2017-07-02 15:14:32.849369 EDT | AverageQLoss                0.00376234
2017-07-02 15:14:32.849651 EDT | AveragePolicySurr          -1.1245
2017-07-02 15:14:32.849864 EDT | AverageQ                    1.07535
2017-07-02 15:14:32.850047 EDT | AverageAbsQ                 1.07802
2017-07-02 15:14:32.850264 EDT | AverageY                    1.07538
2017-07-02 15:14:32.850486 EDT | AverageAbsY                 1.07558
2017-07-02 15:14:32.850688 EDT | AverageAbsQYDiff            0.0168251
2017-07-02 15:14:32.850795 EDT | AverageAction               0.812482
2017-07-02 15:14:32.850898 EDT | PolicyRegParamNorm         64.2079
2017-07-02 15:14:32.850998 EDT | QFunRegParamNorm           62.6906
2017-07-02 15:14:32.851142 EDT | -----------------------  -------------
2017-07-02 15:14:32.851457 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #662 | Training started
2017-07-02 15:14:42.193597 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #662 | Training finished
2017-07-02 15:14:42.199960 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #662 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 15:14:42.200143 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #662 | Collecting samples for evaluation
2017-07-02 15:14:47.790135 EDT | -----------------------  -------------
2017-07-02 15:14:47.790317 EDT | Epoch                     662
2017-07-02 15:14:47.790432 EDT | Iteration                 662
2017-07-02 15:14:47.790547 EDT | AverageReturn            1000
2017-07-02 15:14:47.790674 EDT | StdReturn                   0
2017-07-02 15:14:47.790794 EDT | MaxReturn                1000
2017-07-02 15:14:47.791023 EDT | MinReturn                1000
2017-07-02 15:14:47.791239 EDT | AverageEsReturn            47.15
2017-07-02 15:14:47.791443 EDT | StdEsReturn                42.6805
2017-07-02 15:14:47.791671 EDT | MaxEsReturn               185
2017-07-02 15:14:47.791830 EDT | MinEsReturn                 6
2017-07-02 15:14:47.792062 EDT | AverageDiscountedReturn    99.9957
2017-07-02 15:14:47.792261 EDT | AverageQLoss                0.00416231
2017-07-02 15:14:47.792368 EDT | AveragePolicySurr          -1.12116
2017-07-02 15:14:47.792508 EDT | AverageQ                    1.0691
2017-07-02 15:14:47.792740 EDT | AverageAbsQ                 1.07244
2017-07-02 15:14:47.792933 EDT | AverageY                    1.0691
2017-07-02 15:14:47.793139 EDT | AverageAbsY                 1.06934
2017-07-02 15:14:47.793366 EDT | AverageAbsQYDiff            0.0169587
2017-07-02 15:14:47.793558 EDT | AverageAction               0.423018
2017-07-02 15:14:47.793787 EDT | PolicyRegParamNorm         64.3144
2017-07-02 15:14:47.794007 EDT | QFunRegParamNorm           62.7213
2017-07-02 15:14:47.794238 EDT | -----------------------  -------------
2017-07-02 15:14:47.794549 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #663 | Training started
2017-07-02 15:14:57.126918 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #663 | Training finished
2017-07-02 15:14:57.127470 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #663 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 15:14:57.127729 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #663 | Collecting samples for evaluation
2017-07-02 15:15:02.647726 EDT | -----------------------  -------------
2017-07-02 15:15:02.647988 EDT | Epoch                     663
2017-07-02 15:15:02.648181 EDT | Iteration                 663
2017-07-02 15:15:02.648354 EDT | AverageReturn            1000
2017-07-02 15:15:02.648463 EDT | StdReturn                   0
2017-07-02 15:15:02.648588 EDT | MaxReturn                1000
2017-07-02 15:15:02.648691 EDT | MinReturn                1000
2017-07-02 15:15:02.648806 EDT | AverageEsReturn            42.32
2017-07-02 15:15:02.648999 EDT | StdEsReturn                31.008
2017-07-02 15:15:02.649176 EDT | MaxEsReturn               132
2017-07-02 15:15:02.649372 EDT | MinEsReturn                 3
2017-07-02 15:15:02.649561 EDT | AverageDiscountedReturn    99.9957
2017-07-02 15:15:02.649667 EDT | AverageQLoss                0.00470326
2017-07-02 15:15:02.649777 EDT | AveragePolicySurr          -1.11803
2017-07-02 15:15:02.649981 EDT | AverageQ                    1.06855
2017-07-02 15:15:02.650177 EDT | AverageAbsQ                 1.07185
2017-07-02 15:15:02.650371 EDT | AverageY                    1.06855
2017-07-02 15:15:02.650566 EDT | AverageAbsY                 1.06884
2017-07-02 15:15:02.650680 EDT | AverageAbsQYDiff            0.0184982
2017-07-02 15:15:02.650832 EDT | AverageAction               0.946718
2017-07-02 15:15:02.650942 EDT | PolicyRegParamNorm         64.3202
2017-07-02 15:15:02.651071 EDT | QFunRegParamNorm           62.7457
2017-07-02 15:15:02.651213 EDT | -----------------------  -------------
2017-07-02 15:15:02.651390 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #664 | Training started
2017-07-02 15:15:11.964242 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #664 | Training finished
2017-07-02 15:15:11.964852 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #664 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 15:15:11.965092 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #664 | Collecting samples for evaluation
2017-07-02 15:15:17.495986 EDT | -----------------------  -------------
2017-07-02 15:15:17.496301 EDT | Epoch                     664
2017-07-02 15:15:17.496421 EDT | Iteration                 664
2017-07-02 15:15:17.496529 EDT | AverageReturn            1000
2017-07-02 15:15:17.496632 EDT | StdReturn                   0
2017-07-02 15:15:17.496792 EDT | MaxReturn                1000
2017-07-02 15:15:17.497015 EDT | MinReturn                1000
2017-07-02 15:15:17.497223 EDT | AverageEsReturn            33.7143
2017-07-02 15:15:17.497455 EDT | StdEsReturn                32.8382
2017-07-02 15:15:17.497969 EDT | MaxEsReturn               158
2017-07-02 15:15:17.498189 EDT | MinEsReturn                 4
2017-07-02 15:15:17.498422 EDT | AverageDiscountedReturn    99.9957
2017-07-02 15:15:17.498577 EDT | AverageQLoss                0.00379177
2017-07-02 15:15:17.498803 EDT | AveragePolicySurr          -1.11462
2017-07-02 15:15:17.499127 EDT | AverageQ                    1.06526
2017-07-02 15:15:17.499346 EDT | AverageAbsQ                 1.06811
2017-07-02 15:15:17.499574 EDT | AverageY                    1.06523
2017-07-02 15:15:17.499788 EDT | AverageAbsY                 1.06551
2017-07-02 15:15:17.500028 EDT | AverageAbsQYDiff            0.0160012
2017-07-02 15:15:17.500207 EDT | AverageAction               0.958164
2017-07-02 15:15:17.500433 EDT | PolicyRegParamNorm         64.3347
2017-07-02 15:15:17.500645 EDT | QFunRegParamNorm           62.7513
2017-07-02 15:15:17.500877 EDT | -----------------------  -------------
2017-07-02 15:15:17.501200 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #665 | Training started
2017-07-02 15:15:27.432424 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #665 | Training finished
2017-07-02 15:15:27.432647 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #665 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 15:15:27.432789 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #665 | Collecting samples for evaluation
2017-07-02 15:15:32.927178 EDT | -----------------------  -------------
2017-07-02 15:15:32.927739 EDT | Epoch                     665
2017-07-02 15:15:32.927892 EDT | Iteration                 665
2017-07-02 15:15:32.928105 EDT | AverageReturn            1000
2017-07-02 15:15:32.928314 EDT | StdReturn                   0
2017-07-02 15:15:32.928498 EDT | MaxReturn                1000
2017-07-02 15:15:32.928608 EDT | MinReturn                1000
2017-07-02 15:15:32.928758 EDT | AverageEsReturn            37.9286
2017-07-02 15:15:32.928866 EDT | StdEsReturn                35.4733
2017-07-02 15:15:32.929001 EDT | MaxEsReturn               153
2017-07-02 15:15:32.929182 EDT | MinEsReturn                 4
2017-07-02 15:15:32.929290 EDT | AverageDiscountedReturn    99.9957
2017-07-02 15:15:32.929432 EDT | AverageQLoss                0.00389627
2017-07-02 15:15:32.929573 EDT | AveragePolicySurr          -1.11432
2017-07-02 15:15:32.929742 EDT | AverageQ                    1.06237
2017-07-02 15:15:32.929940 EDT | AverageAbsQ                 1.06584
2017-07-02 15:15:32.930053 EDT | AverageY                    1.06241
2017-07-02 15:15:32.930220 EDT | AverageAbsY                 1.06265
2017-07-02 15:15:32.930357 EDT | AverageAbsQYDiff            0.0174803
2017-07-02 15:15:32.930498 EDT | AverageAction               0.703986
2017-07-02 15:15:32.930662 EDT | PolicyRegParamNorm         64.3828
2017-07-02 15:15:32.930833 EDT | QFunRegParamNorm           62.7885
2017-07-02 15:15:32.931015 EDT | -----------------------  -------------
2017-07-02 15:15:32.931234 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #666 | Training started
2017-07-02 15:15:42.318986 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #666 | Training finished
2017-07-02 15:15:42.319583 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #666 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 15:15:42.319743 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #666 | Collecting samples for evaluation
2017-07-02 15:15:47.581292 EDT | -----------------------  -------------
2017-07-02 15:15:47.581723 EDT | Epoch                     666
2017-07-02 15:15:47.581960 EDT | Iteration                 666
2017-07-02 15:15:47.582183 EDT | AverageReturn            1000
2017-07-02 15:15:47.582417 EDT | StdReturn                   0
2017-07-02 15:15:47.582647 EDT | MaxReturn                1000
2017-07-02 15:15:47.582877 EDT | MinReturn                1000
2017-07-02 15:15:47.583106 EDT | AverageEsReturn            36.96
2017-07-02 15:15:47.583332 EDT | StdEsReturn                28.7576
2017-07-02 15:15:47.583550 EDT | MaxEsReturn               110
2017-07-02 15:15:47.583779 EDT | MinEsReturn                 2
2017-07-02 15:15:47.584009 EDT | AverageDiscountedReturn    99.9957
2017-07-02 15:15:47.584229 EDT | AverageQLoss                0.00468694
2017-07-02 15:15:47.584446 EDT | AveragePolicySurr          -1.10886
2017-07-02 15:15:47.584671 EDT | AverageQ                    1.05828
2017-07-02 15:15:47.584901 EDT | AverageAbsQ                 1.06199
2017-07-02 15:15:47.585130 EDT | AverageY                    1.05829
2017-07-02 15:15:47.585351 EDT | AverageAbsY                 1.05853
2017-07-02 15:15:47.585587 EDT | AverageAbsQYDiff            0.0187172
2017-07-02 15:15:47.585806 EDT | AverageAction               0.92564
2017-07-02 15:15:47.586024 EDT | PolicyRegParamNorm         64.391
2017-07-02 15:15:47.586242 EDT | QFunRegParamNorm           62.8176
2017-07-02 15:15:47.586461 EDT | -----------------------  -------------
2017-07-02 15:15:47.586775 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #667 | Training started
2017-07-02 15:15:56.766314 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #667 | Training finished
2017-07-02 15:15:56.766559 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #667 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 15:15:56.766847 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #667 | Collecting samples for evaluation
2017-07-02 15:16:02.230194 EDT | -----------------------  -------------
2017-07-02 15:16:02.230760 EDT | Epoch                     667
2017-07-02 15:16:02.231004 EDT | Iteration                 667
2017-07-02 15:16:02.231127 EDT | AverageReturn            1000
2017-07-02 15:16:02.231229 EDT | StdReturn                   0
2017-07-02 15:16:02.231328 EDT | MaxReturn                1000
2017-07-02 15:16:02.231467 EDT | MinReturn                1000
2017-07-02 15:16:02.231571 EDT | AverageEsReturn            27.4103
2017-07-02 15:16:02.231708 EDT | StdEsReturn                21.5522
2017-07-02 15:16:02.231921 EDT | MaxEsReturn                85
2017-07-02 15:16:02.232122 EDT | MinEsReturn                 3
2017-07-02 15:16:02.232339 EDT | AverageDiscountedReturn    99.9957
2017-07-02 15:16:02.232549 EDT | AverageQLoss                0.00337021
2017-07-02 15:16:02.232662 EDT | AveragePolicySurr          -1.1095
2017-07-02 15:16:02.232764 EDT | AverageQ                    1.05969
2017-07-02 15:16:02.232979 EDT | AverageAbsQ                 1.06278
2017-07-02 15:16:02.233208 EDT | AverageY                    1.05969
2017-07-02 15:16:02.233423 EDT | AverageAbsY                 1.06009
2017-07-02 15:16:02.233659 EDT | AverageAbsQYDiff            0.0156194
2017-07-02 15:16:02.233868 EDT | AverageAction               0.953186
2017-07-02 15:16:02.234047 EDT | PolicyRegParamNorm         64.3652
2017-07-02 15:16:02.234248 EDT | QFunRegParamNorm           62.7971
2017-07-02 15:16:02.234458 EDT | -----------------------  -------------
2017-07-02 15:16:02.234696 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #668 | Training started
2017-07-02 15:16:11.554953 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #668 | Training finished
2017-07-02 15:16:11.555568 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #668 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 15:16:11.555734 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #668 | Collecting samples for evaluation
2017-07-02 15:16:17.090043 EDT | -----------------------  -------------
2017-07-02 15:16:17.090365 EDT | Epoch                     668
2017-07-02 15:16:17.090513 EDT | Iteration                 668
2017-07-02 15:16:17.090696 EDT | AverageReturn            1000
2017-07-02 15:16:17.090805 EDT | StdReturn                   0
2017-07-02 15:16:17.090908 EDT | MaxReturn                1000
2017-07-02 15:16:17.091076 EDT | MinReturn                1000
2017-07-02 15:16:17.091201 EDT | AverageEsReturn            31.4688
2017-07-02 15:16:17.091326 EDT | StdEsReturn                35.0294
2017-07-02 15:16:17.091520 EDT | MaxEsReturn               161
2017-07-02 15:16:17.091663 EDT | MinEsReturn                 4
2017-07-02 15:16:17.091854 EDT | AverageDiscountedReturn    99.9957
2017-07-02 15:16:17.091981 EDT | AverageQLoss                0.00442447
2017-07-02 15:16:17.092139 EDT | AveragePolicySurr          -1.10691
2017-07-02 15:16:17.092293 EDT | AverageQ                    1.05726
2017-07-02 15:16:17.092496 EDT | AverageAbsQ                 1.061
2017-07-02 15:16:17.092675 EDT | AverageY                    1.05728
2017-07-02 15:16:17.092794 EDT | AverageAbsY                 1.05776
2017-07-02 15:16:17.092941 EDT | AverageAbsQYDiff            0.017898
2017-07-02 15:16:17.093072 EDT | AverageAction               0.585214
2017-07-02 15:16:17.093179 EDT | PolicyRegParamNorm         64.3397
2017-07-02 15:16:17.093351 EDT | QFunRegParamNorm           62.8369
2017-07-02 15:16:17.093670 EDT | -----------------------  -------------
2017-07-02 15:16:17.093845 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #669 | Training started
2017-07-02 15:16:26.559406 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #669 | Training finished
2017-07-02 15:16:26.559637 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #669 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 15:16:26.559756 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #669 | Collecting samples for evaluation
2017-07-02 15:16:32.050916 EDT | -----------------------  -------------
2017-07-02 15:16:32.051521 EDT | Epoch                     669
2017-07-02 15:16:32.051714 EDT | Iteration                 669
2017-07-02 15:16:32.051847 EDT | AverageReturn            1000
2017-07-02 15:16:32.051970 EDT | StdReturn                   0
2017-07-02 15:16:32.052128 EDT | MaxReturn                1000
2017-07-02 15:16:32.052271 EDT | MinReturn                1000
2017-07-02 15:16:32.052422 EDT | AverageEsReturn            36.6667
2017-07-02 15:16:32.052609 EDT | StdEsReturn                44.587
2017-07-02 15:16:32.052791 EDT | MaxEsReturn               221
2017-07-02 15:16:32.052988 EDT | MinEsReturn                 2
2017-07-02 15:16:32.053096 EDT | AverageDiscountedReturn    99.9957
2017-07-02 15:16:32.053209 EDT | AverageQLoss                0.00456667
2017-07-02 15:16:32.053400 EDT | AveragePolicySurr          -1.10221
2017-07-02 15:16:32.053599 EDT | AverageQ                    1.05022
2017-07-02 15:16:32.053734 EDT | AverageAbsQ                 1.05447
2017-07-02 15:16:32.053842 EDT | AverageY                    1.05018
2017-07-02 15:16:32.054001 EDT | AverageAbsY                 1.05049
2017-07-02 15:16:32.054174 EDT | AverageAbsQYDiff            0.0189539
2017-07-02 15:16:32.054319 EDT | AverageAction               0.939223
2017-07-02 15:16:32.054430 EDT | PolicyRegParamNorm         64.3457
2017-07-02 15:16:32.054563 EDT | QFunRegParamNorm           62.8655
2017-07-02 15:16:32.054685 EDT | -----------------------  -------------
2017-07-02 15:16:32.054854 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #670 | Training started
2017-07-02 15:16:41.593173 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #670 | Training finished
2017-07-02 15:16:41.593895 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #670 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 15:16:41.594241 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #670 | Collecting samples for evaluation
2017-07-02 15:16:47.034460 EDT | -----------------------  -------------
2017-07-02 15:16:47.034695 EDT | Epoch                     670
2017-07-02 15:16:47.034898 EDT | Iteration                 670
2017-07-02 15:16:47.035123 EDT | AverageReturn            1000
2017-07-02 15:16:47.035329 EDT | StdReturn                   0
2017-07-02 15:16:47.035518 EDT | MaxReturn                1000
2017-07-02 15:16:47.035647 EDT | MinReturn                1000
2017-07-02 15:16:47.035791 EDT | AverageEsReturn            41.8333
2017-07-02 15:16:47.035985 EDT | StdEsReturn                35.5559
2017-07-02 15:16:47.036092 EDT | MaxEsReturn               149
2017-07-02 15:16:47.036194 EDT | MinEsReturn                 3
2017-07-02 15:16:47.036337 EDT | AverageDiscountedReturn    99.9957
2017-07-02 15:16:47.036476 EDT | AverageQLoss                0.00443789
2017-07-02 15:16:47.036631 EDT | AveragePolicySurr          -1.10039
2017-07-02 15:16:47.036802 EDT | AverageQ                    1.04988
2017-07-02 15:16:47.036949 EDT | AverageAbsQ                 1.05306
2017-07-02 15:16:47.037149 EDT | AverageY                    1.04985
2017-07-02 15:16:47.037347 EDT | AverageAbsY                 1.05012
2017-07-02 15:16:47.037712 EDT | AverageAbsQYDiff            0.017511
2017-07-02 15:16:47.037886 EDT | AverageAction               0.907238
2017-07-02 15:16:47.037992 EDT | PolicyRegParamNorm         64.4234
2017-07-02 15:16:47.038093 EDT | QFunRegParamNorm           62.8872
2017-07-02 15:16:47.038192 EDT | -----------------------  -------------
2017-07-02 15:16:47.038504 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #671 | Training started
2017-07-02 15:16:56.415898 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #671 | Training finished
2017-07-02 15:16:56.416397 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #671 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 15:16:56.416528 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #671 | Collecting samples for evaluation
2017-07-02 15:17:01.862148 EDT | -----------------------  -------------
2017-07-02 15:17:01.862616 EDT | Epoch                     671
2017-07-02 15:17:01.862745 EDT | Iteration                 671
2017-07-02 15:17:01.862853 EDT | AverageReturn            1000
2017-07-02 15:17:01.862978 EDT | StdReturn                   0
2017-07-02 15:17:01.863089 EDT | MaxReturn                1000
2017-07-02 15:17:01.863261 EDT | MinReturn                1000
2017-07-02 15:17:01.863459 EDT | AverageEsReturn            38.9583
2017-07-02 15:17:01.863656 EDT | StdEsReturn                33.5528
2017-07-02 15:17:01.863829 EDT | MaxEsReturn               130
2017-07-02 15:17:01.863931 EDT | MinEsReturn                 5
2017-07-02 15:17:01.864066 EDT | AverageDiscountedReturn    99.9957
2017-07-02 15:17:01.864170 EDT | AverageQLoss                0.00357925
2017-07-02 15:17:01.864270 EDT | AveragePolicySurr          -1.09977
2017-07-02 15:17:01.864403 EDT | AverageQ                    1.04935
2017-07-02 15:17:01.864606 EDT | AverageAbsQ                 1.0527
2017-07-02 15:17:01.864836 EDT | AverageY                    1.04936
2017-07-02 15:17:01.865061 EDT | AverageAbsY                 1.04965
2017-07-02 15:17:01.865293 EDT | AverageAbsQYDiff            0.0166048
2017-07-02 15:17:01.865534 EDT | AverageAction               0.975315
2017-07-02 15:17:01.865742 EDT | PolicyRegParamNorm         64.4522
2017-07-02 15:17:01.865972 EDT | QFunRegParamNorm           62.9115
2017-07-02 15:17:01.866266 EDT | -----------------------  -------------
2017-07-02 15:17:01.866606 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #672 | Training started
2017-07-02 15:17:11.210346 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #672 | Training finished
2017-07-02 15:17:11.210838 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #672 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 15:17:11.211090 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #672 | Collecting samples for evaluation
2017-07-02 15:17:16.701880 EDT | -----------------------  -------------
2017-07-02 15:17:16.702085 EDT | Epoch                     672
2017-07-02 15:17:16.702206 EDT | Iteration                 672
2017-07-02 15:17:16.702344 EDT | AverageReturn            1000
2017-07-02 15:17:16.702507 EDT | StdReturn                   0
2017-07-02 15:17:16.702621 EDT | MaxReturn                1000
2017-07-02 15:17:16.702736 EDT | MinReturn                1000
2017-07-02 15:17:16.702859 EDT | AverageEsReturn            45.4348
2017-07-02 15:17:16.702961 EDT | StdEsReturn                38.278
2017-07-02 15:17:16.703127 EDT | MaxEsReturn               154
2017-07-02 15:17:16.703249 EDT | MinEsReturn                 8
2017-07-02 15:17:16.703378 EDT | AverageDiscountedReturn    99.9957
2017-07-02 15:17:16.703501 EDT | AverageQLoss                0.00409011
2017-07-02 15:17:16.703622 EDT | AveragePolicySurr          -1.09811
2017-07-02 15:17:16.703778 EDT | AverageQ                    1.05114
2017-07-02 15:17:16.703885 EDT | AverageAbsQ                 1.05362
2017-07-02 15:17:16.703986 EDT | AverageY                    1.05105
2017-07-02 15:17:16.704129 EDT | AverageAbsY                 1.05137
2017-07-02 15:17:16.704231 EDT | AverageAbsQYDiff            0.016468
2017-07-02 15:17:16.704373 EDT | AverageAction               0.928256
2017-07-02 15:17:16.704477 EDT | PolicyRegParamNorm         64.5038
2017-07-02 15:17:16.704632 EDT | QFunRegParamNorm           62.9318
2017-07-02 15:17:16.704750 EDT | -----------------------  -------------
2017-07-02 15:17:16.704940 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #673 | Training started
2017-07-02 15:17:25.922933 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #673 | Training finished
2017-07-02 15:17:25.923464 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #673 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 15:17:25.923674 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #673 | Collecting samples for evaluation
2017-07-02 15:17:31.538548 EDT | -----------------------  -------------
2017-07-02 15:17:31.539190 EDT | Epoch                     673
2017-07-02 15:17:31.539399 EDT | Iteration                 673
2017-07-02 15:17:31.539543 EDT | AverageReturn            1000
2017-07-02 15:17:31.539691 EDT | StdReturn                   0
2017-07-02 15:17:31.539858 EDT | MaxReturn                1000
2017-07-02 15:17:31.540053 EDT | MinReturn                1000
2017-07-02 15:17:31.540167 EDT | AverageEsReturn            30.1176
2017-07-02 15:17:31.540311 EDT | StdEsReturn                27.2146
2017-07-02 15:17:31.540499 EDT | MaxEsReturn               109
2017-07-02 15:17:31.540647 EDT | MinEsReturn                 3
2017-07-02 15:17:31.540749 EDT | AverageDiscountedReturn    99.9957
2017-07-02 15:17:31.540887 EDT | AverageQLoss                0.00378328
2017-07-02 15:17:31.541007 EDT | AveragePolicySurr          -1.09686
2017-07-02 15:17:31.541138 EDT | AverageQ                    1.04604
2017-07-02 15:17:31.541321 EDT | AverageAbsQ                 1.04926
2017-07-02 15:17:31.541434 EDT | AverageY                    1.04607
2017-07-02 15:17:31.541650 EDT | AverageAbsY                 1.04634
2017-07-02 15:17:31.541832 EDT | AverageAbsQYDiff            0.0169369
2017-07-02 15:17:31.541953 EDT | AverageAction               0.9252
2017-07-02 15:17:31.542062 EDT | PolicyRegParamNorm         64.5717
2017-07-02 15:17:31.542225 EDT | QFunRegParamNorm           62.9377
2017-07-02 15:17:31.542329 EDT | -----------------------  -------------
2017-07-02 15:17:31.542512 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #674 | Training started
2017-07-02 15:17:40.860784 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #674 | Training finished
2017-07-02 15:17:40.861305 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #674 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 15:17:40.861514 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #674 | Collecting samples for evaluation
2017-07-02 15:17:46.338475 EDT | -----------------------  -------------
2017-07-02 15:17:46.338653 EDT | Epoch                     674
2017-07-02 15:17:46.338820 EDT | Iteration                 674
2017-07-02 15:17:46.339001 EDT | AverageReturn            1000
2017-07-02 15:17:46.339130 EDT | StdReturn                   0
2017-07-02 15:17:46.339240 EDT | MaxReturn                1000
2017-07-02 15:17:46.339342 EDT | MinReturn                1000
2017-07-02 15:17:46.339460 EDT | AverageEsReturn            39.56
2017-07-02 15:17:46.339566 EDT | StdEsReturn                37.9348
2017-07-02 15:17:46.339666 EDT | MaxEsReturn               152
2017-07-02 15:17:46.339783 EDT | MinEsReturn                 3
2017-07-02 15:17:46.339883 EDT | AverageDiscountedReturn    99.9957
2017-07-02 15:17:46.339983 EDT | AverageQLoss                0.00385174
2017-07-02 15:17:46.340092 EDT | AveragePolicySurr          -1.09562
2017-07-02 15:17:46.340219 EDT | AverageQ                    1.04595
2017-07-02 15:17:46.340319 EDT | AverageAbsQ                 1.04855
2017-07-02 15:17:46.340448 EDT | AverageY                    1.04594
2017-07-02 15:17:46.340564 EDT | AverageAbsY                 1.04604
2017-07-02 15:17:46.340723 EDT | AverageAbsQYDiff            0.0159644
2017-07-02 15:17:46.340891 EDT | AverageAction               0.703937
2017-07-02 15:17:46.341091 EDT | PolicyRegParamNorm         64.6062
2017-07-02 15:17:46.341280 EDT | QFunRegParamNorm           62.9595
2017-07-02 15:17:46.341425 EDT | -----------------------  -------------
2017-07-02 15:17:46.341609 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #675 | Training started
2017-07-02 15:17:55.741098 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #675 | Training finished
2017-07-02 15:17:55.741635 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #675 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 15:17:55.741870 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #675 | Collecting samples for evaluation
2017-07-02 15:18:01.166758 EDT | -----------------------  -------------
2017-07-02 15:18:01.167028 EDT | Epoch                     675
2017-07-02 15:18:01.167154 EDT | Iteration                 675
2017-07-02 15:18:01.167258 EDT | AverageReturn            1000
2017-07-02 15:18:01.167358 EDT | StdReturn                   0
2017-07-02 15:18:01.167510 EDT | MaxReturn                1000
2017-07-02 15:18:01.167714 EDT | MinReturn                1000
2017-07-02 15:18:01.167833 EDT | AverageEsReturn            35.8462
2017-07-02 15:18:01.167936 EDT | StdEsReturn                27.9721
2017-07-02 15:18:01.168061 EDT | MaxEsReturn               121
2017-07-02 15:18:01.168228 EDT | MinEsReturn                 4
2017-07-02 15:18:01.168351 EDT | AverageDiscountedReturn    99.9957
2017-07-02 15:18:01.168494 EDT | AverageQLoss                0.00442668
2017-07-02 15:18:01.168636 EDT | AveragePolicySurr          -1.09058
2017-07-02 15:18:01.168832 EDT | AverageQ                    1.04106
2017-07-02 15:18:01.169015 EDT | AverageAbsQ                 1.04436
2017-07-02 15:18:01.169144 EDT | AverageY                    1.04103
2017-07-02 15:18:01.169294 EDT | AverageAbsY                 1.04124
2017-07-02 15:18:01.169400 EDT | AverageAbsQYDiff            0.0175855
2017-07-02 15:18:01.169618 EDT | AverageAction               0.940585
2017-07-02 15:18:01.169742 EDT | PolicyRegParamNorm         64.6289
2017-07-02 15:18:01.169871 EDT | QFunRegParamNorm           62.9845
2017-07-02 15:18:01.170049 EDT | -----------------------  -------------
2017-07-02 15:18:01.170288 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #676 | Training started
2017-07-02 15:18:10.823491 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #676 | Training finished
2017-07-02 15:18:10.824114 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #676 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 15:18:10.824292 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #676 | Collecting samples for evaluation
2017-07-02 15:18:16.354163 EDT | -----------------------  -------------
2017-07-02 15:18:16.354399 EDT | Epoch                     676
2017-07-02 15:18:16.354509 EDT | Iteration                 676
2017-07-02 15:18:16.354663 EDT | AverageReturn            1000
2017-07-02 15:18:16.354853 EDT | StdReturn                   0
2017-07-02 15:18:16.355027 EDT | MaxReturn                1000
2017-07-02 15:18:16.355198 EDT | MinReturn                1000
2017-07-02 15:18:16.355305 EDT | AverageEsReturn            35.7333
2017-07-02 15:18:16.355500 EDT | StdEsReturn                29.769
2017-07-02 15:18:16.355622 EDT | MaxEsReturn               109
2017-07-02 15:18:16.355721 EDT | MinEsReturn                 7
2017-07-02 15:18:16.355823 EDT | AverageDiscountedReturn    99.9957
2017-07-02 15:18:16.356042 EDT | AverageQLoss                0.00423838
2017-07-02 15:18:16.356266 EDT | AveragePolicySurr          -1.09063
2017-07-02 15:18:16.356467 EDT | AverageQ                    1.04189
2017-07-02 15:18:16.356696 EDT | AverageAbsQ                 1.04495
2017-07-02 15:18:16.356920 EDT | AverageY                    1.04199
2017-07-02 15:18:16.357074 EDT | AverageAbsY                 1.04223
2017-07-02 15:18:16.357300 EDT | AverageAbsQYDiff            0.0174386
2017-07-02 15:18:16.357563 EDT | AverageAction               0.965797
2017-07-02 15:18:16.357756 EDT | PolicyRegParamNorm         64.6405
2017-07-02 15:18:16.357987 EDT | QFunRegParamNorm           62.9728
2017-07-02 15:18:16.358197 EDT | -----------------------  -------------
2017-07-02 15:18:16.358440 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #677 | Training started
2017-07-02 15:18:25.714552 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #677 | Training finished
2017-07-02 15:18:25.715169 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #677 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 15:18:25.715306 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #677 | Collecting samples for evaluation
2017-07-02 15:18:31.257084 EDT | -----------------------  -------------
2017-07-02 15:18:31.257391 EDT | Epoch                     677
2017-07-02 15:18:31.257695 EDT | Iteration                 677
2017-07-02 15:18:31.257889 EDT | AverageReturn            1000
2017-07-02 15:18:31.258113 EDT | StdReturn                   0
2017-07-02 15:18:31.258324 EDT | MaxReturn                1000
2017-07-02 15:18:31.258556 EDT | MinReturn                1000
2017-07-02 15:18:31.258749 EDT | AverageEsReturn            39.72
2017-07-02 15:18:31.258855 EDT | StdEsReturn                32.9345
2017-07-02 15:18:31.258957 EDT | MaxEsReturn               169
2017-07-02 15:18:31.259089 EDT | MinEsReturn                 9
2017-07-02 15:18:31.259189 EDT | AverageDiscountedReturn    99.9957
2017-07-02 15:18:31.259289 EDT | AverageQLoss                0.00398954
2017-07-02 15:18:31.259390 EDT | AveragePolicySurr          -1.08802
2017-07-02 15:18:31.259492 EDT | AverageQ                    1.03768
2017-07-02 15:18:31.259673 EDT | AverageAbsQ                 1.04125
2017-07-02 15:18:31.259829 EDT | AverageY                    1.03753
2017-07-02 15:18:31.260004 EDT | AverageAbsY                 1.03792
2017-07-02 15:18:31.260227 EDT | AverageAbsQYDiff            0.0177783
2017-07-02 15:18:31.260432 EDT | AverageAction               0.79695
2017-07-02 15:18:31.260540 EDT | PolicyRegParamNorm         64.6459
2017-07-02 15:18:31.260698 EDT | QFunRegParamNorm           63.0079
2017-07-02 15:18:31.260828 EDT | -----------------------  -------------
2017-07-02 15:18:31.260991 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #678 | Training started
2017-07-02 15:18:40.572519 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #678 | Training finished
2017-07-02 15:18:40.573192 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #678 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 15:18:40.573354 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #678 | Collecting samples for evaluation
2017-07-02 15:18:46.080588 EDT | -----------------------  -------------
2017-07-02 15:18:46.080796 EDT | Epoch                     678
2017-07-02 15:18:46.080952 EDT | Iteration                 678
2017-07-02 15:18:46.081120 EDT | AverageReturn            1000
2017-07-02 15:18:46.081304 EDT | StdReturn                   0
2017-07-02 15:18:46.081541 EDT | MaxReturn                1000
2017-07-02 15:18:46.081735 EDT | MinReturn                1000
2017-07-02 15:18:46.081924 EDT | AverageEsReturn            36.2222
2017-07-02 15:18:46.082111 EDT | StdEsReturn                28.8269
2017-07-02 15:18:46.082337 EDT | MaxEsReturn               121
2017-07-02 15:18:46.082552 EDT | MinEsReturn                10
2017-07-02 15:18:46.082764 EDT | AverageDiscountedReturn    99.9957
2017-07-02 15:18:46.082991 EDT | AverageQLoss                0.00344357
2017-07-02 15:18:46.083214 EDT | AveragePolicySurr          -1.08526
2017-07-02 15:18:46.083401 EDT | AverageQ                    1.03684
2017-07-02 15:18:46.083595 EDT | AverageAbsQ                 1.03986
2017-07-02 15:18:46.083815 EDT | AverageY                    1.03681
2017-07-02 15:18:46.084017 EDT | AverageAbsY                 1.03715
2017-07-02 15:18:46.084213 EDT | AverageAbsQYDiff            0.0153032
2017-07-02 15:18:46.084443 EDT | AverageAction               0.959602
2017-07-02 15:18:46.084664 EDT | PolicyRegParamNorm         64.653
2017-07-02 15:18:46.084889 EDT | QFunRegParamNorm           63.0383
2017-07-02 15:18:46.085115 EDT | -----------------------  -------------
2017-07-02 15:18:46.085422 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #679 | Training started
2017-07-02 15:18:55.420738 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #679 | Training finished
2017-07-02 15:18:55.421322 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #679 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 15:18:55.421558 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #679 | Collecting samples for evaluation
2017-07-02 15:19:00.909303 EDT | -----------------------  -------------
2017-07-02 15:19:00.909633 EDT | Epoch                     679
2017-07-02 15:19:00.909855 EDT | Iteration                 679
2017-07-02 15:19:00.910028 EDT | AverageReturn            1000
2017-07-02 15:19:00.910248 EDT | StdReturn                   0
2017-07-02 15:19:00.910419 EDT | MaxReturn                1000
2017-07-02 15:19:00.910525 EDT | MinReturn                1000
2017-07-02 15:19:00.910637 EDT | AverageEsReturn            41.52
2017-07-02 15:19:00.910854 EDT | StdEsReturn                40.0461
2017-07-02 15:19:00.911076 EDT | MaxEsReturn               184
2017-07-02 15:19:00.911283 EDT | MinEsReturn                 5
2017-07-02 15:19:00.911500 EDT | AverageDiscountedReturn    99.9957
2017-07-02 15:19:00.911697 EDT | AverageQLoss                0.00436544
2017-07-02 15:19:00.911902 EDT | AveragePolicySurr          -1.08614
2017-07-02 15:19:00.912113 EDT | AverageQ                    1.0352
2017-07-02 15:19:00.912221 EDT | AverageAbsQ                 1.03933
2017-07-02 15:19:00.912430 EDT | AverageY                    1.03517
2017-07-02 15:19:00.912649 EDT | AverageAbsY                 1.03541
2017-07-02 15:19:00.912792 EDT | AverageAbsQYDiff            0.0178996
2017-07-02 15:19:00.912897 EDT | AverageAction               0.968344
2017-07-02 15:19:00.912997 EDT | PolicyRegParamNorm         64.6277
2017-07-02 15:19:00.913095 EDT | QFunRegParamNorm           63.0752
2017-07-02 15:19:00.913192 EDT | -----------------------  -------------
2017-07-02 15:19:00.913441 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #680 | Training started
2017-07-02 15:19:10.252669 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #680 | Training finished
2017-07-02 15:19:10.253707 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #680 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 15:19:10.255311 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #680 | Collecting samples for evaluation
2017-07-02 15:19:15.722837 EDT | -----------------------  -------------
2017-07-02 15:19:15.723040 EDT | Epoch                     680
2017-07-02 15:19:15.723229 EDT | Iteration                 680
2017-07-02 15:19:15.723408 EDT | AverageReturn            1000
2017-07-02 15:19:15.723537 EDT | StdReturn                   0
2017-07-02 15:19:15.723663 EDT | MaxReturn                1000
2017-07-02 15:19:15.723767 EDT | MinReturn                1000
2017-07-02 15:19:15.723869 EDT | AverageEsReturn            30.3333
2017-07-02 15:19:15.723980 EDT | StdEsReturn                34.5237
2017-07-02 15:19:15.724129 EDT | MaxEsReturn               168
2017-07-02 15:19:15.724234 EDT | MinEsReturn                 2
2017-07-02 15:19:15.724427 EDT | AverageDiscountedReturn    99.9957
2017-07-02 15:19:15.724546 EDT | AverageQLoss                0.00413331
2017-07-02 15:19:15.724659 EDT | AveragePolicySurr          -1.08053
2017-07-02 15:19:15.724852 EDT | AverageQ                    1.03155
2017-07-02 15:19:15.724956 EDT | AverageAbsQ                 1.03458
2017-07-02 15:19:15.725057 EDT | AverageY                    1.03161
2017-07-02 15:19:15.725178 EDT | AverageAbsY                 1.03204
2017-07-02 15:19:15.725329 EDT | AverageAbsQYDiff            0.0175244
2017-07-02 15:19:15.725430 EDT | AverageAction               0.96685
2017-07-02 15:19:15.725721 EDT | PolicyRegParamNorm         64.597
2017-07-02 15:19:15.725827 EDT | QFunRegParamNorm           63.0957
2017-07-02 15:19:15.725996 EDT | -----------------------  -------------
2017-07-02 15:19:15.726256 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #681 | Training started
2017-07-02 15:19:25.099990 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #681 | Training finished
2017-07-02 15:19:25.100607 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #681 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 15:19:25.100793 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #681 | Collecting samples for evaluation
2017-07-02 15:19:30.565306 EDT | -----------------------  -------------
2017-07-02 15:19:30.565522 EDT | Epoch                     681
2017-07-02 15:19:30.565743 EDT | Iteration                 681
2017-07-02 15:19:30.565973 EDT | AverageReturn            1000
2017-07-02 15:19:30.566152 EDT | StdReturn                   0
2017-07-02 15:19:30.566383 EDT | MaxReturn                1000
2017-07-02 15:19:30.566583 EDT | MinReturn                1000
2017-07-02 15:19:30.566811 EDT | AverageEsReturn            36.1333
2017-07-02 15:19:30.567029 EDT | StdEsReturn                38.2977
2017-07-02 15:19:30.567229 EDT | MaxEsReturn               175
2017-07-02 15:19:30.567457 EDT | MinEsReturn                 4
2017-07-02 15:19:30.567631 EDT | AverageDiscountedReturn    99.9957
2017-07-02 15:19:30.567861 EDT | AverageQLoss                0.00357846
2017-07-02 15:19:30.568056 EDT | AveragePolicySurr          -1.07807
2017-07-02 15:19:30.568285 EDT | AverageQ                    1.02858
2017-07-02 15:19:30.568506 EDT | AverageAbsQ                 1.03181
2017-07-02 15:19:30.568666 EDT | AverageY                    1.0285
2017-07-02 15:19:30.568895 EDT | AverageAbsY                 1.02904
2017-07-02 15:19:30.569079 EDT | AverageAbsQYDiff            0.0163514
2017-07-02 15:19:30.569306 EDT | AverageAction               0.949025
2017-07-02 15:19:30.569530 EDT | PolicyRegParamNorm         64.624
2017-07-02 15:19:30.569699 EDT | QFunRegParamNorm           63.1207
2017-07-02 15:19:30.569929 EDT | -----------------------  -------------
2017-07-02 15:19:30.570212 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #682 | Training started
2017-07-02 15:19:39.992602 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #682 | Training finished
2017-07-02 15:19:39.993232 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #682 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 15:19:39.993459 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #682 | Collecting samples for evaluation
2017-07-02 15:19:45.525604 EDT | -----------------------  -------------
2017-07-02 15:19:45.525891 EDT | Epoch                     682
2017-07-02 15:19:45.526125 EDT | Iteration                 682
2017-07-02 15:19:45.526356 EDT | AverageReturn            1000
2017-07-02 15:19:45.526585 EDT | StdReturn                   0
2017-07-02 15:19:45.526760 EDT | MaxReturn                1000
2017-07-02 15:19:45.526991 EDT | MinReturn                1000
2017-07-02 15:19:45.527211 EDT | AverageEsReturn            31.3548
2017-07-02 15:19:45.527436 EDT | StdEsReturn                25.5741
2017-07-02 15:19:45.527663 EDT | MaxEsReturn               111
2017-07-02 15:19:45.527874 EDT | MinEsReturn                 4
2017-07-02 15:19:45.528102 EDT | AverageDiscountedReturn    99.9957
2017-07-02 15:19:45.528328 EDT | AverageQLoss                0.00409306
2017-07-02 15:19:45.528521 EDT | AveragePolicySurr          -1.07742
2017-07-02 15:19:45.528745 EDT | AverageQ                    1.02987
2017-07-02 15:19:45.528925 EDT | AverageAbsQ                 1.03322
2017-07-02 15:19:45.529155 EDT | AverageY                    1.02988
2017-07-02 15:19:45.529355 EDT | AverageAbsY                 1.03036
2017-07-02 15:19:45.529633 EDT | AverageAbsQYDiff            0.0168383
2017-07-02 15:19:45.529848 EDT | AverageAction               0.924818
2017-07-02 15:19:45.530010 EDT | PolicyRegParamNorm         64.6912
2017-07-02 15:19:45.530240 EDT | QFunRegParamNorm           63.1395
2017-07-02 15:19:45.530419 EDT | -----------------------  -------------
2017-07-02 15:19:45.530742 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #683 | Training started
2017-07-02 15:19:54.849142 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #683 | Training finished
2017-07-02 15:19:54.849751 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #683 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 15:19:54.849941 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #683 | Collecting samples for evaluation
2017-07-02 15:20:00.391350 EDT | -----------------------  -------------
2017-07-02 15:20:00.391546 EDT | Epoch                     683
2017-07-02 15:20:00.391660 EDT | Iteration                 683
2017-07-02 15:20:00.391764 EDT | AverageReturn            1000
2017-07-02 15:20:00.391913 EDT | StdReturn                   0
2017-07-02 15:20:00.392019 EDT | MaxReturn                1000
2017-07-02 15:20:00.392122 EDT | MinReturn                1000
2017-07-02 15:20:00.392222 EDT | AverageEsReturn            38.1923
2017-07-02 15:20:00.392409 EDT | StdEsReturn                35.2005
2017-07-02 15:20:00.392633 EDT | MaxEsReturn               165
2017-07-02 15:20:00.392754 EDT | MinEsReturn                 3
2017-07-02 15:20:00.392927 EDT | AverageDiscountedReturn    99.9957
2017-07-02 15:20:00.393148 EDT | AverageQLoss                0.00393033
2017-07-02 15:20:00.393352 EDT | AveragePolicySurr          -1.07901
2017-07-02 15:20:00.393581 EDT | AverageQ                    1.02882
2017-07-02 15:20:00.393689 EDT | AverageAbsQ                 1.03262
2017-07-02 15:20:00.393789 EDT | AverageY                    1.02877
2017-07-02 15:20:00.393893 EDT | AverageAbsY                 1.02931
2017-07-02 15:20:00.394111 EDT | AverageAbsQYDiff            0.0174474
2017-07-02 15:20:00.394326 EDT | AverageAction               0.91795
2017-07-02 15:20:00.394521 EDT | PolicyRegParamNorm         64.6827
2017-07-02 15:20:00.394738 EDT | QFunRegParamNorm           63.1892
2017-07-02 15:20:00.394967 EDT | -----------------------  -------------
2017-07-02 15:20:00.395282 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #684 | Training started
2017-07-02 15:20:09.760418 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #684 | Training finished
2017-07-02 15:20:09.761050 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #684 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 15:20:09.761242 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #684 | Collecting samples for evaluation
2017-07-02 15:20:15.223683 EDT | -----------------------  -------------
2017-07-02 15:20:15.223942 EDT | Epoch                     684
2017-07-02 15:20:15.224176 EDT | Iteration                 684
2017-07-02 15:20:15.224406 EDT | AverageReturn            1000
2017-07-02 15:20:15.224614 EDT | StdReturn                   0
2017-07-02 15:20:15.225048 EDT | MaxReturn                1000
2017-07-02 15:20:15.225259 EDT | MinReturn                1000
2017-07-02 15:20:15.225370 EDT | AverageEsReturn            34.1
2017-07-02 15:20:15.225536 EDT | StdEsReturn                33.9915
2017-07-02 15:20:15.225645 EDT | MaxEsReturn               167
2017-07-02 15:20:15.225772 EDT | MinEsReturn                 4
2017-07-02 15:20:15.225907 EDT | AverageDiscountedReturn    99.9957
2017-07-02 15:20:15.226008 EDT | AverageQLoss                0.00367678
2017-07-02 15:20:15.226108 EDT | AveragePolicySurr          -1.07507
2017-07-02 15:20:15.226207 EDT | AverageQ                    1.02795
2017-07-02 15:20:15.226306 EDT | AverageAbsQ                 1.03141
2017-07-02 15:20:15.226515 EDT | AverageY                    1.02794
2017-07-02 15:20:15.226798 EDT | AverageAbsY                 1.02865
2017-07-02 15:20:15.227024 EDT | AverageAbsQYDiff            0.0155979
2017-07-02 15:20:15.227209 EDT | AverageAction               0.931678
2017-07-02 15:20:15.227440 EDT | PolicyRegParamNorm         64.7479
2017-07-02 15:20:15.227658 EDT | QFunRegParamNorm           63.2012
2017-07-02 15:20:15.227859 EDT | -----------------------  -------------
2017-07-02 15:20:15.228173 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #685 | Training started
2017-07-02 15:20:25.227152 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #685 | Training finished
2017-07-02 15:20:25.227758 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #685 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 15:20:25.228003 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #685 | Collecting samples for evaluation
2017-07-02 15:20:30.705826 EDT | -----------------------  -------------
2017-07-02 15:20:30.706021 EDT | Epoch                     685
2017-07-02 15:20:30.706205 EDT | Iteration                 685
2017-07-02 15:20:30.706370 EDT | AverageReturn            1000
2017-07-02 15:20:30.706549 EDT | StdReturn                   0
2017-07-02 15:20:30.706672 EDT | MaxReturn                1000
2017-07-02 15:20:30.706774 EDT | MinReturn                1000
2017-07-02 15:20:30.706905 EDT | AverageEsReturn            37.1111
2017-07-02 15:20:30.707033 EDT | StdEsReturn                47.7829
2017-07-02 15:20:30.707136 EDT | MaxEsReturn               254
2017-07-02 15:20:30.707263 EDT | MinEsReturn                 3
2017-07-02 15:20:30.707363 EDT | AverageDiscountedReturn    99.9957
2017-07-02 15:20:30.707462 EDT | AverageQLoss                0.00439359
2017-07-02 15:20:30.707604 EDT | AveragePolicySurr          -1.0733
2017-07-02 15:20:30.707771 EDT | AverageQ                    1.02613
2017-07-02 15:20:30.707914 EDT | AverageAbsQ                 1.0299
2017-07-02 15:20:30.708035 EDT | AverageY                    1.02605
2017-07-02 15:20:30.708169 EDT | AverageAbsY                 1.02671
2017-07-02 15:20:30.708362 EDT | AverageAbsQYDiff            0.017666
2017-07-02 15:20:30.708561 EDT | AverageAction               0.932196
2017-07-02 15:20:30.708738 EDT | PolicyRegParamNorm         64.8199
2017-07-02 15:20:30.708840 EDT | QFunRegParamNorm           63.2279
2017-07-02 15:20:30.709016 EDT | -----------------------  -------------
2017-07-02 15:20:30.709180 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #686 | Training started
2017-07-02 15:20:40.220243 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #686 | Training finished
2017-07-02 15:20:40.220855 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #686 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 15:20:40.221081 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #686 | Collecting samples for evaluation
2017-07-02 15:20:45.659521 EDT | -----------------------  ------------
2017-07-02 15:20:45.659703 EDT | Epoch                     686
2017-07-02 15:20:45.659873 EDT | Iteration                 686
2017-07-02 15:20:45.659988 EDT | AverageReturn            1000
2017-07-02 15:20:45.660092 EDT | StdReturn                   0
2017-07-02 15:20:45.660194 EDT | MaxReturn                1000
2017-07-02 15:20:45.660345 EDT | MinReturn                1000
2017-07-02 15:20:45.660456 EDT | AverageEsReturn            35.3704
2017-07-02 15:20:45.660587 EDT | StdEsReturn                31.8703
2017-07-02 15:20:45.660740 EDT | MaxEsReturn               129
2017-07-02 15:20:45.660891 EDT | MinEsReturn                 3
2017-07-02 15:20:45.660994 EDT | AverageDiscountedReturn    99.9957
2017-07-02 15:20:45.661113 EDT | AverageQLoss                0.0039721
2017-07-02 15:20:45.661217 EDT | AveragePolicySurr          -1.07064
2017-07-02 15:20:45.661378 EDT | AverageQ                    1.02213
2017-07-02 15:20:45.661696 EDT | AverageAbsQ                 1.0259
2017-07-02 15:20:45.661825 EDT | AverageY                    1.02211
2017-07-02 15:20:45.661931 EDT | AverageAbsY                 1.02328
2017-07-02 15:20:45.662032 EDT | AverageAbsQYDiff            0.0166695
2017-07-02 15:20:45.662138 EDT | AverageAction               0.896491
2017-07-02 15:20:45.662301 EDT | PolicyRegParamNorm         64.8738
2017-07-02 15:20:45.662415 EDT | QFunRegParamNorm           63.2527
2017-07-02 15:20:45.662523 EDT | -----------------------  ------------
2017-07-02 15:20:45.662696 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #687 | Training started
2017-07-02 15:20:55.139525 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #687 | Training finished
2017-07-02 15:20:55.140146 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #687 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 15:20:55.140407 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #687 | Collecting samples for evaluation
2017-07-02 15:21:00.625085 EDT | -----------------------  -------------
2017-07-02 15:21:00.625286 EDT | Epoch                     687
2017-07-02 15:21:00.625455 EDT | Iteration                 687
2017-07-02 15:21:00.625672 EDT | AverageReturn            1000
2017-07-02 15:21:00.625837 EDT | StdReturn                   0
2017-07-02 15:21:00.625996 EDT | MaxReturn                1000
2017-07-02 15:21:00.626187 EDT | MinReturn                1000
2017-07-02 15:21:00.626298 EDT | AverageEsReturn            40.7692
2017-07-02 15:21:00.626472 EDT | StdEsReturn                29.2289
2017-07-02 15:21:00.626574 EDT | MaxEsReturn               116
2017-07-02 15:21:00.626675 EDT | MinEsReturn                 5
2017-07-02 15:21:00.626829 EDT | AverageDiscountedReturn    99.9957
2017-07-02 15:21:00.626966 EDT | AverageQLoss                0.00316443
2017-07-02 15:21:00.627068 EDT | AveragePolicySurr          -1.07069
2017-07-02 15:21:00.627214 EDT | AverageQ                    1.02111
2017-07-02 15:21:00.627407 EDT | AverageAbsQ                 1.0249
2017-07-02 15:21:00.627632 EDT | AverageY                    1.02121
2017-07-02 15:21:00.627854 EDT | AverageAbsY                 1.02196
2017-07-02 15:21:00.628036 EDT | AverageAbsQYDiff            0.0155923
2017-07-02 15:21:00.628141 EDT | AverageAction               0.932867
2017-07-02 15:21:00.628242 EDT | PolicyRegParamNorm         64.8781
2017-07-02 15:21:00.628401 EDT | QFunRegParamNorm           63.2651
2017-07-02 15:21:00.628534 EDT | -----------------------  -------------
2017-07-02 15:21:00.628843 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #688 | Training started
2017-07-02 15:21:10.008936 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #688 | Training finished
2017-07-02 15:21:10.009540 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #688 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 15:21:10.009758 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #688 | Collecting samples for evaluation
2017-07-02 15:21:15.470013 EDT | -----------------------  -------------
2017-07-02 15:21:15.470194 EDT | Epoch                     688
2017-07-02 15:21:15.470305 EDT | Iteration                 688
2017-07-02 15:21:15.470410 EDT | AverageReturn            1000
2017-07-02 15:21:15.470511 EDT | StdReturn                   0
2017-07-02 15:21:15.470670 EDT | MaxReturn                1000
2017-07-02 15:21:15.470892 EDT | MinReturn                1000
2017-07-02 15:21:15.471118 EDT | AverageEsReturn            44.2273
2017-07-02 15:21:15.471327 EDT | StdEsReturn                28.849
2017-07-02 15:21:15.471557 EDT | MaxEsReturn               121
2017-07-02 15:21:15.471772 EDT | MinEsReturn                 3
2017-07-02 15:21:15.472006 EDT | AverageDiscountedReturn    99.9957
2017-07-02 15:21:15.472152 EDT | AverageQLoss                0.00392464
2017-07-02 15:21:15.472379 EDT | AveragePolicySurr          -1.06838
2017-07-02 15:21:15.472594 EDT | AverageQ                    1.01998
2017-07-02 15:21:15.472829 EDT | AverageAbsQ                 1.02406
2017-07-02 15:21:15.473001 EDT | AverageY                    1.01985
2017-07-02 15:21:15.473218 EDT | AverageAbsY                 1.0207
2017-07-02 15:21:15.473443 EDT | AverageAbsQYDiff            0.0172158
2017-07-02 15:21:15.473699 EDT | AverageAction               0.886354
2017-07-02 15:21:15.473851 EDT | PolicyRegParamNorm         65.0099
2017-07-02 15:21:15.473958 EDT | QFunRegParamNorm           63.2565
2017-07-02 15:21:15.474184 EDT | -----------------------  -------------
2017-07-02 15:21:15.474490 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #689 | Training started
2017-07-02 15:21:24.769253 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #689 | Training finished
2017-07-02 15:21:24.769945 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #689 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 15:21:24.770201 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #689 | Collecting samples for evaluation
2017-07-02 15:21:30.254094 EDT | -----------------------  -------------
2017-07-02 15:21:30.254373 EDT | Epoch                     689
2017-07-02 15:21:30.254608 EDT | Iteration                 689
2017-07-02 15:21:30.254821 EDT | AverageReturn            1000
2017-07-02 15:21:30.255054 EDT | StdReturn                   0
2017-07-02 15:21:30.255280 EDT | MaxReturn                1000
2017-07-02 15:21:30.255469 EDT | MinReturn                1000
2017-07-02 15:21:30.255700 EDT | AverageEsReturn            42.6087
2017-07-02 15:21:30.255927 EDT | StdEsReturn                28.454
2017-07-02 15:21:30.256108 EDT | MaxEsReturn               103
2017-07-02 15:21:30.256324 EDT | MinEsReturn                 3
2017-07-02 15:21:30.256552 EDT | AverageDiscountedReturn    99.9957
2017-07-02 15:21:30.256751 EDT | AverageQLoss                0.00412344
2017-07-02 15:21:30.256981 EDT | AveragePolicySurr          -1.06527
2017-07-02 15:21:30.257185 EDT | AverageQ                    1.01566
2017-07-02 15:21:30.257414 EDT | AverageAbsQ                 1.01974
2017-07-02 15:21:30.257680 EDT | AverageY                    1.01565
2017-07-02 15:21:30.257879 EDT | AverageAbsY                 1.01642
2017-07-02 15:21:30.258106 EDT | AverageAbsQYDiff            0.0175818
2017-07-02 15:21:30.258266 EDT | AverageAction               0.924331
2017-07-02 15:21:30.258507 EDT | PolicyRegParamNorm         65.0065
2017-07-02 15:21:30.258728 EDT | QFunRegParamNorm           63.276
2017-07-02 15:21:30.258955 EDT | -----------------------  -------------
2017-07-02 15:21:30.259254 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #690 | Training started
2017-07-02 15:21:39.544941 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #690 | Training finished
2017-07-02 15:21:39.545702 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #690 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 15:21:39.545853 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #690 | Collecting samples for evaluation
2017-07-02 15:21:44.960682 EDT | -----------------------  -------------
2017-07-02 15:21:44.960882 EDT | Epoch                     690
2017-07-02 15:21:44.961009 EDT | Iteration                 690
2017-07-02 15:21:44.961114 EDT | AverageReturn            1000
2017-07-02 15:21:44.961233 EDT | StdReturn                   0
2017-07-02 15:21:44.961340 EDT | MaxReturn                1000
2017-07-02 15:21:44.961469 EDT | MinReturn                1000
2017-07-02 15:21:44.961644 EDT | AverageEsReturn            39.9565
2017-07-02 15:21:44.961748 EDT | StdEsReturn                37.2179
2017-07-02 15:21:44.961848 EDT | MaxEsReturn               174
2017-07-02 15:21:44.961981 EDT | MinEsReturn                 6
2017-07-02 15:21:44.962109 EDT | AverageDiscountedReturn    99.9957
2017-07-02 15:21:44.962240 EDT | AverageQLoss                0.00381022
2017-07-02 15:21:44.962385 EDT | AveragePolicySurr          -1.06316
2017-07-02 15:21:44.962492 EDT | AverageQ                    1.01298
2017-07-02 15:21:44.962645 EDT | AverageAbsQ                 1.01638
2017-07-02 15:21:44.962779 EDT | AverageY                    1.01295
2017-07-02 15:21:44.962907 EDT | AverageAbsY                 1.01373
2017-07-02 15:21:44.963112 EDT | AverageAbsQYDiff            0.0170826
2017-07-02 15:21:44.963326 EDT | AverageAction               0.941558
2017-07-02 15:21:44.963561 EDT | PolicyRegParamNorm         65.0315
2017-07-02 15:21:44.963784 EDT | QFunRegParamNorm           63.285
2017-07-02 15:21:44.964002 EDT | -----------------------  -------------
2017-07-02 15:21:44.964320 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #691 | Training started
2017-07-02 15:21:54.351525 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #691 | Training finished
2017-07-02 15:21:54.352275 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #691 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 15:21:54.352447 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #691 | Collecting samples for evaluation
2017-07-02 15:21:59.812460 EDT | -----------------------  -------------
2017-07-02 15:21:59.812750 EDT | Epoch                     691
2017-07-02 15:21:59.812990 EDT | Iteration                 691
2017-07-02 15:21:59.813181 EDT | AverageReturn            1000
2017-07-02 15:21:59.813413 EDT | StdReturn                   0
2017-07-02 15:21:59.813648 EDT | MaxReturn                1000
2017-07-02 15:21:59.813823 EDT | MinReturn                1000
2017-07-02 15:21:59.814054 EDT | AverageEsReturn            53.45
2017-07-02 15:21:59.814254 EDT | StdEsReturn                45.4945
2017-07-02 15:21:59.814487 EDT | MaxEsReturn               184
2017-07-02 15:21:59.814698 EDT | MinEsReturn                 4
2017-07-02 15:21:59.814817 EDT | AverageDiscountedReturn    99.9957
2017-07-02 15:21:59.815046 EDT | AverageQLoss                0.00373874
2017-07-02 15:21:59.815268 EDT | AveragePolicySurr          -1.0627
2017-07-02 15:21:59.815480 EDT | AverageQ                    1.01421
2017-07-02 15:21:59.815708 EDT | AverageAbsQ                 1.01765
2017-07-02 15:21:59.815864 EDT | AverageY                    1.01421
2017-07-02 15:21:59.816096 EDT | AverageAbsY                 1.01476
2017-07-02 15:21:59.816310 EDT | AverageAbsQYDiff            0.016288
2017-07-02 15:21:59.816504 EDT | AverageAction               0.869062
2017-07-02 15:21:59.816732 EDT | PolicyRegParamNorm         65.0718
2017-07-02 15:21:59.816917 EDT | QFunRegParamNorm           63.2975
2017-07-02 15:21:59.817150 EDT | -----------------------  -------------
2017-07-02 15:21:59.817460 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #692 | Training started
2017-07-02 15:22:09.251959 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #692 | Training finished
2017-07-02 15:22:09.252665 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #692 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 15:22:09.252827 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #692 | Collecting samples for evaluation
2017-07-02 15:22:14.758184 EDT | -----------------------  -------------
2017-07-02 15:22:14.758381 EDT | Epoch                     692
2017-07-02 15:22:14.758559 EDT | Iteration                 692
2017-07-02 15:22:14.758665 EDT | AverageReturn            1000
2017-07-02 15:22:14.758845 EDT | StdReturn                   0
2017-07-02 15:22:14.758991 EDT | MaxReturn                1000
2017-07-02 15:22:14.759113 EDT | MinReturn                1000
2017-07-02 15:22:14.759270 EDT | AverageEsReturn            43.8261
2017-07-02 15:22:14.759392 EDT | StdEsReturn                39.4898
2017-07-02 15:22:14.759516 EDT | MaxEsReturn               143
2017-07-02 15:22:14.759618 EDT | MinEsReturn                 3
2017-07-02 15:22:14.759748 EDT | AverageDiscountedReturn    99.9957
2017-07-02 15:22:14.759864 EDT | AverageQLoss                0.00352367
2017-07-02 15:22:14.760022 EDT | AveragePolicySurr          -1.06205
2017-07-02 15:22:14.760210 EDT | AverageQ                    1.01299
2017-07-02 15:22:14.760428 EDT | AverageAbsQ                 1.01608
2017-07-02 15:22:14.760647 EDT | AverageY                    1.01298
2017-07-02 15:22:14.760873 EDT | AverageAbsY                 1.01327
2017-07-02 15:22:14.761060 EDT | AverageAbsQYDiff            0.016173
2017-07-02 15:22:14.761284 EDT | AverageAction               0.928895
2017-07-02 15:22:14.761627 EDT | PolicyRegParamNorm         65.0317
2017-07-02 15:22:14.761859 EDT | QFunRegParamNorm           63.3499
2017-07-02 15:22:14.762077 EDT | -----------------------  -------------
2017-07-02 15:22:14.762395 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #693 | Training started
2017-07-02 15:22:24.126559 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #693 | Training finished
2017-07-02 15:22:24.127091 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #693 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 15:22:24.127263 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #693 | Collecting samples for evaluation
2017-07-02 15:22:29.597438 EDT | -----------------------  -------------
2017-07-02 15:22:29.597722 EDT | Epoch                     693
2017-07-02 15:22:29.597889 EDT | Iteration                 693
2017-07-02 15:22:29.598015 EDT | AverageReturn            1000
2017-07-02 15:22:29.598126 EDT | StdReturn                   0
2017-07-02 15:22:29.598287 EDT | MaxReturn                1000
2017-07-02 15:22:29.598459 EDT | MinReturn                1000
2017-07-02 15:22:29.598656 EDT | AverageEsReturn            51.8
2017-07-02 15:22:29.598839 EDT | StdEsReturn                38.0429
2017-07-02 15:22:29.598981 EDT | MaxEsReturn               136
2017-07-02 15:22:29.599164 EDT | MinEsReturn                 4
2017-07-02 15:22:29.599352 EDT | AverageDiscountedReturn    99.9957
2017-07-02 15:22:29.599527 EDT | AverageQLoss                0.00394918
2017-07-02 15:22:29.599703 EDT | AveragePolicySurr          -1.06081
2017-07-02 15:22:29.599841 EDT | AverageQ                    1.01306
2017-07-02 15:22:29.600019 EDT | AverageAbsQ                 1.01627
2017-07-02 15:22:29.600127 EDT | AverageY                    1.01296
2017-07-02 15:22:29.600305 EDT | AverageAbsY                 1.01349
2017-07-02 15:22:29.600431 EDT | AverageAbsQYDiff            0.0162656
2017-07-02 15:22:29.600558 EDT | AverageAction               0.921661
2017-07-02 15:22:29.600693 EDT | PolicyRegParamNorm         65.0198
2017-07-02 15:22:29.600798 EDT | QFunRegParamNorm           63.377
2017-07-02 15:22:29.600923 EDT | -----------------------  -------------
2017-07-02 15:22:29.601107 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #694 | Training started
2017-07-02 15:22:38.877930 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #694 | Training finished
2017-07-02 15:22:38.878485 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #694 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 15:22:38.878733 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #694 | Collecting samples for evaluation
2017-07-02 15:22:44.398320 EDT | -----------------------  ------------
2017-07-02 15:22:44.398596 EDT | Epoch                     694
2017-07-02 15:22:44.398742 EDT | Iteration                 694
2017-07-02 15:22:44.398851 EDT | AverageReturn            1000
2017-07-02 15:22:44.399049 EDT | StdReturn                   0
2017-07-02 15:22:44.399241 EDT | MaxReturn                1000
2017-07-02 15:22:44.399408 EDT | MinReturn                1000
2017-07-02 15:22:44.399554 EDT | AverageEsReturn            49.4
2017-07-02 15:22:44.399652 EDT | StdEsReturn                39.7145
2017-07-02 15:22:44.399766 EDT | MaxEsReturn               167
2017-07-02 15:22:44.399934 EDT | MinEsReturn                 8
2017-07-02 15:22:44.400036 EDT | AverageDiscountedReturn    99.9957
2017-07-02 15:22:44.400135 EDT | AverageQLoss                0.0033518
2017-07-02 15:22:44.400256 EDT | AveragePolicySurr          -1.05749
2017-07-02 15:22:44.400395 EDT | AverageQ                    1.00892
2017-07-02 15:22:44.400494 EDT | AverageAbsQ                 1.01213
2017-07-02 15:22:44.400594 EDT | AverageY                    1.00896
2017-07-02 15:22:44.400702 EDT | AverageAbsY                 1.00922
2017-07-02 15:22:44.400824 EDT | AverageAbsQYDiff            0.0155907
2017-07-02 15:22:44.400939 EDT | AverageAction               0.929749
2017-07-02 15:22:44.401097 EDT | PolicyRegParamNorm         65.0914
2017-07-02 15:22:44.401199 EDT | QFunRegParamNorm           63.3898
2017-07-02 15:22:44.401297 EDT | -----------------------  ------------
2017-07-02 15:22:44.401479 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #695 | Training started
2017-07-02 15:22:53.711230 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #695 | Training finished
2017-07-02 15:22:53.711775 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #695 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 15:22:53.712131 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #695 | Collecting samples for evaluation
2017-07-02 15:22:59.243164 EDT | -----------------------  -------------
2017-07-02 15:22:59.243385 EDT | Epoch                     695
2017-07-02 15:22:59.243503 EDT | Iteration                 695
2017-07-02 15:22:59.243682 EDT | AverageReturn            1000
2017-07-02 15:22:59.243842 EDT | StdReturn                   0
2017-07-02 15:22:59.244031 EDT | MaxReturn                1000
2017-07-02 15:22:59.244169 EDT | MinReturn                1000
2017-07-02 15:22:59.244333 EDT | AverageEsReturn            48.0952
2017-07-02 15:22:59.244495 EDT | StdEsReturn                35.6142
2017-07-02 15:22:59.244682 EDT | MaxEsReturn               151
2017-07-02 15:22:59.244864 EDT | MinEsReturn                 4
2017-07-02 15:22:59.245009 EDT | AverageDiscountedReturn    99.9957
2017-07-02 15:22:59.245236 EDT | AverageQLoss                0.00387922
2017-07-02 15:22:59.245465 EDT | AveragePolicySurr          -1.05672
2017-07-02 15:22:59.245748 EDT | AverageQ                    1.00877
2017-07-02 15:22:59.245901 EDT | AverageAbsQ                 1.01176
2017-07-02 15:22:59.246009 EDT | AverageY                    1.00882
2017-07-02 15:22:59.246129 EDT | AverageAbsY                 1.00911
2017-07-02 15:22:59.246231 EDT | AverageAbsQYDiff            0.0162633
2017-07-02 15:22:59.246365 EDT | AverageAction               0.918403
2017-07-02 15:22:59.246525 EDT | PolicyRegParamNorm         65.1118
2017-07-02 15:22:59.246629 EDT | QFunRegParamNorm           63.4257
2017-07-02 15:22:59.246763 EDT | -----------------------  -------------
2017-07-02 15:22:59.246950 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #696 | Training started
2017-07-02 15:23:08.522326 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #696 | Training finished
2017-07-02 15:23:08.522892 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #696 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 15:23:08.523083 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #696 | Collecting samples for evaluation
2017-07-02 15:23:14.052236 EDT | -----------------------  -------------
2017-07-02 15:23:14.052441 EDT | Epoch                     696
2017-07-02 15:23:14.052559 EDT | Iteration                 696
2017-07-02 15:23:14.052666 EDT | AverageReturn            1000
2017-07-02 15:23:14.052774 EDT | StdReturn                   0
2017-07-02 15:23:14.052917 EDT | MaxReturn                1000
2017-07-02 15:23:14.053023 EDT | MinReturn                1000
2017-07-02 15:23:14.053122 EDT | AverageEsReturn            53.8889
2017-07-02 15:23:14.053221 EDT | StdEsReturn                39.6217
2017-07-02 15:23:14.053323 EDT | MaxEsReturn               139
2017-07-02 15:23:14.053481 EDT | MinEsReturn                 4
2017-07-02 15:23:14.053645 EDT | AverageDiscountedReturn    99.9957
2017-07-02 15:23:14.053750 EDT | AverageQLoss                0.00332613
2017-07-02 15:23:14.053851 EDT | AveragePolicySurr          -1.05463
2017-07-02 15:23:14.053987 EDT | AverageQ                    1.00704
2017-07-02 15:23:14.054089 EDT | AverageAbsQ                 1.01012
2017-07-02 15:23:14.054189 EDT | AverageY                    1.00699
2017-07-02 15:23:14.054288 EDT | AverageAbsY                 1.00732
2017-07-02 15:23:14.054386 EDT | AverageAbsQYDiff            0.0146556
2017-07-02 15:23:14.054520 EDT | AverageAction               0.94374
2017-07-02 15:23:14.054620 EDT | PolicyRegParamNorm         65.1668
2017-07-02 15:23:14.054719 EDT | QFunRegParamNorm           63.4328
2017-07-02 15:23:14.054817 EDT | -----------------------  -------------
2017-07-02 15:23:14.055020 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #697 | Training started
2017-07-02 15:23:23.367006 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #697 | Training finished
2017-07-02 15:23:23.367505 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #697 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 15:23:23.367752 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #697 | Collecting samples for evaluation
2017-07-02 15:23:29.011692 EDT | -----------------------  -------------
2017-07-02 15:23:29.012001 EDT | Epoch                     697
2017-07-02 15:23:29.012240 EDT | Iteration                 697
2017-07-02 15:23:29.012427 EDT | AverageReturn            1000
2017-07-02 15:23:29.012633 EDT | StdReturn                   0
2017-07-02 15:23:29.012841 EDT | MaxReturn                1000
2017-07-02 15:23:29.013069 EDT | MinReturn                1000
2017-07-02 15:23:29.013281 EDT | AverageEsReturn            41.88
2017-07-02 15:23:29.013523 EDT | StdEsReturn                35.1674
2017-07-02 15:23:29.013747 EDT | MaxEsReturn               117
2017-07-02 15:23:29.013915 EDT | MinEsReturn                 3
2017-07-02 15:23:29.014145 EDT | AverageDiscountedReturn    99.9957
2017-07-02 15:23:29.014356 EDT | AverageQLoss                0.00393012
2017-07-02 15:23:29.014561 EDT | AveragePolicySurr          -1.05506
2017-07-02 15:23:29.014787 EDT | AverageQ                    1.00634
2017-07-02 15:23:29.014920 EDT | AverageAbsQ                 1.00889
2017-07-02 15:23:29.015025 EDT | AverageY                    1.00628
2017-07-02 15:23:29.015126 EDT | AverageAbsY                 1.0065
2017-07-02 15:23:29.015225 EDT | AverageAbsQYDiff            0.0163908
2017-07-02 15:23:29.015326 EDT | AverageAction               0.93428
2017-07-02 15:23:29.015427 EDT | PolicyRegParamNorm         65.1923
2017-07-02 15:23:29.015650 EDT | QFunRegParamNorm           63.4582
2017-07-02 15:23:29.015872 EDT | -----------------------  -------------
2017-07-02 15:23:29.016154 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #698 | Training started
2017-07-02 15:23:38.356296 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #698 | Training finished
2017-07-02 15:23:38.356776 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #698 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 15:23:38.356996 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #698 | Collecting samples for evaluation
2017-07-02 15:23:43.840122 EDT | -----------------------  -------------
2017-07-02 15:23:43.840311 EDT | Epoch                     698
2017-07-02 15:23:43.840446 EDT | Iteration                 698
2017-07-02 15:23:43.840585 EDT | AverageReturn            1000
2017-07-02 15:23:43.840707 EDT | StdReturn                   0
2017-07-02 15:23:43.840898 EDT | MaxReturn                1000
2017-07-02 15:23:43.841019 EDT | MinReturn                1000
2017-07-02 15:23:43.841193 EDT | AverageEsReturn            34.069
2017-07-02 15:23:43.841373 EDT | StdEsReturn                33.6984
2017-07-02 15:23:43.841564 EDT | MaxEsReturn               141
2017-07-02 15:23:43.841725 EDT | MinEsReturn                 3
2017-07-02 15:23:43.841828 EDT | AverageDiscountedReturn    99.9957
2017-07-02 15:23:43.842006 EDT | AverageQLoss                0.00355631
2017-07-02 15:23:43.842152 EDT | AveragePolicySurr          -1.05294
2017-07-02 15:23:43.842285 EDT | AverageQ                    1.00634
2017-07-02 15:23:43.842442 EDT | AverageAbsQ                 1.00957
2017-07-02 15:23:43.842623 EDT | AverageY                    1.00638
2017-07-02 15:23:43.842748 EDT | AverageAbsY                 1.00674
2017-07-02 15:23:43.842913 EDT | AverageAbsQYDiff            0.0156607
2017-07-02 15:23:43.843064 EDT | AverageAction               0.920108
2017-07-02 15:23:43.843195 EDT | PolicyRegParamNorm         65.2326
2017-07-02 15:23:43.843343 EDT | QFunRegParamNorm           63.4897
2017-07-02 15:23:43.843486 EDT | -----------------------  -------------
2017-07-02 15:23:43.843771 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #699 | Training started
2017-07-02 15:23:53.238318 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #699 | Training finished
2017-07-02 15:23:53.238852 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #699 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 15:23:53.238993 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #699 | Collecting samples for evaluation
2017-07-02 15:23:58.638782 EDT | -----------------------  -------------
2017-07-02 15:23:58.639101 EDT | Epoch                     699
2017-07-02 15:23:58.639330 EDT | Iteration                 699
2017-07-02 15:23:58.639562 EDT | AverageReturn            1000
2017-07-02 15:23:58.639731 EDT | StdReturn                   0
2017-07-02 15:23:58.639963 EDT | MaxReturn                1000
2017-07-02 15:23:58.640175 EDT | MinReturn                1000
2017-07-02 15:23:58.640386 EDT | AverageEsReturn            41.7917
2017-07-02 15:23:58.640612 EDT | StdEsReturn                23.4218
2017-07-02 15:23:58.640742 EDT | MaxEsReturn                82
2017-07-02 15:23:58.640848 EDT | MinEsReturn                 5
2017-07-02 15:23:58.640950 EDT | AverageDiscountedReturn    99.9957
2017-07-02 15:23:58.641051 EDT | AverageQLoss                0.00344741
2017-07-02 15:23:58.641150 EDT | AveragePolicySurr          -1.05149
2017-07-02 15:23:58.641249 EDT | AverageQ                    1.00481
2017-07-02 15:23:58.641421 EDT | AverageAbsQ                 1.00787
2017-07-02 15:23:58.641751 EDT | AverageY                    1.00477
2017-07-02 15:23:58.641911 EDT | AverageAbsY                 1.00513
2017-07-02 15:23:58.642082 EDT | AverageAbsQYDiff            0.0153312
2017-07-02 15:23:58.642186 EDT | AverageAction               0.513047
2017-07-02 15:23:58.642286 EDT | PolicyRegParamNorm         65.2694
2017-07-02 15:23:58.642393 EDT | QFunRegParamNorm           63.5091
2017-07-02 15:23:58.642522 EDT | -----------------------  -------------
2017-07-02 15:23:58.642686 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #700 | Training started
2017-07-02 15:24:08.165424 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #700 | Training finished
2017-07-02 15:24:08.165960 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #700 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 15:24:08.166220 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #700 | Collecting samples for evaluation
2017-07-02 15:24:13.566704 EDT | -----------------------  -------------
2017-07-02 15:24:13.566895 EDT | Epoch                     700
2017-07-02 15:24:13.567047 EDT | Iteration                 700
2017-07-02 15:24:13.567206 EDT | AverageReturn            1000
2017-07-02 15:24:13.567335 EDT | StdReturn                   0
2017-07-02 15:24:13.567438 EDT | MaxReturn                1000
2017-07-02 15:24:13.567539 EDT | MinReturn                1000
2017-07-02 15:24:13.567659 EDT | AverageEsReturn            41.375
2017-07-02 15:24:13.567804 EDT | StdEsReturn                37.9954
2017-07-02 15:24:13.567931 EDT | MaxEsReturn               170
2017-07-02 15:24:13.568040 EDT | MinEsReturn                 3
2017-07-02 15:24:13.568142 EDT | AverageDiscountedReturn    99.9957
2017-07-02 15:24:13.568242 EDT | AverageQLoss                0.00395112
2017-07-02 15:24:13.568341 EDT | AveragePolicySurr          -1.0478
2017-07-02 15:24:13.568488 EDT | AverageQ                    1.00015
2017-07-02 15:24:13.568590 EDT | AverageAbsQ                 1.00338
2017-07-02 15:24:13.568711 EDT | AverageY                    1.0002
2017-07-02 15:24:13.568830 EDT | AverageAbsY                 1.00059
2017-07-02 15:24:13.568931 EDT | AverageAbsQYDiff            0.0161921
2017-07-02 15:24:13.569030 EDT | AverageAction               0.314465
2017-07-02 15:24:13.569145 EDT | PolicyRegParamNorm         65.2898
2017-07-02 15:24:13.569253 EDT | QFunRegParamNorm           63.5202
2017-07-02 15:24:13.569359 EDT | -----------------------  -------------
2017-07-02 15:24:13.569582 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #701 | Training started
2017-07-02 15:24:23.004824 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #701 | Training finished
2017-07-02 15:24:23.005446 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #701 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 15:24:23.005680 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #701 | Collecting samples for evaluation
2017-07-02 15:24:28.449054 EDT | -----------------------  -------------
2017-07-02 15:24:28.449347 EDT | Epoch                     701
2017-07-02 15:24:28.449593 EDT | Iteration                 701
2017-07-02 15:24:28.449802 EDT | AverageReturn            1000
2017-07-02 15:24:28.450033 EDT | StdReturn                   0
2017-07-02 15:24:28.450219 EDT | MaxReturn                1000
2017-07-02 15:24:28.450377 EDT | MinReturn                1000
2017-07-02 15:24:28.450609 EDT | AverageEsReturn            31.6429
2017-07-02 15:24:28.450812 EDT | StdEsReturn                32.3995
2017-07-02 15:24:28.451044 EDT | MaxEsReturn               115
2017-07-02 15:24:28.451263 EDT | MinEsReturn                 3
2017-07-02 15:24:28.451369 EDT | AverageDiscountedReturn    99.9957
2017-07-02 15:24:28.451509 EDT | AverageQLoss                0.00353812
2017-07-02 15:24:28.451740 EDT | AveragePolicySurr          -1.04729
2017-07-02 15:24:28.451949 EDT | AverageQ                    1.00062
2017-07-02 15:24:28.452178 EDT | AverageAbsQ                 1.00381
2017-07-02 15:24:28.452403 EDT | AverageY                    1.00051
2017-07-02 15:24:28.452630 EDT | AverageAbsY                 1.0011
2017-07-02 15:24:28.452857 EDT | AverageAbsQYDiff            0.0152209
2017-07-02 15:24:28.452982 EDT | AverageAction               0.828046
2017-07-02 15:24:28.453200 EDT | PolicyRegParamNorm         65.3021
2017-07-02 15:24:28.453427 EDT | QFunRegParamNorm           63.5457
2017-07-02 15:24:28.453620 EDT | -----------------------  -------------
2017-07-02 15:24:28.453956 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #702 | Training started
2017-07-02 15:24:37.826114 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #702 | Training finished
2017-07-02 15:24:37.826649 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #702 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 15:24:37.826885 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #702 | Collecting samples for evaluation
2017-07-02 15:24:43.458646 EDT | -----------------------  -------------
2017-07-02 15:24:43.458854 EDT | Epoch                     702
2017-07-02 15:24:43.458965 EDT | Iteration                 702
2017-07-02 15:24:43.459144 EDT | AverageReturn            1000
2017-07-02 15:24:43.459374 EDT | StdReturn                   0
2017-07-02 15:24:43.459580 EDT | MaxReturn                1000
2017-07-02 15:24:43.459718 EDT | MinReturn                1000
2017-07-02 15:24:43.459836 EDT | AverageEsReturn            46.4167
2017-07-02 15:24:43.459939 EDT | StdEsReturn                34.9511
2017-07-02 15:24:43.460038 EDT | MaxEsReturn               133
2017-07-02 15:24:43.460136 EDT | MinEsReturn                 5
2017-07-02 15:24:43.460252 EDT | AverageDiscountedReturn    99.9957
2017-07-02 15:24:43.460352 EDT | AverageQLoss                0.00444695
2017-07-02 15:24:43.460463 EDT | AveragePolicySurr          -1.04435
2017-07-02 15:24:43.460621 EDT | AverageQ                    0.998484
2017-07-02 15:24:43.460754 EDT | AverageAbsQ                 1.00243
2017-07-02 15:24:43.460874 EDT | AverageY                    0.99857
2017-07-02 15:24:43.460978 EDT | AverageAbsY                 0.999064
2017-07-02 15:24:43.461112 EDT | AverageAbsQYDiff            0.0185576
2017-07-02 15:24:43.461217 EDT | AverageAction               0.9388
2017-07-02 15:24:43.461316 EDT | PolicyRegParamNorm         65.2663
2017-07-02 15:24:43.461424 EDT | QFunRegParamNorm           63.5641
2017-07-02 15:24:43.461900 EDT | -----------------------  -------------
2017-07-02 15:24:43.462123 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #703 | Training started
2017-07-02 15:24:52.758721 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #703 | Training finished
2017-07-02 15:24:52.759215 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #703 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 15:24:52.759572 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #703 | Collecting samples for evaluation
2017-07-02 15:24:58.354111 EDT | -----------------------  -------------
2017-07-02 15:24:58.354370 EDT | Epoch                     703
2017-07-02 15:24:58.354580 EDT | Iteration                 703
2017-07-02 15:24:58.354799 EDT | AverageReturn            1000
2017-07-02 15:24:58.355017 EDT | StdReturn                   0
2017-07-02 15:24:58.355231 EDT | MaxReturn                1000
2017-07-02 15:24:58.355448 EDT | MinReturn                1000
2017-07-02 15:24:58.355666 EDT | AverageEsReturn            38.6923
2017-07-02 15:24:58.355894 EDT | StdEsReturn                35.4084
2017-07-02 15:24:58.356115 EDT | MaxEsReturn               167
2017-07-02 15:24:58.356330 EDT | MinEsReturn                 5
2017-07-02 15:24:58.356539 EDT | AverageDiscountedReturn    99.9957
2017-07-02 15:24:58.356759 EDT | AverageQLoss                0.00391938
2017-07-02 15:24:58.356923 EDT | AveragePolicySurr          -1.04417
2017-07-02 15:24:58.357028 EDT | AverageQ                    0.998119
2017-07-02 15:24:58.357145 EDT | AverageAbsQ                 1.00045
2017-07-02 15:24:58.357353 EDT | AverageY                    0.998074
2017-07-02 15:24:58.358075 EDT | AverageAbsY                 0.998416
2017-07-02 15:24:58.358210 EDT | AverageAbsQYDiff            0.0160743
2017-07-02 15:24:58.358317 EDT | AverageAction               0.942587
2017-07-02 15:24:58.358420 EDT | PolicyRegParamNorm         65.275
2017-07-02 15:24:58.358527 EDT | QFunRegParamNorm           63.6169
2017-07-02 15:24:58.358649 EDT | -----------------------  -------------
2017-07-02 15:24:58.358826 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #704 | Training started
2017-07-02 15:25:07.527627 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #704 | Training finished
2017-07-02 15:25:07.528148 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #704 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 15:25:07.528308 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #704 | Collecting samples for evaluation
2017-07-02 15:25:13.062906 EDT | -----------------------  -------------
2017-07-02 15:25:13.063180 EDT | Epoch                     704
2017-07-02 15:25:13.063304 EDT | Iteration                 704
2017-07-02 15:25:13.063478 EDT | AverageReturn            1000
2017-07-02 15:25:13.063672 EDT | StdReturn                   0
2017-07-02 15:25:13.063848 EDT | MaxReturn                1000
2017-07-02 15:25:13.063963 EDT | MinReturn                1000
2017-07-02 15:25:13.064065 EDT | AverageEsReturn            34.1111
2017-07-02 15:25:13.064225 EDT | StdEsReturn                37.0088
2017-07-02 15:25:13.064380 EDT | MaxEsReturn               162
2017-07-02 15:25:13.064548 EDT | MinEsReturn                 6
2017-07-02 15:25:13.064651 EDT | AverageDiscountedReturn    99.9957
2017-07-02 15:25:13.064840 EDT | AverageQLoss                0.00351207
2017-07-02 15:25:13.064962 EDT | AveragePolicySurr          -1.04231
2017-07-02 15:25:13.065091 EDT | AverageQ                    0.995855
2017-07-02 15:25:13.065195 EDT | AverageAbsQ                 0.998917
2017-07-02 15:25:13.065348 EDT | AverageY                    0.995837
2017-07-02 15:25:13.065665 EDT | AverageAbsY                 0.996142
2017-07-02 15:25:13.065850 EDT | AverageAbsQYDiff            0.0151614
2017-07-02 15:25:13.066036 EDT | AverageAction               0.920801
2017-07-02 15:25:13.066145 EDT | PolicyRegParamNorm         65.2896
2017-07-02 15:25:13.066261 EDT | QFunRegParamNorm           63.61
2017-07-02 15:25:13.066378 EDT | -----------------------  -------------
2017-07-02 15:25:13.066583 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #705 | Training started
2017-07-02 15:25:22.862988 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #705 | Training finished
2017-07-02 15:25:22.863590 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #705 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 15:25:22.863848 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #705 | Collecting samples for evaluation
2017-07-02 15:25:28.380182 EDT | -----------------------  -------------
2017-07-02 15:25:28.380401 EDT | Epoch                     705
2017-07-02 15:25:28.380530 EDT | Iteration                 705
2017-07-02 15:25:28.380667 EDT | AverageReturn            1000
2017-07-02 15:25:28.380770 EDT | StdReturn                   0
2017-07-02 15:25:28.380891 EDT | MaxReturn                1000
2017-07-02 15:25:28.380991 EDT | MinReturn                1000
2017-07-02 15:25:28.381090 EDT | AverageEsReturn            39.4815
2017-07-02 15:25:28.381221 EDT | StdEsReturn                29.7799
2017-07-02 15:25:28.381330 EDT | MaxEsReturn               100
2017-07-02 15:25:28.381471 EDT | MinEsReturn                 5
2017-07-02 15:25:28.381662 EDT | AverageDiscountedReturn    99.9957
2017-07-02 15:25:28.381860 EDT | AverageQLoss                0.00349116
2017-07-02 15:25:28.381996 EDT | AveragePolicySurr          -1.03977
2017-07-02 15:25:28.382126 EDT | AverageQ                    0.99331
2017-07-02 15:25:28.382273 EDT | AverageAbsQ                 0.996069
2017-07-02 15:25:28.382376 EDT | AverageY                    0.993321
2017-07-02 15:25:28.382497 EDT | AverageAbsY                 0.993651
2017-07-02 15:25:28.382609 EDT | AverageAbsQYDiff            0.0148497
2017-07-02 15:25:28.382709 EDT | AverageAction               0.870794
2017-07-02 15:25:28.382808 EDT | PolicyRegParamNorm         65.292
2017-07-02 15:25:28.382907 EDT | QFunRegParamNorm           63.6263
2017-07-02 15:25:28.383096 EDT | -----------------------  -------------
2017-07-02 15:25:28.383347 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #706 | Training started
2017-07-02 15:25:37.697918 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #706 | Training finished
2017-07-02 15:25:37.698504 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #706 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 15:25:37.698731 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #706 | Collecting samples for evaluation
2017-07-02 15:25:43.213619 EDT | -----------------------  -------------
2017-07-02 15:25:43.213903 EDT | Epoch                     706
2017-07-02 15:25:43.214130 EDT | Iteration                 706
2017-07-02 15:25:43.214318 EDT | AverageReturn            1000
2017-07-02 15:25:43.214551 EDT | StdReturn                   0
2017-07-02 15:25:43.214772 EDT | MaxReturn                1000
2017-07-02 15:25:43.214991 EDT | MinReturn                1000
2017-07-02 15:25:43.215209 EDT | AverageEsReturn            73.7692
2017-07-02 15:25:43.215402 EDT | StdEsReturn                63.0423
2017-07-02 15:25:43.215617 EDT | MaxEsReturn               217
2017-07-02 15:25:43.215830 EDT | MinEsReturn                17
2017-07-02 15:25:43.216023 EDT | AverageDiscountedReturn    99.9957
2017-07-02 15:25:43.216254 EDT | AverageQLoss                0.00357261
2017-07-02 15:25:43.216473 EDT | AveragePolicySurr          -1.04137
2017-07-02 15:25:43.216691 EDT | AverageQ                    0.997535
2017-07-02 15:25:43.216904 EDT | AverageAbsQ                 1.00048
2017-07-02 15:25:43.217063 EDT | AverageY                    0.997465
2017-07-02 15:25:43.217281 EDT | AverageAbsY                 0.997795
2017-07-02 15:25:43.217461 EDT | AverageAbsQYDiff            0.014724
2017-07-02 15:25:43.217737 EDT | AverageAction               0.90583
2017-07-02 15:25:43.217953 EDT | PolicyRegParamNorm         65.2913
2017-07-02 15:25:43.218164 EDT | QFunRegParamNorm           63.6489
2017-07-02 15:25:43.218379 EDT | -----------------------  -------------
2017-07-02 15:25:43.218588 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #707 | Training started
2017-07-02 15:25:52.598966 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #707 | Training finished
2017-07-02 15:25:52.599231 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #707 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 15:25:52.599349 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #707 | Collecting samples for evaluation
2017-07-02 15:25:58.164935 EDT | -----------------------  -------------
2017-07-02 15:25:58.165426 EDT | Epoch                     707
2017-07-02 15:25:58.165615 EDT | Iteration                 707
2017-07-02 15:25:58.165739 EDT | AverageReturn            1000
2017-07-02 15:25:58.165860 EDT | StdReturn                   0
2017-07-02 15:25:58.166036 EDT | MaxReturn                1000
2017-07-02 15:25:58.166230 EDT | MinReturn                1000
2017-07-02 15:25:58.166334 EDT | AverageEsReturn            61.7059
2017-07-02 15:25:58.166476 EDT | StdEsReturn                38.5163
2017-07-02 15:25:58.166593 EDT | MaxEsReturn               146
2017-07-02 15:25:58.166726 EDT | MinEsReturn                 4
2017-07-02 15:25:58.166835 EDT | AverageDiscountedReturn    99.9957
2017-07-02 15:25:58.166970 EDT | AverageQLoss                0.00294489
2017-07-02 15:25:58.167072 EDT | AveragePolicySurr          -1.03969
2017-07-02 15:25:58.167197 EDT | AverageQ                    0.994385
2017-07-02 15:25:58.167311 EDT | AverageAbsQ                 0.997397
2017-07-02 15:25:58.167412 EDT | AverageY                    0.994402
2017-07-02 15:25:58.167512 EDT | AverageAbsY                 0.994572
2017-07-02 15:25:58.167625 EDT | AverageAbsQYDiff            0.0149417
2017-07-02 15:25:58.167724 EDT | AverageAction               0.911423
2017-07-02 15:25:58.167822 EDT | PolicyRegParamNorm         65.3515
2017-07-02 15:25:58.167980 EDT | QFunRegParamNorm           63.677
2017-07-02 15:25:58.168083 EDT | -----------------------  -------------
2017-07-02 15:25:58.168244 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #708 | Training started
2017-07-02 15:26:07.436420 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #708 | Training finished
2017-07-02 15:26:07.437034 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #708 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 15:26:07.437180 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #708 | Collecting samples for evaluation
2017-07-02 15:26:13.062957 EDT | -----------------------  -------------
2017-07-02 15:26:13.063176 EDT | Epoch                     708
2017-07-02 15:26:13.063295 EDT | Iteration                 708
2017-07-02 15:26:13.063476 EDT | AverageReturn            1000
2017-07-02 15:26:13.063619 EDT | StdReturn                   0
2017-07-02 15:26:13.063727 EDT | MaxReturn                1000
2017-07-02 15:26:13.063941 EDT | MinReturn                1000
2017-07-02 15:26:13.064169 EDT | AverageEsReturn            38
2017-07-02 15:26:13.064352 EDT | StdEsReturn                32.4535
2017-07-02 15:26:13.064458 EDT | MaxEsReturn               123
2017-07-02 15:26:13.064593 EDT | MinEsReturn                 4
2017-07-02 15:26:13.064697 EDT | AverageDiscountedReturn    99.9957
2017-07-02 15:26:13.064797 EDT | AverageQLoss                0.00391807
2017-07-02 15:26:13.065002 EDT | AveragePolicySurr          -1.03729
2017-07-02 15:26:13.065231 EDT | AverageQ                    0.991055
2017-07-02 15:26:13.065436 EDT | AverageAbsQ                 0.994546
2017-07-02 15:26:13.065689 EDT | AverageY                    0.991066
2017-07-02 15:26:13.065906 EDT | AverageAbsY                 0.99131
2017-07-02 15:26:13.066095 EDT | AverageAbsQYDiff            0.0177911
2017-07-02 15:26:13.066312 EDT | AverageAction               0.909048
2017-07-02 15:26:13.066541 EDT | PolicyRegParamNorm         65.374
2017-07-02 15:26:13.066715 EDT | QFunRegParamNorm           63.6856
2017-07-02 15:26:13.066820 EDT | -----------------------  -------------
2017-07-02 15:26:13.066981 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #709 | Training started
2017-07-02 15:26:22.266113 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #709 | Training finished
2017-07-02 15:26:22.266331 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #709 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 15:26:22.266451 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #709 | Collecting samples for evaluation
2017-07-02 15:26:27.898685 EDT | -----------------------  -------------
2017-07-02 15:26:27.899344 EDT | Epoch                     709
2017-07-02 15:26:27.899523 EDT | Iteration                 709
2017-07-02 15:26:27.899697 EDT | AverageReturn            1000
2017-07-02 15:26:27.899823 EDT | StdReturn                   0
2017-07-02 15:26:27.899959 EDT | MaxReturn                1000
2017-07-02 15:26:27.900063 EDT | MinReturn                1000
2017-07-02 15:26:27.900163 EDT | AverageEsReturn            32.4828
2017-07-02 15:26:27.900262 EDT | StdEsReturn                22.4494
2017-07-02 15:26:27.900400 EDT | MaxEsReturn                76
2017-07-02 15:26:27.900518 EDT | MinEsReturn                 3
2017-07-02 15:26:27.900619 EDT | AverageDiscountedReturn    99.9957
2017-07-02 15:26:27.900735 EDT | AverageQLoss                0.00371682
2017-07-02 15:26:27.900837 EDT | AveragePolicySurr          -1.03713
2017-07-02 15:26:27.900967 EDT | AverageQ                    0.993585
2017-07-02 15:26:27.901086 EDT | AverageAbsQ                 0.996839
2017-07-02 15:26:27.901186 EDT | AverageY                    0.993563
2017-07-02 15:26:27.901285 EDT | AverageAbsY                 0.99369
2017-07-02 15:26:27.901383 EDT | AverageAbsQYDiff            0.0162988
2017-07-02 15:26:27.901550 EDT | AverageAction               0.894394
2017-07-02 15:26:27.901737 EDT | PolicyRegParamNorm         65.383
2017-07-02 15:26:27.901917 EDT | QFunRegParamNorm           63.7166
2017-07-02 15:26:27.902104 EDT | -----------------------  -------------
2017-07-02 15:26:27.902336 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #710 | Training started
2017-07-02 15:26:37.114294 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #710 | Training finished
2017-07-02 15:26:37.114989 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #710 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 15:26:37.115174 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #710 | Collecting samples for evaluation
2017-07-02 15:26:42.711968 EDT | -----------------------  -------------
2017-07-02 15:26:42.712221 EDT | Epoch                     710
2017-07-02 15:26:42.712342 EDT | Iteration                 710
2017-07-02 15:26:42.712482 EDT | AverageReturn            1000
2017-07-02 15:26:42.712586 EDT | StdReturn                   0
2017-07-02 15:26:42.712685 EDT | MaxReturn                1000
2017-07-02 15:26:42.712789 EDT | MinReturn                1000
2017-07-02 15:26:42.712997 EDT | AverageEsReturn            45.8261
2017-07-02 15:26:42.713122 EDT | StdEsReturn                40.4794
2017-07-02 15:26:42.713225 EDT | MaxEsReturn               151
2017-07-02 15:26:42.713364 EDT | MinEsReturn                 6
2017-07-02 15:26:42.713483 EDT | AverageDiscountedReturn    99.9957
2017-07-02 15:26:42.713680 EDT | AverageQLoss                0.00378139
2017-07-02 15:26:42.713795 EDT | AveragePolicySurr          -1.03392
2017-07-02 15:26:42.713929 EDT | AverageQ                    0.988383
2017-07-02 15:26:42.714108 EDT | AverageAbsQ                 0.991676
2017-07-02 15:26:42.714232 EDT | AverageY                    0.988407
2017-07-02 15:26:42.714344 EDT | AverageAbsY                 0.988504
2017-07-02 15:26:42.714450 EDT | AverageAbsQYDiff            0.0161823
2017-07-02 15:26:42.714574 EDT | AverageAction               0.912865
2017-07-02 15:26:42.714691 EDT | PolicyRegParamNorm         65.3941
2017-07-02 15:26:42.714790 EDT | QFunRegParamNorm           63.7288
2017-07-02 15:26:42.714888 EDT | -----------------------  -------------
2017-07-02 15:26:42.715045 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #711 | Training started
2017-07-02 15:26:52.003160 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #711 | Training finished
2017-07-02 15:26:52.003570 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #711 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 15:26:52.003909 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #711 | Collecting samples for evaluation
2017-07-02 15:26:57.437145 EDT | -----------------------  -------------
2017-07-02 15:26:57.437747 EDT | Epoch                     711
2017-07-02 15:26:57.437917 EDT | Iteration                 711
2017-07-02 15:26:57.438098 EDT | AverageReturn            1000
2017-07-02 15:26:57.438296 EDT | StdReturn                   0
2017-07-02 15:26:57.438477 EDT | MaxReturn                1000
2017-07-02 15:26:57.438671 EDT | MinReturn                1000
2017-07-02 15:26:57.438870 EDT | AverageEsReturn            48.7143
2017-07-02 15:26:57.439063 EDT | StdEsReturn                42.5979
2017-07-02 15:26:57.439216 EDT | MaxEsReturn               155
2017-07-02 15:26:57.439352 EDT | MinEsReturn                 3
2017-07-02 15:26:57.439550 EDT | AverageDiscountedReturn    99.9957
2017-07-02 15:26:57.439705 EDT | AverageQLoss                0.00330778
2017-07-02 15:26:57.439840 EDT | AveragePolicySurr          -1.03514
2017-07-02 15:26:57.439946 EDT | AverageQ                    0.989635
2017-07-02 15:26:57.440060 EDT | AverageAbsQ                 0.992356
2017-07-02 15:26:57.440176 EDT | AverageY                    0.98965
2017-07-02 15:26:57.440278 EDT | AverageAbsY                 0.989853
2017-07-02 15:26:57.440391 EDT | AverageAbsQYDiff            0.0145609
2017-07-02 15:26:57.440567 EDT | AverageAction               0.905872
2017-07-02 15:26:57.440683 EDT | PolicyRegParamNorm         65.4087
2017-07-02 15:26:57.440812 EDT | QFunRegParamNorm           63.751
2017-07-02 15:26:57.440957 EDT | -----------------------  -------------
2017-07-02 15:26:57.441214 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #712 | Training started
2017-07-02 15:27:06.791540 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #712 | Training finished
2017-07-02 15:27:06.792295 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #712 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 15:27:06.792946 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #712 | Collecting samples for evaluation
2017-07-02 15:27:12.245092 EDT | -----------------------  -------------
2017-07-02 15:27:12.245537 EDT | Epoch                     712
2017-07-02 15:27:12.245748 EDT | Iteration                 712
2017-07-02 15:27:12.245927 EDT | AverageReturn            1000
2017-07-02 15:27:12.246076 EDT | StdReturn                   0
2017-07-02 15:27:12.246448 EDT | MaxReturn                1000
2017-07-02 15:27:12.246681 EDT | MinReturn                1000
2017-07-02 15:27:12.246894 EDT | AverageEsReturn            53.8889
2017-07-02 15:27:12.247121 EDT | StdEsReturn                41.6998
2017-07-02 15:27:12.247329 EDT | MaxEsReturn               151
2017-07-02 15:27:12.247545 EDT | MinEsReturn                 5
2017-07-02 15:27:12.247762 EDT | AverageDiscountedReturn    99.9957
2017-07-02 15:27:12.247962 EDT | AverageQLoss                0.00386931
2017-07-02 15:27:12.248184 EDT | AveragePolicySurr          -1.03149
2017-07-02 15:27:12.248341 EDT | AverageQ                    0.986709
2017-07-02 15:27:12.248446 EDT | AverageAbsQ                 0.989839
2017-07-02 15:27:12.248609 EDT | AverageY                    0.986661
2017-07-02 15:27:12.248830 EDT | AverageAbsY                 0.986926
2017-07-02 15:27:12.249023 EDT | AverageAbsQYDiff            0.0167135
2017-07-02 15:27:12.249131 EDT | AverageAction               0.946943
2017-07-02 15:27:12.249244 EDT | PolicyRegParamNorm         65.4441
2017-07-02 15:27:12.249357 EDT | QFunRegParamNorm           63.7589
2017-07-02 15:27:12.249457 EDT | -----------------------  -------------
2017-07-02 15:27:12.249879 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #713 | Training started
2017-07-02 15:27:21.693068 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #713 | Training finished
2017-07-02 15:27:21.693686 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #713 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 15:27:21.693943 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #713 | Collecting samples for evaluation
2017-07-02 15:27:27.120956 EDT | -----------------------  -------------
2017-07-02 15:27:27.121549 EDT | Epoch                     713
2017-07-02 15:27:27.121713 EDT | Iteration                 713
2017-07-02 15:27:27.121827 EDT | AverageReturn            1000
2017-07-02 15:27:27.121948 EDT | StdReturn                   0
2017-07-02 15:27:27.122076 EDT | MaxReturn                1000
2017-07-02 15:27:27.122297 EDT | MinReturn                1000
2017-07-02 15:27:27.122505 EDT | AverageEsReturn            43.2917
2017-07-02 15:27:27.122731 EDT | StdEsReturn                40.8223
2017-07-02 15:27:27.122948 EDT | MaxEsReturn               160
2017-07-02 15:27:27.123132 EDT | MinEsReturn                 3
2017-07-02 15:27:27.123235 EDT | AverageDiscountedReturn    99.9957
2017-07-02 15:27:27.123359 EDT | AverageQLoss                0.00307383
2017-07-02 15:27:27.123475 EDT | AveragePolicySurr          -1.03101
2017-07-02 15:27:27.123573 EDT | AverageQ                    0.986096
2017-07-02 15:27:27.123670 EDT | AverageAbsQ                 0.988919
2017-07-02 15:27:27.123766 EDT | AverageY                    0.986157
2017-07-02 15:27:27.123875 EDT | AverageAbsY                 0.986313
2017-07-02 15:27:27.124011 EDT | AverageAbsQYDiff            0.0147572
2017-07-02 15:27:27.124109 EDT | AverageAction               0.694965
2017-07-02 15:27:27.124205 EDT | PolicyRegParamNorm         65.433
2017-07-02 15:27:27.124301 EDT | QFunRegParamNorm           63.7815
2017-07-02 15:27:27.124452 EDT | -----------------------  -------------
2017-07-02 15:27:27.124618 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #714 | Training started
2017-07-02 15:27:36.531750 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #714 | Training finished
2017-07-02 15:27:36.532250 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #714 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 15:27:36.532474 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #714 | Collecting samples for evaluation
2017-07-02 15:27:41.958357 EDT | -----------------------  -------------
2017-07-02 15:27:41.958717 EDT | Epoch                     714
2017-07-02 15:27:41.958956 EDT | Iteration                 714
2017-07-02 15:27:41.959125 EDT | AverageReturn            1000
2017-07-02 15:27:41.959359 EDT | StdReturn                   0
2017-07-02 15:27:41.959551 EDT | MaxReturn                1000
2017-07-02 15:27:41.959763 EDT | MinReturn                1000
2017-07-02 15:27:41.959990 EDT | AverageEsReturn            33.931
2017-07-02 15:27:41.960176 EDT | StdEsReturn                33.598
2017-07-02 15:27:41.960404 EDT | MaxEsReturn               135
2017-07-02 15:27:41.961039 EDT | MinEsReturn                 2
2017-07-02 15:27:41.961271 EDT | AverageDiscountedReturn    99.9957
2017-07-02 15:27:41.961493 EDT | AverageQLoss                0.00375954
2017-07-02 15:27:41.961708 EDT | AveragePolicySurr          -1.02924
2017-07-02 15:27:41.961926 EDT | AverageQ                    0.985033
2017-07-02 15:27:41.962157 EDT | AverageAbsQ                 0.987974
2017-07-02 15:27:41.962382 EDT | AverageY                    0.985007
2017-07-02 15:27:41.962611 EDT | AverageAbsY                 0.985152
2017-07-02 15:27:41.962836 EDT | AverageAbsQYDiff            0.0155769
2017-07-02 15:27:41.962981 EDT | AverageAction               0.873841
2017-07-02 15:27:41.963211 EDT | PolicyRegParamNorm         65.4893
2017-07-02 15:27:41.963416 EDT | QFunRegParamNorm           63.8048
2017-07-02 15:27:41.963539 EDT | -----------------------  -------------
2017-07-02 15:27:41.963860 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #715 | Training started
2017-07-02 15:27:51.387081 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #715 | Training finished
2017-07-02 15:27:51.387582 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #715 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 15:27:51.387746 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #715 | Collecting samples for evaluation
2017-07-02 15:27:56.890792 EDT | -----------------------  -------------
2017-07-02 15:27:56.891284 EDT | Epoch                     715
2017-07-02 15:27:56.891420 EDT | Iteration                 715
2017-07-02 15:27:56.891549 EDT | AverageReturn            1000
2017-07-02 15:27:56.891682 EDT | StdReturn                   0
2017-07-02 15:27:56.891785 EDT | MaxReturn                1000
2017-07-02 15:27:56.891896 EDT | MinReturn                1000
2017-07-02 15:27:56.892002 EDT | AverageEsReturn            42.2917
2017-07-02 15:27:56.892136 EDT | StdEsReturn                36.3415
2017-07-02 15:27:56.892300 EDT | MaxEsReturn               133
2017-07-02 15:27:56.892530 EDT | MinEsReturn                 4
2017-07-02 15:27:56.892758 EDT | AverageDiscountedReturn    99.9957
2017-07-02 15:27:56.892964 EDT | AverageQLoss                0.00364578
2017-07-02 15:27:56.893195 EDT | AveragePolicySurr          -1.02764
2017-07-02 15:27:56.893421 EDT | AverageQ                    0.981789
2017-07-02 15:27:56.893669 EDT | AverageAbsQ                 0.985192
2017-07-02 15:27:56.893895 EDT | AverageY                    0.981695
2017-07-02 15:27:56.894083 EDT | AverageAbsY                 0.981853
2017-07-02 15:27:56.894199 EDT | AverageAbsQYDiff            0.0162737
2017-07-02 15:27:56.894384 EDT | AverageAction               0.911918
2017-07-02 15:27:56.894490 EDT | PolicyRegParamNorm         65.5275
2017-07-02 15:27:56.894638 EDT | QFunRegParamNorm           63.8279
2017-07-02 15:27:56.894860 EDT | -----------------------  -------------
2017-07-02 15:27:56.895177 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #716 | Training started
2017-07-02 15:28:06.247498 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #716 | Training finished
2017-07-02 15:28:06.248038 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #716 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 15:28:06.248451 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #716 | Collecting samples for evaluation
2017-07-02 15:28:11.703321 EDT | -----------------------  -------------
2017-07-02 15:28:11.703501 EDT | Epoch                     716
2017-07-02 15:28:11.703612 EDT | Iteration                 716
2017-07-02 15:28:11.703717 EDT | AverageReturn            1000
2017-07-02 15:28:11.703821 EDT | StdReturn                   0
2017-07-02 15:28:11.703922 EDT | MaxReturn                1000
2017-07-02 15:28:11.704022 EDT | MinReturn                1000
2017-07-02 15:28:11.704122 EDT | AverageEsReturn            42.6087
2017-07-02 15:28:11.704220 EDT | StdEsReturn                31.3365
2017-07-02 15:28:11.704320 EDT | MaxEsReturn               121
2017-07-02 15:28:11.704420 EDT | MinEsReturn                 3
2017-07-02 15:28:11.704519 EDT | AverageDiscountedReturn    99.9957
2017-07-02 15:28:11.704618 EDT | AverageQLoss                0.00365565
2017-07-02 15:28:11.704717 EDT | AveragePolicySurr          -1.02788
2017-07-02 15:28:11.704815 EDT | AverageQ                    0.981698
2017-07-02 15:28:11.704913 EDT | AverageAbsQ                 0.98446
2017-07-02 15:28:11.705012 EDT | AverageY                    0.981716
2017-07-02 15:28:11.705116 EDT | AverageAbsY                 0.981883
2017-07-02 15:28:11.705216 EDT | AverageAbsQYDiff            0.0155505
2017-07-02 15:28:11.705314 EDT | AverageAction               0.927483
2017-07-02 15:28:11.705413 EDT | PolicyRegParamNorm         65.547
2017-07-02 15:28:11.705529 EDT | QFunRegParamNorm           63.8547
2017-07-02 15:28:11.705708 EDT | -----------------------  -------------
2017-07-02 15:28:11.706029 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #717 | Training started
2017-07-02 15:28:21.060068 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #717 | Training finished
2017-07-02 15:28:21.060686 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #717 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 15:28:21.060934 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #717 | Collecting samples for evaluation
2017-07-02 15:28:26.530559 EDT | -----------------------  -------------
2017-07-02 15:28:26.530853 EDT | Epoch                     717
2017-07-02 15:28:26.531089 EDT | Iteration                 717
2017-07-02 15:28:26.531302 EDT | AverageReturn            1000
2017-07-02 15:28:26.531537 EDT | StdReturn                   0
2017-07-02 15:28:26.531759 EDT | MaxReturn                1000
2017-07-02 15:28:26.531883 EDT | MinReturn                1000
2017-07-02 15:28:26.531993 EDT | AverageEsReturn            59.5625
2017-07-02 15:28:26.532186 EDT | StdEsReturn                98.3469
2017-07-02 15:28:26.532418 EDT | MaxEsReturn               432
2017-07-02 15:28:26.532637 EDT | MinEsReturn                 6
2017-07-02 15:28:26.532871 EDT | AverageDiscountedReturn    99.9957
2017-07-02 15:28:26.533079 EDT | AverageQLoss                0.00293478
2017-07-02 15:28:26.533289 EDT | AveragePolicySurr          -1.02511
2017-07-02 15:28:26.533557 EDT | AverageQ                    0.97929
2017-07-02 15:28:26.533801 EDT | AverageAbsQ                 0.981654
2017-07-02 15:28:26.534016 EDT | AverageY                    0.979274
2017-07-02 15:28:26.534241 EDT | AverageAbsY                 0.979424
2017-07-02 15:28:26.534472 EDT | AverageAbsQYDiff            0.0140774
2017-07-02 15:28:26.534694 EDT | AverageAction               0.916624
2017-07-02 15:28:26.534925 EDT | PolicyRegParamNorm         65.5604
2017-07-02 15:28:26.535134 EDT | QFunRegParamNorm           63.8623
2017-07-02 15:28:26.535361 EDT | -----------------------  -------------
2017-07-02 15:28:26.535681 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #718 | Training started
2017-07-02 15:28:35.844098 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #718 | Training finished
2017-07-02 15:28:35.862878 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #718 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 15:28:35.863148 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #718 | Collecting samples for evaluation
2017-07-02 15:28:41.384612 EDT | -----------------------  -------------
2017-07-02 15:28:41.384924 EDT | Epoch                     718
2017-07-02 15:28:41.385150 EDT | Iteration                 718
2017-07-02 15:28:41.385383 EDT | AverageReturn            1000
2017-07-02 15:28:41.385627 EDT | StdReturn                   0
2017-07-02 15:28:41.385828 EDT | MaxReturn                1000
2017-07-02 15:28:41.386055 EDT | MinReturn                1000
2017-07-02 15:28:41.386208 EDT | AverageEsReturn            43.8333
2017-07-02 15:28:41.386435 EDT | StdEsReturn                46.8274
2017-07-02 15:28:41.386663 EDT | MaxEsReturn               223
2017-07-02 15:28:41.386975 EDT | MinEsReturn                 3
2017-07-02 15:28:41.387149 EDT | AverageDiscountedReturn    99.9957
2017-07-02 15:28:41.387288 EDT | AverageQLoss                0.00344997
2017-07-02 15:28:41.387408 EDT | AveragePolicySurr          -1.02223
2017-07-02 15:28:41.387515 EDT | AverageQ                    0.978119
2017-07-02 15:28:41.387646 EDT | AverageAbsQ                 0.980594
2017-07-02 15:28:41.387754 EDT | AverageY                    0.97818
2017-07-02 15:28:41.387859 EDT | AverageAbsY                 0.978354
2017-07-02 15:28:41.387964 EDT | AverageAbsQYDiff            0.0148201
2017-07-02 15:28:41.388087 EDT | AverageAction               0.956766
2017-07-02 15:28:41.388198 EDT | PolicyRegParamNorm         65.5483
2017-07-02 15:28:41.388304 EDT | QFunRegParamNorm           63.8874
2017-07-02 15:28:41.388408 EDT | -----------------------  -------------
2017-07-02 15:28:41.388572 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #719 | Training started
2017-07-02 15:28:50.613171 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #719 | Training finished
2017-07-02 15:28:50.613899 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #719 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 15:28:50.614320 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #719 | Collecting samples for evaluation
2017-07-02 15:28:56.207712 EDT | -----------------------  -------------
2017-07-02 15:28:56.207983 EDT | Epoch                     719
2017-07-02 15:28:56.208155 EDT | Iteration                 719
2017-07-02 15:28:56.208333 EDT | AverageReturn            1000
2017-07-02 15:28:56.208551 EDT | StdReturn                   0
2017-07-02 15:28:56.208777 EDT | MaxReturn                1000
2017-07-02 15:28:56.208990 EDT | MinReturn                1000
2017-07-02 15:28:56.209219 EDT | AverageEsReturn            37.8462
2017-07-02 15:28:56.209431 EDT | StdEsReturn                24.0715
2017-07-02 15:28:56.209653 EDT | MaxEsReturn                97
2017-07-02 15:28:56.209880 EDT | MinEsReturn                 6
2017-07-02 15:28:56.210106 EDT | AverageDiscountedReturn    99.9957
2017-07-02 15:28:56.210334 EDT | AverageQLoss                0.00317389
2017-07-02 15:28:56.210562 EDT | AveragePolicySurr          -1.02257
2017-07-02 15:28:56.210725 EDT | AverageQ                    0.978837
2017-07-02 15:28:56.210955 EDT | AverageAbsQ                 0.981524
2017-07-02 15:28:56.211155 EDT | AverageY                    0.978818
2017-07-02 15:28:56.211375 EDT | AverageAbsY                 0.979058
2017-07-02 15:28:56.211603 EDT | AverageAbsQYDiff            0.0146616
2017-07-02 15:28:56.211808 EDT | AverageAction               0.409096
2017-07-02 15:28:56.212036 EDT | PolicyRegParamNorm         65.5624
2017-07-02 15:28:56.212245 EDT | QFunRegParamNorm           63.9105
2017-07-02 15:28:56.212476 EDT | -----------------------  -------------
2017-07-02 15:28:56.212719 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #720 | Training started
2017-07-02 15:29:05.563696 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #720 | Training finished
2017-07-02 15:29:05.564298 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #720 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 15:29:05.564531 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #720 | Collecting samples for evaluation
2017-07-02 15:29:11.068252 EDT | -----------------------  -------------
2017-07-02 15:29:11.068580 EDT | Epoch                     720
2017-07-02 15:29:11.068821 EDT | Iteration                 720
2017-07-02 15:29:11.069035 EDT | AverageReturn            1000
2017-07-02 15:29:11.069264 EDT | StdReturn                   0
2017-07-02 15:29:11.069484 EDT | MaxReturn                1000
2017-07-02 15:29:11.069738 EDT | MinReturn                1000
2017-07-02 15:29:11.069950 EDT | AverageEsReturn            58.5882
2017-07-02 15:29:11.070191 EDT | StdEsReturn                33.6471
2017-07-02 15:29:11.070410 EDT | MaxEsReturn               126
2017-07-02 15:29:11.070628 EDT | MinEsReturn                13
2017-07-02 15:29:11.070854 EDT | AverageDiscountedReturn    99.9957
2017-07-02 15:29:11.071083 EDT | AverageQLoss                0.00384082
2017-07-02 15:29:11.071315 EDT | AveragePolicySurr          -1.02059
2017-07-02 15:29:11.071524 EDT | AverageQ                    0.975205
2017-07-02 15:29:11.071756 EDT | AverageAbsQ                 0.977966
2017-07-02 15:29:11.071965 EDT | AverageY                    0.975174
2017-07-02 15:29:11.072184 EDT | AverageAbsY                 0.975292
2017-07-02 15:29:11.072388 EDT | AverageAbsQYDiff            0.0161244
2017-07-02 15:29:11.072613 EDT | AverageAction               0.933861
2017-07-02 15:29:11.072798 EDT | PolicyRegParamNorm         65.6039
2017-07-02 15:29:11.073024 EDT | QFunRegParamNorm           63.9735
2017-07-02 15:29:11.073229 EDT | -----------------------  -------------
2017-07-02 15:29:11.073699 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #721 | Training started
2017-07-02 15:29:20.402774 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #721 | Training finished
2017-07-02 15:29:20.403772 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #721 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 15:29:20.403997 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #721 | Collecting samples for evaluation
2017-07-02 15:29:26.158945 EDT | -----------------------  ------------
2017-07-02 15:29:26.159138 EDT | Epoch                    721
2017-07-02 15:29:26.159257 EDT | Iteration                721
2017-07-02 15:29:26.159456 EDT | AverageReturn             50.9695
2017-07-02 15:29:26.159597 EDT | StdReturn                  1.54101
2017-07-02 15:29:26.159769 EDT | MaxReturn                 56
2017-07-02 15:29:26.159905 EDT | MinReturn                 49
2017-07-02 15:29:26.160040 EDT | AverageEsReturn           42.1667
2017-07-02 15:29:26.160229 EDT | StdEsReturn               47.4084
2017-07-02 15:29:26.160446 EDT | MaxEsReturn              194
2017-07-02 15:29:26.160678 EDT | MinEsReturn                4
2017-07-02 15:29:26.160896 EDT | AverageDiscountedReturn   40.0789
2017-07-02 15:29:26.161087 EDT | AverageQLoss               0.00458444
2017-07-02 15:29:26.161207 EDT | AveragePolicySurr         -1.01936
2017-07-02 15:29:26.161411 EDT | AverageQ                   0.97433
2017-07-02 15:29:26.161657 EDT | AverageAbsQ                0.977433
2017-07-02 15:29:26.161856 EDT | AverageY                   0.974224
2017-07-02 15:29:26.162085 EDT | AverageAbsY                0.974439
2017-07-02 15:29:26.162308 EDT | AverageAbsQYDiff           0.0178209
2017-07-02 15:29:26.162528 EDT | AverageAction              0.358955
2017-07-02 15:29:26.162746 EDT | PolicyRegParamNorm        65.5204
2017-07-02 15:29:26.162960 EDT | QFunRegParamNorm          64.0007
2017-07-02 15:29:26.163097 EDT | -----------------------  ------------
2017-07-02 15:29:26.163417 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #722 | Training started
2017-07-02 15:29:35.629974 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #722 | Training finished
2017-07-02 15:29:35.630575 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #722 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 15:29:35.630749 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #722 | Collecting samples for evaluation
2017-07-02 15:29:41.443723 EDT | -----------------------  ------------
2017-07-02 15:29:41.443946 EDT | Epoch                    722
2017-07-02 15:29:41.444067 EDT | Iteration                722
2017-07-02 15:29:41.444220 EDT | AverageReturn             45.1802
2017-07-02 15:29:41.444417 EDT | StdReturn                  0.384337
2017-07-02 15:29:41.444637 EDT | MaxReturn                 46
2017-07-02 15:29:41.444859 EDT | MinReturn                 45
2017-07-02 15:29:41.445078 EDT | AverageEsReturn           22.3256
2017-07-02 15:29:41.445291 EDT | StdEsReturn               19.3484
2017-07-02 15:29:41.445438 EDT | MaxEsReturn               77
2017-07-02 15:29:41.445559 EDT | MinEsReturn                3
2017-07-02 15:29:41.445659 EDT | AverageDiscountedReturn   36.4961
2017-07-02 15:29:41.445806 EDT | AverageQLoss               0.00313772
2017-07-02 15:29:41.446026 EDT | AveragePolicySurr         -1.01985
2017-07-02 15:29:41.446246 EDT | AverageQ                   0.974308
2017-07-02 15:29:41.446417 EDT | AverageAbsQ                0.976383
2017-07-02 15:29:41.446631 EDT | AverageY                   0.974323
2017-07-02 15:29:41.446852 EDT | AverageAbsY                0.974402
2017-07-02 15:29:41.447045 EDT | AverageAbsQYDiff           0.0142717
2017-07-02 15:29:41.447151 EDT | AverageAction              0.476049
2017-07-02 15:29:41.447252 EDT | PolicyRegParamNorm        65.5285
2017-07-02 15:29:41.447354 EDT | QFunRegParamNorm          64.0175
2017-07-02 15:29:41.447568 EDT | -----------------------  ------------
2017-07-02 15:29:41.447858 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #723 | Training started
2017-07-02 15:29:50.690873 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #723 | Training finished
2017-07-02 15:29:50.691448 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #723 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 15:29:50.691709 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #723 | Collecting samples for evaluation
2017-07-02 15:29:56.266438 EDT | -----------------------  -------------
2017-07-02 15:29:56.266737 EDT | Epoch                     723
2017-07-02 15:29:56.266969 EDT | Iteration                 723
2017-07-02 15:29:56.267199 EDT | AverageReturn            1000
2017-07-02 15:29:56.267428 EDT | StdReturn                   0
2017-07-02 15:29:56.267713 EDT | MaxReturn                1000
2017-07-02 15:29:56.268037 EDT | MinReturn                1000
2017-07-02 15:29:56.268312 EDT | AverageEsReturn            28.6486
2017-07-02 15:29:56.268540 EDT | StdEsReturn                28.6632
2017-07-02 15:29:56.268700 EDT | MaxEsReturn               115
2017-07-02 15:29:56.268930 EDT | MinEsReturn                 4
2017-07-02 15:29:56.269146 EDT | AverageDiscountedReturn    99.9957
2017-07-02 15:29:56.269367 EDT | AverageQLoss                0.00318977
2017-07-02 15:29:56.269616 EDT | AveragePolicySurr          -1.01877
2017-07-02 15:29:56.269843 EDT | AverageQ                    0.974559
2017-07-02 15:29:56.270070 EDT | AverageAbsQ                 0.976849
2017-07-02 15:29:56.270299 EDT | AverageY                    0.974598
2017-07-02 15:29:56.270519 EDT | AverageAbsY                 0.974673
2017-07-02 15:29:56.270737 EDT | AverageAbsQYDiff            0.0135103
2017-07-02 15:29:56.270882 EDT | AverageAction               0.824884
2017-07-02 15:29:56.271095 EDT | PolicyRegParamNorm         65.5757
2017-07-02 15:29:56.271318 EDT | QFunRegParamNorm           64.0462
2017-07-02 15:29:56.271542 EDT | -----------------------  -------------
2017-07-02 15:29:56.271856 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #724 | Training started
2017-07-02 15:30:05.477168 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #724 | Training finished
2017-07-02 15:30:05.477738 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #724 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 15:30:05.478103 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #724 | Collecting samples for evaluation
2017-07-02 15:30:11.161311 EDT | -----------------------  -------------
2017-07-02 15:30:11.161513 EDT | Epoch                     724
2017-07-02 15:30:11.161626 EDT | Iteration                 724
2017-07-02 15:30:11.161761 EDT | AverageReturn            1000
2017-07-02 15:30:11.161875 EDT | StdReturn                   0
2017-07-02 15:30:11.161984 EDT | MaxReturn                1000
2017-07-02 15:30:11.162132 EDT | MinReturn                1000
2017-07-02 15:30:11.162270 EDT | AverageEsReturn            24.25
2017-07-02 15:30:11.162408 EDT | StdEsReturn                21.6515
2017-07-02 15:30:11.162597 EDT | MaxEsReturn                99
2017-07-02 15:30:11.162803 EDT | MinEsReturn                 3
2017-07-02 15:30:11.163005 EDT | AverageDiscountedReturn    99.9957
2017-07-02 15:30:11.163177 EDT | AverageQLoss                0.00374729
2017-07-02 15:30:11.163295 EDT | AveragePolicySurr          -1.01562
2017-07-02 15:30:11.163446 EDT | AverageQ                    0.972424
2017-07-02 15:30:11.163548 EDT | AverageAbsQ                 0.975108
2017-07-02 15:30:11.163648 EDT | AverageY                    0.972398
2017-07-02 15:30:11.163805 EDT | AverageAbsY                 0.972559
2017-07-02 15:30:11.163908 EDT | AverageAbsQYDiff            0.0153116
2017-07-02 15:30:11.164008 EDT | AverageAction               0.684612
2017-07-02 15:30:11.164106 EDT | PolicyRegParamNorm         65.601
2017-07-02 15:30:11.164204 EDT | QFunRegParamNorm           64.0833
2017-07-02 15:30:11.164347 EDT | -----------------------  -------------
2017-07-02 15:30:11.164521 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #725 | Training started
2017-07-02 15:30:20.752297 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #725 | Training finished
2017-07-02 15:30:20.752787 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #725 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 15:30:20.752927 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #725 | Collecting samples for evaluation
2017-07-02 15:30:26.432506 EDT | -----------------------  -------------
2017-07-02 15:30:26.432691 EDT | Epoch                     725
2017-07-02 15:30:26.432813 EDT | Iteration                 725
2017-07-02 15:30:26.432928 EDT | AverageReturn            1000
2017-07-02 15:30:26.433031 EDT | StdReturn                   0
2017-07-02 15:30:26.433172 EDT | MaxReturn                1000
2017-07-02 15:30:26.433323 EDT | MinReturn                1000
2017-07-02 15:30:26.433441 EDT | AverageEsReturn            37.2963
2017-07-02 15:30:26.433657 EDT | StdEsReturn                39.0297
2017-07-02 15:30:26.433768 EDT | MaxEsReturn               138
2017-07-02 15:30:26.433943 EDT | MinEsReturn                 4
2017-07-02 15:30:26.434125 EDT | AverageDiscountedReturn    99.9957
2017-07-02 15:30:26.434309 EDT | AverageQLoss                0.00346177
2017-07-02 15:30:26.434427 EDT | AveragePolicySurr          -1.01802
2017-07-02 15:30:26.434528 EDT | AverageQ                    0.97379
2017-07-02 15:30:26.434627 EDT | AverageAbsQ                 0.97661
2017-07-02 15:30:26.434751 EDT | AverageY                    0.973788
2017-07-02 15:30:26.434852 EDT | AverageAbsY                 0.974048
2017-07-02 15:30:26.434992 EDT | AverageAbsQYDiff            0.0153056
2017-07-02 15:30:26.435192 EDT | AverageAction               0.824074
2017-07-02 15:30:26.435358 EDT | PolicyRegParamNorm         65.6112
2017-07-02 15:30:26.435517 EDT | QFunRegParamNorm           64.0998
2017-07-02 15:30:26.435698 EDT | -----------------------  -------------
2017-07-02 15:30:26.435977 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #726 | Training started
2017-07-02 15:30:35.787364 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #726 | Training finished
2017-07-02 15:30:35.788080 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #726 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 15:30:35.788319 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #726 | Collecting samples for evaluation
2017-07-02 15:30:41.183185 EDT | -----------------------  -------------
2017-07-02 15:30:41.183408 EDT | Epoch                     726
2017-07-02 15:30:41.183527 EDT | Iteration                 726
2017-07-02 15:30:41.183654 EDT | AverageReturn            1000
2017-07-02 15:30:41.183761 EDT | StdReturn                   0
2017-07-02 15:30:41.183923 EDT | MaxReturn                1000
2017-07-02 15:30:41.184056 EDT | MinReturn                1000
2017-07-02 15:30:41.184222 EDT | AverageEsReturn            20.551
2017-07-02 15:30:41.184383 EDT | StdEsReturn                20.0184
2017-07-02 15:30:41.184540 EDT | MaxEsReturn               123
2017-07-02 15:30:41.184719 EDT | MinEsReturn                 3
2017-07-02 15:30:41.184904 EDT | AverageDiscountedReturn    99.9957
2017-07-02 15:30:41.185083 EDT | AverageQLoss                0.00313457
2017-07-02 15:30:41.185261 EDT | AveragePolicySurr          -1.01349
2017-07-02 15:30:41.185439 EDT | AverageQ                    0.969988
2017-07-02 15:30:41.185639 EDT | AverageAbsQ                 0.972359
2017-07-02 15:30:41.185817 EDT | AverageY                    0.970023
2017-07-02 15:30:41.185996 EDT | AverageAbsY                 0.970241
2017-07-02 15:30:41.186174 EDT | AverageAbsQYDiff            0.014031
2017-07-02 15:30:41.186349 EDT | AverageAction               0.836383
2017-07-02 15:30:41.186525 EDT | PolicyRegParamNorm         65.7036
2017-07-02 15:30:41.186703 EDT | QFunRegParamNorm           64.1429
2017-07-02 15:30:41.186883 EDT | -----------------------  -------------
2017-07-02 15:30:41.187154 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #727 | Training started
2017-07-02 15:30:50.644704 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #727 | Training finished
2017-07-02 15:30:50.645229 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #727 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 15:30:50.645460 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #727 | Collecting samples for evaluation
2017-07-02 15:30:56.086748 EDT | -----------------------  -------------
2017-07-02 15:30:56.086972 EDT | Epoch                     727
2017-07-02 15:30:56.087205 EDT | Iteration                 727
2017-07-02 15:30:56.087406 EDT | AverageReturn            1000
2017-07-02 15:30:56.087511 EDT | StdReturn                   0
2017-07-02 15:30:56.087676 EDT | MaxReturn                1000
2017-07-02 15:30:56.087902 EDT | MinReturn                1000
2017-07-02 15:30:56.088080 EDT | AverageEsReturn            20.12
2017-07-02 15:30:56.088304 EDT | StdEsReturn                29.0377
2017-07-02 15:30:56.088519 EDT | MaxEsReturn               204
2017-07-02 15:30:56.088716 EDT | MinEsReturn                 3
2017-07-02 15:30:56.088939 EDT | AverageDiscountedReturn    99.9957
2017-07-02 15:30:56.089098 EDT | AverageQLoss                0.00391445
2017-07-02 15:30:56.089326 EDT | AveragePolicySurr          -1.01488
2017-07-02 15:30:56.089628 EDT | AverageQ                    0.969424
2017-07-02 15:30:56.089826 EDT | AverageAbsQ                 0.972851
2017-07-02 15:30:56.090054 EDT | AverageY                    0.969406
2017-07-02 15:30:56.090283 EDT | AverageAbsY                 0.969618
2017-07-02 15:30:56.090453 EDT | AverageAbsQYDiff            0.0169154
2017-07-02 15:30:56.090596 EDT | AverageAction               0.385665
2017-07-02 15:30:56.090723 EDT | PolicyRegParamNorm         65.7125
2017-07-02 15:30:56.090932 EDT | QFunRegParamNorm           64.1713
2017-07-02 15:30:56.091159 EDT | -----------------------  -------------
2017-07-02 15:30:56.091369 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #728 | Training started
2017-07-02 15:31:05.471091 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #728 | Training finished
2017-07-02 15:31:05.471998 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #728 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 15:31:05.472187 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #728 | Collecting samples for evaluation
2017-07-02 15:31:10.917069 EDT | -----------------------  -------------
2017-07-02 15:31:10.917370 EDT | Epoch                     728
2017-07-02 15:31:10.917590 EDT | Iteration                 728
2017-07-02 15:31:10.917820 EDT | AverageReturn            1000
2017-07-02 15:31:10.917981 EDT | StdReturn                   0
2017-07-02 15:31:10.918215 EDT | MaxReturn                1000
2017-07-02 15:31:10.918419 EDT | MinReturn                1000
2017-07-02 15:31:10.918526 EDT | AverageEsReturn            19.4706
2017-07-02 15:31:10.918634 EDT | StdEsReturn                19.8735
2017-07-02 15:31:10.918855 EDT | MaxEsReturn               123
2017-07-02 15:31:10.919076 EDT | MinEsReturn                 3
2017-07-02 15:31:10.919189 EDT | AverageDiscountedReturn    99.9957
2017-07-02 15:31:10.919362 EDT | AverageQLoss                0.00295688
2017-07-02 15:31:10.919591 EDT | AveragePolicySurr          -1.01355
2017-07-02 15:31:10.919755 EDT | AverageQ                    0.97017
2017-07-02 15:31:10.919861 EDT | AverageAbsQ                 0.972439
2017-07-02 15:31:10.919964 EDT | AverageY                    0.970175
2017-07-02 15:31:10.920107 EDT | AverageAbsY                 0.970464
2017-07-02 15:31:10.920334 EDT | AverageAbsQYDiff            0.0142974
2017-07-02 15:31:10.920528 EDT | AverageAction               0.0222518
2017-07-02 15:31:10.920754 EDT | PolicyRegParamNorm         65.7139
2017-07-02 15:31:10.920975 EDT | QFunRegParamNorm           64.2025
2017-07-02 15:31:10.921162 EDT | -----------------------  -------------
2017-07-02 15:31:10.921478 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #729 | Training started
2017-07-02 15:31:20.263408 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #729 | Training finished
2017-07-02 15:31:20.264013 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #729 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 15:31:20.264154 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #729 | Collecting samples for evaluation
2017-07-02 15:31:25.713175 EDT | -----------------------  ------------
2017-07-02 15:31:25.713414 EDT | Epoch                     729
2017-07-02 15:31:25.713623 EDT | Iteration                 729
2017-07-02 15:31:25.713813 EDT | AverageReturn            1000
2017-07-02 15:31:25.713942 EDT | StdReturn                   0
2017-07-02 15:31:25.714070 EDT | MaxReturn                1000
2017-07-02 15:31:25.714190 EDT | MinReturn                1000
2017-07-02 15:31:25.714292 EDT | AverageEsReturn            16.1129
2017-07-02 15:31:25.714392 EDT | StdEsReturn                14.6388
2017-07-02 15:31:25.714491 EDT | MaxEsReturn                61
2017-07-02 15:31:25.714615 EDT | MinEsReturn                 3
2017-07-02 15:31:25.714732 EDT | AverageDiscountedReturn    99.9957
2017-07-02 15:31:25.714840 EDT | AverageQLoss                0.0031689
2017-07-02 15:31:25.714941 EDT | AveragePolicySurr          -1.01364
2017-07-02 15:31:25.715041 EDT | AverageQ                    0.968228
2017-07-02 15:31:25.715154 EDT | AverageAbsQ                 0.970944
2017-07-02 15:31:25.715257 EDT | AverageY                    0.968226
2017-07-02 15:31:25.715357 EDT | AverageAbsY                 0.968587
2017-07-02 15:31:25.715464 EDT | AverageAbsQYDiff            0.0145345
2017-07-02 15:31:25.715563 EDT | AverageAction               0.0169146
2017-07-02 15:31:25.715725 EDT | PolicyRegParamNorm         65.7455
2017-07-02 15:31:25.715843 EDT | QFunRegParamNorm           64.2239
2017-07-02 15:31:25.715943 EDT | -----------------------  ------------
2017-07-02 15:31:25.716122 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #730 | Training started
2017-07-02 15:31:35.091361 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #730 | Training finished
2017-07-02 15:31:35.091892 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #730 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 15:31:35.092155 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #730 | Collecting samples for evaluation
2017-07-02 15:31:40.530747 EDT | -----------------------  -------------
2017-07-02 15:31:40.531064 EDT | Epoch                     730
2017-07-02 15:31:40.531221 EDT | Iteration                 730
2017-07-02 15:31:40.531457 EDT | AverageReturn            1000
2017-07-02 15:31:40.531660 EDT | StdReturn                   0
2017-07-02 15:31:40.531880 EDT | MaxReturn                1000
2017-07-02 15:31:40.532112 EDT | MinReturn                1000
2017-07-02 15:31:40.532233 EDT | AverageEsReturn            19.9796
2017-07-02 15:31:40.532336 EDT | StdEsReturn                15.993
2017-07-02 15:31:40.532437 EDT | MaxEsReturn                87
2017-07-02 15:31:40.532536 EDT | MinEsReturn                 3
2017-07-02 15:31:40.532741 EDT | AverageDiscountedReturn    99.9957
2017-07-02 15:31:40.532969 EDT | AverageQLoss                0.00315513
2017-07-02 15:31:40.533112 EDT | AveragePolicySurr          -1.01218
2017-07-02 15:31:40.533342 EDT | AverageQ                    0.968429
2017-07-02 15:31:40.533616 EDT | AverageAbsQ                 0.970927
2017-07-02 15:31:40.533725 EDT | AverageY                    0.968371
2017-07-02 15:31:40.533837 EDT | AverageAbsY                 0.968665
2017-07-02 15:31:40.534066 EDT | AverageAbsQYDiff            0.013886
2017-07-02 15:31:40.534288 EDT | AverageAction               0.0108738
2017-07-02 15:31:40.534454 EDT | PolicyRegParamNorm         65.7652
2017-07-02 15:31:40.534687 EDT | QFunRegParamNorm           64.2659
2017-07-02 15:31:40.534878 EDT | -----------------------  -------------
2017-07-02 15:31:40.535204 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #731 | Training started
2017-07-02 15:31:49.948870 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #731 | Training finished
2017-07-02 15:31:49.949532 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #731 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 15:31:49.949777 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #731 | Collecting samples for evaluation
2017-07-02 15:31:55.592001 EDT | -----------------------  ------------
2017-07-02 15:31:55.592193 EDT | Epoch                    731
2017-07-02 15:31:55.592350 EDT | Iteration                731
2017-07-02 15:31:55.592499 EDT | AverageReturn             50.3367
2017-07-02 15:31:55.592655 EDT | StdReturn                  0.472576
2017-07-02 15:31:55.592782 EDT | MaxReturn                 51
2017-07-02 15:31:55.592945 EDT | MinReturn                 50
2017-07-02 15:31:55.593090 EDT | AverageEsReturn           13.5325
2017-07-02 15:31:55.593194 EDT | StdEsReturn               13.1619
2017-07-02 15:31:55.593316 EDT | MaxEsReturn               67
2017-07-02 15:31:55.593482 EDT | MinEsReturn                3
2017-07-02 15:31:55.593650 EDT | AverageDiscountedReturn   39.7031
2017-07-02 15:31:55.593777 EDT | AverageQLoss               0.00341545
2017-07-02 15:31:55.593941 EDT | AveragePolicySurr         -1.01226
2017-07-02 15:31:55.594092 EDT | AverageQ                   0.969568
2017-07-02 15:31:55.594248 EDT | AverageAbsQ                0.972161
2017-07-02 15:31:55.594378 EDT | AverageY                   0.969621
2017-07-02 15:31:55.594492 EDT | AverageAbsY                0.970006
2017-07-02 15:31:55.594649 EDT | AverageAbsQYDiff           0.0143986
2017-07-02 15:31:55.594756 EDT | AverageAction              0.239698
2017-07-02 15:31:55.594874 EDT | PolicyRegParamNorm        65.757
2017-07-02 15:31:55.595002 EDT | QFunRegParamNorm          64.2811
2017-07-02 15:31:55.595129 EDT | -----------------------  ------------
2017-07-02 15:31:55.595455 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #732 | Training started
2017-07-02 15:32:05.019907 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #732 | Training finished
2017-07-02 15:32:05.020507 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #732 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 15:32:05.020655 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #732 | Collecting samples for evaluation
2017-07-02 15:32:10.458439 EDT | -----------------------  -------------
2017-07-02 15:32:10.458711 EDT | Epoch                     732
2017-07-02 15:32:10.458860 EDT | Iteration                 732
2017-07-02 15:32:10.459033 EDT | AverageReturn            1000
2017-07-02 15:32:10.459195 EDT | StdReturn                   0
2017-07-02 15:32:10.459300 EDT | MaxReturn                1000
2017-07-02 15:32:10.459401 EDT | MinReturn                1000
2017-07-02 15:32:10.459533 EDT | AverageEsReturn            20.2857
2017-07-02 15:32:10.459637 EDT | StdEsReturn                19.1311
2017-07-02 15:32:10.459774 EDT | MaxEsReturn                79
2017-07-02 15:32:10.459897 EDT | MinEsReturn                 3
2017-07-02 15:32:10.459999 EDT | AverageDiscountedReturn    99.9957
2017-07-02 15:32:10.460172 EDT | AverageQLoss                0.00313933
2017-07-02 15:32:10.460400 EDT | AveragePolicySurr          -1.01198
2017-07-02 15:32:10.460730 EDT | AverageQ                    0.966697
2017-07-02 15:32:10.460912 EDT | AverageAbsQ                 0.969342
2017-07-02 15:32:10.461079 EDT | AverageY                    0.966728
2017-07-02 15:32:10.461286 EDT | AverageAbsY                 0.967057
2017-07-02 15:32:10.461524 EDT | AverageAbsQYDiff            0.0141052
2017-07-02 15:32:10.461745 EDT | AverageAction               0.551384
2017-07-02 15:32:10.461974 EDT | PolicyRegParamNorm         65.7956
2017-07-02 15:32:10.462205 EDT | QFunRegParamNorm           64.2857
2017-07-02 15:32:10.462429 EDT | -----------------------  -------------
2017-07-02 15:32:10.462753 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #733 | Training started
2017-07-02 15:32:19.831265 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #733 | Training finished
2017-07-02 15:32:19.831815 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #733 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 15:32:19.832028 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #733 | Collecting samples for evaluation
2017-07-02 15:32:25.296626 EDT | -----------------------  -------------
2017-07-02 15:32:25.296951 EDT | Epoch                     733
2017-07-02 15:32:25.297184 EDT | Iteration                 733
2017-07-02 15:32:25.297406 EDT | AverageReturn            1000
2017-07-02 15:32:25.297618 EDT | StdReturn                   0
2017-07-02 15:32:25.297842 EDT | MaxReturn                1000
2017-07-02 15:32:25.298036 EDT | MinReturn                1000
2017-07-02 15:32:25.298278 EDT | AverageEsReturn            24.775
2017-07-02 15:32:25.298505 EDT | StdEsReturn                34.3114
2017-07-02 15:32:25.298726 EDT | MaxEsReturn               174
2017-07-02 15:32:25.298878 EDT | MinEsReturn                 3
2017-07-02 15:32:25.299047 EDT | AverageDiscountedReturn    99.9957
2017-07-02 15:32:25.299267 EDT | AverageQLoss                0.00352149
2017-07-02 15:32:25.299465 EDT | AveragePolicySurr          -1.01101
2017-07-02 15:32:25.299680 EDT | AverageQ                    0.966483
2017-07-02 15:32:25.299905 EDT | AverageAbsQ                 0.969581
2017-07-02 15:32:25.300122 EDT | AverageY                    0.966447
2017-07-02 15:32:25.300352 EDT | AverageAbsY                 0.966772
2017-07-02 15:32:25.300467 EDT | AverageAbsQYDiff            0.0155279
2017-07-02 15:32:25.300571 EDT | AverageAction               0.00961125
2017-07-02 15:32:25.300672 EDT | PolicyRegParamNorm         65.8085
2017-07-02 15:32:25.300773 EDT | QFunRegParamNorm           64.2891
2017-07-02 15:32:25.300873 EDT | -----------------------  -------------
2017-07-02 15:32:25.301136 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #734 | Training started
2017-07-02 15:32:34.640881 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #734 | Training finished
2017-07-02 15:32:34.641532 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #734 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 15:32:34.641746 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #734 | Collecting samples for evaluation
2017-07-02 15:32:40.125857 EDT | -----------------------  ------------
2017-07-02 15:32:40.126107 EDT | Epoch                     734
2017-07-02 15:32:40.126230 EDT | Iteration                 734
2017-07-02 15:32:40.126333 EDT | AverageReturn            1000
2017-07-02 15:32:40.126432 EDT | StdReturn                   0
2017-07-02 15:32:40.126610 EDT | MaxReturn                1000
2017-07-02 15:32:40.126743 EDT | MinReturn                1000
2017-07-02 15:32:40.126846 EDT | AverageEsReturn            22.5333
2017-07-02 15:32:40.127051 EDT | StdEsReturn                21.2881
2017-07-02 15:32:40.127179 EDT | MaxEsReturn                99
2017-07-02 15:32:40.127289 EDT | MinEsReturn                 3
2017-07-02 15:32:40.127392 EDT | AverageDiscountedReturn    99.9957
2017-07-02 15:32:40.127509 EDT | AverageQLoss                0.0034265
2017-07-02 15:32:40.127675 EDT | AveragePolicySurr          -1.0102
2017-07-02 15:32:40.127808 EDT | AverageQ                    0.964921
2017-07-02 15:32:40.127910 EDT | AverageAbsQ                 0.967377
2017-07-02 15:32:40.128076 EDT | AverageY                    0.964923
2017-07-02 15:32:40.128229 EDT | AverageAbsY                 0.96513
2017-07-02 15:32:40.128332 EDT | AverageAbsQYDiff            0.0145712
2017-07-02 15:32:40.128430 EDT | AverageAction               0.0161259
2017-07-02 15:32:40.128547 EDT | PolicyRegParamNorm         65.8328
2017-07-02 15:32:40.128721 EDT | QFunRegParamNorm           64.3116
2017-07-02 15:32:40.128914 EDT | -----------------------  ------------
2017-07-02 15:32:40.129122 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #735 | Training started
2017-07-02 15:32:49.446320 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #735 | Training finished
2017-07-02 15:32:49.446946 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #735 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 15:32:49.447124 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #735 | Collecting samples for evaluation
2017-07-02 15:32:54.884558 EDT | -----------------------  -------------
2017-07-02 15:32:54.884795 EDT | Epoch                     735
2017-07-02 15:32:54.885000 EDT | Iteration                 735
2017-07-02 15:32:54.885186 EDT | AverageReturn            1000
2017-07-02 15:32:54.885359 EDT | StdReturn                   0
2017-07-02 15:32:54.885592 EDT | MaxReturn                1000
2017-07-02 15:32:54.885809 EDT | MinReturn                1000
2017-07-02 15:32:54.886028 EDT | AverageEsReturn            16.1613
2017-07-02 15:32:54.886231 EDT | StdEsReturn                15.599
2017-07-02 15:32:54.886394 EDT | MaxEsReturn                67
2017-07-02 15:32:54.886611 EDT | MinEsReturn                 3
2017-07-02 15:32:54.886833 EDT | AverageDiscountedReturn    99.9957
2017-07-02 15:32:54.887051 EDT | AverageQLoss                0.00339575
2017-07-02 15:32:54.887269 EDT | AveragePolicySurr          -1.01079
2017-07-02 15:32:54.887489 EDT | AverageQ                    0.96495
2017-07-02 15:32:54.887667 EDT | AverageAbsQ                 0.967871
2017-07-02 15:32:54.887844 EDT | AverageY                    0.96496
2017-07-02 15:32:54.888017 EDT | AverageAbsY                 0.965211
2017-07-02 15:32:54.888193 EDT | AverageAbsQYDiff            0.0163241
2017-07-02 15:32:54.888370 EDT | AverageAction               0.493372
2017-07-02 15:32:54.888546 EDT | PolicyRegParamNorm         65.8008
2017-07-02 15:32:54.888723 EDT | QFunRegParamNorm           64.3426
2017-07-02 15:32:54.888899 EDT | -----------------------  -------------
2017-07-02 15:32:54.889171 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #736 | Training started
2017-07-02 15:33:04.371369 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #736 | Training finished
2017-07-02 15:33:04.371918 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #736 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 15:33:04.372125 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #736 | Collecting samples for evaluation
2017-07-02 15:33:10.107129 EDT | -----------------------  ------------
2017-07-02 15:33:10.107353 EDT | Epoch                    736
2017-07-02 15:33:10.107579 EDT | Iteration                736
2017-07-02 15:33:10.107784 EDT | AverageReturn             49.6683
2017-07-02 15:33:10.108010 EDT | StdReturn                  0.940763
2017-07-02 15:33:10.108217 EDT | MaxReturn                 52
2017-07-02 15:33:10.108447 EDT | MinReturn                 47
2017-07-02 15:33:10.108653 EDT | AverageEsReturn           13.6849
2017-07-02 15:33:10.108867 EDT | StdEsReturn               13.1523
2017-07-02 15:33:10.109098 EDT | MaxEsReturn               52
2017-07-02 15:33:10.109214 EDT | MinEsReturn                2
2017-07-02 15:33:10.109318 EDT | AverageDiscountedReturn   39.2947
2017-07-02 15:33:10.109462 EDT | AverageQLoss               0.00321437
2017-07-02 15:33:10.109711 EDT | AveragePolicySurr         -1.01138
2017-07-02 15:33:10.109913 EDT | AverageQ                   0.965374
2017-07-02 15:33:10.110141 EDT | AverageAbsQ                0.967993
2017-07-02 15:33:10.110346 EDT | AverageY                   0.965391
2017-07-02 15:33:10.110573 EDT | AverageAbsY                0.965518
2017-07-02 15:33:10.110777 EDT | AverageAbsQYDiff           0.0145434
2017-07-02 15:33:10.110994 EDT | AverageAction              0.296767
2017-07-02 15:33:10.111219 EDT | PolicyRegParamNorm        65.8309
2017-07-02 15:33:10.111388 EDT | QFunRegParamNorm          64.3469
2017-07-02 15:33:10.111603 EDT | -----------------------  ------------
2017-07-02 15:33:10.111904 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #737 | Training started
2017-07-02 15:33:19.588855 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #737 | Training finished
2017-07-02 15:33:19.589454 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #737 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 15:33:19.589636 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #737 | Collecting samples for evaluation
2017-07-02 15:33:25.268197 EDT | -----------------------  -------------
2017-07-02 15:33:25.268368 EDT | Epoch                     737
2017-07-02 15:33:25.268513 EDT | Iteration                 737
2017-07-02 15:33:25.268679 EDT | AverageReturn             689.467
2017-07-02 15:33:25.268859 EDT | StdReturn                 439.176
2017-07-02 15:33:25.269020 EDT | MaxReturn                1000
2017-07-02 15:33:25.269186 EDT | MinReturn                  64
2017-07-02 15:33:25.269290 EDT | AverageEsReturn            14.7164
2017-07-02 15:33:25.269564 EDT | StdEsReturn                15.6203
2017-07-02 15:33:25.269696 EDT | MaxEsReturn                88
2017-07-02 15:33:25.269805 EDT | MinEsReturn                 3
2017-07-02 15:33:25.269928 EDT | AverageDiscountedReturn    83.2017
2017-07-02 15:33:25.270108 EDT | AverageQLoss                0.00343629
2017-07-02 15:33:25.270213 EDT | AveragePolicySurr          -1.00863
2017-07-02 15:33:25.270413 EDT | AverageQ                    0.965087
2017-07-02 15:33:25.270742 EDT | AverageAbsQ                 0.967168
2017-07-02 15:33:25.270862 EDT | AverageY                    0.96499
2017-07-02 15:33:25.271059 EDT | AverageAbsY                 0.965136
2017-07-02 15:33:25.271315 EDT | AverageAbsQYDiff            0.0148569
2017-07-02 15:33:25.271463 EDT | AverageAction               0.0257402
2017-07-02 15:33:25.271633 EDT | PolicyRegParamNorm         65.8402
2017-07-02 15:33:25.271759 EDT | QFunRegParamNorm           64.3826
2017-07-02 15:33:25.271895 EDT | -----------------------  -------------
2017-07-02 15:33:25.272182 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #738 | Training started
2017-07-02 15:33:34.650394 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #738 | Training finished
2017-07-02 15:33:34.650914 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #738 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 15:33:34.651126 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #738 | Collecting samples for evaluation
2017-07-02 15:33:40.264847 EDT | -----------------------  -------------
2017-07-02 15:33:40.265055 EDT | Epoch                     738
2017-07-02 15:33:40.265214 EDT | Iteration                 738
2017-07-02 15:33:40.265346 EDT | AverageReturn            1000
2017-07-02 15:33:40.265553 EDT | StdReturn                   0
2017-07-02 15:33:40.265705 EDT | MaxReturn                1000
2017-07-02 15:33:40.265810 EDT | MinReturn                1000
2017-07-02 15:33:40.265923 EDT | AverageEsReturn            20.16
2017-07-02 15:33:40.266084 EDT | StdEsReturn                17.0884
2017-07-02 15:33:40.266189 EDT | MaxEsReturn                60
2017-07-02 15:33:40.266291 EDT | MinEsReturn                 3
2017-07-02 15:33:40.266392 EDT | AverageDiscountedReturn    99.9957
2017-07-02 15:33:40.266492 EDT | AverageQLoss                0.00347463
2017-07-02 15:33:40.266592 EDT | AveragePolicySurr          -1.00668
2017-07-02 15:33:40.266691 EDT | AverageQ                    0.961759
2017-07-02 15:33:40.266789 EDT | AverageAbsQ                 0.964322
2017-07-02 15:33:40.266887 EDT | AverageY                    0.961752
2017-07-02 15:33:40.266984 EDT | AverageAbsY                 0.96194
2017-07-02 15:33:40.267083 EDT | AverageAbsQYDiff            0.0140226
2017-07-02 15:33:40.267181 EDT | AverageAction               0.0929553
2017-07-02 15:33:40.267279 EDT | PolicyRegParamNorm         65.839
2017-07-02 15:33:40.267376 EDT | QFunRegParamNorm           64.4046
2017-07-02 15:33:40.267474 EDT | -----------------------  -------------
2017-07-02 15:33:40.267636 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #739 | Training started
2017-07-02 15:33:49.508053 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #739 | Training finished
2017-07-02 15:33:49.508351 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #739 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 15:33:49.508583 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #739 | Collecting samples for evaluation
2017-07-02 15:33:55.100924 EDT | -----------------------  -------------
2017-07-02 15:33:55.101517 EDT | Epoch                     739
2017-07-02 15:33:55.101651 EDT | Iteration                 739
2017-07-02 15:33:55.101851 EDT | AverageReturn            1000
2017-07-02 15:33:55.102053 EDT | StdReturn                   0
2017-07-02 15:33:55.102221 EDT | MaxReturn                1000
2017-07-02 15:33:55.102325 EDT | MinReturn                1000
2017-07-02 15:33:55.102453 EDT | AverageEsReturn            20.4167
2017-07-02 15:33:55.102571 EDT | StdEsReturn                22.9436
2017-07-02 15:33:55.102685 EDT | MaxEsReturn               127
2017-07-02 15:33:55.102877 EDT | MinEsReturn                 3
2017-07-02 15:33:55.103046 EDT | AverageDiscountedReturn    99.9957
2017-07-02 15:33:55.103172 EDT | AverageQLoss                0.00301738
2017-07-02 15:33:55.103341 EDT | AveragePolicySurr          -1.00672
2017-07-02 15:33:55.103456 EDT | AverageQ                    0.962174
2017-07-02 15:33:55.103619 EDT | AverageAbsQ                 0.96446
2017-07-02 15:33:55.103749 EDT | AverageY                    0.962151
2017-07-02 15:33:55.103899 EDT | AverageAbsY                 0.962316
2017-07-02 15:33:55.104003 EDT | AverageAbsQYDiff            0.0141656
2017-07-02 15:33:55.104351 EDT | AverageAction               0.385815
2017-07-02 15:33:55.104585 EDT | PolicyRegParamNorm         65.8483
2017-07-02 15:33:55.104801 EDT | QFunRegParamNorm           64.4497
2017-07-02 15:33:55.105032 EDT | -----------------------  -------------
2017-07-02 15:33:55.105328 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #740 | Training started
2017-07-02 15:34:04.328446 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #740 | Training finished
2017-07-02 15:34:04.328961 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #740 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 15:34:04.329281 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #740 | Collecting samples for evaluation
2017-07-02 15:34:09.873934 EDT | -----------------------  -------------
2017-07-02 15:34:09.874262 EDT | Epoch                     740
2017-07-02 15:34:09.874449 EDT | Iteration                 740
2017-07-02 15:34:09.874621 EDT | AverageReturn            1000
2017-07-02 15:34:09.874853 EDT | StdReturn                   0
2017-07-02 15:34:09.875028 EDT | MaxReturn                1000
2017-07-02 15:34:09.875255 EDT | MinReturn                1000
2017-07-02 15:34:09.875472 EDT | AverageEsReturn            22.2826
2017-07-02 15:34:09.875644 EDT | StdEsReturn                19.6786
2017-07-02 15:34:09.875872 EDT | MaxEsReturn                78
2017-07-02 15:34:09.876040 EDT | MinEsReturn                 3
2017-07-02 15:34:09.876259 EDT | AverageDiscountedReturn    99.9957
2017-07-02 15:34:09.876485 EDT | AverageQLoss                0.00391696
2017-07-02 15:34:09.876697 EDT | AveragePolicySurr          -1.00627
2017-07-02 15:34:09.876926 EDT | AverageQ                    0.962517
2017-07-02 15:34:09.877147 EDT | AverageAbsQ                 0.965428
2017-07-02 15:34:09.877360 EDT | AverageY                    0.962454
2017-07-02 15:34:09.877671 EDT | AverageAbsY                 0.96262
2017-07-02 15:34:09.877856 EDT | AverageAbsQYDiff            0.0161006
2017-07-02 15:34:09.878084 EDT | AverageAction               0.136478
2017-07-02 15:34:09.878251 EDT | PolicyRegParamNorm         65.8731
2017-07-02 15:34:09.878427 EDT | QFunRegParamNorm           64.4617
2017-07-02 15:34:09.878655 EDT | -----------------------  -------------
2017-07-02 15:34:09.878978 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #741 | Training started
2017-07-02 15:34:19.164713 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #741 | Training finished
2017-07-02 15:34:19.165323 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #741 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 15:34:19.165550 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #741 | Collecting samples for evaluation
2017-07-02 15:34:24.770319 EDT | -----------------------  ------------
2017-07-02 15:34:24.770599 EDT | Epoch                    741
2017-07-02 15:34:24.770785 EDT | Iteration                741
2017-07-02 15:34:24.770978 EDT | AverageReturn             85.2797
2017-07-02 15:34:24.771084 EDT | StdReturn                 32.6514
2017-07-02 15:34:24.771215 EDT | MaxReturn                195
2017-07-02 15:34:24.771338 EDT | MinReturn                 65
2017-07-02 15:34:24.771439 EDT | AverageEsReturn           29.1176
2017-07-02 15:34:24.771547 EDT | StdEsReturn               20.966
2017-07-02 15:34:24.771653 EDT | MaxEsReturn               83
2017-07-02 15:34:24.771777 EDT | MinEsReturn                4
2017-07-02 15:34:24.771896 EDT | AverageDiscountedReturn   55.7818
2017-07-02 15:34:24.771995 EDT | AverageQLoss               0.00286719
2017-07-02 15:34:24.772093 EDT | AveragePolicySurr         -1.00449
2017-07-02 15:34:24.772205 EDT | AverageQ                   0.959612
2017-07-02 15:34:24.772312 EDT | AverageAbsQ                0.961874
2017-07-02 15:34:24.772436 EDT | AverageY                   0.959601
2017-07-02 15:34:24.772543 EDT | AverageAbsY                0.959745
2017-07-02 15:34:24.772674 EDT | AverageAbsQYDiff           0.0134662
2017-07-02 15:34:24.772775 EDT | AverageAction              0.362797
2017-07-02 15:34:24.772885 EDT | PolicyRegParamNorm        65.9204
2017-07-02 15:34:24.772990 EDT | QFunRegParamNorm          64.4943
2017-07-02 15:34:24.773108 EDT | -----------------------  ------------
2017-07-02 15:34:24.773266 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #742 | Training started
2017-07-02 15:34:34.240371 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #742 | Training finished
2017-07-02 15:34:34.241251 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #742 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 15:34:34.241416 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #742 | Collecting samples for evaluation
2017-07-02 15:34:39.916088 EDT | -----------------------  -------------
2017-07-02 15:34:39.916400 EDT | Epoch                     742
2017-07-02 15:34:39.916550 EDT | Iteration                 742
2017-07-02 15:34:39.916679 EDT | AverageReturn             417.042
2017-07-02 15:34:39.916806 EDT | StdReturn                 253.396
2017-07-02 15:34:39.916926 EDT | MaxReturn                1000
2017-07-02 15:34:39.917047 EDT | MinReturn                 159
2017-07-02 15:34:39.917269 EDT | AverageEsReturn            23.619
2017-07-02 15:34:39.917466 EDT | StdEsReturn                17.0391
2017-07-02 15:34:39.917709 EDT | MaxEsReturn                63
2017-07-02 15:34:39.917901 EDT | MinEsReturn                 4
2017-07-02 15:34:39.918131 EDT | AverageDiscountedReturn    93.0245
2017-07-02 15:34:39.918356 EDT | AverageQLoss                0.00301133
2017-07-02 15:34:39.918576 EDT | AveragePolicySurr          -1.0031
2017-07-02 15:34:39.918751 EDT | AverageQ                    0.958862
2017-07-02 15:34:39.918975 EDT | AverageAbsQ                 0.961688
2017-07-02 15:34:39.919189 EDT | AverageY                    0.958892
2017-07-02 15:34:39.919422 EDT | AverageAbsY                 0.959135
2017-07-02 15:34:39.919656 EDT | AverageAbsQYDiff            0.014715
2017-07-02 15:34:39.919888 EDT | AverageAction               0.285038
2017-07-02 15:34:39.920041 EDT | PolicyRegParamNorm         65.9208
2017-07-02 15:34:39.920144 EDT | QFunRegParamNorm           64.5243
2017-07-02 15:34:39.920244 EDT | -----------------------  -------------
2017-07-02 15:34:39.920470 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #743 | Training started
2017-07-02 15:34:49.339065 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #743 | Training finished
2017-07-02 15:34:49.339624 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #743 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 15:34:49.339763 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #743 | Collecting samples for evaluation
2017-07-02 15:34:54.839402 EDT | -----------------------  -----------
2017-07-02 15:34:54.839601 EDT | Epoch                    743
2017-07-02 15:34:54.839753 EDT | Iteration                743
2017-07-02 15:34:54.839899 EDT | AverageReturn            241.571
2017-07-02 15:34:54.840033 EDT | StdReturn                 85.9494
2017-07-02 15:34:54.840185 EDT | MaxReturn                487
2017-07-02 15:34:54.840313 EDT | MinReturn                163
2017-07-02 15:34:54.840431 EDT | AverageEsReturn           35.5185
2017-07-02 15:34:54.840566 EDT | StdEsReturn               21.5636
2017-07-02 15:34:54.840736 EDT | MaxEsReturn              100
2017-07-02 15:34:54.840887 EDT | MinEsReturn                5
2017-07-02 15:34:54.841052 EDT | AverageDiscountedReturn   88.468
2017-07-02 15:34:54.841176 EDT | AverageQLoss               0.0032984
2017-07-02 15:34:54.841302 EDT | AveragePolicySurr         -1.00254
2017-07-02 15:34:54.841525 EDT | AverageQ                   0.957372
2017-07-02 15:34:54.841756 EDT | AverageAbsQ                0.959921
2017-07-02 15:34:54.841970 EDT | AverageY                   0.957393
2017-07-02 15:34:54.842080 EDT | AverageAbsY                0.957536
2017-07-02 15:34:54.842191 EDT | AverageAbsQYDiff           0.0151138
2017-07-02 15:34:54.842297 EDT | AverageAction              0.246958
2017-07-02 15:34:54.842425 EDT | PolicyRegParamNorm        65.9528
2017-07-02 15:34:54.842525 EDT | QFunRegParamNorm          64.5491
2017-07-02 15:34:54.842624 EDT | -----------------------  -----------
2017-07-02 15:34:54.842784 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #744 | Training started
2017-07-02 15:35:04.294411 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #744 | Training finished
2017-07-02 15:35:04.294926 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #744 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 15:35:04.295134 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #744 | Collecting samples for evaluation
2017-07-02 15:35:09.673398 EDT | -----------------------  -------------
2017-07-02 15:35:09.673702 EDT | Epoch                     744
2017-07-02 15:35:09.673939 EDT | Iteration                 744
2017-07-02 15:35:09.674158 EDT | AverageReturn            1000
2017-07-02 15:35:09.674388 EDT | StdReturn                   0
2017-07-02 15:35:09.674617 EDT | MaxReturn                1000
2017-07-02 15:35:09.674822 EDT | MinReturn                1000
2017-07-02 15:35:09.675383 EDT | AverageEsReturn            28.4324
2017-07-02 15:35:09.675613 EDT | StdEsReturn                22.6913
2017-07-02 15:35:09.675844 EDT | MaxEsReturn                94
2017-07-02 15:35:09.676002 EDT | MinEsReturn                 3
2017-07-02 15:35:09.676180 EDT | AverageDiscountedReturn    99.9957
2017-07-02 15:35:09.676411 EDT | AverageQLoss                0.00383174
2017-07-02 15:35:09.676592 EDT | AveragePolicySurr          -0.999805
2017-07-02 15:35:09.676700 EDT | AverageQ                    0.95686
2017-07-02 15:35:09.676923 EDT | AverageAbsQ                 0.959552
2017-07-02 15:35:09.677152 EDT | AverageY                    0.956698
2017-07-02 15:35:09.677332 EDT | AverageAbsY                 0.956873
2017-07-02 15:35:09.677571 EDT | AverageAbsQYDiff            0.0161539
2017-07-02 15:35:09.677784 EDT | AverageAction               0.0112622
2017-07-02 15:35:09.678013 EDT | PolicyRegParamNorm         65.9831
2017-07-02 15:35:09.678249 EDT | QFunRegParamNorm           64.5456
2017-07-02 15:35:09.678392 EDT | -----------------------  -------------
2017-07-02 15:35:09.678733 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #745 | Training started
2017-07-02 15:35:19.367175 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #745 | Training finished
2017-07-02 15:35:19.367723 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #745 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 15:35:19.367973 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #745 | Collecting samples for evaluation
2017-07-02 15:35:25.640759 EDT | -----------------------  -------------
2017-07-02 15:35:25.641008 EDT | Epoch                     745
2017-07-02 15:35:25.641119 EDT | Iteration                 745
2017-07-02 15:35:25.641248 EDT | AverageReturn             378.31
2017-07-02 15:35:25.641447 EDT | StdReturn                 259.125
2017-07-02 15:35:25.641646 EDT | MaxReturn                1000
2017-07-02 15:35:25.641840 EDT | MinReturn                 203
2017-07-02 15:35:25.642005 EDT | AverageEsReturn            34.7241
2017-07-02 15:35:25.642135 EDT | StdEsReturn                25.1312
2017-07-02 15:35:25.642240 EDT | MaxEsReturn                89
2017-07-02 15:35:25.642358 EDT | MinEsReturn                 4
2017-07-02 15:35:25.642496 EDT | AverageDiscountedReturn    92.5638
2017-07-02 15:35:25.642603 EDT | AverageQLoss                0.00287588
2017-07-02 15:35:25.642726 EDT | AveragePolicySurr          -0.998593
2017-07-02 15:35:25.642826 EDT | AverageQ                    0.954931
2017-07-02 15:35:25.642971 EDT | AverageAbsQ                 0.957446
2017-07-02 15:35:25.643095 EDT | AverageY                    0.955028
2017-07-02 15:35:25.643201 EDT | AverageAbsY                 0.955138
2017-07-02 15:35:25.643368 EDT | AverageAbsQYDiff            0.0139612
2017-07-02 15:35:25.643477 EDT | AverageAction               0.354998
2017-07-02 15:35:25.643599 EDT | PolicyRegParamNorm         66.0356
2017-07-02 15:35:25.643738 EDT | QFunRegParamNorm           64.5599
2017-07-02 15:35:25.643840 EDT | -----------------------  -------------
2017-07-02 15:35:25.644026 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #746 | Training started
2017-07-02 15:35:35.052290 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #746 | Training finished
2017-07-02 15:35:35.052939 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #746 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 15:35:35.053201 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #746 | Collecting samples for evaluation
2017-07-02 15:35:40.425218 EDT | -----------------------  -------------
2017-07-02 15:35:40.425555 EDT | Epoch                     746
2017-07-02 15:35:40.425774 EDT | Iteration                 746
2017-07-02 15:35:40.426002 EDT | AverageReturn            1000
2017-07-02 15:35:40.426308 EDT | StdReturn                   0
2017-07-02 15:35:40.426614 EDT | MaxReturn                1000
2017-07-02 15:35:40.426861 EDT | MinReturn                1000
2017-07-02 15:35:40.427081 EDT | AverageEsReturn            46
2017-07-02 15:35:40.427326 EDT | StdEsReturn                34.1412
2017-07-02 15:35:40.427503 EDT | MaxEsReturn               148
2017-07-02 15:35:40.427728 EDT | MinEsReturn                 3
2017-07-02 15:35:40.427948 EDT | AverageDiscountedReturn    99.9957
2017-07-02 15:35:40.428185 EDT | AverageQLoss                0.00303292
2017-07-02 15:35:40.428325 EDT | AveragePolicySurr          -0.997846
2017-07-02 15:35:40.428555 EDT | AverageQ                    0.953769
2017-07-02 15:35:40.428762 EDT | AverageAbsQ                 0.956495
2017-07-02 15:35:40.428996 EDT | AverageY                    0.953858
2017-07-02 15:35:40.429200 EDT | AverageAbsY                 0.953993
2017-07-02 15:35:40.429430 EDT | AverageAbsQYDiff            0.0143556
2017-07-02 15:35:40.429650 EDT | AverageAction               0.860578
2017-07-02 15:35:40.429866 EDT | PolicyRegParamNorm         66.0574
2017-07-02 15:35:40.430105 EDT | QFunRegParamNorm           64.5669
2017-07-02 15:35:40.430296 EDT | -----------------------  -------------
2017-07-02 15:35:40.430518 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #747 | Training started
2017-07-02 15:35:49.900552 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #747 | Training finished
2017-07-02 15:35:49.901233 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #747 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 15:35:49.901379 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #747 | Collecting samples for evaluation
2017-07-02 15:35:55.290976 EDT | -----------------------  -------------
2017-07-02 15:35:55.291192 EDT | Epoch                     747
2017-07-02 15:35:55.291307 EDT | Iteration                 747
2017-07-02 15:35:55.291422 EDT | AverageReturn            1000
2017-07-02 15:35:55.291590 EDT | StdReturn                   0
2017-07-02 15:35:55.291703 EDT | MaxReturn                1000
2017-07-02 15:35:55.291877 EDT | MinReturn                1000
2017-07-02 15:35:55.292034 EDT | AverageEsReturn            39.5385
2017-07-02 15:35:55.292211 EDT | StdEsReturn                34.3066
2017-07-02 15:35:55.292321 EDT | MaxEsReturn               170
2017-07-02 15:35:55.292432 EDT | MinEsReturn                 7
2017-07-02 15:35:55.292566 EDT | AverageDiscountedReturn    99.9957
2017-07-02 15:35:55.292666 EDT | AverageQLoss                0.00319711
2017-07-02 15:35:55.292782 EDT | AveragePolicySurr          -0.998794
2017-07-02 15:35:55.292890 EDT | AverageQ                    0.955706
2017-07-02 15:35:55.292991 EDT | AverageAbsQ                 0.958286
2017-07-02 15:35:55.293149 EDT | AverageY                    0.955717
2017-07-02 15:35:55.293376 EDT | AverageAbsY                 0.955884
2017-07-02 15:35:55.293676 EDT | AverageAbsQYDiff            0.0145141
2017-07-02 15:35:55.293911 EDT | AverageAction               0.319417
2017-07-02 15:35:55.294140 EDT | PolicyRegParamNorm         66.1008
2017-07-02 15:35:55.294317 EDT | QFunRegParamNorm           64.5741
2017-07-02 15:35:55.294421 EDT | -----------------------  -------------
2017-07-02 15:35:55.294581 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #748 | Training started
2017-07-02 15:36:04.737815 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #748 | Training finished
2017-07-02 15:36:04.738893 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #748 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 15:36:04.739098 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #748 | Collecting samples for evaluation
2017-07-02 15:36:10.203172 EDT | -----------------------  -------------
2017-07-02 15:36:10.203484 EDT | Epoch                     748
2017-07-02 15:36:10.203700 EDT | Iteration                 748
2017-07-02 15:36:10.203921 EDT | AverageReturn            1000
2017-07-02 15:36:10.204149 EDT | StdReturn                   0
2017-07-02 15:36:10.204308 EDT | MaxReturn                1000
2017-07-02 15:36:10.204524 EDT | MinReturn                1000
2017-07-02 15:36:10.204727 EDT | AverageEsReturn            35.8148
2017-07-02 15:36:10.204952 EDT | StdEsReturn                25.6992
2017-07-02 15:36:10.205171 EDT | MaxEsReturn                93
2017-07-02 15:36:10.205285 EDT | MinEsReturn                 3
2017-07-02 15:36:10.205459 EDT | AverageDiscountedReturn    99.9957
2017-07-02 15:36:10.205753 EDT | AverageQLoss                0.00357877
2017-07-02 15:36:10.205936 EDT | AveragePolicySurr          -0.997219
2017-07-02 15:36:10.206046 EDT | AverageQ                    0.953013
2017-07-02 15:36:10.206268 EDT | AverageAbsQ                 0.955906
2017-07-02 15:36:10.206477 EDT | AverageY                    0.952905
2017-07-02 15:36:10.206704 EDT | AverageAbsY                 0.953061
2017-07-02 15:36:10.206918 EDT | AverageAbsQYDiff            0.0149662
2017-07-02 15:36:10.207141 EDT | AverageAction               0.312407
2017-07-02 15:36:10.207348 EDT | PolicyRegParamNorm         66.1758
2017-07-02 15:36:10.207568 EDT | QFunRegParamNorm           64.5645
2017-07-02 15:36:10.207787 EDT | -----------------------  -------------
2017-07-02 15:36:10.208061 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #749 | Training started
2017-07-02 15:36:19.585909 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #749 | Training finished
2017-07-02 15:36:19.586403 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #749 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 15:36:19.586610 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #749 | Collecting samples for evaluation
2017-07-02 15:36:25.116049 EDT | -----------------------  -------------
2017-07-02 15:36:25.116346 EDT | Epoch                     749
2017-07-02 15:36:25.116573 EDT | Iteration                 749
2017-07-02 15:36:25.116765 EDT | AverageReturn            1000
2017-07-02 15:36:25.116961 EDT | StdReturn                   0
2017-07-02 15:36:25.117179 EDT | MaxReturn                1000
2017-07-02 15:36:25.117403 EDT | MinReturn                1000
2017-07-02 15:36:25.117638 EDT | AverageEsReturn            36.0714
2017-07-02 15:36:25.117868 EDT | StdEsReturn                28.4629
2017-07-02 15:36:25.118092 EDT | MaxEsReturn               134
2017-07-02 15:36:25.118314 EDT | MinEsReturn                 4
2017-07-02 15:36:25.118526 EDT | AverageDiscountedReturn    99.9957
2017-07-02 15:36:25.118684 EDT | AverageQLoss                0.00324688
2017-07-02 15:36:25.118904 EDT | AveragePolicySurr          -0.993551
2017-07-02 15:36:25.119098 EDT | AverageQ                    0.95067
2017-07-02 15:36:25.119326 EDT | AverageAbsQ                 0.953183
2017-07-02 15:36:25.119546 EDT | AverageY                    0.950772
2017-07-02 15:36:25.119765 EDT | AverageAbsY                 0.95095
2017-07-02 15:36:25.119970 EDT | AverageAbsQYDiff            0.0144328
2017-07-02 15:36:25.120193 EDT | AverageAction               0.328949
2017-07-02 15:36:25.120386 EDT | PolicyRegParamNorm         66.2246
2017-07-02 15:36:25.120605 EDT | QFunRegParamNorm           64.5946
2017-07-02 15:36:25.120821 EDT | -----------------------  -------------
2017-07-02 15:36:25.121100 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #750 | Training started
2017-07-02 15:36:34.496722 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #750 | Training finished
2017-07-02 15:36:34.497499 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #750 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 15:36:34.497736 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #750 | Collecting samples for evaluation
2017-07-02 15:36:40.197534 EDT | -----------------------  ------------
2017-07-02 15:36:40.197788 EDT | Epoch                    750
2017-07-02 15:36:40.197929 EDT | Iteration                750
2017-07-02 15:36:40.198065 EDT | AverageReturn             54.1946
2017-07-02 15:36:40.198193 EDT | StdReturn                  1.073
2017-07-02 15:36:40.198346 EDT | MaxReturn                 60
2017-07-02 15:36:40.198613 EDT | MinReturn                 53
2017-07-02 15:36:40.198798 EDT | AverageEsReturn           48.3333
2017-07-02 15:36:40.198915 EDT | StdEsReturn               42.0015
2017-07-02 15:36:40.199078 EDT | MaxEsReturn              149
2017-07-02 15:36:40.199187 EDT | MinEsReturn                3
2017-07-02 15:36:40.199306 EDT | AverageDiscountedReturn   41.9936
2017-07-02 15:36:40.199443 EDT | AverageQLoss               0.00361548
2017-07-02 15:36:40.199691 EDT | AveragePolicySurr         -0.995528
2017-07-02 15:36:40.199929 EDT | AverageQ                   0.950973
2017-07-02 15:36:40.200112 EDT | AverageAbsQ                0.954115
2017-07-02 15:36:40.200342 EDT | AverageY                   0.950893
2017-07-02 15:36:40.200570 EDT | AverageAbsY                0.951019
2017-07-02 15:36:40.200791 EDT | AverageAbsQYDiff           0.0156619
2017-07-02 15:36:40.201019 EDT | AverageAction              0.186294
2017-07-02 15:36:40.201212 EDT | PolicyRegParamNorm        66.2241
2017-07-02 15:36:40.201320 EDT | QFunRegParamNorm          64.6039
2017-07-02 15:36:40.201423 EDT | -----------------------  ------------
2017-07-02 15:36:40.201661 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #751 | Training started
2017-07-02 15:36:49.511079 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #751 | Training finished
2017-07-02 15:36:49.511689 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #751 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 15:36:49.511965 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #751 | Collecting samples for evaluation
2017-07-02 15:36:55.001298 EDT | -----------------------  -------------
2017-07-02 15:36:55.001612 EDT | Epoch                     751
2017-07-02 15:36:55.001840 EDT | Iteration                 751
2017-07-02 15:36:55.002040 EDT | AverageReturn            1000
2017-07-02 15:36:55.002210 EDT | StdReturn                   0
2017-07-02 15:36:55.002393 EDT | MaxReturn                1000
2017-07-02 15:36:55.002589 EDT | MinReturn                1000
2017-07-02 15:36:55.002783 EDT | AverageEsReturn            30.1562
2017-07-02 15:36:55.002976 EDT | StdEsReturn                25.1758
2017-07-02 15:36:55.003193 EDT | MaxEsReturn               124
2017-07-02 15:36:55.003414 EDT | MinEsReturn                 6
2017-07-02 15:36:55.003632 EDT | AverageDiscountedReturn    99.9957
2017-07-02 15:36:55.003844 EDT | AverageQLoss                0.00300018
2017-07-02 15:36:55.004030 EDT | AveragePolicySurr          -0.994401
2017-07-02 15:36:55.004247 EDT | AverageQ                    0.949723
2017-07-02 15:36:55.004453 EDT | AverageAbsQ                 0.951824
2017-07-02 15:36:55.004613 EDT | AverageY                    0.949794
2017-07-02 15:36:55.004785 EDT | AverageAbsY                 0.949942
2017-07-02 15:36:55.004889 EDT | AverageAbsQYDiff            0.0137185
2017-07-02 15:36:55.005030 EDT | AverageAction               0.207211
2017-07-02 15:36:55.005245 EDT | PolicyRegParamNorm         66.2542
2017-07-02 15:36:55.005460 EDT | QFunRegParamNorm           64.6186
2017-07-02 15:36:55.005733 EDT | -----------------------  -------------
2017-07-02 15:36:55.006043 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #752 | Training started
2017-07-02 15:37:04.393968 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #752 | Training finished
2017-07-02 15:37:04.394518 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #752 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 15:37:04.394720 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #752 | Collecting samples for evaluation
2017-07-02 15:37:09.842298 EDT | -----------------------  -------------
2017-07-02 15:37:09.842507 EDT | Epoch                     752
2017-07-02 15:37:09.842662 EDT | Iteration                 752
2017-07-02 15:37:09.842772 EDT | AverageReturn             594.647
2017-07-02 15:37:09.842875 EDT | StdReturn                 327.588
2017-07-02 15:37:09.842975 EDT | MaxReturn                1000
2017-07-02 15:37:09.843080 EDT | MinReturn                 171
2017-07-02 15:37:09.843180 EDT | AverageEsReturn            34.7667
2017-07-02 15:37:09.843279 EDT | StdEsReturn                22.8789
2017-07-02 15:37:09.843376 EDT | MaxEsReturn                84
2017-07-02 15:37:09.843511 EDT | MinEsReturn                 7
2017-07-02 15:37:09.843655 EDT | AverageDiscountedReturn    96.2013
2017-07-02 15:37:09.843779 EDT | AverageQLoss                0.00356358
2017-07-02 15:37:09.843902 EDT | AveragePolicySurr          -0.993239
2017-07-02 15:37:09.844004 EDT | AverageQ                    0.94835
2017-07-02 15:37:09.844103 EDT | AverageAbsQ                 0.951227
2017-07-02 15:37:09.844287 EDT | AverageY                    0.948355
2017-07-02 15:37:09.844439 EDT | AverageAbsY                 0.948482
2017-07-02 15:37:09.844609 EDT | AverageAbsQYDiff            0.0158558
2017-07-02 15:37:09.844711 EDT | AverageAction               0.197147
2017-07-02 15:37:09.844901 EDT | PolicyRegParamNorm         66.3005
2017-07-02 15:37:09.845082 EDT | QFunRegParamNorm           64.6539
2017-07-02 15:37:09.845240 EDT | -----------------------  -------------
2017-07-02 15:37:09.845411 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #753 | Training started
2017-07-02 15:37:19.273022 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #753 | Training finished
2017-07-02 15:37:19.273764 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #753 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 15:37:19.273911 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #753 | Collecting samples for evaluation
2017-07-02 15:37:24.674504 EDT | -----------------------  -------------
2017-07-02 15:37:24.674783 EDT | Epoch                     753
2017-07-02 15:37:24.674899 EDT | Iteration                 753
2017-07-02 15:37:24.675004 EDT | AverageReturn            1000
2017-07-02 15:37:24.675107 EDT | StdReturn                   0
2017-07-02 15:37:24.675207 EDT | MaxReturn                1000
2017-07-02 15:37:24.675373 EDT | MinReturn                1000
2017-07-02 15:37:24.675477 EDT | AverageEsReturn            32.2581
2017-07-02 15:37:24.675593 EDT | StdEsReturn                23.2864
2017-07-02 15:37:24.675739 EDT | MaxEsReturn                77
2017-07-02 15:37:24.675841 EDT | MinEsReturn                 3
2017-07-02 15:37:24.675940 EDT | AverageDiscountedReturn    99.9957
2017-07-02 15:37:24.676085 EDT | AverageQLoss                0.00312885
2017-07-02 15:37:24.676224 EDT | AveragePolicySurr          -0.990354
2017-07-02 15:37:24.676325 EDT | AverageQ                    0.944785
2017-07-02 15:37:24.676424 EDT | AverageAbsQ                 0.946949
2017-07-02 15:37:24.676522 EDT | AverageY                    0.944782
2017-07-02 15:37:24.676621 EDT | AverageAbsY                 0.944877
2017-07-02 15:37:24.676719 EDT | AverageAbsQYDiff            0.0140971
2017-07-02 15:37:24.676823 EDT | AverageAction               0.0388515
2017-07-02 15:37:24.676922 EDT | PolicyRegParamNorm         66.3385
2017-07-02 15:37:24.677076 EDT | QFunRegParamNorm           64.6857
2017-07-02 15:37:24.677214 EDT | -----------------------  -------------
2017-07-02 15:37:24.677381 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #754 | Training started
2017-07-02 15:37:34.036242 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #754 | Training finished
2017-07-02 15:37:34.036758 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #754 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 15:37:34.036920 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #754 | Collecting samples for evaluation
2017-07-02 15:37:39.968743 EDT | -----------------------  -------------
2017-07-02 15:37:39.968982 EDT | Epoch                     754
2017-07-02 15:37:39.969097 EDT | Iteration                 754
2017-07-02 15:37:39.969210 EDT | AverageReturn             833.154
2017-07-02 15:37:39.969410 EDT | StdReturn                 235.78
2017-07-02 15:37:39.969638 EDT | MaxReturn                1000
2017-07-02 15:37:39.969760 EDT | MinReturn                 287
2017-07-02 15:37:39.969863 EDT | AverageEsReturn            25.6667
2017-07-02 15:37:39.969964 EDT | StdEsReturn                13.7791
2017-07-02 15:37:39.970109 EDT | MaxEsReturn                60
2017-07-02 15:37:39.970224 EDT | MinEsReturn                 4
2017-07-02 15:37:39.970325 EDT | AverageDiscountedReturn    99.4756
2017-07-02 15:37:39.970424 EDT | AverageQLoss                0.00329444
2017-07-02 15:37:39.970536 EDT | AveragePolicySurr          -0.990462
2017-07-02 15:37:39.970643 EDT | AverageQ                    0.947444
2017-07-02 15:37:39.970780 EDT | AverageAbsQ                 0.950114
2017-07-02 15:37:39.970885 EDT | AverageY                    0.947402
2017-07-02 15:37:39.970987 EDT | AverageAbsY                 0.947532
2017-07-02 15:37:39.971112 EDT | AverageAbsQYDiff            0.0148246
2017-07-02 15:37:39.971212 EDT | AverageAction               0.376935
2017-07-02 15:37:39.971347 EDT | PolicyRegParamNorm         66.356
2017-07-02 15:37:39.971542 EDT | QFunRegParamNorm           64.7084
2017-07-02 15:37:39.971735 EDT | -----------------------  -------------
2017-07-02 15:37:39.971925 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #755 | Training started
2017-07-02 15:37:49.210274 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #755 | Training finished
2017-07-02 15:37:49.210804 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #755 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 15:37:49.211072 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #755 | Collecting samples for evaluation
2017-07-02 15:37:54.800876 EDT | -----------------------  -------------
2017-07-02 15:37:54.801121 EDT | Epoch                     755
2017-07-02 15:37:54.801234 EDT | Iteration                 755
2017-07-02 15:37:54.801339 EDT | AverageReturn            1000
2017-07-02 15:37:54.801473 EDT | StdReturn                   0
2017-07-02 15:37:54.801603 EDT | MaxReturn                1000
2017-07-02 15:37:54.801704 EDT | MinReturn                1000
2017-07-02 15:37:54.801810 EDT | AverageEsReturn            22.1628
2017-07-02 15:37:54.801997 EDT | StdEsReturn                16.8494
2017-07-02 15:37:54.802102 EDT | MaxEsReturn                70
2017-07-02 15:37:54.802220 EDT | MinEsReturn                 3
2017-07-02 15:37:54.802321 EDT | AverageDiscountedReturn    99.9957
2017-07-02 15:37:54.802435 EDT | AverageQLoss                0.00340531
2017-07-02 15:37:54.802549 EDT | AveragePolicySurr          -0.989575
2017-07-02 15:37:54.802649 EDT | AverageQ                    0.946762
2017-07-02 15:37:54.802753 EDT | AverageAbsQ                 0.949625
2017-07-02 15:37:54.802853 EDT | AverageY                    0.94674
2017-07-02 15:37:54.803011 EDT | AverageAbsY                 0.946906
2017-07-02 15:37:54.803137 EDT | AverageAbsQYDiff            0.0154458
2017-07-02 15:37:54.803238 EDT | AverageAction               0.0963669
2017-07-02 15:37:54.803337 EDT | PolicyRegParamNorm         66.3736
2017-07-02 15:37:54.803529 EDT | QFunRegParamNorm           64.7164
2017-07-02 15:37:54.803637 EDT | -----------------------  -------------
2017-07-02 15:37:54.803798 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #756 | Training started
2017-07-02 15:38:04.053929 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #756 | Training finished
2017-07-02 15:38:04.054534 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #756 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 15:38:04.054841 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #756 | Collecting samples for evaluation
2017-07-02 15:38:09.551681 EDT | -----------------------  -------------
2017-07-02 15:38:09.551871 EDT | Epoch                     756
2017-07-02 15:38:09.551982 EDT | Iteration                 756
2017-07-02 15:38:09.552086 EDT | AverageReturn            1000
2017-07-02 15:38:09.552245 EDT | StdReturn                   0
2017-07-02 15:38:09.552467 EDT | MaxReturn                1000
2017-07-02 15:38:09.552668 EDT | MinReturn                1000
2017-07-02 15:38:09.552836 EDT | AverageEsReturn            24.8333
2017-07-02 15:38:09.553068 EDT | StdEsReturn                22.0269
2017-07-02 15:38:09.553284 EDT | MaxEsReturn               113
2017-07-02 15:38:09.553518 EDT | MinEsReturn                 3
2017-07-02 15:38:09.553736 EDT | AverageDiscountedReturn    99.9957
2017-07-02 15:38:09.553938 EDT | AverageQLoss                0.00336282
2017-07-02 15:38:09.554154 EDT | AveragePolicySurr          -0.989321
2017-07-02 15:38:09.554373 EDT | AverageQ                    0.946222
2017-07-02 15:38:09.554560 EDT | AverageAbsQ                 0.948767
2017-07-02 15:38:09.554788 EDT | AverageY                    0.946263
2017-07-02 15:38:09.555005 EDT | AverageAbsY                 0.946525
2017-07-02 15:38:09.555223 EDT | AverageAbsQYDiff            0.0145663
2017-07-02 15:38:09.555437 EDT | AverageAction               0.267893
2017-07-02 15:38:09.555636 EDT | PolicyRegParamNorm         66.3681
2017-07-02 15:38:09.555849 EDT | QFunRegParamNorm           64.747
2017-07-02 15:38:09.556024 EDT | -----------------------  -------------
2017-07-02 15:38:09.556196 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #757 | Training started
2017-07-02 15:38:18.818911 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #757 | Training finished
2017-07-02 15:38:18.819513 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #757 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 15:38:18.819769 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #757 | Collecting samples for evaluation
2017-07-02 15:38:24.473550 EDT | -----------------------  ------------
2017-07-02 15:38:24.473861 EDT | Epoch                    757
2017-07-02 15:38:24.474085 EDT | Iteration                757
2017-07-02 15:38:24.474303 EDT | AverageReturn             57.1829
2017-07-02 15:38:24.474506 EDT | StdReturn                  2.58142
2017-07-02 15:38:24.474706 EDT | MaxReturn                 63
2017-07-02 15:38:24.474937 EDT | MinReturn                 51
2017-07-02 15:38:24.475154 EDT | AverageEsReturn           31.5625
2017-07-02 15:38:24.475374 EDT | StdEsReturn               25.588
2017-07-02 15:38:24.475585 EDT | MaxEsReturn               96
2017-07-02 15:38:24.475794 EDT | MinEsReturn                4
2017-07-02 15:38:24.476010 EDT | AverageDiscountedReturn   43.694
2017-07-02 15:38:24.476225 EDT | AverageQLoss               0.00288587
2017-07-02 15:38:24.476416 EDT | AveragePolicySurr         -0.986887
2017-07-02 15:38:24.476646 EDT | AverageQ                   0.943641
2017-07-02 15:38:24.476863 EDT | AverageAbsQ                0.945969
2017-07-02 15:38:24.477079 EDT | AverageY                   0.9437
2017-07-02 15:38:24.477290 EDT | AverageAbsY                0.94384
2017-07-02 15:38:24.477459 EDT | AverageAbsQYDiff           0.0141841
2017-07-02 15:38:24.477746 EDT | AverageAction              0.326585
2017-07-02 15:38:24.477959 EDT | PolicyRegParamNorm        66.3846
2017-07-02 15:38:24.478185 EDT | QFunRegParamNorm          64.7973
2017-07-02 15:38:24.478403 EDT | -----------------------  ------------
2017-07-02 15:38:24.478694 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #758 | Training started
2017-07-02 15:38:33.913621 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #758 | Training finished
2017-07-02 15:38:33.914237 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #758 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 15:38:33.914464 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #758 | Collecting samples for evaluation
2017-07-02 15:38:39.473654 EDT | -----------------------  -----------
2017-07-02 15:38:39.473846 EDT | Epoch                    758
2017-07-02 15:38:39.474000 EDT | Iteration                758
2017-07-02 15:38:39.474156 EDT | AverageReturn             45.4027
2017-07-02 15:38:39.474283 EDT | StdReturn                  0.99127
2017-07-02 15:38:39.474394 EDT | MaxReturn                 48
2017-07-02 15:38:39.474501 EDT | MinReturn                 43
2017-07-02 15:38:39.474701 EDT | AverageEsReturn           21.2128
2017-07-02 15:38:39.474923 EDT | StdEsReturn               22.648
2017-07-02 15:38:39.475117 EDT | MaxEsReturn               98
2017-07-02 15:38:39.475361 EDT | MinEsReturn                3
2017-07-02 15:38:39.475588 EDT | AverageDiscountedReturn   36.6353
2017-07-02 15:38:39.475809 EDT | AverageQLoss               0.003008
2017-07-02 15:38:39.476003 EDT | AveragePolicySurr         -0.987141
2017-07-02 15:38:39.476226 EDT | AverageQ                   0.943809
2017-07-02 15:38:39.476419 EDT | AverageAbsQ                0.946254
2017-07-02 15:38:39.476653 EDT | AverageY                   0.943787
2017-07-02 15:38:39.476933 EDT | AverageAbsY                0.943996
2017-07-02 15:38:39.477154 EDT | AverageAbsQYDiff           0.0137863
2017-07-02 15:38:39.477349 EDT | AverageAction              0.634275
2017-07-02 15:38:39.477580 EDT | PolicyRegParamNorm        66.4301
2017-07-02 15:38:39.477750 EDT | QFunRegParamNorm          64.8314
2017-07-02 15:38:39.477969 EDT | -----------------------  -----------
2017-07-02 15:38:39.478274 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #759 | Training started
2017-07-02 15:38:48.889651 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #759 | Training finished
2017-07-02 15:38:48.890339 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #759 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 15:38:48.890576 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #759 | Collecting samples for evaluation
2017-07-02 15:38:54.335016 EDT | -----------------------  -------------
2017-07-02 15:38:54.335514 EDT | Epoch                     759
2017-07-02 15:38:54.335758 EDT | Iteration                 759
2017-07-02 15:38:54.335916 EDT | AverageReturn            1000
2017-07-02 15:38:54.336149 EDT | StdReturn                   0
2017-07-02 15:38:54.336382 EDT | MaxReturn                1000
2017-07-02 15:38:54.336598 EDT | MinReturn                1000
2017-07-02 15:38:54.336819 EDT | AverageEsReturn            18.717
2017-07-02 15:38:54.337049 EDT | StdEsReturn                21.6066
2017-07-02 15:38:54.337416 EDT | MaxEsReturn               118
2017-07-02 15:38:54.337856 EDT | MinEsReturn                 3
2017-07-02 15:38:54.338292 EDT | AverageDiscountedReturn    99.9957
2017-07-02 15:38:54.338535 EDT | AverageQLoss                0.00358204
2017-07-02 15:38:54.338749 EDT | AveragePolicySurr          -0.984574
2017-07-02 15:38:54.338980 EDT | AverageQ                    0.942646
2017-07-02 15:38:54.339190 EDT | AverageAbsQ                 0.945662
2017-07-02 15:38:54.339421 EDT | AverageY                    0.94262
2017-07-02 15:38:54.339634 EDT | AverageAbsY                 0.942831
2017-07-02 15:38:54.339857 EDT | AverageAbsQYDiff            0.0157967
2017-07-02 15:38:54.340082 EDT | AverageAction               0.210283
2017-07-02 15:38:54.340279 EDT | PolicyRegParamNorm         66.4578
2017-07-02 15:38:54.340509 EDT | QFunRegParamNorm           64.85
2017-07-02 15:38:54.340689 EDT | -----------------------  -------------
2017-07-02 15:38:54.341114 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #760 | Training started
2017-07-02 15:39:03.770888 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #760 | Training finished
2017-07-02 15:39:03.771390 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #760 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 15:39:03.771547 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #760 | Collecting samples for evaluation
2017-07-02 15:39:09.205849 EDT | -----------------------  -------------
2017-07-02 15:39:09.206171 EDT | Epoch                     760
2017-07-02 15:39:09.206362 EDT | Iteration                 760
2017-07-02 15:39:09.206550 EDT | AverageReturn            1000
2017-07-02 15:39:09.206783 EDT | StdReturn                   0
2017-07-02 15:39:09.207004 EDT | MaxReturn                1000
2017-07-02 15:39:09.207223 EDT | MinReturn                1000
2017-07-02 15:39:09.207452 EDT | AverageEsReturn            29.5
2017-07-02 15:39:09.207666 EDT | StdEsReturn                34.9253
2017-07-02 15:39:09.207779 EDT | MaxEsReturn               153
2017-07-02 15:39:09.207882 EDT | MinEsReturn                 3
2017-07-02 15:39:09.207982 EDT | AverageDiscountedReturn    99.9957
2017-07-02 15:39:09.208083 EDT | AverageQLoss                0.00299279
2017-07-02 15:39:09.208183 EDT | AveragePolicySurr          -0.986031
2017-07-02 15:39:09.208283 EDT | AverageQ                    0.942245
2017-07-02 15:39:09.208383 EDT | AverageAbsQ                 0.945279
2017-07-02 15:39:09.208482 EDT | AverageY                    0.942173
2017-07-02 15:39:09.208580 EDT | AverageAbsY                 0.9424
2017-07-02 15:39:09.208678 EDT | AverageAbsQYDiff            0.0146523
2017-07-02 15:39:09.208776 EDT | AverageAction               0.256989
2017-07-02 15:39:09.208873 EDT | PolicyRegParamNorm         66.4717
2017-07-02 15:39:09.208969 EDT | QFunRegParamNorm           64.8649
2017-07-02 15:39:09.209065 EDT | -----------------------  -------------
2017-07-02 15:39:09.209224 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #761 | Training started
2017-07-02 15:39:18.645694 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #761 | Training finished
2017-07-02 15:39:18.648367 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #761 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 15:39:18.648575 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #761 | Collecting samples for evaluation
2017-07-02 15:39:24.120855 EDT | -----------------------  -------------
2017-07-02 15:39:24.121079 EDT | Epoch                     761
2017-07-02 15:39:24.121244 EDT | Iteration                 761
2017-07-02 15:39:24.121411 EDT | AverageReturn            1000
2017-07-02 15:39:24.121557 EDT | StdReturn                   0
2017-07-02 15:39:24.121689 EDT | MaxReturn                1000
2017-07-02 15:39:24.121880 EDT | MinReturn                1000
2017-07-02 15:39:24.122092 EDT | AverageEsReturn            16.4828
2017-07-02 15:39:24.122317 EDT | StdEsReturn                12.4972
2017-07-02 15:39:24.122490 EDT | MaxEsReturn                47
2017-07-02 15:39:24.122595 EDT | MinEsReturn                 3
2017-07-02 15:39:24.122697 EDT | AverageDiscountedReturn    99.9957
2017-07-02 15:39:24.122797 EDT | AverageQLoss                0.00332423
2017-07-02 15:39:24.122897 EDT | AveragePolicySurr          -0.9871
2017-07-02 15:39:24.123107 EDT | AverageQ                    0.944077
2017-07-02 15:39:24.123316 EDT | AverageAbsQ                 0.946742
2017-07-02 15:39:24.123533 EDT | AverageY                    0.944125
2017-07-02 15:39:24.123748 EDT | AverageAbsY                 0.944505
2017-07-02 15:39:24.123932 EDT | AverageAbsQYDiff            0.0148975
2017-07-02 15:39:24.124170 EDT | AverageAction               0.250622
2017-07-02 15:39:24.124389 EDT | PolicyRegParamNorm         66.5155
2017-07-02 15:39:24.124606 EDT | QFunRegParamNorm           64.912
2017-07-02 15:39:24.124818 EDT | -----------------------  -------------
2017-07-02 15:39:24.125082 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #762 | Training started
2017-07-02 15:39:33.544959 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #762 | Training finished
2017-07-02 15:39:33.558798 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #762 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 15:39:33.559095 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #762 | Collecting samples for evaluation
2017-07-02 15:39:39.095096 EDT | -----------------------  -------------
2017-07-02 15:39:39.095414 EDT | Epoch                     762
2017-07-02 15:39:39.095588 EDT | Iteration                 762
2017-07-02 15:39:39.095711 EDT | AverageReturn            1000
2017-07-02 15:39:39.095814 EDT | StdReturn                   0
2017-07-02 15:39:39.095913 EDT | MaxReturn                1000
2017-07-02 15:39:39.096032 EDT | MinReturn                1000
2017-07-02 15:39:39.096260 EDT | AverageEsReturn            18.5818
2017-07-02 15:39:39.096472 EDT | StdEsReturn                17.3338
2017-07-02 15:39:39.096580 EDT | MaxEsReturn                67
2017-07-02 15:39:39.096682 EDT | MinEsReturn                 3
2017-07-02 15:39:39.096851 EDT | AverageDiscountedReturn    99.9957
2017-07-02 15:39:39.097080 EDT | AverageQLoss                0.00298141
2017-07-02 15:39:39.097264 EDT | AveragePolicySurr          -0.984369
2017-07-02 15:39:39.097651 EDT | AverageQ                    0.939017
2017-07-02 15:39:39.097795 EDT | AverageAbsQ                 0.941917
2017-07-02 15:39:39.097901 EDT | AverageY                    0.939038
2017-07-02 15:39:39.098051 EDT | AverageAbsY                 0.939383
2017-07-02 15:39:39.098277 EDT | AverageAbsQYDiff            0.014465
2017-07-02 15:39:39.098502 EDT | AverageAction               0.215087
2017-07-02 15:39:39.098707 EDT | PolicyRegParamNorm         66.5489
2017-07-02 15:39:39.098936 EDT | QFunRegParamNorm           64.956
2017-07-02 15:39:39.099161 EDT | -----------------------  -------------
2017-07-02 15:39:39.099481 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #763 | Training started
2017-07-02 15:39:48.542193 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #763 | Training finished
2017-07-02 15:39:48.542734 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #763 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 15:39:48.542992 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #763 | Collecting samples for evaluation
2017-07-02 15:39:54.135637 EDT | -----------------------  ------------
2017-07-02 15:39:54.135959 EDT | Epoch                    763
2017-07-02 15:39:54.136257 EDT | Iteration                763
2017-07-02 15:39:54.136495 EDT | AverageReturn             51.5487
2017-07-02 15:39:54.136728 EDT | StdReturn                  1.54636
2017-07-02 15:39:54.136964 EDT | MaxReturn                 55
2017-07-02 15:39:54.137158 EDT | MinReturn                 48
2017-07-02 15:39:54.137388 EDT | AverageEsReturn           20.1961
2017-07-02 15:39:54.137637 EDT | StdEsReturn               17.7941
2017-07-02 15:39:54.137833 EDT | MaxEsReturn               98
2017-07-02 15:39:54.138063 EDT | MinEsReturn                3
2017-07-02 15:39:54.138288 EDT | AverageDiscountedReturn   40.4266
2017-07-02 15:39:54.138485 EDT | AverageQLoss               0.00319509
2017-07-02 15:39:54.138713 EDT | AveragePolicySurr         -0.984645
2017-07-02 15:39:54.138876 EDT | AverageQ                   0.940474
2017-07-02 15:39:54.139107 EDT | AverageAbsQ                0.943545
2017-07-02 15:39:54.139313 EDT | AverageY                   0.940448
2017-07-02 15:39:54.139420 EDT | AverageAbsY                0.941008
2017-07-02 15:39:54.139564 EDT | AverageAbsQYDiff           0.0150764
2017-07-02 15:39:54.139794 EDT | AverageAction              0.441585
2017-07-02 15:39:54.139987 EDT | PolicyRegParamNorm        66.5954
2017-07-02 15:39:54.140218 EDT | QFunRegParamNorm          64.9913
2017-07-02 15:39:54.140437 EDT | -----------------------  ------------
2017-07-02 15:39:54.140739 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #764 | Training started
2017-07-02 15:40:03.548203 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #764 | Training finished
2017-07-02 15:40:03.548734 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #764 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 15:40:03.548866 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #764 | Collecting samples for evaluation
2017-07-02 15:40:09.046751 EDT | -----------------------  -------------
2017-07-02 15:40:09.047067 EDT | Epoch                     764
2017-07-02 15:40:09.047277 EDT | Iteration                 764
2017-07-02 15:40:09.047505 EDT | AverageReturn            1000
2017-07-02 15:40:09.047732 EDT | StdReturn                   0
2017-07-02 15:40:09.047955 EDT | MaxReturn                1000
2017-07-02 15:40:09.048187 EDT | MinReturn                1000
2017-07-02 15:40:09.048399 EDT | AverageEsReturn            25.6842
2017-07-02 15:40:09.048626 EDT | StdEsReturn                29.648
2017-07-02 15:40:09.048843 EDT | MaxEsReturn               162
2017-07-02 15:40:09.049022 EDT | MinEsReturn                 3
2017-07-02 15:40:09.049249 EDT | AverageDiscountedReturn    99.9957
2017-07-02 15:40:09.049414 EDT | AverageQLoss                0.00306854
2017-07-02 15:40:09.049639 EDT | AveragePolicySurr          -0.983448
2017-07-02 15:40:09.049864 EDT | AverageQ                    0.942004
2017-07-02 15:40:09.049993 EDT | AverageAbsQ                 0.944856
2017-07-02 15:40:09.050096 EDT | AverageY                    0.941955
2017-07-02 15:40:09.050198 EDT | AverageAbsY                 0.942471
2017-07-02 15:40:09.050298 EDT | AverageAbsQYDiff            0.0145615
2017-07-02 15:40:09.050490 EDT | AverageAction               0.318072
2017-07-02 15:40:09.050716 EDT | PolicyRegParamNorm         66.653
2017-07-02 15:40:09.050882 EDT | QFunRegParamNorm           64.9774
2017-07-02 15:40:09.051113 EDT | -----------------------  -------------
2017-07-02 15:40:09.051429 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #765 | Training started
2017-07-02 15:40:18.532198 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #765 | Training finished
2017-07-02 15:40:18.532799 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #765 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 15:40:18.533058 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #765 | Collecting samples for evaluation
2017-07-02 15:40:24.425509 EDT | -----------------------  -------------
2017-07-02 15:40:24.425780 EDT | Epoch                     765
2017-07-02 15:40:24.425902 EDT | Iteration                 765
2017-07-02 15:40:24.426036 EDT | AverageReturn            1000
2017-07-02 15:40:24.426213 EDT | StdReturn                   0
2017-07-02 15:40:24.426322 EDT | MaxReturn                1000
2017-07-02 15:40:24.426441 EDT | MinReturn                1000
2017-07-02 15:40:24.426549 EDT | AverageEsReturn            19.7647
2017-07-02 15:40:24.426660 EDT | StdEsReturn                19.7936
2017-07-02 15:40:24.426797 EDT | MaxEsReturn               107
2017-07-02 15:40:24.426965 EDT | MinEsReturn                 3
2017-07-02 15:40:24.427092 EDT | AverageDiscountedReturn    99.9957
2017-07-02 15:40:24.427261 EDT | AverageQLoss                0.00333354
2017-07-02 15:40:24.427416 EDT | AveragePolicySurr          -0.98317
2017-07-02 15:40:24.427544 EDT | AverageQ                    0.938924
2017-07-02 15:40:24.427673 EDT | AverageAbsQ                 0.942722
2017-07-02 15:40:24.427798 EDT | AverageY                    0.938937
2017-07-02 15:40:24.427919 EDT | AverageAbsY                 0.939664
2017-07-02 15:40:24.428092 EDT | AverageAbsQYDiff            0.0162902
2017-07-02 15:40:24.428206 EDT | AverageAction               0.289322
2017-07-02 15:40:24.428321 EDT | PolicyRegParamNorm         66.707
2017-07-02 15:40:24.428483 EDT | QFunRegParamNorm           65.0106
2017-07-02 15:40:24.428662 EDT | -----------------------  -------------
2017-07-02 15:40:24.428915 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #766 | Training started
2017-07-02 15:40:33.732259 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #766 | Training finished
2017-07-02 15:40:33.732799 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #766 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 15:40:33.733050 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #766 | Collecting samples for evaluation
2017-07-02 15:40:39.220690 EDT | -----------------------  -------------
2017-07-02 15:40:39.220992 EDT | Epoch                     766
2017-07-02 15:40:39.221226 EDT | Iteration                 766
2017-07-02 15:40:39.221448 EDT | AverageReturn            1000
2017-07-02 15:40:39.221690 EDT | StdReturn                   0
2017-07-02 15:40:39.221902 EDT | MaxReturn                1000
2017-07-02 15:40:39.222077 EDT | MinReturn                1000
2017-07-02 15:40:39.222296 EDT | AverageEsReturn            17.5263
2017-07-02 15:40:39.222510 EDT | StdEsReturn                13.4779
2017-07-02 15:40:39.222714 EDT | MaxEsReturn                48
2017-07-02 15:40:39.222943 EDT | MinEsReturn                 3
2017-07-02 15:40:39.223160 EDT | AverageDiscountedReturn    99.9957
2017-07-02 15:40:39.223379 EDT | AverageQLoss                0.00316872
2017-07-02 15:40:39.223590 EDT | AveragePolicySurr          -0.98393
2017-07-02 15:40:39.223802 EDT | AverageQ                    0.939367
2017-07-02 15:40:39.224028 EDT | AverageAbsQ                 0.942181
2017-07-02 15:40:39.224248 EDT | AverageY                    0.93938
2017-07-02 15:40:39.224466 EDT | AverageAbsY                 0.940033
2017-07-02 15:40:39.224694 EDT | AverageAbsQYDiff            0.0144437
2017-07-02 15:40:39.224919 EDT | AverageAction               0.320435
2017-07-02 15:40:39.225129 EDT | PolicyRegParamNorm         66.7153
2017-07-02 15:40:39.225353 EDT | QFunRegParamNorm           65.0116
2017-07-02 15:40:39.225626 EDT | -----------------------  -------------
2017-07-02 15:40:39.225924 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #767 | Training started
2017-07-02 15:40:48.580884 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #767 | Training finished
2017-07-02 15:40:48.581413 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #767 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 15:40:48.581608 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #767 | Collecting samples for evaluation
2017-07-02 15:40:53.997304 EDT | -----------------------  -------------
2017-07-02 15:40:53.997512 EDT | Epoch                     767
2017-07-02 15:40:53.997740 EDT | Iteration                 767
2017-07-02 15:40:53.997971 EDT | AverageReturn            1000
2017-07-02 15:40:53.998184 EDT | StdReturn                   0
2017-07-02 15:40:53.998413 EDT | MaxReturn                1000
2017-07-02 15:40:53.998680 EDT | MinReturn                1000
2017-07-02 15:40:53.998998 EDT | AverageEsReturn            24.1667
2017-07-02 15:40:53.999286 EDT | StdEsReturn                20.3948
2017-07-02 15:40:53.999676 EDT | MaxEsReturn                91
2017-07-02 15:40:53.999904 EDT | MinEsReturn                 3
2017-07-02 15:40:54.000133 EDT | AverageDiscountedReturn    99.9957
2017-07-02 15:40:54.000324 EDT | AverageQLoss                0.00363893
2017-07-02 15:40:54.000430 EDT | AveragePolicySurr          -0.984053
2017-07-02 15:40:54.000532 EDT | AverageQ                    0.939888
2017-07-02 15:40:54.000643 EDT | AverageAbsQ                 0.942559
2017-07-02 15:40:54.000840 EDT | AverageY                    0.939927
2017-07-02 15:40:54.001069 EDT | AverageAbsY                 0.940342
2017-07-02 15:40:54.001287 EDT | AverageAbsQYDiff            0.0160824
2017-07-02 15:40:54.001490 EDT | AverageAction               0.135393
2017-07-02 15:40:54.001765 EDT | PolicyRegParamNorm         66.7547
2017-07-02 15:40:54.001988 EDT | QFunRegParamNorm           65.0412
2017-07-02 15:40:54.002175 EDT | -----------------------  -------------
2017-07-02 15:40:54.002497 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #768 | Training started
2017-07-02 15:41:03.466227 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #768 | Training finished
2017-07-02 15:41:03.466726 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #768 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 15:41:03.466967 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #768 | Collecting samples for evaluation
2017-07-02 15:41:08.857837 EDT | -----------------------  -------------
2017-07-02 15:41:08.858158 EDT | Epoch                     768
2017-07-02 15:41:08.858392 EDT | Iteration                 768
2017-07-02 15:41:08.858613 EDT | AverageReturn            1000
2017-07-02 15:41:08.858830 EDT | StdReturn                   0
2017-07-02 15:41:08.859055 EDT | MaxReturn                1000
2017-07-02 15:41:08.859346 EDT | MinReturn                1000
2017-07-02 15:41:08.859564 EDT | AverageEsReturn            21.5435
2017-07-02 15:41:08.859786 EDT | StdEsReturn                16.3809
2017-07-02 15:41:08.860020 EDT | MaxEsReturn                68
2017-07-02 15:41:08.860211 EDT | MinEsReturn                 3
2017-07-02 15:41:08.860439 EDT | AverageDiscountedReturn    99.9957
2017-07-02 15:41:08.860603 EDT | AverageQLoss                0.00344482
2017-07-02 15:41:08.860832 EDT | AveragePolicySurr          -0.98181
2017-07-02 15:41:08.861057 EDT | AverageQ                    0.936444
2017-07-02 15:41:08.861284 EDT | AverageAbsQ                 0.939752
2017-07-02 15:41:08.861516 EDT | AverageY                    0.936397
2017-07-02 15:41:08.861667 EDT | AverageAbsY                 0.937025
2017-07-02 15:41:08.861898 EDT | AverageAbsQYDiff            0.0158334
2017-07-02 15:41:08.862097 EDT | AverageAction               0.498114
2017-07-02 15:41:08.862202 EDT | PolicyRegParamNorm         66.7999
2017-07-02 15:41:08.862313 EDT | QFunRegParamNorm           65.071
2017-07-02 15:41:08.862425 EDT | -----------------------  -------------
2017-07-02 15:41:08.862626 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #769 | Training started
2017-07-02 15:41:18.279891 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #769 | Training finished
2017-07-02 15:41:18.280678 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #769 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 15:41:18.280874 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #769 | Collecting samples for evaluation
2017-07-02 15:41:24.004377 EDT | -----------------------  -------------
2017-07-02 15:41:24.004604 EDT | Epoch                     769
2017-07-02 15:41:24.004716 EDT | Iteration                 769
2017-07-02 15:41:24.004820 EDT | AverageReturn              81.2381
2017-07-02 15:41:24.004979 EDT | StdReturn                 106.883
2017-07-02 15:41:24.005081 EDT | MaxReturn                1000
2017-07-02 15:41:24.005182 EDT | MinReturn                  51
2017-07-02 15:41:24.005282 EDT | AverageEsReturn            17.8571
2017-07-02 15:41:24.005382 EDT | StdEsReturn                19.1614
2017-07-02 15:41:24.005517 EDT | MaxEsReturn                82
2017-07-02 15:41:24.005634 EDT | MinEsReturn                 3
2017-07-02 15:41:24.005747 EDT | AverageDiscountedReturn    48.6297
2017-07-02 15:41:24.005855 EDT | AverageQLoss                0.00313834
2017-07-02 15:41:24.005956 EDT | AveragePolicySurr          -0.980858
2017-07-02 15:41:24.006055 EDT | AverageQ                    0.935664
2017-07-02 15:41:24.006153 EDT | AverageAbsQ                 0.939151
2017-07-02 15:41:24.006278 EDT | AverageY                    0.935712
2017-07-02 15:41:24.006494 EDT | AverageAbsY                 0.9362
2017-07-02 15:41:24.006717 EDT | AverageAbsQYDiff            0.0150967
2017-07-02 15:41:24.006923 EDT | AverageAction               0.396976
2017-07-02 15:41:24.007140 EDT | PolicyRegParamNorm         66.8237
2017-07-02 15:41:24.007361 EDT | QFunRegParamNorm           65.0919
2017-07-02 15:41:24.007578 EDT | -----------------------  -------------
2017-07-02 15:41:24.007859 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #770 | Training started
2017-07-02 15:41:33.347111 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #770 | Training finished
2017-07-02 15:41:33.347601 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #770 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 15:41:33.347769 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #770 | Collecting samples for evaluation
2017-07-02 15:41:39.201461 EDT | -----------------------  -------------
2017-07-02 15:41:39.201776 EDT | Epoch                     770
2017-07-02 15:41:39.201936 EDT | Iteration                 770
2017-07-02 15:41:39.202049 EDT | AverageReturn             560.368
2017-07-02 15:41:39.202244 EDT | StdReturn                 387.887
2017-07-02 15:41:39.202391 EDT | MaxReturn                1000
2017-07-02 15:41:39.202493 EDT | MinReturn                  64
2017-07-02 15:41:39.202612 EDT | AverageEsReturn            15.2424
2017-07-02 15:41:39.202799 EDT | StdEsReturn                14.1465
2017-07-02 15:41:39.202983 EDT | MaxEsReturn                61
2017-07-02 15:41:39.203142 EDT | MinEsReturn                 3
2017-07-02 15:41:39.203245 EDT | AverageDiscountedReturn    88.7174
2017-07-02 15:41:39.203345 EDT | AverageQLoss                0.00321447
2017-07-02 15:41:39.203444 EDT | AveragePolicySurr          -0.98211
2017-07-02 15:41:39.203544 EDT | AverageQ                    0.937037
2017-07-02 15:41:39.203644 EDT | AverageAbsQ                 0.940506
2017-07-02 15:41:39.203743 EDT | AverageY                    0.937009
2017-07-02 15:41:39.203882 EDT | AverageAbsY                 0.937569
2017-07-02 15:41:39.204102 EDT | AverageAbsQYDiff            0.0155894
2017-07-02 15:41:39.204212 EDT | AverageAction               0.362224
2017-07-02 15:41:39.204313 EDT | PolicyRegParamNorm         66.8668
2017-07-02 15:41:39.204412 EDT | QFunRegParamNorm           65.1122
2017-07-02 15:41:39.204510 EDT | -----------------------  -------------
2017-07-02 15:41:39.204708 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #771 | Training started
2017-07-02 15:41:48.466790 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #771 | Training finished
2017-07-02 15:41:48.467577 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #771 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 15:41:48.467767 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #771 | Collecting samples for evaluation
2017-07-02 15:41:54.480994 EDT | -----------------------  -------------
2017-07-02 15:41:54.481300 EDT | Epoch                     771
2017-07-02 15:41:54.481560 EDT | Iteration                 771
2017-07-02 15:41:54.481783 EDT | AverageReturn             105.389
2017-07-02 15:41:54.482003 EDT | StdReturn                 210.959
2017-07-02 15:41:54.482219 EDT | MaxReturn                1000
2017-07-02 15:41:54.482428 EDT | MinReturn                  46
2017-07-02 15:41:54.482636 EDT | AverageEsReturn            17.9464
2017-07-02 15:41:54.482780 EDT | StdEsReturn                19.6254
2017-07-02 15:41:54.482994 EDT | MaxEsReturn               114
2017-07-02 15:41:54.483214 EDT | MinEsReturn                 3
2017-07-02 15:41:54.483425 EDT | AverageDiscountedReturn    45.7528
2017-07-02 15:41:54.483634 EDT | AverageQLoss                0.00345651
2017-07-02 15:41:54.483842 EDT | AveragePolicySurr          -0.982254
2017-07-02 15:41:54.484056 EDT | AverageQ                    0.938593
2017-07-02 15:41:54.484227 EDT | AverageAbsQ                 0.941614
2017-07-02 15:41:54.484386 EDT | AverageY                    0.938581
2017-07-02 15:41:54.484602 EDT | AverageAbsY                 0.939203
2017-07-02 15:41:54.484735 EDT | AverageAbsQYDiff            0.0150803
2017-07-02 15:41:54.484924 EDT | AverageAction               0.253761
2017-07-02 15:41:54.485140 EDT | PolicyRegParamNorm         66.8971
2017-07-02 15:41:54.485304 EDT | QFunRegParamNorm           65.1147
2017-07-02 15:41:54.485406 EDT | -----------------------  -------------
2017-07-02 15:41:54.485611 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #772 | Training started
2017-07-02 15:42:03.674431 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #772 | Training finished
2017-07-02 15:42:03.675006 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #772 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 15:42:03.675361 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #772 | Collecting samples for evaluation
2017-07-02 15:42:09.497949 EDT | -----------------------  ------------
2017-07-02 15:42:09.498233 EDT | Epoch                    772
2017-07-02 15:42:09.498464 EDT | Iteration                772
2017-07-02 15:42:09.498688 EDT | AverageReturn             46.5814
2017-07-02 15:42:09.498916 EDT | StdReturn                  2.42499
2017-07-02 15:42:09.499133 EDT | MaxReturn                 55
2017-07-02 15:42:09.499345 EDT | MinReturn                 43
2017-07-02 15:42:09.499544 EDT | AverageEsReturn           18.8868
2017-07-02 15:42:09.499763 EDT | StdEsReturn               19.53
2017-07-02 15:42:09.499899 EDT | MaxEsReturn               86
2017-07-02 15:42:09.500004 EDT | MinEsReturn                3
2017-07-02 15:42:09.500126 EDT | AverageDiscountedReturn   37.3661
2017-07-02 15:42:09.500339 EDT | AverageQLoss               0.00338941
2017-07-02 15:42:09.500559 EDT | AveragePolicySurr         -0.982591
2017-07-02 15:42:09.500769 EDT | AverageQ                   0.937113
2017-07-02 15:42:09.500989 EDT | AverageAbsQ                0.939872
2017-07-02 15:42:09.501126 EDT | AverageY                   0.937047
2017-07-02 15:42:09.501347 EDT | AverageAbsY                0.93783
2017-07-02 15:42:09.501546 EDT | AverageAbsQYDiff           0.0150465
2017-07-02 15:42:09.501763 EDT | AverageAction              0.629513
2017-07-02 15:42:09.501981 EDT | PolicyRegParamNorm        66.91
2017-07-02 15:42:09.502126 EDT | QFunRegParamNorm          65.1137
2017-07-02 15:42:09.502230 EDT | -----------------------  ------------
2017-07-02 15:42:09.502404 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #773 | Training started
2017-07-02 15:42:18.816210 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #773 | Training finished
2017-07-02 15:42:18.816783 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #773 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 15:42:18.816973 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #773 | Collecting samples for evaluation
2017-07-02 15:42:24.382141 EDT | -----------------------  -------------
2017-07-02 15:42:24.382447 EDT | Epoch                     773
2017-07-02 15:42:24.382687 EDT | Iteration                 773
2017-07-02 15:42:24.383004 EDT | AverageReturn             138.917
2017-07-02 15:42:24.383242 EDT | StdReturn                 259.64
2017-07-02 15:42:24.383444 EDT | MaxReturn                1000
2017-07-02 15:42:24.383674 EDT | MinReturn                  57
2017-07-02 15:42:24.383893 EDT | AverageEsReturn            16.5833
2017-07-02 15:42:24.384002 EDT | StdEsReturn                18.4113
2017-07-02 15:42:24.384101 EDT | MaxEsReturn                81
2017-07-02 15:42:24.384299 EDT | MinEsReturn                 2
2017-07-02 15:42:24.384523 EDT | AverageDiscountedReturn    50.1446
2017-07-02 15:42:24.384722 EDT | AverageQLoss                0.00311106
2017-07-02 15:42:24.384951 EDT | AveragePolicySurr          -0.98288
2017-07-02 15:42:24.385144 EDT | AverageQ                    0.938161
2017-07-02 15:42:24.385374 EDT | AverageAbsQ                 0.94051
2017-07-02 15:42:24.385606 EDT | AverageY                    0.938173
2017-07-02 15:42:24.385789 EDT | AverageAbsY                 0.938729
2017-07-02 15:42:24.386017 EDT | AverageAbsQYDiff            0.0146518
2017-07-02 15:42:24.386239 EDT | AverageAction               0.120622
2017-07-02 15:42:24.386469 EDT | PolicyRegParamNorm         66.9523
2017-07-02 15:42:24.386693 EDT | QFunRegParamNorm           65.1558
2017-07-02 15:42:24.386877 EDT | -----------------------  -------------
2017-07-02 15:42:24.387207 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #774 | Training started
2017-07-02 15:42:33.903458 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #774 | Training finished
2017-07-02 15:42:33.904205 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #774 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 15:42:33.904349 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #774 | Collecting samples for evaluation
2017-07-02 15:42:39.325162 EDT | -----------------------  -------------
2017-07-02 15:42:39.325364 EDT | Epoch                     774
2017-07-02 15:42:39.325506 EDT | Iteration                 774
2017-07-02 15:42:39.325661 EDT | AverageReturn            1000
2017-07-02 15:42:39.325771 EDT | StdReturn                   0
2017-07-02 15:42:39.325904 EDT | MaxReturn                1000
2017-07-02 15:42:39.326007 EDT | MinReturn                1000
2017-07-02 15:42:39.326109 EDT | AverageEsReturn            18.8302
2017-07-02 15:42:39.326210 EDT | StdEsReturn                18.5266
2017-07-02 15:42:39.326326 EDT | MaxEsReturn                86
2017-07-02 15:42:39.326515 EDT | MinEsReturn                 3
2017-07-02 15:42:39.326650 EDT | AverageDiscountedReturn    99.9957
2017-07-02 15:42:39.326751 EDT | AverageQLoss                0.00393506
2017-07-02 15:42:39.326851 EDT | AveragePolicySurr          -0.981005
2017-07-02 15:42:39.326949 EDT | AverageQ                    0.937732
2017-07-02 15:42:39.327083 EDT | AverageAbsQ                 0.941174
2017-07-02 15:42:39.327185 EDT | AverageY                    0.937634
2017-07-02 15:42:39.327290 EDT | AverageAbsY                 0.938494
2017-07-02 15:42:39.327444 EDT | AverageAbsQYDiff            0.0168656
2017-07-02 15:42:39.327553 EDT | AverageAction               0.0112535
2017-07-02 15:42:39.327653 EDT | PolicyRegParamNorm         66.9949
2017-07-02 15:42:39.327752 EDT | QFunRegParamNorm           65.1822
2017-07-02 15:42:39.327852 EDT | -----------------------  -------------
2017-07-02 15:42:39.328032 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #775 | Training started
2017-07-02 15:42:48.742014 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #775 | Training finished
2017-07-02 15:42:48.742526 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #775 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 15:42:48.742699 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #775 | Collecting samples for evaluation
2017-07-02 15:42:54.226749 EDT | -----------------------  -------------
2017-07-02 15:42:54.226957 EDT | Epoch                     775
2017-07-02 15:42:54.227164 EDT | Iteration                 775
2017-07-02 15:42:54.227346 EDT | AverageReturn            1000
2017-07-02 15:42:54.227451 EDT | StdReturn                   0
2017-07-02 15:42:54.227552 EDT | MaxReturn                1000
2017-07-02 15:42:54.227651 EDT | MinReturn                1000
2017-07-02 15:42:54.227758 EDT | AverageEsReturn            16.1186
2017-07-02 15:42:54.227858 EDT | StdEsReturn                16.0139
2017-07-02 15:42:54.227981 EDT | MaxEsReturn                83
2017-07-02 15:42:54.228086 EDT | MinEsReturn                 3
2017-07-02 15:42:54.228209 EDT | AverageDiscountedReturn    99.9957
2017-07-02 15:42:54.228310 EDT | AverageQLoss                0.00342477
2017-07-02 15:42:54.228410 EDT | AveragePolicySurr          -0.980503
2017-07-02 15:42:54.228555 EDT | AverageQ                    0.937594
2017-07-02 15:42:54.228657 EDT | AverageAbsQ                 0.940593
2017-07-02 15:42:54.228757 EDT | AverageY                    0.937686
2017-07-02 15:42:54.228860 EDT | AverageAbsY                 0.938275
2017-07-02 15:42:54.228977 EDT | AverageAbsQYDiff            0.0158165
2017-07-02 15:42:54.229086 EDT | AverageAction               0.151829
2017-07-02 15:42:54.229203 EDT | PolicyRegParamNorm         67.0061
2017-07-02 15:42:54.229308 EDT | QFunRegParamNorm           65.1918
2017-07-02 15:42:54.229463 EDT | -----------------------  -------------
2017-07-02 15:42:54.230157 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #776 | Training started
2017-07-02 15:43:03.747165 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #776 | Training finished
2017-07-02 15:43:03.747696 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #776 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 15:43:03.747970 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #776 | Collecting samples for evaluation
2017-07-02 15:43:09.165775 EDT | -----------------------  -------------
2017-07-02 15:43:09.166008 EDT | Epoch                     776
2017-07-02 15:43:09.166127 EDT | Iteration                 776
2017-07-02 15:43:09.166232 EDT | AverageReturn            1000
2017-07-02 15:43:09.166333 EDT | StdReturn                   0
2017-07-02 15:43:09.166432 EDT | MaxReturn                1000
2017-07-02 15:43:09.166619 EDT | MinReturn                1000
2017-07-02 15:43:09.166753 EDT | AverageEsReturn            16.8871
2017-07-02 15:43:09.166898 EDT | StdEsReturn                15.9486
2017-07-02 15:43:09.167009 EDT | MaxEsReturn                91
2017-07-02 15:43:09.167143 EDT | MinEsReturn                 3
2017-07-02 15:43:09.167246 EDT | AverageDiscountedReturn    99.9957
2017-07-02 15:43:09.167348 EDT | AverageQLoss                0.00304915
2017-07-02 15:43:09.167447 EDT | AveragePolicySurr          -0.979931
2017-07-02 15:43:09.167580 EDT | AverageQ                    0.936424
2017-07-02 15:43:09.167682 EDT | AverageAbsQ                 0.939281
2017-07-02 15:43:09.167780 EDT | AverageY                    0.936362
2017-07-02 15:43:09.167878 EDT | AverageAbsY                 0.936882
2017-07-02 15:43:09.167977 EDT | AverageAbsQYDiff            0.0149072
2017-07-02 15:43:09.168074 EDT | AverageAction               0.250118
2017-07-02 15:43:09.168172 EDT | PolicyRegParamNorm         67.0566
2017-07-02 15:43:09.168270 EDT | QFunRegParamNorm           65.2164
2017-07-02 15:43:09.168368 EDT | -----------------------  -------------
2017-07-02 15:43:09.168539 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #777 | Training started
2017-07-02 15:43:18.537624 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #777 | Training finished
2017-07-02 15:43:18.538213 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #777 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 15:43:18.538407 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #777 | Collecting samples for evaluation
2017-07-02 15:43:24.203514 EDT | -----------------------  ------------
2017-07-02 15:43:24.203725 EDT | Epoch                    777
2017-07-02 15:43:24.203885 EDT | Iteration                777
2017-07-02 15:43:24.203993 EDT | AverageReturn             52.3333
2017-07-02 15:43:24.204104 EDT | StdReturn                  1.09608
2017-07-02 15:43:24.204245 EDT | MaxReturn                 58
2017-07-02 15:43:24.204347 EDT | MinReturn                 50
2017-07-02 15:43:24.204448 EDT | AverageEsReturn           17.4286
2017-07-02 15:43:24.204547 EDT | StdEsReturn               15.7286
2017-07-02 15:43:24.204677 EDT | MaxEsReturn               69
2017-07-02 15:43:24.204777 EDT | MinEsReturn                3
2017-07-02 15:43:24.204973 EDT | AverageDiscountedReturn   40.8981
2017-07-02 15:43:24.205127 EDT | AverageQLoss               0.00315254
2017-07-02 15:43:24.205250 EDT | AveragePolicySurr         -0.979634
2017-07-02 15:43:24.205366 EDT | AverageQ                   0.935671
2017-07-02 15:43:24.205502 EDT | AverageAbsQ                0.938648
2017-07-02 15:43:24.205673 EDT | AverageY                   0.935662
2017-07-02 15:43:24.205787 EDT | AverageAbsY                0.936197
2017-07-02 15:43:24.205927 EDT | AverageAbsQYDiff           0.014989
2017-07-02 15:43:24.206118 EDT | AverageAction              0.338508
2017-07-02 15:43:24.206273 EDT | PolicyRegParamNorm        67.0462
2017-07-02 15:43:24.206383 EDT | QFunRegParamNorm          65.2498
2017-07-02 15:43:24.206568 EDT | -----------------------  ------------
2017-07-02 15:43:24.206820 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #778 | Training started
2017-07-02 15:43:33.772369 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #778 | Training finished
2017-07-02 15:43:33.772985 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #778 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 15:43:33.773173 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #778 | Collecting samples for evaluation
2017-07-02 15:43:39.155873 EDT | -----------------------  -------------
2017-07-02 15:43:39.156125 EDT | Epoch                     778
2017-07-02 15:43:39.156328 EDT | Iteration                 778
2017-07-02 15:43:39.156465 EDT | AverageReturn            1000
2017-07-02 15:43:39.156604 EDT | StdReturn                   0
2017-07-02 15:43:39.156729 EDT | MaxReturn                1000
2017-07-02 15:43:39.156861 EDT | MinReturn                1000
2017-07-02 15:43:39.156963 EDT | AverageEsReturn            16.125
2017-07-02 15:43:39.157084 EDT | StdEsReturn                15.372
2017-07-02 15:43:39.157194 EDT | MaxEsReturn                75
2017-07-02 15:43:39.157314 EDT | MinEsReturn                 3
2017-07-02 15:43:39.157416 EDT | AverageDiscountedReturn    99.9957
2017-07-02 15:43:39.157555 EDT | AverageQLoss                0.00346523
2017-07-02 15:43:39.157683 EDT | AveragePolicySurr          -0.979068
2017-07-02 15:43:39.157818 EDT | AverageQ                    0.937796
2017-07-02 15:43:39.157918 EDT | AverageAbsQ                 0.941152
2017-07-02 15:43:39.158017 EDT | AverageY                    0.937819
2017-07-02 15:43:39.158151 EDT | AverageAbsY                 0.938308
2017-07-02 15:43:39.158252 EDT | AverageAbsQYDiff            0.0158697
2017-07-02 15:43:39.158495 EDT | AverageAction               0.127984
2017-07-02 15:43:39.158737 EDT | PolicyRegParamNorm         67.0515
2017-07-02 15:43:39.159045 EDT | QFunRegParamNorm           65.2859
2017-07-02 15:43:39.159243 EDT | -----------------------  -------------
2017-07-02 15:43:39.159514 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #779 | Training started
2017-07-02 15:43:48.673857 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #779 | Training finished
2017-07-02 15:43:48.674151 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #779 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 15:43:48.674371 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #779 | Collecting samples for evaluation
2017-07-02 15:43:54.118531 EDT | -----------------------  -------------
2017-07-02 15:43:54.119025 EDT | Epoch                     779
2017-07-02 15:43:54.119245 EDT | Iteration                 779
2017-07-02 15:43:54.119475 EDT | AverageReturn            1000
2017-07-02 15:43:54.119650 EDT | StdReturn                   0
2017-07-02 15:43:54.119761 EDT | MaxReturn                1000
2017-07-02 15:43:54.119869 EDT | MinReturn                1000
2017-07-02 15:43:54.119976 EDT | AverageEsReturn            19.5686
2017-07-02 15:43:54.120082 EDT | StdEsReturn                24.5191
2017-07-02 15:43:54.120187 EDT | MaxEsReturn               168
2017-07-02 15:43:54.120291 EDT | MinEsReturn                 3
2017-07-02 15:43:54.120396 EDT | AverageDiscountedReturn    99.9957
2017-07-02 15:43:54.120500 EDT | AverageQLoss                0.00327413
2017-07-02 15:43:54.120626 EDT | AveragePolicySurr          -0.980699
2017-07-02 15:43:54.120861 EDT | AverageQ                    0.935326
2017-07-02 15:43:54.121087 EDT | AverageAbsQ                 0.938501
2017-07-02 15:43:54.121309 EDT | AverageY                    0.9353
2017-07-02 15:43:54.121533 EDT | AverageAbsY                 0.935817
2017-07-02 15:43:54.121720 EDT | AverageAbsQYDiff            0.0151412
2017-07-02 15:43:54.121938 EDT | AverageAction               0.117873
2017-07-02 15:43:54.122046 EDT | PolicyRegParamNorm         67.0925
2017-07-02 15:43:54.122146 EDT | QFunRegParamNorm           65.2928
2017-07-02 15:43:54.122244 EDT | -----------------------  -------------
2017-07-02 15:43:54.122402 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #780 | Training started
2017-07-02 15:44:03.550538 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #780 | Training finished
2017-07-02 15:44:03.551118 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #780 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 15:44:03.551449 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #780 | Collecting samples for evaluation
2017-07-02 15:44:09.036334 EDT | -----------------------  -------------
2017-07-02 15:44:09.036595 EDT | Epoch                     780
2017-07-02 15:44:09.036707 EDT | Iteration                 780
2017-07-02 15:44:09.036823 EDT | AverageReturn            1000
2017-07-02 15:44:09.036952 EDT | StdReturn                   0
2017-07-02 15:44:09.037073 EDT | MaxReturn                1000
2017-07-02 15:44:09.037175 EDT | MinReturn                1000
2017-07-02 15:44:09.037272 EDT | AverageEsReturn            14.9552
2017-07-02 15:44:09.037370 EDT | StdEsReturn                13.6736
2017-07-02 15:44:09.037590 EDT | MaxEsReturn                56
2017-07-02 15:44:09.037697 EDT | MinEsReturn                 3
2017-07-02 15:44:09.037827 EDT | AverageDiscountedReturn    99.9957
2017-07-02 15:44:09.037928 EDT | AverageQLoss                0.00284247
2017-07-02 15:44:09.038056 EDT | AveragePolicySurr          -0.980319
2017-07-02 15:44:09.038164 EDT | AverageQ                    0.936482
2017-07-02 15:44:09.038278 EDT | AverageAbsQ                 0.938802
2017-07-02 15:44:09.038435 EDT | AverageY                    0.93651
2017-07-02 15:44:09.038541 EDT | AverageAbsY                 0.937057
2017-07-02 15:44:09.038646 EDT | AverageAbsQYDiff            0.0133893
2017-07-02 15:44:09.038751 EDT | AverageAction               0.0101912
2017-07-02 15:44:09.038860 EDT | PolicyRegParamNorm         67.1028
2017-07-02 15:44:09.038994 EDT | QFunRegParamNorm           65.3193
2017-07-02 15:44:09.039149 EDT | -----------------------  -------------
2017-07-02 15:44:09.039366 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #781 | Training started
2017-07-02 15:44:18.479563 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #781 | Training finished
2017-07-02 15:44:18.479774 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #781 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 15:44:18.479917 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #781 | Collecting samples for evaluation
2017-07-02 15:44:23.985281 EDT | -----------------------  -------------
2017-07-02 15:44:23.985881 EDT | Epoch                     781
2017-07-02 15:44:23.986076 EDT | Iteration                 781
2017-07-02 15:44:23.986281 EDT | AverageReturn            1000
2017-07-02 15:44:23.986493 EDT | StdReturn                   0
2017-07-02 15:44:23.986718 EDT | MaxReturn                1000
2017-07-02 15:44:23.986909 EDT | MinReturn                1000
2017-07-02 15:44:23.987297 EDT | AverageEsReturn            13.9286
2017-07-02 15:44:23.987524 EDT | StdEsReturn                12.8256
2017-07-02 15:44:23.987806 EDT | MaxEsReturn                57
2017-07-02 15:44:23.988034 EDT | MinEsReturn                 3
2017-07-02 15:44:23.988253 EDT | AverageDiscountedReturn    99.9957
2017-07-02 15:44:23.988469 EDT | AverageQLoss                0.00297617
2017-07-02 15:44:23.988679 EDT | AveragePolicySurr          -0.980991
2017-07-02 15:44:23.988870 EDT | AverageQ                    0.937076
2017-07-02 15:44:23.989081 EDT | AverageAbsQ                 0.940185
2017-07-02 15:44:23.989303 EDT | AverageY                    0.937057
2017-07-02 15:44:23.989516 EDT | AverageAbsY                 0.937529
2017-07-02 15:44:23.989690 EDT | AverageAbsQYDiff            0.0145557
2017-07-02 15:44:23.989862 EDT | AverageAction               0.183709
2017-07-02 15:44:23.990070 EDT | PolicyRegParamNorm         67.1762
2017-07-02 15:44:23.990296 EDT | QFunRegParamNorm           65.3256
2017-07-02 15:44:23.990512 EDT | -----------------------  -------------
2017-07-02 15:44:23.990817 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #782 | Training started
2017-07-02 15:44:33.301552 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #782 | Training finished
2017-07-02 15:44:33.302137 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #782 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 15:44:33.302354 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #782 | Collecting samples for evaluation
2017-07-02 15:44:39.073701 EDT | -----------------------  -----------
2017-07-02 15:44:39.073939 EDT | Epoch                    782
2017-07-02 15:44:39.074057 EDT | Iteration                782
2017-07-02 15:44:39.074164 EDT | AverageReturn             47.9713
2017-07-02 15:44:39.074266 EDT | StdReturn                  1.34454
2017-07-02 15:44:39.074373 EDT | MaxReturn                 52
2017-07-02 15:44:39.074525 EDT | MinReturn                 46
2017-07-02 15:44:39.074628 EDT | AverageEsReturn           12.8846
2017-07-02 15:44:39.074739 EDT | StdEsReturn               11.3114
2017-07-02 15:44:39.074881 EDT | MaxEsReturn               53
2017-07-02 15:44:39.075000 EDT | MinEsReturn                3
2017-07-02 15:44:39.075115 EDT | AverageDiscountedReturn   38.2475
2017-07-02 15:44:39.075219 EDT | AverageQLoss               0.0031552
2017-07-02 15:44:39.075318 EDT | AveragePolicySurr         -0.980885
2017-07-02 15:44:39.075417 EDT | AverageQ                   0.935481
2017-07-02 15:44:39.075579 EDT | AverageAbsQ                0.938321
2017-07-02 15:44:39.075736 EDT | AverageY                   0.935477
2017-07-02 15:44:39.075877 EDT | AverageAbsY                0.935965
2017-07-02 15:44:39.075996 EDT | AverageAbsQYDiff           0.0149611
2017-07-02 15:44:39.076098 EDT | AverageAction              0.353521
2017-07-02 15:44:39.076197 EDT | PolicyRegParamNorm        67.1808
2017-07-02 15:44:39.076296 EDT | QFunRegParamNorm          65.3736
2017-07-02 15:44:39.076439 EDT | -----------------------  -----------
2017-07-02 15:44:39.076605 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #783 | Training started
2017-07-02 15:44:48.391578 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #783 | Training finished
2017-07-02 15:44:48.392184 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #783 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 15:44:48.392420 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #783 | Collecting samples for evaluation
2017-07-02 15:44:53.983154 EDT | -----------------------  ------------
2017-07-02 15:44:53.983763 EDT | Epoch                    783
2017-07-02 15:44:53.983998 EDT | Iteration                783
2017-07-02 15:44:53.984182 EDT | AverageReturn             56.9545
2017-07-02 15:44:53.984411 EDT | StdReturn                  2.66675
2017-07-02 15:44:53.984630 EDT | MaxReturn                 71
2017-07-02 15:44:53.984849 EDT | MinReturn                 54
2017-07-02 15:44:53.985065 EDT | AverageEsReturn           12.9241
2017-07-02 15:44:53.985266 EDT | StdEsReturn               13.7645
2017-07-02 15:44:53.985474 EDT | MaxEsReturn               81
2017-07-02 15:44:53.985710 EDT | MinEsReturn                3
2017-07-02 15:44:53.985969 EDT | AverageDiscountedReturn   43.5639
2017-07-02 15:44:53.986190 EDT | AverageQLoss               0.00329298
2017-07-02 15:44:53.986404 EDT | AveragePolicySurr         -0.981385
2017-07-02 15:44:53.986626 EDT | AverageQ                   0.937147
2017-07-02 15:44:53.986818 EDT | AverageAbsQ                0.939862
2017-07-02 15:44:53.987032 EDT | AverageY                   0.937161
2017-07-02 15:44:53.987143 EDT | AverageAbsY                0.937614
2017-07-02 15:44:53.987356 EDT | AverageAbsQYDiff           0.0146261
2017-07-02 15:44:53.987578 EDT | AverageAction              0.415334
2017-07-02 15:44:53.987770 EDT | PolicyRegParamNorm        67.2092
2017-07-02 15:44:53.987880 EDT | QFunRegParamNorm          65.407
2017-07-02 15:44:53.987990 EDT | -----------------------  ------------
2017-07-02 15:44:53.988195 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #784 | Training started
2017-07-02 15:45:03.355057 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #784 | Training finished
2017-07-02 15:45:03.355591 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #784 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 15:45:03.355778 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #784 | Collecting samples for evaluation
2017-07-02 15:45:08.870859 EDT | -----------------------  -------------
2017-07-02 15:45:08.871062 EDT | Epoch                     784
2017-07-02 15:45:08.871180 EDT | Iteration                 784
2017-07-02 15:45:08.871290 EDT | AverageReturn            1000
2017-07-02 15:45:08.871435 EDT | StdReturn                   0
2017-07-02 15:45:08.871571 EDT | MaxReturn                1000
2017-07-02 15:45:08.871680 EDT | MinReturn                1000
2017-07-02 15:45:08.871801 EDT | AverageEsReturn            12.7838
2017-07-02 15:45:08.871912 EDT | StdEsReturn                12.6077
2017-07-02 15:45:08.872017 EDT | MaxEsReturn                71
2017-07-02 15:45:08.872122 EDT | MinEsReturn                 2
2017-07-02 15:45:08.872250 EDT | AverageDiscountedReturn    99.9957
2017-07-02 15:45:08.872356 EDT | AverageQLoss                0.00272861
2017-07-02 15:45:08.872461 EDT | AveragePolicySurr          -0.981013
2017-07-02 15:45:08.872566 EDT | AverageQ                    0.938943
2017-07-02 15:45:08.872684 EDT | AverageAbsQ                 0.941707
2017-07-02 15:45:08.872789 EDT | AverageY                    0.938943
2017-07-02 15:45:08.872892 EDT | AverageAbsY                 0.939338
2017-07-02 15:45:08.872995 EDT | AverageAbsQYDiff            0.0139948
2017-07-02 15:45:08.873104 EDT | AverageAction               0.0161958
2017-07-02 15:45:08.873218 EDT | PolicyRegParamNorm         67.2381
2017-07-02 15:45:08.873322 EDT | QFunRegParamNorm           65.4438
2017-07-02 15:45:08.873425 EDT | -----------------------  -------------
2017-07-02 15:45:08.873643 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #785 | Training started
2017-07-02 15:45:18.364433 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #785 | Training finished
2017-07-02 15:45:18.365103 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #785 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 15:45:18.365361 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #785 | Collecting samples for evaluation
2017-07-02 15:45:24.278156 EDT | -----------------------  -------------
2017-07-02 15:45:24.278712 EDT | Epoch                     785
2017-07-02 15:45:24.278955 EDT | Iteration                 785
2017-07-02 15:45:24.279176 EDT | AverageReturn            1000
2017-07-02 15:45:24.279303 EDT | StdReturn                   0
2017-07-02 15:45:24.279438 EDT | MaxReturn                1000
2017-07-02 15:45:24.279560 EDT | MinReturn                1000
2017-07-02 15:45:24.279683 EDT | AverageEsReturn            16.9839
2017-07-02 15:45:24.279831 EDT | StdEsReturn                17.2079
2017-07-02 15:45:24.279931 EDT | MaxEsReturn                83
2017-07-02 15:45:24.280116 EDT | MinEsReturn                 3
2017-07-02 15:45:24.280225 EDT | AverageDiscountedReturn    99.9957
2017-07-02 15:45:24.280397 EDT | AverageQLoss                0.00348909
2017-07-02 15:45:24.280595 EDT | AveragePolicySurr          -0.983945
2017-07-02 15:45:24.280740 EDT | AverageQ                    0.938159
2017-07-02 15:45:24.280843 EDT | AverageAbsQ                 0.941293
2017-07-02 15:45:24.281021 EDT | AverageY                    0.938117
2017-07-02 15:45:24.281243 EDT | AverageAbsY                 0.938352
2017-07-02 15:45:24.281458 EDT | AverageAbsQYDiff            0.0161172
2017-07-02 15:45:24.282106 EDT | AverageAction               0.00963288
2017-07-02 15:45:24.282329 EDT | PolicyRegParamNorm         67.2691
2017-07-02 15:45:24.282561 EDT | QFunRegParamNorm           65.4463
2017-07-02 15:45:24.282784 EDT | -----------------------  -------------
2017-07-02 15:45:24.283101 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #786 | Training started
2017-07-02 15:45:33.612869 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #786 | Training finished
2017-07-02 15:45:33.613432 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #786 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 15:45:33.613619 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #786 | Collecting samples for evaluation
2017-07-02 15:45:39.108897 EDT | -----------------------  -------------
2017-07-02 15:45:39.109199 EDT | Epoch                     786
2017-07-02 15:45:39.109429 EDT | Iteration                 786
2017-07-02 15:45:39.109602 EDT | AverageReturn            1000
2017-07-02 15:45:39.109791 EDT | StdReturn                   0
2017-07-02 15:45:39.109947 EDT | MaxReturn                1000
2017-07-02 15:45:39.110143 EDT | MinReturn                1000
2017-07-02 15:45:39.110341 EDT | AverageEsReturn            13.0395
2017-07-02 15:45:39.110559 EDT | StdEsReturn                14.4089
2017-07-02 15:45:39.110758 EDT | MaxEsReturn                88
2017-07-02 15:45:39.110864 EDT | MinEsReturn                 2
2017-07-02 15:45:39.110981 EDT | AverageDiscountedReturn    99.9957
2017-07-02 15:45:39.111106 EDT | AverageQLoss                0.00369361
2017-07-02 15:45:39.111210 EDT | AveragePolicySurr          -0.985061
2017-07-02 15:45:39.111394 EDT | AverageQ                    0.940008
2017-07-02 15:45:39.111612 EDT | AverageAbsQ                 0.943236
2017-07-02 15:45:39.111815 EDT | AverageY                    0.939996
2017-07-02 15:45:39.112039 EDT | AverageAbsY                 0.940265
2017-07-02 15:45:39.112261 EDT | AverageAbsQYDiff            0.0162147
2017-07-02 15:45:39.112477 EDT | AverageAction               0.0122201
2017-07-02 15:45:39.112693 EDT | PolicyRegParamNorm         67.2669
2017-07-02 15:45:39.112902 EDT | QFunRegParamNorm           65.476
2017-07-02 15:45:39.113069 EDT | -----------------------  -------------
2017-07-02 15:45:39.113383 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #787 | Training started
2017-07-02 15:45:48.329693 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #787 | Training finished
2017-07-02 15:45:48.330376 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #787 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 15:45:48.330786 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #787 | Collecting samples for evaluation
2017-07-02 15:45:53.854062 EDT | -----------------------  ------------
2017-07-02 15:45:53.854861 EDT | Epoch                    787
2017-07-02 15:45:53.855092 EDT | Iteration                787
2017-07-02 15:45:53.855226 EDT | AverageReturn             53.3564
2017-07-02 15:45:53.855537 EDT | StdReturn                  1.60968
2017-07-02 15:45:53.855727 EDT | MaxReturn                 58
2017-07-02 15:45:53.855886 EDT | MinReturn                 51
2017-07-02 15:45:53.856002 EDT | AverageEsReturn           11.5904
2017-07-02 15:45:53.856109 EDT | StdEsReturn               10.0852
2017-07-02 15:45:53.856237 EDT | MaxEsReturn               45
2017-07-02 15:45:53.856342 EDT | MinEsReturn                3
2017-07-02 15:45:53.856462 EDT | AverageDiscountedReturn   41.4986
2017-07-02 15:45:53.856582 EDT | AverageQLoss               0.00342948
2017-07-02 15:45:53.856718 EDT | AveragePolicySurr         -0.985289
2017-07-02 15:45:53.856837 EDT | AverageQ                   0.941702
2017-07-02 15:45:53.856945 EDT | AverageAbsQ                0.944457
2017-07-02 15:45:53.857106 EDT | AverageY                   0.941731
2017-07-02 15:45:53.857260 EDT | AverageAbsY                0.941948
2017-07-02 15:45:53.857463 EDT | AverageAbsQYDiff           0.0155908
2017-07-02 15:45:53.857705 EDT | AverageAction              0.294936
2017-07-02 15:45:53.857907 EDT | PolicyRegParamNorm        67.3265
2017-07-02 15:45:53.858113 EDT | QFunRegParamNorm          65.5156
2017-07-02 15:45:53.858333 EDT | -----------------------  ------------
2017-07-02 15:45:53.858646 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #788 | Training started
2017-07-02 15:46:03.103426 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #788 | Training finished
2017-07-02 15:46:03.104042 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #788 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 15:46:03.104183 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #788 | Collecting samples for evaluation
2017-07-02 15:46:08.550039 EDT | -----------------------  -------------
2017-07-02 15:46:08.550257 EDT | Epoch                     788
2017-07-02 15:46:08.550400 EDT | Iteration                 788
2017-07-02 15:46:08.550504 EDT | AverageReturn            1000
2017-07-02 15:46:08.550640 EDT | StdReturn                   0
2017-07-02 15:46:08.550760 EDT | MaxReturn                1000
2017-07-02 15:46:08.550868 EDT | MinReturn                1000
2017-07-02 15:46:08.550999 EDT | AverageEsReturn            18.2807
2017-07-02 15:46:08.551107 EDT | StdEsReturn                16.4719
2017-07-02 15:46:08.551217 EDT | MaxEsReturn                86
2017-07-02 15:46:08.551413 EDT | MinEsReturn                 3
2017-07-02 15:46:08.551538 EDT | AverageDiscountedReturn    99.9957
2017-07-02 15:46:08.551690 EDT | AverageQLoss                0.00329443
2017-07-02 15:46:08.551813 EDT | AveragePolicySurr          -0.9823
2017-07-02 15:46:08.551920 EDT | AverageQ                    0.93708
2017-07-02 15:46:08.552067 EDT | AverageAbsQ                 0.939816
2017-07-02 15:46:08.552225 EDT | AverageY                    0.937137
2017-07-02 15:46:08.552360 EDT | AverageAbsY                 0.937573
2017-07-02 15:46:08.552733 EDT | AverageAbsQYDiff            0.0144172
2017-07-02 15:46:08.552892 EDT | AverageAction               0.0152406
2017-07-02 15:46:08.553036 EDT | PolicyRegParamNorm         67.3349
2017-07-02 15:46:08.553145 EDT | QFunRegParamNorm           65.5408
2017-07-02 15:46:08.553260 EDT | -----------------------  -------------
2017-07-02 15:46:08.553449 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #789 | Training started
2017-07-02 15:46:17.916220 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #789 | Training finished
2017-07-02 15:46:17.916844 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #789 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 15:46:17.917102 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #789 | Collecting samples for evaluation
2017-07-02 15:46:23.639608 EDT | -----------------------  ------------
2017-07-02 15:46:23.639919 EDT | Epoch                    789
2017-07-02 15:46:23.640119 EDT | Iteration                789
2017-07-02 15:46:23.640346 EDT | AverageReturn             50.5075
2017-07-02 15:46:23.640561 EDT | StdReturn                  1.61298
2017-07-02 15:46:23.640781 EDT | MaxReturn                 57
2017-07-02 15:46:23.640995 EDT | MinReturn                 48
2017-07-02 15:46:23.641208 EDT | AverageEsReturn           16.678
2017-07-02 15:46:23.641428 EDT | StdEsReturn               23.2885
2017-07-02 15:46:23.642405 EDT | MaxEsReturn              143
2017-07-02 15:46:23.642554 EDT | MinEsReturn                3
2017-07-02 15:46:23.642783 EDT | AverageDiscountedReturn   39.7994
2017-07-02 15:46:23.643005 EDT | AverageQLoss               0.00303502
2017-07-02 15:46:23.643145 EDT | AveragePolicySurr         -0.983898
2017-07-02 15:46:23.643248 EDT | AverageQ                   0.940767
2017-07-02 15:46:23.643397 EDT | AverageAbsQ                0.943692
2017-07-02 15:46:23.643499 EDT | AverageY                   0.940768
2017-07-02 15:46:23.643697 EDT | AverageAbsY                0.941189
2017-07-02 15:46:23.643914 EDT | AverageAbsQYDiff           0.0146424
2017-07-02 15:46:23.644125 EDT | AverageAction              0.38943
2017-07-02 15:46:23.644352 EDT | PolicyRegParamNorm        67.3521
2017-07-02 15:46:23.644569 EDT | QFunRegParamNorm          65.5768
2017-07-02 15:46:23.644790 EDT | -----------------------  ------------
2017-07-02 15:46:23.645122 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #790 | Training started
2017-07-02 15:46:33.136909 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #790 | Training finished
2017-07-02 15:46:33.137473 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #790 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 15:46:33.137815 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #790 | Collecting samples for evaluation
2017-07-02 15:46:38.839291 EDT | -----------------------  ------------
2017-07-02 15:46:38.839633 EDT | Epoch                    790
2017-07-02 15:46:38.839815 EDT | Iteration                790
2017-07-02 15:46:38.839950 EDT | AverageReturn             48.2356
2017-07-02 15:46:38.840086 EDT | StdReturn                  0.712042
2017-07-02 15:46:38.840220 EDT | MaxReturn                 50
2017-07-02 15:46:38.840328 EDT | MinReturn                 46
2017-07-02 15:46:38.840477 EDT | AverageEsReturn           23.6829
2017-07-02 15:46:38.840670 EDT | StdEsReturn               22.5296
2017-07-02 15:46:38.840861 EDT | MaxEsReturn              107
2017-07-02 15:46:38.841050 EDT | MinEsReturn                3
2017-07-02 15:46:38.841203 EDT | AverageDiscountedReturn   38.4154
2017-07-02 15:46:38.841306 EDT | AverageQLoss               0.00296995
2017-07-02 15:46:38.841418 EDT | AveragePolicySurr         -0.98157
2017-07-02 15:46:38.841571 EDT | AverageQ                   0.937286
2017-07-02 15:46:38.841746 EDT | AverageAbsQ                0.939993
2017-07-02 15:46:38.841931 EDT | AverageY                   0.937294
2017-07-02 15:46:38.842041 EDT | AverageAbsY                0.937729
2017-07-02 15:46:38.842238 EDT | AverageAbsQYDiff           0.0140931
2017-07-02 15:46:38.842443 EDT | AverageAction              0.522117
2017-07-02 15:46:38.842647 EDT | PolicyRegParamNorm        67.3539
2017-07-02 15:46:38.842769 EDT | QFunRegParamNorm          65.6049
2017-07-02 15:46:38.842915 EDT | -----------------------  ------------
2017-07-02 15:46:38.843093 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #791 | Training started
2017-07-02 15:46:48.367090 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #791 | Training finished
2017-07-02 15:46:48.367697 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #791 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 15:46:48.367876 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #791 | Collecting samples for evaluation
2017-07-02 15:46:53.859463 EDT | -----------------------  -------------
2017-07-02 15:46:53.859738 EDT | Epoch                     791
2017-07-02 15:46:53.859975 EDT | Iteration                 791
2017-07-02 15:46:53.860154 EDT | AverageReturn            1000
2017-07-02 15:46:53.860382 EDT | StdReturn                   0
2017-07-02 15:46:53.860605 EDT | MaxReturn                1000
2017-07-02 15:46:53.860767 EDT | MinReturn                1000
2017-07-02 15:46:53.860999 EDT | AverageEsReturn            19.4444
2017-07-02 15:46:53.861180 EDT | StdEsReturn                20.0339
2017-07-02 15:46:53.861341 EDT | MaxEsReturn                90
2017-07-02 15:46:53.861711 EDT | MinEsReturn                 3
2017-07-02 15:46:53.861919 EDT | AverageDiscountedReturn    99.9957
2017-07-02 15:46:53.862150 EDT | AverageQLoss                0.00331566
2017-07-02 15:46:53.862332 EDT | AveragePolicySurr          -0.97978
2017-07-02 15:46:53.862565 EDT | AverageQ                    0.938475
2017-07-02 15:46:53.862752 EDT | AverageAbsQ                 0.941522
2017-07-02 15:46:53.862985 EDT | AverageY                    0.938432
2017-07-02 15:46:53.863194 EDT | AverageAbsY                 0.938942
2017-07-02 15:46:53.863302 EDT | AverageAbsQYDiff            0.0148968
2017-07-02 15:46:53.863404 EDT | AverageAction               0.0117626
2017-07-02 15:46:53.863549 EDT | PolicyRegParamNorm         67.3541
2017-07-02 15:46:53.863778 EDT | QFunRegParamNorm           65.6049
2017-07-02 15:46:53.863971 EDT | -----------------------  -------------
2017-07-02 15:46:53.864213 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #792 | Training started
2017-07-02 15:47:03.395664 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #792 | Training finished
2017-07-02 15:47:03.396260 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #792 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 15:47:03.396487 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #792 | Collecting samples for evaluation
2017-07-02 15:47:08.845308 EDT | -----------------------  -------------
2017-07-02 15:47:08.845507 EDT | Epoch                     792
2017-07-02 15:47:08.845620 EDT | Iteration                 792
2017-07-02 15:47:08.845909 EDT | AverageReturn            1000
2017-07-02 15:47:08.846045 EDT | StdReturn                   0
2017-07-02 15:47:08.846233 EDT | MaxReturn                1000
2017-07-02 15:47:08.846362 EDT | MinReturn                1000
2017-07-02 15:47:08.846511 EDT | AverageEsReturn            28.9697
2017-07-02 15:47:08.846665 EDT | StdEsReturn                21.3051
2017-07-02 15:47:08.846821 EDT | MaxEsReturn                85
2017-07-02 15:47:08.846970 EDT | MinEsReturn                 3
2017-07-02 15:47:08.847117 EDT | AverageDiscountedReturn    99.9957
2017-07-02 15:47:08.847258 EDT | AverageQLoss                0.00300509
2017-07-02 15:47:08.847446 EDT | AveragePolicySurr          -0.979456
2017-07-02 15:47:08.847582 EDT | AverageQ                    0.934745
2017-07-02 15:47:08.847710 EDT | AverageAbsQ                 0.937848
2017-07-02 15:47:08.847836 EDT | AverageY                    0.9347
2017-07-02 15:47:08.847966 EDT | AverageAbsY                 0.935099
2017-07-02 15:47:08.848168 EDT | AverageAbsQYDiff            0.0142402
2017-07-02 15:47:08.848332 EDT | AverageAction               0.0172494
2017-07-02 15:47:08.848478 EDT | PolicyRegParamNorm         67.3906
2017-07-02 15:47:08.848665 EDT | QFunRegParamNorm           65.6146
2017-07-02 15:47:08.848878 EDT | -----------------------  -------------
2017-07-02 15:47:08.849106 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #793 | Training started
2017-07-02 15:47:18.403030 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #793 | Training finished
2017-07-02 15:47:18.403635 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #793 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 15:47:18.403899 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #793 | Collecting samples for evaluation
2017-07-02 15:47:23.921764 EDT | -----------------------  -------------
2017-07-02 15:47:23.921996 EDT | Epoch                     793
2017-07-02 15:47:23.922105 EDT | Iteration                 793
2017-07-02 15:47:23.922285 EDT | AverageReturn            1000
2017-07-02 15:47:23.922430 EDT | StdReturn                   0
2017-07-02 15:47:23.922652 EDT | MaxReturn                1000
2017-07-02 15:47:23.922835 EDT | MinReturn                1000
2017-07-02 15:47:23.923006 EDT | AverageEsReturn            27.1053
2017-07-02 15:47:23.923191 EDT | StdEsReturn                23.1855
2017-07-02 15:47:23.923382 EDT | MaxEsReturn                97
2017-07-02 15:47:23.923534 EDT | MinEsReturn                 3
2017-07-02 15:47:23.923708 EDT | AverageDiscountedReturn    99.9957
2017-07-02 15:47:23.923901 EDT | AverageQLoss                0.00333287
2017-07-02 15:47:23.924092 EDT | AveragePolicySurr          -0.978133
2017-07-02 15:47:23.924276 EDT | AverageQ                    0.933271
2017-07-02 15:47:23.924471 EDT | AverageAbsQ                 0.936722
2017-07-02 15:47:23.924654 EDT | AverageY                    0.933208
2017-07-02 15:47:23.924871 EDT | AverageAbsY                 0.933796
2017-07-02 15:47:23.925078 EDT | AverageAbsQYDiff            0.0155449
2017-07-02 15:47:23.925305 EDT | AverageAction               0.00330529
2017-07-02 15:47:23.925484 EDT | PolicyRegParamNorm         67.4025
2017-07-02 15:47:23.925597 EDT | QFunRegParamNorm           65.6425
2017-07-02 15:47:23.925698 EDT | -----------------------  -------------
2017-07-02 15:47:23.925873 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #794 | Training started
2017-07-02 15:47:33.364754 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #794 | Training finished
2017-07-02 15:47:33.365359 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #794 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 15:47:33.365529 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #794 | Collecting samples for evaluation
2017-07-02 15:47:38.792389 EDT | -----------------------  ------------
2017-07-02 15:47:38.792675 EDT | Epoch                     794
2017-07-02 15:47:38.792911 EDT | Iteration                 794
2017-07-02 15:47:38.793136 EDT | AverageReturn            1000
2017-07-02 15:47:38.793358 EDT | StdReturn                   0
2017-07-02 15:47:38.793601 EDT | MaxReturn                1000
2017-07-02 15:47:38.793816 EDT | MinReturn                1000
2017-07-02 15:47:38.793998 EDT | AverageEsReturn            18.463
2017-07-02 15:47:38.794217 EDT | StdEsReturn                17.6842
2017-07-02 15:47:38.794435 EDT | MaxEsReturn                73
2017-07-02 15:47:38.794668 EDT | MinEsReturn                 3
2017-07-02 15:47:38.794889 EDT | AverageDiscountedReturn    99.9957
2017-07-02 15:47:38.795107 EDT | AverageQLoss                0.0034501
2017-07-02 15:47:38.795330 EDT | AveragePolicySurr          -0.976907
2017-07-02 15:47:38.795528 EDT | AverageQ                    0.931075
2017-07-02 15:47:38.795744 EDT | AverageAbsQ                 0.934292
2017-07-02 15:47:38.795937 EDT | AverageY                    0.93114
2017-07-02 15:47:38.796155 EDT | AverageAbsY                 0.931757
2017-07-02 15:47:38.796352 EDT | AverageAbsQYDiff            0.0153782
2017-07-02 15:47:38.796546 EDT | AverageAction               0.0117486
2017-07-02 15:47:38.796736 EDT | PolicyRegParamNorm         67.4498
2017-07-02 15:47:38.796943 EDT | QFunRegParamNorm           65.6813
2017-07-02 15:47:38.797157 EDT | -----------------------  ------------
2017-07-02 15:47:38.797462 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #795 | Training started
2017-07-02 15:47:48.179587 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #795 | Training finished
2017-07-02 15:47:48.180219 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #795 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 15:47:48.180454 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #795 | Collecting samples for evaluation
2017-07-02 15:47:53.633050 EDT | -----------------------  -------------
2017-07-02 15:47:53.633357 EDT | Epoch                     795
2017-07-02 15:47:53.633585 EDT | Iteration                 795
2017-07-02 15:47:53.633750 EDT | AverageReturn            1000
2017-07-02 15:47:53.634020 EDT | StdReturn                   0
2017-07-02 15:47:53.634302 EDT | MaxReturn                1000
2017-07-02 15:47:53.634510 EDT | MinReturn                1000
2017-07-02 15:47:53.634697 EDT | AverageEsReturn            16.9667
2017-07-02 15:47:53.634843 EDT | StdEsReturn                16.8037
2017-07-02 15:47:53.635079 EDT | MaxEsReturn                94
2017-07-02 15:47:53.635305 EDT | MinEsReturn                 3
2017-07-02 15:47:53.635528 EDT | AverageDiscountedReturn    99.9957
2017-07-02 15:47:53.635743 EDT | AverageQLoss                0.00306296
2017-07-02 15:47:53.635953 EDT | AveragePolicySurr          -0.974829
2017-07-02 15:47:53.636178 EDT | AverageQ                    0.931971
2017-07-02 15:47:53.636406 EDT | AverageAbsQ                 0.935107
2017-07-02 15:47:53.636649 EDT | AverageY                    0.931977
2017-07-02 15:47:53.636881 EDT | AverageAbsY                 0.932664
2017-07-02 15:47:53.637109 EDT | AverageAbsQYDiff            0.0137869
2017-07-02 15:47:53.637281 EDT | AverageAction               0.0151611
2017-07-02 15:47:53.637505 EDT | PolicyRegParamNorm         67.4457
2017-07-02 15:47:53.637696 EDT | QFunRegParamNorm           65.6968
2017-07-02 15:47:53.637913 EDT | -----------------------  -------------
2017-07-02 15:47:53.638218 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #796 | Training started
2017-07-02 15:48:03.050976 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #796 | Training finished
2017-07-02 15:48:03.051563 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #796 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 15:48:03.051792 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #796 | Collecting samples for evaluation
2017-07-02 15:48:08.963604 EDT | -----------------------  -----------
2017-07-02 15:48:08.963907 EDT | Epoch                    796
2017-07-02 15:48:08.964119 EDT | Iteration                796
2017-07-02 15:48:08.964341 EDT | AverageReturn             53.9839
2017-07-02 15:48:08.964545 EDT | StdReturn                  0.813038
2017-07-02 15:48:08.964766 EDT | MaxReturn                 55
2017-07-02 15:48:08.964991 EDT | MinReturn                 51
2017-07-02 15:48:08.965211 EDT | AverageEsReturn           17.1207
2017-07-02 15:48:08.965893 EDT | StdEsReturn               14.3324
2017-07-02 15:48:08.966135 EDT | MaxEsReturn               57
2017-07-02 15:48:08.966412 EDT | MinEsReturn                2
2017-07-02 15:48:08.966643 EDT | AverageDiscountedReturn   41.872
2017-07-02 15:48:08.966862 EDT | AverageQLoss               0.0036936
2017-07-02 15:48:08.967082 EDT | AveragePolicySurr         -0.975463
2017-07-02 15:48:08.967291 EDT | AverageQ                   0.930456
2017-07-02 15:48:08.967501 EDT | AverageAbsQ                0.933655
2017-07-02 15:48:08.967718 EDT | AverageY                   0.930427
2017-07-02 15:48:08.967919 EDT | AverageAbsY                0.930991
2017-07-02 15:48:08.968132 EDT | AverageAbsQYDiff           0.01604
2017-07-02 15:48:08.968344 EDT | AverageAction              0.333382
2017-07-02 15:48:08.968562 EDT | PolicyRegParamNorm        67.4935
2017-07-02 15:48:08.968730 EDT | QFunRegParamNorm          65.7003
2017-07-02 15:48:08.968946 EDT | -----------------------  -----------
2017-07-02 15:48:08.969234 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #797 | Training started
2017-07-02 15:48:18.625537 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #797 | Training finished
2017-07-02 15:48:18.626062 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #797 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 15:48:18.626238 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #797 | Collecting samples for evaluation
2017-07-02 15:48:24.188672 EDT | -----------------------  -------------
2017-07-02 15:48:24.188966 EDT | Epoch                     797
2017-07-02 15:48:24.189155 EDT | Iteration                 797
2017-07-02 15:48:24.189324 EDT | AverageReturn            1000
2017-07-02 15:48:24.189430 EDT | StdReturn                   0
2017-07-02 15:48:24.189569 EDT | MaxReturn                1000
2017-07-02 15:48:24.189693 EDT | MinReturn                1000
2017-07-02 15:48:24.189797 EDT | AverageEsReturn            17.3448
2017-07-02 15:48:24.189898 EDT | StdEsReturn                17.8543
2017-07-02 15:48:24.189997 EDT | MaxEsReturn                80
2017-07-02 15:48:24.190128 EDT | MinEsReturn                 3
2017-07-02 15:48:24.190246 EDT | AverageDiscountedReturn    99.9957
2017-07-02 15:48:24.190346 EDT | AverageQLoss                0.00343977
2017-07-02 15:48:24.190446 EDT | AveragePolicySurr          -0.976653
2017-07-02 15:48:24.190574 EDT | AverageQ                    0.93255
2017-07-02 15:48:24.190741 EDT | AverageAbsQ                 0.935806
2017-07-02 15:48:24.190898 EDT | AverageY                    0.932558
2017-07-02 15:48:24.191068 EDT | AverageAbsY                 0.932927
2017-07-02 15:48:24.191222 EDT | AverageAbsQYDiff            0.0156681
2017-07-02 15:48:24.191360 EDT | AverageAction               0.0111961
2017-07-02 15:48:24.191465 EDT | PolicyRegParamNorm         67.4763
2017-07-02 15:48:24.191566 EDT | QFunRegParamNorm           65.7439
2017-07-02 15:48:24.191729 EDT | -----------------------  -------------
2017-07-02 15:48:24.192020 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #798 | Training started
2017-07-02 15:48:33.492295 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #798 | Training finished
2017-07-02 15:48:33.492911 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #798 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 15:48:33.493168 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #798 | Collecting samples for evaluation
2017-07-02 15:48:39.023922 EDT | -----------------------  -------------
2017-07-02 15:48:39.024235 EDT | Epoch                     798
2017-07-02 15:48:39.024434 EDT | Iteration                 798
2017-07-02 15:48:39.024549 EDT | AverageReturn            1000
2017-07-02 15:48:39.024653 EDT | StdReturn                   0
2017-07-02 15:48:39.024754 EDT | MaxReturn                1000
2017-07-02 15:48:39.024854 EDT | MinReturn                1000
2017-07-02 15:48:39.025065 EDT | AverageEsReturn            19.2745
2017-07-02 15:48:39.025255 EDT | StdEsReturn                17.1865
2017-07-02 15:48:39.025477 EDT | MaxEsReturn                75
2017-07-02 15:48:39.025693 EDT | MinEsReturn                 3
2017-07-02 15:48:39.025799 EDT | AverageDiscountedReturn    99.9957
2017-07-02 15:48:39.025902 EDT | AverageQLoss                0.00301611
2017-07-02 15:48:39.026004 EDT | AveragePolicySurr          -0.976766
2017-07-02 15:48:39.026102 EDT | AverageQ                    0.933802
2017-07-02 15:48:39.026203 EDT | AverageAbsQ                 0.93641
2017-07-02 15:48:39.026299 EDT | AverageY                    0.933815
2017-07-02 15:48:39.026396 EDT | AverageAbsY                 0.93435
2017-07-02 15:48:39.026510 EDT | AverageAbsQYDiff            0.0138132
2017-07-02 15:48:39.026639 EDT | AverageAction               0.0316759
2017-07-02 15:48:39.026740 EDT | PolicyRegParamNorm         67.5063
2017-07-02 15:48:39.026839 EDT | QFunRegParamNorm           65.7677
2017-07-02 15:48:39.026939 EDT | -----------------------  -------------
2017-07-02 15:48:39.027214 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #799 | Training started
2017-07-02 15:48:48.347007 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #799 | Training finished
2017-07-02 15:48:48.347210 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #799 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 15:48:48.347337 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #799 | Collecting samples for evaluation
2017-07-02 15:48:53.807433 EDT | -----------------------  -------------
2017-07-02 15:48:53.808022 EDT | Epoch                     799
2017-07-02 15:48:53.808189 EDT | Iteration                 799
2017-07-02 15:48:53.808380 EDT | AverageReturn            1000
2017-07-02 15:48:53.808497 EDT | StdReturn                   0
2017-07-02 15:48:53.808605 EDT | MaxReturn                1000
2017-07-02 15:48:53.808707 EDT | MinReturn                1000
2017-07-02 15:48:53.808811 EDT | AverageEsReturn            20.32
2017-07-02 15:48:53.809021 EDT | StdEsReturn                28.3552
2017-07-02 15:48:53.809218 EDT | MaxEsReturn               132
2017-07-02 15:48:53.809368 EDT | MinEsReturn                 3
2017-07-02 15:48:53.809607 EDT | AverageDiscountedReturn    99.9957
2017-07-02 15:48:53.810329 EDT | AverageQLoss                0.00358809
2017-07-02 15:48:53.810482 EDT | AveragePolicySurr          -0.975099
2017-07-02 15:48:53.810642 EDT | AverageQ                    0.931677
2017-07-02 15:48:53.810803 EDT | AverageAbsQ                 0.934788
2017-07-02 15:48:53.810997 EDT | AverageY                    0.931651
2017-07-02 15:48:53.811162 EDT | AverageAbsY                 0.932167
2017-07-02 15:48:53.811271 EDT | AverageAbsQYDiff            0.015014
2017-07-02 15:48:53.811373 EDT | AverageAction               0.0187009
2017-07-02 15:48:53.811513 EDT | PolicyRegParamNorm         67.5372
2017-07-02 15:48:53.811705 EDT | QFunRegParamNorm           65.7859
2017-07-02 15:48:53.811899 EDT | -----------------------  -------------
2017-07-02 15:48:53.812175 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #800 | Training started
2017-07-02 15:49:03.141699 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #800 | Training finished
2017-07-02 15:49:03.142228 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #800 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 15:49:03.142403 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #800 | Collecting samples for evaluation
2017-07-02 15:49:08.587830 EDT | -----------------------  -------------
2017-07-02 15:49:08.588038 EDT | Epoch                     800
2017-07-02 15:49:08.588173 EDT | Iteration                 800
2017-07-02 15:49:08.588300 EDT | AverageReturn            1000
2017-07-02 15:49:08.588430 EDT | StdReturn                   0
2017-07-02 15:49:08.588535 EDT | MaxReturn                1000
2017-07-02 15:49:08.588645 EDT | MinReturn                1000
2017-07-02 15:49:08.588769 EDT | AverageEsReturn            18.0189
2017-07-02 15:49:08.588968 EDT | StdEsReturn                18.415
2017-07-02 15:49:08.589152 EDT | MaxEsReturn                91
2017-07-02 15:49:08.589329 EDT | MinEsReturn                 3
2017-07-02 15:49:08.589473 EDT | AverageDiscountedReturn    99.9957
2017-07-02 15:49:08.590223 EDT | AverageQLoss                0.00315678
2017-07-02 15:49:08.590366 EDT | AveragePolicySurr          -0.975618
2017-07-02 15:49:08.590562 EDT | AverageQ                    0.9297
2017-07-02 15:49:08.590685 EDT | AverageAbsQ                 0.933073
2017-07-02 15:49:08.590792 EDT | AverageY                    0.929707
2017-07-02 15:49:08.591477 EDT | AverageAbsY                 0.930007
2017-07-02 15:49:08.592150 EDT | AverageAbsQYDiff            0.0154378
2017-07-02 15:49:08.592294 EDT | AverageAction               0.0106291
2017-07-02 15:49:08.592402 EDT | PolicyRegParamNorm         67.5479
2017-07-02 15:49:08.592505 EDT | QFunRegParamNorm           65.841
2017-07-02 15:49:08.592651 EDT | -----------------------  -------------
2017-07-02 15:49:08.592817 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #801 | Training started
2017-07-02 15:49:17.985424 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #801 | Training finished
2017-07-02 15:49:17.985974 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #801 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 15:49:17.986484 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #801 | Collecting samples for evaluation
2017-07-02 15:49:23.615167 EDT | -----------------------  -------------
2017-07-02 15:49:23.615457 EDT | Epoch                     801
2017-07-02 15:49:23.615686 EDT | Iteration                 801
2017-07-02 15:49:23.615895 EDT | AverageReturn             364.071
2017-07-02 15:49:23.616120 EDT | StdReturn                 437.702
2017-07-02 15:49:23.616338 EDT | MaxReturn                1000
2017-07-02 15:49:23.616549 EDT | MinReturn                  59
2017-07-02 15:49:23.616764 EDT | AverageEsReturn            18.0345
2017-07-02 15:49:23.616973 EDT | StdEsReturn                12.9867
2017-07-02 15:49:23.617202 EDT | MaxEsReturn                49
2017-07-02 15:49:23.617406 EDT | MinEsReturn                 3
2017-07-02 15:49:23.617693 EDT | AverageDiscountedReturn    63.8591
2017-07-02 15:49:23.617899 EDT | AverageQLoss                0.00289647
2017-07-02 15:49:23.618120 EDT | AveragePolicySurr          -0.975517
2017-07-02 15:49:23.618345 EDT | AverageQ                    0.930851
2017-07-02 15:49:23.618575 EDT | AverageAbsQ                 0.934081
2017-07-02 15:49:23.618783 EDT | AverageY                    0.930841
2017-07-02 15:49:23.619004 EDT | AverageAbsY                 0.931106
2017-07-02 15:49:23.619226 EDT | AverageAbsQYDiff            0.0148414
2017-07-02 15:49:23.619381 EDT | AverageAction               0.3005
2017-07-02 15:49:23.619597 EDT | PolicyRegParamNorm         67.5534
2017-07-02 15:49:23.619803 EDT | QFunRegParamNorm           65.8493
2017-07-02 15:49:23.620026 EDT | -----------------------  -------------
2017-07-02 15:49:23.620340 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #802 | Training started
2017-07-02 15:49:32.910375 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #802 | Training finished
2017-07-02 15:49:32.911053 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #802 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 15:49:32.911305 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #802 | Collecting samples for evaluation
2017-07-02 15:49:38.665430 EDT | -----------------------  -------------
2017-07-02 15:49:38.665637 EDT | Epoch                     802
2017-07-02 15:49:38.665750 EDT | Iteration                 802
2017-07-02 15:49:38.665856 EDT | AverageReturn            1000
2017-07-02 15:49:38.665958 EDT | StdReturn                   0
2017-07-02 15:49:38.666058 EDT | MaxReturn                1000
2017-07-02 15:49:38.666159 EDT | MinReturn                1000
2017-07-02 15:49:38.666294 EDT | AverageEsReturn            16.3607
2017-07-02 15:49:38.666446 EDT | StdEsReturn                15.2681
2017-07-02 15:49:38.666557 EDT | MaxEsReturn                73
2017-07-02 15:49:38.666699 EDT | MinEsReturn                 3
2017-07-02 15:49:38.666892 EDT | AverageDiscountedReturn    99.9957
2017-07-02 15:49:38.667046 EDT | AverageQLoss                0.00333361
2017-07-02 15:49:38.667206 EDT | AveragePolicySurr          -0.975786
2017-07-02 15:49:38.667384 EDT | AverageQ                    0.932758
2017-07-02 15:49:38.667488 EDT | AverageAbsQ                 0.935604
2017-07-02 15:49:38.667658 EDT | AverageY                    0.932759
2017-07-02 15:49:38.667761 EDT | AverageAbsY                 0.933074
2017-07-02 15:49:38.667952 EDT | AverageAbsQYDiff            0.0148544
2017-07-02 15:49:38.668143 EDT | AverageAction               0.00572751
2017-07-02 15:49:38.668285 EDT | PolicyRegParamNorm         67.5623
2017-07-02 15:49:38.668386 EDT | QFunRegParamNorm           65.8622
2017-07-02 15:49:38.668503 EDT | -----------------------  -------------
2017-07-02 15:49:38.668898 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #803 | Training started
2017-07-02 15:49:47.830487 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #803 | Training finished
2017-07-02 15:49:47.831219 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #803 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 15:49:47.831520 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #803 | Collecting samples for evaluation
2017-07-02 15:49:53.409366 EDT | -----------------------  -------------
2017-07-02 15:49:53.409605 EDT | Epoch                     803
2017-07-02 15:49:53.409747 EDT | Iteration                 803
2017-07-02 15:49:53.409884 EDT | AverageReturn            1000
2017-07-02 15:49:53.410058 EDT | StdReturn                   0
2017-07-02 15:49:53.410239 EDT | MaxReturn                1000
2017-07-02 15:49:53.410343 EDT | MinReturn                1000
2017-07-02 15:49:53.410468 EDT | AverageEsReturn            15.6094
2017-07-02 15:49:53.410617 EDT | StdEsReturn                14.166
2017-07-02 15:49:53.410719 EDT | MaxEsReturn                57
2017-07-02 15:49:53.410819 EDT | MinEsReturn                 3
2017-07-02 15:49:53.411011 EDT | AverageDiscountedReturn    99.9957
2017-07-02 15:49:53.411205 EDT | AverageQLoss                0.00349895
2017-07-02 15:49:53.411346 EDT | AveragePolicySurr          -0.973039
2017-07-02 15:49:53.411467 EDT | AverageQ                    0.927129
2017-07-02 15:49:53.411570 EDT | AverageAbsQ                 0.929996
2017-07-02 15:49:53.411706 EDT | AverageY                    0.927088
2017-07-02 15:49:53.411809 EDT | AverageAbsY                 0.927338
2017-07-02 15:49:53.411908 EDT | AverageAbsQYDiff            0.0155192
2017-07-02 15:49:53.412007 EDT | AverageAction               0.0126747
2017-07-02 15:49:53.412136 EDT | PolicyRegParamNorm         67.5726
2017-07-02 15:49:53.412293 EDT | QFunRegParamNorm           65.9136
2017-07-02 15:49:53.412416 EDT | -----------------------  -------------
2017-07-02 15:49:53.412607 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #804 | Training started
2017-07-02 15:50:02.598464 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #804 | Training finished
2017-07-02 15:50:02.598965 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #804 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 15:50:02.599099 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #804 | Collecting samples for evaluation
2017-07-02 15:50:08.268646 EDT | -----------------------  ------------
2017-07-02 15:50:08.268933 EDT | Epoch                    804
2017-07-02 15:50:08.269074 EDT | Iteration                804
2017-07-02 15:50:08.269180 EDT | AverageReturn             60.5663
2017-07-02 15:50:08.269282 EDT | StdReturn                  5.29308
2017-07-02 15:50:08.269411 EDT | MaxReturn                 88
2017-07-02 15:50:08.269558 EDT | MinReturn                 52
2017-07-02 15:50:08.269786 EDT | AverageEsReturn           18.3396
2017-07-02 15:50:08.270006 EDT | StdEsReturn               15.2933
2017-07-02 15:50:08.270121 EDT | MaxEsReturn               83
2017-07-02 15:50:08.270234 EDT | MinEsReturn                3
2017-07-02 15:50:08.270377 EDT | AverageDiscountedReturn   45.5202
2017-07-02 15:50:08.270495 EDT | AverageQLoss               0.00296299
2017-07-02 15:50:08.270609 EDT | AveragePolicySurr         -0.974922
2017-07-02 15:50:08.270710 EDT | AverageQ                   0.930344
2017-07-02 15:50:08.270876 EDT | AverageAbsQ                0.932844
2017-07-02 15:50:08.271027 EDT | AverageY                   0.930404
2017-07-02 15:50:08.271134 EDT | AverageAbsY                0.930583
2017-07-02 15:50:08.271315 EDT | AverageAbsQYDiff           0.0143789
2017-07-02 15:50:08.271488 EDT | AverageAction              0.376534
2017-07-02 15:50:08.271619 EDT | PolicyRegParamNorm        67.6498
2017-07-02 15:50:08.271727 EDT | QFunRegParamNorm          65.935
2017-07-02 15:50:08.271827 EDT | -----------------------  ------------
2017-07-02 15:50:08.272012 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #805 | Training started
2017-07-02 15:50:17.693923 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #805 | Training finished
2017-07-02 15:50:17.694560 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #805 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 15:50:17.694821 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #805 | Collecting samples for evaluation
2017-07-02 15:50:23.567674 EDT | -----------------------  -------------
2017-07-02 15:50:23.567955 EDT | Epoch                     805
2017-07-02 15:50:23.568152 EDT | Iteration                 805
2017-07-02 15:50:23.568356 EDT | AverageReturn            1000
2017-07-02 15:50:23.568517 EDT | StdReturn                   0
2017-07-02 15:50:23.568647 EDT | MaxReturn                1000
2017-07-02 15:50:23.568821 EDT | MinReturn                1000
2017-07-02 15:50:23.569006 EDT | AverageEsReturn            16.5484
2017-07-02 15:50:23.569200 EDT | StdEsReturn                19.3021
2017-07-02 15:50:23.569325 EDT | MaxEsReturn               125
2017-07-02 15:50:23.569453 EDT | MinEsReturn                 3
2017-07-02 15:50:23.569598 EDT | AverageDiscountedReturn    99.9957
2017-07-02 15:50:23.569727 EDT | AverageQLoss                0.00277963
2017-07-02 15:50:23.569829 EDT | AveragePolicySurr          -0.974961
2017-07-02 15:50:23.569945 EDT | AverageQ                    0.929086
2017-07-02 15:50:23.570121 EDT | AverageAbsQ                 0.931724
2017-07-02 15:50:23.570304 EDT | AverageY                    0.929095
2017-07-02 15:50:23.570451 EDT | AverageAbsY                 0.929295
2017-07-02 15:50:23.570615 EDT | AverageAbsQYDiff            0.0138785
2017-07-02 15:50:23.570796 EDT | AverageAction               0.00715892
2017-07-02 15:50:23.570913 EDT | PolicyRegParamNorm         67.6601
2017-07-02 15:50:23.571071 EDT | QFunRegParamNorm           65.9562
2017-07-02 15:50:23.571244 EDT | -----------------------  -------------
2017-07-02 15:50:23.571489 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #806 | Training started
2017-07-02 15:50:33.081726 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #806 | Training finished
2017-07-02 15:50:33.082232 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #806 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 15:50:33.082481 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #806 | Collecting samples for evaluation
2017-07-02 15:50:38.607235 EDT | -----------------------  -------------
2017-07-02 15:50:38.607436 EDT | Epoch                     806
2017-07-02 15:50:38.607549 EDT | Iteration                 806
2017-07-02 15:50:38.607696 EDT | AverageReturn            1000
2017-07-02 15:50:38.607801 EDT | StdReturn                   0
2017-07-02 15:50:38.607906 EDT | MaxReturn                1000
2017-07-02 15:50:38.608067 EDT | MinReturn                1000
2017-07-02 15:50:38.608175 EDT | AverageEsReturn            15.1364
2017-07-02 15:50:38.608302 EDT | StdEsReturn                14.0226
2017-07-02 15:50:38.608449 EDT | MaxEsReturn                92
2017-07-02 15:50:38.608564 EDT | MinEsReturn                 3
2017-07-02 15:50:38.608729 EDT | AverageDiscountedReturn    99.9957
2017-07-02 15:50:38.608851 EDT | AverageQLoss                0.00306862
2017-07-02 15:50:38.608952 EDT | AveragePolicySurr          -0.976865
2017-07-02 15:50:38.609052 EDT | AverageQ                    0.932288
2017-07-02 15:50:38.609152 EDT | AverageAbsQ                 0.935317
2017-07-02 15:50:38.609278 EDT | AverageY                    0.932229
2017-07-02 15:50:38.609378 EDT | AverageAbsY                 0.932605
2017-07-02 15:50:38.609477 EDT | AverageAbsQYDiff            0.0147205
2017-07-02 15:50:38.609593 EDT | AverageAction               0.0131544
2017-07-02 15:50:38.609709 EDT | PolicyRegParamNorm         67.6959
2017-07-02 15:50:38.609838 EDT | QFunRegParamNorm           65.9751
2017-07-02 15:50:38.609938 EDT | -----------------------  -------------
2017-07-02 15:50:38.610098 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #807 | Training started
2017-07-02 15:50:48.052874 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #807 | Training finished
2017-07-02 15:50:48.053391 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #807 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 15:50:48.053569 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #807 | Collecting samples for evaluation
2017-07-02 15:50:53.797374 EDT | -----------------------  ------------
2017-07-02 15:50:53.797657 EDT | Epoch                     807
2017-07-02 15:50:53.797859 EDT | Iteration                 807
2017-07-02 15:50:53.798069 EDT | AverageReturn             611.412
2017-07-02 15:50:53.798290 EDT | StdReturn                 464.464
2017-07-02 15:50:53.798509 EDT | MaxReturn                1000
2017-07-02 15:50:53.798645 EDT | MinReturn                  50
2017-07-02 15:50:53.798749 EDT | AverageEsReturn            17.9818
2017-07-02 15:50:53.798850 EDT | StdEsReturn                17.8585
2017-07-02 15:50:53.799051 EDT | MaxEsReturn                70
2017-07-02 15:50:53.799250 EDT | MinEsReturn                 3
2017-07-02 15:50:53.799478 EDT | AverageDiscountedReturn    76.5779
2017-07-02 15:50:53.799681 EDT | AverageQLoss                0.0034569
2017-07-02 15:50:53.799903 EDT | AveragePolicySurr          -0.976737
2017-07-02 15:50:53.800121 EDT | AverageQ                    0.932346
2017-07-02 15:50:53.800339 EDT | AverageAbsQ                 0.935347
2017-07-02 15:50:53.800552 EDT | AverageY                    0.932337
2017-07-02 15:50:53.800711 EDT | AverageAbsY                 0.93272
2017-07-02 15:50:53.800816 EDT | AverageAbsQYDiff            0.0158942
2017-07-02 15:50:53.801025 EDT | AverageAction               0.0377528
2017-07-02 15:50:53.801214 EDT | PolicyRegParamNorm         67.7765
2017-07-02 15:50:53.801320 EDT | QFunRegParamNorm           65.9882
2017-07-02 15:50:53.801421 EDT | -----------------------  ------------
2017-07-02 15:50:53.801677 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #808 | Training started
2017-07-02 15:51:03.110467 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #808 | Training finished
2017-07-02 15:51:03.111069 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #808 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 15:51:03.111300 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #808 | Collecting samples for evaluation
2017-07-02 15:51:08.528533 EDT | -----------------------  -------------
2017-07-02 15:51:08.529097 EDT | Epoch                     808
2017-07-02 15:51:08.529388 EDT | Iteration                 808
2017-07-02 15:51:08.529682 EDT | AverageReturn            1000
2017-07-02 15:51:08.529914 EDT | StdReturn                   0
2017-07-02 15:51:08.530131 EDT | MaxReturn                1000
2017-07-02 15:51:08.530363 EDT | MinReturn                1000
2017-07-02 15:51:08.530601 EDT | AverageEsReturn            13.0128
2017-07-02 15:51:08.530760 EDT | StdEsReturn                11.436
2017-07-02 15:51:08.530935 EDT | MaxEsReturn                56
2017-07-02 15:51:08.531068 EDT | MinEsReturn                 3
2017-07-02 15:51:08.531176 EDT | AverageDiscountedReturn    99.9957
2017-07-02 15:51:08.531286 EDT | AverageQLoss                0.00350267
2017-07-02 15:51:08.531416 EDT | AveragePolicySurr          -0.976758
2017-07-02 15:51:08.531522 EDT | AverageQ                    0.930324
2017-07-02 15:51:08.531626 EDT | AverageAbsQ                 0.933276
2017-07-02 15:51:08.531744 EDT | AverageY                    0.930292
2017-07-02 15:51:08.531880 EDT | AverageAbsY                 0.930759
2017-07-02 15:51:08.532019 EDT | AverageAbsQYDiff            0.0159797
2017-07-02 15:51:08.532125 EDT | AverageAction               0.015925
2017-07-02 15:51:08.532245 EDT | PolicyRegParamNorm         67.7551
2017-07-02 15:51:08.532389 EDT | QFunRegParamNorm           66.0149
2017-07-02 15:51:08.532500 EDT | -----------------------  -------------
2017-07-02 15:51:08.532675 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #809 | Training started
2017-07-02 15:51:17.978647 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #809 | Training finished
2017-07-02 15:51:17.979215 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #809 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 15:51:17.979447 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #809 | Collecting samples for evaluation
2017-07-02 15:51:23.497437 EDT | -----------------------  -------------
2017-07-02 15:51:23.497676 EDT | Epoch                     809
2017-07-02 15:51:23.497790 EDT | Iteration                 809
2017-07-02 15:51:23.497896 EDT | AverageReturn            1000
2017-07-02 15:51:23.498002 EDT | StdReturn                   0
2017-07-02 15:51:23.498157 EDT | MaxReturn                1000
2017-07-02 15:51:23.498270 EDT | MinReturn                1000
2017-07-02 15:51:23.498379 EDT | AverageEsReturn            12.9351
2017-07-02 15:51:23.498524 EDT | StdEsReturn                11.8237
2017-07-02 15:51:23.498704 EDT | MaxEsReturn                54
2017-07-02 15:51:23.498880 EDT | MinEsReturn                 3
2017-07-02 15:51:23.499093 EDT | AverageDiscountedReturn    99.9957
2017-07-02 15:51:23.499314 EDT | AverageQLoss                0.00346961
2017-07-02 15:51:23.499516 EDT | AveragePolicySurr          -0.976552
2017-07-02 15:51:23.499646 EDT | AverageQ                    0.932804
2017-07-02 15:51:23.499755 EDT | AverageAbsQ                 0.935628
2017-07-02 15:51:23.499876 EDT | AverageY                    0.932819
2017-07-02 15:51:23.500048 EDT | AverageAbsY                 0.933424
2017-07-02 15:51:23.500235 EDT | AverageAbsQYDiff            0.0152414
2017-07-02 15:51:23.500424 EDT | AverageAction               0.00825708
2017-07-02 15:51:23.500535 EDT | PolicyRegParamNorm         67.7526
2017-07-02 15:51:23.500642 EDT | QFunRegParamNorm           66.0461
2017-07-02 15:51:23.500748 EDT | -----------------------  -------------
2017-07-02 15:51:23.500916 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #810 | Training started
2017-07-02 15:51:32.930808 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #810 | Training finished
2017-07-02 15:51:32.931325 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #810 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 15:51:32.931495 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #810 | Collecting samples for evaluation
2017-07-02 15:51:38.575926 EDT | -----------------------  ------------
2017-07-02 15:51:38.576153 EDT | Epoch                    810
2017-07-02 15:51:38.576270 EDT | Iteration                810
2017-07-02 15:51:38.576409 EDT | AverageReturn             48.9463
2017-07-02 15:51:38.576514 EDT | StdReturn                  0.706795
2017-07-02 15:51:38.576663 EDT | MaxReturn                 51
2017-07-02 15:51:38.576831 EDT | MinReturn                 48
2017-07-02 15:51:38.576958 EDT | AverageEsReturn           12.3333
2017-07-02 15:51:38.577103 EDT | StdEsReturn               12.0851
2017-07-02 15:51:38.577238 EDT | MaxEsReturn               68
2017-07-02 15:51:38.577339 EDT | MinEsReturn                3
2017-07-02 15:51:38.577516 EDT | AverageDiscountedReturn   38.8538
2017-07-02 15:51:38.577629 EDT | AverageQLoss               0.00279869
2017-07-02 15:51:38.577736 EDT | AveragePolicySurr         -0.977729
2017-07-02 15:51:38.577891 EDT | AverageQ                   0.930732
2017-07-02 15:51:38.578011 EDT | AverageAbsQ                0.9338
2017-07-02 15:51:38.578140 EDT | AverageY                   0.930809
2017-07-02 15:51:38.578245 EDT | AverageAbsY                0.931443
2017-07-02 15:51:38.578346 EDT | AverageAbsQYDiff           0.0143713
2017-07-02 15:51:38.578447 EDT | AverageAction              0.30261
2017-07-02 15:51:38.578656 EDT | PolicyRegParamNorm        67.8151
2017-07-02 15:51:38.578861 EDT | QFunRegParamNorm          66.0633
2017-07-02 15:51:38.578980 EDT | -----------------------  ------------
2017-07-02 15:51:38.579159 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #811 | Training started
2017-07-02 15:51:48.051421 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #811 | Training finished
2017-07-02 15:51:48.051969 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #811 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 15:51:48.052141 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #811 | Collecting samples for evaluation
2017-07-02 15:51:53.446808 EDT | -----------------------  -------------
2017-07-02 15:51:53.447026 EDT | Epoch                     811
2017-07-02 15:51:53.447143 EDT | Iteration                 811
2017-07-02 15:51:53.447252 EDT | AverageReturn            1000
2017-07-02 15:51:53.447448 EDT | StdReturn                   0
2017-07-02 15:51:53.447662 EDT | MaxReturn                1000
2017-07-02 15:51:53.447880 EDT | MinReturn                1000
2017-07-02 15:51:53.448097 EDT | AverageEsReturn            12.0723
2017-07-02 15:51:53.448297 EDT | StdEsReturn                 9.50812
2017-07-02 15:51:53.448403 EDT | MaxEsReturn                52
2017-07-02 15:51:53.448506 EDT | MinEsReturn                 3
2017-07-02 15:51:53.448606 EDT | AverageDiscountedReturn    99.9957
2017-07-02 15:51:53.448705 EDT | AverageQLoss                0.003552
2017-07-02 15:51:53.448903 EDT | AveragePolicySurr          -0.979624
2017-07-02 15:51:53.449123 EDT | AverageQ                    0.932535
2017-07-02 15:51:53.449318 EDT | AverageAbsQ                 0.93548
2017-07-02 15:51:53.449475 EDT | AverageY                    0.932545
2017-07-02 15:51:53.449791 EDT | AverageAbsY                 0.933171
2017-07-02 15:51:53.449988 EDT | AverageAbsQYDiff            0.0151578
2017-07-02 15:51:53.450193 EDT | AverageAction               0.00721352
2017-07-02 15:51:53.450383 EDT | PolicyRegParamNorm         67.8027
2017-07-02 15:51:53.450579 EDT | QFunRegParamNorm           66.0868
2017-07-02 15:51:53.450772 EDT | -----------------------  -------------
2017-07-02 15:51:53.450940 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #812 | Training started
2017-07-02 15:52:02.794360 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #812 | Training finished
2017-07-02 15:52:02.794963 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #812 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 15:52:02.795300 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #812 | Collecting samples for evaluation
2017-07-02 15:52:08.289327 EDT | -----------------------  -------------
2017-07-02 15:52:08.289538 EDT | Epoch                     812
2017-07-02 15:52:08.289729 EDT | Iteration                 812
2017-07-02 15:52:08.289933 EDT | AverageReturn            1000
2017-07-02 15:52:08.290129 EDT | StdReturn                   0
2017-07-02 15:52:08.290325 EDT | MaxReturn                1000
2017-07-02 15:52:08.290498 EDT | MinReturn                1000
2017-07-02 15:52:08.290658 EDT | AverageEsReturn            12.0361
2017-07-02 15:52:08.290867 EDT | StdEsReturn                 9.93405
2017-07-02 15:52:08.291044 EDT | MaxEsReturn                41
2017-07-02 15:52:08.291213 EDT | MinEsReturn                 3
2017-07-02 15:52:08.291402 EDT | AverageDiscountedReturn    99.9957
2017-07-02 15:52:08.291534 EDT | AverageQLoss                0.00318766
2017-07-02 15:52:08.291646 EDT | AveragePolicySurr          -0.981596
2017-07-02 15:52:08.291798 EDT | AverageQ                    0.934826
2017-07-02 15:52:08.291923 EDT | AverageAbsQ                 0.937833
2017-07-02 15:52:08.292024 EDT | AverageY                    0.934718
2017-07-02 15:52:08.292177 EDT | AverageAbsY                 0.935249
2017-07-02 15:52:08.292309 EDT | AverageAbsQYDiff            0.0149838
2017-07-02 15:52:08.292459 EDT | AverageAction               0.0170562
2017-07-02 15:52:08.292645 EDT | PolicyRegParamNorm         67.8494
2017-07-02 15:52:08.292813 EDT | QFunRegParamNorm           66.1013
2017-07-02 15:52:08.292916 EDT | -----------------------  -------------
2017-07-02 15:52:08.293093 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #813 | Training started
2017-07-02 15:52:17.597035 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #813 | Training finished
2017-07-02 15:52:17.597580 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #813 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 15:52:17.597727 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #813 | Collecting samples for evaluation
2017-07-02 15:52:23.447340 EDT | -----------------------  -------------
2017-07-02 15:52:23.447616 EDT | Epoch                     813
2017-07-02 15:52:23.447765 EDT | Iteration                 813
2017-07-02 15:52:23.447958 EDT | AverageReturn             561.632
2017-07-02 15:52:23.448128 EDT | StdReturn                 462.114
2017-07-02 15:52:23.448327 EDT | MaxReturn                1000
2017-07-02 15:52:23.448453 EDT | MinReturn                  57
2017-07-02 15:52:23.448556 EDT | AverageEsReturn            14.1714
2017-07-02 15:52:23.448691 EDT | StdEsReturn                13.3993
2017-07-02 15:52:23.448825 EDT | MaxEsReturn                66
2017-07-02 15:52:23.449009 EDT | MinEsReturn                 3
2017-07-02 15:52:23.449112 EDT | AverageDiscountedReturn    77.5317
2017-07-02 15:52:23.449239 EDT | AverageQLoss                0.00304644
2017-07-02 15:52:23.449349 EDT | AveragePolicySurr          -0.984839
2017-07-02 15:52:23.449473 EDT | AverageQ                    0.938811
2017-07-02 15:52:23.449663 EDT | AverageAbsQ                 0.941613
2017-07-02 15:52:23.449852 EDT | AverageY                    0.938922
2017-07-02 15:52:23.450107 EDT | AverageAbsY                 0.939273
2017-07-02 15:52:23.450285 EDT | AverageAbsQYDiff            0.0147645
2017-07-02 15:52:23.450498 EDT | AverageAction               0.0391643
2017-07-02 15:52:23.450617 EDT | PolicyRegParamNorm         67.953
2017-07-02 15:52:23.450720 EDT | QFunRegParamNorm           66.1199
2017-07-02 15:52:23.450858 EDT | -----------------------  -------------
2017-07-02 15:52:23.451132 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #814 | Training started
2017-07-02 15:52:32.885347 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #814 | Training finished
2017-07-02 15:52:32.885894 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #814 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 15:52:32.886034 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #814 | Collecting samples for evaluation
2017-07-02 15:52:38.618232 EDT | -----------------------  ------------
2017-07-02 15:52:38.618422 EDT | Epoch                    814
2017-07-02 15:52:38.618533 EDT | Iteration                814
2017-07-02 15:52:38.618635 EDT | AverageReturn             44.8036
2017-07-02 15:52:38.618737 EDT | StdReturn                  0.397296
2017-07-02 15:52:38.618840 EDT | MaxReturn                 45
2017-07-02 15:52:38.619023 EDT | MinReturn                 44
2017-07-02 15:52:38.619127 EDT | AverageEsReturn           12.9744
2017-07-02 15:52:38.619275 EDT | StdEsReturn               12.4499
2017-07-02 15:52:38.619396 EDT | MaxEsReturn               68
2017-07-02 15:52:38.619546 EDT | MinEsReturn                3
2017-07-02 15:52:38.619648 EDT | AverageDiscountedReturn   36.2552
2017-07-02 15:52:38.619747 EDT | AverageQLoss               0.00229744
2017-07-02 15:52:38.619846 EDT | AveragePolicySurr         -0.988024
2017-07-02 15:52:38.619973 EDT | AverageQ                   0.94107
2017-07-02 15:52:38.620079 EDT | AverageAbsQ                0.943552
2017-07-02 15:52:38.620221 EDT | AverageY                   0.941033
2017-07-02 15:52:38.620329 EDT | AverageAbsY                0.941402
2017-07-02 15:52:38.620442 EDT | AverageAbsQYDiff           0.0129464
2017-07-02 15:52:38.620553 EDT | AverageAction              0.306298
2017-07-02 15:52:38.620652 EDT | PolicyRegParamNorm        68.0261
2017-07-02 15:52:38.620750 EDT | QFunRegParamNorm          66.1384
2017-07-02 15:52:38.620848 EDT | -----------------------  ------------
2017-07-02 15:52:38.621057 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #815 | Training started
2017-07-02 15:52:48.055933 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #815 | Training finished
2017-07-02 15:52:48.056595 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #815 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 15:52:48.056792 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #815 | Collecting samples for evaluation
2017-07-02 15:52:53.499600 EDT | -----------------------  -------------
2017-07-02 15:52:53.499925 EDT | Epoch                     815
2017-07-02 15:52:53.500122 EDT | Iteration                 815
2017-07-02 15:52:53.500274 EDT | AverageReturn            1000
2017-07-02 15:52:53.500384 EDT | StdReturn                   0
2017-07-02 15:52:53.500490 EDT | MaxReturn                1000
2017-07-02 15:52:53.500669 EDT | MinReturn                1000
2017-07-02 15:52:53.500893 EDT | AverageEsReturn            14.6269
2017-07-02 15:52:53.501120 EDT | StdEsReturn                13.2978
2017-07-02 15:52:53.501363 EDT | MaxEsReturn                64
2017-07-02 15:52:53.501652 EDT | MinEsReturn                 3
2017-07-02 15:52:53.501935 EDT | AverageDiscountedReturn    99.9957
2017-07-02 15:52:53.502153 EDT | AverageQLoss                0.00414757
2017-07-02 15:52:53.502387 EDT | AveragePolicySurr          -0.987569
2017-07-02 15:52:53.502606 EDT | AverageQ                    0.940222
2017-07-02 15:52:53.502720 EDT | AverageAbsQ                 0.943683
2017-07-02 15:52:53.502832 EDT | AverageY                    0.940248
2017-07-02 15:52:53.502965 EDT | AverageAbsY                 0.940698
2017-07-02 15:52:53.503125 EDT | AverageAbsQYDiff            0.0174999
2017-07-02 15:52:53.503248 EDT | AverageAction               0.0278212
2017-07-02 15:52:53.503356 EDT | PolicyRegParamNorm         68.0494
2017-07-02 15:52:53.503555 EDT | QFunRegParamNorm           66.1616
2017-07-02 15:52:53.503671 EDT | -----------------------  -------------
2017-07-02 15:52:53.503861 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #816 | Training started
2017-07-02 15:53:02.913947 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #816 | Training finished
2017-07-02 15:53:02.914581 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #816 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 15:53:02.914829 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #816 | Collecting samples for evaluation
2017-07-02 15:53:08.711429 EDT | -----------------------  ------------
2017-07-02 15:53:08.711670 EDT | Epoch                    816
2017-07-02 15:53:08.711788 EDT | Iteration                816
2017-07-02 15:53:08.711896 EDT | AverageReturn             38.9105
2017-07-02 15:53:08.712044 EDT | StdReturn                  0.708321
2017-07-02 15:53:08.712171 EDT | MaxReturn                 41
2017-07-02 15:53:08.712325 EDT | MinReturn                 38
2017-07-02 15:53:08.712507 EDT | AverageEsReturn           17.6667
2017-07-02 15:53:08.712635 EDT | StdEsReturn               22.951
2017-07-02 15:53:08.712807 EDT | MaxEsReturn              127
2017-07-02 15:53:08.713011 EDT | MinEsReturn                3
2017-07-02 15:53:08.713146 EDT | AverageDiscountedReturn   32.3646
2017-07-02 15:53:08.713304 EDT | AverageQLoss               0.00345366
2017-07-02 15:53:08.713447 EDT | AveragePolicySurr         -0.987574
2017-07-02 15:53:08.713586 EDT | AverageQ                   0.944837
2017-07-02 15:53:08.713687 EDT | AverageAbsQ                0.94738
2017-07-02 15:53:08.713820 EDT | AverageY                   0.944846
2017-07-02 15:53:08.713929 EDT | AverageAbsY                0.945332
2017-07-02 15:53:08.714035 EDT | AverageAbsQYDiff           0.015027
2017-07-02 15:53:08.714137 EDT | AverageAction              0.37384
2017-07-02 15:53:08.714348 EDT | PolicyRegParamNorm        68.0994
2017-07-02 15:53:08.714570 EDT | QFunRegParamNorm          66.1812
2017-07-02 15:53:08.714762 EDT | -----------------------  ------------
2017-07-02 15:53:08.715015 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #817 | Training started
2017-07-02 15:53:18.001047 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #817 | Training finished
2017-07-02 15:53:18.001597 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #817 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 15:53:18.001866 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #817 | Collecting samples for evaluation
2017-07-02 15:53:23.651546 EDT | -----------------------  -------------
2017-07-02 15:53:23.651846 EDT | Epoch                     817
2017-07-02 15:53:23.652083 EDT | Iteration                 817
2017-07-02 15:53:23.652289 EDT | AverageReturn             841
2017-07-02 15:53:23.652508 EDT | StdReturn                 355.535
2017-07-02 15:53:23.652742 EDT | MaxReturn                1000
2017-07-02 15:53:23.652964 EDT | MinReturn                  45
2017-07-02 15:53:23.653157 EDT | AverageEsReturn            13.3467
2017-07-02 15:53:23.653380 EDT | StdEsReturn                15.4613
2017-07-02 15:53:23.653625 EDT | MaxEsReturn                80
2017-07-02 15:53:23.653858 EDT | MinEsReturn                 3
2017-07-02 15:53:23.654007 EDT | AverageDiscountedReturn    89.4988
2017-07-02 15:53:23.654237 EDT | AverageQLoss                0.00360294
2017-07-02 15:53:23.654436 EDT | AveragePolicySurr          -0.985605
2017-07-02 15:53:23.654646 EDT | AverageQ                    0.938958
2017-07-02 15:53:23.654852 EDT | AverageAbsQ                 0.941806
2017-07-02 15:53:23.655085 EDT | AverageY                    0.938946
2017-07-02 15:53:23.655252 EDT | AverageAbsY                 0.939385
2017-07-02 15:53:23.655358 EDT | AverageAbsQYDiff            0.016104
2017-07-02 15:53:23.655481 EDT | AverageAction               0.21903
2017-07-02 15:53:23.655708 EDT | PolicyRegParamNorm         68.1685
2017-07-02 15:53:23.655919 EDT | QFunRegParamNorm           66.1939
2017-07-02 15:53:23.656152 EDT | -----------------------  -------------
2017-07-02 15:53:23.656406 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #818 | Training started
2017-07-02 15:53:32.787244 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #818 | Training finished
2017-07-02 15:53:32.787828 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #818 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 15:53:32.788085 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #818 | Collecting samples for evaluation
2017-07-02 15:53:38.408468 EDT | -----------------------  -------------
2017-07-02 15:53:38.408783 EDT | Epoch                     818
2017-07-02 15:53:38.408921 EDT | Iteration                 818
2017-07-02 15:53:38.409061 EDT | AverageReturn            1000
2017-07-02 15:53:38.409245 EDT | StdReturn                   0
2017-07-02 15:53:38.409408 EDT | MaxReturn                1000
2017-07-02 15:53:38.409618 EDT | MinReturn                1000
2017-07-02 15:53:38.409724 EDT | AverageEsReturn            11.8941
2017-07-02 15:53:38.409855 EDT | StdEsReturn                11.7333
2017-07-02 15:53:38.409957 EDT | MaxEsReturn                61
2017-07-02 15:53:38.410132 EDT | MinEsReturn                 3
2017-07-02 15:53:38.410357 EDT | AverageDiscountedReturn    99.9957
2017-07-02 15:53:38.410574 EDT | AverageQLoss                0.00325745
2017-07-02 15:53:38.410788 EDT | AveragePolicySurr          -0.985553
2017-07-02 15:53:38.410995 EDT | AverageQ                    0.938246
2017-07-02 15:53:38.411178 EDT | AverageAbsQ                 0.940866
2017-07-02 15:53:38.411395 EDT | AverageY                    0.938271
2017-07-02 15:53:38.411544 EDT | AverageAbsY                 0.938673
2017-07-02 15:53:38.411648 EDT | AverageAbsQYDiff            0.014707
2017-07-02 15:53:38.412068 EDT | AverageAction               0.0110675
2017-07-02 15:53:38.412302 EDT | PolicyRegParamNorm         68.1402
2017-07-02 15:53:38.412526 EDT | QFunRegParamNorm           66.2049
2017-07-02 15:53:38.412715 EDT | -----------------------  -------------
2017-07-02 15:53:38.413025 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #819 | Training started
2017-07-02 15:53:47.727287 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #819 | Training finished
2017-07-02 15:53:47.727586 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #819 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 15:53:47.727813 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #819 | Collecting samples for evaluation
2017-07-02 15:53:53.512955 EDT | -----------------------  ------------
2017-07-02 15:53:53.513536 EDT | Epoch                    819
2017-07-02 15:53:53.513731 EDT | Iteration                819
2017-07-02 15:53:53.513953 EDT | AverageReturn             46.1014
2017-07-02 15:53:53.514136 EDT | StdReturn                  1.5327
2017-07-02 15:53:53.515076 EDT | MaxReturn                 49
2017-07-02 15:53:53.515362 EDT | MinReturn                 43
2017-07-02 15:53:53.515665 EDT | AverageEsReturn           15.4308
2017-07-02 15:53:53.515999 EDT | StdEsReturn               17.5078
2017-07-02 15:53:53.516329 EDT | MaxEsReturn               89
2017-07-02 15:53:53.516555 EDT | MinEsReturn                3
2017-07-02 15:53:53.516766 EDT | AverageDiscountedReturn   37.0743
2017-07-02 15:53:53.516923 EDT | AverageQLoss               0.00339573
2017-07-02 15:53:53.517148 EDT | AveragePolicySurr         -0.987167
2017-07-02 15:53:53.517301 EDT | AverageQ                   0.941442
2017-07-02 15:53:53.517528 EDT | AverageAbsQ                0.944642
2017-07-02 15:53:53.517758 EDT | AverageY                   0.941443
2017-07-02 15:53:53.517976 EDT | AverageAbsY                0.941741
2017-07-02 15:53:53.518182 EDT | AverageAbsQYDiff           0.0154951
2017-07-02 15:53:53.518373 EDT | AverageAction              0.364628
2017-07-02 15:53:53.518570 EDT | PolicyRegParamNorm        68.1064
2017-07-02 15:53:53.518690 EDT | QFunRegParamNorm          66.2122
2017-07-02 15:53:53.518911 EDT | -----------------------  ------------
2017-07-02 15:53:53.519193 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #820 | Training started
2017-07-02 15:54:02.860661 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #820 | Training finished
2017-07-02 15:54:02.861221 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #820 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 15:54:02.861471 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #820 | Collecting samples for evaluation
2017-07-02 15:54:08.476034 EDT | -----------------------  ------------
2017-07-02 15:54:08.476360 EDT | Epoch                    820
2017-07-02 15:54:08.476583 EDT | Iteration                820
2017-07-02 15:54:08.476812 EDT | AverageReturn             54.694
2017-07-02 15:54:08.477043 EDT | StdReturn                  2.32692
2017-07-02 15:54:08.477243 EDT | MaxReturn                 59
2017-07-02 15:54:08.477375 EDT | MinReturn                 50
2017-07-02 15:54:08.477605 EDT | AverageEsReturn           15.0606
2017-07-02 15:54:08.477830 EDT | StdEsReturn               18.5193
2017-07-02 15:54:08.478016 EDT | MaxEsReturn               93
2017-07-02 15:54:08.478241 EDT | MinEsReturn                3
2017-07-02 15:54:08.478471 EDT | AverageDiscountedReturn   42.2715
2017-07-02 15:54:08.478692 EDT | AverageQLoss               0.00311651
2017-07-02 15:54:08.478919 EDT | AveragePolicySurr         -0.98572
2017-07-02 15:54:08.479049 EDT | AverageQ                   0.939249
2017-07-02 15:54:08.479280 EDT | AverageAbsQ                0.942163
2017-07-02 15:54:08.479492 EDT | AverageY                   0.939219
2017-07-02 15:54:08.479640 EDT | AverageAbsY                0.939696
2017-07-02 15:54:08.479867 EDT | AverageAbsQYDiff           0.0150498
2017-07-02 15:54:08.480061 EDT | AverageAction              0.339238
2017-07-02 15:54:08.480278 EDT | PolicyRegParamNorm        68.1045
2017-07-02 15:54:08.480506 EDT | QFunRegParamNorm          66.2282
2017-07-02 15:54:08.480699 EDT | -----------------------  ------------
2017-07-02 15:54:08.481021 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #821 | Training started
2017-07-02 15:54:17.847860 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #821 | Training finished
2017-07-02 15:54:17.848403 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #821 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 15:54:17.848577 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #821 | Collecting samples for evaluation
2017-07-02 15:54:23.399278 EDT | -----------------------  -------------
2017-07-02 15:54:23.399796 EDT | Epoch                     821
2017-07-02 15:54:23.399978 EDT | Iteration                 821
2017-07-02 15:54:23.400203 EDT | AverageReturn            1000
2017-07-02 15:54:23.400422 EDT | StdReturn                   0
2017-07-02 15:54:23.400600 EDT | MaxReturn                1000
2017-07-02 15:54:23.400785 EDT | MinReturn                1000
2017-07-02 15:54:23.400938 EDT | AverageEsReturn             9.67308
2017-07-02 15:54:23.401071 EDT | StdEsReturn                11.5187
2017-07-02 15:54:23.401173 EDT | MaxEsReturn                92
2017-07-02 15:54:23.401291 EDT | MinEsReturn                 3
2017-07-02 15:54:23.401529 EDT | AverageDiscountedReturn    99.9957
2017-07-02 15:54:23.401735 EDT | AverageQLoss                0.00310238
2017-07-02 15:54:23.401957 EDT | AveragePolicySurr          -0.987531
2017-07-02 15:54:23.402169 EDT | AverageQ                    0.940845
2017-07-02 15:54:23.402381 EDT | AverageAbsQ                 0.943979
2017-07-02 15:54:23.402615 EDT | AverageY                    0.940912
2017-07-02 15:54:23.402833 EDT | AverageAbsY                 0.941523
2017-07-02 15:54:23.403052 EDT | AverageAbsQYDiff            0.0147798
2017-07-02 15:54:23.403270 EDT | AverageAction               0.0164153
2017-07-02 15:54:23.403481 EDT | PolicyRegParamNorm         68.151
2017-07-02 15:54:23.403693 EDT | QFunRegParamNorm           66.2411
2017-07-02 15:54:23.403906 EDT | -----------------------  -------------
2017-07-02 15:54:23.404177 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #822 | Training started
2017-07-02 15:54:32.782095 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #822 | Training finished
2017-07-02 15:54:32.782636 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #822 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 15:54:32.782888 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #822 | Collecting samples for evaluation
2017-07-02 15:54:38.663100 EDT | -----------------------  ------------
2017-07-02 15:54:38.663441 EDT | Epoch                    822
2017-07-02 15:54:38.663647 EDT | Iteration                822
2017-07-02 15:54:38.663844 EDT | AverageReturn             43.9912
2017-07-02 15:54:38.664040 EDT | StdReturn                  1.53323
2017-07-02 15:54:38.664268 EDT | MaxReturn                 47
2017-07-02 15:54:38.664476 EDT | MinReturn                 42
2017-07-02 15:54:38.664671 EDT | AverageEsReturn           11
2017-07-02 15:54:38.664862 EDT | StdEsReturn                9.95157
2017-07-02 15:54:38.665145 EDT | MaxEsReturn               40
2017-07-02 15:54:38.665443 EDT | MinEsReturn                3
2017-07-02 15:54:38.665737 EDT | AverageDiscountedReturn   35.7256
2017-07-02 15:54:38.666001 EDT | AverageQLoss               0.00304605
2017-07-02 15:54:38.666304 EDT | AveragePolicySurr         -0.988565
2017-07-02 15:54:38.666509 EDT | AverageQ                   0.943758
2017-07-02 15:54:38.666704 EDT | AverageAbsQ                0.946292
2017-07-02 15:54:38.666906 EDT | AverageY                   0.943695
2017-07-02 15:54:38.667128 EDT | AverageAbsY                0.94414
2017-07-02 15:54:38.667349 EDT | AverageAbsQYDiff           0.0141209
2017-07-02 15:54:38.667537 EDT | AverageAction              0.310545
2017-07-02 15:54:38.667726 EDT | PolicyRegParamNorm        68.1563
2017-07-02 15:54:38.667924 EDT | QFunRegParamNorm          66.2479
2017-07-02 15:54:38.668151 EDT | -----------------------  ------------
2017-07-02 15:54:38.668468 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #823 | Training started
2017-07-02 15:54:48.126174 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #823 | Training finished
2017-07-02 15:54:48.126717 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #823 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 15:54:48.127078 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #823 | Collecting samples for evaluation
2017-07-02 15:54:53.628874 EDT | -----------------------  -------------
2017-07-02 15:54:53.629408 EDT | Epoch                     823
2017-07-02 15:54:53.629629 EDT | Iteration                 823
2017-07-02 15:54:53.629842 EDT | AverageReturn            1000
2017-07-02 15:54:53.630052 EDT | StdReturn                   0
2017-07-02 15:54:53.630254 EDT | MaxReturn                1000
2017-07-02 15:54:53.630445 EDT | MinReturn                1000
2017-07-02 15:54:53.630558 EDT | AverageEsReturn            12.75
2017-07-02 15:54:53.630699 EDT | StdEsReturn                13.162
2017-07-02 15:54:53.630834 EDT | MaxEsReturn                77
2017-07-02 15:54:53.630957 EDT | MinEsReturn                 3
2017-07-02 15:54:53.631060 EDT | AverageDiscountedReturn    99.9957
2017-07-02 15:54:53.631203 EDT | AverageQLoss                0.00320583
2017-07-02 15:54:53.631304 EDT | AveragePolicySurr          -0.987812
2017-07-02 15:54:53.631412 EDT | AverageQ                    0.94097
2017-07-02 15:54:53.631571 EDT | AverageAbsQ                 0.943865
2017-07-02 15:54:53.631673 EDT | AverageY                    0.941064
2017-07-02 15:54:53.631774 EDT | AverageAbsY                 0.941361
2017-07-02 15:54:53.631953 EDT | AverageAbsQYDiff            0.0146435
2017-07-02 15:54:53.632055 EDT | AverageAction               0.0248164
2017-07-02 15:54:53.632165 EDT | PolicyRegParamNorm         68.2424
2017-07-02 15:54:53.632292 EDT | QFunRegParamNorm           66.2952
2017-07-02 15:54:53.632411 EDT | -----------------------  -------------
2017-07-02 15:54:53.632586 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #824 | Training started
2017-07-02 15:55:03.080261 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #824 | Training finished
2017-07-02 15:55:03.080874 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #824 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 15:55:03.081109 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #824 | Collecting samples for evaluation
2017-07-02 15:55:08.469694 EDT | -----------------------  -------------
2017-07-02 15:55:08.469902 EDT | Epoch                     824
2017-07-02 15:55:08.470110 EDT | Iteration                 824
2017-07-02 15:55:08.470332 EDT | AverageReturn            1000
2017-07-02 15:55:08.470545 EDT | StdReturn                   0
2017-07-02 15:55:08.470700 EDT | MaxReturn                1000
2017-07-02 15:55:08.470885 EDT | MinReturn                1000
2017-07-02 15:55:08.471018 EDT | AverageEsReturn            13
2017-07-02 15:55:08.471124 EDT | StdEsReturn                14.6125
2017-07-02 15:55:08.471319 EDT | MaxEsReturn                95
2017-07-02 15:55:08.471507 EDT | MinEsReturn                 3
2017-07-02 15:55:08.471706 EDT | AverageDiscountedReturn    99.9957
2017-07-02 15:55:08.471842 EDT | AverageQLoss                0.00287817
2017-07-02 15:55:08.471945 EDT | AveragePolicySurr          -0.991011
2017-07-02 15:55:08.472045 EDT | AverageQ                    0.945351
2017-07-02 15:55:08.472228 EDT | AverageAbsQ                 0.947795
2017-07-02 15:55:08.472419 EDT | AverageY                    0.945318
2017-07-02 15:55:08.472617 EDT | AverageAbsY                 0.945546
2017-07-02 15:55:08.472822 EDT | AverageAbsQYDiff            0.0141023
2017-07-02 15:55:08.473047 EDT | AverageAction               0.00676842
2017-07-02 15:55:08.473266 EDT | PolicyRegParamNorm         68.228
2017-07-02 15:55:08.473480 EDT | QFunRegParamNorm           66.3266
2017-07-02 15:55:08.473750 EDT | -----------------------  -------------
2017-07-02 15:55:08.474039 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #825 | Training started
2017-07-02 15:55:17.971460 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #825 | Training finished
2017-07-02 15:55:17.972183 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #825 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 15:55:17.972399 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #825 | Collecting samples for evaluation
2017-07-02 15:55:23.973742 EDT | -----------------------  -------------
2017-07-02 15:55:23.974338 EDT | Epoch                     825
2017-07-02 15:55:23.974551 EDT | Iteration                 825
2017-07-02 15:55:23.974772 EDT | AverageReturn            1000
2017-07-02 15:55:23.974960 EDT | StdReturn                   0
2017-07-02 15:55:23.975192 EDT | MaxReturn                1000
2017-07-02 15:55:23.975411 EDT | MinReturn                1000
2017-07-02 15:55:23.975629 EDT | AverageEsReturn            13.2237
2017-07-02 15:55:23.975839 EDT | StdEsReturn                12.5369
2017-07-02 15:55:23.976025 EDT | MaxEsReturn                57
2017-07-02 15:55:23.976237 EDT | MinEsReturn                 3
2017-07-02 15:55:23.976418 EDT | AverageDiscountedReturn    99.9957
2017-07-02 15:55:23.976632 EDT | AverageQLoss                0.00319903
2017-07-02 15:55:23.976849 EDT | AveragePolicySurr          -0.989528
2017-07-02 15:55:23.977062 EDT | AverageQ                    0.944608
2017-07-02 15:55:23.977258 EDT | AverageAbsQ                 0.948063
2017-07-02 15:55:23.977420 EDT | AverageY                    0.944621
2017-07-02 15:55:23.977657 EDT | AverageAbsY                 0.945093
2017-07-02 15:55:23.977834 EDT | AverageAbsQYDiff            0.0154474
2017-07-02 15:55:23.978025 EDT | AverageAction               0.0121271
2017-07-02 15:55:23.978247 EDT | PolicyRegParamNorm         68.2664
2017-07-02 15:55:23.978478 EDT | QFunRegParamNorm           66.3523
2017-07-02 15:55:23.978608 EDT | -----------------------  -------------
2017-07-02 15:55:23.978780 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #826 | Training started
2017-07-02 15:55:33.348562 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #826 | Training finished
2017-07-02 15:55:33.349114 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #826 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 15:55:33.349282 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #826 | Collecting samples for evaluation
2017-07-02 15:55:38.869713 EDT | -----------------------  ------------
2017-07-02 15:55:38.869929 EDT | Epoch                     826
2017-07-02 15:55:38.870063 EDT | Iteration                 826
2017-07-02 15:55:38.870384 EDT | AverageReturn            1000
2017-07-02 15:55:38.870641 EDT | StdReturn                   0
2017-07-02 15:55:38.870862 EDT | MaxReturn                1000
2017-07-02 15:55:38.871074 EDT | MinReturn                1000
2017-07-02 15:55:38.871285 EDT | AverageEsReturn            14.6232
2017-07-02 15:55:38.871500 EDT | StdEsReturn                13.6457
2017-07-02 15:55:38.871687 EDT | MaxEsReturn                60
2017-07-02 15:55:38.871918 EDT | MinEsReturn                 3
2017-07-02 15:55:38.872137 EDT | AverageDiscountedReturn    99.9957
2017-07-02 15:55:38.872354 EDT | AverageQLoss                0.0035479
2017-07-02 15:55:38.872570 EDT | AveragePolicySurr          -0.9884
2017-07-02 15:55:38.872767 EDT | AverageQ                    0.94246
2017-07-02 15:55:38.872980 EDT | AverageAbsQ                 0.945115
2017-07-02 15:55:38.873181 EDT | AverageY                    0.942472
2017-07-02 15:55:38.873390 EDT | AverageAbsY                 0.942894
2017-07-02 15:55:38.873627 EDT | AverageAbsQYDiff            0.0155289
2017-07-02 15:55:38.873845 EDT | AverageAction               0.0139527
2017-07-02 15:55:38.874061 EDT | PolicyRegParamNorm         68.3419
2017-07-02 15:55:38.874270 EDT | QFunRegParamNorm           66.3969
2017-07-02 15:55:38.874391 EDT | -----------------------  ------------
2017-07-02 15:55:38.874612 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #827 | Training started
2017-07-02 15:55:48.193454 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #827 | Training finished
2017-07-02 15:55:48.193970 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #827 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 15:55:48.194125 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #827 | Collecting samples for evaluation
2017-07-02 15:55:53.956507 EDT | -----------------------  -----------
2017-07-02 15:55:53.957007 EDT | Epoch                    827
2017-07-02 15:55:53.957243 EDT | Iteration                827
2017-07-02 15:55:53.957453 EDT | AverageReturn             48.7718
2017-07-02 15:55:53.957686 EDT | StdReturn                  0.419643
2017-07-02 15:55:53.957879 EDT | MaxReturn                 49
2017-07-02 15:55:53.958109 EDT | MinReturn                 48
2017-07-02 15:55:53.958331 EDT | AverageEsReturn           17.8214
2017-07-02 15:55:53.958550 EDT | StdEsReturn               18.3099
2017-07-02 15:55:53.958758 EDT | MaxEsReturn               79
2017-07-02 15:55:53.958980 EDT | MinEsReturn                2
2017-07-02 15:55:53.959205 EDT | AverageDiscountedReturn   38.7474
2017-07-02 15:55:53.959337 EDT | AverageQLoss               0.002913
2017-07-02 15:55:53.959464 EDT | AveragePolicySurr         -0.991426
2017-07-02 15:55:53.959590 EDT | AverageQ                   0.944297
2017-07-02 15:55:53.959714 EDT | AverageAbsQ                0.946923
2017-07-02 15:55:53.959877 EDT | AverageY                   0.944274
2017-07-02 15:55:53.960098 EDT | AverageAbsY                0.944605
2017-07-02 15:55:53.960310 EDT | AverageAbsQYDiff           0.0147127
2017-07-02 15:55:53.960525 EDT | AverageAction              0.330165
2017-07-02 15:55:53.960739 EDT | PolicyRegParamNorm        68.3531
2017-07-02 15:55:53.960918 EDT | QFunRegParamNorm          66.4362
2017-07-02 15:55:53.961144 EDT | -----------------------  -----------
2017-07-02 15:55:53.961461 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #828 | Training started
2017-07-02 15:56:03.275956 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #828 | Training finished
2017-07-02 15:56:03.276499 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #828 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 15:56:03.276675 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #828 | Collecting samples for evaluation
2017-07-02 15:56:08.810460 EDT | -----------------------  -------------
2017-07-02 15:56:08.810665 EDT | Epoch                     828
2017-07-02 15:56:08.810873 EDT | Iteration                 828
2017-07-02 15:56:08.811094 EDT | AverageReturn            1000
2017-07-02 15:56:08.811318 EDT | StdReturn                   0
2017-07-02 15:56:08.811538 EDT | MaxReturn                1000
2017-07-02 15:56:08.811747 EDT | MinReturn                1000
2017-07-02 15:56:08.811970 EDT | AverageEsReturn            13.7639
2017-07-02 15:56:08.812127 EDT | StdEsReturn                13.9568
2017-07-02 15:56:08.812230 EDT | MaxEsReturn                70
2017-07-02 15:56:08.812332 EDT | MinEsReturn                 3
2017-07-02 15:56:08.812443 EDT | AverageDiscountedReturn    99.9957
2017-07-02 15:56:08.812549 EDT | AverageQLoss                0.00324372
2017-07-02 15:56:08.812656 EDT | AveragePolicySurr          -0.992474
2017-07-02 15:56:08.812794 EDT | AverageQ                    0.945657
2017-07-02 15:56:08.813012 EDT | AverageAbsQ                 0.948469
2017-07-02 15:56:08.813168 EDT | AverageY                    0.945683
2017-07-02 15:56:08.813340 EDT | AverageAbsY                 0.945893
2017-07-02 15:56:08.813584 EDT | AverageAbsQYDiff            0.0155817
2017-07-02 15:56:08.813793 EDT | AverageAction               0.00560027
2017-07-02 15:56:08.813962 EDT | PolicyRegParamNorm         68.3788
2017-07-02 15:56:08.814157 EDT | QFunRegParamNorm           66.461
2017-07-02 15:56:08.814347 EDT | -----------------------  -------------
2017-07-02 15:56:08.814516 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #829 | Training started
2017-07-02 15:56:18.275320 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #829 | Training finished
2017-07-02 15:56:18.275879 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #829 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 15:56:18.276057 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #829 | Collecting samples for evaluation
2017-07-02 15:56:23.729724 EDT | -----------------------  -------------
2017-07-02 15:56:23.729966 EDT | Epoch                     829
2017-07-02 15:56:23.730179 EDT | Iteration                 829
2017-07-02 15:56:23.730451 EDT | AverageReturn            1000
2017-07-02 15:56:23.730656 EDT | StdReturn                   0
2017-07-02 15:56:23.730880 EDT | MaxReturn                1000
2017-07-02 15:56:23.731102 EDT | MinReturn                1000
2017-07-02 15:56:23.731337 EDT | AverageEsReturn            18.2545
2017-07-02 15:56:23.731564 EDT | StdEsReturn                26.3723
2017-07-02 15:56:23.731787 EDT | MaxEsReturn               165
2017-07-02 15:56:23.732004 EDT | MinEsReturn                 3
2017-07-02 15:56:23.732220 EDT | AverageDiscountedReturn    99.9957
2017-07-02 15:56:23.732444 EDT | AverageQLoss                0.00306535
2017-07-02 15:56:23.732599 EDT | AveragePolicySurr          -0.992122
2017-07-02 15:56:23.732778 EDT | AverageQ                    0.944782
2017-07-02 15:56:23.732940 EDT | AverageAbsQ                 0.947404
2017-07-02 15:56:23.733150 EDT | AverageY                    0.944758
2017-07-02 15:56:23.733363 EDT | AverageAbsY                 0.944977
2017-07-02 15:56:23.733650 EDT | AverageAbsQYDiff            0.0151821
2017-07-02 15:56:23.733866 EDT | AverageAction               0.0174079
2017-07-02 15:56:23.734098 EDT | PolicyRegParamNorm         68.3814
2017-07-02 15:56:23.734326 EDT | QFunRegParamNorm           66.4828
2017-07-02 15:56:23.734551 EDT | -----------------------  -------------
2017-07-02 15:56:23.734859 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #830 | Training started
2017-07-02 15:56:33.164439 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #830 | Training finished
2017-07-02 15:56:33.165055 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #830 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 15:56:33.165309 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #830 | Collecting samples for evaluation
2017-07-02 15:56:38.612695 EDT | -----------------------  -------------
2017-07-02 15:56:38.612910 EDT | Epoch                     830
2017-07-02 15:56:38.613029 EDT | Iteration                 830
2017-07-02 15:56:38.613259 EDT | AverageReturn            1000
2017-07-02 15:56:38.613474 EDT | StdReturn                   0
2017-07-02 15:56:38.613732 EDT | MaxReturn                1000
2017-07-02 15:56:38.613944 EDT | MinReturn                1000
2017-07-02 15:56:38.614137 EDT | AverageEsReturn            18.7255
2017-07-02 15:56:38.614339 EDT | StdEsReturn                23.4103
2017-07-02 15:56:38.614535 EDT | MaxEsReturn               129
2017-07-02 15:56:38.614663 EDT | MinEsReturn                 3
2017-07-02 15:56:38.614801 EDT | AverageDiscountedReturn    99.9957
2017-07-02 15:56:38.614906 EDT | AverageQLoss                0.00358518
2017-07-02 15:56:38.615053 EDT | AveragePolicySurr          -0.99207
2017-07-02 15:56:38.615156 EDT | AverageQ                    0.945038
2017-07-02 15:56:38.615284 EDT | AverageAbsQ                 0.948598
2017-07-02 15:56:38.615388 EDT | AverageY                    0.945031
2017-07-02 15:56:38.615490 EDT | AverageAbsY                 0.945322
2017-07-02 15:56:38.615590 EDT | AverageAbsQYDiff            0.0163991
2017-07-02 15:56:38.615690 EDT | AverageAction               0.00433306
2017-07-02 15:56:38.615789 EDT | PolicyRegParamNorm         68.4285
2017-07-02 15:56:38.615889 EDT | QFunRegParamNorm           66.5073
2017-07-02 15:56:38.616033 EDT | -----------------------  -------------
2017-07-02 15:56:38.616215 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #831 | Training started
2017-07-02 15:56:48.058431 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #831 | Training finished
2017-07-02 15:56:48.059011 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #831 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 15:56:48.059187 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #831 | Collecting samples for evaluation
2017-07-02 15:56:53.538010 EDT | -----------------------  -------------
2017-07-02 15:56:53.538313 EDT | Epoch                     831
2017-07-02 15:56:53.538539 EDT | Iteration                 831
2017-07-02 15:56:53.538764 EDT | AverageReturn            1000
2017-07-02 15:56:53.538985 EDT | StdReturn                   0
2017-07-02 15:56:53.539211 EDT | MaxReturn                1000
2017-07-02 15:56:53.539433 EDT | MinReturn                1000
2017-07-02 15:56:53.539664 EDT | AverageEsReturn            12.6747
2017-07-02 15:56:53.539883 EDT | StdEsReturn                15.3066
2017-07-02 15:56:53.540104 EDT | MaxEsReturn               108
2017-07-02 15:56:53.540400 EDT | MinEsReturn                 3
2017-07-02 15:56:53.540612 EDT | AverageDiscountedReturn    99.9957
2017-07-02 15:56:53.540832 EDT | AverageQLoss                0.00320578
2017-07-02 15:56:53.541022 EDT | AveragePolicySurr          -0.994711
2017-07-02 15:56:53.541252 EDT | AverageQ                    0.949097
2017-07-02 15:56:53.541474 EDT | AverageAbsQ                 0.951242
2017-07-02 15:56:53.541699 EDT | AverageY                    0.949161
2017-07-02 15:56:53.541911 EDT | AverageAbsY                 0.94956
2017-07-02 15:56:53.542113 EDT | AverageAbsQYDiff            0.0148377
2017-07-02 15:56:53.542330 EDT | AverageAction               0.00536737
2017-07-02 15:56:53.542555 EDT | PolicyRegParamNorm         68.4033
2017-07-02 15:56:53.542775 EDT | QFunRegParamNorm           66.549
2017-07-02 15:56:53.542986 EDT | -----------------------  -------------
2017-07-02 15:56:53.543278 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #832 | Training started
2017-07-02 15:57:02.815725 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #832 | Training finished
2017-07-02 15:57:02.816227 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #832 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 15:57:02.816463 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #832 | Collecting samples for evaluation
2017-07-02 15:57:08.376142 EDT | -----------------------  -------------
2017-07-02 15:57:08.376333 EDT | Epoch                     832
2017-07-02 15:57:08.376448 EDT | Iteration                 832
2017-07-02 15:57:08.376552 EDT | AverageReturn            1000
2017-07-02 15:57:08.376740 EDT | StdReturn                   0
2017-07-02 15:57:08.376925 EDT | MaxReturn                1000
2017-07-02 15:57:08.377067 EDT | MinReturn                1000
2017-07-02 15:57:08.377218 EDT | AverageEsReturn            13.1867
2017-07-02 15:57:08.377332 EDT | StdEsReturn                11.1531
2017-07-02 15:57:08.377468 EDT | MaxEsReturn                53
2017-07-02 15:57:08.377618 EDT | MinEsReturn                 2
2017-07-02 15:57:08.377766 EDT | AverageDiscountedReturn    99.9957
2017-07-02 15:57:08.377895 EDT | AverageQLoss                0.00313944
2017-07-02 15:57:08.378011 EDT | AveragePolicySurr          -0.995759
2017-07-02 15:57:08.378208 EDT | AverageQ                    0.949306
2017-07-02 15:57:08.378314 EDT | AverageAbsQ                 0.952586
2017-07-02 15:57:08.378415 EDT | AverageY                    0.949279
2017-07-02 15:57:08.378517 EDT | AverageAbsY                 0.94961
2017-07-02 15:57:08.378686 EDT | AverageAbsQYDiff            0.0152848
2017-07-02 15:57:08.378829 EDT | AverageAction               0.00862094
2017-07-02 15:57:08.378991 EDT | PolicyRegParamNorm         68.4349
2017-07-02 15:57:08.379144 EDT | QFunRegParamNorm           66.549
2017-07-02 15:57:08.379327 EDT | -----------------------  -------------
2017-07-02 15:57:08.379594 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #833 | Training started
2017-07-02 15:57:17.595392 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #833 | Training finished
2017-07-02 15:57:17.595949 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #833 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 15:57:17.596108 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #833 | Collecting samples for evaluation
2017-07-02 15:57:23.221145 EDT | -----------------------  -------------
2017-07-02 15:57:23.221335 EDT | Epoch                     833
2017-07-02 15:57:23.221483 EDT | Iteration                 833
2017-07-02 15:57:23.221663 EDT | AverageReturn            1000
2017-07-02 15:57:23.221838 EDT | StdReturn                   0
2017-07-02 15:57:23.221998 EDT | MaxReturn                1000
2017-07-02 15:57:23.222128 EDT | MinReturn                1000
2017-07-02 15:57:23.222289 EDT | AverageEsReturn            12.3171
2017-07-02 15:57:23.222482 EDT | StdEsReturn                14.7515
2017-07-02 15:57:23.222702 EDT | MaxEsReturn                99
2017-07-02 15:57:23.222863 EDT | MinEsReturn                 3
2017-07-02 15:57:23.222973 EDT | AverageDiscountedReturn    99.9957
2017-07-02 15:57:23.223106 EDT | AverageQLoss                0.00325386
2017-07-02 15:57:23.223207 EDT | AveragePolicySurr          -0.996708
2017-07-02 15:57:23.223305 EDT | AverageQ                    0.947764
2017-07-02 15:57:23.223454 EDT | AverageAbsQ                 0.950425
2017-07-02 15:57:23.223558 EDT | AverageY                    0.947787
2017-07-02 15:57:23.223722 EDT | AverageAbsY                 0.948281
2017-07-02 15:57:23.223829 EDT | AverageAbsQYDiff            0.0155119
2017-07-02 15:57:23.224045 EDT | AverageAction               0.00464644
2017-07-02 15:57:23.224275 EDT | PolicyRegParamNorm         68.4644
2017-07-02 15:57:23.224480 EDT | QFunRegParamNorm           66.5824
2017-07-02 15:57:23.224713 EDT | -----------------------  -------------
2017-07-02 15:57:23.225036 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #834 | Training started
2017-07-02 15:57:32.439542 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #834 | Training finished
2017-07-02 15:57:32.440353 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #834 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 15:57:32.440514 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #834 | Collecting samples for evaluation
2017-07-02 15:57:38.013449 EDT | -----------------------  -------------
2017-07-02 15:57:38.013702 EDT | Epoch                     834
2017-07-02 15:57:38.013842 EDT | Iteration                 834
2017-07-02 15:57:38.014037 EDT | AverageReturn            1000
2017-07-02 15:57:38.014238 EDT | StdReturn                   0
2017-07-02 15:57:38.014416 EDT | MaxReturn                1000
2017-07-02 15:57:38.014576 EDT | MinReturn                1000
2017-07-02 15:57:38.014699 EDT | AverageEsReturn            14.2714
2017-07-02 15:57:38.014843 EDT | StdEsReturn                21.6735
2017-07-02 15:57:38.014969 EDT | MaxEsReturn               142
2017-07-02 15:57:38.015091 EDT | MinEsReturn                 3
2017-07-02 15:57:38.015250 EDT | AverageDiscountedReturn    99.9957
2017-07-02 15:57:38.015394 EDT | AverageQLoss                0.00347243
2017-07-02 15:57:38.015534 EDT | AveragePolicySurr          -0.999749
2017-07-02 15:57:38.015660 EDT | AverageQ                    0.950963
2017-07-02 15:57:38.015784 EDT | AverageAbsQ                 0.954063
2017-07-02 15:57:38.015905 EDT | AverageY                    0.950937
2017-07-02 15:57:38.016036 EDT | AverageAbsY                 0.951323
2017-07-02 15:57:38.016191 EDT | AverageAbsQYDiff            0.016176
2017-07-02 15:57:38.016354 EDT | AverageAction               0.00410296
2017-07-02 15:57:38.016512 EDT | PolicyRegParamNorm         68.4924
2017-07-02 15:57:38.016668 EDT | QFunRegParamNorm           66.6255
2017-07-02 15:57:38.016877 EDT | -----------------------  -------------
2017-07-02 15:57:38.017090 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #835 | Training started
2017-07-02 15:57:47.283252 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #835 | Training finished
2017-07-02 15:57:47.284093 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #835 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 15:57:47.284354 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #835 | Collecting samples for evaluation
2017-07-02 15:57:52.852425 EDT | -----------------------  -------------
2017-07-02 15:57:52.852710 EDT | Epoch                     835
2017-07-02 15:57:52.852930 EDT | Iteration                 835
2017-07-02 15:57:52.853158 EDT | AverageReturn            1000
2017-07-02 15:57:52.853378 EDT | StdReturn                   0
2017-07-02 15:57:52.853623 EDT | MaxReturn                1000
2017-07-02 15:57:52.853833 EDT | MinReturn                1000
2017-07-02 15:57:52.854043 EDT | AverageEsReturn            15.5714
2017-07-02 15:57:52.854266 EDT | StdEsReturn                16.5172
2017-07-02 15:57:52.854489 EDT | MaxEsReturn                88
2017-07-02 15:57:52.854713 EDT | MinEsReturn                 3
2017-07-02 15:57:52.854926 EDT | AverageDiscountedReturn    99.9957
2017-07-02 15:57:52.855145 EDT | AverageQLoss                0.00354809
2017-07-02 15:57:52.855259 EDT | AveragePolicySurr          -0.996543
2017-07-02 15:57:52.855457 EDT | AverageQ                    0.950491
2017-07-02 15:57:52.855646 EDT | AverageAbsQ                 0.953781
2017-07-02 15:57:52.855752 EDT | AverageY                    0.950457
2017-07-02 15:57:52.855853 EDT | AverageAbsY                 0.950895
2017-07-02 15:57:52.856039 EDT | AverageAbsQYDiff            0.0164723
2017-07-02 15:57:52.856255 EDT | AverageAction               0.113225
2017-07-02 15:57:52.856457 EDT | PolicyRegParamNorm         68.5488
2017-07-02 15:57:52.856777 EDT | QFunRegParamNorm           66.6464
2017-07-02 15:57:52.857016 EDT | -----------------------  -------------
2017-07-02 15:57:52.857326 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #836 | Training started
2017-07-02 15:58:02.104653 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #836 | Training finished
2017-07-02 15:58:02.105257 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #836 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 15:58:02.105459 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #836 | Collecting samples for evaluation
2017-07-02 15:58:07.853233 EDT | -----------------------  -------------
2017-07-02 15:58:07.853538 EDT | Epoch                     836
2017-07-02 15:58:07.853708 EDT | Iteration                 836
2017-07-02 15:58:07.853907 EDT | AverageReturn             379.37
2017-07-02 15:58:07.854130 EDT | StdReturn                 438.89
2017-07-02 15:58:07.854334 EDT | MaxReturn                1000
2017-07-02 15:58:07.854527 EDT | MinReturn                  61
2017-07-02 15:58:07.854727 EDT | AverageEsReturn            17.0167
2017-07-02 15:58:07.854926 EDT | StdEsReturn                14.508
2017-07-02 15:58:07.855053 EDT | MaxEsReturn                64
2017-07-02 15:58:07.855216 EDT | MinEsReturn                 3
2017-07-02 15:58:07.855369 EDT | AverageDiscountedReturn    66.6118
2017-07-02 15:58:07.855475 EDT | AverageQLoss                0.00358261
2017-07-02 15:58:07.855656 EDT | AveragePolicySurr          -0.999448
2017-07-02 15:58:07.855857 EDT | AverageQ                    0.95351
2017-07-02 15:58:07.856009 EDT | AverageAbsQ                 0.956676
2017-07-02 15:58:07.856182 EDT | AverageY                    0.953566
2017-07-02 15:58:07.856380 EDT | AverageAbsY                 0.954143
2017-07-02 15:58:07.856571 EDT | AverageAbsQYDiff            0.0165697
2017-07-02 15:58:07.856696 EDT | AverageAction               0.0421679
2017-07-02 15:58:07.856823 EDT | PolicyRegParamNorm         68.6141
2017-07-02 15:58:07.856983 EDT | QFunRegParamNorm           66.6629
2017-07-02 15:58:07.857108 EDT | -----------------------  -------------
2017-07-02 15:58:07.857426 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #837 | Training started
2017-07-02 15:58:17.088739 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #837 | Training finished
2017-07-02 15:58:17.089346 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #837 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 15:58:17.089510 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #837 | Collecting samples for evaluation
2017-07-02 15:58:22.572922 EDT | -----------------------  -------------
2017-07-02 15:58:22.573323 EDT | Epoch                     837
2017-07-02 15:58:22.573545 EDT | Iteration                 837
2017-07-02 15:58:22.573747 EDT | AverageReturn            1000
2017-07-02 15:58:22.573901 EDT | StdReturn                   0
2017-07-02 15:58:22.574013 EDT | MaxReturn                1000
2017-07-02 15:58:22.574177 EDT | MinReturn                1000
2017-07-02 15:58:22.574307 EDT | AverageEsReturn            11.747
2017-07-02 15:58:22.574410 EDT | StdEsReturn                18.0594
2017-07-02 15:58:22.574510 EDT | MaxEsReturn               114
2017-07-02 15:58:22.574645 EDT | MinEsReturn                 2
2017-07-02 15:58:22.574796 EDT | AverageDiscountedReturn    99.9957
2017-07-02 15:58:22.574931 EDT | AverageQLoss                0.00398469
2017-07-02 15:58:22.575063 EDT | AveragePolicySurr          -0.999996
2017-07-02 15:58:22.575167 EDT | AverageQ                    0.952042
2017-07-02 15:58:22.575304 EDT | AverageAbsQ                 0.955332
2017-07-02 15:58:22.575485 EDT | AverageY                    0.951984
2017-07-02 15:58:22.575607 EDT | AverageAbsY                 0.952413
2017-07-02 15:58:22.575709 EDT | AverageAbsQYDiff            0.0180333
2017-07-02 15:58:22.575867 EDT | AverageAction               0.00358065
2017-07-02 15:58:22.575995 EDT | PolicyRegParamNorm         68.6427
2017-07-02 15:58:22.576181 EDT | QFunRegParamNorm           66.6716
2017-07-02 15:58:22.576359 EDT | -----------------------  -------------
2017-07-02 15:58:22.576536 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #838 | Training started
2017-07-02 15:58:31.954038 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #838 | Training finished
2017-07-02 15:58:31.954669 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #838 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 15:58:31.954926 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #838 | Collecting samples for evaluation
2017-07-02 15:58:37.347721 EDT | -----------------------  -------------
2017-07-02 15:58:37.347938 EDT | Epoch                     838
2017-07-02 15:58:37.348054 EDT | Iteration                 838
2017-07-02 15:58:37.348195 EDT | AverageReturn            1000
2017-07-02 15:58:37.348340 EDT | StdReturn                   0
2017-07-02 15:58:37.348443 EDT | MaxReturn                1000
2017-07-02 15:58:37.348567 EDT | MinReturn                1000
2017-07-02 15:58:37.348705 EDT | AverageEsReturn            12.2
2017-07-02 15:58:37.348874 EDT | StdEsReturn                13.588
2017-07-02 15:58:37.349025 EDT | MaxEsReturn                81
2017-07-02 15:58:37.349180 EDT | MinEsReturn                 3
2017-07-02 15:58:37.349373 EDT | AverageDiscountedReturn    99.9957
2017-07-02 15:58:37.349502 EDT | AverageQLoss                0.00343952
2017-07-02 15:58:37.349633 EDT | AveragePolicySurr          -1.0001
2017-07-02 15:58:37.349740 EDT | AverageQ                    0.950958
2017-07-02 15:58:37.349840 EDT | AverageAbsQ                 0.954289
2017-07-02 15:58:37.349949 EDT | AverageY                    0.950832
2017-07-02 15:58:37.350085 EDT | AverageAbsY                 0.951629
2017-07-02 15:58:37.350188 EDT | AverageAbsQYDiff            0.016783
2017-07-02 15:58:37.350313 EDT | AverageAction               0.00256981
2017-07-02 15:58:37.350465 EDT | PolicyRegParamNorm         68.7074
2017-07-02 15:58:37.350592 EDT | QFunRegParamNorm           66.6918
2017-07-02 15:58:37.350716 EDT | -----------------------  -------------
2017-07-02 15:58:37.350910 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #839 | Training started
2017-07-02 15:58:46.803224 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #839 | Training finished
2017-07-02 15:58:46.803800 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #839 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 15:58:46.803944 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #839 | Collecting samples for evaluation
2017-07-02 15:58:52.192001 EDT | -----------------------  -------------
2017-07-02 15:58:52.192598 EDT | Epoch                     839
2017-07-02 15:58:52.192820 EDT | Iteration                 839
2017-07-02 15:58:52.193023 EDT | AverageReturn            1000
2017-07-02 15:58:52.193252 EDT | StdReturn                   0
2017-07-02 15:58:52.193469 EDT | MaxReturn                1000
2017-07-02 15:58:52.193701 EDT | MinReturn                1000
2017-07-02 15:58:52.193903 EDT | AverageEsReturn            17.6949
2017-07-02 15:58:52.194099 EDT | StdEsReturn                15.5544
2017-07-02 15:58:52.194324 EDT | MaxEsReturn                64
2017-07-02 15:58:52.194498 EDT | MinEsReturn                 3
2017-07-02 15:58:52.194680 EDT | AverageDiscountedReturn    99.9957
2017-07-02 15:58:52.194884 EDT | AverageQLoss                0.00367062
2017-07-02 15:58:52.195083 EDT | AveragePolicySurr          -1.00208
2017-07-02 15:58:52.195278 EDT | AverageQ                    0.952622
2017-07-02 15:58:52.195506 EDT | AverageAbsQ                 0.955705
2017-07-02 15:58:52.195677 EDT | AverageY                    0.95271
2017-07-02 15:58:52.195898 EDT | AverageAbsY                 0.953213
2017-07-02 15:58:52.196094 EDT | AverageAbsQYDiff            0.0165066
2017-07-02 15:58:52.196288 EDT | AverageAction               0.00343596
2017-07-02 15:58:52.196502 EDT | PolicyRegParamNorm         68.6929
2017-07-02 15:58:52.196717 EDT | QFunRegParamNorm           66.7242
2017-07-02 15:58:52.196919 EDT | -----------------------  -------------
2017-07-02 15:58:52.197217 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #840 | Training started
2017-07-02 15:59:01.607351 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #840 | Training finished
2017-07-02 15:59:01.608020 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #840 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 15:59:01.608258 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #840 | Collecting samples for evaluation
2017-07-02 15:59:07.007014 EDT | -----------------------  -------------
2017-07-02 15:59:07.007320 EDT | Epoch                     840
2017-07-02 15:59:07.007526 EDT | Iteration                 840
2017-07-02 15:59:07.007748 EDT | AverageReturn            1000
2017-07-02 15:59:07.007976 EDT | StdReturn                   0
2017-07-02 15:59:07.008181 EDT | MaxReturn                1000
2017-07-02 15:59:07.008389 EDT | MinReturn                1000
2017-07-02 15:59:07.008591 EDT | AverageEsReturn            15.6774
2017-07-02 15:59:07.008815 EDT | StdEsReturn                16.1483
2017-07-02 15:59:07.009020 EDT | MaxEsReturn                65
2017-07-02 15:59:07.009247 EDT | MinEsReturn                 3
2017-07-02 15:59:07.009446 EDT | AverageDiscountedReturn    99.9957
2017-07-02 15:59:07.009709 EDT | AverageQLoss                0.0031721
2017-07-02 15:59:07.009939 EDT | AveragePolicySurr          -1.00476
2017-07-02 15:59:07.010171 EDT | AverageQ                    0.95707
2017-07-02 15:59:07.010386 EDT | AverageAbsQ                 0.960163
2017-07-02 15:59:07.010583 EDT | AverageY                    0.95705
2017-07-02 15:59:07.010778 EDT | AverageAbsY                 0.957757
2017-07-02 15:59:07.011010 EDT | AverageAbsQYDiff            0.0164283
2017-07-02 15:59:07.011210 EDT | AverageAction               0.00301639
2017-07-02 15:59:07.011436 EDT | PolicyRegParamNorm         68.7285
2017-07-02 15:59:07.011644 EDT | QFunRegParamNorm           66.7518
2017-07-02 15:59:07.011877 EDT | -----------------------  -------------
2017-07-02 15:59:07.012180 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #841 | Training started
2017-07-02 15:59:16.383183 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #841 | Training finished
2017-07-02 15:59:16.383784 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #841 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 15:59:16.383978 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #841 | Collecting samples for evaluation
2017-07-02 15:59:21.899320 EDT | -----------------------  -------------
2017-07-02 15:59:21.899867 EDT | Epoch                     841
2017-07-02 15:59:21.900089 EDT | Iteration                 841
2017-07-02 15:59:21.900207 EDT | AverageReturn            1000
2017-07-02 15:59:21.900310 EDT | StdReturn                   0
2017-07-02 15:59:21.900449 EDT | MaxReturn                1000
2017-07-02 15:59:21.900644 EDT | MinReturn                1000
2017-07-02 15:59:21.900810 EDT | AverageEsReturn            18.9444
2017-07-02 15:59:21.900983 EDT | StdEsReturn                18.831
2017-07-02 15:59:21.901202 EDT | MaxEsReturn                80
2017-07-02 15:59:21.901411 EDT | MinEsReturn                 3
2017-07-02 15:59:21.901562 EDT | AverageDiscountedReturn    99.9957
2017-07-02 15:59:21.901769 EDT | AverageQLoss                0.00342883
2017-07-02 15:59:21.901974 EDT | AveragePolicySurr          -1.00856
2017-07-02 15:59:21.902199 EDT | AverageQ                    0.959176
2017-07-02 15:59:21.902418 EDT | AverageAbsQ                 0.962281
2017-07-02 15:59:21.902634 EDT | AverageY                    0.959295
2017-07-02 15:59:21.902850 EDT | AverageAbsY                 0.959812
2017-07-02 15:59:21.903060 EDT | AverageAbsQYDiff            0.0165563
2017-07-02 15:59:21.903250 EDT | AverageAction               0.0270278
2017-07-02 15:59:21.903468 EDT | PolicyRegParamNorm         68.7384
2017-07-02 15:59:21.903657 EDT | QFunRegParamNorm           66.776
2017-07-02 15:59:21.903992 EDT | -----------------------  -------------
2017-07-02 15:59:21.904311 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #842 | Training started
2017-07-02 15:59:31.293993 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #842 | Training finished
2017-07-02 15:59:31.294544 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #842 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 15:59:31.294808 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #842 | Collecting samples for evaluation
2017-07-02 15:59:36.867603 EDT | -----------------------  -------------
2017-07-02 15:59:36.867793 EDT | Epoch                     842
2017-07-02 15:59:36.867916 EDT | Iteration                 842
2017-07-02 15:59:36.868062 EDT | AverageReturn            1000
2017-07-02 15:59:36.868172 EDT | StdReturn                   0
2017-07-02 15:59:36.868288 EDT | MaxReturn                1000
2017-07-02 15:59:36.868395 EDT | MinReturn                1000
2017-07-02 15:59:36.868506 EDT | AverageEsReturn            16.6949
2017-07-02 15:59:36.868635 EDT | StdEsReturn                15.3648
2017-07-02 15:59:36.868755 EDT | MaxEsReturn                64
2017-07-02 15:59:36.868861 EDT | MinEsReturn                 3
2017-07-02 15:59:36.868970 EDT | AverageDiscountedReturn    99.9957
2017-07-02 15:59:36.869098 EDT | AverageQLoss                0.00332246
2017-07-02 15:59:36.869204 EDT | AveragePolicySurr          -1.01034
2017-07-02 15:59:36.869321 EDT | AverageQ                    0.960692
2017-07-02 15:59:36.869472 EDT | AverageAbsQ                 0.964134
2017-07-02 15:59:36.869720 EDT | AverageY                    0.960713
2017-07-02 15:59:36.869945 EDT | AverageAbsY                 0.961286
2017-07-02 15:59:36.870162 EDT | AverageAbsQYDiff            0.0167435
2017-07-02 15:59:36.870289 EDT | AverageAction               0.00273526
2017-07-02 15:59:36.870462 EDT | PolicyRegParamNorm         68.7263
2017-07-02 15:59:36.870609 EDT | QFunRegParamNorm           66.8176
2017-07-02 15:59:36.870809 EDT | -----------------------  -------------
2017-07-02 15:59:36.871081 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #843 | Training started
2017-07-02 15:59:46.429667 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #843 | Training finished
2017-07-02 15:59:46.430147 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #843 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 15:59:46.430320 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #843 | Collecting samples for evaluation
2017-07-02 15:59:51.897791 EDT | -----------------------  -------------
2017-07-02 15:59:51.897998 EDT | Epoch                     843
2017-07-02 15:59:51.898111 EDT | Iteration                 843
2017-07-02 15:59:51.898215 EDT | AverageReturn            1000
2017-07-02 15:59:51.898344 EDT | StdReturn                   0
2017-07-02 15:59:51.898574 EDT | MaxReturn                1000
2017-07-02 15:59:51.898793 EDT | MinReturn                1000
2017-07-02 15:59:51.898995 EDT | AverageEsReturn            12.642
2017-07-02 15:59:51.899223 EDT | StdEsReturn                10.1547
2017-07-02 15:59:51.899450 EDT | MaxEsReturn                43
2017-07-02 15:59:51.899680 EDT | MinEsReturn                 3
2017-07-02 15:59:51.899859 EDT | AverageDiscountedReturn    99.9957
2017-07-02 15:59:51.900092 EDT | AverageQLoss                0.00382318
2017-07-02 15:59:51.900307 EDT | AveragePolicySurr          -1.01475
2017-07-02 15:59:51.900533 EDT | AverageQ                    0.963783
2017-07-02 15:59:51.900761 EDT | AverageAbsQ                 0.96689
2017-07-02 15:59:51.900978 EDT | AverageY                    0.963708
2017-07-02 15:59:51.901207 EDT | AverageAbsY                 0.964177
2017-07-02 15:59:51.901392 EDT | AverageAbsQYDiff            0.017805
2017-07-02 15:59:51.902574 EDT | AverageAction               0.00307341
2017-07-02 15:59:51.902805 EDT | PolicyRegParamNorm         68.7882
2017-07-02 15:59:51.903037 EDT | QFunRegParamNorm           66.8442
2017-07-02 15:59:51.903235 EDT | -----------------------  -------------
2017-07-02 15:59:51.903560 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #844 | Training started
2017-07-02 16:00:01.338049 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #844 | Training finished
2017-07-02 16:00:01.338669 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #844 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 16:00:01.338922 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #844 | Collecting samples for evaluation
2017-07-02 16:00:06.780702 EDT | -----------------------  -------------
2017-07-02 16:00:06.780999 EDT | Epoch                     844
2017-07-02 16:00:06.781236 EDT | Iteration                 844
2017-07-02 16:00:06.781439 EDT | AverageReturn            1000
2017-07-02 16:00:06.781614 EDT | StdReturn                   0
2017-07-02 16:00:06.781753 EDT | MaxReturn                1000
2017-07-02 16:00:06.781857 EDT | MinReturn                1000
2017-07-02 16:00:06.782048 EDT | AverageEsReturn            15.0847
2017-07-02 16:00:06.782244 EDT | StdEsReturn                16.468
2017-07-02 16:00:06.782439 EDT | MaxEsReturn                89
2017-07-02 16:00:06.782570 EDT | MinEsReturn                 3
2017-07-02 16:00:06.782671 EDT | AverageDiscountedReturn    99.9957
2017-07-02 16:00:06.782826 EDT | AverageQLoss                0.00301799
2017-07-02 16:00:06.782934 EDT | AveragePolicySurr          -1.01885
2017-07-02 16:00:06.783033 EDT | AverageQ                    0.966804
2017-07-02 16:00:06.783191 EDT | AverageAbsQ                 0.968988
2017-07-02 16:00:06.783297 EDT | AverageY                    0.966825
2017-07-02 16:00:06.783396 EDT | AverageAbsY                 0.967088
2017-07-02 16:00:06.783494 EDT | AverageAbsQYDiff            0.0158705
2017-07-02 16:00:06.783617 EDT | AverageAction               0.0026342
2017-07-02 16:00:06.783725 EDT | PolicyRegParamNorm         68.8414
2017-07-02 16:00:06.783825 EDT | QFunRegParamNorm           66.8753
2017-07-02 16:00:06.783924 EDT | -----------------------  -------------
2017-07-02 16:00:06.784141 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #845 | Training started
2017-07-02 16:00:16.226078 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #845 | Training finished
2017-07-02 16:00:16.226626 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #845 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 16:00:16.226881 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #845 | Collecting samples for evaluation
2017-07-02 16:00:22.102549 EDT | -----------------------  -------------
2017-07-02 16:00:22.102863 EDT | Epoch                     845
2017-07-02 16:00:22.103104 EDT | Iteration                 845
2017-07-02 16:00:22.103336 EDT | AverageReturn            1000
2017-07-02 16:00:22.103470 EDT | StdReturn                   0
2017-07-02 16:00:22.103691 EDT | MaxReturn                1000
2017-07-02 16:00:22.103921 EDT | MinReturn                1000
2017-07-02 16:00:22.104094 EDT | AverageEsReturn            16.2308
2017-07-02 16:00:22.104327 EDT | StdEsReturn                20.0973
2017-07-02 16:00:22.104541 EDT | MaxEsReturn               113
2017-07-02 16:00:22.104775 EDT | MinEsReturn                 3
2017-07-02 16:00:22.104989 EDT | AverageDiscountedReturn    99.9957
2017-07-02 16:00:22.105211 EDT | AverageQLoss                0.0035679
2017-07-02 16:00:22.105335 EDT | AveragePolicySurr          -1.02404
2017-07-02 16:00:22.105575 EDT | AverageQ                    0.971282
2017-07-02 16:00:22.105804 EDT | AverageAbsQ                 0.974231
2017-07-02 16:00:22.105985 EDT | AverageY                    0.971268
2017-07-02 16:00:22.106217 EDT | AverageAbsY                 0.971446
2017-07-02 16:00:22.106407 EDT | AverageAbsQYDiff            0.0174034
2017-07-02 16:00:22.106512 EDT | AverageAction               0.00159994
2017-07-02 16:00:22.106663 EDT | PolicyRegParamNorm         68.944
2017-07-02 16:00:22.106765 EDT | QFunRegParamNorm           66.9059
2017-07-02 16:00:22.106865 EDT | -----------------------  -------------
2017-07-02 16:00:22.107050 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #846 | Training started
2017-07-02 16:00:31.542899 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #846 | Training finished
2017-07-02 16:00:31.544041 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #846 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 16:00:31.544297 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #846 | Collecting samples for evaluation
2017-07-02 16:00:36.995119 EDT | -----------------------  -------------
2017-07-02 16:00:36.995425 EDT | Epoch                     846
2017-07-02 16:00:36.995638 EDT | Iteration                 846
2017-07-02 16:00:36.995872 EDT | AverageReturn            1000
2017-07-02 16:00:36.996084 EDT | StdReturn                   0
2017-07-02 16:00:36.996319 EDT | MaxReturn                1000
2017-07-02 16:00:36.996536 EDT | MinReturn                1000
2017-07-02 16:00:36.996705 EDT | AverageEsReturn            14.4861
2017-07-02 16:00:36.996943 EDT | StdEsReturn                16.768
2017-07-02 16:00:36.997121 EDT | MaxEsReturn                76
2017-07-02 16:00:36.997257 EDT | MinEsReturn                 3
2017-07-02 16:00:36.997699 EDT | AverageDiscountedReturn    99.9957
2017-07-02 16:00:36.997944 EDT | AverageQLoss                0.00320235
2017-07-02 16:00:36.998172 EDT | AveragePolicySurr          -1.0292
2017-07-02 16:00:36.998377 EDT | AverageQ                    0.976631
2017-07-02 16:00:36.998609 EDT | AverageAbsQ                 0.979065
2017-07-02 16:00:36.998806 EDT | AverageY                    0.976643
2017-07-02 16:00:36.999038 EDT | AverageAbsY                 0.976906
2017-07-02 16:00:36.999263 EDT | AverageAbsQYDiff            0.0164337
2017-07-02 16:00:36.999480 EDT | AverageAction               0.00182442
2017-07-02 16:00:36.999707 EDT | PolicyRegParamNorm         68.9989
2017-07-02 16:00:36.999916 EDT | QFunRegParamNorm           66.9299
2017-07-02 16:00:37.000113 EDT | -----------------------  -------------
2017-07-02 16:00:37.000441 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #847 | Training started
2017-07-02 16:00:46.406738 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #847 | Training finished
2017-07-02 16:00:46.407297 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #847 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 16:00:46.407449 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #847 | Collecting samples for evaluation
2017-07-02 16:00:51.905601 EDT | -----------------------  ------------
2017-07-02 16:00:51.905817 EDT | Epoch                     847
2017-07-02 16:00:51.906064 EDT | Iteration                 847
2017-07-02 16:00:51.906286 EDT | AverageReturn            1000
2017-07-02 16:00:51.906531 EDT | StdReturn                   0
2017-07-02 16:00:51.906743 EDT | MaxReturn                1000
2017-07-02 16:00:51.906891 EDT | MinReturn                1000
2017-07-02 16:00:51.907036 EDT | AverageEsReturn            15
2017-07-02 16:00:51.907144 EDT | StdEsReturn                14.7422
2017-07-02 16:00:51.907275 EDT | MaxEsReturn                91
2017-07-02 16:00:51.907438 EDT | MinEsReturn                 3
2017-07-02 16:00:51.907660 EDT | AverageDiscountedReturn    99.9957
2017-07-02 16:00:51.907887 EDT | AverageQLoss                0.0038997
2017-07-02 16:00:51.908094 EDT | AveragePolicySurr          -1.03596
2017-07-02 16:00:51.908326 EDT | AverageQ                    0.982636
2017-07-02 16:00:51.908553 EDT | AverageAbsQ                 0.985685
2017-07-02 16:00:51.908756 EDT | AverageY                    0.982718
2017-07-02 16:00:51.908962 EDT | AverageAbsY                 0.982941
2017-07-02 16:00:51.909197 EDT | AverageAbsQYDiff            0.0184399
2017-07-02 16:00:51.909413 EDT | AverageAction               0.0014429
2017-07-02 16:00:51.909643 EDT | PolicyRegParamNorm         69.1099
2017-07-02 16:00:51.909871 EDT | QFunRegParamNorm           66.9577
2017-07-02 16:00:51.910058 EDT | -----------------------  ------------
2017-07-02 16:00:51.910386 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #848 | Training started
2017-07-02 16:01:01.305378 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #848 | Training finished
2017-07-02 16:01:01.305922 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #848 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 16:01:01.306061 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #848 | Collecting samples for evaluation
2017-07-02 16:01:06.786858 EDT | -----------------------  -------------
2017-07-02 16:01:06.787172 EDT | Epoch                     848
2017-07-02 16:01:06.787412 EDT | Iteration                 848
2017-07-02 16:01:06.787626 EDT | AverageReturn            1000
2017-07-02 16:01:06.787860 EDT | StdReturn                   0
2017-07-02 16:01:06.788086 EDT | MaxReturn                1000
2017-07-02 16:01:06.788200 EDT | MinReturn                1000
2017-07-02 16:01:06.788305 EDT | AverageEsReturn            25.575
2017-07-02 16:01:06.788480 EDT | StdEsReturn                31.1544
2017-07-02 16:01:06.788710 EDT | MaxEsReturn               163
2017-07-02 16:01:06.788889 EDT | MinEsReturn                 3
2017-07-02 16:01:06.789119 EDT | AverageDiscountedReturn    99.9957
2017-07-02 16:01:06.789336 EDT | AverageQLoss                0.00343061
2017-07-02 16:01:06.789566 EDT | AveragePolicySurr          -1.04287
2017-07-02 16:01:06.789795 EDT | AverageQ                    0.989914
2017-07-02 16:01:06.789960 EDT | AverageAbsQ                 0.992377
2017-07-02 16:01:06.790193 EDT | AverageY                    0.989997
2017-07-02 16:01:06.790395 EDT | AverageAbsY                 0.990293
2017-07-02 16:01:06.790519 EDT | AverageAbsQYDiff            0.017461
2017-07-02 16:01:06.790751 EDT | AverageAction               0.00114418
2017-07-02 16:01:06.790967 EDT | PolicyRegParamNorm         69.2035
2017-07-02 16:01:06.791191 EDT | QFunRegParamNorm           67.0059
2017-07-02 16:01:06.791415 EDT | -----------------------  -------------
2017-07-02 16:01:06.791703 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #849 | Training started
2017-07-02 16:01:16.078606 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #849 | Training finished
2017-07-02 16:01:16.079249 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #849 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 16:01:16.079416 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #849 | Collecting samples for evaluation
2017-07-02 16:01:21.602283 EDT | -----------------------  -------------
2017-07-02 16:01:21.602587 EDT | Epoch                     849
2017-07-02 16:01:21.602822 EDT | Iteration                 849
2017-07-02 16:01:21.603036 EDT | AverageReturn            1000
2017-07-02 16:01:21.603238 EDT | StdReturn                   0
2017-07-02 16:01:21.603458 EDT | MaxReturn                1000
2017-07-02 16:01:21.603678 EDT | MinReturn                1000
2017-07-02 16:01:21.603905 EDT | AverageEsReturn            23.7619
2017-07-02 16:01:21.604100 EDT | StdEsReturn                29.8774
2017-07-02 16:01:21.604301 EDT | MaxEsReturn               148
2017-07-02 16:01:21.604526 EDT | MinEsReturn                 2
2017-07-02 16:01:21.604744 EDT | AverageDiscountedReturn    99.9957
2017-07-02 16:01:21.604970 EDT | AverageQLoss                0.00371056
2017-07-02 16:01:21.605180 EDT | AveragePolicySurr          -1.04662
2017-07-02 16:01:21.605328 EDT | AverageQ                    0.994402
2017-07-02 16:01:21.605432 EDT | AverageAbsQ                 0.997648
2017-07-02 16:01:21.605625 EDT | AverageY                    0.994396
2017-07-02 16:01:21.605826 EDT | AverageAbsY                 0.994698
2017-07-02 16:01:21.606019 EDT | AverageAbsQYDiff            0.0188532
2017-07-02 16:01:21.606225 EDT | AverageAction               0.00104884
2017-07-02 16:01:21.606409 EDT | PolicyRegParamNorm         69.23
2017-07-02 16:01:21.606547 EDT | QFunRegParamNorm           67.026
2017-07-02 16:01:21.606670 EDT | -----------------------  -------------
2017-07-02 16:01:21.606863 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #850 | Training started
2017-07-02 16:01:30.743009 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #850 | Training finished
2017-07-02 16:01:30.743657 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #850 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 16:01:30.743809 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #850 | Collecting samples for evaluation
2017-07-02 16:01:36.333727 EDT | -----------------------  --------------
2017-07-02 16:01:36.333950 EDT | Epoch                     850
2017-07-02 16:01:36.334136 EDT | Iteration                 850
2017-07-02 16:01:36.334296 EDT | AverageReturn            1000
2017-07-02 16:01:36.334399 EDT | StdReturn                   0
2017-07-02 16:01:36.334593 EDT | MaxReturn                1000
2017-07-02 16:01:36.334771 EDT | MinReturn                1000
2017-07-02 16:01:36.334916 EDT | AverageEsReturn            25.2051
2017-07-02 16:01:36.335019 EDT | StdEsReturn                27.3573
2017-07-02 16:01:36.335138 EDT | MaxEsReturn               111
2017-07-02 16:01:36.335239 EDT | MinEsReturn                 3
2017-07-02 16:01:36.335340 EDT | AverageDiscountedReturn    99.9957
2017-07-02 16:01:36.335456 EDT | AverageQLoss                0.00395999
2017-07-02 16:01:36.335556 EDT | AveragePolicySurr          -1.05243
2017-07-02 16:01:36.335655 EDT | AverageQ                    0.997742
2017-07-02 16:01:36.335754 EDT | AverageAbsQ                 1.00105
2017-07-02 16:01:36.335851 EDT | AverageY                    0.997787
2017-07-02 16:01:36.335951 EDT | AverageAbsY                 0.998133
2017-07-02 16:01:36.336051 EDT | AverageAbsQYDiff            0.0193177
2017-07-02 16:01:36.336168 EDT | AverageAction               0.000879861
2017-07-02 16:01:36.336268 EDT | PolicyRegParamNorm         69.2849
2017-07-02 16:01:36.336371 EDT | QFunRegParamNorm           67.0412
2017-07-02 16:01:36.336548 EDT | -----------------------  --------------
2017-07-02 16:01:36.336727 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #851 | Training started
2017-07-02 16:01:45.592685 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #851 | Training finished
2017-07-02 16:01:45.593212 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #851 | Trained qf 1000 steps, policy 1000 steps
2017-07-02 16:01:45.593374 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #851 | Collecting samples for evaluation
2017-07-02 16:01:51.060028 EDT | -----------------------  -------------
2017-07-02 16:01:51.060346 EDT | Epoch                     851
2017-07-02 16:01:51.060533 EDT | Iteration                 851
2017-07-02 16:01:51.060770 EDT | AverageReturn            1000
2017-07-02 16:01:51.060996 EDT | StdReturn                   0
2017-07-02 16:01:51.061219 EDT | MaxReturn                1000
2017-07-02 16:01:51.061425 EDT | MinReturn                1000
2017-07-02 16:01:51.061670 EDT | AverageEsReturn            18.8148
2017-07-02 16:01:51.061852 EDT | StdEsReturn                21.9975
2017-07-02 16:01:51.062079 EDT | MaxEsReturn                99
2017-07-02 16:01:51.062305 EDT | MinEsReturn                 3
2017-07-02 16:01:51.062527 EDT | AverageDiscountedReturn    99.9957
2017-07-02 16:01:51.062740 EDT | AverageQLoss                0.00355236
2017-07-02 16:01:51.062882 EDT | AveragePolicySurr          -1.05904
2017-07-02 16:01:51.063100 EDT | AverageQ                    1.00429
2017-07-02 16:01:51.063247 EDT | AverageAbsQ                 1.00698
2017-07-02 16:01:51.063349 EDT | AverageY                    1.00432
2017-07-02 16:01:51.063544 EDT | AverageAbsY                 1.00463
2017-07-02 16:01:51.063752 EDT | AverageAbsQYDiff            0.0183162
2017-07-02 16:01:51.063961 EDT | AverageAction               0.00112362
2017-07-02 16:01:51.064181 EDT | PolicyRegParamNorm         69.3119
2017-07-02 16:01:51.064397 EDT | QFunRegParamNorm           67.0781
2017-07-02 16:01:51.064576 EDT | -----------------------  -------------
2017-07-02 16:01:51.064784 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.01_Experiment_1] epoch #852 | Training started
