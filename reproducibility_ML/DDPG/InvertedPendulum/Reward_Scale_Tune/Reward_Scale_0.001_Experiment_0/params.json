{
  "args_data": "gANjcmxsYWIubWlzYy5pbnN0cnVtZW50ClN0dWJNZXRob2RDYWxsCnEAKYFxAX1xAihYBgAAAF9fYXJnc3EDKGNybGxhYi5taXNjLmluc3RydW1lbnQKU3R1Yk9iamVjdApxBCmBcQV9cQYoWAQAAABhcmdzcQcpWAYAAABrd2FyZ3NxCH1xCShYCAAAAGRpc2NvdW50cQpHP++uFHrhR65YDQAAAG1pbl9wb29sX3NpemVxC00QJ1gMAAAAZXBvY2hfbGVuZ3RocQxN6ANYFAAAAHBvbGljeV9sZWFybmluZ19yYXRlcQ1HPxo24uscQy1YAgAAAHFmcQ5oBCmBcQ99cRAoaAcpaAh9cREoWBMAAABoaWRkZW5fbm9ubGluZWFyaXR5cRJjdGVuc29yZmxvdy5weXRob24ub3BzLmdlbl9ubl9vcHMKcmVsdQpxE1gIAAAAZW52X3NwZWNxFGNybGxhYi5taXNjLmluc3RydW1lbnQKU3R1YkF0dHIKcRUpgXEWfXEXKFgKAAAAX2F0dHJfbmFtZXEYWAQAAABzcGVjcRlYBAAAAF9vYmpxGmgEKYFxG31xHChoByloCH1xHVgLAAAAd3JhcHBlZF9lbnZxHmgEKYFxH31xIChoByloCH1xIVgDAAAAZW52cSJoBCmBcSN9cSQoaAcpaAh9cSUoWAgAAABlbnZfbmFtZXEmWBMAAABJbnZlcnRlZFBlbmR1bHVtLXYxcSdYCwAAAGZvcmNlX3Jlc2V0cSiIWAwAAAByZWNvcmRfdmlkZW9xKYlYCgAAAHJlY29yZF9sb2dxKol1WAsAAABwcm94eV9jbGFzc3ErY3JsbGFiLmVudnMuZ3ltX2VudgpHeW1FbnYKcSx1YnNoK2NybGxhYi5lbnZzLm5vcm1hbGl6ZWRfZW52Ck5vcm1hbGl6ZWRFbnYKcS11YnNoK2NzYW5kYm94LnJvY2t5LnRmLmVudnMuYmFzZQpUZkVudgpxLnVidWJYDAAAAGhpZGRlbl9zaXplc3EvS2RLZIZxMHVoK2NzYW5kYm94LnJvY2t5LnRmLnFfZnVuY3Rpb25zLmNvbnRpbnVvdXNfbWxwX3FfZnVuY3Rpb24KQ29udGludW91c01MUFFGdW5jdGlvbgpxMXViWAwAAABzY2FsZV9yZXdhcmRxMkc/UGJN0vGp/FgCAAAAZXNxM2gEKYFxNH1xNShoByloCH1xNmgUaBUpgXE3fXE4KGgYaBloGmgbdWJzaCtjcmxsYWIuZXhwbG9yYXRpb25fc3RyYXRlZ2llcy5vdV9zdHJhdGVneQpPVVN0cmF0ZWd5CnE5dWJYDwAAAG1heF9wYXRoX2xlbmd0aHE6aBUpgXE7fXE8KGgYWAcAAABob3Jpem9ucT1oGmgbdWJoImgbWBAAAABxZl9sZWFybmluZ19yYXRlcT5HP1BiTdLxqfxYBgAAAHBvbGljeXE/aAQpgXFAfXFBKGgHKWgIfXFCKGgSaBNoFGgVKYFxQ31xRChoGGgZaBpoG3ViaC9LZEsySxmHcUVYBAAAAG5hbWVxRmg/dWgrY3NhbmRib3gucm9ja3kudGYucG9saWNpZXMuZGV0ZXJtaW5pc3RpY19tbHBfcG9saWN5CkRldGVybWluaXN0aWNNTFBQb2xpY3kKcUd1YlgIAAAAbl9lcG9jaHNxSE2IE1gEAAAAcGxvdHFJiVgKAAAAYmF0Y2hfc2l6ZXFKSyB1aCtjZGRwZ190ZW5zb3JmbG93LmRkcGcKRERQRwpxS3ViWAUAAAB0cmFpbnFMKX1xTXRxTlgIAAAAX19rd2FyZ3NxT31xUHViLg==",
  "exp_name": "reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0",
  "json_args": {
    "algo": {
      "_name": "ddpg_tensorflow.ddpg.DDPG",
      "batch_size": 32,
      "discount": 0.99,
      "epoch_length": 1000,
      "es": {
        "_name": "rllab.exploration_strategies.ou_strategy.OUStrategy",
        "env_spec": {
          "attr": "spec",
          "obj": {
            "_name": "sandbox.rocky.tf.envs.base.TfEnv",
            "wrapped_env": {
              "_name": "rllab.envs.normalized_env.NormalizedEnv",
              "env": {
                "_name": "rllab.envs.gym_env.GymEnv",
                "env_name": "InvertedPendulum-v1",
                "force_reset": true,
                "record_log": false,
                "record_video": false
              }
            }
          }
        }
      },
      "max_path_length": {
        "attr": "horizon",
        "obj": {
          "_name": "sandbox.rocky.tf.envs.base.TfEnv",
          "wrapped_env": {
            "_name": "rllab.envs.normalized_env.NormalizedEnv",
            "env": {
              "_name": "rllab.envs.gym_env.GymEnv",
              "env_name": "InvertedPendulum-v1",
              "force_reset": true,
              "record_log": false,
              "record_video": false
            }
          }
        }
      },
      "min_pool_size": 10000,
      "n_epochs": 5000,
      "plot": false,
      "policy_learning_rate": 0.0001,
      "qf": {
        "_name": "sandbox.rocky.tf.q_functions.continuous_mlp_q_function.ContinuousMLPQFunction",
        "env_spec": {
          "attr": "spec",
          "obj": {
            "_name": "sandbox.rocky.tf.envs.base.TfEnv",
            "wrapped_env": {
              "_name": "rllab.envs.normalized_env.NormalizedEnv",
              "env": {
                "_name": "rllab.envs.gym_env.GymEnv",
                "env_name": "InvertedPendulum-v1",
                "force_reset": true,
                "record_log": false,
                "record_video": false
              }
            }
          }
        },
        "hidden_nonlinearity": "tensorflow.python.ops.gen_nn_ops.relu",
        "hidden_sizes": [
          100,
          100
        ]
      },
      "qf_learning_rate": 0.001,
      "scale_reward": 0.001
    },
    "env": {
      "_name": "sandbox.rocky.tf.envs.base.TfEnv",
      "wrapped_env": {
        "_name": "rllab.envs.normalized_env.NormalizedEnv",
        "env": {
          "_name": "rllab.envs.gym_env.GymEnv",
          "env_name": "InvertedPendulum-v1",
          "force_reset": true,
          "record_log": false,
          "record_video": false
        }
      }
    },
    "policy": {
      "_name": "sandbox.rocky.tf.policies.deterministic_mlp_policy.DeterministicMLPPolicy",
      "env_spec": {
        "attr": "spec",
        "obj": {
          "_name": "sandbox.rocky.tf.envs.base.TfEnv",
          "wrapped_env": {
            "_name": "rllab.envs.normalized_env.NormalizedEnv",
            "env": {
              "_name": "rllab.envs.gym_env.GymEnv",
              "env_name": "InvertedPendulum-v1",
              "force_reset": true,
              "record_log": false,
              "record_video": false
            }
          }
        }
      },
      "hidden_nonlinearity": "tensorflow.python.ops.gen_nn_ops.relu",
      "hidden_sizes": [
        100,
        50,
        25
      ],
      "name": "policy"
    }
  },
  "log_dir": "/home/ml/rislam4/Documents/RLLAB/rllab/data/local/experiment/reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0",
  "log_tabular_only": false,
  "n_parallel": 1,
  "params_log_file": "params.json",
  "plot": false,
  "resume_from": null,
  "seed": 1,
  "snapshot_gap": 1,
  "snapshot_mode": "last",
  "tabular_log_file": "progress.csv",
  "text_log_file": "debug.log",
  "use_cloudpickle": false,
  "variant_data": null,
  "variant_log_file": "variant.json"
}