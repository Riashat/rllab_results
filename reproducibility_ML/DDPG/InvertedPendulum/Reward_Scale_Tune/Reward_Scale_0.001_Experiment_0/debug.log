2017-06-03 12:49:32.609414 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] observation space: Box(4,)
2017-06-03 12:49:32.609846 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] action space: Box(1,)
2017-06-03 12:49:33.414468 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] Populating workers...
2017-06-03 12:49:33.415438 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] Populated
2017-06-03 12:49:34.447266 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #0 | Training started
2017-06-03 12:49:35.907701 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #0 | Training finished
2017-06-03 12:49:35.908084 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #0 | Trained qf 0 steps, policy 0 steps
2017-06-03 12:49:35.908408 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #1 | Training started
2017-06-03 12:49:36.924051 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #1 | Training finished
2017-06-03 12:49:36.925509 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #1 | Trained qf 0 steps, policy 0 steps
2017-06-03 12:49:36.925835 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #2 | Training started
2017-06-03 12:49:38.000199 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #2 | Training finished
2017-06-03 12:49:38.000563 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #2 | Trained qf 0 steps, policy 0 steps
2017-06-03 12:49:38.000860 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #3 | Training started
2017-06-03 12:49:38.856511 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #3 | Training finished
2017-06-03 12:49:38.856854 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #3 | Trained qf 0 steps, policy 0 steps
2017-06-03 12:49:38.857164 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #4 | Training started
2017-06-03 12:49:39.915170 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #4 | Training finished
2017-06-03 12:49:39.915557 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #4 | Trained qf 0 steps, policy 0 steps
2017-06-03 12:49:39.915873 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #5 | Training started
2017-06-03 12:49:41.109085 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #5 | Training finished
2017-06-03 12:49:41.109510 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #5 | Trained qf 0 steps, policy 0 steps
2017-06-03 12:49:41.109822 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #6 | Training started
2017-06-03 12:49:42.218272 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #6 | Training finished
2017-06-03 12:49:42.219145 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #6 | Trained qf 0 steps, policy 0 steps
2017-06-03 12:49:42.219478 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #7 | Training started
2017-06-03 12:49:43.102808 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #7 | Training finished
2017-06-03 12:49:43.103231 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #7 | Trained qf 0 steps, policy 0 steps
2017-06-03 12:49:43.103514 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #8 | Training started
2017-06-03 12:49:44.134447 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #8 | Training finished
2017-06-03 12:49:44.135065 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #8 | Trained qf 0 steps, policy 0 steps
2017-06-03 12:49:44.135402 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #9 | Training started
2017-06-03 12:49:45.620838 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #9 | Training finished
2017-06-03 12:49:45.621239 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #9 | Trained qf 1 steps, policy 1 steps
2017-06-03 12:49:45.621503 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #9 | Collecting samples for evaluation
2017-06-03 12:49:55.120705 EDT | -----------------------  ------------
2017-06-03 12:49:55.121190 EDT | Epoch                     9
2017-06-03 12:49:55.121444 EDT | Iteration                 9
2017-06-03 12:49:55.121686 EDT | AverageReturn            22.3803
2017-06-03 12:49:55.121962 EDT | StdReturn                 4.69693
2017-06-03 12:49:55.122213 EDT | MaxReturn                36
2017-06-03 12:49:55.122450 EDT | MinReturn                15
2017-06-03 12:49:55.122716 EDT | AverageEsReturn           5.86847
2017-06-03 12:49:55.122955 EDT | StdEsReturn               2.89659
2017-06-03 12:49:55.123188 EDT | MaxEsReturn              29
2017-06-03 12:49:55.123421 EDT | MinEsReturn               3
2017-06-03 12:49:55.123653 EDT | AverageDiscountedReturn  20.0539
2017-06-03 12:49:55.123898 EDT | AverageQLoss              0.0267973
2017-06-03 12:49:55.124131 EDT | AveragePolicySurr         0.0162635
2017-06-03 12:49:55.124365 EDT | AverageQ                  0.0639861
2017-06-03 12:49:55.124596 EDT | AverageAbsQ               0.0703461
2017-06-03 12:49:55.124827 EDT | AverageY                 -0.0131741
2017-06-03 12:49:55.125058 EDT | AverageAbsY               0.0574493
2017-06-03 12:49:55.125290 EDT | AverageAbsQYDiff          0.103903
2017-06-03 12:49:55.125522 EDT | AverageAction             0.000618868
2017-06-03 12:49:55.125778 EDT | PolicyRegParamNorm       10.4747
2017-06-03 12:49:55.126014 EDT | QFunRegParamNorm         10.4469
2017-06-03 12:49:55.126247 EDT | -----------------------  ------------
2017-06-03 12:49:55.126786 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #10 | Training started
2017-06-03 12:50:11.296246 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #10 | Training finished
2017-06-03 12:50:11.297159 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #10 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 12:50:11.297434 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #10 | Collecting samples for evaluation
2017-06-03 12:50:22.742892 EDT | -----------------------  ------------
2017-06-03 12:50:22.743322 EDT | Epoch                    10
2017-06-03 12:50:22.743605 EDT | Iteration                10
2017-06-03 12:50:22.743836 EDT | AverageReturn             2.38597
2017-06-03 12:50:22.744061 EDT | StdReturn                 0.486824
2017-06-03 12:50:22.744282 EDT | MaxReturn                 3
2017-06-03 12:50:22.744503 EDT | MinReturn                 2
2017-06-03 12:50:22.744728 EDT | AverageEsReturn           2.84419
2017-06-03 12:50:22.744952 EDT | StdEsReturn               0.718888
2017-06-03 12:50:22.745235 EDT | MaxEsReturn               7
2017-06-03 12:50:22.745502 EDT | MinEsReturn               2
2017-06-03 12:50:22.745766 EDT | AverageDiscountedReturn   2.36829
2017-06-03 12:50:22.746035 EDT | AverageQLoss              0.000888473
2017-06-03 12:50:22.746317 EDT | AveragePolicySurr        -0.077445
2017-06-03 12:50:22.746549 EDT | AverageQ                  0.025033
2017-06-03 12:50:22.746805 EDT | AverageAbsQ               0.0476798
2017-06-03 12:50:22.747080 EDT | AverageY                  0.0250747
2017-06-03 12:50:22.747330 EDT | AverageAbsY               0.0457071
2017-06-03 12:50:22.747561 EDT | AverageAbsQYDiff          0.0165813
2017-06-03 12:50:22.747832 EDT | AverageAction             0.999945
2017-06-03 12:50:22.748138 EDT | PolicyRegParamNorm       11.1908
2017-06-03 12:50:22.748433 EDT | QFunRegParamNorm         10.7711
2017-06-03 12:50:22.748699 EDT | -----------------------  ------------
2017-06-03 12:50:22.749174 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #11 | Training started
2017-06-03 12:50:40.488857 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #11 | Training finished
2017-06-03 12:50:40.489558 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #11 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 12:50:40.489855 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #11 | Collecting samples for evaluation
2017-06-03 12:50:52.151293 EDT | -----------------------  ------------
2017-06-03 12:50:52.152097 EDT | Epoch                    11
2017-06-03 12:50:52.152361 EDT | Iteration                11
2017-06-03 12:50:52.152604 EDT | AverageReturn             2.38484
2017-06-03 12:50:52.152845 EDT | StdReturn                 0.486556
2017-06-03 12:50:52.153085 EDT | MaxReturn                 3
2017-06-03 12:50:52.153332 EDT | MinReturn                 2
2017-06-03 12:50:52.153571 EDT | AverageEsReturn           2.73973
2017-06-03 12:50:52.153855 EDT | StdEsReturn               0.611026
2017-06-03 12:50:52.154132 EDT | MaxEsReturn               9
2017-06-03 12:50:52.154370 EDT | MinEsReturn               2
2017-06-03 12:50:52.154621 EDT | AverageDiscountedReturn   2.36718
2017-06-03 12:50:52.154858 EDT | AverageQLoss              0.000273694
2017-06-03 12:50:52.155099 EDT | AveragePolicySurr        -0.0284415
2017-06-03 12:50:52.155350 EDT | AverageQ                  0.0562928
2017-06-03 12:50:52.155596 EDT | AverageAbsQ               0.058708
2017-06-03 12:50:52.155858 EDT | AverageY                  0.0563145
2017-06-03 12:50:52.156101 EDT | AverageAbsY               0.0573225
2017-06-03 12:50:52.156352 EDT | AverageAbsQYDiff          0.00913448
2017-06-03 12:50:52.156598 EDT | AverageAction             0.999909
2017-06-03 12:50:52.156837 EDT | PolicyRegParamNorm       11.1467
2017-06-03 12:50:52.157077 EDT | QFunRegParamNorm         10.9851
2017-06-03 12:50:52.157315 EDT | -----------------------  ------------
2017-06-03 12:50:52.157753 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #12 | Training started
2017-06-03 12:51:08.074486 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #12 | Training finished
2017-06-03 12:51:08.075509 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #12 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 12:51:08.075824 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #12 | Collecting samples for evaluation
2017-06-03 12:51:17.213892 EDT | -----------------------  ------------
2017-06-03 12:51:17.214810 EDT | Epoch                    12
2017-06-03 12:51:17.215067 EDT | Iteration                12
2017-06-03 12:51:17.215331 EDT | AverageReturn             4.02901
2017-06-03 12:51:17.215652 EDT | StdReturn                 0.167831
2017-06-03 12:51:17.215985 EDT | MaxReturn                 5
2017-06-03 12:51:17.216339 EDT | MinReturn                 4
2017-06-03 12:51:17.216681 EDT | AverageEsReturn           3.34448
2017-06-03 12:51:17.217028 EDT | StdEsReturn               1.75366
2017-06-03 12:51:17.217354 EDT | MaxEsReturn              16
2017-06-03 12:51:17.217711 EDT | MinEsReturn               2
2017-06-03 12:51:17.218068 EDT | AverageDiscountedReturn   3.96826
2017-06-03 12:51:17.218309 EDT | AverageQLoss              6.76025e-05
2017-06-03 12:51:17.218539 EDT | AveragePolicySurr        -0.0262677
2017-06-03 12:51:17.218765 EDT | AverageQ                  0.0308085
2017-06-03 12:51:17.218991 EDT | AverageAbsQ               0.0324476
2017-06-03 12:51:17.219226 EDT | AverageY                  0.0307934
2017-06-03 12:51:17.219450 EDT | AverageAbsY               0.0314073
2017-06-03 12:51:17.219675 EDT | AverageAbsQYDiff          0.00469539
2017-06-03 12:51:17.219899 EDT | AverageAction             0.311022
2017-06-03 12:51:17.220122 EDT | PolicyRegParamNorm       12.2634
2017-06-03 12:51:17.220353 EDT | QFunRegParamNorm         11.0211
2017-06-03 12:51:17.220576 EDT | -----------------------  ------------
2017-06-03 12:51:17.220976 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #13 | Training started
2017-06-03 12:51:34.558778 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #13 | Training finished
2017-06-03 12:51:34.560593 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #13 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 12:51:34.560871 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #13 | Collecting samples for evaluation
2017-06-03 12:51:41.988780 EDT | -----------------------  ------------
2017-06-03 12:51:41.989213 EDT | Epoch                    13
2017-06-03 12:51:41.989472 EDT | Iteration                13
2017-06-03 12:51:41.989731 EDT | AverageReturn            48.1683
2017-06-03 12:51:41.989993 EDT | StdReturn                 2.50683
2017-06-03 12:51:41.990241 EDT | MaxReturn                65
2017-06-03 12:51:41.990515 EDT | MinReturn                41
2017-06-03 12:51:41.990762 EDT | AverageEsReturn          12.1728
2017-06-03 12:51:41.991009 EDT | StdEsReturn              11.2115
2017-06-03 12:51:41.991269 EDT | MaxEsReturn              52
2017-06-03 12:51:41.991537 EDT | MinEsReturn               3
2017-06-03 12:51:41.991805 EDT | AverageDiscountedReturn  38.356
2017-06-03 12:51:41.992061 EDT | AverageQLoss              4.10606e-05
2017-06-03 12:51:41.992306 EDT | AveragePolicySurr        -0.0629361
2017-06-03 12:51:41.992549 EDT | AverageQ                  0.0373182
2017-06-03 12:51:41.992791 EDT | AverageAbsQ               0.038402
2017-06-03 12:51:41.993045 EDT | AverageY                  0.0373283
2017-06-03 12:51:41.993298 EDT | AverageAbsY               0.0374374
2017-06-03 12:51:41.993541 EDT | AverageAbsQYDiff          0.00422785
2017-06-03 12:51:41.993795 EDT | AverageAction             0.38617
2017-06-03 12:51:41.994049 EDT | PolicyRegParamNorm       13.9207
2017-06-03 12:51:41.994297 EDT | QFunRegParamNorm         11.0983
2017-06-03 12:51:41.994571 EDT | -----------------------  ------------
2017-06-03 12:51:41.995002 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #14 | Training started
2017-06-03 12:51:58.378215 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #14 | Training finished
2017-06-03 12:51:58.379138 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #14 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 12:51:58.379414 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #14 | Collecting samples for evaluation
2017-06-03 12:52:06.422130 EDT | -----------------------  ------------
2017-06-03 12:52:06.423010 EDT | Epoch                    14
2017-06-03 12:52:06.423399 EDT | Iteration                14
2017-06-03 12:52:06.423745 EDT | AverageReturn            69.9301
2017-06-03 12:52:06.424095 EDT | StdReturn                 2.6907
2017-06-03 12:52:06.424414 EDT | MaxReturn                77
2017-06-03 12:52:06.424729 EDT | MinReturn                64
2017-06-03 12:52:06.425053 EDT | AverageEsReturn          22.2791
2017-06-03 12:52:06.425389 EDT | StdEsReturn              16.8058
2017-06-03 12:52:06.425708 EDT | MaxEsReturn              72
2017-06-03 12:52:06.426046 EDT | MinEsReturn               3
2017-06-03 12:52:06.426359 EDT | AverageDiscountedReturn  50.4633
2017-06-03 12:52:06.426672 EDT | AverageQLoss              5.50421e-05
2017-06-03 12:52:06.426995 EDT | AveragePolicySurr        -0.0646372
2017-06-03 12:52:06.427308 EDT | AverageQ                  0.0457335
2017-06-03 12:52:06.427620 EDT | AverageAbsQ               0.0473339
2017-06-03 12:52:06.427935 EDT | AverageY                  0.0457448
2017-06-03 12:52:06.428246 EDT | AverageAbsY               0.0465692
2017-06-03 12:52:06.428556 EDT | AverageAbsQYDiff          0.00499147
2017-06-03 12:52:06.428868 EDT | AverageAction             0.0101476
2017-06-03 12:52:06.429176 EDT | PolicyRegParamNorm       15.206
2017-06-03 12:52:06.429486 EDT | QFunRegParamNorm         11.2571
2017-06-03 12:52:06.429805 EDT | -----------------------  ------------
2017-06-03 12:52:06.430275 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #15 | Training started
2017-06-03 12:52:23.266018 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #15 | Training finished
2017-06-03 12:52:23.266908 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #15 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 12:52:23.267181 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #15 | Collecting samples for evaluation
2017-06-03 12:52:31.377174 EDT | -----------------------  ------------
2017-06-03 12:52:31.378067 EDT | Epoch                    15
2017-06-03 12:52:31.378343 EDT | Iteration                15
2017-06-03 12:52:31.378596 EDT | AverageReturn            51.2398
2017-06-03 12:52:31.378851 EDT | StdReturn                 1.11055
2017-06-03 12:52:31.379091 EDT | MaxReturn                54
2017-06-03 12:52:31.379335 EDT | MinReturn                49
2017-06-03 12:52:31.379572 EDT | AverageEsReturn          28.3514
2017-06-03 12:52:31.379807 EDT | StdEsReturn              21.8016
2017-06-03 12:52:31.380044 EDT | MaxEsReturn              96
2017-06-03 12:52:31.380279 EDT | MinEsReturn               3
2017-06-03 12:52:31.380515 EDT | AverageDiscountedReturn  40.2449
2017-06-03 12:52:31.380750 EDT | AverageQLoss              6.22742e-05
2017-06-03 12:52:31.381010 EDT | AveragePolicySurr        -0.0669998
2017-06-03 12:52:31.381244 EDT | AverageQ                  0.0496584
2017-06-03 12:52:31.381478 EDT | AverageAbsQ               0.0513119
2017-06-03 12:52:31.381731 EDT | AverageY                  0.0496608
2017-06-03 12:52:31.381970 EDT | AverageAbsY               0.050613
2017-06-03 12:52:31.382204 EDT | AverageAbsQYDiff          0.00506756
2017-06-03 12:52:31.382437 EDT | AverageAction             0.188253
2017-06-03 12:52:31.382670 EDT | PolicyRegParamNorm       15.6389
2017-06-03 12:52:31.382912 EDT | QFunRegParamNorm         11.4562
2017-06-03 12:52:31.383145 EDT | -----------------------  ------------
2017-06-03 12:52:31.383553 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #16 | Training started
2017-06-03 12:52:49.996793 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #16 | Training finished
2017-06-03 12:52:49.997973 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #16 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 12:52:49.998263 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #16 | Collecting samples for evaluation
2017-06-03 12:52:59.438735 EDT | -----------------------  ------------
2017-06-03 12:52:59.439629 EDT | Epoch                    16
2017-06-03 12:52:59.439893 EDT | Iteration                16
2017-06-03 12:52:59.440134 EDT | AverageReturn            41.7333
2017-06-03 12:52:59.440404 EDT | StdReturn                 0.732954
2017-06-03 12:52:59.440644 EDT | MaxReturn                45
2017-06-03 12:52:59.440875 EDT | MinReturn                40
2017-06-03 12:52:59.441106 EDT | AverageEsReturn          23.3095
2017-06-03 12:52:59.441335 EDT | StdEsReturn              13.7243
2017-06-03 12:52:59.441573 EDT | MaxEsReturn              46
2017-06-03 12:52:59.441829 EDT | MinEsReturn               4
2017-06-03 12:52:59.442059 EDT | AverageDiscountedReturn  34.2563
2017-06-03 12:52:59.442288 EDT | AverageQLoss              5.91141e-05
2017-06-03 12:52:59.442516 EDT | AveragePolicySurr        -0.0713751
2017-06-03 12:52:59.442744 EDT | AverageQ                  0.0551765
2017-06-03 12:52:59.442971 EDT | AverageAbsQ               0.0563846
2017-06-03 12:52:59.443200 EDT | AverageY                  0.0551818
2017-06-03 12:52:59.443450 EDT | AverageAbsY               0.0557232
2017-06-03 12:52:59.443677 EDT | AverageAbsQYDiff          0.00472669
2017-06-03 12:52:59.443904 EDT | AverageAction             0.131321
2017-06-03 12:52:59.444159 EDT | PolicyRegParamNorm       15.9829
2017-06-03 12:52:59.444387 EDT | QFunRegParamNorm         11.6784
2017-06-03 12:52:59.444615 EDT | -----------------------  ------------
2017-06-03 12:52:59.444963 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #17 | Training started
2017-06-03 12:53:17.656751 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #17 | Training finished
2017-06-03 12:53:17.657738 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #17 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 12:53:17.658107 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #17 | Collecting samples for evaluation
2017-06-03 12:53:30.151215 EDT | -----------------------  ------------
2017-06-03 12:53:30.152052 EDT | Epoch                    17
2017-06-03 12:53:30.152334 EDT | Iteration                17
2017-06-03 12:53:30.152590 EDT | AverageReturn            36.1516
2017-06-03 12:53:30.152840 EDT | StdReturn                 0.508526
2017-06-03 12:53:30.153098 EDT | MaxReturn                37
2017-06-03 12:53:30.153353 EDT | MinReturn                35
2017-06-03 12:53:30.153599 EDT | AverageEsReturn          25.0488
2017-06-03 12:53:30.153854 EDT | StdEsReturn              13.9912
2017-06-03 12:53:30.154152 EDT | MaxEsReturn              48
2017-06-03 12:53:30.154397 EDT | MinEsReturn               5
2017-06-03 12:53:30.154642 EDT | AverageDiscountedReturn  30.4638
2017-06-03 12:53:30.154890 EDT | AverageQLoss              5.79859e-05
2017-06-03 12:53:30.155134 EDT | AveragePolicySurr        -0.0744616
2017-06-03 12:53:30.155403 EDT | AverageQ                  0.0588693
2017-06-03 12:53:30.155652 EDT | AverageAbsQ               0.0601039
2017-06-03 12:53:30.155895 EDT | AverageY                  0.0588925
2017-06-03 12:53:30.156167 EDT | AverageAbsY               0.0594669
2017-06-03 12:53:30.156411 EDT | AverageAbsQYDiff          0.00455623
2017-06-03 12:53:30.156654 EDT | AverageAction             0.0197052
2017-06-03 12:53:30.156902 EDT | PolicyRegParamNorm       16.3114
2017-06-03 12:53:30.157146 EDT | QFunRegParamNorm         11.9646
2017-06-03 12:53:30.157393 EDT | -----------------------  ------------
2017-06-03 12:53:30.157860 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #18 | Training started
2017-06-03 12:53:48.863950 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #18 | Training finished
2017-06-03 12:53:48.864887 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #18 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 12:53:48.865302 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #18 | Collecting samples for evaluation
2017-06-03 12:53:57.559038 EDT | -----------------------  ------------
2017-06-03 12:53:57.560010 EDT | Epoch                    18
2017-06-03 12:53:57.560285 EDT | Iteration                18
2017-06-03 12:53:57.560524 EDT | AverageReturn            38.2176
2017-06-03 12:53:57.560756 EDT | StdReturn                 0.934086
2017-06-03 12:53:57.560998 EDT | MaxReturn                40
2017-06-03 12:53:57.561225 EDT | MinReturn                36
2017-06-03 12:53:57.561453 EDT | AverageEsReturn          20.8723
2017-06-03 12:53:57.561678 EDT | StdEsReturn              14.3135
2017-06-03 12:53:57.562237 EDT | MaxEsReturn              59
2017-06-03 12:53:57.562552 EDT | MinEsReturn               3
2017-06-03 12:53:57.562862 EDT | AverageDiscountedReturn  31.8906
2017-06-03 12:53:57.563170 EDT | AverageQLoss              5.30945e-05
2017-06-03 12:53:57.563493 EDT | AveragePolicySurr        -0.0782511
2017-06-03 12:53:57.563802 EDT | AverageQ                  0.0631511
2017-06-03 12:53:57.564109 EDT | AverageAbsQ               0.0640181
2017-06-03 12:53:57.564437 EDT | AverageY                  0.0631539
2017-06-03 12:53:57.564757 EDT | AverageAbsY               0.063473
2017-06-03 12:53:57.565068 EDT | AverageAbsQYDiff          0.00420482
2017-06-03 12:53:57.565378 EDT | AverageAction             0.121649
2017-06-03 12:53:57.565705 EDT | PolicyRegParamNorm       16.9
2017-06-03 12:53:57.566013 EDT | QFunRegParamNorm         12.2338
2017-06-03 12:53:57.566334 EDT | -----------------------  ------------
2017-06-03 12:53:57.566805 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #19 | Training started
2017-06-03 12:54:19.061738 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #19 | Training finished
2017-06-03 12:54:19.062667 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #19 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 12:54:19.062951 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #19 | Collecting samples for evaluation
2017-06-03 12:54:29.018676 EDT | -----------------------  ------------
2017-06-03 12:54:29.019524 EDT | Epoch                    19
2017-06-03 12:54:29.019779 EDT | Iteration                19
2017-06-03 12:54:29.020017 EDT | AverageReturn            35.7464
2017-06-03 12:54:29.020247 EDT | StdReturn                 0.510589
2017-06-03 12:54:29.020479 EDT | MaxReturn                37
2017-06-03 12:54:29.020709 EDT | MinReturn                34
2017-06-03 12:54:29.020936 EDT | AverageEsReturn          22.1087
2017-06-03 12:54:29.021164 EDT | StdEsReturn              14.6514
2017-06-03 12:54:29.021389 EDT | MaxEsReturn              57
2017-06-03 12:54:29.021622 EDT | MinEsReturn               3
2017-06-03 12:54:29.021871 EDT | AverageDiscountedReturn  30.1801
2017-06-03 12:54:29.022108 EDT | AverageQLoss              5.61189e-05
2017-06-03 12:54:29.022333 EDT | AveragePolicySurr        -0.0822529
2017-06-03 12:54:29.022558 EDT | AverageQ                  0.0667474
2017-06-03 12:54:29.022782 EDT | AverageAbsQ               0.0674399
2017-06-03 12:54:29.023006 EDT | AverageY                  0.0667576
2017-06-03 12:54:29.023234 EDT | AverageAbsY               0.0669147
2017-06-03 12:54:29.023466 EDT | AverageAbsQYDiff          0.00422792
2017-06-03 12:54:29.023704 EDT | AverageAction             0.0755238
2017-06-03 12:54:29.023935 EDT | PolicyRegParamNorm       17.4647
2017-06-03 12:54:29.024164 EDT | QFunRegParamNorm         12.5353
2017-06-03 12:54:29.024392 EDT | -----------------------  ------------
2017-06-03 12:54:29.024756 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #20 | Training started
2017-06-03 12:54:49.187977 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #20 | Training finished
2017-06-03 12:54:49.188899 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #20 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 12:54:49.189187 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #20 | Collecting samples for evaluation
2017-06-03 12:54:59.067742 EDT | -----------------------  ------------
2017-06-03 12:54:59.070625 EDT | Epoch                    20
2017-06-03 12:54:59.070952 EDT | Iteration                20
2017-06-03 12:54:59.071208 EDT | AverageReturn            32.8393
2017-06-03 12:54:59.071484 EDT | StdReturn                 0.787459
2017-06-03 12:54:59.071734 EDT | MaxReturn                35
2017-06-03 12:54:59.071974 EDT | MinReturn                31
2017-06-03 12:54:59.072228 EDT | AverageEsReturn          16.129
2017-06-03 12:54:59.072467 EDT | StdEsReturn              12.9172
2017-06-03 12:54:59.072699 EDT | MaxEsReturn              42
2017-06-03 12:54:59.072935 EDT | MinEsReturn               3
2017-06-03 12:54:59.073174 EDT | AverageDiscountedReturn  28.1087
2017-06-03 12:54:59.073424 EDT | AverageQLoss              5.31497e-05
2017-06-03 12:54:59.073661 EDT | AveragePolicySurr        -0.0875291
2017-06-03 12:54:59.073954 EDT | AverageQ                  0.0713001
2017-06-03 12:54:59.074201 EDT | AverageAbsQ               0.0719135
2017-06-03 12:54:59.074432 EDT | AverageY                  0.0712976
2017-06-03 12:54:59.074679 EDT | AverageAbsY               0.0714383
2017-06-03 12:54:59.074920 EDT | AverageAbsQYDiff          0.00406339
2017-06-03 12:54:59.075160 EDT | AverageAction             0.158957
2017-06-03 12:54:59.075391 EDT | PolicyRegParamNorm       17.9069
2017-06-03 12:54:59.075637 EDT | QFunRegParamNorm         12.8094
2017-06-03 12:54:59.075891 EDT | -----------------------  ------------
2017-06-03 12:54:59.076309 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #21 | Training started
2017-06-03 12:55:18.009678 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #21 | Training finished
2017-06-03 12:55:18.010739 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #21 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 12:55:18.011142 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #21 | Collecting samples for evaluation
2017-06-03 12:55:28.791388 EDT | -----------------------  ------------
2017-06-03 12:55:28.791806 EDT | Epoch                    21
2017-06-03 12:55:28.792058 EDT | Iteration                21
2017-06-03 12:55:28.792299 EDT | AverageReturn            33.0132
2017-06-03 12:55:28.792539 EDT | StdReturn                 0.292633
2017-06-03 12:55:28.792775 EDT | MaxReturn                34
2017-06-03 12:55:28.793044 EDT | MinReturn                32
2017-06-03 12:55:28.793293 EDT | AverageEsReturn          16.5167
2017-06-03 12:55:28.793531 EDT | StdEsReturn              12.0934
2017-06-03 12:55:28.793778 EDT | MaxEsReturn              40
2017-06-03 12:55:28.794014 EDT | MinEsReturn               3
2017-06-03 12:55:28.794249 EDT | AverageDiscountedReturn  28.2362
2017-06-03 12:55:28.794529 EDT | AverageQLoss              5.65926e-05
2017-06-03 12:55:28.794763 EDT | AveragePolicySurr        -0.0922958
2017-06-03 12:55:28.795000 EDT | AverageQ                  0.075316
2017-06-03 12:55:28.795241 EDT | AverageAbsQ               0.0758989
2017-06-03 12:55:28.795477 EDT | AverageY                  0.0753255
2017-06-03 12:55:28.795719 EDT | AverageAbsY               0.07543
2017-06-03 12:55:28.795951 EDT | AverageAbsQYDiff          0.00416358
2017-06-03 12:55:28.796189 EDT | AverageAction             0.052672
2017-06-03 12:55:28.796425 EDT | PolicyRegParamNorm       18.4782
2017-06-03 12:55:28.796658 EDT | QFunRegParamNorm         13.0794
2017-06-03 12:55:28.796890 EDT | -----------------------  ------------
2017-06-03 12:55:28.797293 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #22 | Training started
2017-06-03 12:55:47.236860 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #22 | Training finished
2017-06-03 12:55:47.238160 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #22 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 12:55:47.238487 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #22 | Collecting samples for evaluation
2017-06-03 12:55:57.726251 EDT | -----------------------  ------------
2017-06-03 12:55:57.727081 EDT | Epoch                    22
2017-06-03 12:55:57.727340 EDT | Iteration                22
2017-06-03 12:55:57.727581 EDT | AverageReturn            29.7946
2017-06-03 12:55:57.727816 EDT | StdReturn                 0.403962
2017-06-03 12:55:57.728057 EDT | MaxReturn                30
2017-06-03 12:55:57.728288 EDT | MinReturn                29
2017-06-03 12:55:57.728523 EDT | AverageEsReturn          13.6081
2017-06-03 12:55:57.728753 EDT | StdEsReturn              11.8171
2017-06-03 12:55:57.728982 EDT | MaxEsReturn              47
2017-06-03 12:55:57.729212 EDT | MinEsReturn               3
2017-06-03 12:55:57.729440 EDT | AverageDiscountedReturn  25.8765
2017-06-03 12:55:57.729668 EDT | AverageQLoss              6.48366e-05
2017-06-03 12:55:57.729908 EDT | AveragePolicySurr        -0.0960959
2017-06-03 12:55:57.730137 EDT | AverageQ                  0.0797451
2017-06-03 12:55:57.730366 EDT | AverageAbsQ               0.0803546
2017-06-03 12:55:57.730594 EDT | AverageY                  0.0797488
2017-06-03 12:55:57.730822 EDT | AverageAbsY               0.0798932
2017-06-03 12:55:57.731050 EDT | AverageAbsQYDiff          0.00438917
2017-06-03 12:55:57.731278 EDT | AverageAction             0.402166
2017-06-03 12:55:57.731506 EDT | PolicyRegParamNorm       18.8731
2017-06-03 12:55:57.731733 EDT | QFunRegParamNorm         13.4249
2017-06-03 12:55:57.731961 EDT | -----------------------  ------------
2017-06-03 12:55:57.732309 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #23 | Training started
2017-06-03 12:56:17.080811 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #23 | Training finished
2017-06-03 12:56:17.081802 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #23 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 12:56:17.082091 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #23 | Collecting samples for evaluation
2017-06-03 12:56:27.423341 EDT | -----------------------  ------------
2017-06-03 12:56:27.426081 EDT | Epoch                    23
2017-06-03 12:56:27.426353 EDT | Iteration                23
2017-06-03 12:56:27.426593 EDT | AverageReturn            30.7846
2017-06-03 12:56:27.426835 EDT | StdReturn                 0.411089
2017-06-03 12:56:27.427069 EDT | MaxReturn                31
2017-06-03 12:56:27.427301 EDT | MinReturn                30
2017-06-03 12:56:27.427531 EDT | AverageEsReturn          11.1461
2017-06-03 12:56:27.427781 EDT | StdEsReturn              10.2645
2017-06-03 12:56:27.428010 EDT | MaxEsReturn              44
2017-06-03 12:56:27.428248 EDT | MinEsReturn               2
2017-06-03 12:56:27.428487 EDT | AverageDiscountedReturn  26.6103
2017-06-03 12:56:27.428721 EDT | AverageQLoss              6.90969e-05
2017-06-03 12:56:27.428950 EDT | AveragePolicySurr        -0.0995959
2017-06-03 12:56:27.429189 EDT | AverageQ                  0.0819715
2017-06-03 12:56:27.429422 EDT | AverageAbsQ               0.0826329
2017-06-03 12:56:27.429676 EDT | AverageY                  0.081976
2017-06-03 12:56:27.430528 EDT | AverageAbsY               0.0821267
2017-06-03 12:56:27.431422 EDT | AverageAbsQYDiff          0.00438123
2017-06-03 12:56:27.431679 EDT | AverageAction             0.0549296
2017-06-03 12:56:27.432512 EDT | PolicyRegParamNorm       19.3241
2017-06-03 12:56:27.432767 EDT | QFunRegParamNorm         13.761
2017-06-03 12:56:27.433603 EDT | -----------------------  ------------
2017-06-03 12:56:27.434594 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #24 | Training started
2017-06-03 12:56:46.483379 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #24 | Training finished
2017-06-03 12:56:46.484335 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #24 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 12:56:46.484646 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #24 | Collecting samples for evaluation
2017-06-03 12:56:56.911295 EDT | -----------------------  ------------
2017-06-03 12:56:56.912177 EDT | Epoch                    24
2017-06-03 12:56:56.912486 EDT | Iteration                24
2017-06-03 12:56:56.912762 EDT | AverageReturn            27.3079
2017-06-03 12:56:56.913059 EDT | StdReturn                 0.461626
2017-06-03 12:56:56.913346 EDT | MaxReturn                28
2017-06-03 12:56:56.913647 EDT | MinReturn                27
2017-06-03 12:56:56.913919 EDT | AverageEsReturn          14.3188
2017-06-03 12:56:56.914245 EDT | StdEsReturn              10.675
2017-06-03 12:56:56.914515 EDT | MaxEsReturn              40
2017-06-03 12:56:56.914824 EDT | MinEsReturn               3
2017-06-03 12:56:56.915104 EDT | AverageDiscountedReturn  24.0005
2017-06-03 12:56:56.915371 EDT | AverageQLoss              7.70014e-05
2017-06-03 12:56:56.915619 EDT | AveragePolicySurr        -0.104097
2017-06-03 12:56:56.915863 EDT | AverageQ                  0.0857532
2017-06-03 12:56:56.916116 EDT | AverageAbsQ               0.0864851
2017-06-03 12:56:56.916359 EDT | AverageY                  0.0857652
2017-06-03 12:56:56.916601 EDT | AverageAbsY               0.0859529
2017-06-03 12:56:56.916843 EDT | AverageAbsQYDiff          0.00455895
2017-06-03 12:56:56.917083 EDT | AverageAction             0.058584
2017-06-03 12:56:56.917325 EDT | PolicyRegParamNorm       19.7866
2017-06-03 12:56:56.917564 EDT | QFunRegParamNorm         14.1538
2017-06-03 12:56:56.917820 EDT | -----------------------  ------------
2017-06-03 12:56:56.918200 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #25 | Training started
2017-06-03 12:57:16.145126 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #25 | Training finished
2017-06-03 12:57:16.146269 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #25 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 12:57:16.146714 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #25 | Collecting samples for evaluation
2017-06-03 12:57:26.713566 EDT | -----------------------  ------------
2017-06-03 12:57:26.714646 EDT | Epoch                    25
2017-06-03 12:57:26.714926 EDT | Iteration                25
2017-06-03 12:57:26.715208 EDT | AverageReturn            27.4192
2017-06-03 12:57:26.715472 EDT | StdReturn                 0.493425
2017-06-03 12:57:26.715733 EDT | MaxReturn                28
2017-06-03 12:57:26.715991 EDT | MinReturn                27
2017-06-03 12:57:26.716262 EDT | AverageEsReturn          10.8085
2017-06-03 12:57:26.716526 EDT | StdEsReturn               9.52184
2017-06-03 12:57:26.716783 EDT | MaxEsReturn              39
2017-06-03 12:57:26.717040 EDT | MinEsReturn               3
2017-06-03 12:57:26.717296 EDT | AverageDiscountedReturn  24.0853
2017-06-03 12:57:26.717558 EDT | AverageQLoss              7.88018e-05
2017-06-03 12:57:26.717827 EDT | AveragePolicySurr        -0.10982
2017-06-03 12:57:26.718089 EDT | AverageQ                  0.0903905
2017-06-03 12:57:26.718345 EDT | AverageAbsQ               0.0911314
2017-06-03 12:57:26.718602 EDT | AverageY                  0.0903921
2017-06-03 12:57:26.718857 EDT | AverageAbsY               0.0906296
2017-06-03 12:57:26.719112 EDT | AverageAbsQYDiff          0.0046365
2017-06-03 12:57:26.719369 EDT | AverageAction             0.0575305
2017-06-03 12:57:26.719624 EDT | PolicyRegParamNorm       20.1896
2017-06-03 12:57:26.719906 EDT | QFunRegParamNorm         14.4783
2017-06-03 12:57:26.720163 EDT | -----------------------  ------------
2017-06-03 12:57:26.720584 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #26 | Training started
2017-06-03 12:57:46.483233 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #26 | Training finished
2017-06-03 12:57:46.484119 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #26 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 12:57:46.484391 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #26 | Collecting samples for evaluation
2017-06-03 12:57:58.231783 EDT | -----------------------  ------------
2017-06-03 12:57:58.232627 EDT | Epoch                    26
2017-06-03 12:57:58.232891 EDT | Iteration                26
2017-06-03 12:57:58.233134 EDT | AverageReturn            33.8311
2017-06-03 12:57:58.233374 EDT | StdReturn                 0.37468
2017-06-03 12:57:58.233621 EDT | MaxReturn                34
2017-06-03 12:57:58.233870 EDT | MinReturn                33
2017-06-03 12:57:58.234108 EDT | AverageEsReturn          13.0135
2017-06-03 12:57:58.234344 EDT | StdEsReturn              11.7755
2017-06-03 12:57:58.234580 EDT | MaxEsReturn              45
2017-06-03 12:57:58.234815 EDT | MinEsReturn               3
2017-06-03 12:57:58.235064 EDT | AverageDiscountedReturn  28.8234
2017-06-03 12:57:58.235335 EDT | AverageQLoss              9.50426e-05
2017-06-03 12:57:58.235589 EDT | AveragePolicySurr        -0.113692
2017-06-03 12:57:58.235827 EDT | AverageQ                  0.0941433
2017-06-03 12:57:58.236077 EDT | AverageAbsQ               0.0949223
2017-06-03 12:57:58.236318 EDT | AverageY                  0.0941568
2017-06-03 12:57:58.236553 EDT | AverageAbsY               0.0944162
2017-06-03 12:57:58.236787 EDT | AverageAbsQYDiff          0.00490337
2017-06-03 12:57:58.237021 EDT | AverageAction             0.505795
2017-06-03 12:57:58.237254 EDT | PolicyRegParamNorm       20.8732
2017-06-03 12:57:58.237488 EDT | QFunRegParamNorm         14.826
2017-06-03 12:57:58.237731 EDT | -----------------------  ------------
2017-06-03 12:57:58.238098 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #27 | Training started
2017-06-03 12:58:18.048577 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #27 | Training finished
2017-06-03 12:58:18.049508 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #27 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 12:58:18.049945 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #27 | Collecting samples for evaluation
2017-06-03 12:58:29.648312 EDT | -----------------------  ------------
2017-06-03 12:58:29.648702 EDT | Epoch                    27
2017-06-03 12:58:29.648965 EDT | Iteration                27
2017-06-03 12:58:29.649217 EDT | AverageReturn            39.082
2017-06-03 12:58:29.649459 EDT | StdReturn                 0.489249
2017-06-03 12:58:29.649708 EDT | MaxReturn                40
2017-06-03 12:58:29.649954 EDT | MinReturn                38
2017-06-03 12:58:29.650197 EDT | AverageEsReturn          11.8506
2017-06-03 12:58:29.650437 EDT | StdEsReturn              11.7096
2017-06-03 12:58:29.650677 EDT | MaxEsReturn              52
2017-06-03 12:58:29.650917 EDT | MinEsReturn               3
2017-06-03 12:58:29.651159 EDT | AverageDiscountedReturn  32.482
2017-06-03 12:58:29.651398 EDT | AverageQLoss              0.000100279
2017-06-03 12:58:29.651636 EDT | AveragePolicySurr        -0.117799
2017-06-03 12:58:29.651874 EDT | AverageQ                  0.0976497
2017-06-03 12:58:29.652113 EDT | AverageAbsQ               0.0984861
2017-06-03 12:58:29.652350 EDT | AverageY                  0.0976454
2017-06-03 12:58:29.652587 EDT | AverageAbsY               0.0979871
2017-06-03 12:58:29.652824 EDT | AverageAbsQYDiff          0.00492316
2017-06-03 12:58:29.653062 EDT | AverageAction             0.476626
2017-06-03 12:58:29.653299 EDT | PolicyRegParamNorm       21.3953
2017-06-03 12:58:29.653536 EDT | QFunRegParamNorm         15.1477
2017-06-03 12:58:29.653784 EDT | -----------------------  ------------
2017-06-03 12:58:29.654173 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #28 | Training started
2017-06-03 12:58:48.736173 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #28 | Training finished
2017-06-03 12:58:48.737167 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #28 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 12:58:48.737538 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #28 | Collecting samples for evaluation
2017-06-03 12:58:58.217195 EDT | -----------------------  ------------
2017-06-03 12:58:58.229433 EDT | Epoch                    28
2017-06-03 12:58:58.229822 EDT | Iteration                28
2017-06-03 12:58:58.230065 EDT | AverageReturn            45.6621
2017-06-03 12:58:58.230342 EDT | StdReturn                 3.06027
2017-06-03 12:58:58.230597 EDT | MaxReturn                58
2017-06-03 12:58:58.230868 EDT | MinReturn                42
2017-06-03 12:58:58.231156 EDT | AverageEsReturn          13.4865
2017-06-03 12:58:58.231413 EDT | StdEsReturn              15.284
2017-06-03 12:58:58.231643 EDT | MaxEsReturn              52
2017-06-03 12:58:58.231870 EDT | MinEsReturn               3
2017-06-03 12:58:58.232105 EDT | AverageDiscountedReturn  36.774
2017-06-03 12:58:58.232340 EDT | AverageQLoss              0.000110763
2017-06-03 12:58:58.232564 EDT | AveragePolicySurr        -0.121566
2017-06-03 12:58:58.232788 EDT | AverageQ                  0.100846
2017-06-03 12:58:58.233056 EDT | AverageAbsQ               0.101722
2017-06-03 12:58:58.233302 EDT | AverageY                  0.100863
2017-06-03 12:58:58.233529 EDT | AverageAbsY               0.101299
2017-06-03 12:58:58.233807 EDT | AverageAbsQYDiff          0.00513828
2017-06-03 12:58:58.234036 EDT | AverageAction             0.733774
2017-06-03 12:58:58.234261 EDT | PolicyRegParamNorm       21.9783
2017-06-03 12:58:58.234482 EDT | QFunRegParamNorm         15.5062
2017-06-03 12:58:58.234758 EDT | -----------------------  ------------
2017-06-03 12:58:58.235203 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #29 | Training started
2017-06-03 12:59:16.917499 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #29 | Training finished
2017-06-03 12:59:16.918502 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #29 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 12:59:16.918789 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #29 | Collecting samples for evaluation
2017-06-03 12:59:27.761971 EDT | -----------------------  ------------
2017-06-03 12:59:27.762816 EDT | Epoch                    29
2017-06-03 12:59:27.763088 EDT | Iteration                29
2017-06-03 12:59:27.763338 EDT | AverageReturn            46.8364
2017-06-03 12:59:27.763595 EDT | StdReturn                 2.83443
2017-06-03 12:59:27.763837 EDT | MaxReturn                56
2017-06-03 12:59:27.764076 EDT | MinReturn                42
2017-06-03 12:59:27.764317 EDT | AverageEsReturn          14.2817
2017-06-03 12:59:27.764556 EDT | StdEsReturn              14.7841
2017-06-03 12:59:27.764814 EDT | MaxEsReturn              51
2017-06-03 12:59:27.765054 EDT | MinEsReturn               3
2017-06-03 12:59:27.765291 EDT | AverageDiscountedReturn  37.5197
2017-06-03 12:59:27.765533 EDT | AverageQLoss              0.000113811
2017-06-03 12:59:27.765787 EDT | AveragePolicySurr        -0.124446
2017-06-03 12:59:27.766030 EDT | AverageQ                  0.10354
2017-06-03 12:59:27.766267 EDT | AverageAbsQ               0.104403
2017-06-03 12:59:27.766504 EDT | AverageY                  0.103545
2017-06-03 12:59:27.766739 EDT | AverageAbsY               0.10396
2017-06-03 12:59:27.766976 EDT | AverageAbsQYDiff          0.00515344
2017-06-03 12:59:27.767211 EDT | AverageAction             0.725678
2017-06-03 12:59:27.767447 EDT | PolicyRegParamNorm       22.3315
2017-06-03 12:59:27.767683 EDT | QFunRegParamNorm         15.7687
2017-06-03 12:59:27.767924 EDT | -----------------------  ------------
2017-06-03 12:59:27.768334 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #30 | Training started
2017-06-03 12:59:46.239077 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #30 | Training finished
2017-06-03 12:59:46.239944 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #30 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 12:59:46.240213 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #30 | Collecting samples for evaluation
2017-06-03 12:59:56.835078 EDT | -----------------------  ------------
2017-06-03 12:59:56.835952 EDT | Epoch                    30
2017-06-03 12:59:56.836217 EDT | Iteration                30
2017-06-03 12:59:56.836458 EDT | AverageReturn            46.055
2017-06-03 12:59:56.836695 EDT | StdReturn                 3.8631
2017-06-03 12:59:56.836937 EDT | MaxReturn                67
2017-06-03 12:59:56.837169 EDT | MinReturn                39
2017-06-03 12:59:56.837399 EDT | AverageEsReturn          16.6
2017-06-03 12:59:56.837635 EDT | StdEsReturn              15.5812
2017-06-03 12:59:56.837895 EDT | MaxEsReturn              69
2017-06-03 12:59:56.838127 EDT | MinEsReturn               3
2017-06-03 12:59:56.838364 EDT | AverageDiscountedReturn  37.0064
2017-06-03 12:59:56.838596 EDT | AverageQLoss              0.000116347
2017-06-03 12:59:56.838825 EDT | AveragePolicySurr        -0.126261
2017-06-03 12:59:56.839055 EDT | AverageQ                  0.105813
2017-06-03 12:59:56.839283 EDT | AverageAbsQ               0.106751
2017-06-03 12:59:56.839512 EDT | AverageY                  0.105826
2017-06-03 12:59:56.839740 EDT | AverageAbsY               0.106231
2017-06-03 12:59:56.839967 EDT | AverageAbsQYDiff          0.0052966
2017-06-03 12:59:56.840195 EDT | AverageAction             0.77102
2017-06-03 12:59:56.840422 EDT | PolicyRegParamNorm       22.637
2017-06-03 12:59:56.840649 EDT | QFunRegParamNorm         15.9943
2017-06-03 12:59:56.840876 EDT | -----------------------  ------------
2017-06-03 12:59:56.841259 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #31 | Training started
2017-06-03 13:00:15.022748 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #31 | Training finished
2017-06-03 13:00:15.023723 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #31 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 13:00:15.024000 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #31 | Collecting samples for evaluation
2017-06-03 13:00:25.555111 EDT | -----------------------  ------------
2017-06-03 13:00:25.555969 EDT | Epoch                    31
2017-06-03 13:00:25.556245 EDT | Iteration                31
2017-06-03 13:00:25.556502 EDT | AverageReturn            62.7687
2017-06-03 13:00:25.556738 EDT | StdReturn                 6.21412
2017-06-03 13:00:25.556970 EDT | MaxReturn                84
2017-06-03 13:00:25.557201 EDT | MinReturn                49
2017-06-03 13:00:25.557436 EDT | AverageEsReturn          26.6944
2017-06-03 13:00:25.557671 EDT | StdEsReturn              24.1532
2017-06-03 13:00:25.557914 EDT | MaxEsReturn              91
2017-06-03 13:00:25.558144 EDT | MinEsReturn               3
2017-06-03 13:00:25.558377 EDT | AverageDiscountedReturn  46.6823
2017-06-03 13:00:25.558614 EDT | AverageQLoss              0.000113763
2017-06-03 13:00:25.558851 EDT | AveragePolicySurr        -0.127146
2017-06-03 13:00:25.559079 EDT | AverageQ                  0.107125
2017-06-03 13:00:25.559324 EDT | AverageAbsQ               0.108053
2017-06-03 13:00:25.559551 EDT | AverageY                  0.107134
2017-06-03 13:00:25.559778 EDT | AverageAbsY               0.107442
2017-06-03 13:00:25.560009 EDT | AverageAbsQYDiff          0.00528397
2017-06-03 13:00:25.560237 EDT | AverageAction             0.832817
2017-06-03 13:00:25.560480 EDT | PolicyRegParamNorm       22.9225
2017-06-03 13:00:25.560708 EDT | QFunRegParamNorm         16.1844
2017-06-03 13:00:25.560935 EDT | -----------------------  ------------
2017-06-03 13:00:25.561317 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #32 | Training started
2017-06-03 13:00:44.984355 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #32 | Training finished
2017-06-03 13:00:44.985294 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #32 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 13:00:44.985717 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #32 | Collecting samples for evaluation
2017-06-03 13:00:55.096805 EDT | -----------------------  ------------
2017-06-03 13:00:55.097724 EDT | Epoch                    32
2017-06-03 13:00:55.098039 EDT | Iteration                32
2017-06-03 13:00:55.098330 EDT | AverageReturn            70.5
2017-06-03 13:00:55.098611 EDT | StdReturn                 6.18807
2017-06-03 13:00:55.098897 EDT | MaxReturn                96
2017-06-03 13:00:55.099185 EDT | MinReturn                56
2017-06-03 13:00:55.099477 EDT | AverageEsReturn          20.2745
2017-06-03 13:00:55.099767 EDT | StdEsReturn              19.1025
2017-06-03 13:00:55.100050 EDT | MaxEsReturn              76
2017-06-03 13:00:55.100334 EDT | MinEsReturn               3
2017-06-03 13:00:55.100619 EDT | AverageDiscountedReturn  50.6702
2017-06-03 13:00:55.100903 EDT | AverageQLoss              0.000108824
2017-06-03 13:00:55.101188 EDT | AveragePolicySurr        -0.127518
2017-06-03 13:00:55.101473 EDT | AverageQ                  0.107902
2017-06-03 13:00:55.103662 EDT | AverageAbsQ               0.108776
2017-06-03 13:00:55.103955 EDT | AverageY                  0.107902
2017-06-03 13:00:55.104241 EDT | AverageAbsY               0.108401
2017-06-03 13:00:55.104529 EDT | AverageAbsQYDiff          0.00505184
2017-06-03 13:00:55.104814 EDT | AverageAction             0.867372
2017-06-03 13:00:55.105091 EDT | PolicyRegParamNorm       23.1426
2017-06-03 13:00:55.105375 EDT | QFunRegParamNorm         16.3547
2017-06-03 13:00:55.105656 EDT | -----------------------  ------------
2017-06-03 13:00:55.106135 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #33 | Training started
2017-06-03 13:01:14.244193 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #33 | Training finished
2017-06-03 13:01:14.245128 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #33 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 13:01:14.245527 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #33 | Collecting samples for evaluation
2017-06-03 13:01:24.542363 EDT | -----------------------  ------------
2017-06-03 13:01:24.543344 EDT | Epoch                    33
2017-06-03 13:01:24.543728 EDT | Iteration                33
2017-06-03 13:01:24.544079 EDT | AverageReturn            50.4472
2017-06-03 13:01:24.544402 EDT | StdReturn                 1.48898
2017-06-03 13:01:24.544723 EDT | MaxReturn                54
2017-06-03 13:01:24.545102 EDT | MinReturn                47
2017-06-03 13:01:24.545417 EDT | AverageEsReturn          19.7647
2017-06-03 13:01:24.545746 EDT | StdEsReturn              17.4969
2017-06-03 13:01:24.546659 EDT | MaxEsReturn              71
2017-06-03 13:01:24.547621 EDT | MinEsReturn               3
2017-06-03 13:01:24.547956 EDT | AverageDiscountedReturn  39.764
2017-06-03 13:01:24.548291 EDT | AverageQLoss              0.000113679
2017-06-03 13:01:24.548696 EDT | AveragePolicySurr        -0.126823
2017-06-03 13:01:24.549073 EDT | AverageQ                  0.107301
2017-06-03 13:01:24.549747 EDT | AverageAbsQ               0.10829
2017-06-03 13:01:24.550075 EDT | AverageY                  0.107309
2017-06-03 13:01:24.550465 EDT | AverageAbsY               0.107851
2017-06-03 13:01:24.550789 EDT | AverageAbsQYDiff          0.00524441
2017-06-03 13:01:24.551111 EDT | AverageAction             0.633
2017-06-03 13:01:24.551430 EDT | PolicyRegParamNorm       23.5014
2017-06-03 13:01:24.551851 EDT | QFunRegParamNorm         16.5669
2017-06-03 13:01:24.552185 EDT | -----------------------  ------------
2017-06-03 13:01:24.552672 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #34 | Training started
2017-06-03 13:01:44.522995 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #34 | Training finished
2017-06-03 13:01:44.524088 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #34 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 13:01:44.524499 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #34 | Collecting samples for evaluation
2017-06-03 13:01:54.410167 EDT | -----------------------  -------------
2017-06-03 13:01:54.411039 EDT | Epoch                     34
2017-06-03 13:01:54.411326 EDT | Iteration                 34
2017-06-03 13:01:54.411589 EDT | AverageReturn             93.1944
2017-06-03 13:01:54.411849 EDT | StdReturn                 10.1082
2017-06-03 13:01:54.412106 EDT | MaxReturn                120
2017-06-03 13:01:54.412361 EDT | MinReturn                 69
2017-06-03 13:01:54.412615 EDT | AverageEsReturn           28.8182
2017-06-03 13:01:54.412868 EDT | StdEsReturn               17.3073
2017-06-03 13:01:54.413120 EDT | MaxEsReturn               72
2017-06-03 13:01:54.413377 EDT | MinEsReturn                3
2017-06-03 13:01:54.413646 EDT | AverageDiscountedReturn   60.6018
2017-06-03 13:01:54.413927 EDT | AverageQLoss               0.000105263
2017-06-03 13:01:54.414182 EDT | AveragePolicySurr         -0.126333
2017-06-03 13:01:54.414435 EDT | AverageQ                   0.107192
2017-06-03 13:01:54.414688 EDT | AverageAbsQ                0.108085
2017-06-03 13:01:54.414940 EDT | AverageY                   0.107198
2017-06-03 13:01:54.415203 EDT | AverageAbsY                0.10765
2017-06-03 13:01:54.415454 EDT | AverageAbsQYDiff           0.00488208
2017-06-03 13:01:54.415714 EDT | AverageAction              0.75677
2017-06-03 13:01:54.415968 EDT | PolicyRegParamNorm        23.809
2017-06-03 13:01:54.416226 EDT | QFunRegParamNorm          16.69
2017-06-03 13:01:54.416478 EDT | -----------------------  -------------
2017-06-03 13:01:54.416883 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #35 | Training started
2017-06-03 13:02:12.498260 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #35 | Training finished
2017-06-03 13:02:12.498875 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #35 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 13:02:12.499151 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #35 | Collecting samples for evaluation
2017-06-03 13:02:23.351665 EDT | -----------------------  ------------
2017-06-03 13:02:23.352502 EDT | Epoch                     35
2017-06-03 13:02:23.352773 EDT | Iteration                 35
2017-06-03 13:02:23.353026 EDT | AverageReturn            137.781
2017-06-03 13:02:23.353274 EDT | StdReturn                 62.4476
2017-06-03 13:02:23.353534 EDT | MaxReturn                376
2017-06-03 13:02:23.353795 EDT | MinReturn                 84
2017-06-03 13:02:23.354047 EDT | AverageEsReturn           34.3
2017-06-03 13:02:23.354292 EDT | StdEsReturn               28.68
2017-06-03 13:02:23.354541 EDT | MaxEsReturn              104
2017-06-03 13:02:23.354790 EDT | MinEsReturn                4
2017-06-03 13:02:23.355033 EDT | AverageDiscountedReturn   71.1358
2017-06-03 13:02:23.355275 EDT | AverageQLoss               0.00011019
2017-06-03 13:02:23.355515 EDT | AveragePolicySurr         -0.125147
2017-06-03 13:02:23.355782 EDT | AverageQ                   0.107025
2017-06-03 13:02:23.356024 EDT | AverageAbsQ                0.107928
2017-06-03 13:02:23.356265 EDT | AverageY                   0.107029
2017-06-03 13:02:23.356508 EDT | AverageAbsY                0.107378
2017-06-03 13:02:23.356759 EDT | AverageAbsQYDiff           0.00498858
2017-06-03 13:02:23.357020 EDT | AverageAction              0.89354
2017-06-03 13:02:23.357259 EDT | PolicyRegParamNorm        24.1914
2017-06-03 13:02:23.357509 EDT | QFunRegParamNorm          16.8943
2017-06-03 13:02:23.357761 EDT | -----------------------  ------------
2017-06-03 13:02:23.358136 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #36 | Training started
2017-06-03 13:02:42.235070 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #36 | Training finished
2017-06-03 13:02:42.236011 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #36 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 13:02:42.236381 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #36 | Collecting samples for evaluation
2017-06-03 13:02:54.597308 EDT | -----------------------  --------------
2017-06-03 13:02:54.598183 EDT | Epoch                      36
2017-06-03 13:02:54.598455 EDT | Iteration                  36
2017-06-03 13:02:54.598702 EDT | AverageReturn             839.538
2017-06-03 13:02:54.598944 EDT | StdReturn                 288.448
2017-06-03 13:02:54.599197 EDT | MaxReturn                1000
2017-06-03 13:02:54.599434 EDT | MinReturn                 199
2017-06-03 13:02:54.599671 EDT | AverageEsReturn            44.6364
2017-06-03 13:02:54.599921 EDT | StdEsReturn                34.5274
2017-06-03 13:02:54.600163 EDT | MaxEsReturn               122
2017-06-03 13:02:54.600399 EDT | MinEsReturn                 3
2017-06-03 13:02:54.600634 EDT | AverageDiscountedReturn    98.4783
2017-06-03 13:02:54.600870 EDT | AverageQLoss                0.000108693
2017-06-03 13:02:54.601115 EDT | AveragePolicySurr          -0.124735
2017-06-03 13:02:54.601367 EDT | AverageQ                    0.107143
2017-06-03 13:02:54.601648 EDT | AverageAbsQ                 0.107928
2017-06-03 13:02:54.601906 EDT | AverageY                    0.107149
2017-06-03 13:02:54.602143 EDT | AverageAbsY                 0.107457
2017-06-03 13:02:54.602382 EDT | AverageAbsQYDiff            0.00473485
2017-06-03 13:02:54.602634 EDT | AverageAction               0.871798
2017-06-03 13:02:54.602870 EDT | PolicyRegParamNorm         24.434
2017-06-03 13:02:54.603104 EDT | QFunRegParamNorm           16.9917
2017-06-03 13:02:54.603338 EDT | -----------------------  --------------
2017-06-03 13:02:54.603741 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #37 | Training started
2017-06-03 13:03:13.481128 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #37 | Training finished
2017-06-03 13:03:13.482050 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #37 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 13:03:13.482325 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #37 | Collecting samples for evaluation
2017-06-03 13:03:23.678253 EDT | -----------------------  --------------
2017-06-03 13:03:23.679089 EDT | Epoch                      37
2017-06-03 13:03:23.679356 EDT | Iteration                  37
2017-06-03 13:03:23.679636 EDT | AverageReturn             809.538
2017-06-03 13:03:23.679887 EDT | StdReturn                 250.927
2017-06-03 13:03:23.680139 EDT | MaxReturn                1000
2017-06-03 13:03:23.680388 EDT | MinReturn                 236
2017-06-03 13:03:23.680633 EDT | AverageEsReturn            35.9643
2017-06-03 13:03:23.680892 EDT | StdEsReturn                35.0881
2017-06-03 13:03:23.681135 EDT | MaxEsReturn               137
2017-06-03 13:03:23.681378 EDT | MinEsReturn                 3
2017-06-03 13:03:23.681620 EDT | AverageDiscountedReturn    99.1081
2017-06-03 13:03:23.681872 EDT | AverageQLoss                9.06413e-05
2017-06-03 13:03:23.682133 EDT | AveragePolicySurr          -0.124153
2017-06-03 13:03:23.682378 EDT | AverageQ                    0.10642
2017-06-03 13:03:23.682620 EDT | AverageAbsQ                 0.107252
2017-06-03 13:03:23.682864 EDT | AverageY                    0.106431
2017-06-03 13:03:23.683114 EDT | AverageAbsY                 0.1068
2017-06-03 13:03:23.683367 EDT | AverageAbsQYDiff            0.00451506
2017-06-03 13:03:23.683616 EDT | AverageAction               0.859376
2017-06-03 13:03:23.683857 EDT | PolicyRegParamNorm         24.6652
2017-06-03 13:03:23.684199 EDT | QFunRegParamNorm           17.1522
2017-06-03 13:03:23.684648 EDT | -----------------------  --------------
2017-06-03 13:03:23.685257 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #38 | Training started
2017-06-03 13:03:42.742548 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #38 | Training finished
2017-06-03 13:03:42.743461 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #38 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 13:03:42.743812 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #38 | Collecting samples for evaluation
2017-06-03 13:03:52.575037 EDT | -----------------------  --------------
2017-06-03 13:03:52.576016 EDT | Epoch                      38
2017-06-03 13:03:52.576275 EDT | Iteration                  38
2017-06-03 13:03:52.576512 EDT | AverageReturn            1000
2017-06-03 13:03:52.576747 EDT | StdReturn                   0
2017-06-03 13:03:52.576984 EDT | MaxReturn                1000
2017-06-03 13:03:52.577239 EDT | MinReturn                1000
2017-06-03 13:03:52.577471 EDT | AverageEsReturn            36.4643
2017-06-03 13:03:52.577721 EDT | StdEsReturn                30.2141
2017-06-03 13:03:52.577960 EDT | MaxEsReturn               128
2017-06-03 13:03:52.578197 EDT | MinEsReturn                 3
2017-06-03 13:03:52.578495 EDT | AverageDiscountedReturn    99.9957
2017-06-03 13:03:52.578736 EDT | AverageQLoss                8.83174e-05
2017-06-03 13:03:52.578970 EDT | AveragePolicySurr          -0.124815
2017-06-03 13:03:52.579201 EDT | AverageQ                    0.106674
2017-06-03 13:03:52.579433 EDT | AverageAbsQ                 0.10751
2017-06-03 13:03:52.579679 EDT | AverageY                    0.106672
2017-06-03 13:03:52.579913 EDT | AverageAbsY                 0.107041
2017-06-03 13:03:52.580153 EDT | AverageAbsQYDiff            0.00443437
2017-06-03 13:03:52.580411 EDT | AverageAction               0.573245
2017-06-03 13:03:52.580641 EDT | PolicyRegParamNorm         24.9004
2017-06-03 13:03:52.580871 EDT | QFunRegParamNorm           17.3354
2017-06-03 13:03:52.581097 EDT | -----------------------  --------------
2017-06-03 13:03:52.581464 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #39 | Training started
2017-06-03 13:04:12.304385 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #39 | Training finished
2017-06-03 13:04:12.305335 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #39 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 13:04:12.305706 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #39 | Collecting samples for evaluation
2017-06-03 13:04:23.372319 EDT | -----------------------  -------------
2017-06-03 13:04:23.373777 EDT | Epoch                     39
2017-06-03 13:04:23.374043 EDT | Iteration                 39
2017-06-03 13:04:23.374293 EDT | AverageReturn            113.607
2017-06-03 13:04:23.374535 EDT | StdReturn                  7.56636
2017-06-03 13:04:23.374775 EDT | MaxReturn                137
2017-06-03 13:04:23.375012 EDT | MinReturn                103
2017-06-03 13:04:23.375248 EDT | AverageEsReturn           47.8
2017-06-03 13:04:23.375482 EDT | StdEsReturn               45.6482
2017-06-03 13:04:23.375726 EDT | MaxEsReturn              203
2017-06-03 13:04:23.376018 EDT | MinEsReturn                7
2017-06-03 13:04:23.376267 EDT | AverageDiscountedReturn   67.9852
2017-06-03 13:04:23.376509 EDT | AverageQLoss               8.56272e-05
2017-06-03 13:04:23.376753 EDT | AveragePolicySurr         -0.125266
2017-06-03 13:04:23.377004 EDT | AverageQ                   0.107666
2017-06-03 13:04:23.377254 EDT | AverageAbsQ                0.108518
2017-06-03 13:04:23.377494 EDT | AverageY                   0.107671
2017-06-03 13:04:23.377787 EDT | AverageAbsY                0.108022
2017-06-03 13:04:23.378034 EDT | AverageAbsQYDiff           0.0043951
2017-06-03 13:04:23.378263 EDT | AverageAction              0.912495
2017-06-03 13:04:23.378489 EDT | PolicyRegParamNorm        25.0792
2017-06-03 13:04:23.378715 EDT | QFunRegParamNorm          17.4271
2017-06-03 13:04:23.378962 EDT | -----------------------  -------------
2017-06-03 13:04:23.379353 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #40 | Training started
2017-06-03 13:04:42.897310 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #40 | Training finished
2017-06-03 13:04:42.898178 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #40 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 13:04:42.898494 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #40 | Collecting samples for evaluation
2017-06-03 13:04:52.898370 EDT | -----------------------  --------------
2017-06-03 13:04:52.899442 EDT | Epoch                      40
2017-06-03 13:04:52.900773 EDT | Iteration                  40
2017-06-03 13:04:52.901137 EDT | AverageReturn            1000
2017-06-03 13:04:52.901455 EDT | StdReturn                   0
2017-06-03 13:04:52.901940 EDT | MaxReturn                1000
2017-06-03 13:04:52.902227 EDT | MinReturn                1000
2017-06-03 13:04:52.902516 EDT | AverageEsReturn            45.7826
2017-06-03 13:04:52.902830 EDT | StdEsReturn                37.1284
2017-06-03 13:04:52.903111 EDT | MaxEsReturn               176
2017-06-03 13:04:52.903409 EDT | MinEsReturn                 5
2017-06-03 13:04:52.903705 EDT | AverageDiscountedReturn    99.9957
2017-06-03 13:04:52.904011 EDT | AverageQLoss                9.57711e-05
2017-06-03 13:04:52.904299 EDT | AveragePolicySurr          -0.126135
2017-06-03 13:04:52.904595 EDT | AverageQ                    0.108798
2017-06-03 13:04:52.904906 EDT | AverageAbsQ                 0.109748
2017-06-03 13:04:52.905226 EDT | AverageY                    0.108808
2017-06-03 13:04:52.905480 EDT | AverageAbsY                 0.109271
2017-06-03 13:04:52.905745 EDT | AverageAbsQYDiff            0.0045991
2017-06-03 13:04:52.906009 EDT | AverageAction               0.0674061
2017-06-03 13:04:52.906286 EDT | PolicyRegParamNorm         25.2876
2017-06-03 13:04:52.906577 EDT | QFunRegParamNorm           17.5508
2017-06-03 13:04:52.906960 EDT | -----------------------  --------------
2017-06-03 13:04:52.907557 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #41 | Training started
2017-06-03 13:05:11.786216 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #41 | Training finished
2017-06-03 13:05:11.787724 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #41 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 13:05:11.788127 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #41 | Collecting samples for evaluation
2017-06-03 13:05:20.970261 EDT | -----------------------  --------------
2017-06-03 13:05:20.971164 EDT | Epoch                      41
2017-06-03 13:05:20.971427 EDT | Iteration                  41
2017-06-03 13:05:20.971668 EDT | AverageReturn            1000
2017-06-03 13:05:20.971946 EDT | StdReturn                   0
2017-06-03 13:05:20.972199 EDT | MaxReturn                1000
2017-06-03 13:05:20.972432 EDT | MinReturn                1000
2017-06-03 13:05:20.972663 EDT | AverageEsReturn            32.9667
2017-06-03 13:05:20.972894 EDT | StdEsReturn                24.3577
2017-06-03 13:05:20.973124 EDT | MaxEsReturn                98
2017-06-03 13:05:20.973369 EDT | MinEsReturn                 5
2017-06-03 13:05:20.973598 EDT | AverageDiscountedReturn    99.9957
2017-06-03 13:05:20.973865 EDT | AverageQLoss                8.76517e-05
2017-06-03 13:05:20.974113 EDT | AveragePolicySurr          -0.127319
2017-06-03 13:05:20.974406 EDT | AverageQ                    0.110145
2017-06-03 13:05:20.974652 EDT | AverageAbsQ                 0.111085
2017-06-03 13:05:20.974896 EDT | AverageY                    0.110139
2017-06-03 13:05:20.975142 EDT | AverageAbsY                 0.11067
2017-06-03 13:05:20.975385 EDT | AverageAbsQYDiff            0.00435029
2017-06-03 13:05:20.975642 EDT | AverageAction               0.393758
2017-06-03 13:05:20.975886 EDT | PolicyRegParamNorm         25.4004
2017-06-03 13:05:20.976129 EDT | QFunRegParamNorm           17.6629
2017-06-03 13:05:20.976372 EDT | -----------------------  --------------
2017-06-03 13:05:20.976769 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #42 | Training started
2017-06-03 13:05:39.692979 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #42 | Training finished
2017-06-03 13:05:39.696005 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #42 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 13:05:39.696629 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #42 | Collecting samples for evaluation
2017-06-03 13:05:48.009237 EDT | -----------------------  -------------
2017-06-03 13:05:48.010097 EDT | Epoch                     42
2017-06-03 13:05:48.010354 EDT | Iteration                 42
2017-06-03 13:05:48.010588 EDT | AverageReturn            153.985
2017-06-03 13:05:48.010827 EDT | StdReturn                 10.9944
2017-06-03 13:05:48.011055 EDT | MaxReturn                188
2017-06-03 13:05:48.011280 EDT | MinReturn                130
2017-06-03 13:05:48.011505 EDT | AverageEsReturn           25.0513
2017-06-03 13:05:48.011731 EDT | StdEsReturn               17.1419
2017-06-03 13:05:48.011956 EDT | MaxEsReturn               76
2017-06-03 13:05:48.012180 EDT | MinEsReturn                3
2017-06-03 13:05:48.012403 EDT | AverageDiscountedReturn   78.5979
2017-06-03 13:05:48.012627 EDT | AverageQLoss               9.57983e-05
2017-06-03 13:05:48.012850 EDT | AveragePolicySurr         -0.127955
2017-06-03 13:05:48.013075 EDT | AverageQ                   0.110733
2017-06-03 13:05:48.013298 EDT | AverageAbsQ                0.111765
2017-06-03 13:05:48.013521 EDT | AverageY                   0.110734
2017-06-03 13:05:48.013780 EDT | AverageAbsY                0.111352
2017-06-03 13:05:48.014018 EDT | AverageAbsQYDiff           0.00457286
2017-06-03 13:05:48.014258 EDT | AverageAction              0.345914
2017-06-03 13:05:48.014513 EDT | PolicyRegParamNorm        25.5736
2017-06-03 13:05:48.014752 EDT | QFunRegParamNorm          17.7494
2017-06-03 13:05:48.014990 EDT | -----------------------  -------------
2017-06-03 13:05:48.015351 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #43 | Training started
2017-06-03 13:06:05.761065 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #43 | Training finished
2017-06-03 13:06:05.761998 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #43 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 13:06:05.762284 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #43 | Collecting samples for evaluation
2017-06-03 13:06:15.039660 EDT | -----------------------  --------------
2017-06-03 13:06:15.040062 EDT | Epoch                      43
2017-06-03 13:06:15.040316 EDT | Iteration                  43
2017-06-03 13:06:15.040558 EDT | AverageReturn            1000
2017-06-03 13:06:15.040797 EDT | StdReturn                   0
2017-06-03 13:06:15.041030 EDT | MaxReturn                1000
2017-06-03 13:06:15.041287 EDT | MinReturn                1000
2017-06-03 13:06:15.041523 EDT | AverageEsReturn            26
2017-06-03 13:06:15.041771 EDT | StdEsReturn                22.9652
2017-06-03 13:06:15.042005 EDT | MaxEsReturn               128
2017-06-03 13:06:15.042240 EDT | MinEsReturn                 4
2017-06-03 13:06:15.042489 EDT | AverageDiscountedReturn    99.9957
2017-06-03 13:06:15.042721 EDT | AverageQLoss                7.38749e-05
2017-06-03 13:06:15.042952 EDT | AveragePolicySurr          -0.128917
2017-06-03 13:06:15.043184 EDT | AverageQ                    0.112588
2017-06-03 13:06:15.043418 EDT | AverageAbsQ                 0.113602
2017-06-03 13:06:15.043651 EDT | AverageY                    0.112595
2017-06-03 13:06:15.043882 EDT | AverageAbsY                 0.113269
2017-06-03 13:06:15.044139 EDT | AverageAbsQYDiff            0.00409771
2017-06-03 13:06:15.044371 EDT | AverageAction               0.215844
2017-06-03 13:06:15.044603 EDT | PolicyRegParamNorm         25.7418
2017-06-03 13:06:15.044835 EDT | QFunRegParamNorm           17.9076
2017-06-03 13:06:15.045070 EDT | -----------------------  --------------
2017-06-03 13:06:15.045471 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #44 | Training started
2017-06-03 13:06:34.353539 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #44 | Training finished
2017-06-03 13:06:34.354526 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #44 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 13:06:34.354800 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #44 | Collecting samples for evaluation
2017-06-03 13:06:43.626130 EDT | -----------------------  --------------
2017-06-03 13:06:43.626617 EDT | Epoch                      44
2017-06-03 13:06:43.626881 EDT | Iteration                  44
2017-06-03 13:06:43.627121 EDT | AverageReturn            1000
2017-06-03 13:06:43.627359 EDT | StdReturn                   0
2017-06-03 13:06:43.627594 EDT | MaxReturn                1000
2017-06-03 13:06:43.627829 EDT | MinReturn                1000
2017-06-03 13:06:43.628063 EDT | AverageEsReturn            30.9677
2017-06-03 13:06:43.628299 EDT | StdEsReturn                23.5748
2017-06-03 13:06:43.628532 EDT | MaxEsReturn                92
2017-06-03 13:06:43.628766 EDT | MinEsReturn                 2
2017-06-03 13:06:43.628999 EDT | AverageDiscountedReturn    99.9957
2017-06-03 13:06:43.629232 EDT | AverageQLoss                8.84996e-05
2017-06-03 13:06:43.629466 EDT | AveragePolicySurr          -0.130326
2017-06-03 13:06:43.629806 EDT | AverageQ                    0.113712
2017-06-03 13:06:43.630057 EDT | AverageAbsQ                 0.114761
2017-06-03 13:06:43.630291 EDT | AverageY                    0.113714
2017-06-03 13:06:43.630524 EDT | AverageAbsY                 0.114293
2017-06-03 13:06:43.630764 EDT | AverageAbsQYDiff            0.00437357
2017-06-03 13:06:43.631006 EDT | AverageAction               0.0442154
2017-06-03 13:06:43.631239 EDT | PolicyRegParamNorm         26.0702
2017-06-03 13:06:43.631470 EDT | QFunRegParamNorm           18.0069
2017-06-03 13:06:43.631703 EDT | -----------------------  --------------
2017-06-03 13:06:43.632238 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #45 | Training started
2017-06-03 13:07:02.165569 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #45 | Training finished
2017-06-03 13:07:02.166586 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #45 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 13:07:02.166964 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #45 | Collecting samples for evaluation
2017-06-03 13:07:11.697359 EDT | -----------------------  ------------
2017-06-03 13:07:11.698330 EDT | Epoch                    45
2017-06-03 13:07:11.698606 EDT | Iteration                45
2017-06-03 13:07:11.698854 EDT | AverageReturn            86.8966
2017-06-03 13:07:11.699105 EDT | StdReturn                 2.71452
2017-06-03 13:07:11.699347 EDT | MaxReturn                94
2017-06-03 13:07:11.699590 EDT | MinReturn                80
2017-06-03 13:07:11.699829 EDT | AverageEsReturn          32.4062
2017-06-03 13:07:11.700067 EDT | StdEsReturn              22.7347
2017-06-03 13:07:11.700301 EDT | MaxEsReturn              92
2017-06-03 13:07:11.700535 EDT | MinEsReturn               5
2017-06-03 13:07:11.700770 EDT | AverageDiscountedReturn  58.229
2017-06-03 13:07:11.701004 EDT | AverageQLoss              9.61742e-05
2017-06-03 13:07:11.701237 EDT | AveragePolicySurr        -0.131199
2017-06-03 13:07:11.701470 EDT | AverageQ                  0.115037
2017-06-03 13:07:11.701815 EDT | AverageAbsQ               0.116145
2017-06-03 13:07:11.702060 EDT | AverageY                  0.115042
2017-06-03 13:07:11.702294 EDT | AverageAbsY               0.115689
2017-06-03 13:07:11.702526 EDT | AverageAbsQYDiff          0.00452757
2017-06-03 13:07:11.702758 EDT | AverageAction             0.322838
2017-06-03 13:07:11.703001 EDT | PolicyRegParamNorm       26.3194
2017-06-03 13:07:11.703233 EDT | QFunRegParamNorm         18.0926
2017-06-03 13:07:11.703465 EDT | -----------------------  ------------
2017-06-03 13:07:11.703900 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #46 | Training started
2017-06-03 13:07:30.312121 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #46 | Training finished
2017-06-03 13:07:30.313141 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #46 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 13:07:30.313508 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #46 | Collecting samples for evaluation
2017-06-03 13:07:40.233956 EDT | -----------------------  --------------
2017-06-03 13:07:40.234940 EDT | Epoch                      46
2017-06-03 13:07:40.235294 EDT | Iteration                  46
2017-06-03 13:07:40.235628 EDT | AverageReturn            1000
2017-06-03 13:07:40.235941 EDT | StdReturn                   0
2017-06-03 13:07:40.236252 EDT | MaxReturn                1000
2017-06-03 13:07:40.236569 EDT | MinReturn                1000
2017-06-03 13:07:40.236884 EDT | AverageEsReturn            28.8235
2017-06-03 13:07:40.237209 EDT | StdEsReturn                26.379
2017-06-03 13:07:40.237522 EDT | MaxEsReturn                95
2017-06-03 13:07:40.237871 EDT | MinEsReturn                 3
2017-06-03 13:07:40.238199 EDT | AverageDiscountedReturn    99.9957
2017-06-03 13:07:40.238539 EDT | AverageQLoss                9.17369e-05
2017-06-03 13:07:40.238867 EDT | AveragePolicySurr          -0.132575
2017-06-03 13:07:40.239175 EDT | AverageQ                    0.11605
2017-06-03 13:07:40.239484 EDT | AverageAbsQ                 0.117222
2017-06-03 13:07:40.239812 EDT | AverageY                    0.116051
2017-06-03 13:07:40.240119 EDT | AverageAbsY                 0.11675
2017-06-03 13:07:40.240423 EDT | AverageAbsQYDiff            0.00436277
2017-06-03 13:07:40.240737 EDT | AverageAction               0.564106
2017-06-03 13:07:40.241046 EDT | PolicyRegParamNorm         26.6506
2017-06-03 13:07:40.241386 EDT | QFunRegParamNorm           18.1879
2017-06-03 13:07:40.241689 EDT | -----------------------  --------------
2017-06-03 13:07:40.242149 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #47 | Training started
2017-06-03 13:07:59.157988 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #47 | Training finished
2017-06-03 13:07:59.158950 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #47 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 13:07:59.159255 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #47 | Collecting samples for evaluation
2017-06-03 13:08:09.658764 EDT | -----------------------  -------------
2017-06-03 13:08:09.659610 EDT | Epoch                     47
2017-06-03 13:08:09.659915 EDT | Iteration                 47
2017-06-03 13:08:09.660164 EDT | AverageReturn            102.194
2017-06-03 13:08:09.660405 EDT | StdReturn                 32.0286
2017-06-03 13:08:09.660647 EDT | MaxReturn                198
2017-06-03 13:08:09.660890 EDT | MinReturn                 56
2017-06-03 13:08:09.661137 EDT | AverageEsReturn           27.9714
2017-06-03 13:08:09.661375 EDT | StdEsReturn               22.7087
2017-06-03 13:08:09.661612 EDT | MaxEsReturn              118
2017-06-03 13:08:09.661866 EDT | MinEsReturn                3
2017-06-03 13:08:09.662099 EDT | AverageDiscountedReturn   62.4609
2017-06-03 13:08:09.662332 EDT | AverageQLoss               9.50931e-05
2017-06-03 13:08:09.662586 EDT | AveragePolicySurr         -0.133748
2017-06-03 13:08:09.662823 EDT | AverageQ                   0.117375
2017-06-03 13:08:09.663059 EDT | AverageAbsQ                0.118522
2017-06-03 13:08:09.663294 EDT | AverageY                   0.117374
2017-06-03 13:08:09.663529 EDT | AverageAbsY                0.118108
2017-06-03 13:08:09.663771 EDT | AverageAbsQYDiff           0.00427392
2017-06-03 13:08:09.664013 EDT | AverageAction              0.651574
2017-06-03 13:08:09.664249 EDT | PolicyRegParamNorm        26.9514
2017-06-03 13:08:09.664484 EDT | QFunRegParamNorm          18.2867
2017-06-03 13:08:09.664715 EDT | -----------------------  -------------
2017-06-03 13:08:09.665121 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #48 | Training started
2017-06-03 13:08:30.150604 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #48 | Training finished
2017-06-03 13:08:30.151561 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #48 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 13:08:30.151841 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #48 | Collecting samples for evaluation
2017-06-03 13:08:41.703644 EDT | -----------------------  --------------
2017-06-03 13:08:41.704653 EDT | Epoch                      48
2017-06-03 13:08:41.705002 EDT | Iteration                  48
2017-06-03 13:08:41.705343 EDT | AverageReturn             393.259
2017-06-03 13:08:41.705672 EDT | StdReturn                 429.092
2017-06-03 13:08:41.706001 EDT | MaxReturn                1000
2017-06-03 13:08:41.706321 EDT | MinReturn                  74
2017-06-03 13:08:41.706630 EDT | AverageEsReturn            36.6429
2017-06-03 13:08:41.706949 EDT | StdEsReturn                31.0589
2017-06-03 13:08:41.707263 EDT | MaxEsReturn               122
2017-06-03 13:08:41.707573 EDT | MinEsReturn                 3
2017-06-03 13:08:41.707884 EDT | AverageDiscountedReturn    72.8785
2017-06-03 13:08:41.708195 EDT | AverageQLoss                0.000110385
2017-06-03 13:08:41.708506 EDT | AveragePolicySurr          -0.134737
2017-06-03 13:08:41.708829 EDT | AverageQ                    0.118422
2017-06-03 13:08:41.709149 EDT | AverageAbsQ                 0.119557
2017-06-03 13:08:41.709460 EDT | AverageY                    0.11842
2017-06-03 13:08:41.709776 EDT | AverageAbsY                 0.119149
2017-06-03 13:08:41.710086 EDT | AverageAbsQYDiff            0.00453501
2017-06-03 13:08:41.710396 EDT | AverageAction               0.0710192
2017-06-03 13:08:41.710709 EDT | PolicyRegParamNorm         27.2458
2017-06-03 13:08:41.711016 EDT | QFunRegParamNorm           18.347
2017-06-03 13:08:41.711323 EDT | -----------------------  --------------
2017-06-03 13:08:41.711939 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #49 | Training started
2017-06-03 13:09:00.008611 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #49 | Training finished
2017-06-03 13:09:00.009494 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #49 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 13:09:00.009793 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #49 | Collecting samples for evaluation
2017-06-03 13:09:09.463030 EDT | -----------------------  -------------
2017-06-03 13:09:09.463884 EDT | Epoch                      49
2017-06-03 13:09:09.464150 EDT | Iteration                  49
2017-06-03 13:09:09.464390 EDT | AverageReturn            1000
2017-06-03 13:09:09.464623 EDT | StdReturn                   0
2017-06-03 13:09:09.464864 EDT | MaxReturn                1000
2017-06-03 13:09:09.465099 EDT | MinReturn                1000
2017-06-03 13:09:09.465334 EDT | AverageEsReturn            28.8
2017-06-03 13:09:09.465564 EDT | StdEsReturn                21.6159
2017-06-03 13:09:09.465806 EDT | MaxEsReturn                82
2017-06-03 13:09:09.466035 EDT | MinEsReturn                 3
2017-06-03 13:09:09.466264 EDT | AverageDiscountedReturn    99.9957
2017-06-03 13:09:09.466527 EDT | AverageQLoss                8.89e-05
2017-06-03 13:09:09.466781 EDT | AveragePolicySurr          -0.135823
2017-06-03 13:09:09.467021 EDT | AverageQ                    0.119607
2017-06-03 13:09:09.467251 EDT | AverageAbsQ                 0.120748
2017-06-03 13:09:09.467480 EDT | AverageY                    0.119619
2017-06-03 13:09:09.467709 EDT | AverageAbsY                 0.120359
2017-06-03 13:09:09.467937 EDT | AverageAbsQYDiff            0.00418887
2017-06-03 13:09:09.468174 EDT | AverageAction               0.130153
2017-06-03 13:09:09.468401 EDT | PolicyRegParamNorm         27.4887
2017-06-03 13:09:09.468631 EDT | QFunRegParamNorm           18.4478
2017-06-03 13:09:09.468880 EDT | -----------------------  -------------
2017-06-03 13:09:09.469236 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #50 | Training started
2017-06-03 13:09:28.588813 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #50 | Training finished
2017-06-03 13:09:28.589757 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #50 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 13:09:28.590042 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #50 | Collecting samples for evaluation
2017-06-03 13:09:39.131001 EDT | -----------------------  --------------
2017-06-03 13:09:39.131750 EDT | Epoch                      50
2017-06-03 13:09:39.132046 EDT | Iteration                  50
2017-06-03 13:09:39.132307 EDT | AverageReturn            1000
2017-06-03 13:09:39.132563 EDT | StdReturn                   0
2017-06-03 13:09:39.132823 EDT | MaxReturn                1000
2017-06-03 13:09:39.133094 EDT | MinReturn                1000
2017-06-03 13:09:39.133344 EDT | AverageEsReturn            29.4839
2017-06-03 13:09:39.133595 EDT | StdEsReturn                27.2774
2017-06-03 13:09:39.133883 EDT | MaxEsReturn               101
2017-06-03 13:09:39.134198 EDT | MinEsReturn                 4
2017-06-03 13:09:39.134542 EDT | AverageDiscountedReturn    99.9957
2017-06-03 13:09:39.134878 EDT | AverageQLoss                9.99625e-05
2017-06-03 13:09:39.135141 EDT | AveragePolicySurr          -0.138384
2017-06-03 13:09:39.135390 EDT | AverageQ                    0.122108
2017-06-03 13:09:39.135640 EDT | AverageAbsQ                 0.123159
2017-06-03 13:09:39.135895 EDT | AverageY                    0.122105
2017-06-03 13:09:39.136151 EDT | AverageAbsY                 0.122812
2017-06-03 13:09:39.136409 EDT | AverageAbsQYDiff            0.00430946
2017-06-03 13:09:39.136654 EDT | AverageAction               0.0451113
2017-06-03 13:09:39.136898 EDT | PolicyRegParamNorm         27.6333
2017-06-03 13:09:39.137142 EDT | QFunRegParamNorm           18.5756
2017-06-03 13:09:39.137419 EDT | -----------------------  --------------
2017-06-03 13:09:39.137980 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #51 | Training started
2017-06-03 13:09:57.877638 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #51 | Training finished
2017-06-03 13:09:57.878605 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #51 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 13:09:57.878976 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #51 | Collecting samples for evaluation
2017-06-03 13:10:07.632229 EDT | -----------------------  --------------
2017-06-03 13:10:07.633114 EDT | Epoch                      51
2017-06-03 13:10:07.633389 EDT | Iteration                  51
2017-06-03 13:10:07.633634 EDT | AverageReturn            1000
2017-06-03 13:10:07.633886 EDT | StdReturn                   0
2017-06-03 13:10:07.634133 EDT | MaxReturn                1000
2017-06-03 13:10:07.634374 EDT | MinReturn                1000
2017-06-03 13:10:07.634609 EDT | AverageEsReturn            44.6667
2017-06-03 13:10:07.634845 EDT | StdEsReturn                33.7733
2017-06-03 13:10:07.635089 EDT | MaxEsReturn               135
2017-06-03 13:10:07.635333 EDT | MinEsReturn                 3
2017-06-03 13:10:07.635567 EDT | AverageDiscountedReturn    99.9957
2017-06-03 13:10:07.635800 EDT | AverageQLoss                8.54786e-05
2017-06-03 13:10:07.636033 EDT | AveragePolicySurr          -0.14007
2017-06-03 13:10:07.636265 EDT | AverageQ                    0.124181
2017-06-03 13:10:07.636498 EDT | AverageAbsQ                 0.125347
2017-06-03 13:10:07.636744 EDT | AverageY                    0.124193
2017-06-03 13:10:07.636999 EDT | AverageAbsY                 0.124941
2017-06-03 13:10:07.637244 EDT | AverageAbsQYDiff            0.00399192
2017-06-03 13:10:07.637487 EDT | AverageAction               0.660628
2017-06-03 13:10:07.637738 EDT | PolicyRegParamNorm         27.8496
2017-06-03 13:10:07.638009 EDT | QFunRegParamNorm           18.6337
2017-06-03 13:10:07.638259 EDT | -----------------------  --------------
2017-06-03 13:10:07.638643 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #52 | Training started
2017-06-03 13:10:26.536144 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #52 | Training finished
2017-06-03 13:10:26.539819 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #52 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 13:10:26.540208 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #52 | Collecting samples for evaluation
2017-06-03 13:10:39.514561 EDT | -----------------------  --------------
2017-06-03 13:10:39.515492 EDT | Epoch                      52
2017-06-03 13:10:39.515756 EDT | Iteration                  52
2017-06-03 13:10:39.515993 EDT | AverageReturn            1000
2017-06-03 13:10:39.516226 EDT | StdReturn                   0
2017-06-03 13:10:39.516456 EDT | MaxReturn                1000
2017-06-03 13:10:39.516686 EDT | MinReturn                1000
2017-06-03 13:10:39.516916 EDT | AverageEsReturn            25.8462
2017-06-03 13:10:39.517149 EDT | StdEsReturn                18.6128
2017-06-03 13:10:39.517384 EDT | MaxEsReturn                88
2017-06-03 13:10:39.517642 EDT | MinEsReturn                 3
2017-06-03 13:10:39.517891 EDT | AverageDiscountedReturn    99.9957
2017-06-03 13:10:39.518131 EDT | AverageQLoss                9.99988e-05
2017-06-03 13:10:39.518361 EDT | AveragePolicySurr          -0.140869
2017-06-03 13:10:39.518588 EDT | AverageQ                    0.125254
2017-06-03 13:10:39.518837 EDT | AverageAbsQ                 0.126396
2017-06-03 13:10:39.519116 EDT | AverageY                    0.125249
2017-06-03 13:10:39.519375 EDT | AverageAbsY                 0.125983
2017-06-03 13:10:39.519606 EDT | AverageAbsQYDiff            0.00431823
2017-06-03 13:10:39.519834 EDT | AverageAction               0.778855
2017-06-03 13:10:39.520097 EDT | PolicyRegParamNorm         28.0076
2017-06-03 13:10:39.520326 EDT | QFunRegParamNorm           18.7144
2017-06-03 13:10:39.520554 EDT | -----------------------  --------------
2017-06-03 13:10:39.521093 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #53 | Training started
2017-06-03 13:10:58.682132 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #53 | Training finished
2017-06-03 13:10:58.682990 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #53 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 13:10:58.683383 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #53 | Collecting samples for evaluation
2017-06-03 13:11:09.092238 EDT | -----------------------  --------------
2017-06-03 13:11:09.092623 EDT | Epoch                      53
2017-06-03 13:11:09.092880 EDT | Iteration                  53
2017-06-03 13:11:09.093123 EDT | AverageReturn            1000
2017-06-03 13:11:09.093369 EDT | StdReturn                   0
2017-06-03 13:11:09.093609 EDT | MaxReturn                1000
2017-06-03 13:11:09.093861 EDT | MinReturn                1000
2017-06-03 13:11:09.094100 EDT | AverageEsReturn            38.9231
2017-06-03 13:11:09.094337 EDT | StdEsReturn                31.376
2017-06-03 13:11:09.094573 EDT | MaxEsReturn               135
2017-06-03 13:11:09.094809 EDT | MinEsReturn                 3
2017-06-03 13:11:09.095046 EDT | AverageDiscountedReturn    99.9957
2017-06-03 13:11:09.095281 EDT | AverageQLoss                0.000103229
2017-06-03 13:11:09.095516 EDT | AveragePolicySurr          -0.14114
2017-06-03 13:11:09.095751 EDT | AverageQ                    0.125802
2017-06-03 13:11:09.095986 EDT | AverageAbsQ                 0.126927
2017-06-03 13:11:09.096221 EDT | AverageY                    0.125804
2017-06-03 13:11:09.096455 EDT | AverageAbsY                 0.126539
2017-06-03 13:11:09.096688 EDT | AverageAbsQYDiff            0.00441233
2017-06-03 13:11:09.096922 EDT | AverageAction               0.273512
2017-06-03 13:11:09.097155 EDT | PolicyRegParamNorm         28.251
2017-06-03 13:11:09.097389 EDT | QFunRegParamNorm           18.7549
2017-06-03 13:11:09.097623 EDT | -----------------------  --------------
2017-06-03 13:11:09.097984 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #54 | Training started
2017-06-03 13:11:27.400166 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #54 | Training finished
2017-06-03 13:11:27.401175 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #54 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 13:11:27.401582 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #54 | Collecting samples for evaluation
2017-06-03 13:11:38.315204 EDT | -----------------------  --------------
2017-06-03 13:11:38.318730 EDT | Epoch                      54
2017-06-03 13:11:38.319118 EDT | Iteration                  54
2017-06-03 13:11:38.319443 EDT | AverageReturn            1000
2017-06-03 13:11:38.319769 EDT | StdReturn                   0
2017-06-03 13:11:38.320084 EDT | MaxReturn                1000
2017-06-03 13:11:38.320394 EDT | MinReturn                1000
2017-06-03 13:11:38.320703 EDT | AverageEsReturn            26.9459
2017-06-03 13:11:38.321014 EDT | StdEsReturn                20.4278
2017-06-03 13:11:38.321331 EDT | MaxEsReturn                94
2017-06-03 13:11:38.321722 EDT | MinEsReturn                 3
2017-06-03 13:11:38.322156 EDT | AverageDiscountedReturn    99.9957
2017-06-03 13:11:38.322495 EDT | AverageQLoss                9.88017e-05
2017-06-03 13:11:38.322905 EDT | AveragePolicySurr          -0.14253
2017-06-03 13:11:38.323270 EDT | AverageQ                    0.12735
2017-06-03 13:11:38.323658 EDT | AverageAbsQ                 0.128352
2017-06-03 13:11:38.324082 EDT | AverageY                    0.127358
2017-06-03 13:11:38.324490 EDT | AverageAbsY                 0.128011
2017-06-03 13:11:38.324883 EDT | AverageAbsQYDiff            0.00422379
2017-06-03 13:11:38.325208 EDT | AverageAction               0.558834
2017-06-03 13:11:38.325522 EDT | PolicyRegParamNorm         28.555
2017-06-03 13:11:38.325928 EDT | QFunRegParamNorm           18.8059
2017-06-03 13:11:38.326295 EDT | -----------------------  --------------
2017-06-03 13:11:38.326871 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #55 | Training started
2017-06-03 13:11:58.017675 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #55 | Training finished
2017-06-03 13:11:58.018574 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #55 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 13:11:58.018878 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #55 | Collecting samples for evaluation
2017-06-03 13:12:07.995194 EDT | -----------------------  --------------
2017-06-03 13:12:07.996031 EDT | Epoch                      55
2017-06-03 13:12:07.996296 EDT | Iteration                  55
2017-06-03 13:12:07.996545 EDT | AverageReturn            1000
2017-06-03 13:12:07.996787 EDT | StdReturn                   0
2017-06-03 13:12:07.997027 EDT | MaxReturn                1000
2017-06-03 13:12:07.997265 EDT | MinReturn                1000
2017-06-03 13:12:07.997499 EDT | AverageEsReturn            39.32
2017-06-03 13:12:07.997744 EDT | StdEsReturn                29.4207
2017-06-03 13:12:07.997984 EDT | MaxEsReturn               113
2017-06-03 13:12:07.998220 EDT | MinEsReturn                 4
2017-06-03 13:12:07.998458 EDT | AverageDiscountedReturn    99.9957
2017-06-03 13:12:07.998698 EDT | AverageQLoss                9.49011e-05
2017-06-03 13:12:07.998963 EDT | AveragePolicySurr          -0.143841
2017-06-03 13:12:07.999202 EDT | AverageQ                    0.128387
2017-06-03 13:12:07.999437 EDT | AverageAbsQ                 0.12939
2017-06-03 13:12:07.999671 EDT | AverageY                    0.128383
2017-06-03 13:12:07.999912 EDT | AverageAbsY                 0.128998
2017-06-03 13:12:08.000147 EDT | AverageAbsQYDiff            0.00410646
2017-06-03 13:12:08.000380 EDT | AverageAction               0.644588
2017-06-03 13:12:08.000615 EDT | PolicyRegParamNorm         28.8346
2017-06-03 13:12:08.000857 EDT | QFunRegParamNorm           18.9455
2017-06-03 13:12:08.001095 EDT | -----------------------  --------------
2017-06-03 13:12:08.001478 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #56 | Training started
2017-06-03 13:12:28.616735 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #56 | Training finished
2017-06-03 13:12:28.617672 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #56 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 13:12:28.617974 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #56 | Collecting samples for evaluation
2017-06-03 13:12:37.849181 EDT | -----------------------  --------------
2017-06-03 13:12:37.850021 EDT | Epoch                      56
2017-06-03 13:12:37.850291 EDT | Iteration                  56
2017-06-03 13:12:37.850551 EDT | AverageReturn            1000
2017-06-03 13:12:37.850795 EDT | StdReturn                   0
2017-06-03 13:12:37.851038 EDT | MaxReturn                1000
2017-06-03 13:12:37.851285 EDT | MinReturn                1000
2017-06-03 13:12:37.851525 EDT | AverageEsReturn            28.25
2017-06-03 13:12:37.851768 EDT | StdEsReturn                25.3074
2017-06-03 13:12:37.852013 EDT | MaxEsReturn               109
2017-06-03 13:12:37.852253 EDT | MinEsReturn                 3
2017-06-03 13:12:37.852595 EDT | AverageDiscountedReturn    99.9957
2017-06-03 13:12:37.852905 EDT | AverageQLoss                0.000108385
2017-06-03 13:12:37.853215 EDT | AveragePolicySurr          -0.145002
2017-06-03 13:12:37.853527 EDT | AverageQ                    0.129308
2017-06-03 13:12:37.853845 EDT | AverageAbsQ                 0.130425
2017-06-03 13:12:37.854151 EDT | AverageY                    0.129316
2017-06-03 13:12:37.854455 EDT | AverageAbsY                 0.129932
2017-06-03 13:12:37.854758 EDT | AverageAbsQYDiff            0.00438537
2017-06-03 13:12:37.855063 EDT | AverageAction               0.66594
2017-06-03 13:12:37.855367 EDT | PolicyRegParamNorm         29.2648
2017-06-03 13:12:37.855671 EDT | QFunRegParamNorm           19.0052
2017-06-03 13:12:37.855975 EDT | -----------------------  --------------
2017-06-03 13:12:37.856547 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #57 | Training started
2017-06-03 13:12:57.807960 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #57 | Training finished
2017-06-03 13:12:57.809046 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #57 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 13:12:57.809446 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #57 | Collecting samples for evaluation
2017-06-03 13:13:07.944844 EDT | -----------------------  ------------
2017-06-03 13:13:07.945755 EDT | Epoch                    57
2017-06-03 13:13:07.946141 EDT | Iteration                57
2017-06-03 13:13:07.947060 EDT | AverageReturn            39.082
2017-06-03 13:13:07.947643 EDT | StdReturn                 1.40212
2017-06-03 13:13:07.948319 EDT | MaxReturn                44
2017-06-03 13:13:07.948574 EDT | MinReturn                37
2017-06-03 13:13:07.949266 EDT | AverageEsReturn          25.7436
2017-06-03 13:13:07.949507 EDT | StdEsReturn              22.9657
2017-06-03 13:13:07.949760 EDT | MaxEsReturn              83
2017-06-03 13:13:07.950002 EDT | MinEsReturn               3
2017-06-03 13:13:07.950906 EDT | AverageDiscountedReturn  32.4761
2017-06-03 13:13:07.951193 EDT | AverageQLoss              9.91805e-05
2017-06-03 13:13:07.951428 EDT | AveragePolicySurr        -0.146801
2017-06-03 13:13:07.951679 EDT | AverageQ                  0.131191
2017-06-03 13:13:07.951913 EDT | AverageAbsQ               0.13211
2017-06-03 13:13:07.952145 EDT | AverageY                  0.131197
2017-06-03 13:13:07.952379 EDT | AverageAbsY               0.131704
2017-06-03 13:13:07.952610 EDT | AverageAbsQYDiff          0.00413041
2017-06-03 13:13:07.952842 EDT | AverageAction             0.821753
2017-06-03 13:13:07.953073 EDT | PolicyRegParamNorm       29.6526
2017-06-03 13:13:07.953304 EDT | QFunRegParamNorm         19.0452
2017-06-03 13:13:07.953545 EDT | -----------------------  ------------
2017-06-03 13:13:07.954549 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #58 | Training started
2017-06-03 13:13:26.722335 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #58 | Training finished
2017-06-03 13:13:26.723299 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #58 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 13:13:26.723711 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #58 | Collecting samples for evaluation
2017-06-03 13:13:38.906571 EDT | -----------------------  ------------
2017-06-03 13:13:38.907415 EDT | Epoch                    58
2017-06-03 13:13:38.907674 EDT | Iteration                58
2017-06-03 13:13:38.907913 EDT | AverageReturn            39.9522
2017-06-03 13:13:38.908249 EDT | StdReturn                 3.07763
2017-06-03 13:13:38.908600 EDT | MaxReturn                52
2017-06-03 13:13:38.908887 EDT | MinReturn                36
2017-06-03 13:13:38.909171 EDT | AverageEsReturn          24.0976
2017-06-03 13:13:38.909508 EDT | StdEsReturn              17.9713
2017-06-03 13:13:38.909802 EDT | MaxEsReturn              61
2017-06-03 13:13:38.910048 EDT | MinEsReturn               4
2017-06-03 13:13:38.910284 EDT | AverageDiscountedReturn  33.039
2017-06-03 13:13:38.910528 EDT | AverageQLoss              9.57368e-05
2017-06-03 13:13:38.910770 EDT | AveragePolicySurr        -0.146909
2017-06-03 13:13:38.911002 EDT | AverageQ                  0.132725
2017-06-03 13:13:38.911243 EDT | AverageAbsQ               0.13359
2017-06-03 13:13:38.911474 EDT | AverageY                  0.132714
2017-06-03 13:13:38.911722 EDT | AverageAbsY               0.133167
2017-06-03 13:13:38.912060 EDT | AverageAbsQYDiff          0.00400768
2017-06-03 13:13:38.912397 EDT | AverageAction             0.77942
2017-06-03 13:13:38.912688 EDT | PolicyRegParamNorm       29.8898
2017-06-03 13:13:38.913027 EDT | QFunRegParamNorm         19.0686
2017-06-03 13:13:38.913308 EDT | -----------------------  ------------
2017-06-03 13:13:38.913726 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #59 | Training started
2017-06-03 13:13:59.114911 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #59 | Training finished
2017-06-03 13:13:59.115805 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #59 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 13:13:59.116091 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #59 | Collecting samples for evaluation
2017-06-03 13:14:08.890174 EDT | -----------------------  -------------
2017-06-03 13:14:08.891058 EDT | Epoch                     59
2017-06-03 13:14:08.891335 EDT | Iteration                 59
2017-06-03 13:14:08.891589 EDT | AverageReturn            113.64
2017-06-03 13:14:08.891854 EDT | StdReturn                 38.0072
2017-06-03 13:14:08.892103 EDT | MaxReturn                160
2017-06-03 13:14:08.892347 EDT | MinReturn                 44
2017-06-03 13:14:08.892594 EDT | AverageEsReturn           23.5814
2017-06-03 13:14:08.892859 EDT | StdEsReturn               18.6189
2017-06-03 13:14:08.893102 EDT | MaxEsReturn               87
2017-06-03 13:14:08.893344 EDT | MinEsReturn                3
2017-06-03 13:14:08.893587 EDT | AverageDiscountedReturn   65.454
2017-06-03 13:14:08.893853 EDT | AverageQLoss               0.000105315
2017-06-03 13:14:08.894095 EDT | AveragePolicySurr         -0.147558
2017-06-03 13:14:08.894336 EDT | AverageQ                   0.132919
2017-06-03 13:14:08.894579 EDT | AverageAbsQ                0.133826
2017-06-03 13:14:08.894822 EDT | AverageY                   0.132936
2017-06-03 13:14:08.895064 EDT | AverageAbsY                0.13342
2017-06-03 13:14:08.895303 EDT | AverageAbsQYDiff           0.00417886
2017-06-03 13:14:08.895562 EDT | AverageAction              0.503668
2017-06-03 13:14:08.895813 EDT | PolicyRegParamNorm        30.082
2017-06-03 13:14:08.896053 EDT | QFunRegParamNorm          19.2026
2017-06-03 13:14:08.896295 EDT | -----------------------  -------------
2017-06-03 13:14:08.896794 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #60 | Training started
2017-06-03 13:14:27.405181 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #60 | Training finished
2017-06-03 13:14:27.406161 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #60 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 13:14:27.406526 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #60 | Collecting samples for evaluation
2017-06-03 13:14:36.506903 EDT | -----------------------  -------------
2017-06-03 13:14:36.507782 EDT | Epoch                     60
2017-06-03 13:14:36.508056 EDT | Iteration                 60
2017-06-03 13:14:36.508303 EDT | AverageReturn            108.957
2017-06-03 13:14:36.508547 EDT | StdReturn                 48.1763
2017-06-03 13:14:36.508878 EDT | MaxReturn                247
2017-06-03 13:14:36.509211 EDT | MinReturn                 45
2017-06-03 13:14:36.509527 EDT | AverageEsReturn           26.3421
2017-06-03 13:14:36.509870 EDT | StdEsReturn               19.9305
2017-06-03 13:14:36.510216 EDT | MaxEsReturn               97
2017-06-03 13:14:36.510528 EDT | MinEsReturn                3
2017-06-03 13:14:36.510870 EDT | AverageDiscountedReturn   62.5018
2017-06-03 13:14:36.511187 EDT | AverageQLoss               9.95605e-05
2017-06-03 13:14:36.511511 EDT | AveragePolicySurr         -0.146902
2017-06-03 13:14:36.511839 EDT | AverageQ                   0.132347
2017-06-03 13:14:36.512152 EDT | AverageAbsQ                0.13333
2017-06-03 13:14:36.512464 EDT | AverageY                   0.132344
2017-06-03 13:14:36.512780 EDT | AverageAbsY                0.13287
2017-06-03 13:14:36.513108 EDT | AverageAbsQYDiff           0.00407469
2017-06-03 13:14:36.513677 EDT | AverageAction              0.532835
2017-06-03 13:14:36.514178 EDT | PolicyRegParamNorm        30.2746
2017-06-03 13:14:36.514695 EDT | QFunRegParamNorm          19.2746
2017-06-03 13:14:36.515353 EDT | -----------------------  -------------
2017-06-03 13:14:36.515994 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #61 | Training started
2017-06-03 13:14:55.689329 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #61 | Training finished
2017-06-03 13:14:55.690271 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #61 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 13:14:55.690595 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #61 | Collecting samples for evaluation
2017-06-03 13:15:05.403605 EDT | -----------------------  --------------
2017-06-03 13:15:05.404552 EDT | Epoch                      61
2017-06-03 13:15:05.404836 EDT | Iteration                  61
2017-06-03 13:15:05.405093 EDT | AverageReturn            1000
2017-06-03 13:15:05.405353 EDT | StdReturn                   0
2017-06-03 13:15:05.405604 EDT | MaxReturn                1000
2017-06-03 13:15:05.405872 EDT | MinReturn                1000
2017-06-03 13:15:05.406169 EDT | AverageEsReturn            25.359
2017-06-03 13:15:05.406431 EDT | StdEsReturn                20.1526
2017-06-03 13:15:05.406684 EDT | MaxEsReturn                76
2017-06-03 13:15:05.406935 EDT | MinEsReturn                 2
2017-06-03 13:15:05.407241 EDT | AverageDiscountedReturn    99.9957
2017-06-03 13:15:05.407493 EDT | AverageQLoss                0.000107358
2017-06-03 13:15:05.407743 EDT | AveragePolicySurr          -0.147406
2017-06-03 13:15:05.407992 EDT | AverageQ                    0.13328
2017-06-03 13:15:05.408253 EDT | AverageAbsQ                 0.134255
2017-06-03 13:15:05.408499 EDT | AverageY                    0.133281
2017-06-03 13:15:05.408761 EDT | AverageAbsY                 0.133751
2017-06-03 13:15:05.409018 EDT | AverageAbsQYDiff            0.00413344
2017-06-03 13:15:05.409264 EDT | AverageAction               0.464429
2017-06-03 13:15:05.409532 EDT | PolicyRegParamNorm         30.4289
2017-06-03 13:15:05.409798 EDT | QFunRegParamNorm           19.318
2017-06-03 13:15:05.410060 EDT | -----------------------  --------------
2017-06-03 13:15:05.410479 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #62 | Training started
2017-06-03 13:15:25.891787 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #62 | Training finished
2017-06-03 13:15:25.892723 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #62 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 13:15:25.893032 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #62 | Collecting samples for evaluation
2017-06-03 13:15:36.695246 EDT | -----------------------  --------------
2017-06-03 13:15:36.696113 EDT | Epoch                      62
2017-06-03 13:15:36.696404 EDT | Iteration                  62
2017-06-03 13:15:36.696647 EDT | AverageReturn            1000
2017-06-03 13:15:36.696877 EDT | StdReturn                   0
2017-06-03 13:15:36.697105 EDT | MaxReturn                1000
2017-06-03 13:15:36.697334 EDT | MinReturn                1000
2017-06-03 13:15:36.697567 EDT | AverageEsReturn            28.4286
2017-06-03 13:15:36.697807 EDT | StdEsReturn                21.8858
2017-06-03 13:15:36.698059 EDT | MaxEsReturn                90
2017-06-03 13:15:36.698289 EDT | MinEsReturn                 3
2017-06-03 13:15:36.698517 EDT | AverageDiscountedReturn    99.9957
2017-06-03 13:15:36.698746 EDT | AverageQLoss                0.000103791
2017-06-03 13:15:36.698981 EDT | AveragePolicySurr          -0.14737
2017-06-03 13:15:36.699209 EDT | AverageQ                    0.133599
2017-06-03 13:15:36.699446 EDT | AverageAbsQ                 0.134424
2017-06-03 13:15:36.699682 EDT | AverageY                    0.133605
2017-06-03 13:15:36.699964 EDT | AverageAbsY                 0.134072
2017-06-03 13:15:36.700197 EDT | AverageAbsQYDiff            0.00407047
2017-06-03 13:15:36.700422 EDT | AverageAction               0.730362
2017-06-03 13:15:36.700648 EDT | PolicyRegParamNorm         30.6316
2017-06-03 13:15:36.700875 EDT | QFunRegParamNorm           19.3804
2017-06-03 13:15:36.701109 EDT | -----------------------  --------------
2017-06-03 13:15:36.701541 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #63 | Training started
2017-06-03 13:15:55.702172 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #63 | Training finished
2017-06-03 13:15:55.703016 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #63 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 13:15:55.703279 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #63 | Collecting samples for evaluation
2017-06-03 13:16:06.515657 EDT | -----------------------  --------------
2017-06-03 13:16:06.516062 EDT | Epoch                      63
2017-06-03 13:16:06.516320 EDT | Iteration                  63
2017-06-03 13:16:06.516563 EDT | AverageReturn            1000
2017-06-03 13:16:06.516803 EDT | StdReturn                   0
2017-06-03 13:16:06.517042 EDT | MaxReturn                1000
2017-06-03 13:16:06.517297 EDT | MinReturn                1000
2017-06-03 13:16:06.517541 EDT | AverageEsReturn            40.3043
2017-06-03 13:16:06.517790 EDT | StdEsReturn                29.4728
2017-06-03 13:16:06.518028 EDT | MaxEsReturn               102
2017-06-03 13:16:06.518264 EDT | MinEsReturn                 7
2017-06-03 13:16:06.518507 EDT | AverageDiscountedReturn    99.9957
2017-06-03 13:16:06.518741 EDT | AverageQLoss                9.31503e-05
2017-06-03 13:16:06.518975 EDT | AveragePolicySurr          -0.148322
2017-06-03 13:16:06.519207 EDT | AverageQ                    0.134362
2017-06-03 13:16:06.519440 EDT | AverageAbsQ                 0.135229
2017-06-03 13:16:06.519672 EDT | AverageY                    0.134368
2017-06-03 13:16:06.519904 EDT | AverageAbsY                 0.134763
2017-06-03 13:16:06.520136 EDT | AverageAbsQYDiff            0.00394021
2017-06-03 13:16:06.520367 EDT | AverageAction               0.562482
2017-06-03 13:16:06.520600 EDT | PolicyRegParamNorm         31.018
2017-06-03 13:16:06.520831 EDT | QFunRegParamNorm           19.4393
2017-06-03 13:16:06.521063 EDT | -----------------------  --------------
2017-06-03 13:16:06.521426 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #64 | Training started
2017-06-03 13:16:26.044910 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #64 | Training finished
2017-06-03 13:16:26.045911 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #64 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 13:16:26.046307 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #64 | Collecting samples for evaluation
2017-06-03 13:16:35.903006 EDT | -----------------------  --------------
2017-06-03 13:16:35.903976 EDT | Epoch                      64
2017-06-03 13:16:35.904314 EDT | Iteration                  64
2017-06-03 13:16:35.904637 EDT | AverageReturn            1000
2017-06-03 13:16:35.904972 EDT | StdReturn                   0
2017-06-03 13:16:35.905285 EDT | MaxReturn                1000
2017-06-03 13:16:35.905600 EDT | MinReturn                1000
2017-06-03 13:16:35.905946 EDT | AverageEsReturn            41.92
2017-06-03 13:16:35.906268 EDT | StdEsReturn                35.9087
2017-06-03 13:16:35.906581 EDT | MaxEsReturn               116
2017-06-03 13:16:35.906897 EDT | MinEsReturn                 3
2017-06-03 13:16:35.907211 EDT | AverageDiscountedReturn    99.9957
2017-06-03 13:16:35.907523 EDT | AverageQLoss                0.000107578
2017-06-03 13:16:35.907840 EDT | AveragePolicySurr          -0.148877
2017-06-03 13:16:35.908153 EDT | AverageQ                    0.135095
2017-06-03 13:16:35.908462 EDT | AverageAbsQ                 0.135916
2017-06-03 13:16:35.908770 EDT | AverageY                    0.135095
2017-06-03 13:16:35.909078 EDT | AverageAbsY                 0.135465
2017-06-03 13:16:35.909387 EDT | AverageAbsQYDiff            0.00405393
2017-06-03 13:16:35.909770 EDT | AverageAction               0.523324
2017-06-03 13:16:35.910084 EDT | PolicyRegParamNorm         31.3586
2017-06-03 13:16:35.910394 EDT | QFunRegParamNorm           19.4979
2017-06-03 13:16:35.910707 EDT | -----------------------  --------------
2017-06-03 13:16:35.911167 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #65 | Training started
2017-06-03 13:16:54.848018 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #65 | Training finished
2017-06-03 13:16:54.848924 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #65 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 13:16:54.849305 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #65 | Collecting samples for evaluation
2017-06-03 13:17:04.027959 EDT | -----------------------  -------------
2017-06-03 13:17:04.028891 EDT | Epoch                      65
2017-06-03 13:17:04.029229 EDT | Iteration                  65
2017-06-03 13:17:04.029546 EDT | AverageReturn            1000
2017-06-03 13:17:04.029885 EDT | StdReturn                   0
2017-06-03 13:17:04.030225 EDT | MaxReturn                1000
2017-06-03 13:17:04.030530 EDT | MinReturn                1000
2017-06-03 13:17:04.030836 EDT | AverageEsReturn            26.6154
2017-06-03 13:17:04.031150 EDT | StdEsReturn                20.2023
2017-06-03 13:17:04.031455 EDT | MaxEsReturn                99
2017-06-03 13:17:04.031758 EDT | MinEsReturn                 3
2017-06-03 13:17:04.032060 EDT | AverageDiscountedReturn    99.9957
2017-06-03 13:17:04.032363 EDT | AverageQLoss                8.8756e-05
2017-06-03 13:17:04.032667 EDT | AveragePolicySurr          -0.149109
2017-06-03 13:17:04.032977 EDT | AverageQ                    0.135394
2017-06-03 13:17:04.033279 EDT | AverageAbsQ                 0.13618
2017-06-03 13:17:04.033580 EDT | AverageY                    0.1354
2017-06-03 13:17:04.033907 EDT | AverageAbsY                 0.135717
2017-06-03 13:17:04.034210 EDT | AverageAbsQYDiff            0.0037509
2017-06-03 13:17:04.034513 EDT | AverageAction               0.462043
2017-06-03 13:17:04.034816 EDT | PolicyRegParamNorm         31.7737
2017-06-03 13:17:04.035117 EDT | QFunRegParamNorm           19.5279
2017-06-03 13:17:04.035418 EDT | -----------------------  -------------
2017-06-03 13:17:04.035901 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #66 | Training started
2017-06-03 13:17:24.385290 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #66 | Training finished
2017-06-03 13:17:24.385951 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #66 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 13:17:24.386230 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #66 | Collecting samples for evaluation
2017-06-03 13:17:33.858661 EDT | -----------------------  -------------
2017-06-03 13:17:33.859545 EDT | Epoch                      66
2017-06-03 13:17:33.859847 EDT | Iteration                  66
2017-06-03 13:17:33.860111 EDT | AverageReturn            1000
2017-06-03 13:17:33.860353 EDT | StdReturn                   0
2017-06-03 13:17:33.860587 EDT | MaxReturn                1000
2017-06-03 13:17:33.860820 EDT | MinReturn                1000
2017-06-03 13:17:33.861450 EDT | AverageEsReturn            24.7949
2017-06-03 13:17:33.861745 EDT | StdEsReturn                22.8991
2017-06-03 13:17:33.861984 EDT | MaxEsReturn                96
2017-06-03 13:17:33.862271 EDT | MinEsReturn                 3
2017-06-03 13:17:33.862524 EDT | AverageDiscountedReturn    99.9957
2017-06-03 13:17:33.862785 EDT | AverageQLoss                0.00011755
2017-06-03 13:17:33.863021 EDT | AveragePolicySurr          -0.15049
2017-06-03 13:17:33.863266 EDT | AverageQ                    0.136763
2017-06-03 13:17:33.863528 EDT | AverageAbsQ                 0.137586
2017-06-03 13:17:33.863778 EDT | AverageY                    0.136767
2017-06-03 13:17:33.864024 EDT | AverageAbsY                 0.137117
2017-06-03 13:17:33.864256 EDT | AverageAbsQYDiff            0.00436679
2017-06-03 13:17:33.864488 EDT | AverageAction               0.333064
2017-06-03 13:17:33.864718 EDT | PolicyRegParamNorm         32.0783
2017-06-03 13:17:33.864946 EDT | QFunRegParamNorm           19.6136
2017-06-03 13:17:33.865177 EDT | -----------------------  -------------
2017-06-03 13:17:33.865565 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #67 | Training started
2017-06-03 13:17:52.513698 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #67 | Training finished
2017-06-03 13:17:52.514739 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #67 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 13:17:52.515172 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #67 | Collecting samples for evaluation
2017-06-03 13:18:01.792894 EDT | -----------------------  --------------
2017-06-03 13:18:01.793776 EDT | Epoch                      67
2017-06-03 13:18:01.794073 EDT | Iteration                  67
2017-06-03 13:18:01.794369 EDT | AverageReturn            1000
2017-06-03 13:18:01.794662 EDT | StdReturn                   0
2017-06-03 13:18:01.794914 EDT | MaxReturn                1000
2017-06-03 13:18:01.795238 EDT | MinReturn                1000
2017-06-03 13:18:01.795478 EDT | AverageEsReturn            29
2017-06-03 13:18:01.795703 EDT | StdEsReturn                24.9788
2017-06-03 13:18:01.795925 EDT | MaxEsReturn               118
2017-06-03 13:18:01.796155 EDT | MinEsReturn                 3
2017-06-03 13:18:01.796374 EDT | AverageDiscountedReturn    99.9957
2017-06-03 13:18:01.796594 EDT | AverageQLoss                0.000101884
2017-06-03 13:18:01.796811 EDT | AveragePolicySurr          -0.151642
2017-06-03 13:18:01.797035 EDT | AverageQ                    0.137898
2017-06-03 13:18:01.797253 EDT | AverageAbsQ                 0.138653
2017-06-03 13:18:01.797474 EDT | AverageY                    0.137893
2017-06-03 13:18:01.797723 EDT | AverageAbsY                 0.138259
2017-06-03 13:18:01.798009 EDT | AverageAbsQYDiff            0.00401008
2017-06-03 13:18:01.798259 EDT | AverageAction               0.0205615
2017-06-03 13:18:01.798488 EDT | PolicyRegParamNorm         32.3197
2017-06-03 13:18:01.798714 EDT | QFunRegParamNorm           19.697
2017-06-03 13:18:01.798939 EDT | -----------------------  --------------
2017-06-03 13:18:01.799325 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #68 | Training started
2017-06-03 13:18:20.970979 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #68 | Training finished
2017-06-03 13:18:20.971907 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #68 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 13:18:20.972328 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #68 | Collecting samples for evaluation
2017-06-03 13:18:30.471942 EDT | -----------------------  --------------
2017-06-03 13:18:30.472804 EDT | Epoch                      68
2017-06-03 13:18:30.473071 EDT | Iteration                  68
2017-06-03 13:18:30.473318 EDT | AverageReturn            1000
2017-06-03 13:18:30.473558 EDT | StdReturn                   0
2017-06-03 13:18:30.473824 EDT | MaxReturn                1000
2017-06-03 13:18:30.474063 EDT | MinReturn                1000
2017-06-03 13:18:30.474319 EDT | AverageEsReturn            28.8235
2017-06-03 13:18:30.474559 EDT | StdEsReturn                26.4269
2017-06-03 13:18:30.474795 EDT | MaxEsReturn                93
2017-06-03 13:18:30.475030 EDT | MinEsReturn                 3
2017-06-03 13:18:30.475274 EDT | AverageDiscountedReturn    99.9957
2017-06-03 13:18:30.475509 EDT | AverageQLoss                9.24456e-05
2017-06-03 13:18:30.475743 EDT | AveragePolicySurr          -0.151808
2017-06-03 13:18:30.475978 EDT | AverageQ                    0.138314
2017-06-03 13:18:30.476212 EDT | AverageAbsQ                 0.139027
2017-06-03 13:18:30.476446 EDT | AverageY                    0.138314
2017-06-03 13:18:30.476680 EDT | AverageAbsY                 0.138671
2017-06-03 13:18:30.476914 EDT | AverageAbsQYDiff            0.0037858
2017-06-03 13:18:30.477148 EDT | AverageAction               0.5055
2017-06-03 13:18:30.477382 EDT | PolicyRegParamNorm         32.6436
2017-06-03 13:18:30.477620 EDT | QFunRegParamNorm           19.7803
2017-06-03 13:18:30.477867 EDT | -----------------------  --------------
2017-06-03 13:18:30.478251 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #69 | Training started
2017-06-03 13:18:48.932659 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #69 | Training finished
2017-06-03 13:18:48.933785 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #69 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 13:18:48.934181 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #69 | Collecting samples for evaluation
2017-06-03 13:19:00.142181 EDT | -----------------------  -------------
2017-06-03 13:19:00.143074 EDT | Epoch                      69
2017-06-03 13:19:00.143364 EDT | Iteration                  69
2017-06-03 13:19:00.143621 EDT | AverageReturn            1000
2017-06-03 13:19:00.143884 EDT | StdReturn                   0
2017-06-03 13:19:00.144136 EDT | MaxReturn                1000
2017-06-03 13:19:00.144393 EDT | MinReturn                1000
2017-06-03 13:19:00.144659 EDT | AverageEsReturn            35.6897
2017-06-03 13:19:00.144910 EDT | StdEsReturn                25.2629
2017-06-03 13:19:00.145157 EDT | MaxEsReturn                90
2017-06-03 13:19:00.145417 EDT | MinEsReturn                 3
2017-06-03 13:19:00.145662 EDT | AverageDiscountedReturn    99.9957
2017-06-03 13:19:00.145926 EDT | AverageQLoss                8.9274e-05
2017-06-03 13:19:00.146171 EDT | AveragePolicySurr          -0.152794
2017-06-03 13:19:00.146423 EDT | AverageQ                    0.139063
2017-06-03 13:19:00.146666 EDT | AverageAbsQ                 0.139865
2017-06-03 13:19:00.146921 EDT | AverageY                    0.139068
2017-06-03 13:19:00.147164 EDT | AverageAbsY                 0.139467
2017-06-03 13:19:00.147407 EDT | AverageAbsQYDiff            0.00370844
2017-06-03 13:19:00.147651 EDT | AverageAction               0.608569
2017-06-03 13:19:00.147905 EDT | PolicyRegParamNorm         32.9172
2017-06-03 13:19:00.148148 EDT | QFunRegParamNorm           19.8373
2017-06-03 13:19:00.148399 EDT | -----------------------  -------------
2017-06-03 13:19:00.148811 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #70 | Training started
2017-06-03 13:19:18.020259 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #70 | Training finished
2017-06-03 13:19:18.021169 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #70 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 13:19:18.021544 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #70 | Collecting samples for evaluation
2017-06-03 13:19:27.616755 EDT | -----------------------  --------------
2017-06-03 13:19:27.617599 EDT | Epoch                      70
2017-06-03 13:19:27.617881 EDT | Iteration                  70
2017-06-03 13:19:27.618152 EDT | AverageReturn            1000
2017-06-03 13:19:27.618395 EDT | StdReturn                   0
2017-06-03 13:19:27.618634 EDT | MaxReturn                1000
2017-06-03 13:19:27.618872 EDT | MinReturn                1000
2017-06-03 13:19:27.619114 EDT | AverageEsReturn            23.3256
2017-06-03 13:19:27.619390 EDT | StdEsReturn                22.2791
2017-06-03 13:19:27.619627 EDT | MaxEsReturn                93
2017-06-03 13:19:27.619863 EDT | MinEsReturn                 3
2017-06-03 13:19:27.620098 EDT | AverageDiscountedReturn    99.9957
2017-06-03 13:19:27.620333 EDT | AverageQLoss                9.88769e-05
2017-06-03 13:19:27.620577 EDT | AveragePolicySurr          -0.153441
2017-06-03 13:19:27.620811 EDT | AverageQ                    0.140288
2017-06-03 13:19:27.621053 EDT | AverageAbsQ                 0.141164
2017-06-03 13:19:27.621286 EDT | AverageY                    0.140288
2017-06-03 13:19:27.621540 EDT | AverageAbsY                 0.140726
2017-06-03 13:19:27.621790 EDT | AverageAbsQYDiff            0.00390444
2017-06-03 13:19:27.622026 EDT | AverageAction               0.0541049
2017-06-03 13:19:27.622260 EDT | PolicyRegParamNorm         33.156
2017-06-03 13:19:27.622494 EDT | QFunRegParamNorm           19.916
2017-06-03 13:19:27.622736 EDT | -----------------------  --------------
2017-06-03 13:19:27.623109 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #71 | Training started
2017-06-03 13:19:46.378441 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #71 | Training finished
2017-06-03 13:19:46.379411 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #71 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 13:19:46.379683 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #71 | Collecting samples for evaluation
2017-06-03 13:19:55.669552 EDT | -----------------------  --------------
2017-06-03 13:19:55.670419 EDT | Epoch                      71
2017-06-03 13:19:55.670701 EDT | Iteration                  71
2017-06-03 13:19:55.670951 EDT | AverageReturn            1000
2017-06-03 13:19:55.671193 EDT | StdReturn                   0
2017-06-03 13:19:55.671485 EDT | MaxReturn                1000
2017-06-03 13:19:55.671735 EDT | MinReturn                1000
2017-06-03 13:19:55.671985 EDT | AverageEsReturn            26.1579
2017-06-03 13:19:55.672227 EDT | StdEsReturn                22.114
2017-06-03 13:19:55.672465 EDT | MaxEsReturn               100
2017-06-03 13:19:55.672702 EDT | MinEsReturn                 3
2017-06-03 13:19:55.672937 EDT | AverageDiscountedReturn    99.9957
2017-06-03 13:19:55.673173 EDT | AverageQLoss                0.000106417
2017-06-03 13:19:55.673414 EDT | AveragePolicySurr          -0.15468
2017-06-03 13:19:55.673649 EDT | AverageQ                    0.141462
2017-06-03 13:19:55.673931 EDT | AverageAbsQ                 0.142214
2017-06-03 13:19:55.674170 EDT | AverageY                    0.141463
2017-06-03 13:19:55.674407 EDT | AverageAbsY                 0.141846
2017-06-03 13:19:55.674649 EDT | AverageAbsQYDiff            0.004035
2017-06-03 13:19:55.674910 EDT | AverageAction               0.387096
2017-06-03 13:19:55.675148 EDT | PolicyRegParamNorm         33.4655
2017-06-03 13:19:55.675394 EDT | QFunRegParamNorm           19.9778
2017-06-03 13:19:55.675631 EDT | -----------------------  --------------
2017-06-03 13:19:55.676039 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #72 | Training started
2017-06-03 13:20:14.142694 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #72 | Training finished
2017-06-03 13:20:14.143670 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #72 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 13:20:14.144144 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #72 | Collecting samples for evaluation
2017-06-03 13:20:24.097024 EDT | -----------------------  -------------
2017-06-03 13:20:24.097886 EDT | Epoch                      72
2017-06-03 13:20:24.098155 EDT | Iteration                  72
2017-06-03 13:20:24.098397 EDT | AverageReturn            1000
2017-06-03 13:20:24.098645 EDT | StdReturn                   0
2017-06-03 13:20:24.098888 EDT | MaxReturn                1000
2017-06-03 13:20:24.099119 EDT | MinReturn                1000
2017-06-03 13:20:24.099351 EDT | AverageEsReturn            29.1818
2017-06-03 13:20:24.099582 EDT | StdEsReturn                38.6244
2017-06-03 13:20:24.099816 EDT | MaxEsReturn               211
2017-06-03 13:20:24.100056 EDT | MinEsReturn                 3
2017-06-03 13:20:24.100289 EDT | AverageDiscountedReturn    99.9957
2017-06-03 13:20:24.100518 EDT | AverageQLoss                0.00010008
2017-06-03 13:20:24.100747 EDT | AveragePolicySurr          -0.154791
2017-06-03 13:20:24.100975 EDT | AverageQ                    0.141565
2017-06-03 13:20:24.101204 EDT | AverageAbsQ                 0.142434
2017-06-03 13:20:24.101432 EDT | AverageY                    0.141568
2017-06-03 13:20:24.101665 EDT | AverageAbsY                 0.142057
2017-06-03 13:20:24.101931 EDT | AverageAbsQYDiff            0.00395673
2017-06-03 13:20:24.102179 EDT | AverageAction               0.619962
2017-06-03 13:20:24.102425 EDT | PolicyRegParamNorm         33.9024
2017-06-03 13:20:24.102670 EDT | QFunRegParamNorm           20.0709
2017-06-03 13:20:24.102914 EDT | -----------------------  -------------
2017-06-03 13:20:24.103370 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #73 | Training started
2017-06-03 13:20:42.930031 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #73 | Training finished
2017-06-03 13:20:42.931008 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #73 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 13:20:42.931469 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #73 | Collecting samples for evaluation
2017-06-03 13:20:54.247502 EDT | -----------------------  -------------
2017-06-03 13:20:54.248542 EDT | Epoch                      73
2017-06-03 13:20:54.248815 EDT | Iteration                  73
2017-06-03 13:20:54.249060 EDT | AverageReturn            1000
2017-06-03 13:20:54.249305 EDT | StdReturn                   0
2017-06-03 13:20:54.249545 EDT | MaxReturn                1000
2017-06-03 13:20:54.249795 EDT | MinReturn                1000
2017-06-03 13:20:54.250059 EDT | AverageEsReturn            27.8649
2017-06-03 13:20:54.250301 EDT | StdEsReturn                28.7742
2017-06-03 13:20:54.250555 EDT | MaxEsReturn               107
2017-06-03 13:20:54.250801 EDT | MinEsReturn                 3
2017-06-03 13:20:54.251043 EDT | AverageDiscountedReturn    99.9957
2017-06-03 13:20:54.251278 EDT | AverageQLoss                9.9957e-05
2017-06-03 13:20:54.251512 EDT | AveragePolicySurr          -0.15494
2017-06-03 13:20:54.251759 EDT | AverageQ                    0.142042
2017-06-03 13:20:54.251994 EDT | AverageAbsQ                 0.143094
2017-06-03 13:20:54.252227 EDT | AverageY                    0.142041
2017-06-03 13:20:54.252475 EDT | AverageAbsY                 0.142668
2017-06-03 13:20:54.252712 EDT | AverageAbsQYDiff            0.00396439
2017-06-03 13:20:54.252955 EDT | AverageAction               0.429566
2017-06-03 13:20:54.253187 EDT | PolicyRegParamNorm         34.3929
2017-06-03 13:20:54.253434 EDT | QFunRegParamNorm           20.1371
2017-06-03 13:20:54.253669 EDT | -----------------------  -------------
2017-06-03 13:20:54.254049 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #74 | Training started
2017-06-03 13:21:13.390832 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #74 | Training finished
2017-06-03 13:21:13.391888 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #74 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 13:21:13.392475 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #74 | Collecting samples for evaluation
2017-06-03 13:21:23.955489 EDT | -----------------------  --------------
2017-06-03 13:21:23.956341 EDT | Epoch                      74
2017-06-03 13:21:23.956601 EDT | Iteration                  74
2017-06-03 13:21:23.956839 EDT | AverageReturn            1000
2017-06-03 13:21:23.957103 EDT | StdReturn                   0
2017-06-03 13:21:23.957335 EDT | MaxReturn                1000
2017-06-03 13:21:23.957566 EDT | MinReturn                1000
2017-06-03 13:21:23.957841 EDT | AverageEsReturn            21.8095
2017-06-03 13:21:23.958098 EDT | StdEsReturn                19.4254
2017-06-03 13:21:23.958343 EDT | MaxEsReturn                95
2017-06-03 13:21:23.958593 EDT | MinEsReturn                 3
2017-06-03 13:21:23.958837 EDT | AverageDiscountedReturn    99.9957
2017-06-03 13:21:23.959080 EDT | AverageQLoss                0.000122561
2017-06-03 13:21:23.959324 EDT | AveragePolicySurr          -0.155591
2017-06-03 13:21:23.959568 EDT | AverageQ                    0.142565
2017-06-03 13:21:23.959813 EDT | AverageAbsQ                 0.14366
2017-06-03 13:21:23.960057 EDT | AverageY                    0.142561
2017-06-03 13:21:23.960295 EDT | AverageAbsY                 0.143229
2017-06-03 13:21:23.960534 EDT | AverageAbsQYDiff            0.00427376
2017-06-03 13:21:23.960774 EDT | AverageAction               0.554443
2017-06-03 13:21:23.961013 EDT | PolicyRegParamNorm         34.7308
2017-06-03 13:21:23.961251 EDT | QFunRegParamNorm           20.2337
2017-06-03 13:21:23.961490 EDT | -----------------------  --------------
2017-06-03 13:21:23.961892 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #75 | Training started
2017-06-03 13:21:43.186153 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #75 | Training finished
2017-06-03 13:21:43.187126 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #75 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 13:21:43.187536 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #75 | Collecting samples for evaluation
2017-06-03 13:21:52.321878 EDT | -----------------------  --------------
2017-06-03 13:21:52.322759 EDT | Epoch                      75
2017-06-03 13:21:52.323150 EDT | Iteration                  75
2017-06-03 13:21:52.323481 EDT | AverageReturn            1000
2017-06-03 13:21:52.323802 EDT | StdReturn                   0
2017-06-03 13:21:52.324130 EDT | MaxReturn                1000
2017-06-03 13:21:52.324461 EDT | MinReturn                1000
2017-06-03 13:21:52.324773 EDT | AverageEsReturn            29.8611
2017-06-03 13:21:52.325088 EDT | StdEsReturn                30.1802
2017-06-03 13:21:52.325422 EDT | MaxEsReturn               113
2017-06-03 13:21:52.325742 EDT | MinEsReturn                 3
2017-06-03 13:21:52.326055 EDT | AverageDiscountedReturn    99.9957
2017-06-03 13:21:52.326375 EDT | AverageQLoss                9.83811e-05
2017-06-03 13:21:52.326690 EDT | AveragePolicySurr          -0.156718
2017-06-03 13:21:52.327003 EDT | AverageQ                    0.143496
2017-06-03 13:21:52.327329 EDT | AverageAbsQ                 0.144612
2017-06-03 13:21:52.327641 EDT | AverageY                    0.143504
2017-06-03 13:21:52.327951 EDT | AverageAbsY                 0.144227
2017-06-03 13:21:52.328264 EDT | AverageAbsQYDiff            0.00384727
2017-06-03 13:21:52.328585 EDT | AverageAction               0.455029
2017-06-03 13:21:52.328896 EDT | PolicyRegParamNorm         34.9922
2017-06-03 13:21:52.329271 EDT | QFunRegParamNorm           20.2678
2017-06-03 13:21:52.329819 EDT | -----------------------  --------------
2017-06-03 13:21:52.330553 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #76 | Training started
2017-06-03 13:22:11.326806 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #76 | Training finished
2017-06-03 13:22:11.327735 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #76 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 13:22:11.328040 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #76 | Collecting samples for evaluation
2017-06-03 13:22:23.146352 EDT | -----------------------  --------------
2017-06-03 13:22:23.147197 EDT | Epoch                      76
2017-06-03 13:22:23.147486 EDT | Iteration                  76
2017-06-03 13:22:23.147753 EDT | AverageReturn            1000
2017-06-03 13:22:23.147994 EDT | StdReturn                   0
2017-06-03 13:22:23.148232 EDT | MaxReturn                1000
2017-06-03 13:22:23.148468 EDT | MinReturn                1000
2017-06-03 13:22:23.148710 EDT | AverageEsReturn            22.7333
2017-06-03 13:22:23.148955 EDT | StdEsReturn                18.401
2017-06-03 13:22:23.149189 EDT | MaxEsReturn                70
2017-06-03 13:22:23.149424 EDT | MinEsReturn                 3
2017-06-03 13:22:23.149657 EDT | AverageDiscountedReturn    99.9957
2017-06-03 13:22:23.149904 EDT | AverageQLoss                0.000101988
2017-06-03 13:22:23.150139 EDT | AveragePolicySurr          -0.157084
2017-06-03 13:22:23.150372 EDT | AverageQ                    0.144133
2017-06-03 13:22:23.150607 EDT | AverageAbsQ                 0.145436
2017-06-03 13:22:23.150840 EDT | AverageY                    0.144138
2017-06-03 13:22:23.151073 EDT | AverageAbsY                 0.145023
2017-06-03 13:22:23.151305 EDT | AverageAbsQYDiff            0.00401451
2017-06-03 13:22:23.151539 EDT | AverageAction               0.582824
2017-06-03 13:22:23.151771 EDT | PolicyRegParamNorm         35.3251
2017-06-03 13:22:23.152003 EDT | QFunRegParamNorm           20.3699
2017-06-03 13:22:23.152234 EDT | -----------------------  --------------
2017-06-03 13:22:23.152629 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #77 | Training started
2017-06-03 13:22:41.862590 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #77 | Training finished
2017-06-03 13:22:41.863485 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #77 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 13:22:41.863901 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #77 | Collecting samples for evaluation
2017-06-03 13:22:52.219044 EDT | -----------------------  --------------
2017-06-03 13:22:52.219943 EDT | Epoch                      77
2017-06-03 13:22:52.220220 EDT | Iteration                  77
2017-06-03 13:22:52.220484 EDT | AverageReturn            1000
2017-06-03 13:22:52.220737 EDT | StdReturn                   0
2017-06-03 13:22:52.220982 EDT | MaxReturn                1000
2017-06-03 13:22:52.221242 EDT | MinReturn                1000
2017-06-03 13:22:52.221494 EDT | AverageEsReturn            30.0606
2017-06-03 13:22:52.221750 EDT | StdEsReturn                25.4165
2017-06-03 13:22:52.221996 EDT | MaxEsReturn               101
2017-06-03 13:22:52.222236 EDT | MinEsReturn                 3
2017-06-03 13:22:52.222487 EDT | AverageDiscountedReturn    99.9957
2017-06-03 13:22:52.222726 EDT | AverageQLoss                0.000110345
2017-06-03 13:22:52.222966 EDT | AveragePolicySurr          -0.157879
2017-06-03 13:22:52.223207 EDT | AverageQ                    0.145446
2017-06-03 13:22:52.223451 EDT | AverageAbsQ                 0.146661
2017-06-03 13:22:52.223690 EDT | AverageY                    0.145448
2017-06-03 13:22:52.223929 EDT | AverageAbsY                 0.146228
2017-06-03 13:22:52.224182 EDT | AverageAbsQYDiff            0.00412214
2017-06-03 13:22:52.224429 EDT | AverageAction               0.556739
2017-06-03 13:22:52.224668 EDT | PolicyRegParamNorm         35.5165
2017-06-03 13:22:52.224906 EDT | QFunRegParamNorm           20.4525
2017-06-03 13:22:52.225145 EDT | -----------------------  --------------
2017-06-03 13:22:52.225530 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #78 | Training started
2017-06-03 13:23:11.074459 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #78 | Training finished
2017-06-03 13:23:11.075385 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #78 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 13:23:11.075659 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #78 | Collecting samples for evaluation
2017-06-03 13:23:20.975424 EDT | -----------------------  --------------
2017-06-03 13:23:20.976311 EDT | Epoch                      78
2017-06-03 13:23:20.976620 EDT | Iteration                  78
2017-06-03 13:23:20.976887 EDT | AverageReturn            1000
2017-06-03 13:23:20.977141 EDT | StdReturn                   0
2017-06-03 13:23:20.977389 EDT | MaxReturn                1000
2017-06-03 13:23:20.977634 EDT | MinReturn                1000
2017-06-03 13:23:20.977908 EDT | AverageEsReturn            37.1154
2017-06-03 13:23:20.978155 EDT | StdEsReturn                40.1941
2017-06-03 13:23:20.978398 EDT | MaxEsReturn               182
2017-06-03 13:23:20.978651 EDT | MinEsReturn                 3
2017-06-03 13:23:20.978893 EDT | AverageDiscountedReturn    99.9957
2017-06-03 13:23:20.979135 EDT | AverageQLoss                0.000113143
2017-06-03 13:23:20.979378 EDT | AveragePolicySurr          -0.158141
2017-06-03 13:23:20.979620 EDT | AverageQ                    0.145416
2017-06-03 13:23:20.979862 EDT | AverageAbsQ                 0.146666
2017-06-03 13:23:20.980104 EDT | AverageY                    0.145417
2017-06-03 13:23:20.980346 EDT | AverageAbsY                 0.146208
2017-06-03 13:23:20.980587 EDT | AverageAbsQYDiff            0.00420315
2017-06-03 13:23:20.980828 EDT | AverageAction               0.54803
2017-06-03 13:23:20.981070 EDT | PolicyRegParamNorm         35.7796
2017-06-03 13:23:20.981333 EDT | QFunRegParamNorm           20.5209
2017-06-03 13:23:20.981575 EDT | -----------------------  --------------
2017-06-03 13:23:20.981994 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #79 | Training started
2017-06-03 13:23:40.647151 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #79 | Training finished
2017-06-03 13:23:40.648249 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #79 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 13:23:40.648670 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #79 | Collecting samples for evaluation
2017-06-03 13:23:50.707963 EDT | -----------------------  --------------
2017-06-03 13:23:50.708802 EDT | Epoch                      79
2017-06-03 13:23:50.709089 EDT | Iteration                  79
2017-06-03 13:23:50.709334 EDT | AverageReturn            1000
2017-06-03 13:23:50.709574 EDT | StdReturn                   0
2017-06-03 13:23:50.709832 EDT | MaxReturn                1000
2017-06-03 13:23:50.710082 EDT | MinReturn                1000
2017-06-03 13:23:50.710336 EDT | AverageEsReturn            25.8
2017-06-03 13:23:50.710573 EDT | StdEsReturn                19.8207
2017-06-03 13:23:50.710822 EDT | MaxEsReturn                80
2017-06-03 13:23:50.711077 EDT | MinEsReturn                 3
2017-06-03 13:23:50.711310 EDT | AverageDiscountedReturn    99.9957
2017-06-03 13:23:50.711552 EDT | AverageQLoss                0.000109018
2017-06-03 13:23:50.711786 EDT | AveragePolicySurr          -0.158035
2017-06-03 13:23:50.712018 EDT | AverageQ                    0.145612
2017-06-03 13:23:50.712249 EDT | AverageAbsQ                 0.146961
2017-06-03 13:23:50.712482 EDT | AverageY                    0.1456
2017-06-03 13:23:50.712729 EDT | AverageAbsY                 0.146461
2017-06-03 13:23:50.712982 EDT | AverageAbsQYDiff            0.00414357
2017-06-03 13:23:50.713212 EDT | AverageAction               0.332629
2017-06-03 13:23:50.713441 EDT | PolicyRegParamNorm         35.9655
2017-06-03 13:23:50.713669 EDT | QFunRegParamNorm           20.6114
2017-06-03 13:23:50.713913 EDT | -----------------------  --------------
2017-06-03 13:23:50.714335 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #80 | Training started
2017-06-03 13:24:08.695448 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #80 | Training finished
2017-06-03 13:24:08.696330 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #80 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 13:24:08.696610 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #80 | Collecting samples for evaluation
2017-06-03 13:24:18.482668 EDT | -----------------------  --------------
2017-06-03 13:24:18.483076 EDT | Epoch                      80
2017-06-03 13:24:18.483325 EDT | Iteration                  80
2017-06-03 13:24:18.483562 EDT | AverageReturn            1000
2017-06-03 13:24:18.483794 EDT | StdReturn                   0
2017-06-03 13:24:18.484025 EDT | MaxReturn                1000
2017-06-03 13:24:18.484255 EDT | MinReturn                1000
2017-06-03 13:24:18.484484 EDT | AverageEsReturn            41.75
2017-06-03 13:24:18.484713 EDT | StdEsReturn                30.2466
2017-06-03 13:24:18.484942 EDT | MaxEsReturn               127
2017-06-03 13:24:18.485169 EDT | MinEsReturn                 5
2017-06-03 13:24:18.485397 EDT | AverageDiscountedReturn    99.9957
2017-06-03 13:24:18.485625 EDT | AverageQLoss                0.000105925
2017-06-03 13:24:18.485867 EDT | AveragePolicySurr          -0.158971
2017-06-03 13:24:18.486096 EDT | AverageQ                    0.145939
2017-06-03 13:24:18.486324 EDT | AverageAbsQ                 0.14707
2017-06-03 13:24:18.486552 EDT | AverageY                    0.145947
2017-06-03 13:24:18.486782 EDT | AverageAbsY                 0.14674
2017-06-03 13:24:18.487010 EDT | AverageAbsQYDiff            0.00386941
2017-06-03 13:24:18.487237 EDT | AverageAction               0.600911
2017-06-03 13:24:18.487463 EDT | PolicyRegParamNorm         36.1847
2017-06-03 13:24:18.487690 EDT | QFunRegParamNorm           20.706
2017-06-03 13:24:18.487918 EDT | -----------------------  --------------
2017-06-03 13:24:18.488254 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #81 | Training started
2017-06-03 13:24:37.515011 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #81 | Training finished
2017-06-03 13:24:37.515927 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #81 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 13:24:37.516209 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #81 | Collecting samples for evaluation
2017-06-03 13:24:47.808800 EDT | -----------------------  --------------
2017-06-03 13:24:47.809212 EDT | Epoch                      81
2017-06-03 13:24:47.809463 EDT | Iteration                  81
2017-06-03 13:24:47.809758 EDT | AverageReturn            1000
2017-06-03 13:24:47.810136 EDT | StdReturn                   0
2017-06-03 13:24:47.810529 EDT | MaxReturn                1000
2017-06-03 13:24:47.810901 EDT | MinReturn                1000
2017-06-03 13:24:47.811265 EDT | AverageEsReturn            34.5172
2017-06-03 13:24:47.811673 EDT | StdEsReturn                26.8593
2017-06-03 13:24:47.812127 EDT | MaxEsReturn                91
2017-06-03 13:24:47.812520 EDT | MinEsReturn                 4
2017-06-03 13:24:47.812866 EDT | AverageDiscountedReturn    99.9957
2017-06-03 13:24:47.813255 EDT | AverageQLoss                0.000106507
2017-06-03 13:24:47.813543 EDT | AveragePolicySurr          -0.159417
2017-06-03 13:24:47.813822 EDT | AverageQ                    0.146585
2017-06-03 13:24:47.814062 EDT | AverageAbsQ                 0.147558
2017-06-03 13:24:47.814324 EDT | AverageY                    0.146578
2017-06-03 13:24:47.814585 EDT | AverageAbsY                 0.147221
2017-06-03 13:24:47.814843 EDT | AverageAbsQYDiff            0.00397241
2017-06-03 13:24:47.815075 EDT | AverageAction               0.543871
2017-06-03 13:24:47.815306 EDT | PolicyRegParamNorm         36.4452
2017-06-03 13:24:47.815535 EDT | QFunRegParamNorm           20.7775
2017-06-03 13:24:47.815807 EDT | -----------------------  --------------
2017-06-03 13:24:47.816264 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #82 | Training started
2017-06-03 13:25:06.655010 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #82 | Training finished
2017-06-03 13:25:06.655957 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #82 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 13:25:06.656245 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #82 | Collecting samples for evaluation
2017-06-03 13:25:16.938331 EDT | -----------------------  --------------
2017-06-03 13:25:16.938700 EDT | Epoch                      82
2017-06-03 13:25:16.938932 EDT | Iteration                  82
2017-06-03 13:25:16.939153 EDT | AverageReturn            1000
2017-06-03 13:25:16.939374 EDT | StdReturn                   0
2017-06-03 13:25:16.939606 EDT | MaxReturn                1000
2017-06-03 13:25:16.939822 EDT | MinReturn                1000
2017-06-03 13:25:16.940036 EDT | AverageEsReturn            33.1
2017-06-03 13:25:16.940282 EDT | StdEsReturn                29.2305
2017-06-03 13:25:16.940516 EDT | MaxEsReturn               112
2017-06-03 13:25:16.940746 EDT | MinEsReturn                 4
2017-06-03 13:25:16.940975 EDT | AverageDiscountedReturn    99.9957
2017-06-03 13:25:16.941204 EDT | AverageQLoss                0.000100473
2017-06-03 13:25:16.941447 EDT | AveragePolicySurr          -0.160245
2017-06-03 13:25:16.941675 EDT | AverageQ                    0.148123
2017-06-03 13:25:16.941918 EDT | AverageAbsQ                 0.149008
2017-06-03 13:25:16.942147 EDT | AverageY                    0.14813
2017-06-03 13:25:16.942446 EDT | AverageAbsY                 0.148576
2017-06-03 13:25:16.942668 EDT | AverageAbsQYDiff            0.00384928
2017-06-03 13:25:16.942886 EDT | AverageAction               0.595914
2017-06-03 13:25:16.943101 EDT | PolicyRegParamNorm         36.6762
2017-06-03 13:25:16.943315 EDT | QFunRegParamNorm           20.8749
2017-06-03 13:25:16.943531 EDT | -----------------------  --------------
2017-06-03 13:25:16.943880 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #83 | Training started
2017-06-03 13:25:36.648573 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #83 | Training finished
2017-06-03 13:25:36.649572 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #83 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 13:25:36.649940 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #83 | Collecting samples for evaluation
2017-06-03 13:25:46.814549 EDT | -----------------------  --------------
2017-06-03 13:25:46.815421 EDT | Epoch                      83
2017-06-03 13:25:46.815710 EDT | Iteration                  83
2017-06-03 13:25:46.816005 EDT | AverageReturn            1000
2017-06-03 13:25:46.816383 EDT | StdReturn                   0
2017-06-03 13:25:46.816721 EDT | MaxReturn                1000
2017-06-03 13:25:46.817077 EDT | MinReturn                1000
2017-06-03 13:25:46.817402 EDT | AverageEsReturn            26.4737
2017-06-03 13:25:46.817732 EDT | StdEsReturn                25.0628
2017-06-03 13:25:46.818053 EDT | MaxEsReturn               100
2017-06-03 13:25:46.818386 EDT | MinEsReturn                 4
2017-06-03 13:25:46.818741 EDT | AverageDiscountedReturn    99.9957
2017-06-03 13:25:46.819092 EDT | AverageQLoss                0.000107275
2017-06-03 13:25:46.819413 EDT | AveragePolicySurr          -0.160947
2017-06-03 13:25:46.819761 EDT | AverageQ                    0.14858
2017-06-03 13:25:46.820111 EDT | AverageAbsQ                 0.149198
2017-06-03 13:25:46.820423 EDT | AverageY                    0.148586
2017-06-03 13:25:46.820732 EDT | AverageAbsY                 0.148854
2017-06-03 13:25:46.821054 EDT | AverageAbsQYDiff            0.00385506
2017-06-03 13:25:46.821406 EDT | AverageAction               0.213429
2017-06-03 13:25:46.821767 EDT | PolicyRegParamNorm         36.8966
2017-06-03 13:25:46.822109 EDT | QFunRegParamNorm           20.9416
2017-06-03 13:25:46.822468 EDT | -----------------------  --------------
2017-06-03 13:25:46.822953 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #84 | Training started
2017-06-03 13:26:08.527271 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #84 | Training finished
2017-06-03 13:26:08.527628 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #84 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 13:26:08.527887 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #84 | Collecting samples for evaluation
2017-06-03 13:26:18.328363 EDT | -----------------------  --------------
2017-06-03 13:26:18.329257 EDT | Epoch                      84
2017-06-03 13:26:18.329612 EDT | Iteration                  84
2017-06-03 13:26:18.329887 EDT | AverageReturn            1000
2017-06-03 13:26:18.330140 EDT | StdReturn                   0
2017-06-03 13:26:18.330464 EDT | MaxReturn                1000
2017-06-03 13:26:18.330722 EDT | MinReturn                1000
2017-06-03 13:26:18.331038 EDT | AverageEsReturn            24.5385
2017-06-03 13:26:18.331295 EDT | StdEsReturn                23.4114
2017-06-03 13:26:18.331630 EDT | MaxEsReturn               134
2017-06-03 13:26:18.331894 EDT | MinEsReturn                 3
2017-06-03 13:26:18.332209 EDT | AverageDiscountedReturn    99.9957
2017-06-03 13:26:18.332465 EDT | AverageQLoss                0.000105626
2017-06-03 13:26:18.332806 EDT | AveragePolicySurr          -0.161011
2017-06-03 13:26:18.333061 EDT | AverageQ                    0.148554
2017-06-03 13:26:18.333371 EDT | AverageAbsQ                 0.149225
2017-06-03 13:26:18.333638 EDT | AverageY                    0.14855
2017-06-03 13:26:18.334000 EDT | AverageAbsY                 0.14873
2017-06-03 13:26:18.334256 EDT | AverageAbsQYDiff            0.00395486
2017-06-03 13:26:18.334562 EDT | AverageAction               0.478059
2017-06-03 13:26:18.334828 EDT | PolicyRegParamNorm         37.0951
2017-06-03 13:26:18.335149 EDT | QFunRegParamNorm           20.9763
2017-06-03 13:26:18.335405 EDT | -----------------------  --------------
2017-06-03 13:26:18.335871 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #85 | Training started
2017-06-03 13:26:38.381156 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #85 | Training finished
2017-06-03 13:26:38.381561 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #85 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 13:26:38.381854 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #85 | Collecting samples for evaluation
2017-06-03 13:26:48.998418 EDT | -----------------------  --------------
2017-06-03 13:26:49.000966 EDT | Epoch                      85
2017-06-03 13:26:49.001257 EDT | Iteration                  85
2017-06-03 13:26:49.001507 EDT | AverageReturn            1000
2017-06-03 13:26:49.001769 EDT | StdReturn                   0
2017-06-03 13:26:49.002025 EDT | MaxReturn                1000
2017-06-03 13:26:49.002270 EDT | MinReturn                1000
2017-06-03 13:26:49.002508 EDT | AverageEsReturn            28.2
2017-06-03 13:26:49.002746 EDT | StdEsReturn                38.0982
2017-06-03 13:26:49.002988 EDT | MaxEsReturn               211
2017-06-03 13:26:49.003225 EDT | MinEsReturn                 3
2017-06-03 13:26:49.003461 EDT | AverageDiscountedReturn    99.9957
2017-06-03 13:26:49.003697 EDT | AverageQLoss                0.000100668
2017-06-03 13:26:49.003933 EDT | AveragePolicySurr          -0.161659
2017-06-03 13:26:49.004170 EDT | AverageQ                    0.149647
2017-06-03 13:26:49.004407 EDT | AverageAbsQ                 0.150148
2017-06-03 13:26:49.004676 EDT | AverageY                    0.149656
2017-06-03 13:26:49.004914 EDT | AverageAbsY                 0.149795
2017-06-03 13:26:49.005150 EDT | AverageAbsQYDiff            0.0036451
2017-06-03 13:26:49.005387 EDT | AverageAction               0.540418
2017-06-03 13:26:49.005621 EDT | PolicyRegParamNorm         37.318
2017-06-03 13:26:49.005885 EDT | QFunRegParamNorm           21.0657
2017-06-03 13:26:49.006122 EDT | -----------------------  --------------
2017-06-03 13:26:49.006523 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #86 | Training started
2017-06-03 13:27:08.519373 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #86 | Training finished
2017-06-03 13:27:08.519735 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #86 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 13:27:08.520009 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #86 | Collecting samples for evaluation
2017-06-03 13:27:18.239291 EDT | -----------------------  -------------
2017-06-03 13:27:18.240136 EDT | Epoch                      86
2017-06-03 13:27:18.240418 EDT | Iteration                  86
2017-06-03 13:27:18.240669 EDT | AverageReturn            1000
2017-06-03 13:27:18.240913 EDT | StdReturn                   0
2017-06-03 13:27:18.241152 EDT | MaxReturn                1000
2017-06-03 13:27:18.241391 EDT | MinReturn                1000
2017-06-03 13:27:18.241630 EDT | AverageEsReturn            26.5263
2017-06-03 13:27:18.241889 EDT | StdEsReturn                25.2813
2017-06-03 13:27:18.242132 EDT | MaxEsReturn               113
2017-06-03 13:27:18.242371 EDT | MinEsReturn                 3
2017-06-03 13:27:18.242630 EDT | AverageDiscountedReturn    99.9957
2017-06-03 13:27:18.242880 EDT | AverageQLoss                0.00011005
2017-06-03 13:27:18.243248 EDT | AveragePolicySurr          -0.162123
2017-06-03 13:27:18.243571 EDT | AverageQ                    0.150383
2017-06-03 13:27:18.243897 EDT | AverageAbsQ                 0.150907
2017-06-03 13:27:18.244212 EDT | AverageY                    0.150378
2017-06-03 13:27:18.244524 EDT | AverageAbsY                 0.150509
2017-06-03 13:27:18.244846 EDT | AverageAbsQYDiff            0.00383863
2017-06-03 13:27:18.245155 EDT | AverageAction               0.545249
2017-06-03 13:27:18.245463 EDT | PolicyRegParamNorm         37.5391
2017-06-03 13:27:18.245786 EDT | QFunRegParamNorm           21.1462
2017-06-03 13:27:18.246127 EDT | -----------------------  -------------
2017-06-03 13:27:18.246573 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #87 | Training started
2017-06-03 13:27:36.827890 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #87 | Training finished
2017-06-03 13:27:36.828812 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #87 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 13:27:36.829094 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #87 | Collecting samples for evaluation
2017-06-03 13:27:46.326261 EDT | -----------------------  --------------
2017-06-03 13:27:46.327241 EDT | Epoch                      87
2017-06-03 13:27:46.327621 EDT | Iteration                  87
2017-06-03 13:27:46.327879 EDT | AverageReturn            1000
2017-06-03 13:27:46.328110 EDT | StdReturn                   0
2017-06-03 13:27:46.328336 EDT | MaxReturn                1000
2017-06-03 13:27:46.328576 EDT | MinReturn                1000
2017-06-03 13:27:46.328813 EDT | AverageEsReturn            37.2857
2017-06-03 13:27:46.329037 EDT | StdEsReturn                27.652
2017-06-03 13:27:46.329260 EDT | MaxEsReturn               129
2017-06-03 13:27:46.329483 EDT | MinEsReturn                10
2017-06-03 13:27:46.329737 EDT | AverageDiscountedReturn    99.9957
2017-06-03 13:27:46.329979 EDT | AverageQLoss                0.000105382
2017-06-03 13:27:46.330223 EDT | AveragePolicySurr          -0.162397
2017-06-03 13:27:46.330470 EDT | AverageQ                    0.150634
2017-06-03 13:27:46.330710 EDT | AverageAbsQ                 0.151184
2017-06-03 13:27:46.330956 EDT | AverageY                    0.150647
2017-06-03 13:27:46.331196 EDT | AverageAbsY                 0.150775
2017-06-03 13:27:46.331485 EDT | AverageAbsQYDiff            0.00375774
2017-06-03 13:27:46.331725 EDT | AverageAction               0.511646
2017-06-03 13:27:46.331964 EDT | PolicyRegParamNorm         37.6688
2017-06-03 13:27:46.332217 EDT | QFunRegParamNorm           21.1929
2017-06-03 13:27:46.332458 EDT | -----------------------  --------------
2017-06-03 13:27:46.332848 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #88 | Training started
2017-06-03 13:28:04.939541 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #88 | Training finished
2017-06-03 13:28:04.940462 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #88 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 13:28:04.940736 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #88 | Collecting samples for evaluation
2017-06-03 13:28:14.000403 EDT | -----------------------  --------------
2017-06-03 13:28:14.003764 EDT | Epoch                      88
2017-06-03 13:28:14.004048 EDT | Iteration                  88
2017-06-03 13:28:14.004298 EDT | AverageReturn            1000
2017-06-03 13:28:14.004537 EDT | StdReturn                   0
2017-06-03 13:28:14.004773 EDT | MaxReturn                1000
2017-06-03 13:28:14.005008 EDT | MinReturn                1000
2017-06-03 13:28:14.005243 EDT | AverageEsReturn            32.6129
2017-06-03 13:28:14.005478 EDT | StdEsReturn                35.3988
2017-06-03 13:28:14.005721 EDT | MaxEsReturn               156
2017-06-03 13:28:14.005967 EDT | MinEsReturn                 4
2017-06-03 13:28:14.006204 EDT | AverageDiscountedReturn    99.9957
2017-06-03 13:28:14.006437 EDT | AverageQLoss                9.84671e-05
2017-06-03 13:28:14.006670 EDT | AveragePolicySurr          -0.162597
2017-06-03 13:28:14.006907 EDT | AverageQ                    0.150855
2017-06-03 13:28:14.007139 EDT | AverageAbsQ                 0.151412
2017-06-03 13:28:14.007372 EDT | AverageY                    0.150847
2017-06-03 13:28:14.007604 EDT | AverageAbsY                 0.150989
2017-06-03 13:28:14.007837 EDT | AverageAbsQYDiff            0.003629
2017-06-03 13:28:14.008068 EDT | AverageAction               0.568065
2017-06-03 13:28:14.008299 EDT | PolicyRegParamNorm         37.7798
2017-06-03 13:28:14.008530 EDT | QFunRegParamNorm           21.2542
2017-06-03 13:28:14.008761 EDT | -----------------------  --------------
2017-06-03 13:28:14.009159 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #89 | Training started
2017-06-03 13:28:35.382929 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #89 | Training finished
2017-06-03 13:28:35.383959 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #89 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 13:28:35.384282 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #89 | Collecting samples for evaluation
2017-06-03 13:28:45.358808 EDT | -----------------------  --------------
2017-06-03 13:28:45.359746 EDT | Epoch                      89
2017-06-03 13:28:45.360124 EDT | Iteration                  89
2017-06-03 13:28:45.360580 EDT | AverageReturn            1000
2017-06-03 13:28:45.361028 EDT | StdReturn                   0
2017-06-03 13:28:45.361444 EDT | MaxReturn                1000
2017-06-03 13:28:45.361772 EDT | MinReturn                1000
2017-06-03 13:28:45.362092 EDT | AverageEsReturn            31.0312
2017-06-03 13:28:45.362411 EDT | StdEsReturn                37.2563
2017-06-03 13:28:45.362718 EDT | MaxEsReturn               163
2017-06-03 13:28:45.363025 EDT | MinEsReturn                 4
2017-06-03 13:28:45.363330 EDT | AverageDiscountedReturn    99.9957
2017-06-03 13:28:45.363635 EDT | AverageQLoss                0.000101776
2017-06-03 13:28:45.363941 EDT | AveragePolicySurr          -0.162725
2017-06-03 13:28:45.364307 EDT | AverageQ                    0.151139
2017-06-03 13:28:45.364619 EDT | AverageAbsQ                 0.151722
2017-06-03 13:28:45.364928 EDT | AverageY                    0.151141
2017-06-03 13:28:45.365236 EDT | AverageAbsY                 0.151267
2017-06-03 13:28:45.365559 EDT | AverageAbsQYDiff            0.00369896
2017-06-03 13:28:45.365891 EDT | AverageAction               0.611231
2017-06-03 13:28:45.366202 EDT | PolicyRegParamNorm         37.993
2017-06-03 13:28:45.366554 EDT | QFunRegParamNorm           21.2763
2017-06-03 13:28:45.366999 EDT | -----------------------  --------------
2017-06-03 13:28:45.367578 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #90 | Training started
2017-06-03 13:29:05.344941 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #90 | Training finished
2017-06-03 13:29:05.345791 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #90 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 13:29:05.346060 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #90 | Collecting samples for evaluation
2017-06-03 13:29:16.083813 EDT | -----------------------  --------------
2017-06-03 13:29:16.084863 EDT | Epoch                      90
2017-06-03 13:29:16.085328 EDT | Iteration                  90
2017-06-03 13:29:16.085784 EDT | AverageReturn            1000
2017-06-03 13:29:16.086120 EDT | StdReturn                   0
2017-06-03 13:29:16.086452 EDT | MaxReturn                1000
2017-06-03 13:29:16.086779 EDT | MinReturn                1000
2017-06-03 13:29:16.087093 EDT | AverageEsReturn            31
2017-06-03 13:29:16.087410 EDT | StdEsReturn                22.9347
2017-06-03 13:29:16.087732 EDT | MaxEsReturn                81
2017-06-03 13:29:16.088051 EDT | MinEsReturn                 4
2017-06-03 13:29:16.088365 EDT | AverageDiscountedReturn    99.9957
2017-06-03 13:29:16.088673 EDT | AverageQLoss                0.000106303
2017-06-03 13:29:16.088981 EDT | AveragePolicySurr          -0.163477
2017-06-03 13:29:16.089290 EDT | AverageQ                    0.151458
2017-06-03 13:29:16.089597 EDT | AverageAbsQ                 0.151993
2017-06-03 13:29:16.089916 EDT | AverageY                    0.151454
2017-06-03 13:29:16.090223 EDT | AverageAbsY                 0.151538
2017-06-03 13:29:16.090529 EDT | AverageAbsQYDiff            0.00380074
2017-06-03 13:29:16.090870 EDT | AverageAction               0.574137
2017-06-03 13:29:16.091179 EDT | PolicyRegParamNorm         38.1317
2017-06-03 13:29:16.091483 EDT | QFunRegParamNorm           21.3586
2017-06-03 13:29:16.091799 EDT | -----------------------  --------------
2017-06-03 13:29:16.092261 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #91 | Training started
2017-06-03 13:29:34.969556 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #91 | Training finished
2017-06-03 13:29:34.970443 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #91 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 13:29:34.970714 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #91 | Collecting samples for evaluation
2017-06-03 13:29:44.835832 EDT | -----------------------  --------------
2017-06-03 13:29:44.836691 EDT | Epoch                      91
2017-06-03 13:29:44.836984 EDT | Iteration                  91
2017-06-03 13:29:44.837250 EDT | AverageReturn            1000
2017-06-03 13:29:44.837499 EDT | StdReturn                   0
2017-06-03 13:29:44.837755 EDT | MaxReturn                1000
2017-06-03 13:29:44.838003 EDT | MinReturn                1000
2017-06-03 13:29:44.838246 EDT | AverageEsReturn            26.9189
2017-06-03 13:29:44.838491 EDT | StdEsReturn                24.9121
2017-06-03 13:29:44.838739 EDT | MaxEsReturn               109
2017-06-03 13:29:44.838981 EDT | MinEsReturn                 3
2017-06-03 13:29:44.839222 EDT | AverageDiscountedReturn    99.9957
2017-06-03 13:29:44.839464 EDT | AverageQLoss                0.000110616
2017-06-03 13:29:44.839705 EDT | AveragePolicySurr          -0.163361
2017-06-03 13:29:44.839955 EDT | AverageQ                    0.152021
2017-06-03 13:29:44.840200 EDT | AverageAbsQ                 0.1525
2017-06-03 13:29:44.840441 EDT | AverageY                    0.152018
2017-06-03 13:29:44.840682 EDT | AverageAbsY                 0.152099
2017-06-03 13:29:44.840923 EDT | AverageAbsQYDiff            0.00377558
2017-06-03 13:29:44.841171 EDT | AverageAction               0.258674
2017-06-03 13:29:44.841410 EDT | PolicyRegParamNorm         38.3357
2017-06-03 13:29:44.841649 EDT | QFunRegParamNorm           21.3966
2017-06-03 13:29:44.841940 EDT | -----------------------  --------------
2017-06-03 13:29:44.842313 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #92 | Training started
2017-06-03 13:30:03.977244 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #92 | Training finished
2017-06-03 13:30:03.978180 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #92 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 13:30:03.978679 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #92 | Collecting samples for evaluation
2017-06-03 13:30:12.941721 EDT | -----------------------  --------------
2017-06-03 13:30:12.944237 EDT | Epoch                      92
2017-06-03 13:30:12.944560 EDT | Iteration                  92
2017-06-03 13:30:12.944816 EDT | AverageReturn            1000
2017-06-03 13:30:12.945076 EDT | StdReturn                   0
2017-06-03 13:30:12.945335 EDT | MaxReturn                1000
2017-06-03 13:30:12.945573 EDT | MinReturn                1000
2017-06-03 13:30:12.945872 EDT | AverageEsReturn            23.2093
2017-06-03 13:30:12.946152 EDT | StdEsReturn                14.7152
2017-06-03 13:30:12.946392 EDT | MaxEsReturn                59
2017-06-03 13:30:12.946628 EDT | MinEsReturn                 3
2017-06-03 13:30:12.946861 EDT | AverageDiscountedReturn    99.9957
2017-06-03 13:30:12.947096 EDT | AverageQLoss                0.000116973
2017-06-03 13:30:12.947363 EDT | AveragePolicySurr          -0.163662
2017-06-03 13:30:12.947631 EDT | AverageQ                    0.152002
2017-06-03 13:30:12.947903 EDT | AverageAbsQ                 0.152627
2017-06-03 13:30:12.948162 EDT | AverageY                    0.152003
2017-06-03 13:30:12.948400 EDT | AverageAbsY                 0.152114
2017-06-03 13:30:12.948664 EDT | AverageAbsQYDiff            0.00392203
2017-06-03 13:30:12.948942 EDT | AverageAction               0.058253
2017-06-03 13:30:12.949184 EDT | PolicyRegParamNorm         38.6079
2017-06-03 13:30:12.949418 EDT | QFunRegParamNorm           21.4834
2017-06-03 13:30:12.949652 EDT | -----------------------  --------------
2017-06-03 13:30:12.950061 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #93 | Training started
2017-06-03 13:30:32.660902 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #93 | Training finished
2017-06-03 13:30:32.661762 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #93 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 13:30:32.662162 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #93 | Collecting samples for evaluation
2017-06-03 13:30:42.240816 EDT | -----------------------  --------------
2017-06-03 13:30:42.241670 EDT | Epoch                      93
2017-06-03 13:30:42.241951 EDT | Iteration                  93
2017-06-03 13:30:42.242197 EDT | AverageReturn            1000
2017-06-03 13:30:42.242444 EDT | StdReturn                   0
2017-06-03 13:30:42.242679 EDT | MaxReturn                1000
2017-06-03 13:30:42.242910 EDT | MinReturn                1000
2017-06-03 13:30:42.243144 EDT | AverageEsReturn            21.4783
2017-06-03 13:30:42.243378 EDT | StdEsReturn                17.5149
2017-06-03 13:30:42.243607 EDT | MaxEsReturn                67
2017-06-03 13:30:42.243836 EDT | MinEsReturn                 3
2017-06-03 13:30:42.244067 EDT | AverageDiscountedReturn    99.9957
2017-06-03 13:30:42.244335 EDT | AverageQLoss                0.000112378
2017-06-03 13:30:42.244567 EDT | AveragePolicySurr          -0.163732
2017-06-03 13:30:42.244799 EDT | AverageQ                    0.151611
2017-06-03 13:30:42.245032 EDT | AverageAbsQ                 0.15214
2017-06-03 13:30:42.245263 EDT | AverageY                    0.151625
2017-06-03 13:30:42.245501 EDT | AverageAbsY                 0.151753
2017-06-03 13:30:42.245741 EDT | AverageAbsQYDiff            0.00387098
2017-06-03 13:30:42.245976 EDT | AverageAction               0.373676
2017-06-03 13:30:42.246208 EDT | PolicyRegParamNorm         38.8251
2017-06-03 13:30:42.246437 EDT | QFunRegParamNorm           21.5064
2017-06-03 13:30:42.246668 EDT | -----------------------  --------------
2017-06-03 13:30:42.247026 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #94 | Training started
2017-06-03 13:31:02.224788 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #94 | Training finished
2017-06-03 13:31:02.225836 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #94 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 13:31:02.226215 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #94 | Collecting samples for evaluation
2017-06-03 13:31:11.571398 EDT | -----------------------  --------------
2017-06-03 13:31:11.572275 EDT | Epoch                      94
2017-06-03 13:31:11.572557 EDT | Iteration                  94
2017-06-03 13:31:11.572811 EDT | AverageReturn            1000
2017-06-03 13:31:11.573060 EDT | StdReturn                   0
2017-06-03 13:31:11.573320 EDT | MaxReturn                1000
2017-06-03 13:31:11.573576 EDT | MinReturn                1000
2017-06-03 13:31:11.573851 EDT | AverageEsReturn            24.5366
2017-06-03 13:31:11.574099 EDT | StdEsReturn                26.8029
2017-06-03 13:31:11.574346 EDT | MaxEsReturn               147
2017-06-03 13:31:11.574592 EDT | MinEsReturn                 3
2017-06-03 13:31:11.574849 EDT | AverageDiscountedReturn    99.9957
2017-06-03 13:31:11.575091 EDT | AverageQLoss                0.000119322
2017-06-03 13:31:11.575334 EDT | AveragePolicySurr          -0.163447
2017-06-03 13:31:11.575577 EDT | AverageQ                    0.152253
2017-06-03 13:31:11.575819 EDT | AverageAbsQ                 0.152779
2017-06-03 13:31:11.576067 EDT | AverageY                    0.152254
2017-06-03 13:31:11.576313 EDT | AverageAbsY                 0.152399
2017-06-03 13:31:11.576554 EDT | AverageAbsQYDiff            0.00389453
2017-06-03 13:31:11.576795 EDT | AverageAction               0.256317
2017-06-03 13:31:11.577056 EDT | PolicyRegParamNorm         39.0092
2017-06-03 13:31:11.577301 EDT | QFunRegParamNorm           21.5825
2017-06-03 13:31:11.577541 EDT | -----------------------  --------------
2017-06-03 13:31:11.577979 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #95 | Training started
2017-06-03 13:31:30.623304 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #95 | Training finished
2017-06-03 13:31:30.624295 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #95 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 13:31:30.624715 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #95 | Collecting samples for evaluation
2017-06-03 13:31:40.102982 EDT | -----------------------  --------------
2017-06-03 13:31:40.103826 EDT | Epoch                      95
2017-06-03 13:31:40.104143 EDT | Iteration                  95
2017-06-03 13:31:40.104394 EDT | AverageReturn            1000
2017-06-03 13:31:40.104640 EDT | StdReturn                   0
2017-06-03 13:31:40.104882 EDT | MaxReturn                1000
2017-06-03 13:31:40.105123 EDT | MinReturn                1000
2017-06-03 13:31:40.105363 EDT | AverageEsReturn            25.6579
2017-06-03 13:31:40.105590 EDT | StdEsReturn                21.6604
2017-06-03 13:31:40.105832 EDT | MaxEsReturn               123
2017-06-03 13:31:40.106058 EDT | MinEsReturn                 3
2017-06-03 13:31:40.106280 EDT | AverageDiscountedReturn    99.9957
2017-06-03 13:31:40.106502 EDT | AverageQLoss                9.69417e-05
2017-06-03 13:31:40.106724 EDT | AveragePolicySurr          -0.163603
2017-06-03 13:31:40.106946 EDT | AverageQ                    0.151847
2017-06-03 13:31:40.107203 EDT | AverageAbsQ                 0.152344
2017-06-03 13:31:40.107469 EDT | AverageY                    0.151849
2017-06-03 13:31:40.107698 EDT | AverageAbsY                 0.151987
2017-06-03 13:31:40.107958 EDT | AverageAbsQYDiff            0.00358004
2017-06-03 13:31:40.108223 EDT | AverageAction               0.0228548
2017-06-03 13:31:40.108459 EDT | PolicyRegParamNorm         39.1717
2017-06-03 13:31:40.108732 EDT | QFunRegParamNorm           21.602
2017-06-03 13:31:40.108960 EDT | -----------------------  --------------
2017-06-03 13:31:40.109431 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #96 | Training started
2017-06-03 13:31:58.028161 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #96 | Training finished
2017-06-03 13:31:58.029011 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #96 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 13:31:58.029299 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #96 | Collecting samples for evaluation
2017-06-03 13:32:07.471629 EDT | -----------------------  --------------
2017-06-03 13:32:07.472565 EDT | Epoch                      96
2017-06-03 13:32:07.472831 EDT | Iteration                  96
2017-06-03 13:32:07.473083 EDT | AverageReturn            1000
2017-06-03 13:32:07.473330 EDT | StdReturn                   0
2017-06-03 13:32:07.473566 EDT | MaxReturn                1000
2017-06-03 13:32:07.473849 EDT | MinReturn                1000
2017-06-03 13:32:07.474106 EDT | AverageEsReturn            23.3556
2017-06-03 13:32:07.474341 EDT | StdEsReturn                19.5586
2017-06-03 13:32:07.474572 EDT | MaxEsReturn                78
2017-06-03 13:32:07.474803 EDT | MinEsReturn                 3
2017-06-03 13:32:07.475034 EDT | AverageDiscountedReturn    99.9957
2017-06-03 13:32:07.475275 EDT | AverageQLoss                0.000102839
2017-06-03 13:32:07.475505 EDT | AveragePolicySurr          -0.163721
2017-06-03 13:32:07.475735 EDT | AverageQ                    0.152911
2017-06-03 13:32:07.475964 EDT | AverageAbsQ                 0.153369
2017-06-03 13:32:07.476194 EDT | AverageY                    0.152908
2017-06-03 13:32:07.476424 EDT | AverageAbsY                 0.152974
2017-06-03 13:32:07.476653 EDT | AverageAbsQYDiff            0.00366322
2017-06-03 13:32:07.476882 EDT | AverageAction               0.255998
2017-06-03 13:32:07.477110 EDT | PolicyRegParamNorm         39.3428
2017-06-03 13:32:07.477338 EDT | QFunRegParamNorm           21.6618
2017-06-03 13:32:07.477599 EDT | -----------------------  --------------
2017-06-03 13:32:07.478146 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #97 | Training started
2017-06-03 13:32:26.026916 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #97 | Training finished
2017-06-03 13:32:26.027877 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #97 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 13:32:26.028148 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #97 | Collecting samples for evaluation
2017-06-03 13:32:35.654090 EDT | -----------------------  --------------
2017-06-03 13:32:35.654627 EDT | Epoch                      97
2017-06-03 13:32:35.654921 EDT | Iteration                  97
2017-06-03 13:32:35.655185 EDT | AverageReturn            1000
2017-06-03 13:32:35.655431 EDT | StdReturn                   0
2017-06-03 13:32:35.655699 EDT | MaxReturn                1000
2017-06-03 13:32:35.655944 EDT | MinReturn                1000
2017-06-03 13:32:35.656185 EDT | AverageEsReturn            21.0889
2017-06-03 13:32:35.656438 EDT | StdEsReturn                19.3377
2017-06-03 13:32:35.656692 EDT | MaxEsReturn                86
2017-06-03 13:32:35.656932 EDT | MinEsReturn                 3
2017-06-03 13:32:35.657179 EDT | AverageDiscountedReturn    99.9957
2017-06-03 13:32:35.657421 EDT | AverageQLoss                0.000116779
2017-06-03 13:32:35.657672 EDT | AveragePolicySurr          -0.163809
2017-06-03 13:32:35.657929 EDT | AverageQ                    0.152338
2017-06-03 13:32:35.658186 EDT | AverageAbsQ                 0.1528
2017-06-03 13:32:35.658432 EDT | AverageY                    0.152344
2017-06-03 13:32:35.658680 EDT | AverageAbsY                 0.152418
2017-06-03 13:32:35.658929 EDT | AverageAbsQYDiff            0.00379824
2017-06-03 13:32:35.659171 EDT | AverageAction               0.521539
2017-06-03 13:32:35.659416 EDT | PolicyRegParamNorm         39.4395
2017-06-03 13:32:35.659665 EDT | QFunRegParamNorm           21.7265
2017-06-03 13:32:35.659905 EDT | -----------------------  --------------
2017-06-03 13:32:35.660301 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #98 | Training started
2017-06-03 13:32:54.052778 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #98 | Training finished
2017-06-03 13:32:54.053853 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #98 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 13:32:54.054368 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #98 | Collecting samples for evaluation
2017-06-03 13:33:03.313924 EDT | -----------------------  --------------
2017-06-03 13:33:03.315085 EDT | Epoch                      98
2017-06-03 13:33:03.315462 EDT | Iteration                  98
2017-06-03 13:33:03.315727 EDT | AverageReturn            1000
2017-06-03 13:33:03.315984 EDT | StdReturn                   0
2017-06-03 13:33:03.316244 EDT | MaxReturn                1000
2017-06-03 13:33:03.316498 EDT | MinReturn                1000
2017-06-03 13:33:03.316786 EDT | AverageEsReturn            27
2017-06-03 13:33:03.317032 EDT | StdEsReturn                21.4452
2017-06-03 13:33:03.317275 EDT | MaxEsReturn                97
2017-06-03 13:33:03.317517 EDT | MinEsReturn                 3
2017-06-03 13:33:03.317769 EDT | AverageDiscountedReturn    99.9957
2017-06-03 13:33:03.318022 EDT | AverageQLoss                0.000105947
2017-06-03 13:33:03.318263 EDT | AveragePolicySurr          -0.163509
2017-06-03 13:33:03.318509 EDT | AverageQ                    0.152329
2017-06-03 13:33:03.318750 EDT | AverageAbsQ                 0.152895
2017-06-03 13:33:03.318991 EDT | AverageY                    0.152335
2017-06-03 13:33:03.319231 EDT | AverageAbsY                 0.152421
2017-06-03 13:33:03.319471 EDT | AverageAbsQYDiff            0.00385146
2017-06-03 13:33:03.319712 EDT | AverageAction               0.253293
2017-06-03 13:33:03.319951 EDT | PolicyRegParamNorm         39.6219
2017-06-03 13:33:03.320190 EDT | QFunRegParamNorm           21.7638
2017-06-03 13:33:03.320429 EDT | -----------------------  --------------
2017-06-03 13:33:03.320822 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #99 | Training started
2017-06-03 13:33:23.695584 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #99 | Training finished
2017-06-03 13:33:23.696433 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #99 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 13:33:23.696738 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #99 | Collecting samples for evaluation
2017-06-03 13:33:33.512692 EDT | -----------------------  --------------
2017-06-03 13:33:33.513582 EDT | Epoch                      99
2017-06-03 13:33:33.513873 EDT | Iteration                  99
2017-06-03 13:33:33.514136 EDT | AverageReturn            1000
2017-06-03 13:33:33.514384 EDT | StdReturn                   0
2017-06-03 13:33:33.514630 EDT | MaxReturn                1000
2017-06-03 13:33:33.514872 EDT | MinReturn                1000
2017-06-03 13:33:33.515116 EDT | AverageEsReturn            23.0233
2017-06-03 13:33:33.515368 EDT | StdEsReturn                21.7859
2017-06-03 13:33:33.515610 EDT | MaxEsReturn                91
2017-06-03 13:33:33.515855 EDT | MinEsReturn                 4
2017-06-03 13:33:33.516097 EDT | AverageDiscountedReturn    99.9957
2017-06-03 13:33:33.516338 EDT | AverageQLoss                9.92615e-05
2017-06-03 13:33:33.516587 EDT | AveragePolicySurr          -0.163804
2017-06-03 13:33:33.516830 EDT | AverageQ                    0.152789
2017-06-03 13:33:33.517072 EDT | AverageAbsQ                 0.153349
2017-06-03 13:33:33.517312 EDT | AverageY                    0.152783
2017-06-03 13:33:33.517553 EDT | AverageAbsY                 0.152911
2017-06-03 13:33:33.517819 EDT | AverageAbsQYDiff            0.00366916
2017-06-03 13:33:33.518135 EDT | AverageAction               0.503317
2017-06-03 13:33:33.518656 EDT | PolicyRegParamNorm         39.8211
2017-06-03 13:33:33.519135 EDT | QFunRegParamNorm           21.8219
2017-06-03 13:33:33.519590 EDT | -----------------------  --------------
2017-06-03 13:33:33.520245 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #100 | Training started
2017-06-03 13:33:51.935050 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #100 | Training finished
2017-06-03 13:33:52.025217 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #100 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 13:33:52.025590 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #100 | Collecting samples for evaluation
2017-06-03 13:34:03.091286 EDT | -----------------------  -------------
2017-06-03 13:34:03.092133 EDT | Epoch                     100
2017-06-03 13:34:03.092380 EDT | Iteration                 100
2017-06-03 13:34:03.092604 EDT | AverageReturn            1000
2017-06-03 13:34:03.092823 EDT | StdReturn                   0
2017-06-03 13:34:03.093035 EDT | MaxReturn                1000
2017-06-03 13:34:03.093246 EDT | MinReturn                1000
2017-06-03 13:34:03.093456 EDT | AverageEsReturn            25.9231
2017-06-03 13:34:03.093666 EDT | StdEsReturn                26.4472
2017-06-03 13:34:03.093943 EDT | MaxEsReturn               118
2017-06-03 13:34:03.094211 EDT | MinEsReturn                 3
2017-06-03 13:34:03.094443 EDT | AverageDiscountedReturn    99.9957
2017-06-03 13:34:03.094684 EDT | AverageQLoss                0.00011265
2017-06-03 13:34:03.094915 EDT | AveragePolicySurr          -0.16403
2017-06-03 13:34:03.095142 EDT | AverageQ                    0.152518
2017-06-03 13:34:03.095370 EDT | AverageAbsQ                 0.153097
2017-06-03 13:34:03.095597 EDT | AverageY                    0.152529
2017-06-03 13:34:03.095834 EDT | AverageAbsY                 0.152686
2017-06-03 13:34:03.096061 EDT | AverageAbsQYDiff            0.0038233
2017-06-03 13:34:03.096307 EDT | AverageAction               0.544448
2017-06-03 13:34:03.096538 EDT | PolicyRegParamNorm         40.0139
2017-06-03 13:34:03.096769 EDT | QFunRegParamNorm           21.8812
2017-06-03 13:34:03.097000 EDT | -----------------------  -------------
2017-06-03 13:34:03.097356 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #101 | Training started
2017-06-03 13:34:21.428110 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #101 | Training finished
2017-06-03 13:34:21.429043 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #101 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 13:34:21.429391 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #101 | Collecting samples for evaluation
2017-06-03 13:34:31.683657 EDT | -----------------------  --------------
2017-06-03 13:34:31.684594 EDT | Epoch                     101
2017-06-03 13:34:31.684968 EDT | Iteration                 101
2017-06-03 13:34:31.685240 EDT | AverageReturn            1000
2017-06-03 13:34:31.685490 EDT | StdReturn                   0
2017-06-03 13:34:31.685763 EDT | MaxReturn                1000
2017-06-03 13:34:31.686009 EDT | MinReturn                1000
2017-06-03 13:34:31.686269 EDT | AverageEsReturn            21.7174
2017-06-03 13:34:31.686517 EDT | StdEsReturn                19.1069
2017-06-03 13:34:31.686760 EDT | MaxEsReturn               111
2017-06-03 13:34:31.686995 EDT | MinEsReturn                 3
2017-06-03 13:34:31.687242 EDT | AverageDiscountedReturn    99.9957
2017-06-03 13:34:31.687474 EDT | AverageQLoss                0.000110145
2017-06-03 13:34:31.687706 EDT | AveragePolicySurr          -0.164254
2017-06-03 13:34:31.687951 EDT | AverageQ                    0.152727
2017-06-03 13:34:31.688211 EDT | AverageAbsQ                 0.153285
2017-06-03 13:34:31.688444 EDT | AverageY                    0.152734
2017-06-03 13:34:31.688675 EDT | AverageAbsY                 0.152882
2017-06-03 13:34:31.688925 EDT | AverageAbsQYDiff            0.0037882
2017-06-03 13:34:31.689183 EDT | AverageAction               0.604432
2017-06-03 13:34:31.689438 EDT | PolicyRegParamNorm         40.1896
2017-06-03 13:34:31.689676 EDT | QFunRegParamNorm           21.9319
2017-06-03 13:34:31.689996 EDT | -----------------------  --------------
2017-06-03 13:34:31.690397 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #102 | Training started
2017-06-03 13:34:50.773541 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #102 | Training finished
2017-06-03 13:34:50.774548 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #102 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 13:34:50.775025 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #102 | Collecting samples for evaluation
2017-06-03 13:35:00.677715 EDT | -----------------------  --------------
2017-06-03 13:35:00.688810 EDT | Epoch                     102
2017-06-03 13:35:00.689212 EDT | Iteration                 102
2017-06-03 13:35:00.689479 EDT | AverageReturn            1000
2017-06-03 13:35:00.689747 EDT | StdReturn                   0
2017-06-03 13:35:00.690005 EDT | MaxReturn                1000
2017-06-03 13:35:00.690370 EDT | MinReturn                1000
2017-06-03 13:35:00.690633 EDT | AverageEsReturn            26.1579
2017-06-03 13:35:00.690884 EDT | StdEsReturn                29.2156
2017-06-03 13:35:00.691137 EDT | MaxEsReturn               123
2017-06-03 13:35:00.691383 EDT | MinEsReturn                 3
2017-06-03 13:35:00.691636 EDT | AverageDiscountedReturn    99.9957
2017-06-03 13:35:00.691880 EDT | AverageQLoss                0.000121091
2017-06-03 13:35:00.692127 EDT | AveragePolicySurr          -0.16399
2017-06-03 13:35:00.692376 EDT | AverageQ                    0.152805
2017-06-03 13:35:00.692619 EDT | AverageAbsQ                 0.15333
2017-06-03 13:35:00.692861 EDT | AverageY                    0.152809
2017-06-03 13:35:00.693103 EDT | AverageAbsY                 0.152894
2017-06-03 13:35:00.693350 EDT | AverageAbsQYDiff            0.00392508
2017-06-03 13:35:00.693621 EDT | AverageAction               0.607064
2017-06-03 13:35:00.693876 EDT | PolicyRegParamNorm         40.4208
2017-06-03 13:35:00.694119 EDT | QFunRegParamNorm           21.9781
2017-06-03 13:35:00.694360 EDT | -----------------------  --------------
2017-06-03 13:35:00.694781 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #103 | Training started
2017-06-03 13:35:19.603745 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #103 | Training finished
2017-06-03 13:35:19.604650 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #103 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 13:35:19.604913 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #103 | Collecting samples for evaluation
2017-06-03 13:35:29.023946 EDT | -----------------------  --------------
2017-06-03 13:35:29.024325 EDT | Epoch                     103
2017-06-03 13:35:29.024584 EDT | Iteration                 103
2017-06-03 13:35:29.024841 EDT | AverageReturn            1000
2017-06-03 13:35:29.025094 EDT | StdReturn                   0
2017-06-03 13:35:29.025364 EDT | MaxReturn                1000
2017-06-03 13:35:29.025610 EDT | MinReturn                1000
2017-06-03 13:35:29.025865 EDT | AverageEsReturn            25.9737
2017-06-03 13:35:29.026109 EDT | StdEsReturn                21.4703
2017-06-03 13:35:29.026353 EDT | MaxEsReturn                93
2017-06-03 13:35:29.026606 EDT | MinEsReturn                 3
2017-06-03 13:35:29.026850 EDT | AverageDiscountedReturn    99.9957
2017-06-03 13:35:29.027092 EDT | AverageQLoss                0.000105416
2017-06-03 13:35:29.027333 EDT | AveragePolicySurr          -0.16436
2017-06-03 13:35:29.027576 EDT | AverageQ                    0.153446
2017-06-03 13:35:29.027817 EDT | AverageAbsQ                 0.153925
2017-06-03 13:35:29.028058 EDT | AverageY                    0.153434
2017-06-03 13:35:29.028299 EDT | AverageAbsY                 0.153518
2017-06-03 13:35:29.028540 EDT | AverageAbsQYDiff            0.00372919
2017-06-03 13:35:29.028778 EDT | AverageAction               0.609238
2017-06-03 13:35:29.029016 EDT | PolicyRegParamNorm         40.637
2017-06-03 13:35:29.029254 EDT | QFunRegParamNorm           22.0161
2017-06-03 13:35:29.029493 EDT | -----------------------  --------------
2017-06-03 13:35:29.029978 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #104 | Training started
2017-06-03 13:35:47.110305 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #104 | Training finished
2017-06-03 13:35:47.111237 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #104 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 13:35:47.111586 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #104 | Collecting samples for evaluation
2017-06-03 13:35:57.019514 EDT | -----------------------  --------------
2017-06-03 13:35:57.020396 EDT | Epoch                     104
2017-06-03 13:35:57.020711 EDT | Iteration                 104
2017-06-03 13:35:57.021006 EDT | AverageReturn            1000
2017-06-03 13:35:57.021294 EDT | StdReturn                   0
2017-06-03 13:35:57.021558 EDT | MaxReturn                1000
2017-06-03 13:35:57.021832 EDT | MinReturn                1000
2017-06-03 13:35:57.022088 EDT | AverageEsReturn            24.8537
2017-06-03 13:35:57.022336 EDT | StdEsReturn                20.7888
2017-06-03 13:35:57.022598 EDT | MaxEsReturn                79
2017-06-03 13:35:57.022861 EDT | MinEsReturn                 4
2017-06-03 13:35:57.023107 EDT | AverageDiscountedReturn    99.9957
2017-06-03 13:35:57.023350 EDT | AverageQLoss                0.000109403
2017-06-03 13:35:57.023592 EDT | AveragePolicySurr          -0.164251
2017-06-03 13:35:57.023839 EDT | AverageQ                    0.15347
2017-06-03 13:35:57.024113 EDT | AverageAbsQ                 0.154028
2017-06-03 13:35:57.024418 EDT | AverageY                    0.153478
2017-06-03 13:35:57.024687 EDT | AverageAbsY                 0.153561
2017-06-03 13:35:57.024933 EDT | AverageAbsQYDiff            0.00377015
2017-06-03 13:35:57.025206 EDT | AverageAction               0.307909
2017-06-03 13:35:57.025476 EDT | PolicyRegParamNorm         40.7914
2017-06-03 13:35:57.025753 EDT | QFunRegParamNorm           22.0544
2017-06-03 13:35:57.026078 EDT | -----------------------  --------------
2017-06-03 13:35:57.026674 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #105 | Training started
2017-06-03 13:36:16.193603 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #105 | Training finished
2017-06-03 13:36:16.194588 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #105 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 13:36:16.194976 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #105 | Collecting samples for evaluation
2017-06-03 13:36:26.708974 EDT | -----------------------  --------------
2017-06-03 13:36:26.709841 EDT | Epoch                     105
2017-06-03 13:36:26.710207 EDT | Iteration                 105
2017-06-03 13:36:26.710537 EDT | AverageReturn            1000
2017-06-03 13:36:26.710864 EDT | StdReturn                   0
2017-06-03 13:36:26.711186 EDT | MaxReturn                1000
2017-06-03 13:36:26.711508 EDT | MinReturn                1000
2017-06-03 13:36:26.711824 EDT | AverageEsReturn            27.7143
2017-06-03 13:36:26.712142 EDT | StdEsReturn                28.3988
2017-06-03 13:36:26.712477 EDT | MaxEsReturn               141
2017-06-03 13:36:26.712792 EDT | MinEsReturn                 3
2017-06-03 13:36:26.713101 EDT | AverageDiscountedReturn    99.9957
2017-06-03 13:36:26.713413 EDT | AverageQLoss                0.000109708
2017-06-03 13:36:26.713750 EDT | AveragePolicySurr          -0.164025
2017-06-03 13:36:26.714069 EDT | AverageQ                    0.153202
2017-06-03 13:36:26.714382 EDT | AverageAbsQ                 0.153709
2017-06-03 13:36:26.714728 EDT | AverageY                    0.153207
2017-06-03 13:36:26.715042 EDT | AverageAbsY                 0.153289
2017-06-03 13:36:26.715353 EDT | AverageAbsQYDiff            0.00374757
2017-06-03 13:36:26.715664 EDT | AverageAction               0.699435
2017-06-03 13:36:26.716079 EDT | PolicyRegParamNorm         41.0595
2017-06-03 13:36:26.716551 EDT | QFunRegParamNorm           22.086
2017-06-03 13:36:26.717074 EDT | -----------------------  --------------
2017-06-03 13:36:26.717775 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #106 | Training started
2017-06-03 13:36:47.135542 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #106 | Training finished
2017-06-03 13:36:47.136403 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #106 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 13:36:47.136671 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #106 | Collecting samples for evaluation
2017-06-03 13:36:56.025715 EDT | -----------------------  -------------
2017-06-03 13:36:56.026646 EDT | Epoch                     106
2017-06-03 13:36:56.026981 EDT | Iteration                 106
2017-06-03 13:36:56.027241 EDT | AverageReturn            1000
2017-06-03 13:36:56.027491 EDT | StdReturn                   0
2017-06-03 13:36:56.027737 EDT | MaxReturn                1000
2017-06-03 13:36:56.027981 EDT | MinReturn                1000
2017-06-03 13:36:56.028234 EDT | AverageEsReturn            28.4167
2017-06-03 13:36:56.028488 EDT | StdEsReturn                23.3528
2017-06-03 13:36:56.028735 EDT | MaxEsReturn                95
2017-06-03 13:36:56.028977 EDT | MinEsReturn                 3
2017-06-03 13:36:56.029218 EDT | AverageDiscountedReturn    99.9957
2017-06-03 13:36:56.029459 EDT | AverageQLoss                0.00010308
2017-06-03 13:36:56.029707 EDT | AveragePolicySurr          -0.163626
2017-06-03 13:36:56.029954 EDT | AverageQ                    0.153029
2017-06-03 13:36:56.030193 EDT | AverageAbsQ                 0.153491
2017-06-03 13:36:56.030439 EDT | AverageY                    0.153022
2017-06-03 13:36:56.030678 EDT | AverageAbsY                 0.153143
2017-06-03 13:36:56.030923 EDT | AverageAbsQYDiff            0.00354978
2017-06-03 13:36:56.031162 EDT | AverageAction               0.644233
2017-06-03 13:36:56.031402 EDT | PolicyRegParamNorm         41.2772
2017-06-03 13:36:56.031641 EDT | QFunRegParamNorm           22.1096
2017-06-03 13:36:56.031881 EDT | -----------------------  -------------
2017-06-03 13:36:56.032254 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #107 | Training started
2017-06-03 13:37:15.425275 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #107 | Training finished
2017-06-03 13:37:15.426331 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #107 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 13:37:15.426689 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #107 | Collecting samples for evaluation
2017-06-03 13:37:26.034876 EDT | -----------------------  --------------
2017-06-03 13:37:26.035745 EDT | Epoch                     107
2017-06-03 13:37:26.036019 EDT | Iteration                 107
2017-06-03 13:37:26.036275 EDT | AverageReturn            1000
2017-06-03 13:37:26.036641 EDT | StdReturn                   0
2017-06-03 13:37:26.036973 EDT | MaxReturn                1000
2017-06-03 13:37:26.037296 EDT | MinReturn                1000
2017-06-03 13:37:26.037621 EDT | AverageEsReturn            22.1333
2017-06-03 13:37:26.037967 EDT | StdEsReturn                17.3636
2017-06-03 13:37:26.038292 EDT | MaxEsReturn                68
2017-06-03 13:37:26.038603 EDT | MinEsReturn                 3
2017-06-03 13:37:26.038918 EDT | AverageDiscountedReturn    99.9957
2017-06-03 13:37:26.039232 EDT | AverageQLoss                9.93877e-05
2017-06-03 13:37:26.039561 EDT | AveragePolicySurr          -0.163666
2017-06-03 13:37:26.039902 EDT | AverageQ                    0.152996
2017-06-03 13:37:26.040250 EDT | AverageAbsQ                 0.153589
2017-06-03 13:37:26.040581 EDT | AverageY                    0.152996
2017-06-03 13:37:26.040900 EDT | AverageAbsY                 0.153159
2017-06-03 13:37:26.041218 EDT | AverageAbsQYDiff            0.00357662
2017-06-03 13:37:26.041532 EDT | AverageAction               0.712362
2017-06-03 13:37:26.041871 EDT | PolicyRegParamNorm         41.506
2017-06-03 13:37:26.042183 EDT | QFunRegParamNorm           22.1685
2017-06-03 13:37:26.042496 EDT | -----------------------  --------------
2017-06-03 13:37:26.042984 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #108 | Training started
2017-06-03 13:37:45.580795 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #108 | Training finished
2017-06-03 13:37:45.581736 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #108 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 13:37:45.582087 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #108 | Collecting samples for evaluation
2017-06-03 13:37:55.740615 EDT | -----------------------  --------------
2017-06-03 13:37:55.741648 EDT | Epoch                     108
2017-06-03 13:37:55.741974 EDT | Iteration                 108
2017-06-03 13:37:55.742233 EDT | AverageReturn            1000
2017-06-03 13:37:55.742481 EDT | StdReturn                   0
2017-06-03 13:37:55.742715 EDT | MaxReturn                1000
2017-06-03 13:37:55.743004 EDT | MinReturn                1000
2017-06-03 13:37:55.743274 EDT | AverageEsReturn            38.64
2017-06-03 13:37:55.743524 EDT | StdEsReturn                40.1655
2017-06-03 13:37:55.743752 EDT | MaxEsReturn               192
2017-06-03 13:37:55.743977 EDT | MinEsReturn                 6
2017-06-03 13:37:55.744210 EDT | AverageDiscountedReturn    99.9957
2017-06-03 13:37:55.744455 EDT | AverageQLoss                9.53448e-05
2017-06-03 13:37:55.744705 EDT | AveragePolicySurr          -0.1633
2017-06-03 13:37:55.744936 EDT | AverageQ                    0.152938
2017-06-03 13:37:55.745165 EDT | AverageAbsQ                 0.153473
2017-06-03 13:37:55.745393 EDT | AverageY                    0.152939
2017-06-03 13:37:55.745615 EDT | AverageAbsY                 0.153121
2017-06-03 13:37:55.746510 EDT | AverageAbsQYDiff            0.00339872
2017-06-03 13:37:55.746826 EDT | AverageAction               0.636781
2017-06-03 13:37:55.747160 EDT | PolicyRegParamNorm         41.6395
2017-06-03 13:37:55.747481 EDT | QFunRegParamNorm           22.2134
2017-06-03 13:37:55.747792 EDT | -----------------------  --------------
2017-06-03 13:37:55.748920 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #109 | Training started
2017-06-03 13:38:16.198770 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #109 | Training finished
2017-06-03 13:38:16.199742 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #109 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 13:38:16.200103 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #109 | Collecting samples for evaluation
2017-06-03 13:38:25.051513 EDT | -----------------------  --------------
2017-06-03 13:38:25.052336 EDT | Epoch                     109
2017-06-03 13:38:25.052605 EDT | Iteration                 109
2017-06-03 13:38:25.052848 EDT | AverageReturn            1000
2017-06-03 13:38:25.053082 EDT | StdReturn                   0
2017-06-03 13:38:25.053322 EDT | MaxReturn                1000
2017-06-03 13:38:25.053555 EDT | MinReturn                1000
2017-06-03 13:38:25.053805 EDT | AverageEsReturn            26.4211
2017-06-03 13:38:25.054038 EDT | StdEsReturn                22.948
2017-06-03 13:38:25.054270 EDT | MaxEsReturn               106
2017-06-03 13:38:25.054512 EDT | MinEsReturn                 3
2017-06-03 13:38:25.054761 EDT | AverageDiscountedReturn    99.9957
2017-06-03 13:38:25.054993 EDT | AverageQLoss                0.000101413
2017-06-03 13:38:25.055226 EDT | AveragePolicySurr          -0.162857
2017-06-03 13:38:25.055458 EDT | AverageQ                    0.152103
2017-06-03 13:38:25.055687 EDT | AverageAbsQ                 0.152694
2017-06-03 13:38:25.055916 EDT | AverageY                    0.152108
2017-06-03 13:38:25.056145 EDT | AverageAbsY                 0.152269
2017-06-03 13:38:25.056387 EDT | AverageAbsQYDiff            0.00362084
2017-06-03 13:38:25.056617 EDT | AverageAction               0.77076
2017-06-03 13:38:25.056845 EDT | PolicyRegParamNorm         41.9481
2017-06-03 13:38:25.057076 EDT | QFunRegParamNorm           22.2726
2017-06-03 13:38:25.057305 EDT | -----------------------  --------------
2017-06-03 13:38:25.057709 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #110 | Training started
2017-06-03 13:38:44.855797 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #110 | Training finished
2017-06-03 13:38:44.856726 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #110 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 13:38:44.857062 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #110 | Collecting samples for evaluation
2017-06-03 13:38:54.771943 EDT | -----------------------  --------------
2017-06-03 13:38:54.772773 EDT | Epoch                     110
2017-06-03 13:38:54.773031 EDT | Iteration                 110
2017-06-03 13:38:54.773269 EDT | AverageReturn            1000
2017-06-03 13:38:54.773553 EDT | StdReturn                   0
2017-06-03 13:38:54.773797 EDT | MaxReturn                1000
2017-06-03 13:38:54.774032 EDT | MinReturn                1000
2017-06-03 13:38:54.774269 EDT | AverageEsReturn            27.2647
2017-06-03 13:38:54.774501 EDT | StdEsReturn                18.8138
2017-06-03 13:38:54.774739 EDT | MaxEsReturn                86
2017-06-03 13:38:54.774970 EDT | MinEsReturn                 3
2017-06-03 13:38:54.775200 EDT | AverageDiscountedReturn    99.9957
2017-06-03 13:38:54.775431 EDT | AverageQLoss                0.000112686
2017-06-03 13:38:54.775661 EDT | AveragePolicySurr          -0.163338
2017-06-03 13:38:54.775892 EDT | AverageQ                    0.152928
2017-06-03 13:38:54.776121 EDT | AverageAbsQ                 0.1535
2017-06-03 13:38:54.776364 EDT | AverageY                    0.152924
2017-06-03 13:38:54.776598 EDT | AverageAbsY                 0.153117
2017-06-03 13:38:54.776828 EDT | AverageAbsQYDiff            0.00376533
2017-06-03 13:38:54.777057 EDT | AverageAction               0.71278
2017-06-03 13:38:54.777285 EDT | PolicyRegParamNorm         41.9748
2017-06-03 13:38:54.777514 EDT | QFunRegParamNorm           22.3263
2017-06-03 13:38:54.777753 EDT | -----------------------  --------------
2017-06-03 13:38:54.778100 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #111 | Training started
2017-06-03 13:39:13.596291 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #111 | Training finished
2017-06-03 13:39:13.597360 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #111 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 13:39:13.597719 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #111 | Collecting samples for evaluation
2017-06-03 13:39:21.744814 EDT | -----------------------  --------------
2017-06-03 13:39:21.745687 EDT | Epoch                     111
2017-06-03 13:39:21.745972 EDT | Iteration                 111
2017-06-03 13:39:21.746213 EDT | AverageReturn            1000
2017-06-03 13:39:21.746466 EDT | StdReturn                   0
2017-06-03 13:39:21.746702 EDT | MaxReturn                1000
2017-06-03 13:39:21.746936 EDT | MinReturn                1000
2017-06-03 13:39:21.747170 EDT | AverageEsReturn            33.3438
2017-06-03 13:39:21.747407 EDT | StdEsReturn                28.0609
2017-06-03 13:39:21.747648 EDT | MaxEsReturn               118
2017-06-03 13:39:21.747880 EDT | MinEsReturn                 3
2017-06-03 13:39:21.748111 EDT | AverageDiscountedReturn    99.9957
2017-06-03 13:39:21.748343 EDT | AverageQLoss                0.000101143
2017-06-03 13:39:21.748573 EDT | AveragePolicySurr          -0.162721
2017-06-03 13:39:21.748804 EDT | AverageQ                    0.152372
2017-06-03 13:39:21.749034 EDT | AverageAbsQ                 0.153027
2017-06-03 13:39:21.749264 EDT | AverageY                    0.152374
2017-06-03 13:39:21.749493 EDT | AverageAbsY                 0.152591
2017-06-03 13:39:21.749733 EDT | AverageAbsQYDiff            0.00363399
2017-06-03 13:39:21.749966 EDT | AverageAction               0.746948
2017-06-03 13:39:21.750197 EDT | PolicyRegParamNorm         42.1906
2017-06-03 13:39:21.750427 EDT | QFunRegParamNorm           22.3456
2017-06-03 13:39:21.750660 EDT | -----------------------  --------------
2017-06-03 13:39:21.751033 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #112 | Training started
2017-06-03 13:39:40.366853 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #112 | Training finished
2017-06-03 13:39:40.370424 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #112 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 13:39:40.370743 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #112 | Collecting samples for evaluation
2017-06-03 13:39:49.620320 EDT | -----------------------  --------------
2017-06-03 13:39:49.621198 EDT | Epoch                     112
2017-06-03 13:39:49.621511 EDT | Iteration                 112
2017-06-03 13:39:49.621793 EDT | AverageReturn            1000
2017-06-03 13:39:49.622069 EDT | StdReturn                   0
2017-06-03 13:39:49.622358 EDT | MaxReturn                1000
2017-06-03 13:39:49.622599 EDT | MinReturn                1000
2017-06-03 13:39:49.622862 EDT | AverageEsReturn            26.3846
2017-06-03 13:39:49.623100 EDT | StdEsReturn                20.1477
2017-06-03 13:39:49.623333 EDT | MaxEsReturn                88
2017-06-03 13:39:49.623567 EDT | MinEsReturn                 5
2017-06-03 13:39:49.623806 EDT | AverageDiscountedReturn    99.9957
2017-06-03 13:39:49.624050 EDT | AverageQLoss                0.000101993
2017-06-03 13:39:49.624282 EDT | AveragePolicySurr          -0.162897
2017-06-03 13:39:49.624514 EDT | AverageQ                    0.152347
2017-06-03 13:39:49.624744 EDT | AverageAbsQ                 0.152948
2017-06-03 13:39:49.624998 EDT | AverageY                    0.152349
2017-06-03 13:39:49.625241 EDT | AverageAbsY                 0.152618
2017-06-03 13:39:49.625469 EDT | AverageAbsQYDiff            0.00343294
2017-06-03 13:39:49.625781 EDT | AverageAction               0.747576
2017-06-03 13:39:49.626034 EDT | PolicyRegParamNorm         42.3095
2017-06-03 13:39:49.626265 EDT | QFunRegParamNorm           22.4353
2017-06-03 13:39:49.626495 EDT | -----------------------  --------------
2017-06-03 13:39:49.626858 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #113 | Training started
2017-06-03 13:40:07.898530 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #113 | Training finished
2017-06-03 13:40:07.899514 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #113 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 13:40:07.899879 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #113 | Collecting samples for evaluation
2017-06-03 13:40:17.505209 EDT | -----------------------  --------------
2017-06-03 13:40:17.506101 EDT | Epoch                     113
2017-06-03 13:40:17.506372 EDT | Iteration                 113
2017-06-03 13:40:17.506618 EDT | AverageReturn            1000
2017-06-03 13:40:17.506863 EDT | StdReturn                   0
2017-06-03 13:40:17.507108 EDT | MaxReturn                1000
2017-06-03 13:40:17.507381 EDT | MinReturn                1000
2017-06-03 13:40:17.507615 EDT | AverageEsReturn            28.1667
2017-06-03 13:40:17.507874 EDT | StdEsReturn                31.394
2017-06-03 13:40:17.508106 EDT | MaxEsReturn               138
2017-06-03 13:40:17.508342 EDT | MinEsReturn                 3
2017-06-03 13:40:17.508572 EDT | AverageDiscountedReturn    99.9957
2017-06-03 13:40:17.508803 EDT | AverageQLoss                9.90881e-05
2017-06-03 13:40:17.509162 EDT | AveragePolicySurr          -0.162582
2017-06-03 13:40:17.509479 EDT | AverageQ                    0.152283
2017-06-03 13:40:17.509800 EDT | AverageAbsQ                 0.152969
2017-06-03 13:40:17.510122 EDT | AverageY                    0.152278
2017-06-03 13:40:17.510436 EDT | AverageAbsY                 0.152481
2017-06-03 13:40:17.510744 EDT | AverageAbsQYDiff            0.00359878
2017-06-03 13:40:17.511053 EDT | AverageAction               0.728318
2017-06-03 13:40:17.511360 EDT | PolicyRegParamNorm         42.5019
2017-06-03 13:40:17.511777 EDT | QFunRegParamNorm           22.4594
2017-06-03 13:40:17.512328 EDT | -----------------------  --------------
2017-06-03 13:40:17.512927 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #114 | Training started
2017-06-03 13:40:35.780249 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #114 | Training finished
2017-06-03 13:40:35.781187 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #114 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 13:40:35.781472 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #114 | Collecting samples for evaluation
2017-06-03 13:40:45.648270 EDT | -----------------------  --------------
2017-06-03 13:40:45.649103 EDT | Epoch                     114
2017-06-03 13:40:45.649364 EDT | Iteration                 114
2017-06-03 13:40:45.649606 EDT | AverageReturn            1000
2017-06-03 13:40:45.649855 EDT | StdReturn                   0
2017-06-03 13:40:45.650098 EDT | MaxReturn                1000
2017-06-03 13:40:45.650351 EDT | MinReturn                1000
2017-06-03 13:40:45.650596 EDT | AverageEsReturn            23.0238
2017-06-03 13:40:45.650844 EDT | StdEsReturn                21.2328
2017-06-03 13:40:45.651078 EDT | MaxEsReturn               101
2017-06-03 13:40:45.651310 EDT | MinEsReturn                 5
2017-06-03 13:40:45.651553 EDT | AverageDiscountedReturn    99.9957
2017-06-03 13:40:45.651790 EDT | AverageQLoss                0.000107351
2017-06-03 13:40:45.652021 EDT | AveragePolicySurr          -0.162259
2017-06-03 13:40:45.652256 EDT | AverageQ                    0.152231
2017-06-03 13:40:45.652488 EDT | AverageAbsQ                 0.152804
2017-06-03 13:40:45.652719 EDT | AverageY                    0.152232
2017-06-03 13:40:45.652950 EDT | AverageAbsY                 0.152382
2017-06-03 13:40:45.653179 EDT | AverageAbsQYDiff            0.00361574
2017-06-03 13:40:45.653415 EDT | AverageAction               0.784565
2017-06-03 13:40:45.653644 EDT | PolicyRegParamNorm         42.5881
2017-06-03 13:40:45.653889 EDT | QFunRegParamNorm           22.5241
2017-06-03 13:40:45.654125 EDT | -----------------------  --------------
2017-06-03 13:40:45.654516 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #115 | Training started
2017-06-03 13:41:04.067353 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #115 | Training finished
2017-06-03 13:41:04.068245 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #115 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 13:41:04.068618 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #115 | Collecting samples for evaluation
2017-06-03 13:41:13.296230 EDT | -----------------------  --------------
2017-06-03 13:41:13.297068 EDT | Epoch                     115
2017-06-03 13:41:13.297377 EDT | Iteration                 115
2017-06-03 13:41:13.297631 EDT | AverageReturn            1000
2017-06-03 13:41:13.297893 EDT | StdReturn                   0
2017-06-03 13:41:13.298137 EDT | MaxReturn                1000
2017-06-03 13:41:13.298391 EDT | MinReturn                1000
2017-06-03 13:41:13.298633 EDT | AverageEsReturn            25.2821
2017-06-03 13:41:13.298874 EDT | StdEsReturn                16.1165
2017-06-03 13:41:13.299118 EDT | MaxEsReturn                86
2017-06-03 13:41:13.299360 EDT | MinEsReturn                 6
2017-06-03 13:41:13.299601 EDT | AverageDiscountedReturn    99.9957
2017-06-03 13:41:13.299841 EDT | AverageQLoss                0.000100513
2017-06-03 13:41:13.300093 EDT | AveragePolicySurr          -0.163045
2017-06-03 13:41:13.300334 EDT | AverageQ                    0.152532
2017-06-03 13:41:13.300574 EDT | AverageAbsQ                 0.153136
2017-06-03 13:41:13.300815 EDT | AverageY                    0.152531
2017-06-03 13:41:13.301056 EDT | AverageAbsY                 0.152669
2017-06-03 13:41:13.301307 EDT | AverageAbsQYDiff            0.0036766
2017-06-03 13:41:13.301547 EDT | AverageAction               0.681385
2017-06-03 13:41:13.301800 EDT | PolicyRegParamNorm         42.7953
2017-06-03 13:41:13.302041 EDT | QFunRegParamNorm           22.5422
2017-06-03 13:41:13.302282 EDT | -----------------------  --------------
2017-06-03 13:41:13.302639 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #116 | Training started
2017-06-03 13:41:31.876542 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #116 | Training finished
2017-06-03 13:41:31.877460 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #116 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 13:41:31.877746 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #116 | Collecting samples for evaluation
2017-06-03 13:41:41.508623 EDT | -----------------------  --------------
2017-06-03 13:41:41.509446 EDT | Epoch                     116
2017-06-03 13:41:41.509753 EDT | Iteration                 116
2017-06-03 13:41:41.510022 EDT | AverageReturn            1000
2017-06-03 13:41:41.510308 EDT | StdReturn                   0
2017-06-03 13:41:41.510566 EDT | MaxReturn                1000
2017-06-03 13:41:41.510847 EDT | MinReturn                1000
2017-06-03 13:41:41.511094 EDT | AverageEsReturn            32.4688
2017-06-03 13:41:41.511394 EDT | StdEsReturn                27.173
2017-06-03 13:41:41.511645 EDT | MaxEsReturn               123
2017-06-03 13:41:41.511900 EDT | MinEsReturn                 3
2017-06-03 13:41:41.512169 EDT | AverageDiscountedReturn    99.9957
2017-06-03 13:41:41.512414 EDT | AverageQLoss                0.000109182
2017-06-03 13:41:41.512661 EDT | AveragePolicySurr          -0.163607
2017-06-03 13:41:41.512890 EDT | AverageQ                    0.152929
2017-06-03 13:41:41.513113 EDT | AverageAbsQ                 0.153514
2017-06-03 13:41:41.513335 EDT | AverageY                    0.152931
2017-06-03 13:41:41.513561 EDT | AverageAbsY                 0.153045
2017-06-03 13:41:41.513808 EDT | AverageAbsQYDiff            0.00370312
2017-06-03 13:41:41.514032 EDT | AverageAction               0.688935
2017-06-03 13:41:41.514253 EDT | PolicyRegParamNorm         42.902
2017-06-03 13:41:41.514478 EDT | QFunRegParamNorm           22.5688
2017-06-03 13:41:41.514730 EDT | -----------------------  --------------
2017-06-03 13:41:41.515127 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #117 | Training started
2017-06-03 13:42:01.408745 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #117 | Training finished
2017-06-03 13:42:01.409589 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #117 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 13:42:01.409878 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #117 | Collecting samples for evaluation
2017-06-03 13:42:11.073975 EDT | -----------------------  --------------
2017-06-03 13:42:11.074831 EDT | Epoch                     117
2017-06-03 13:42:11.075120 EDT | Iteration                 117
2017-06-03 13:42:11.075361 EDT | AverageReturn            1000
2017-06-03 13:42:11.075598 EDT | StdReturn                   0
2017-06-03 13:42:11.075874 EDT | MaxReturn                1000
2017-06-03 13:42:11.076124 EDT | MinReturn                1000
2017-06-03 13:42:11.076363 EDT | AverageEsReturn            23.3721
2017-06-03 13:42:11.076595 EDT | StdEsReturn                20.4246
2017-06-03 13:42:11.076845 EDT | MaxEsReturn               121
2017-06-03 13:42:11.077116 EDT | MinEsReturn                 3
2017-06-03 13:42:11.077446 EDT | AverageDiscountedReturn    99.9957
2017-06-03 13:42:11.077711 EDT | AverageQLoss                0.000116018
2017-06-03 13:42:11.077954 EDT | AveragePolicySurr          -0.163525
2017-06-03 13:42:11.078201 EDT | AverageQ                    0.152749
2017-06-03 13:42:11.078436 EDT | AverageAbsQ                 0.153278
2017-06-03 13:42:11.078668 EDT | AverageY                    0.152749
2017-06-03 13:42:11.078907 EDT | AverageAbsY                 0.152899
2017-06-03 13:42:11.079145 EDT | AverageAbsQYDiff            0.00388565
2017-06-03 13:42:11.079377 EDT | AverageAction               0.668566
2017-06-03 13:42:11.079607 EDT | PolicyRegParamNorm         42.9775
2017-06-03 13:42:11.079843 EDT | QFunRegParamNorm           22.5948
2017-06-03 13:42:11.080076 EDT | -----------------------  --------------
2017-06-03 13:42:11.080424 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #118 | Training started
2017-06-03 13:42:30.262513 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #118 | Training finished
2017-06-03 13:42:30.263404 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #118 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 13:42:30.263687 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #118 | Collecting samples for evaluation
2017-06-03 13:42:40.195856 EDT | -----------------------  --------------
2017-06-03 13:42:40.196903 EDT | Epoch                     118
2017-06-03 13:42:40.197281 EDT | Iteration                 118
2017-06-03 13:42:40.197648 EDT | AverageReturn            1000
2017-06-03 13:42:40.198102 EDT | StdReturn                   0
2017-06-03 13:42:40.198500 EDT | MaxReturn                1000
2017-06-03 13:42:40.198821 EDT | MinReturn                1000
2017-06-03 13:42:40.199131 EDT | AverageEsReturn            21.6957
2017-06-03 13:42:40.199598 EDT | StdEsReturn                16.3053
2017-06-03 13:42:40.199956 EDT | MaxEsReturn                88
2017-06-03 13:42:40.200290 EDT | MinEsReturn                 3
2017-06-03 13:42:40.200640 EDT | AverageDiscountedReturn    99.9957
2017-06-03 13:42:40.200953 EDT | AverageQLoss                0.000108468
2017-06-03 13:42:40.201263 EDT | AveragePolicySurr          -0.165397
2017-06-03 13:42:40.201624 EDT | AverageQ                    0.153832
2017-06-03 13:42:40.201964 EDT | AverageAbsQ                 0.154368
2017-06-03 13:42:40.202335 EDT | AverageY                    0.153835
2017-06-03 13:42:40.202673 EDT | AverageAbsY                 0.153985
2017-06-03 13:42:40.203004 EDT | AverageAbsQYDiff            0.00369376
2017-06-03 13:42:40.203420 EDT | AverageAction               0.69314
2017-06-03 13:42:40.203875 EDT | PolicyRegParamNorm         43.1104
2017-06-03 13:42:40.204329 EDT | QFunRegParamNorm           22.612
2017-06-03 13:42:40.204780 EDT | -----------------------  --------------
2017-06-03 13:42:40.205406 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #119 | Training started
2017-06-03 13:42:59.474224 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #119 | Training finished
2017-06-03 13:42:59.475208 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #119 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 13:42:59.475606 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #119 | Collecting samples for evaluation
2017-06-03 13:43:08.362803 EDT | -----------------------  -------------
2017-06-03 13:43:08.363203 EDT | Epoch                     119
2017-06-03 13:43:08.363463 EDT | Iteration                 119
2017-06-03 13:43:08.363705 EDT | AverageReturn            1000
2017-06-03 13:43:08.363942 EDT | StdReturn                   0
2017-06-03 13:43:08.364212 EDT | MaxReturn                1000
2017-06-03 13:43:08.364447 EDT | MinReturn                1000
2017-06-03 13:43:08.364681 EDT | AverageEsReturn            24.7179
2017-06-03 13:43:08.364914 EDT | StdEsReturn                28.1488
2017-06-03 13:43:08.365161 EDT | MaxEsReturn               152
2017-06-03 13:43:08.365394 EDT | MinEsReturn                 3
2017-06-03 13:43:08.365626 EDT | AverageDiscountedReturn    99.9957
2017-06-03 13:43:08.365871 EDT | AverageQLoss                0.00012189
2017-06-03 13:43:08.366103 EDT | AveragePolicySurr          -0.166508
2017-06-03 13:43:08.366335 EDT | AverageQ                    0.154603
2017-06-03 13:43:08.366567 EDT | AverageAbsQ                 0.155304
2017-06-03 13:43:08.366799 EDT | AverageY                    0.154607
2017-06-03 13:43:08.367030 EDT | AverageAbsY                 0.154772
2017-06-03 13:43:08.367260 EDT | AverageAbsQYDiff            0.00398011
2017-06-03 13:43:08.367491 EDT | AverageAction               0.019159
2017-06-03 13:43:08.367721 EDT | PolicyRegParamNorm         43.3088
2017-06-03 13:43:08.367951 EDT | QFunRegParamNorm           22.6357
2017-06-03 13:43:08.368181 EDT | -----------------------  -------------
2017-06-03 13:43:08.368579 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #120 | Training started
2017-06-03 13:43:28.075555 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #120 | Training finished
2017-06-03 13:43:28.076905 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #120 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 13:43:28.077191 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #120 | Collecting samples for evaluation
2017-06-03 13:43:37.711795 EDT | -----------------------  --------------
2017-06-03 13:43:37.712313 EDT | Epoch                     120
2017-06-03 13:43:37.712648 EDT | Iteration                 120
2017-06-03 13:43:37.712981 EDT | AverageReturn            1000
2017-06-03 13:43:37.713299 EDT | StdReturn                   0
2017-06-03 13:43:37.713613 EDT | MaxReturn                1000
2017-06-03 13:43:37.713955 EDT | MinReturn                1000
2017-06-03 13:43:37.714272 EDT | AverageEsReturn            22.9318
2017-06-03 13:43:37.714588 EDT | StdEsReturn                21.8074
2017-06-03 13:43:37.714901 EDT | MaxEsReturn               110
2017-06-03 13:43:37.715212 EDT | MinEsReturn                 3
2017-06-03 13:43:37.715521 EDT | AverageDiscountedReturn    99.9957
2017-06-03 13:43:37.715834 EDT | AverageQLoss                0.000110297
2017-06-03 13:43:37.716159 EDT | AveragePolicySurr          -0.168681
2017-06-03 13:43:37.716472 EDT | AverageQ                    0.156722
2017-06-03 13:43:37.716780 EDT | AverageAbsQ                 0.157275
2017-06-03 13:43:37.717094 EDT | AverageY                    0.156721
2017-06-03 13:43:37.717402 EDT | AverageAbsY                 0.156829
2017-06-03 13:43:37.717715 EDT | AverageAbsQYDiff            0.0038781
2017-06-03 13:43:37.718025 EDT | AverageAction               0.013455
2017-06-03 13:43:37.718333 EDT | PolicyRegParamNorm         43.4441
2017-06-03 13:43:37.718663 EDT | QFunRegParamNorm           22.6501
2017-06-03 13:43:37.718914 EDT | -----------------------  --------------
2017-06-03 13:43:37.719275 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #121 | Training started
2017-06-03 13:43:55.876342 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #121 | Training finished
2017-06-03 13:43:55.978667 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #121 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 13:43:55.979045 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #121 | Collecting samples for evaluation
2017-06-03 13:44:05.320118 EDT | -----------------------  --------------
2017-06-03 13:44:05.320973 EDT | Epoch                     121
2017-06-03 13:44:05.321271 EDT | Iteration                 121
2017-06-03 13:44:05.321533 EDT | AverageReturn            1000
2017-06-03 13:44:05.321801 EDT | StdReturn                   0
2017-06-03 13:44:05.322049 EDT | MaxReturn                1000
2017-06-03 13:44:05.322305 EDT | MinReturn                1000
2017-06-03 13:44:05.322554 EDT | AverageEsReturn            18.8545
2017-06-03 13:44:05.322900 EDT | StdEsReturn                19.2377
2017-06-03 13:44:05.323187 EDT | MaxEsReturn               114
2017-06-03 13:44:05.323432 EDT | MinEsReturn                 3
2017-06-03 13:44:05.323681 EDT | AverageDiscountedReturn    99.9957
2017-06-03 13:44:05.323924 EDT | AverageQLoss                0.000101238
2017-06-03 13:44:05.324167 EDT | AveragePolicySurr          -0.169656
2017-06-03 13:44:05.324426 EDT | AverageQ                    0.15775
2017-06-03 13:44:05.324670 EDT | AverageAbsQ                 0.158365
2017-06-03 13:44:05.324917 EDT | AverageY                    0.157763
2017-06-03 13:44:05.325159 EDT | AverageAbsY                 0.157877
2017-06-03 13:44:05.325418 EDT | AverageAbsQYDiff            0.00389431
2017-06-03 13:44:05.325662 EDT | AverageAction               0.700987
2017-06-03 13:44:05.325918 EDT | PolicyRegParamNorm         43.55
2017-06-03 13:44:05.326160 EDT | QFunRegParamNorm           22.6751
2017-06-03 13:44:05.326402 EDT | -----------------------  --------------
2017-06-03 13:44:05.326900 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #122 | Training started
2017-06-03 13:44:22.735305 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #122 | Training finished
2017-06-03 13:44:22.736231 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #122 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 13:44:22.736506 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #122 | Collecting samples for evaluation
2017-06-03 13:44:32.104389 EDT | -----------------------  --------------
2017-06-03 13:44:32.105262 EDT | Epoch                     122
2017-06-03 13:44:32.105534 EDT | Iteration                 122
2017-06-03 13:44:32.105835 EDT | AverageReturn            1000
2017-06-03 13:44:32.106090 EDT | StdReturn                   0
2017-06-03 13:44:32.106342 EDT | MaxReturn                1000
2017-06-03 13:44:32.106602 EDT | MinReturn                1000
2017-06-03 13:44:32.106860 EDT | AverageEsReturn            21.234
2017-06-03 13:44:32.107116 EDT | StdEsReturn                26.3085
2017-06-03 13:44:32.107363 EDT | MaxEsReturn               120
2017-06-03 13:44:32.107612 EDT | MinEsReturn                 3
2017-06-03 13:44:32.107861 EDT | AverageDiscountedReturn    99.9957
2017-06-03 13:44:32.108111 EDT | AverageQLoss                0.000119181
2017-06-03 13:44:32.108365 EDT | AveragePolicySurr          -0.171355
2017-06-03 13:44:32.108612 EDT | AverageQ                    0.159191
2017-06-03 13:44:32.108860 EDT | AverageAbsQ                 0.159728
2017-06-03 13:44:32.109111 EDT | AverageY                    0.159194
2017-06-03 13:44:32.109357 EDT | AverageAbsY                 0.159336
2017-06-03 13:44:32.109603 EDT | AverageAbsQYDiff            0.00412722
2017-06-03 13:44:32.109862 EDT | AverageAction               0.0170892
2017-06-03 13:44:32.110110 EDT | PolicyRegParamNorm         43.7333
2017-06-03 13:44:32.110357 EDT | QFunRegParamNorm           22.7087
2017-06-03 13:44:32.110603 EDT | -----------------------  --------------
2017-06-03 13:44:32.111011 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #123 | Training started
2017-06-03 13:44:50.954589 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #123 | Training finished
2017-06-03 13:44:50.955437 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #123 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 13:44:50.955702 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #123 | Collecting samples for evaluation
2017-06-03 13:45:01.684478 EDT | -----------------------  -------------
2017-06-03 13:45:01.685501 EDT | Epoch                     123
2017-06-03 13:45:01.685863 EDT | Iteration                 123
2017-06-03 13:45:01.686184 EDT | AverageReturn            1000
2017-06-03 13:45:01.686502 EDT | StdReturn                   0
2017-06-03 13:45:01.686813 EDT | MaxReturn                1000
2017-06-03 13:45:01.687131 EDT | MinReturn                1000
2017-06-03 13:45:01.687438 EDT | AverageEsReturn            19.2115
2017-06-03 13:45:01.687745 EDT | StdEsReturn                18.6664
2017-06-03 13:45:01.688052 EDT | MaxEsReturn                83
2017-06-03 13:45:01.688392 EDT | MinEsReturn                 3
2017-06-03 13:45:01.688695 EDT | AverageDiscountedReturn    99.9957
2017-06-03 13:45:01.689004 EDT | AverageQLoss                0.00011594
2017-06-03 13:45:01.689327 EDT | AveragePolicySurr          -0.172722
2017-06-03 13:45:01.689637 EDT | AverageQ                    0.160466
2017-06-03 13:45:01.689953 EDT | AverageAbsQ                 0.161015
2017-06-03 13:45:01.690256 EDT | AverageY                    0.160465
2017-06-03 13:45:01.690589 EDT | AverageAbsY                 0.160638
2017-06-03 13:45:01.690892 EDT | AverageAbsQYDiff            0.00422333
2017-06-03 13:45:01.691195 EDT | AverageAction               0.00906322
2017-06-03 13:45:01.691506 EDT | PolicyRegParamNorm         43.8585
2017-06-03 13:45:01.691819 EDT | QFunRegParamNorm           22.7387
2017-06-03 13:45:01.692120 EDT | -----------------------  -------------
2017-06-03 13:45:01.692587 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #124 | Training started
2017-06-03 13:45:20.440365 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #124 | Training finished
2017-06-03 13:45:20.441353 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #124 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 13:45:20.441745 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #124 | Collecting samples for evaluation
2017-06-03 13:45:31.105556 EDT | -----------------------  --------------
2017-06-03 13:45:31.106420 EDT | Epoch                     124
2017-06-03 13:45:31.106698 EDT | Iteration                 124
2017-06-03 13:45:31.106944 EDT | AverageReturn            1000
2017-06-03 13:45:31.107194 EDT | StdReturn                   0
2017-06-03 13:45:31.107430 EDT | MaxReturn                1000
2017-06-03 13:45:31.107664 EDT | MinReturn                1000
2017-06-03 13:45:31.107909 EDT | AverageEsReturn            15.1846
2017-06-03 13:45:31.108143 EDT | StdEsReturn                15.9517
2017-06-03 13:45:31.108378 EDT | MaxEsReturn                75
2017-06-03 13:45:31.108615 EDT | MinEsReturn                 3
2017-06-03 13:45:31.108846 EDT | AverageDiscountedReturn    99.9957
2017-06-03 13:45:31.109078 EDT | AverageQLoss                0.000126475
2017-06-03 13:45:31.109333 EDT | AveragePolicySurr          -0.175227
2017-06-03 13:45:31.109566 EDT | AverageQ                    0.162531
2017-06-03 13:45:31.109818 EDT | AverageAbsQ                 0.163132
2017-06-03 13:45:31.110051 EDT | AverageY                    0.162548
2017-06-03 13:45:31.110282 EDT | AverageAbsY                 0.162742
2017-06-03 13:45:31.110523 EDT | AverageAbsQYDiff            0.00421473
2017-06-03 13:45:31.110754 EDT | AverageAction               0.00667933
2017-06-03 13:45:31.110989 EDT | PolicyRegParamNorm         43.9186
2017-06-03 13:45:31.111219 EDT | QFunRegParamNorm           22.7561
2017-06-03 13:45:31.111449 EDT | -----------------------  --------------
2017-06-03 13:45:31.111852 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #125 | Training started
2017-06-03 13:45:49.933168 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #125 | Training finished
2017-06-03 13:45:49.934167 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #125 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 13:45:49.934555 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #125 | Collecting samples for evaluation
2017-06-03 13:46:01.052091 EDT | -----------------------  --------------
2017-06-03 13:46:01.052470 EDT | Epoch                     125
2017-06-03 13:46:01.052723 EDT | Iteration                 125
2017-06-03 13:46:01.052964 EDT | AverageReturn            1000
2017-06-03 13:46:01.053199 EDT | StdReturn                   0
2017-06-03 13:46:01.053432 EDT | MaxReturn                1000
2017-06-03 13:46:01.053669 EDT | MinReturn                1000
2017-06-03 13:46:01.053915 EDT | AverageEsReturn            16.7333
2017-06-03 13:46:01.054197 EDT | StdEsReturn                15.4649
2017-06-03 13:46:01.054432 EDT | MaxEsReturn                64
2017-06-03 13:46:01.054666 EDT | MinEsReturn                 3
2017-06-03 13:46:01.054898 EDT | AverageDiscountedReturn    99.9957
2017-06-03 13:46:01.055140 EDT | AverageQLoss                0.000134565
2017-06-03 13:46:01.055378 EDT | AveragePolicySurr          -0.177602
2017-06-03 13:46:01.055611 EDT | AverageQ                    0.16375
2017-06-03 13:46:01.055841 EDT | AverageAbsQ                 0.16441
2017-06-03 13:46:01.056072 EDT | AverageY                    0.163743
2017-06-03 13:46:01.056304 EDT | AverageAbsY                 0.163946
2017-06-03 13:46:01.056535 EDT | AverageAbsQYDiff            0.00445467
2017-06-03 13:46:01.056766 EDT | AverageAction               0.00785564
2017-06-03 13:46:01.056997 EDT | PolicyRegParamNorm         44.012
2017-06-03 13:46:01.057227 EDT | QFunRegParamNorm           22.7804
2017-06-03 13:46:01.057457 EDT | -----------------------  --------------
2017-06-03 13:46:01.057902 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #126 | Training started
2017-06-03 13:46:20.612446 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #126 | Training finished
2017-06-03 13:46:20.613742 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #126 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 13:46:20.614016 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #126 | Collecting samples for evaluation
2017-06-03 13:46:31.965576 EDT | -----------------------  --------------
2017-06-03 13:46:31.966425 EDT | Epoch                     126
2017-06-03 13:46:31.966687 EDT | Iteration                 126
2017-06-03 13:46:31.966928 EDT | AverageReturn            1000
2017-06-03 13:46:31.967166 EDT | StdReturn                   0
2017-06-03 13:46:31.967400 EDT | MaxReturn                1000
2017-06-03 13:46:31.967638 EDT | MinReturn                1000
2017-06-03 13:46:31.967871 EDT | AverageEsReturn            15.5385
2017-06-03 13:46:31.968104 EDT | StdEsReturn                16.5046
2017-06-03 13:46:31.968335 EDT | MaxEsReturn                89
2017-06-03 13:46:31.968584 EDT | MinEsReturn                 3
2017-06-03 13:46:31.968817 EDT | AverageDiscountedReturn    99.9957
2017-06-03 13:46:31.969047 EDT | AverageQLoss                0.000138734
2017-06-03 13:46:31.969277 EDT | AveragePolicySurr          -0.182022
2017-06-03 13:46:31.969511 EDT | AverageQ                    0.167462
2017-06-03 13:46:31.969777 EDT | AverageAbsQ                 0.168101
2017-06-03 13:46:31.970014 EDT | AverageY                    0.167479
2017-06-03 13:46:31.970246 EDT | AverageAbsY                 0.167713
2017-06-03 13:46:31.970477 EDT | AverageAbsQYDiff            0.00452112
2017-06-03 13:46:31.970714 EDT | AverageAction               0.00656175
2017-06-03 13:46:31.970946 EDT | PolicyRegParamNorm         44.1634
2017-06-03 13:46:31.971177 EDT | QFunRegParamNorm           22.8116
2017-06-03 13:46:31.971431 EDT | -----------------------  --------------
2017-06-03 13:46:31.971811 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #127 | Training started
2017-06-03 13:46:52.206938 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #127 | Training finished
2017-06-03 13:46:52.207853 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #127 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 13:46:52.208129 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #127 | Collecting samples for evaluation
2017-06-03 13:47:03.086763 EDT | -----------------------  --------------
2017-06-03 13:47:03.087575 EDT | Epoch                     127
2017-06-03 13:47:03.087838 EDT | Iteration                 127
2017-06-03 13:47:03.088074 EDT | AverageReturn            1000
2017-06-03 13:47:03.088303 EDT | StdReturn                   0
2017-06-03 13:47:03.088531 EDT | MaxReturn                1000
2017-06-03 13:47:03.088757 EDT | MinReturn                1000
2017-06-03 13:47:03.088982 EDT | AverageEsReturn            17.386
2017-06-03 13:47:03.089208 EDT | StdEsReturn                19.7046
2017-06-03 13:47:03.089432 EDT | MaxEsReturn                86
2017-06-03 13:47:03.089657 EDT | MinEsReturn                 3
2017-06-03 13:47:03.089892 EDT | AverageDiscountedReturn    99.9957
2017-06-03 13:47:03.090115 EDT | AverageQLoss                0.000164036
2017-06-03 13:47:03.090353 EDT | AveragePolicySurr          -0.185317
2017-06-03 13:47:03.090629 EDT | AverageQ                    0.170415
2017-06-03 13:47:03.090891 EDT | AverageAbsQ                 0.17107
2017-06-03 13:47:03.091120 EDT | AverageY                    0.170411
2017-06-03 13:47:03.091363 EDT | AverageAbsY                 0.170523
2017-06-03 13:47:03.091626 EDT | AverageAbsQYDiff            0.00492286
2017-06-03 13:47:03.091860 EDT | AverageAction               0.0063769
2017-06-03 13:47:03.092085 EDT | PolicyRegParamNorm         44.2129
2017-06-03 13:47:03.092308 EDT | QFunRegParamNorm           22.8484
2017-06-03 13:47:03.092522 EDT | -----------------------  --------------
2017-06-03 13:47:03.092903 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #128 | Training started
2017-06-03 13:47:21.477492 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #128 | Training finished
2017-06-03 13:47:21.478464 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #128 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 13:47:21.478887 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #128 | Collecting samples for evaluation
2017-06-03 13:47:30.887653 EDT | -----------------------  --------------
2017-06-03 13:47:30.888519 EDT | Epoch                     128
2017-06-03 13:47:30.888789 EDT | Iteration                 128
2017-06-03 13:47:30.889033 EDT | AverageReturn            1000
2017-06-03 13:47:30.889284 EDT | StdReturn                   0
2017-06-03 13:47:30.889516 EDT | MaxReturn                1000
2017-06-03 13:47:30.889775 EDT | MinReturn                1000
2017-06-03 13:47:30.890021 EDT | AverageEsReturn            15.125
2017-06-03 13:47:30.890268 EDT | StdEsReturn                15.594
2017-06-03 13:47:30.890512 EDT | MaxEsReturn                63
2017-06-03 13:47:30.890809 EDT | MinEsReturn                 3
2017-06-03 13:47:30.891056 EDT | AverageDiscountedReturn    99.9957
2017-06-03 13:47:30.891299 EDT | AverageQLoss                0.000132018
2017-06-03 13:47:30.891543 EDT | AveragePolicySurr          -0.189077
2017-06-03 13:47:30.891785 EDT | AverageQ                    0.173504
2017-06-03 13:47:30.892037 EDT | AverageAbsQ                 0.174071
2017-06-03 13:47:30.892278 EDT | AverageY                    0.173513
2017-06-03 13:47:30.892519 EDT | AverageAbsY                 0.173657
2017-06-03 13:47:30.892761 EDT | AverageAbsQYDiff            0.00445451
2017-06-03 13:47:30.893002 EDT | AverageAction               0.00688654
2017-06-03 13:47:30.893242 EDT | PolicyRegParamNorm         44.316
2017-06-03 13:47:30.893484 EDT | QFunRegParamNorm           22.9121
2017-06-03 13:47:30.893731 EDT | -----------------------  --------------
2017-06-03 13:47:30.894132 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #129 | Training started
2017-06-03 13:47:50.636409 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #129 | Training finished
2017-06-03 13:47:50.637372 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #129 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 13:47:50.637836 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #129 | Collecting samples for evaluation
2017-06-03 13:48:00.221058 EDT | -----------------------  --------------
2017-06-03 13:48:00.222001 EDT | Epoch                     129
2017-06-03 13:48:00.222291 EDT | Iteration                 129
2017-06-03 13:48:00.222598 EDT | AverageReturn            1000
2017-06-03 13:48:00.222929 EDT | StdReturn                   0
2017-06-03 13:48:00.223197 EDT | MaxReturn                1000
2017-06-03 13:48:00.223437 EDT | MinReturn                1000
2017-06-03 13:48:00.223755 EDT | AverageEsReturn            16.8475
2017-06-03 13:48:00.224066 EDT | StdEsReturn                21.4047
2017-06-03 13:48:00.224316 EDT | MaxEsReturn               112
2017-06-03 13:48:00.224587 EDT | MinEsReturn                 3
2017-06-03 13:48:00.224910 EDT | AverageDiscountedReturn    99.9957
2017-06-03 13:48:00.225188 EDT | AverageQLoss                0.000150615
2017-06-03 13:48:00.225462 EDT | AveragePolicySurr          -0.193284
2017-06-03 13:48:00.225835 EDT | AverageQ                    0.176947
2017-06-03 13:48:00.226165 EDT | AverageAbsQ                 0.177539
2017-06-03 13:48:00.226422 EDT | AverageY                    0.176962
2017-06-03 13:48:00.226715 EDT | AverageAbsY                 0.177101
2017-06-03 13:48:00.227056 EDT | AverageAbsQYDiff            0.00476545
2017-06-03 13:48:00.227356 EDT | AverageAction               0.00943082
2017-06-03 13:48:00.227609 EDT | PolicyRegParamNorm         44.5012
2017-06-03 13:48:00.227942 EDT | QFunRegParamNorm           22.9497
2017-06-03 13:48:00.228266 EDT | -----------------------  --------------
2017-06-03 13:48:00.228703 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #130 | Training started
2017-06-03 13:48:18.664025 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #130 | Training finished
2017-06-03 13:48:18.664998 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #130 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 13:48:18.665285 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #130 | Collecting samples for evaluation
2017-06-03 13:48:29.791821 EDT | -----------------------  -------------
2017-06-03 13:48:29.792691 EDT | Epoch                     130
2017-06-03 13:48:29.792952 EDT | Iteration                 130
2017-06-03 13:48:29.793205 EDT | AverageReturn            1000
2017-06-03 13:48:29.793438 EDT | StdReturn                   0
2017-06-03 13:48:29.793669 EDT | MaxReturn                1000
2017-06-03 13:48:29.793911 EDT | MinReturn                1000
2017-06-03 13:48:29.794181 EDT | AverageEsReturn            15.6818
2017-06-03 13:48:29.794414 EDT | StdEsReturn                16.2538
2017-06-03 13:48:29.794657 EDT | MaxEsReturn                71
2017-06-03 13:48:29.794888 EDT | MinEsReturn                 3
2017-06-03 13:48:29.795116 EDT | AverageDiscountedReturn    99.9957
2017-06-03 13:48:29.795342 EDT | AverageQLoss                0.00016124
2017-06-03 13:48:29.795568 EDT | AveragePolicySurr          -0.197548
2017-06-03 13:48:29.795808 EDT | AverageQ                    0.181029
2017-06-03 13:48:29.796033 EDT | AverageAbsQ                 0.181744
2017-06-03 13:48:29.796264 EDT | AverageY                    0.181031
2017-06-03 13:48:29.796489 EDT | AverageAbsY                 0.181185
2017-06-03 13:48:29.796712 EDT | AverageAbsQYDiff            0.0049067
2017-06-03 13:48:29.796937 EDT | AverageAction               0.00971973
2017-06-03 13:48:29.797162 EDT | PolicyRegParamNorm         44.5737
2017-06-03 13:48:29.797387 EDT | QFunRegParamNorm           23.0044
2017-06-03 13:48:29.797611 EDT | -----------------------  -------------
2017-06-03 13:48:29.798050 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #131 | Training started
2017-06-03 13:48:48.970711 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #131 | Training finished
2017-06-03 13:48:48.971684 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #131 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 13:48:48.972064 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #131 | Collecting samples for evaluation
2017-06-03 13:48:59.788205 EDT | -----------------------  --------------
2017-06-03 13:48:59.789048 EDT | Epoch                     131
2017-06-03 13:48:59.789315 EDT | Iteration                 131
2017-06-03 13:48:59.789605 EDT | AverageReturn            1000
2017-06-03 13:48:59.789861 EDT | StdReturn                   0
2017-06-03 13:48:59.790102 EDT | MaxReturn                1000
2017-06-03 13:48:59.790341 EDT | MinReturn                1000
2017-06-03 13:48:59.790590 EDT | AverageEsReturn            21.7609
2017-06-03 13:48:59.790832 EDT | StdEsReturn                35.1068
2017-06-03 13:48:59.791071 EDT | MaxEsReturn               157
2017-06-03 13:48:59.791309 EDT | MinEsReturn                 3
2017-06-03 13:48:59.791545 EDT | AverageDiscountedReturn    99.9957
2017-06-03 13:48:59.791783 EDT | AverageQLoss                0.000184862
2017-06-03 13:48:59.792018 EDT | AveragePolicySurr          -0.201277
2017-06-03 13:48:59.792254 EDT | AverageQ                    0.184217
2017-06-03 13:48:59.792492 EDT | AverageAbsQ                 0.184942
2017-06-03 13:48:59.792728 EDT | AverageY                    0.184207
2017-06-03 13:48:59.792966 EDT | AverageAbsY                 0.184346
2017-06-03 13:48:59.793203 EDT | AverageAbsQYDiff            0.00523562
2017-06-03 13:48:59.793439 EDT | AverageAction               0.0113661
2017-06-03 13:48:59.793676 EDT | PolicyRegParamNorm         44.711
2017-06-03 13:48:59.794505 EDT | QFunRegParamNorm           23.0369
2017-06-03 13:48:59.794765 EDT | -----------------------  --------------
2017-06-03 13:48:59.795295 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #132 | Training started
2017-06-03 13:49:19.303491 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #132 | Training finished
2017-06-03 13:49:19.304440 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #132 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 13:49:19.304919 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #132 | Collecting samples for evaluation
2017-06-03 13:49:29.140049 EDT | -----------------------  --------------
2017-06-03 13:49:29.140969 EDT | Epoch                     132
2017-06-03 13:49:29.141235 EDT | Iteration                 132
2017-06-03 13:49:29.141484 EDT | AverageReturn            1000
2017-06-03 13:49:29.141724 EDT | StdReturn                   0
2017-06-03 13:49:29.141957 EDT | MaxReturn                1000
2017-06-03 13:49:29.142187 EDT | MinReturn                1000
2017-06-03 13:49:29.142417 EDT | AverageEsReturn            28.9143
2017-06-03 13:49:29.142659 EDT | StdEsReturn                32.5632
2017-06-03 13:49:29.142886 EDT | MaxEsReturn               167
2017-06-03 13:49:29.143113 EDT | MinEsReturn                 3
2017-06-03 13:49:29.143339 EDT | AverageDiscountedReturn    99.9957
2017-06-03 13:49:29.143562 EDT | AverageQLoss                0.000177817
2017-06-03 13:49:29.143788 EDT | AveragePolicySurr          -0.206829
2017-06-03 13:49:29.144014 EDT | AverageQ                    0.188565
2017-06-03 13:49:29.144240 EDT | AverageAbsQ                 0.189247
2017-06-03 13:49:29.144463 EDT | AverageY                    0.188577
2017-06-03 13:49:29.144689 EDT | AverageAbsY                 0.188722
2017-06-03 13:49:29.144919 EDT | AverageAbsQYDiff            0.00511952
2017-06-03 13:49:29.145144 EDT | AverageAction               0.0303887
2017-06-03 13:49:29.145378 EDT | PolicyRegParamNorm         44.7678
2017-06-03 13:49:29.145606 EDT | QFunRegParamNorm           23.0836
2017-06-03 13:49:29.145850 EDT | -----------------------  --------------
2017-06-03 13:49:29.146257 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #133 | Training started
2017-06-03 13:49:47.779397 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #133 | Training finished
2017-06-03 13:49:47.780375 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #133 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 13:49:47.780867 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #133 | Collecting samples for evaluation
2017-06-03 13:49:57.697098 EDT | -----------------------  --------------
2017-06-03 13:49:57.698273 EDT | Epoch                     133
2017-06-03 13:49:57.698549 EDT | Iteration                 133
2017-06-03 13:49:57.698789 EDT | AverageReturn            1000
2017-06-03 13:49:57.699032 EDT | StdReturn                   0
2017-06-03 13:49:57.699264 EDT | MaxReturn                1000
2017-06-03 13:49:57.699493 EDT | MinReturn                1000
2017-06-03 13:49:57.699720 EDT | AverageEsReturn            13.4444
2017-06-03 13:49:57.699948 EDT | StdEsReturn                17.1892
2017-06-03 13:49:57.700173 EDT | MaxEsReturn                87
2017-06-03 13:49:57.700398 EDT | MinEsReturn                 3
2017-06-03 13:49:57.700621 EDT | AverageDiscountedReturn    99.9957
2017-06-03 13:49:57.700851 EDT | AverageQLoss                0.000186963
2017-06-03 13:49:57.701242 EDT | AveragePolicySurr          -0.210782
2017-06-03 13:49:57.701622 EDT | AverageQ                    0.192199
2017-06-03 13:49:57.701995 EDT | AverageAbsQ                 0.192775
2017-06-03 13:49:57.702269 EDT | AverageY                    0.192217
2017-06-03 13:49:57.702527 EDT | AverageAbsY                 0.192308
2017-06-03 13:49:57.702783 EDT | AverageAbsQYDiff            0.00531658
2017-06-03 13:49:57.703047 EDT | AverageAction               0.00691077
2017-06-03 13:49:57.703385 EDT | PolicyRegParamNorm         44.9137
2017-06-03 13:49:57.703811 EDT | QFunRegParamNorm           23.1214
2017-06-03 13:49:57.704141 EDT | -----------------------  --------------
2017-06-03 13:49:57.704692 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #134 | Training started
2017-06-03 13:50:16.354230 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #134 | Training finished
2017-06-03 13:50:16.355095 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #134 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 13:50:16.355361 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #134 | Collecting samples for evaluation
2017-06-03 13:50:25.819984 EDT | -----------------------  --------------
2017-06-03 13:50:25.820996 EDT | Epoch                     134
2017-06-03 13:50:25.821274 EDT | Iteration                 134
2017-06-03 13:50:25.821524 EDT | AverageReturn            1000
2017-06-03 13:50:25.821778 EDT | StdReturn                   0
2017-06-03 13:50:25.822021 EDT | MaxReturn                1000
2017-06-03 13:50:25.822271 EDT | MinReturn                1000
2017-06-03 13:50:25.822510 EDT | AverageEsReturn            19.4528
2017-06-03 13:50:25.822749 EDT | StdEsReturn                23.6704
2017-06-03 13:50:25.822986 EDT | MaxEsReturn                98
2017-06-03 13:50:25.823224 EDT | MinEsReturn                 3
2017-06-03 13:50:25.823461 EDT | AverageDiscountedReturn    99.9957
2017-06-03 13:50:25.823701 EDT | AverageQLoss                0.000221989
2017-06-03 13:50:25.823940 EDT | AveragePolicySurr          -0.217126
2017-06-03 13:50:25.824216 EDT | AverageQ                    0.19768
2017-06-03 13:50:25.824465 EDT | AverageAbsQ                 0.198228
2017-06-03 13:50:25.824706 EDT | AverageY                    0.197672
2017-06-03 13:50:25.824946 EDT | AverageAbsY                 0.19773
2017-06-03 13:50:25.825184 EDT | AverageAbsQYDiff            0.00567938
2017-06-03 13:50:25.825433 EDT | AverageAction               0.0167977
2017-06-03 13:50:25.825675 EDT | PolicyRegParamNorm         45.0086
2017-06-03 13:50:25.825930 EDT | QFunRegParamNorm           23.1681
2017-06-03 13:50:25.826170 EDT | -----------------------  --------------
2017-06-03 13:50:25.826558 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #135 | Training started
2017-06-03 13:50:44.939626 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #135 | Training finished
2017-06-03 13:50:44.940486 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #135 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 13:50:44.940771 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #135 | Collecting samples for evaluation
2017-06-03 13:50:54.730067 EDT | -----------------------  --------------
2017-06-03 13:50:54.730941 EDT | Epoch                     135
2017-06-03 13:50:54.731314 EDT | Iteration                 135
2017-06-03 13:50:54.731662 EDT | AverageReturn            1000
2017-06-03 13:50:54.731961 EDT | StdReturn                   0
2017-06-03 13:50:54.732195 EDT | MaxReturn                1000
2017-06-03 13:50:54.732419 EDT | MinReturn                1000
2017-06-03 13:50:54.732640 EDT | AverageEsReturn            18.8846
2017-06-03 13:50:54.732861 EDT | StdEsReturn                23.1804
2017-06-03 13:50:54.733090 EDT | MaxEsReturn               103
2017-06-03 13:50:54.733315 EDT | MinEsReturn                 3
2017-06-03 13:50:54.733542 EDT | AverageDiscountedReturn    99.9957
2017-06-03 13:50:54.733778 EDT | AverageQLoss                0.000207509
2017-06-03 13:50:54.734013 EDT | AveragePolicySurr          -0.221646
2017-06-03 13:50:54.734233 EDT | AverageQ                    0.202357
2017-06-03 13:50:54.734461 EDT | AverageAbsQ                 0.202953
2017-06-03 13:50:54.734683 EDT | AverageY                    0.202364
2017-06-03 13:50:54.734905 EDT | AverageAbsY                 0.202473
2017-06-03 13:50:54.735132 EDT | AverageAbsQYDiff            0.00554672
2017-06-03 13:50:54.735357 EDT | AverageAction               0.624464
2017-06-03 13:50:54.735587 EDT | PolicyRegParamNorm         45.0768
2017-06-03 13:50:54.735823 EDT | QFunRegParamNorm           23.2526
2017-06-03 13:50:54.736051 EDT | -----------------------  --------------
2017-06-03 13:50:54.736406 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #136 | Training started
2017-06-03 13:51:13.385802 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #136 | Training finished
2017-06-03 13:51:13.388466 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #136 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 13:51:13.389000 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #136 | Collecting samples for evaluation
2017-06-03 13:51:22.912705 EDT | -----------------------  --------------
2017-06-03 13:51:22.913752 EDT | Epoch                     136
2017-06-03 13:51:22.914138 EDT | Iteration                 136
2017-06-03 13:51:22.914494 EDT | AverageReturn            1000
2017-06-03 13:51:22.914851 EDT | StdReturn                   0
2017-06-03 13:51:22.915188 EDT | MaxReturn                1000
2017-06-03 13:51:22.915534 EDT | MinReturn                1000
2017-06-03 13:51:22.915886 EDT | AverageEsReturn            23.1818
2017-06-03 13:51:22.916229 EDT | StdEsReturn                24.6561
2017-06-03 13:51:22.916561 EDT | MaxEsReturn               133
2017-06-03 13:51:22.916970 EDT | MinEsReturn                 3
2017-06-03 13:51:22.917304 EDT | AverageDiscountedReturn    99.9957
2017-06-03 13:51:22.917632 EDT | AverageQLoss                0.000208193
2017-06-03 13:51:22.918018 EDT | AveragePolicySurr          -0.227133
2017-06-03 13:51:22.918361 EDT | AverageQ                    0.206926
2017-06-03 13:51:22.918705 EDT | AverageAbsQ                 0.207613
2017-06-03 13:51:22.919033 EDT | AverageY                    0.206931
2017-06-03 13:51:22.919369 EDT | AverageAbsY                 0.207108
2017-06-03 13:51:22.919705 EDT | AverageAbsQYDiff            0.00562388
2017-06-03 13:51:22.920034 EDT | AverageAction               0.502627
2017-06-03 13:51:22.920367 EDT | PolicyRegParamNorm         45.2563
2017-06-03 13:51:22.920679 EDT | QFunRegParamNorm           23.3055
2017-06-03 13:51:22.920991 EDT | -----------------------  --------------
2017-06-03 13:51:22.921568 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #137 | Training started
2017-06-03 13:51:41.497056 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #137 | Training finished
2017-06-03 13:51:41.497982 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #137 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 13:51:41.498254 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #137 | Collecting samples for evaluation
2017-06-03 13:51:50.763016 EDT | -----------------------  --------------
2017-06-03 13:51:50.764025 EDT | Epoch                     137
2017-06-03 13:51:50.764315 EDT | Iteration                 137
2017-06-03 13:51:50.764553 EDT | AverageReturn            1000
2017-06-03 13:51:50.764788 EDT | StdReturn                   0
2017-06-03 13:51:50.765262 EDT | MaxReturn                1000
2017-06-03 13:51:50.765583 EDT | MinReturn                1000
2017-06-03 13:51:50.765940 EDT | AverageEsReturn            20.8333
2017-06-03 13:51:50.766266 EDT | StdEsReturn                19.1793
2017-06-03 13:51:50.766597 EDT | MaxEsReturn                85
2017-06-03 13:51:50.766914 EDT | MinEsReturn                 3
2017-06-03 13:51:50.767241 EDT | AverageDiscountedReturn    99.9957
2017-06-03 13:51:50.767567 EDT | AverageQLoss                0.000246459
2017-06-03 13:51:50.767893 EDT | AveragePolicySurr          -0.231769
2017-06-03 13:51:50.768237 EDT | AverageQ                    0.210774
2017-06-03 13:51:50.768549 EDT | AverageAbsQ                 0.211526
2017-06-03 13:51:50.768860 EDT | AverageY                    0.210781
2017-06-03 13:51:50.769189 EDT | AverageAbsY                 0.210975
2017-06-03 13:51:50.769510 EDT | AverageAbsQYDiff            0.00596118
2017-06-03 13:51:50.769852 EDT | AverageAction               0.604186
2017-06-03 13:51:50.770183 EDT | PolicyRegParamNorm         45.3806
2017-06-03 13:51:50.770497 EDT | QFunRegParamNorm           23.3623
2017-06-03 13:51:50.770814 EDT | -----------------------  --------------
2017-06-03 13:51:50.771324 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #138 | Training started
2017-06-03 13:52:08.781725 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #138 | Training finished
2017-06-03 13:52:08.782642 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #138 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 13:52:08.782990 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #138 | Collecting samples for evaluation
2017-06-03 13:52:18.956521 EDT | -----------------------  --------------
2017-06-03 13:52:18.956891 EDT | Epoch                     138
2017-06-03 13:52:18.957164 EDT | Iteration                 138
2017-06-03 13:52:18.957424 EDT | AverageReturn            1000
2017-06-03 13:52:18.957669 EDT | StdReturn                   0
2017-06-03 13:52:18.957941 EDT | MaxReturn                1000
2017-06-03 13:52:18.958204 EDT | MinReturn                1000
2017-06-03 13:52:18.958464 EDT | AverageEsReturn            16.1129
2017-06-03 13:52:18.958702 EDT | StdEsReturn                20.1703
2017-06-03 13:52:18.958960 EDT | MaxEsReturn               114
2017-06-03 13:52:18.959223 EDT | MinEsReturn                 3
2017-06-03 13:52:18.959473 EDT | AverageDiscountedReturn    99.9957
2017-06-03 13:52:18.959707 EDT | AverageQLoss                0.000197141
2017-06-03 13:52:18.959963 EDT | AveragePolicySurr          -0.237636
2017-06-03 13:52:18.960225 EDT | AverageQ                    0.216536
2017-06-03 13:52:18.960476 EDT | AverageAbsQ                 0.217114
2017-06-03 13:52:18.960709 EDT | AverageY                    0.216567
2017-06-03 13:52:18.960964 EDT | AverageAbsY                 0.216713
2017-06-03 13:52:18.961222 EDT | AverageAbsQYDiff            0.00541174
2017-06-03 13:52:18.961478 EDT | AverageAction               0.590947
2017-06-03 13:52:18.961724 EDT | PolicyRegParamNorm         45.5192
2017-06-03 13:52:18.961984 EDT | QFunRegParamNorm           23.4079
2017-06-03 13:52:18.962249 EDT | -----------------------  --------------
2017-06-03 13:52:18.962618 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #139 | Training started
2017-06-03 13:52:37.868946 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #139 | Training finished
2017-06-03 13:52:37.869809 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #139 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 13:52:37.870086 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #139 | Collecting samples for evaluation
2017-06-03 13:52:47.481759 EDT | -----------------------  --------------
2017-06-03 13:52:47.482161 EDT | Epoch                     139
2017-06-03 13:52:47.482415 EDT | Iteration                 139
2017-06-03 13:52:47.482657 EDT | AverageReturn            1000
2017-06-03 13:52:47.482893 EDT | StdReturn                   0
2017-06-03 13:52:47.483127 EDT | MaxReturn                1000
2017-06-03 13:52:47.483385 EDT | MinReturn                1000
2017-06-03 13:52:47.483619 EDT | AverageEsReturn            24.9487
2017-06-03 13:52:47.483854 EDT | StdEsReturn                32.5103
2017-06-03 13:52:47.484087 EDT | MaxEsReturn               139
2017-06-03 13:52:47.484318 EDT | MinEsReturn                 3
2017-06-03 13:52:47.484563 EDT | AverageDiscountedReturn    99.9957
2017-06-03 13:52:47.484798 EDT | AverageQLoss                0.000222227
2017-06-03 13:52:47.485030 EDT | AveragePolicySurr          -0.242945
2017-06-03 13:52:47.485261 EDT | AverageQ                    0.221594
2017-06-03 13:52:47.485492 EDT | AverageAbsQ                 0.222363
2017-06-03 13:52:47.485790 EDT | AverageY                    0.221592
2017-06-03 13:52:47.486076 EDT | AverageAbsY                 0.221789
2017-06-03 13:52:47.486309 EDT | AverageAbsQYDiff            0.00584682
2017-06-03 13:52:47.486540 EDT | AverageAction               0.687533
2017-06-03 13:52:47.486771 EDT | PolicyRegParamNorm         45.6278
2017-06-03 13:52:47.487006 EDT | QFunRegParamNorm           23.4663
2017-06-03 13:52:47.487245 EDT | -----------------------  --------------
2017-06-03 13:52:47.487608 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #140 | Training started
2017-06-03 13:53:06.091725 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #140 | Training finished
2017-06-03 13:53:06.093190 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #140 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 13:53:06.093469 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #140 | Collecting samples for evaluation
2017-06-03 13:53:16.092275 EDT | -----------------------  --------------
2017-06-03 13:53:16.093123 EDT | Epoch                     140
2017-06-03 13:53:16.093402 EDT | Iteration                 140
2017-06-03 13:53:16.093640 EDT | AverageReturn            1000
2017-06-03 13:53:16.093885 EDT | StdReturn                   0
2017-06-03 13:53:16.094112 EDT | MaxReturn                1000
2017-06-03 13:53:16.094350 EDT | MinReturn                1000
2017-06-03 13:53:16.094600 EDT | AverageEsReturn            28.7143
2017-06-03 13:53:16.094856 EDT | StdEsReturn                28.9113
2017-06-03 13:53:16.095084 EDT | MaxEsReturn               100
2017-06-03 13:53:16.095311 EDT | MinEsReturn                 3
2017-06-03 13:53:16.095562 EDT | AverageDiscountedReturn    99.9957
2017-06-03 13:53:16.095801 EDT | AverageQLoss                0.000258453
2017-06-03 13:53:16.096028 EDT | AveragePolicySurr          -0.247898
2017-06-03 13:53:16.096265 EDT | AverageQ                    0.226581
2017-06-03 13:53:16.096514 EDT | AverageAbsQ                 0.227351
2017-06-03 13:53:16.096747 EDT | AverageY                    0.226595
2017-06-03 13:53:16.096976 EDT | AverageAbsY                 0.226812
2017-06-03 13:53:16.097204 EDT | AverageAbsQYDiff            0.00625422
2017-06-03 13:53:16.097432 EDT | AverageAction               0.821991
2017-06-03 13:53:16.097686 EDT | PolicyRegParamNorm         45.7631
2017-06-03 13:53:16.097931 EDT | QFunRegParamNorm           23.4879
2017-06-03 13:53:16.098163 EDT | -----------------------  --------------
2017-06-03 13:53:16.098560 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #141 | Training started
2017-06-03 13:53:34.411422 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #141 | Training finished
2017-06-03 13:53:34.412504 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #141 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 13:53:34.412854 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #141 | Collecting samples for evaluation
2017-06-03 13:53:44.049573 EDT | -----------------------  --------------
2017-06-03 13:53:44.050480 EDT | Epoch                     141
2017-06-03 13:53:44.050741 EDT | Iteration                 141
2017-06-03 13:53:44.050984 EDT | AverageReturn            1000
2017-06-03 13:53:44.051230 EDT | StdReturn                   0
2017-06-03 13:53:44.051463 EDT | MaxReturn                1000
2017-06-03 13:53:44.051692 EDT | MinReturn                1000
2017-06-03 13:53:44.051921 EDT | AverageEsReturn            35.5185
2017-06-03 13:53:44.052151 EDT | StdEsReturn                25.7601
2017-06-03 13:53:44.052381 EDT | MaxEsReturn               108
2017-06-03 13:53:44.052612 EDT | MinEsReturn                 3
2017-06-03 13:53:44.052841 EDT | AverageDiscountedReturn    99.9957
2017-06-03 13:53:44.053068 EDT | AverageQLoss                0.000252942
2017-06-03 13:53:44.053296 EDT | AveragePolicySurr          -0.251625
2017-06-03 13:53:44.053524 EDT | AverageQ                    0.229958
2017-06-03 13:53:44.053762 EDT | AverageAbsQ                 0.230816
2017-06-03 13:53:44.053992 EDT | AverageY                    0.229978
2017-06-03 13:53:44.054219 EDT | AverageAbsY                 0.23014
2017-06-03 13:53:44.054447 EDT | AverageAbsQYDiff            0.00627242
2017-06-03 13:53:44.054673 EDT | AverageAction               0.794265
2017-06-03 13:53:44.054900 EDT | PolicyRegParamNorm         45.8608
2017-06-03 13:53:44.055127 EDT | QFunRegParamNorm           23.5233
2017-06-03 13:53:44.055354 EDT | -----------------------  --------------
2017-06-03 13:53:44.055724 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #142 | Training started
2017-06-03 13:54:04.315389 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #142 | Training finished
2017-06-03 13:54:04.316290 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #142 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 13:54:04.316721 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #142 | Collecting samples for evaluation
2017-06-03 13:54:13.969577 EDT | -----------------------  --------------
2017-06-03 13:54:13.970532 EDT | Epoch                     142
2017-06-03 13:54:13.970855 EDT | Iteration                 142
2017-06-03 13:54:13.971193 EDT | AverageReturn            1000
2017-06-03 13:54:13.971485 EDT | StdReturn                   0
2017-06-03 13:54:13.971756 EDT | MaxReturn                1000
2017-06-03 13:54:13.972064 EDT | MinReturn                1000
2017-06-03 13:54:13.972388 EDT | AverageEsReturn            29.1389
2017-06-03 13:54:13.972670 EDT | StdEsReturn                23.5397
2017-06-03 13:54:13.972944 EDT | MaxEsReturn                84
2017-06-03 13:54:13.973258 EDT | MinEsReturn                 3
2017-06-03 13:54:13.973580 EDT | AverageDiscountedReturn    99.9957
2017-06-03 13:54:13.973862 EDT | AverageQLoss                0.000243789
2017-06-03 13:54:13.974136 EDT | AveragePolicySurr          -0.255989
2017-06-03 13:54:13.974463 EDT | AverageQ                    0.234465
2017-06-03 13:54:13.974780 EDT | AverageAbsQ                 0.235192
2017-06-03 13:54:13.975049 EDT | AverageY                    0.234487
2017-06-03 13:54:13.975324 EDT | AverageAbsY                 0.234607
2017-06-03 13:54:13.975651 EDT | AverageAbsQYDiff            0.00598547
2017-06-03 13:54:13.975964 EDT | AverageAction               0.734794
2017-06-03 13:54:13.976230 EDT | PolicyRegParamNorm         45.9657
2017-06-03 13:54:13.976515 EDT | QFunRegParamNorm           23.4946
2017-06-03 13:54:13.976841 EDT | -----------------------  --------------
2017-06-03 13:54:13.977265 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #143 | Training started
2017-06-03 13:54:32.776208 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #143 | Training finished
2017-06-03 13:54:32.777081 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #143 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 13:54:32.777348 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #143 | Collecting samples for evaluation
2017-06-03 13:54:42.907383 EDT | -----------------------  --------------
2017-06-03 13:54:42.908263 EDT | Epoch                     143
2017-06-03 13:54:42.908520 EDT | Iteration                 143
2017-06-03 13:54:42.908760 EDT | AverageReturn            1000
2017-06-03 13:54:42.908995 EDT | StdReturn                   0
2017-06-03 13:54:42.909228 EDT | MaxReturn                1000
2017-06-03 13:54:42.909460 EDT | MinReturn                1000
2017-06-03 13:54:42.909687 EDT | AverageEsReturn            22.5778
2017-06-03 13:54:42.909931 EDT | StdEsReturn                23.2804
2017-06-03 13:54:42.910163 EDT | MaxEsReturn               108
2017-06-03 13:54:42.910421 EDT | MinEsReturn                 3
2017-06-03 13:54:42.910653 EDT | AverageDiscountedReturn    99.9957
2017-06-03 13:54:42.910881 EDT | AverageQLoss                0.000288484
2017-06-03 13:54:42.911110 EDT | AveragePolicySurr          -0.259042
2017-06-03 13:54:42.911340 EDT | AverageQ                    0.238401
2017-06-03 13:54:42.911585 EDT | AverageAbsQ                 0.239138
2017-06-03 13:54:42.911811 EDT | AverageY                    0.238392
2017-06-03 13:54:42.912040 EDT | AverageAbsY                 0.238533
2017-06-03 13:54:42.912269 EDT | AverageAbsQYDiff            0.00632171
2017-06-03 13:54:42.912498 EDT | AverageAction               0.857397
2017-06-03 13:54:42.912728 EDT | PolicyRegParamNorm         46.064
2017-06-03 13:54:42.912954 EDT | QFunRegParamNorm           23.5102
2017-06-03 13:54:42.913190 EDT | -----------------------  --------------
2017-06-03 13:54:42.913568 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #144 | Training started
2017-06-03 13:55:01.299083 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #144 | Training finished
2017-06-03 13:55:01.300000 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #144 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 13:55:01.300465 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #144 | Collecting samples for evaluation
2017-06-03 13:55:11.155800 EDT | -----------------------  --------------
2017-06-03 13:55:11.156642 EDT | Epoch                     144
2017-06-03 13:55:11.156913 EDT | Iteration                 144
2017-06-03 13:55:11.157165 EDT | AverageReturn            1000
2017-06-03 13:55:11.157412 EDT | StdReturn                   0
2017-06-03 13:55:11.157657 EDT | MaxReturn                1000
2017-06-03 13:55:11.157915 EDT | MinReturn                1000
2017-06-03 13:55:11.158159 EDT | AverageEsReturn            33.1667
2017-06-03 13:55:11.158404 EDT | StdEsReturn                31.1791
2017-06-03 13:55:11.158647 EDT | MaxEsReturn               118
2017-06-03 13:55:11.158889 EDT | MinEsReturn                 2
2017-06-03 13:55:11.159131 EDT | AverageDiscountedReturn    99.9957
2017-06-03 13:55:11.159373 EDT | AverageQLoss                0.000271864
2017-06-03 13:55:11.159614 EDT | AveragePolicySurr          -0.261498
2017-06-03 13:55:11.159855 EDT | AverageQ                    0.24071
2017-06-03 13:55:11.160096 EDT | AverageAbsQ                 0.241504
2017-06-03 13:55:11.160336 EDT | AverageY                    0.240723
2017-06-03 13:55:11.160577 EDT | AverageAbsY                 0.240887
2017-06-03 13:55:11.160818 EDT | AverageAbsQYDiff            0.00622851
2017-06-03 13:55:11.161058 EDT | AverageAction               0.666422
2017-06-03 13:55:11.161299 EDT | PolicyRegParamNorm         46.1854
2017-06-03 13:55:11.161540 EDT | QFunRegParamNorm           23.5698
2017-06-03 13:55:11.161792 EDT | -----------------------  --------------
2017-06-03 13:55:11.162148 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #145 | Training started
2017-06-03 13:55:29.068199 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #145 | Training finished
2017-06-03 13:55:29.068525 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #145 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 13:55:29.068777 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #145 | Collecting samples for evaluation
2017-06-03 13:55:37.322667 EDT | -----------------------  --------------
2017-06-03 13:55:37.323546 EDT | Epoch                     145
2017-06-03 13:55:37.323841 EDT | Iteration                 145
2017-06-03 13:55:37.324125 EDT | AverageReturn            1000
2017-06-03 13:55:37.324367 EDT | StdReturn                   0
2017-06-03 13:55:37.324625 EDT | MaxReturn                1000
2017-06-03 13:55:37.324880 EDT | MinReturn                1000
2017-06-03 13:55:37.325146 EDT | AverageEsReturn            30.625
2017-06-03 13:55:37.325388 EDT | StdEsReturn                34.3727
2017-06-03 13:55:37.325651 EDT | MaxEsReturn               189
2017-06-03 13:55:37.325929 EDT | MinEsReturn                 3
2017-06-03 13:55:37.326171 EDT | AverageDiscountedReturn    99.9957
2017-06-03 13:55:37.326415 EDT | AverageQLoss                0.000247726
2017-06-03 13:55:37.326675 EDT | AveragePolicySurr          -0.263452
2017-06-03 13:55:37.326938 EDT | AverageQ                    0.243172
2017-06-03 13:55:37.327177 EDT | AverageAbsQ                 0.243982
2017-06-03 13:55:37.327429 EDT | AverageY                    0.243192
2017-06-03 13:55:37.327695 EDT | AverageAbsY                 0.243376
2017-06-03 13:55:37.327975 EDT | AverageAbsQYDiff            0.00586291
2017-06-03 13:55:37.328209 EDT | AverageAction               0.678349
2017-06-03 13:55:37.328468 EDT | PolicyRegParamNorm         46.2761
2017-06-03 13:55:37.328731 EDT | QFunRegParamNorm           23.6123
2017-06-03 13:55:37.328982 EDT | -----------------------  --------------
2017-06-03 13:55:37.329477 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #146 | Training started
2017-06-03 13:55:56.854185 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #146 | Training finished
2017-06-03 13:55:56.855067 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #146 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 13:55:56.855471 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #146 | Collecting samples for evaluation
2017-06-03 13:56:06.526503 EDT | -----------------------  --------------
2017-06-03 13:56:06.527381 EDT | Epoch                     146
2017-06-03 13:56:06.527648 EDT | Iteration                 146
2017-06-03 13:56:06.527895 EDT | AverageReturn            1000
2017-06-03 13:56:06.528141 EDT | StdReturn                   0
2017-06-03 13:56:06.528382 EDT | MaxReturn                1000
2017-06-03 13:56:06.528616 EDT | MinReturn                1000
2017-06-03 13:56:06.528854 EDT | AverageEsReturn            24.2143
2017-06-03 13:56:06.529088 EDT | StdEsReturn                24.9815
2017-06-03 13:56:06.529320 EDT | MaxEsReturn               114
2017-06-03 13:56:06.529550 EDT | MinEsReturn                 3
2017-06-03 13:56:06.529802 EDT | AverageDiscountedReturn    99.9957
2017-06-03 13:56:06.530035 EDT | AverageQLoss                0.000237124
2017-06-03 13:56:06.530267 EDT | AveragePolicySurr          -0.266221
2017-06-03 13:56:06.530504 EDT | AverageQ                    0.245761
2017-06-03 13:56:06.530732 EDT | AverageAbsQ                 0.246504
2017-06-03 13:56:06.530963 EDT | AverageY                    0.245772
2017-06-03 13:56:06.531194 EDT | AverageAbsY                 0.24598
2017-06-03 13:56:06.531423 EDT | AverageAbsQYDiff            0.00574138
2017-06-03 13:56:06.531658 EDT | AverageAction               0.70814
2017-06-03 13:56:06.531889 EDT | PolicyRegParamNorm         46.3253
2017-06-03 13:56:06.532117 EDT | QFunRegParamNorm           23.6654
2017-06-03 13:56:06.532343 EDT | -----------------------  --------------
2017-06-03 13:56:06.532698 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #147 | Training started
2017-06-03 13:56:25.053928 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #147 | Training finished
2017-06-03 13:56:25.054817 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #147 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 13:56:25.055098 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #147 | Collecting samples for evaluation
2017-06-03 13:56:35.125124 EDT | -----------------------  --------------
2017-06-03 13:56:35.125971 EDT | Epoch                     147
2017-06-03 13:56:35.126241 EDT | Iteration                 147
2017-06-03 13:56:35.126483 EDT | AverageReturn            1000
2017-06-03 13:56:35.126717 EDT | StdReturn                   0
2017-06-03 13:56:35.126950 EDT | MaxReturn                1000
2017-06-03 13:56:35.127189 EDT | MinReturn                1000
2017-06-03 13:56:35.127417 EDT | AverageEsReturn            19.72
2017-06-03 13:56:35.127647 EDT | StdEsReturn                16.2604
2017-06-03 13:56:35.127874 EDT | MaxEsReturn                71
2017-06-03 13:56:35.128101 EDT | MinEsReturn                 3
2017-06-03 13:56:35.128328 EDT | AverageDiscountedReturn    99.9957
2017-06-03 13:56:35.128564 EDT | AverageQLoss                0.000257148
2017-06-03 13:56:35.128793 EDT | AveragePolicySurr          -0.267448
2017-06-03 13:56:35.129030 EDT | AverageQ                    0.247493
2017-06-03 13:56:35.129256 EDT | AverageAbsQ                 0.248338
2017-06-03 13:56:35.129482 EDT | AverageY                    0.247514
2017-06-03 13:56:35.129755 EDT | AverageAbsY                 0.247746
2017-06-03 13:56:35.130038 EDT | AverageAbsQYDiff            0.00605391
2017-06-03 13:56:35.130282 EDT | AverageAction               0.710326
2017-06-03 13:56:35.130525 EDT | PolicyRegParamNorm         46.3877
2017-06-03 13:56:35.130767 EDT | QFunRegParamNorm           23.7029
2017-06-03 13:56:35.131017 EDT | -----------------------  --------------
2017-06-03 13:56:35.131421 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #148 | Training started
2017-06-03 13:56:53.245434 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #148 | Training finished
2017-06-03 13:56:53.246208 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #148 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 13:56:53.246500 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #148 | Collecting samples for evaluation
2017-06-03 13:57:02.555475 EDT | -----------------------  --------------
2017-06-03 13:57:02.556303 EDT | Epoch                     148
2017-06-03 13:57:02.556563 EDT | Iteration                 148
2017-06-03 13:57:02.556804 EDT | AverageReturn            1000
2017-06-03 13:57:02.557039 EDT | StdReturn                   0
2017-06-03 13:57:02.557273 EDT | MaxReturn                1000
2017-06-03 13:57:02.557506 EDT | MinReturn                1000
2017-06-03 13:57:02.557747 EDT | AverageEsReturn            23.6512
2017-06-03 13:57:02.557986 EDT | StdEsReturn                18.7615
2017-06-03 13:57:02.558215 EDT | MaxEsReturn                78
2017-06-03 13:57:02.558446 EDT | MinEsReturn                 3
2017-06-03 13:57:02.558677 EDT | AverageDiscountedReturn    99.9957
2017-06-03 13:57:02.558912 EDT | AverageQLoss                0.000259659
2017-06-03 13:57:02.559140 EDT | AveragePolicySurr          -0.269777
2017-06-03 13:57:02.559370 EDT | AverageQ                    0.250254
2017-06-03 13:57:02.559620 EDT | AverageAbsQ                 0.250981
2017-06-03 13:57:02.559849 EDT | AverageY                    0.25025
2017-06-03 13:57:02.560076 EDT | AverageAbsY                 0.25054
2017-06-03 13:57:02.560301 EDT | AverageAbsQYDiff            0.00587608
2017-06-03 13:57:02.560530 EDT | AverageAction               0.680899
2017-06-03 13:57:02.560802 EDT | PolicyRegParamNorm         46.4967
2017-06-03 13:57:02.561028 EDT | QFunRegParamNorm           23.7604
2017-06-03 13:57:02.561262 EDT | -----------------------  --------------
2017-06-03 13:57:02.561614 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #149 | Training started
2017-06-03 13:57:21.507617 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #149 | Training finished
2017-06-03 13:57:21.508514 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #149 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 13:57:21.508812 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #149 | Collecting samples for evaluation
2017-06-03 13:57:32.189051 EDT | -----------------------  --------------
2017-06-03 13:57:32.189492 EDT | Epoch                     149
2017-06-03 13:57:32.189781 EDT | Iteration                 149
2017-06-03 13:57:32.190070 EDT | AverageReturn            1000
2017-06-03 13:57:32.190320 EDT | StdReturn                   0
2017-06-03 13:57:32.190567 EDT | MaxReturn                1000
2017-06-03 13:57:32.190816 EDT | MinReturn                1000
2017-06-03 13:57:32.191087 EDT | AverageEsReturn            22.3182
2017-06-03 13:57:32.191336 EDT | StdEsReturn                16.2085
2017-06-03 13:57:32.191614 EDT | MaxEsReturn                74
2017-06-03 13:57:32.191867 EDT | MinEsReturn                 3
2017-06-03 13:57:32.192129 EDT | AverageDiscountedReturn    99.9957
2017-06-03 13:57:32.192384 EDT | AverageQLoss                0.000273118
2017-06-03 13:57:32.192635 EDT | AveragePolicySurr          -0.27059
2017-06-03 13:57:32.192895 EDT | AverageQ                    0.251238
2017-06-03 13:57:32.193141 EDT | AverageAbsQ                 0.252188
2017-06-03 13:57:32.193398 EDT | AverageY                    0.251275
2017-06-03 13:57:32.193647 EDT | AverageAbsY                 0.251564
2017-06-03 13:57:32.193910 EDT | AverageAbsQYDiff            0.00590626
2017-06-03 13:57:32.194166 EDT | AverageAction               0.637411
2017-06-03 13:57:32.194409 EDT | PolicyRegParamNorm         46.6361
2017-06-03 13:57:32.194702 EDT | QFunRegParamNorm           23.7899
2017-06-03 13:57:32.195114 EDT | -----------------------  --------------
2017-06-03 13:57:32.195823 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #150 | Training started
2017-06-03 13:57:51.005717 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #150 | Training finished
2017-06-03 13:57:51.006664 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #150 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 13:57:51.007053 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #150 | Collecting samples for evaluation
2017-06-03 13:58:00.088614 EDT | -----------------------  --------------
2017-06-03 13:58:00.088976 EDT | Epoch                     150
2017-06-03 13:58:00.089239 EDT | Iteration                 150
2017-06-03 13:58:00.089524 EDT | AverageReturn            1000
2017-06-03 13:58:00.089787 EDT | StdReturn                   0
2017-06-03 13:58:00.090042 EDT | MaxReturn                1000
2017-06-03 13:58:00.090293 EDT | MinReturn                1000
2017-06-03 13:58:00.090552 EDT | AverageEsReturn            18.9074
2017-06-03 13:58:00.090838 EDT | StdEsReturn                18.0291
2017-06-03 13:58:00.091088 EDT | MaxEsReturn                86
2017-06-03 13:58:00.091340 EDT | MinEsReturn                 3
2017-06-03 13:58:00.091589 EDT | AverageDiscountedReturn    99.9957
2017-06-03 13:58:00.091845 EDT | AverageQLoss                0.000287164
2017-06-03 13:58:00.092093 EDT | AveragePolicySurr          -0.271885
2017-06-03 13:58:00.092347 EDT | AverageQ                    0.253479
2017-06-03 13:58:00.092595 EDT | AverageAbsQ                 0.254364
2017-06-03 13:58:00.092843 EDT | AverageY                    0.253487
2017-06-03 13:58:00.093089 EDT | AverageAbsY                 0.253743
2017-06-03 13:58:00.093337 EDT | AverageAbsQYDiff            0.00599545
2017-06-03 13:58:00.093583 EDT | AverageAction               0.695168
2017-06-03 13:58:00.093843 EDT | PolicyRegParamNorm         46.8082
2017-06-03 13:58:00.094091 EDT | QFunRegParamNorm           23.8484
2017-06-03 13:58:00.094337 EDT | -----------------------  --------------
2017-06-03 13:58:00.094706 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #151 | Training started
2017-06-03 13:58:17.944162 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #151 | Training finished
2017-06-03 13:58:17.945130 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #151 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 13:58:17.945537 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #151 | Collecting samples for evaluation
2017-06-03 13:58:27.575975 EDT | -----------------------  --------------
2017-06-03 13:58:27.576954 EDT | Epoch                     151
2017-06-03 13:58:27.577277 EDT | Iteration                 151
2017-06-03 13:58:27.577541 EDT | AverageReturn            1000
2017-06-03 13:58:27.577803 EDT | StdReturn                   0
2017-06-03 13:58:27.578049 EDT | MaxReturn                1000
2017-06-03 13:58:27.578303 EDT | MinReturn                1000
2017-06-03 13:58:27.578540 EDT | AverageEsReturn            21.7174
2017-06-03 13:58:27.578774 EDT | StdEsReturn                24.5035
2017-06-03 13:58:27.579017 EDT | MaxEsReturn               130
2017-06-03 13:58:27.579249 EDT | MinEsReturn                 3
2017-06-03 13:58:27.579481 EDT | AverageDiscountedReturn    99.9957
2017-06-03 13:58:27.579756 EDT | AverageQLoss                0.000283391
2017-06-03 13:58:27.579995 EDT | AveragePolicySurr          -0.27198
2017-06-03 13:58:27.580244 EDT | AverageQ                    0.252901
2017-06-03 13:58:27.580496 EDT | AverageAbsQ                 0.25386
2017-06-03 13:58:27.580739 EDT | AverageY                    0.252886
2017-06-03 13:58:27.580983 EDT | AverageAbsY                 0.253242
2017-06-03 13:58:27.581226 EDT | AverageAbsQYDiff            0.00594054
2017-06-03 13:58:27.581467 EDT | AverageAction               0.687591
2017-06-03 13:58:27.581716 EDT | PolicyRegParamNorm         47.0101
2017-06-03 13:58:27.581962 EDT | QFunRegParamNorm           23.8868
2017-06-03 13:58:27.582204 EDT | -----------------------  --------------
2017-06-03 13:58:27.582623 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #152 | Training started
2017-06-03 13:58:45.406883 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #152 | Training finished
2017-06-03 13:58:45.407769 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #152 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 13:58:45.408032 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #152 | Collecting samples for evaluation
2017-06-03 13:58:54.982480 EDT | -----------------------  --------------
2017-06-03 13:58:54.983500 EDT | Epoch                     152
2017-06-03 13:58:54.983853 EDT | Iteration                 152
2017-06-03 13:58:54.984180 EDT | AverageReturn            1000
2017-06-03 13:58:54.984506 EDT | StdReturn                   0
2017-06-03 13:58:54.984834 EDT | MaxReturn                1000
2017-06-03 13:58:54.985153 EDT | MinReturn                1000
2017-06-03 13:58:54.985469 EDT | AverageEsReturn            20.5
2017-06-03 13:58:54.985799 EDT | StdEsReturn                16.0247
2017-06-03 13:58:54.986117 EDT | MaxEsReturn                71
2017-06-03 13:58:54.986431 EDT | MinEsReturn                 3
2017-06-03 13:58:54.986744 EDT | AverageDiscountedReturn    99.9957
2017-06-03 13:58:54.987056 EDT | AverageQLoss                0.000260981
2017-06-03 13:58:54.987368 EDT | AveragePolicySurr          -0.271717
2017-06-03 13:58:54.987680 EDT | AverageQ                    0.252964
2017-06-03 13:58:54.987992 EDT | AverageAbsQ                 0.253854
2017-06-03 13:58:54.988302 EDT | AverageY                    0.252988
2017-06-03 13:58:54.988613 EDT | AverageAbsY                 0.253354
2017-06-03 13:58:54.988921 EDT | AverageAbsQYDiff            0.00541942
2017-06-03 13:58:54.989267 EDT | AverageAction               0.645143
2017-06-03 13:58:54.989594 EDT | PolicyRegParamNorm         47.3428
2017-06-03 13:58:54.989918 EDT | QFunRegParamNorm           23.9354
2017-06-03 13:58:54.990229 EDT | -----------------------  --------------
2017-06-03 13:58:54.990678 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #153 | Training started
2017-06-03 13:59:14.003789 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #153 | Training finished
2017-06-03 13:59:14.004958 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #153 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 13:59:14.005335 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #153 | Collecting samples for evaluation
2017-06-03 13:59:23.004368 EDT | -----------------------  -------------
2017-06-03 13:59:23.005206 EDT | Epoch                     153
2017-06-03 13:59:23.005477 EDT | Iteration                 153
2017-06-03 13:59:23.005737 EDT | AverageReturn            1000
2017-06-03 13:59:23.005987 EDT | StdReturn                   0
2017-06-03 13:59:23.006233 EDT | MaxReturn                1000
2017-06-03 13:59:23.006482 EDT | MinReturn                1000
2017-06-03 13:59:23.006726 EDT | AverageEsReturn            22.4889
2017-06-03 13:59:23.006970 EDT | StdEsReturn                26.1684
2017-06-03 13:59:23.007214 EDT | MaxEsReturn               131
2017-06-03 13:59:23.007454 EDT | MinEsReturn                 3
2017-06-03 13:59:23.007693 EDT | AverageDiscountedReturn    99.9957
2017-06-03 13:59:23.007935 EDT | AverageQLoss                0.000281
2017-06-03 13:59:23.008178 EDT | AveragePolicySurr          -0.271921
2017-06-03 13:59:23.008418 EDT | AverageQ                    0.254588
2017-06-03 13:59:23.008657 EDT | AverageAbsQ                 0.255558
2017-06-03 13:59:23.008901 EDT | AverageY                    0.254611
2017-06-03 13:59:23.009141 EDT | AverageAbsY                 0.254993
2017-06-03 13:59:23.009382 EDT | AverageAbsQYDiff            0.00569579
2017-06-03 13:59:23.009763 EDT | AverageAction               0.635024
2017-06-03 13:59:23.010229 EDT | PolicyRegParamNorm         47.4601
2017-06-03 13:59:23.010676 EDT | QFunRegParamNorm           23.9922
2017-06-03 13:59:23.011126 EDT | -----------------------  -------------
2017-06-03 13:59:23.011700 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #154 | Training started
2017-06-03 13:59:41.481589 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #154 | Training finished
2017-06-03 13:59:41.482503 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #154 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 13:59:41.482774 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #154 | Collecting samples for evaluation
2017-06-03 13:59:52.395681 EDT | -----------------------  --------------
2017-06-03 13:59:52.396685 EDT | Epoch                     154
2017-06-03 13:59:52.397030 EDT | Iteration                 154
2017-06-03 13:59:52.397368 EDT | AverageReturn            1000
2017-06-03 13:59:52.397706 EDT | StdReturn                   0
2017-06-03 13:59:52.398031 EDT | MaxReturn                1000
2017-06-03 13:59:52.398374 EDT | MinReturn                1000
2017-06-03 13:59:52.398701 EDT | AverageEsReturn            18.3333
2017-06-03 13:59:52.399030 EDT | StdEsReturn                16.0069
2017-06-03 13:59:52.399351 EDT | MaxEsReturn                78
2017-06-03 13:59:52.399683 EDT | MinEsReturn                 3
2017-06-03 13:59:52.400038 EDT | AverageDiscountedReturn    99.9957
2017-06-03 13:59:52.400352 EDT | AverageQLoss                0.000241737
2017-06-03 13:59:52.400680 EDT | AveragePolicySurr          -0.271266
2017-06-03 13:59:52.401015 EDT | AverageQ                    0.25401
2017-06-03 13:59:52.401329 EDT | AverageAbsQ                 0.254891
2017-06-03 13:59:52.401641 EDT | AverageY                    0.254001
2017-06-03 13:59:52.401971 EDT | AverageAbsY                 0.254348
2017-06-03 13:59:52.402291 EDT | AverageAbsQYDiff            0.00528349
2017-06-03 13:59:52.402618 EDT | AverageAction               0.670374
2017-06-03 13:59:52.402961 EDT | PolicyRegParamNorm         47.5092
2017-06-03 13:59:52.403281 EDT | QFunRegParamNorm           24.0353
2017-06-03 13:59:52.403591 EDT | -----------------------  --------------
2017-06-03 13:59:52.404098 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #155 | Training started
2017-06-03 14:00:10.930863 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #155 | Training finished
2017-06-03 14:00:10.931570 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #155 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 14:00:10.931835 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #155 | Collecting samples for evaluation
2017-06-03 14:00:20.785026 EDT | -----------------------  --------------
2017-06-03 14:00:20.785908 EDT | Epoch                     155
2017-06-03 14:00:20.786286 EDT | Iteration                 155
2017-06-03 14:00:20.786616 EDT | AverageReturn            1000
2017-06-03 14:00:20.786941 EDT | StdReturn                   0
2017-06-03 14:00:20.787261 EDT | MaxReturn                1000
2017-06-03 14:00:20.787592 EDT | MinReturn                1000
2017-06-03 14:00:20.787914 EDT | AverageEsReturn            29.2059
2017-06-03 14:00:20.788228 EDT | StdEsReturn                17.1718
2017-06-03 14:00:20.788564 EDT | MaxEsReturn                80
2017-06-03 14:00:20.788879 EDT | MinEsReturn                 3
2017-06-03 14:00:20.789188 EDT | AverageDiscountedReturn    99.9957
2017-06-03 14:00:20.789513 EDT | AverageQLoss                0.000302022
2017-06-03 14:00:20.789839 EDT | AveragePolicySurr          -0.269972
2017-06-03 14:00:20.790152 EDT | AverageQ                    0.252554
2017-06-03 14:00:20.790468 EDT | AverageAbsQ                 0.253547
2017-06-03 14:00:20.790800 EDT | AverageY                    0.252561
2017-06-03 14:00:20.791125 EDT | AverageAbsY                 0.252921
2017-06-03 14:00:20.791434 EDT | AverageAbsQYDiff            0.00573485
2017-06-03 14:00:20.791766 EDT | AverageAction               0.651436
2017-06-03 14:00:20.792078 EDT | PolicyRegParamNorm         47.6129
2017-06-03 14:00:20.792384 EDT | QFunRegParamNorm           24.1012
2017-06-03 14:00:20.792701 EDT | -----------------------  --------------
2017-06-03 14:00:20.793139 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #156 | Training started
2017-06-03 14:00:39.261517 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #156 | Training finished
2017-06-03 14:00:39.262433 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #156 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 14:00:39.262715 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #156 | Collecting samples for evaluation
2017-06-03 14:00:47.971999 EDT | -----------------------  --------------
2017-06-03 14:00:47.972897 EDT | Epoch                     156
2017-06-03 14:00:47.973225 EDT | Iteration                 156
2017-06-03 14:00:47.973516 EDT | AverageReturn            1000
2017-06-03 14:00:47.973810 EDT | StdReturn                   0
2017-06-03 14:00:47.974074 EDT | MaxReturn                1000
2017-06-03 14:00:47.974342 EDT | MinReturn                1000
2017-06-03 14:00:47.974604 EDT | AverageEsReturn            33.2
2017-06-03 14:00:47.974873 EDT | StdEsReturn                24.7715
2017-06-03 14:00:47.975149 EDT | MaxEsReturn                95
2017-06-03 14:00:47.975435 EDT | MinEsReturn                 6
2017-06-03 14:00:47.975693 EDT | AverageDiscountedReturn    99.9957
2017-06-03 14:00:47.975926 EDT | AverageQLoss                0.000281453
2017-06-03 14:00:47.976152 EDT | AveragePolicySurr          -0.269157
2017-06-03 14:00:47.976378 EDT | AverageQ                    0.252621
2017-06-03 14:00:47.976606 EDT | AverageAbsQ                 0.253505
2017-06-03 14:00:47.976830 EDT | AverageY                    0.252637
2017-06-03 14:00:47.977056 EDT | AverageAbsY                 0.252942
2017-06-03 14:00:47.977304 EDT | AverageAbsQYDiff            0.00544978
2017-06-03 14:00:47.977538 EDT | AverageAction               0.691381
2017-06-03 14:00:47.977782 EDT | PolicyRegParamNorm         47.6812
2017-06-03 14:00:47.978012 EDT | QFunRegParamNorm           24.1442
2017-06-03 14:00:47.978251 EDT | -----------------------  --------------
2017-06-03 14:00:47.978736 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #157 | Training started
2017-06-03 14:01:06.251997 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #157 | Training finished
2017-06-03 14:01:06.252940 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #157 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 14:01:06.253293 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #157 | Collecting samples for evaluation
2017-06-03 14:01:16.373622 EDT | -----------------------  --------------
2017-06-03 14:01:16.374475 EDT | Epoch                     157
2017-06-03 14:01:16.374751 EDT | Iteration                 157
2017-06-03 14:01:16.375013 EDT | AverageReturn            1000
2017-06-03 14:01:16.375266 EDT | StdReturn                   0
2017-06-03 14:01:16.375507 EDT | MaxReturn                1000
2017-06-03 14:01:16.375746 EDT | MinReturn                1000
2017-06-03 14:01:16.375993 EDT | AverageEsReturn            30.8485
2017-06-03 14:01:16.376241 EDT | StdEsReturn                32.2172
2017-06-03 14:01:16.376481 EDT | MaxEsReturn               122
2017-06-03 14:01:16.376721 EDT | MinEsReturn                 3
2017-06-03 14:01:16.376960 EDT | AverageDiscountedReturn    99.9957
2017-06-03 14:01:16.377199 EDT | AverageQLoss                0.000256074
2017-06-03 14:01:16.377438 EDT | AveragePolicySurr          -0.268132
2017-06-03 14:01:16.377676 EDT | AverageQ                    0.251536
2017-06-03 14:01:16.377935 EDT | AverageAbsQ                 0.252505
2017-06-03 14:01:16.378174 EDT | AverageY                    0.251542
2017-06-03 14:01:16.378412 EDT | AverageAbsY                 0.251852
2017-06-03 14:01:16.378649 EDT | AverageAbsQYDiff            0.00520009
2017-06-03 14:01:16.378904 EDT | AverageAction               0.354537
2017-06-03 14:01:16.379140 EDT | PolicyRegParamNorm         47.7755
2017-06-03 14:01:16.379367 EDT | QFunRegParamNorm           24.1989
2017-06-03 14:01:16.379623 EDT | -----------------------  --------------
2017-06-03 14:01:16.379979 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #158 | Training started
2017-06-03 14:01:35.044779 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #158 | Training finished
2017-06-03 14:01:35.045669 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #158 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 14:01:35.046031 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #158 | Collecting samples for evaluation
2017-06-03 14:01:43.859165 EDT | -----------------------  --------------
2017-06-03 14:01:43.859703 EDT | Epoch                     158
2017-06-03 14:01:43.860045 EDT | Iteration                 158
2017-06-03 14:01:43.860362 EDT | AverageReturn            1000
2017-06-03 14:01:43.860675 EDT | StdReturn                   0
2017-06-03 14:01:43.860984 EDT | MaxReturn                1000
2017-06-03 14:01:43.861290 EDT | MinReturn                1000
2017-06-03 14:01:43.861596 EDT | AverageEsReturn            37.9231
2017-06-03 14:01:43.861930 EDT | StdEsReturn                32.5965
2017-06-03 14:01:43.862240 EDT | MaxEsReturn               169
2017-06-03 14:01:43.862545 EDT | MinEsReturn                 5
2017-06-03 14:01:43.862847 EDT | AverageDiscountedReturn    99.9957
2017-06-03 14:01:43.863152 EDT | AverageQLoss                0.000268426
2017-06-03 14:01:43.863457 EDT | AveragePolicySurr          -0.26684
2017-06-03 14:01:43.863768 EDT | AverageQ                    0.250622
2017-06-03 14:01:43.864072 EDT | AverageAbsQ                 0.251542
2017-06-03 14:01:43.864373 EDT | AverageY                    0.250623
2017-06-03 14:01:43.864674 EDT | AverageAbsY                 0.250972
2017-06-03 14:01:43.864973 EDT | AverageAbsQYDiff            0.0051651
2017-06-03 14:01:43.865275 EDT | AverageAction               0.000323301
2017-06-03 14:01:43.865573 EDT | PolicyRegParamNorm         47.8417
2017-06-03 14:01:43.865889 EDT | QFunRegParamNorm           24.2541
2017-06-03 14:01:43.866190 EDT | -----------------------  --------------
2017-06-03 14:01:43.866624 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #159 | Training started
2017-06-03 14:02:05.259309 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #159 | Training finished
2017-06-03 14:02:05.260222 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #159 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 14:02:05.260492 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #159 | Collecting samples for evaluation
2017-06-03 14:02:15.042108 EDT | -----------------------  --------------
2017-06-03 14:02:15.042959 EDT | Epoch                     159
2017-06-03 14:02:15.043229 EDT | Iteration                 159
2017-06-03 14:02:15.043485 EDT | AverageReturn            1000
2017-06-03 14:02:15.043777 EDT | StdReturn                   0
2017-06-03 14:02:15.044032 EDT | MaxReturn                1000
2017-06-03 14:02:15.044308 EDT | MinReturn                1000
2017-06-03 14:02:15.044564 EDT | AverageEsReturn            39.3077
2017-06-03 14:02:15.044822 EDT | StdEsReturn                49.5835
2017-06-03 14:02:15.045067 EDT | MaxEsReturn               257
2017-06-03 14:02:15.045311 EDT | MinEsReturn                 3
2017-06-03 14:02:15.045555 EDT | AverageDiscountedReturn    99.9957
2017-06-03 14:02:15.045827 EDT | AverageQLoss                0.000302418
2017-06-03 14:02:15.046078 EDT | AveragePolicySurr          -0.265509
2017-06-03 14:02:15.046321 EDT | AverageQ                    0.249666
2017-06-03 14:02:15.046564 EDT | AverageAbsQ                 0.250535
2017-06-03 14:02:15.046807 EDT | AverageY                    0.249679
2017-06-03 14:02:15.047052 EDT | AverageAbsY                 0.249985
2017-06-03 14:02:15.047294 EDT | AverageAbsQYDiff            0.00539149
2017-06-03 14:02:15.047536 EDT | AverageAction               0.679908
2017-06-03 14:02:15.047777 EDT | PolicyRegParamNorm         47.8756
2017-06-03 14:02:15.048019 EDT | QFunRegParamNorm           24.3144
2017-06-03 14:02:15.048261 EDT | -----------------------  --------------
2017-06-03 14:02:15.048668 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #160 | Training started
2017-06-03 14:02:32.874635 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #160 | Training finished
2017-06-03 14:02:32.875521 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #160 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 14:02:32.875793 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #160 | Collecting samples for evaluation
2017-06-03 14:02:42.006553 EDT | -----------------------  --------------
2017-06-03 14:02:42.007055 EDT | Epoch                     160
2017-06-03 14:02:42.007408 EDT | Iteration                 160
2017-06-03 14:02:42.007738 EDT | AverageReturn            1000
2017-06-03 14:02:42.008060 EDT | StdReturn                   0
2017-06-03 14:02:42.008380 EDT | MaxReturn                1000
2017-06-03 14:02:42.008699 EDT | MinReturn                1000
2017-06-03 14:02:42.009019 EDT | AverageEsReturn            29.2424
2017-06-03 14:02:42.009339 EDT | StdEsReturn                25.1348
2017-06-03 14:02:42.009660 EDT | MaxEsReturn               125
2017-06-03 14:02:42.009991 EDT | MinEsReturn                 4
2017-06-03 14:02:42.010307 EDT | AverageDiscountedReturn    99.9957
2017-06-03 14:02:42.010641 EDT | AverageQLoss                0.000255611
2017-06-03 14:02:42.010957 EDT | AveragePolicySurr          -0.264233
2017-06-03 14:02:42.011271 EDT | AverageQ                    0.248786
2017-06-03 14:02:42.011594 EDT | AverageAbsQ                 0.249612
2017-06-03 14:02:42.011907 EDT | AverageY                    0.248782
2017-06-03 14:02:42.012225 EDT | AverageAbsY                 0.249074
2017-06-03 14:02:42.012538 EDT | AverageAbsQYDiff            0.00498065
2017-06-03 14:02:42.012850 EDT | AverageAction               0.531967
2017-06-03 14:02:42.013163 EDT | PolicyRegParamNorm         47.9104
2017-06-03 14:02:42.013480 EDT | QFunRegParamNorm           24.3525
2017-06-03 14:02:42.013815 EDT | -----------------------  --------------
2017-06-03 14:02:42.014253 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #161 | Training started
2017-06-03 14:02:59.719972 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #161 | Training finished
2017-06-03 14:02:59.720874 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #161 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 14:02:59.721167 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #161 | Collecting samples for evaluation
2017-06-03 14:03:09.572393 EDT | -----------------------  --------------
2017-06-03 14:03:09.573237 EDT | Epoch                     161
2017-06-03 14:03:09.573498 EDT | Iteration                 161
2017-06-03 14:03:09.573745 EDT | AverageReturn            1000
2017-06-03 14:03:09.573976 EDT | StdReturn                   0
2017-06-03 14:03:09.574202 EDT | MaxReturn                1000
2017-06-03 14:03:09.574432 EDT | MinReturn                1000
2017-06-03 14:03:09.574662 EDT | AverageEsReturn            35.6552
2017-06-03 14:03:09.574891 EDT | StdEsReturn                24.3796
2017-06-03 14:03:09.575121 EDT | MaxEsReturn                85
2017-06-03 14:03:09.575347 EDT | MinEsReturn                 3
2017-06-03 14:03:09.575608 EDT | AverageDiscountedReturn    99.9957
2017-06-03 14:03:09.575937 EDT | AverageQLoss                0.000263663
2017-06-03 14:03:09.576241 EDT | AveragePolicySurr          -0.262438
2017-06-03 14:03:09.576586 EDT | AverageQ                    0.247296
2017-06-03 14:03:09.576934 EDT | AverageAbsQ                 0.248264
2017-06-03 14:03:09.577282 EDT | AverageY                    0.247298
2017-06-03 14:03:09.577619 EDT | AverageAbsY                 0.247553
2017-06-03 14:03:09.577948 EDT | AverageAbsQYDiff            0.00525789
2017-06-03 14:03:09.578301 EDT | AverageAction               0.000275167
2017-06-03 14:03:09.578621 EDT | PolicyRegParamNorm         47.9603
2017-06-03 14:03:09.578854 EDT | QFunRegParamNorm           24.4196
2017-06-03 14:03:09.579084 EDT | -----------------------  --------------
2017-06-03 14:03:09.579460 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #162 | Training started
2017-06-03 14:03:30.456683 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #162 | Training finished
2017-06-03 14:03:30.457564 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #162 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 14:03:30.457886 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #162 | Collecting samples for evaluation
2017-06-03 14:03:40.724607 EDT | -----------------------  --------------
2017-06-03 14:03:40.725602 EDT | Epoch                     162
2017-06-03 14:03:40.725960 EDT | Iteration                 162
2017-06-03 14:03:40.726293 EDT | AverageReturn            1000
2017-06-03 14:03:40.726628 EDT | StdReturn                   0
2017-06-03 14:03:40.726950 EDT | MaxReturn                1000
2017-06-03 14:03:40.727270 EDT | MinReturn                1000
2017-06-03 14:03:40.727597 EDT | AverageEsReturn            35.6786
2017-06-03 14:03:40.727920 EDT | StdEsReturn                38.4495
2017-06-03 14:03:40.728239 EDT | MaxEsReturn               171
2017-06-03 14:03:40.728556 EDT | MinEsReturn                 3
2017-06-03 14:03:40.728868 EDT | AverageDiscountedReturn    99.9957
2017-06-03 14:03:40.729182 EDT | AverageQLoss                0.00026451
2017-06-03 14:03:40.729494 EDT | AveragePolicySurr          -0.26241
2017-06-03 14:03:40.729818 EDT | AverageQ                    0.246613
2017-06-03 14:03:40.730132 EDT | AverageAbsQ                 0.247434
2017-06-03 14:03:40.730444 EDT | AverageY                    0.246606
2017-06-03 14:03:40.730757 EDT | AverageAbsY                 0.246852
2017-06-03 14:03:40.731067 EDT | AverageAbsQYDiff            0.00484037
2017-06-03 14:03:40.731379 EDT | AverageAction               0.000511275
2017-06-03 14:03:40.731689 EDT | PolicyRegParamNorm         47.9663
2017-06-03 14:03:40.731999 EDT | QFunRegParamNorm           24.4134
2017-06-03 14:03:40.732310 EDT | -----------------------  --------------
2017-06-03 14:03:40.732744 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #163 | Training started
2017-06-03 14:03:59.793887 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #163 | Training finished
2017-06-03 14:03:59.795491 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #163 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 14:03:59.795779 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #163 | Collecting samples for evaluation
2017-06-03 14:04:09.671246 EDT | -----------------------  --------------
2017-06-03 14:04:09.672159 EDT | Epoch                     163
2017-06-03 14:04:09.672442 EDT | Iteration                 163
2017-06-03 14:04:09.672684 EDT | AverageReturn            1000
2017-06-03 14:04:09.672926 EDT | StdReturn                   0
2017-06-03 14:04:09.673168 EDT | MaxReturn                1000
2017-06-03 14:04:09.673400 EDT | MinReturn                1000
2017-06-03 14:04:09.673640 EDT | AverageEsReturn            39.32
2017-06-03 14:04:09.673895 EDT | StdEsReturn                33.2935
2017-06-03 14:04:09.674135 EDT | MaxEsReturn               115
2017-06-03 14:04:09.674366 EDT | MinEsReturn                 3
2017-06-03 14:04:09.674593 EDT | AverageDiscountedReturn    99.9957
2017-06-03 14:04:09.674825 EDT | AverageQLoss                0.000266202
2017-06-03 14:04:09.675056 EDT | AveragePolicySurr          -0.261194
2017-06-03 14:04:09.675282 EDT | AverageQ                    0.246213
2017-06-03 14:04:09.675506 EDT | AverageAbsQ                 0.246946
2017-06-03 14:04:09.675729 EDT | AverageY                    0.24622
2017-06-03 14:04:09.675953 EDT | AverageAbsY                 0.246406
2017-06-03 14:04:09.676181 EDT | AverageAbsQYDiff            0.0049513
2017-06-03 14:04:09.676408 EDT | AverageAction               0.00127567
2017-06-03 14:04:09.676636 EDT | PolicyRegParamNorm         48.0302
2017-06-03 14:04:09.676863 EDT | QFunRegParamNorm           24.4457
2017-06-03 14:04:09.677091 EDT | -----------------------  --------------
2017-06-03 14:04:09.677470 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #164 | Training started
2017-06-03 14:04:28.083051 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #164 | Training finished
2017-06-03 14:04:28.084066 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #164 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 14:04:28.084848 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #164 | Collecting samples for evaluation
2017-06-03 14:04:37.432120 EDT | -----------------------  --------------
2017-06-03 14:04:37.433140 EDT | Epoch                     164
2017-06-03 14:04:37.433432 EDT | Iteration                 164
2017-06-03 14:04:37.433701 EDT | AverageReturn            1000
2017-06-03 14:04:37.433946 EDT | StdReturn                   0
2017-06-03 14:04:37.434194 EDT | MaxReturn                1000
2017-06-03 14:04:37.434488 EDT | MinReturn                1000
2017-06-03 14:04:37.434731 EDT | AverageEsReturn            35.8214
2017-06-03 14:04:37.434992 EDT | StdEsReturn                44.7006
2017-06-03 14:04:37.435256 EDT | MaxEsReturn               217
2017-06-03 14:04:37.435528 EDT | MinEsReturn                 3
2017-06-03 14:04:37.435790 EDT | AverageDiscountedReturn    99.9957
2017-06-03 14:04:37.436046 EDT | AverageQLoss                0.000245886
2017-06-03 14:04:37.436302 EDT | AveragePolicySurr          -0.260243
2017-06-03 14:04:37.436554 EDT | AverageQ                    0.244989
2017-06-03 14:04:37.436786 EDT | AverageAbsQ                 0.245792
2017-06-03 14:04:37.437004 EDT | AverageY                    0.244993
2017-06-03 14:04:37.437223 EDT | AverageAbsY                 0.245154
2017-06-03 14:04:37.437469 EDT | AverageAbsQYDiff            0.00474977
2017-06-03 14:04:37.438264 EDT | AverageAction               0.000683559
2017-06-03 14:04:37.438628 EDT | PolicyRegParamNorm         48.109
2017-06-03 14:04:37.438976 EDT | QFunRegParamNorm           24.4905
2017-06-03 14:04:37.439303 EDT | -----------------------  --------------
2017-06-03 14:04:37.439783 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #165 | Training started
2017-06-03 14:04:55.429517 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #165 | Training finished
2017-06-03 14:04:55.430475 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #165 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 14:04:55.430783 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #165 | Collecting samples for evaluation
2017-06-03 14:05:06.184488 EDT | -----------------------  --------------
2017-06-03 14:05:06.185331 EDT | Epoch                     165
2017-06-03 14:05:06.185613 EDT | Iteration                 165
2017-06-03 14:05:06.185888 EDT | AverageReturn            1000
2017-06-03 14:05:06.186128 EDT | StdReturn                   0
2017-06-03 14:05:06.186362 EDT | MaxReturn                1000
2017-06-03 14:05:06.186593 EDT | MinReturn                1000
2017-06-03 14:05:06.186851 EDT | AverageEsReturn            31.5625
2017-06-03 14:05:06.187088 EDT | StdEsReturn                20.5517
2017-06-03 14:05:06.187321 EDT | MaxEsReturn                80
2017-06-03 14:05:06.187554 EDT | MinEsReturn                 3
2017-06-03 14:05:06.187789 EDT | AverageDiscountedReturn    99.9957
2017-06-03 14:05:06.188053 EDT | AverageQLoss                0.000244905
2017-06-03 14:05:06.188314 EDT | AveragePolicySurr          -0.258756
2017-06-03 14:05:06.188546 EDT | AverageQ                    0.243712
2017-06-03 14:05:06.188777 EDT | AverageAbsQ                 0.24462
2017-06-03 14:05:06.189031 EDT | AverageY                    0.243697
2017-06-03 14:05:06.189264 EDT | AverageAbsY                 0.243903
2017-06-03 14:05:06.189503 EDT | AverageAbsQYDiff            0.00483443
2017-06-03 14:05:06.189744 EDT | AverageAction               0.000139633
2017-06-03 14:05:06.189990 EDT | PolicyRegParamNorm         48.1321
2017-06-03 14:05:06.190227 EDT | QFunRegParamNorm           24.5243
2017-06-03 14:05:06.190458 EDT | -----------------------  --------------
2017-06-03 14:05:06.190836 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #166 | Training started
2017-06-03 14:05:24.804699 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #166 | Training finished
2017-06-03 14:05:24.805564 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #166 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 14:05:24.805870 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #166 | Collecting samples for evaluation
2017-06-03 14:05:34.619745 EDT | -----------------------  -------------
2017-06-03 14:05:34.620582 EDT | Epoch                     166
2017-06-03 14:05:34.620856 EDT | Iteration                 166
2017-06-03 14:05:34.621093 EDT | AverageReturn            1000
2017-06-03 14:05:34.621326 EDT | StdReturn                   0
2017-06-03 14:05:34.621557 EDT | MaxReturn                1000
2017-06-03 14:05:34.621798 EDT | MinReturn                1000
2017-06-03 14:05:34.622028 EDT | AverageEsReturn            36.7692
2017-06-03 14:05:34.622261 EDT | StdEsReturn                32.5568
2017-06-03 14:05:34.622490 EDT | MaxEsReturn               149
2017-06-03 14:05:34.622717 EDT | MinEsReturn                 5
2017-06-03 14:05:34.622945 EDT | AverageDiscountedReturn    99.9957
2017-06-03 14:05:34.623173 EDT | AverageQLoss                0.00020347
2017-06-03 14:05:34.623408 EDT | AveragePolicySurr          -0.257911
2017-06-03 14:05:34.623650 EDT | AverageQ                    0.242952
2017-06-03 14:05:34.623881 EDT | AverageAbsQ                 0.243677
2017-06-03 14:05:34.624107 EDT | AverageY                    0.242971
2017-06-03 14:05:34.624333 EDT | AverageAbsY                 0.243247
2017-06-03 14:05:34.624560 EDT | AverageAbsQYDiff            0.00427607
2017-06-03 14:05:34.624786 EDT | AverageAction               0.256783
2017-06-03 14:05:34.625013 EDT | PolicyRegParamNorm         48.2503
2017-06-03 14:05:34.625239 EDT | QFunRegParamNorm           24.5798
2017-06-03 14:05:34.625466 EDT | -----------------------  -------------
2017-06-03 14:05:34.625812 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #167 | Training started
2017-06-03 14:05:54.176823 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #167 | Training finished
2017-06-03 14:05:54.177890 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #167 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 14:05:54.178148 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #167 | Collecting samples for evaluation
2017-06-03 14:06:04.717308 EDT | -----------------------  --------------
2017-06-03 14:06:04.717716 EDT | Epoch                     167
2017-06-03 14:06:04.717967 EDT | Iteration                 167
2017-06-03 14:06:04.718207 EDT | AverageReturn            1000
2017-06-03 14:06:04.718442 EDT | StdReturn                   0
2017-06-03 14:06:04.718684 EDT | MaxReturn                1000
2017-06-03 14:06:04.718920 EDT | MinReturn                1000
2017-06-03 14:06:04.719163 EDT | AverageEsReturn            37.2143
2017-06-03 14:06:04.719398 EDT | StdEsReturn                30.8155
2017-06-03 14:06:04.719630 EDT | MaxEsReturn               133
2017-06-03 14:06:04.719861 EDT | MinEsReturn                 5
2017-06-03 14:06:04.720091 EDT | AverageDiscountedReturn    99.9957
2017-06-03 14:06:04.720321 EDT | AverageQLoss                0.000262454
2017-06-03 14:06:04.720551 EDT | AveragePolicySurr          -0.256979
2017-06-03 14:06:04.720782 EDT | AverageQ                    0.242306
2017-06-03 14:06:04.721032 EDT | AverageAbsQ                 0.243166
2017-06-03 14:06:04.721264 EDT | AverageY                    0.242292
2017-06-03 14:06:04.721495 EDT | AverageAbsY                 0.242531
2017-06-03 14:06:04.721738 EDT | AverageAbsQYDiff            0.00475942
2017-06-03 14:06:04.721979 EDT | AverageAction               0.000134784
2017-06-03 14:06:04.722209 EDT | PolicyRegParamNorm         48.2796
2017-06-03 14:06:04.722462 EDT | QFunRegParamNorm           24.6002
2017-06-03 14:06:04.722697 EDT | -----------------------  --------------
2017-06-03 14:06:04.723075 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #168 | Training started
2017-06-03 14:06:23.648849 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #168 | Training finished
2017-06-03 14:06:23.649804 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #168 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 14:06:23.650069 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #168 | Collecting samples for evaluation
2017-06-03 14:06:32.588910 EDT | -----------------------  --------------
2017-06-03 14:06:32.589803 EDT | Epoch                     168
2017-06-03 14:06:32.590108 EDT | Iteration                 168
2017-06-03 14:06:32.590362 EDT | AverageReturn            1000
2017-06-03 14:06:32.590609 EDT | StdReturn                   0
2017-06-03 14:06:32.590887 EDT | MaxReturn                1000
2017-06-03 14:06:32.591164 EDT | MinReturn                1000
2017-06-03 14:06:32.591402 EDT | AverageEsReturn            40.4583
2017-06-03 14:06:32.591659 EDT | StdEsReturn                36.5502
2017-06-03 14:06:32.591929 EDT | MaxEsReturn               139
2017-06-03 14:06:32.592184 EDT | MinEsReturn                 4
2017-06-03 14:06:32.592420 EDT | AverageDiscountedReturn    99.9957
2017-06-03 14:06:32.592682 EDT | AverageQLoss                0.000279974
2017-06-03 14:06:32.592956 EDT | AveragePolicySurr          -0.255366
2017-06-03 14:06:32.593195 EDT | AverageQ                    0.240534
2017-06-03 14:06:32.593442 EDT | AverageAbsQ                 0.241407
2017-06-03 14:06:32.593713 EDT | AverageY                    0.240536
2017-06-03 14:06:32.593987 EDT | AverageAbsY                 0.240702
2017-06-03 14:06:32.594223 EDT | AverageAbsQYDiff            0.00508135
2017-06-03 14:06:32.594476 EDT | AverageAction               3.99008e-05
2017-06-03 14:06:32.594742 EDT | PolicyRegParamNorm         48.3356
2017-06-03 14:06:32.594995 EDT | QFunRegParamNorm           24.6228
2017-06-03 14:06:32.595229 EDT | -----------------------  --------------
2017-06-03 14:06:32.595630 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #169 | Training started
2017-06-03 14:06:52.277229 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #169 | Training finished
2017-06-03 14:06:52.278128 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #169 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 14:06:52.278416 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #169 | Collecting samples for evaluation
2017-06-03 14:07:00.683845 EDT | -----------------------  --------------
2017-06-03 14:07:00.684680 EDT | Epoch                     169
2017-06-03 14:07:00.684943 EDT | Iteration                 169
2017-06-03 14:07:00.685184 EDT | AverageReturn            1000
2017-06-03 14:07:00.685421 EDT | StdReturn                   0
2017-06-03 14:07:00.685704 EDT | MaxReturn                1000
2017-06-03 14:07:00.685945 EDT | MinReturn                1000
2017-06-03 14:07:00.686180 EDT | AverageEsReturn            35.4615
2017-06-03 14:07:00.686446 EDT | StdEsReturn                34.9177
2017-06-03 14:07:00.686683 EDT | MaxEsReturn               150
2017-06-03 14:07:00.686916 EDT | MinEsReturn                 4
2017-06-03 14:07:00.687148 EDT | AverageDiscountedReturn    99.9957
2017-06-03 14:07:00.687382 EDT | AverageQLoss                0.000245936
2017-06-03 14:07:00.687627 EDT | AveragePolicySurr          -0.25483
2017-06-03 14:07:00.687858 EDT | AverageQ                    0.240635
2017-06-03 14:07:00.688094 EDT | AverageAbsQ                 0.241442
2017-06-03 14:07:00.688334 EDT | AverageY                    0.240629
2017-06-03 14:07:00.688566 EDT | AverageAbsY                 0.240789
2017-06-03 14:07:00.688798 EDT | AverageAbsQYDiff            0.00464456
2017-06-03 14:07:00.689029 EDT | AverageAction               0.19796
2017-06-03 14:07:00.689260 EDT | PolicyRegParamNorm         48.4048
2017-06-03 14:07:00.689497 EDT | QFunRegParamNorm           24.6318
2017-06-03 14:07:00.689740 EDT | -----------------------  --------------
2017-06-03 14:07:00.690103 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #170 | Training started
2017-06-03 14:07:19.122387 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #170 | Training finished
2017-06-03 14:07:19.123417 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #170 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 14:07:19.123808 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #170 | Collecting samples for evaluation
2017-06-03 14:07:28.406793 EDT | -----------------------  --------------
2017-06-03 14:07:28.407681 EDT | Epoch                     170
2017-06-03 14:07:28.407979 EDT | Iteration                 170
2017-06-03 14:07:28.408250 EDT | AverageReturn            1000
2017-06-03 14:07:28.408501 EDT | StdReturn                   0
2017-06-03 14:07:28.408764 EDT | MaxReturn                1000
2017-06-03 14:07:28.409027 EDT | MinReturn                1000
2017-06-03 14:07:28.409268 EDT | AverageEsReturn            55.7
2017-06-03 14:07:28.409507 EDT | StdEsReturn                42.9303
2017-06-03 14:07:28.409775 EDT | MaxEsReturn               141
2017-06-03 14:07:28.410007 EDT | MinEsReturn                 7
2017-06-03 14:07:28.410246 EDT | AverageDiscountedReturn    99.9957
2017-06-03 14:07:28.410477 EDT | AverageQLoss                0.000236076
2017-06-03 14:07:28.410706 EDT | AveragePolicySurr          -0.253603
2017-06-03 14:07:28.410933 EDT | AverageQ                    0.239369
2017-06-03 14:07:28.411162 EDT | AverageAbsQ                 0.240131
2017-06-03 14:07:28.411388 EDT | AverageY                    0.239375
2017-06-03 14:07:28.411615 EDT | AverageAbsY                 0.239591
2017-06-03 14:07:28.411841 EDT | AverageAbsQYDiff            0.00451638
2017-06-03 14:07:28.412067 EDT | AverageAction               0.472726
2017-06-03 14:07:28.412292 EDT | PolicyRegParamNorm         48.5035
2017-06-03 14:07:28.412517 EDT | QFunRegParamNorm           24.6382
2017-06-03 14:07:28.412743 EDT | -----------------------  --------------
2017-06-03 14:07:28.413126 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #171 | Training started
2017-06-03 14:07:47.433612 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #171 | Training finished
2017-06-03 14:07:47.434550 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #171 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 14:07:47.434854 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #171 | Collecting samples for evaluation
2017-06-03 14:07:57.737082 EDT | -----------------------  --------------
2017-06-03 14:07:57.737936 EDT | Epoch                     171
2017-06-03 14:07:57.738222 EDT | Iteration                 171
2017-06-03 14:07:57.738468 EDT | AverageReturn            1000
2017-06-03 14:07:57.738709 EDT | StdReturn                   0
2017-06-03 14:07:57.738947 EDT | MaxReturn                1000
2017-06-03 14:07:57.739204 EDT | MinReturn                1000
2017-06-03 14:07:57.739450 EDT | AverageEsReturn            34.0714
2017-06-03 14:07:57.739715 EDT | StdEsReturn                38.1828
2017-06-03 14:07:57.739951 EDT | MaxEsReturn               153
2017-06-03 14:07:57.740185 EDT | MinEsReturn                 3
2017-06-03 14:07:57.740418 EDT | AverageDiscountedReturn    99.9957
2017-06-03 14:07:57.740670 EDT | AverageQLoss                0.000243229
2017-06-03 14:07:57.740912 EDT | AveragePolicySurr          -0.252528
2017-06-03 14:07:57.741144 EDT | AverageQ                    0.238167
2017-06-03 14:07:57.741376 EDT | AverageAbsQ                 0.239012
2017-06-03 14:07:57.741608 EDT | AverageY                    0.238174
2017-06-03 14:07:57.741911 EDT | AverageAbsY                 0.238345
2017-06-03 14:07:57.742145 EDT | AverageAbsQYDiff            0.00475504
2017-06-03 14:07:57.742378 EDT | AverageAction               0.0791406
2017-06-03 14:07:57.742611 EDT | PolicyRegParamNorm         48.6222
2017-06-03 14:07:57.742850 EDT | QFunRegParamNorm           24.6874
2017-06-03 14:07:57.743081 EDT | -----------------------  --------------
2017-06-03 14:07:57.743452 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #172 | Training started
2017-06-03 14:08:15.722828 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #172 | Training finished
2017-06-03 14:08:15.723749 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #172 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 14:08:15.724099 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #172 | Collecting samples for evaluation
2017-06-03 14:08:26.820341 EDT | -----------------------  --------------
2017-06-03 14:08:26.821226 EDT | Epoch                     172
2017-06-03 14:08:26.821492 EDT | Iteration                 172
2017-06-03 14:08:26.821752 EDT | AverageReturn            1000
2017-06-03 14:08:26.821992 EDT | StdReturn                   0
2017-06-03 14:08:26.822228 EDT | MaxReturn                1000
2017-06-03 14:08:26.822463 EDT | MinReturn                1000
2017-06-03 14:08:26.822697 EDT | AverageEsReturn            25.561
2017-06-03 14:08:26.822937 EDT | StdEsReturn                27.5398
2017-06-03 14:08:26.823171 EDT | MaxEsReturn               122
2017-06-03 14:08:26.823404 EDT | MinEsReturn                 3
2017-06-03 14:08:26.823637 EDT | AverageDiscountedReturn    99.9957
2017-06-03 14:08:26.823869 EDT | AverageQLoss                0.000231525
2017-06-03 14:08:26.824100 EDT | AveragePolicySurr          -0.252128
2017-06-03 14:08:26.824332 EDT | AverageQ                    0.237338
2017-06-03 14:08:26.824570 EDT | AverageAbsQ                 0.238184
2017-06-03 14:08:26.824803 EDT | AverageY                    0.237331
2017-06-03 14:08:26.825035 EDT | AverageAbsY                 0.237547
2017-06-03 14:08:26.825268 EDT | AverageAbsQYDiff            0.00467655
2017-06-03 14:08:26.825501 EDT | AverageAction               0.0107417
2017-06-03 14:08:26.825805 EDT | PolicyRegParamNorm         48.7161
2017-06-03 14:08:26.826048 EDT | QFunRegParamNorm           24.7042
2017-06-03 14:08:26.826281 EDT | -----------------------  --------------
2017-06-03 14:08:26.826808 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #173 | Training started
2017-06-03 14:08:47.370876 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #173 | Training finished
2017-06-03 14:08:47.372132 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #173 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 14:08:47.372498 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #173 | Collecting samples for evaluation
2017-06-03 14:08:57.057752 EDT | -----------------------  --------------
2017-06-03 14:08:57.058591 EDT | Epoch                     173
2017-06-03 14:08:57.058868 EDT | Iteration                 173
2017-06-03 14:08:57.059114 EDT | AverageReturn            1000
2017-06-03 14:08:57.059345 EDT | StdReturn                   0
2017-06-03 14:08:57.059575 EDT | MaxReturn                1000
2017-06-03 14:08:57.059812 EDT | MinReturn                1000
2017-06-03 14:08:57.060053 EDT | AverageEsReturn            28.5429
2017-06-03 14:08:57.060283 EDT | StdEsReturn                31.7367
2017-06-03 14:08:57.060516 EDT | MaxEsReturn               124
2017-06-03 14:08:57.060745 EDT | MinEsReturn                 3
2017-06-03 14:08:57.060975 EDT | AverageDiscountedReturn    99.9957
2017-06-03 14:08:57.061202 EDT | AverageQLoss                0.000218531
2017-06-03 14:08:57.061429 EDT | AveragePolicySurr          -0.251388
2017-06-03 14:08:57.061656 EDT | AverageQ                    0.236969
2017-06-03 14:08:57.061968 EDT | AverageAbsQ                 0.237756
2017-06-03 14:08:57.062199 EDT | AverageY                    0.236973
2017-06-03 14:08:57.062426 EDT | AverageAbsY                 0.23724
2017-06-03 14:08:57.062654 EDT | AverageAbsQYDiff            0.00454198
2017-06-03 14:08:57.062882 EDT | AverageAction               0.713057
2017-06-03 14:08:57.063118 EDT | PolicyRegParamNorm         48.7715
2017-06-03 14:08:57.063345 EDT | QFunRegParamNorm           24.7505
2017-06-03 14:08:57.063572 EDT | -----------------------  --------------
2017-06-03 14:08:57.063930 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #174 | Training started
2017-06-03 14:09:16.808388 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #174 | Training finished
2017-06-03 14:09:16.810294 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #174 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 14:09:16.810698 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #174 | Collecting samples for evaluation
2017-06-03 14:09:26.906597 EDT | -----------------------  --------------
2017-06-03 14:09:26.907427 EDT | Epoch                     174
2017-06-03 14:09:26.907680 EDT | Iteration                 174
2017-06-03 14:09:26.907917 EDT | AverageReturn            1000
2017-06-03 14:09:26.908147 EDT | StdReturn                   0
2017-06-03 14:09:26.908375 EDT | MaxReturn                1000
2017-06-03 14:09:26.908605 EDT | MinReturn                1000
2017-06-03 14:09:26.908831 EDT | AverageEsReturn            22.5
2017-06-03 14:09:26.909059 EDT | StdEsReturn                22.6711
2017-06-03 14:09:26.909285 EDT | MaxEsReturn               110
2017-06-03 14:09:26.909510 EDT | MinEsReturn                 3
2017-06-03 14:09:26.909746 EDT | AverageDiscountedReturn    99.9957
2017-06-03 14:09:26.909973 EDT | AverageQLoss                0.000203297
2017-06-03 14:09:26.910205 EDT | AveragePolicySurr          -0.249905
2017-06-03 14:09:26.910435 EDT | AverageQ                    0.235776
2017-06-03 14:09:26.910660 EDT | AverageAbsQ                 0.236591
2017-06-03 14:09:26.910884 EDT | AverageY                    0.235769
2017-06-03 14:09:26.911108 EDT | AverageAbsY                 0.236042
2017-06-03 14:09:26.911333 EDT | AverageAbsQYDiff            0.00437163
2017-06-03 14:09:26.911564 EDT | AverageAction               0.00389414
2017-06-03 14:09:26.911804 EDT | PolicyRegParamNorm         48.8161
2017-06-03 14:09:26.912029 EDT | QFunRegParamNorm           24.7967
2017-06-03 14:09:26.912254 EDT | -----------------------  --------------
2017-06-03 14:09:26.912617 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #175 | Training started
2017-06-03 14:09:44.292429 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #175 | Training finished
2017-06-03 14:09:44.293421 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #175 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 14:09:44.293980 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #175 | Collecting samples for evaluation
2017-06-03 14:09:54.031693 EDT | -----------------------  --------------
2017-06-03 14:09:54.032676 EDT | Epoch                     175
2017-06-03 14:09:54.033025 EDT | Iteration                 175
2017-06-03 14:09:54.033349 EDT | AverageReturn            1000
2017-06-03 14:09:54.033670 EDT | StdReturn                   0
2017-06-03 14:09:54.034001 EDT | MaxReturn                1000
2017-06-03 14:09:54.034318 EDT | MinReturn                1000
2017-06-03 14:09:54.034634 EDT | AverageEsReturn            22.3556
2017-06-03 14:09:54.034949 EDT | StdEsReturn                21.693
2017-06-03 14:09:54.035273 EDT | MaxEsReturn                96
2017-06-03 14:09:54.035584 EDT | MinEsReturn                 3
2017-06-03 14:09:54.035896 EDT | AverageDiscountedReturn    99.9957
2017-06-03 14:09:54.036235 EDT | AverageQLoss                0.000223605
2017-06-03 14:09:54.036551 EDT | AveragePolicySurr          -0.248585
2017-06-03 14:09:54.036861 EDT | AverageQ                    0.234923
2017-06-03 14:09:54.037170 EDT | AverageAbsQ                 0.235908
2017-06-03 14:09:54.037492 EDT | AverageY                    0.234936
2017-06-03 14:09:54.037815 EDT | AverageAbsY                 0.235242
2017-06-03 14:09:54.038126 EDT | AverageAbsQYDiff            0.00450309
2017-06-03 14:09:54.038435 EDT | AverageAction               0.454504
2017-06-03 14:09:54.038743 EDT | PolicyRegParamNorm         48.9554
2017-06-03 14:09:54.039048 EDT | QFunRegParamNorm           24.8095
2017-06-03 14:09:54.039355 EDT | -----------------------  --------------
2017-06-03 14:09:54.039810 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #176 | Training started
2017-06-03 14:10:13.074055 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #176 | Training finished
2017-06-03 14:10:13.074996 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #176 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 14:10:13.075325 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #176 | Collecting samples for evaluation
2017-06-03 14:10:22.652974 EDT | -----------------------  --------------
2017-06-03 14:10:22.653981 EDT | Epoch                     176
2017-06-03 14:10:22.654249 EDT | Iteration                 176
2017-06-03 14:10:22.654488 EDT | AverageReturn            1000
2017-06-03 14:10:22.654725 EDT | StdReturn                   0
2017-06-03 14:10:22.654967 EDT | MaxReturn                1000
2017-06-03 14:10:22.655200 EDT | MinReturn                1000
2017-06-03 14:10:22.655429 EDT | AverageEsReturn            20.3265
2017-06-03 14:10:22.655658 EDT | StdEsReturn                18.2761
2017-06-03 14:10:22.655887 EDT | MaxEsReturn               104
2017-06-03 14:10:22.656123 EDT | MinEsReturn                 3
2017-06-03 14:10:22.656350 EDT | AverageDiscountedReturn    99.9957
2017-06-03 14:10:22.656577 EDT | AverageQLoss                0.000213837
2017-06-03 14:10:22.656803 EDT | AveragePolicySurr          -0.248205
2017-06-03 14:10:22.657029 EDT | AverageQ                    0.233736
2017-06-03 14:10:22.657256 EDT | AverageAbsQ                 0.234577
2017-06-03 14:10:22.657483 EDT | AverageY                    0.233736
2017-06-03 14:10:22.658147 EDT | AverageAbsY                 0.233994
2017-06-03 14:10:22.658471 EDT | AverageAbsQYDiff            0.00426165
2017-06-03 14:10:22.658786 EDT | AverageAction               0.61907
2017-06-03 14:10:22.659098 EDT | PolicyRegParamNorm         48.9814
2017-06-03 14:10:22.659408 EDT | QFunRegParamNorm           24.8131
2017-06-03 14:10:22.659717 EDT | -----------------------  --------------
2017-06-03 14:10:22.660291 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #177 | Training started
2017-06-03 14:10:41.017165 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #177 | Training finished
2017-06-03 14:10:41.018116 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #177 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 14:10:41.018517 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #177 | Collecting samples for evaluation
2017-06-03 14:10:51.826953 EDT | -----------------------  --------------
2017-06-03 14:10:51.827923 EDT | Epoch                     177
2017-06-03 14:10:51.828280 EDT | Iteration                 177
2017-06-03 14:10:51.828630 EDT | AverageReturn            1000
2017-06-03 14:10:51.828949 EDT | StdReturn                   0
2017-06-03 14:10:51.829267 EDT | MaxReturn                1000
2017-06-03 14:10:51.829590 EDT | MinReturn                1000
2017-06-03 14:10:51.829921 EDT | AverageEsReturn            20.2857
2017-06-03 14:10:51.830254 EDT | StdEsReturn                18.5802
2017-06-03 14:10:51.830571 EDT | MaxEsReturn                90
2017-06-03 14:10:51.830885 EDT | MinEsReturn                 3
2017-06-03 14:10:51.831214 EDT | AverageDiscountedReturn    99.9957
2017-06-03 14:10:51.831535 EDT | AverageQLoss                0.000231247
2017-06-03 14:10:51.831872 EDT | AveragePolicySurr          -0.247208
2017-06-03 14:10:51.832185 EDT | AverageQ                    0.233161
2017-06-03 14:10:51.832499 EDT | AverageAbsQ                 0.234111
2017-06-03 14:10:51.832825 EDT | AverageY                    0.233129
2017-06-03 14:10:51.833139 EDT | AverageAbsY                 0.23334
2017-06-03 14:10:51.833488 EDT | AverageAbsQYDiff            0.00453862
2017-06-03 14:10:51.833822 EDT | AverageAction               0.571764
2017-06-03 14:10:51.834140 EDT | PolicyRegParamNorm         49.0454
2017-06-03 14:10:51.834460 EDT | QFunRegParamNorm           24.821
2017-06-03 14:10:51.834772 EDT | -----------------------  --------------
2017-06-03 14:10:51.835258 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #178 | Training started
2017-06-03 14:11:09.954352 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #178 | Training finished
2017-06-03 14:11:09.955440 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #178 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 14:11:09.955711 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #178 | Collecting samples for evaluation
2017-06-03 14:11:20.577914 EDT | -----------------------  --------------
2017-06-03 14:11:20.578802 EDT | Epoch                     178
2017-06-03 14:11:20.579077 EDT | Iteration                 178
2017-06-03 14:11:20.579394 EDT | AverageReturn            1000
2017-06-03 14:11:20.579711 EDT | StdReturn                   0
2017-06-03 14:11:20.580017 EDT | MaxReturn                1000
2017-06-03 14:11:20.580256 EDT | MinReturn                1000
2017-06-03 14:11:20.580484 EDT | AverageEsReturn            21.5319
2017-06-03 14:11:20.580706 EDT | StdEsReturn                23.3793
2017-06-03 14:11:20.580941 EDT | MaxEsReturn               122
2017-06-03 14:11:20.581165 EDT | MinEsReturn                 3
2017-06-03 14:11:20.581386 EDT | AverageDiscountedReturn    99.9957
2017-06-03 14:11:20.581605 EDT | AverageQLoss                0.000189628
2017-06-03 14:11:20.581838 EDT | AveragePolicySurr          -0.246132
2017-06-03 14:11:20.582061 EDT | AverageQ                    0.232373
2017-06-03 14:11:20.582283 EDT | AverageAbsQ                 0.233138
2017-06-03 14:11:20.582502 EDT | AverageY                    0.232399
2017-06-03 14:11:20.582722 EDT | AverageAbsY                 0.232553
2017-06-03 14:11:20.582943 EDT | AverageAbsQYDiff            0.00417295
2017-06-03 14:11:20.583170 EDT | AverageAction               0.129971
2017-06-03 14:11:20.583388 EDT | PolicyRegParamNorm         49.0964
2017-06-03 14:11:20.583605 EDT | QFunRegParamNorm           24.8357
2017-06-03 14:11:20.583826 EDT | -----------------------  --------------
2017-06-03 14:11:20.584198 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #179 | Training started
2017-06-03 14:11:39.497879 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #179 | Training finished
2017-06-03 14:11:39.498798 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #179 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 14:11:39.499204 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #179 | Collecting samples for evaluation
2017-06-03 14:11:49.748000 EDT | -----------------------  --------------
2017-06-03 14:11:49.748850 EDT | Epoch                     179
2017-06-03 14:11:49.749119 EDT | Iteration                 179
2017-06-03 14:11:49.749357 EDT | AverageReturn            1000
2017-06-03 14:11:49.749589 EDT | StdReturn                   0
2017-06-03 14:11:49.749840 EDT | MaxReturn                1000
2017-06-03 14:11:49.750070 EDT | MinReturn                1000
2017-06-03 14:11:49.750303 EDT | AverageEsReturn            17.8214
2017-06-03 14:11:49.750532 EDT | StdEsReturn                16.5444
2017-06-03 14:11:49.750758 EDT | MaxEsReturn                96
2017-06-03 14:11:49.750984 EDT | MinEsReturn                 3
2017-06-03 14:11:49.751210 EDT | AverageDiscountedReturn    99.9957
2017-06-03 14:11:49.751436 EDT | AverageQLoss                0.000211014
2017-06-03 14:11:49.751660 EDT | AveragePolicySurr          -0.245276
2017-06-03 14:11:49.751886 EDT | AverageQ                    0.231327
2017-06-03 14:11:49.752116 EDT | AverageAbsQ                 0.232055
2017-06-03 14:11:49.752356 EDT | AverageY                    0.231334
2017-06-03 14:11:49.752581 EDT | AverageAbsY                 0.231499
2017-06-03 14:11:49.752806 EDT | AverageAbsQYDiff            0.00416838
2017-06-03 14:11:49.753031 EDT | AverageAction               0.393972
2017-06-03 14:11:49.753256 EDT | PolicyRegParamNorm         49.1946
2017-06-03 14:11:49.753484 EDT | QFunRegParamNorm           24.8752
2017-06-03 14:11:49.753728 EDT | -----------------------  --------------
2017-06-03 14:11:49.754120 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #180 | Training started
2017-06-03 14:12:08.332136 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #180 | Training finished
2017-06-03 14:12:08.332773 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #180 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 14:12:08.333157 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #180 | Collecting samples for evaluation
2017-06-03 14:12:18.036237 EDT | -----------------------  -------------
2017-06-03 14:12:18.037090 EDT | Epoch                     180
2017-06-03 14:12:18.037348 EDT | Iteration                 180
2017-06-03 14:12:18.037603 EDT | AverageReturn            1000
2017-06-03 14:12:18.037852 EDT | StdReturn                   0
2017-06-03 14:12:18.038085 EDT | MaxReturn                1000
2017-06-03 14:12:18.038338 EDT | MinReturn                1000
2017-06-03 14:12:18.038574 EDT | AverageEsReturn            17.4912
2017-06-03 14:12:18.038807 EDT | StdEsReturn                16.3043
2017-06-03 14:12:18.039038 EDT | MaxEsReturn                67
2017-06-03 14:12:18.039268 EDT | MinEsReturn                 3
2017-06-03 14:12:18.039506 EDT | AverageDiscountedReturn    99.9957
2017-06-03 14:12:18.039804 EDT | AverageQLoss                0.00023307
2017-06-03 14:12:18.040161 EDT | AveragePolicySurr          -0.244541
2017-06-03 14:12:18.040523 EDT | AverageQ                    0.230115
2017-06-03 14:12:18.040776 EDT | AverageAbsQ                 0.230929
2017-06-03 14:12:18.041005 EDT | AverageY                    0.230104
2017-06-03 14:12:18.041231 EDT | AverageAbsY                 0.230296
2017-06-03 14:12:18.041459 EDT | AverageAbsQYDiff            0.0045768
2017-06-03 14:12:18.041735 EDT | AverageAction               0.306115
2017-06-03 14:12:18.041970 EDT | PolicyRegParamNorm         49.3102
2017-06-03 14:12:18.042202 EDT | QFunRegParamNorm           24.9255
2017-06-03 14:12:18.042464 EDT | -----------------------  -------------
2017-06-03 14:12:18.042829 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #181 | Training started
2017-06-03 14:12:36.530534 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #181 | Training finished
2017-06-03 14:12:36.531596 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #181 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 14:12:36.532029 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #181 | Collecting samples for evaluation
2017-06-03 14:12:46.653663 EDT | -----------------------  --------------
2017-06-03 14:12:46.654719 EDT | Epoch                     181
2017-06-03 14:12:46.655097 EDT | Iteration                 181
2017-06-03 14:12:46.655432 EDT | AverageReturn            1000
2017-06-03 14:12:46.655765 EDT | StdReturn                   0
2017-06-03 14:12:46.656098 EDT | MaxReturn                1000
2017-06-03 14:12:46.656423 EDT | MinReturn                1000
2017-06-03 14:12:46.656743 EDT | AverageEsReturn            19.0189
2017-06-03 14:12:46.657066 EDT | StdEsReturn                15.1825
2017-06-03 14:12:46.657387 EDT | MaxEsReturn                87
2017-06-03 14:12:46.657712 EDT | MinEsReturn                 3
2017-06-03 14:12:46.658043 EDT | AverageDiscountedReturn    99.9957
2017-06-03 14:12:46.658362 EDT | AverageQLoss                0.000219377
2017-06-03 14:12:46.658681 EDT | AveragePolicySurr          -0.244404
2017-06-03 14:12:46.659003 EDT | AverageQ                    0.230163
2017-06-03 14:12:46.659324 EDT | AverageAbsQ                 0.230917
2017-06-03 14:12:46.659640 EDT | AverageY                    0.23017
2017-06-03 14:12:46.659957 EDT | AverageAbsY                 0.230405
2017-06-03 14:12:46.660274 EDT | AverageAbsQYDiff            0.00423742
2017-06-03 14:12:46.660591 EDT | AverageAction               0.431212
2017-06-03 14:12:46.660906 EDT | PolicyRegParamNorm         49.3948
2017-06-03 14:12:46.661224 EDT | QFunRegParamNorm           24.958
2017-06-03 14:12:46.661543 EDT | -----------------------  --------------
2017-06-03 14:12:46.662031 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #182 | Training started
2017-06-03 14:13:05.646940 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #182 | Training finished
2017-06-03 14:13:05.647866 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #182 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 14:13:05.648272 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #182 | Collecting samples for evaluation
2017-06-03 14:13:15.214808 EDT | -----------------------  --------------
2017-06-03 14:13:15.215199 EDT | Epoch                     182
2017-06-03 14:13:15.215467 EDT | Iteration                 182
2017-06-03 14:13:15.215729 EDT | AverageReturn            1000
2017-06-03 14:13:15.215973 EDT | StdReturn                   0
2017-06-03 14:13:15.216216 EDT | MaxReturn                1000
2017-06-03 14:13:15.216459 EDT | MinReturn                1000
2017-06-03 14:13:15.216701 EDT | AverageEsReturn            15.6094
2017-06-03 14:13:15.216942 EDT | StdEsReturn                18.1742
2017-06-03 14:13:15.217307 EDT | MaxEsReturn               110
2017-06-03 14:13:15.217626 EDT | MinEsReturn                 3
2017-06-03 14:13:15.217951 EDT | AverageDiscountedReturn    99.9957
2017-06-03 14:13:15.218267 EDT | AverageQLoss                0.000199355
2017-06-03 14:13:15.218591 EDT | AveragePolicySurr          -0.243326
2017-06-03 14:13:15.218909 EDT | AverageQ                    0.228913
2017-06-03 14:13:15.219223 EDT | AverageAbsQ                 0.229759
2017-06-03 14:13:15.219537 EDT | AverageY                    0.228926
2017-06-03 14:13:15.219847 EDT | AverageAbsY                 0.22915
2017-06-03 14:13:15.220157 EDT | AverageAbsQYDiff            0.00415699
2017-06-03 14:13:15.220466 EDT | AverageAction               0.506811
2017-06-03 14:13:15.220776 EDT | PolicyRegParamNorm         49.5122
2017-06-03 14:13:15.221089 EDT | QFunRegParamNorm           24.9748
2017-06-03 14:13:15.221397 EDT | -----------------------  --------------
2017-06-03 14:13:15.221825 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #183 | Training started
2017-06-03 14:13:34.554038 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #183 | Training finished
2017-06-03 14:13:34.554903 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #183 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 14:13:34.555172 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #183 | Collecting samples for evaluation
2017-06-03 14:13:44.058618 EDT | -----------------------  --------------
2017-06-03 14:13:44.059018 EDT | Epoch                     183
2017-06-03 14:13:44.059317 EDT | Iteration                 183
2017-06-03 14:13:44.059591 EDT | AverageReturn            1000
2017-06-03 14:13:44.059844 EDT | StdReturn                   0
2017-06-03 14:13:44.060090 EDT | MaxReturn                1000
2017-06-03 14:13:44.060364 EDT | MinReturn                1000
2017-06-03 14:13:44.060633 EDT | AverageEsReturn            14.4783
2017-06-03 14:13:44.060880 EDT | StdEsReturn                17.0171
2017-06-03 14:13:44.061113 EDT | MaxEsReturn                98
2017-06-03 14:13:44.061342 EDT | MinEsReturn                 3
2017-06-03 14:13:44.061569 EDT | AverageDiscountedReturn    99.9957
2017-06-03 14:13:44.061818 EDT | AverageQLoss                0.000207842
2017-06-03 14:13:44.062093 EDT | AveragePolicySurr          -0.242856
2017-06-03 14:13:44.062355 EDT | AverageQ                    0.228921
2017-06-03 14:13:44.062626 EDT | AverageAbsQ                 0.22974
2017-06-03 14:13:44.062906 EDT | AverageY                    0.228904
2017-06-03 14:13:44.063158 EDT | AverageAbsY                 0.229112
2017-06-03 14:13:44.063437 EDT | AverageAbsQYDiff            0.00402139
2017-06-03 14:13:44.063702 EDT | AverageAction               0.00517435
2017-06-03 14:13:44.063961 EDT | PolicyRegParamNorm         49.6016
2017-06-03 14:13:44.064225 EDT | QFunRegParamNorm           24.9654
2017-06-03 14:13:44.064489 EDT | -----------------------  --------------
2017-06-03 14:13:44.064861 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #184 | Training started
2017-06-03 14:14:02.231124 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #184 | Training finished
2017-06-03 14:14:02.232079 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #184 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 14:14:02.232521 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #184 | Collecting samples for evaluation
2017-06-03 14:14:12.966466 EDT | -----------------------  --------------
2017-06-03 14:14:12.966825 EDT | Epoch                     184
2017-06-03 14:14:12.967098 EDT | Iteration                 184
2017-06-03 14:14:12.967358 EDT | AverageReturn            1000
2017-06-03 14:14:12.967611 EDT | StdReturn                   0
2017-06-03 14:14:12.967861 EDT | MaxReturn                1000
2017-06-03 14:14:12.968109 EDT | MinReturn                1000
2017-06-03 14:14:12.968356 EDT | AverageEsReturn            14.7164
2017-06-03 14:14:12.968604 EDT | StdEsReturn                15.5523
2017-06-03 14:14:12.968860 EDT | MaxEsReturn                88
2017-06-03 14:14:12.969109 EDT | MinEsReturn                 3
2017-06-03 14:14:12.969369 EDT | AverageDiscountedReturn    99.9957
2017-06-03 14:14:12.969620 EDT | AverageQLoss                0.000175946
2017-06-03 14:14:12.969883 EDT | AveragePolicySurr          -0.241921
2017-06-03 14:14:12.970131 EDT | AverageQ                    0.227793
2017-06-03 14:14:12.970387 EDT | AverageAbsQ                 0.228554
2017-06-03 14:14:12.970632 EDT | AverageY                    0.227792
2017-06-03 14:14:12.970878 EDT | AverageAbsY                 0.227985
2017-06-03 14:14:12.971124 EDT | AverageAbsQYDiff            0.00382746
2017-06-03 14:14:12.971383 EDT | AverageAction               0.501487
2017-06-03 14:14:12.971629 EDT | PolicyRegParamNorm         49.6592
2017-06-03 14:14:12.971874 EDT | QFunRegParamNorm           24.9888
2017-06-03 14:14:12.972142 EDT | -----------------------  --------------
2017-06-03 14:14:12.972564 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #185 | Training started
2017-06-03 14:14:32.324745 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #185 | Training finished
2017-06-03 14:14:32.325586 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #185 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 14:14:32.325865 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #185 | Collecting samples for evaluation
2017-06-03 14:14:41.638104 EDT | -----------------------  --------------
2017-06-03 14:14:41.638952 EDT | Epoch                     185
2017-06-03 14:14:41.639207 EDT | Iteration                 185
2017-06-03 14:14:41.639441 EDT | AverageReturn            1000
2017-06-03 14:14:41.639678 EDT | StdReturn                   0
2017-06-03 14:14:41.639902 EDT | MaxReturn                1000
2017-06-03 14:14:41.640136 EDT | MinReturn                1000
2017-06-03 14:14:41.640359 EDT | AverageEsReturn            17.4655
2017-06-03 14:14:41.640584 EDT | StdEsReturn                14.0703
2017-06-03 14:14:41.640807 EDT | MaxEsReturn                66
2017-06-03 14:14:41.641028 EDT | MinEsReturn                 3
2017-06-03 14:14:41.641254 EDT | AverageDiscountedReturn    99.9957
2017-06-03 14:14:41.641474 EDT | AverageQLoss                0.000208537
2017-06-03 14:14:41.641729 EDT | AveragePolicySurr          -0.241078
2017-06-03 14:14:41.641979 EDT | AverageQ                    0.227819
2017-06-03 14:14:41.642216 EDT | AverageAbsQ                 0.22859
2017-06-03 14:14:41.642457 EDT | AverageY                    0.227822
2017-06-03 14:14:41.642694 EDT | AverageAbsY                 0.228008
2017-06-03 14:14:41.642930 EDT | AverageAbsQYDiff            0.00410798
2017-06-03 14:14:41.643166 EDT | AverageAction               0.134031
2017-06-03 14:14:41.643402 EDT | PolicyRegParamNorm         49.7469
2017-06-03 14:14:41.643638 EDT | QFunRegParamNorm           25.0189
2017-06-03 14:14:41.643874 EDT | -----------------------  --------------
2017-06-03 14:14:41.644229 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #186 | Training started
2017-06-03 14:14:59.188051 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #186 | Training finished
2017-06-03 14:14:59.188923 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #186 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 14:14:59.189187 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #186 | Collecting samples for evaluation
2017-06-03 14:15:09.739173 EDT | -----------------------  --------------
2017-06-03 14:15:09.740112 EDT | Epoch                     186
2017-06-03 14:15:09.740396 EDT | Iteration                 186
2017-06-03 14:15:09.740650 EDT | AverageReturn            1000
2017-06-03 14:15:09.740886 EDT | StdReturn                   0
2017-06-03 14:15:09.741137 EDT | MaxReturn                1000
2017-06-03 14:15:09.741380 EDT | MinReturn                1000
2017-06-03 14:15:09.741634 EDT | AverageEsReturn            19.98
2017-06-03 14:15:09.741892 EDT | StdEsReturn                15.5003
2017-06-03 14:15:09.742130 EDT | MaxEsReturn                65
2017-06-03 14:15:09.742370 EDT | MinEsReturn                 3
2017-06-03 14:15:09.742609 EDT | AverageDiscountedReturn    99.9957
2017-06-03 14:15:09.742848 EDT | AverageQLoss                0.000216777
2017-06-03 14:15:09.743087 EDT | AveragePolicySurr          -0.240547
2017-06-03 14:15:09.743326 EDT | AverageQ                    0.226627
2017-06-03 14:15:09.743563 EDT | AverageAbsQ                 0.22741
2017-06-03 14:15:09.743800 EDT | AverageY                    0.226634
2017-06-03 14:15:09.744038 EDT | AverageAbsY                 0.226782
2017-06-03 14:15:09.744275 EDT | AverageAbsQYDiff            0.00417797
2017-06-03 14:15:09.744512 EDT | AverageAction               0.0118029
2017-06-03 14:15:09.744749 EDT | PolicyRegParamNorm         49.8401
2017-06-03 14:15:09.744986 EDT | QFunRegParamNorm           25.0577
2017-06-03 14:15:09.745223 EDT | -----------------------  --------------
2017-06-03 14:15:09.745627 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #187 | Training started
2017-06-03 14:15:28.793920 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #187 | Training finished
2017-06-03 14:15:28.794287 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #187 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 14:15:28.794550 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #187 | Collecting samples for evaluation
2017-06-03 14:15:37.462003 EDT | -----------------------  -------------
2017-06-03 14:15:37.462889 EDT | Epoch                     187
2017-06-03 14:15:37.463166 EDT | Iteration                 187
2017-06-03 14:15:37.463416 EDT | AverageReturn            1000
2017-06-03 14:15:37.463659 EDT | StdReturn                   0
2017-06-03 14:15:37.463914 EDT | MaxReturn                1000
2017-06-03 14:15:37.464159 EDT | MinReturn                1000
2017-06-03 14:15:37.464390 EDT | AverageEsReturn            17.2759
2017-06-03 14:15:37.464619 EDT | StdEsReturn                16.3589
2017-06-03 14:15:37.464848 EDT | MaxEsReturn                73
2017-06-03 14:15:37.465077 EDT | MinEsReturn                 3
2017-06-03 14:15:37.465304 EDT | AverageDiscountedReturn    99.9957
2017-06-03 14:15:37.465530 EDT | AverageQLoss                0.00021335
2017-06-03 14:15:37.465771 EDT | AveragePolicySurr          -0.2399
2017-06-03 14:15:37.466026 EDT | AverageQ                    0.225942
2017-06-03 14:15:37.466254 EDT | AverageAbsQ                 0.226769
2017-06-03 14:15:37.466479 EDT | AverageY                    0.225946
2017-06-03 14:15:37.466719 EDT | AverageAbsY                 0.226096
2017-06-03 14:15:37.466971 EDT | AverageAbsQYDiff            0.00414244
2017-06-03 14:15:37.467221 EDT | AverageAction               0.51798
2017-06-03 14:15:37.467450 EDT | PolicyRegParamNorm         49.861
2017-06-03 14:15:37.467676 EDT | QFunRegParamNorm           25.0632
2017-06-03 14:15:37.467918 EDT | -----------------------  -------------
2017-06-03 14:15:37.468380 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #188 | Training started
2017-06-03 14:15:56.281020 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #188 | Training finished
2017-06-03 14:15:56.281948 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #188 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 14:15:56.282307 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #188 | Collecting samples for evaluation
2017-06-03 14:16:06.523003 EDT | -----------------------  --------------
2017-06-03 14:16:06.523834 EDT | Epoch                     188
2017-06-03 14:16:06.524097 EDT | Iteration                 188
2017-06-03 14:16:06.524340 EDT | AverageReturn            1000
2017-06-03 14:16:06.524578 EDT | StdReturn                   0
2017-06-03 14:16:06.524827 EDT | MaxReturn                1000
2017-06-03 14:16:06.525061 EDT | MinReturn                1000
2017-06-03 14:16:06.525293 EDT | AverageEsReturn            23.3023
2017-06-03 14:16:06.525527 EDT | StdEsReturn                18.7077
2017-06-03 14:16:06.525771 EDT | MaxEsReturn                84
2017-06-03 14:16:06.526005 EDT | MinEsReturn                 3
2017-06-03 14:16:06.526237 EDT | AverageDiscountedReturn    99.9957
2017-06-03 14:16:06.526468 EDT | AverageQLoss                0.000212669
2017-06-03 14:16:06.526699 EDT | AveragePolicySurr          -0.238088
2017-06-03 14:16:06.526930 EDT | AverageQ                    0.22451
2017-06-03 14:16:06.527161 EDT | AverageAbsQ                 0.225253
2017-06-03 14:16:06.527391 EDT | AverageY                    0.224506
2017-06-03 14:16:06.527644 EDT | AverageAbsY                 0.224675
2017-06-03 14:16:06.527876 EDT | AverageAbsQYDiff            0.00399269
2017-06-03 14:16:06.528107 EDT | AverageAction               0.439324
2017-06-03 14:16:06.528336 EDT | PolicyRegParamNorm         49.9484
2017-06-03 14:16:06.528575 EDT | QFunRegParamNorm           25.081
2017-06-03 14:16:06.528806 EDT | -----------------------  --------------
2017-06-03 14:16:06.529161 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #189 | Training started
2017-06-03 14:16:24.361953 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #189 | Training finished
2017-06-03 14:16:24.362876 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #189 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 14:16:24.363154 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #189 | Collecting samples for evaluation
2017-06-03 14:16:34.285305 EDT | -----------------------  --------------
2017-06-03 14:16:34.286195 EDT | Epoch                     189
2017-06-03 14:16:34.286468 EDT | Iteration                 189
2017-06-03 14:16:34.286713 EDT | AverageReturn            1000
2017-06-03 14:16:34.286950 EDT | StdReturn                   0
2017-06-03 14:16:34.287203 EDT | MaxReturn                1000
2017-06-03 14:16:34.287436 EDT | MinReturn                1000
2017-06-03 14:16:34.287670 EDT | AverageEsReturn            30.9375
2017-06-03 14:16:34.287904 EDT | StdEsReturn                42.5925
2017-06-03 14:16:34.288137 EDT | MaxEsReturn               191
2017-06-03 14:16:34.288399 EDT | MinEsReturn                 3
2017-06-03 14:16:34.288634 EDT | AverageDiscountedReturn    99.9957
2017-06-03 14:16:34.288866 EDT | AverageQLoss                0.000187026
2017-06-03 14:16:34.289098 EDT | AveragePolicySurr          -0.236703
2017-06-03 14:16:34.289330 EDT | AverageQ                    0.223982
2017-06-03 14:16:34.289570 EDT | AverageAbsQ                 0.224773
2017-06-03 14:16:34.289815 EDT | AverageY                    0.223984
2017-06-03 14:16:34.290047 EDT | AverageAbsY                 0.224141
2017-06-03 14:16:34.290278 EDT | AverageAbsQYDiff            0.00398564
2017-06-03 14:16:34.290508 EDT | AverageAction               0.454597
2017-06-03 14:16:34.290737 EDT | PolicyRegParamNorm         49.9776
2017-06-03 14:16:34.290967 EDT | QFunRegParamNorm           25.1156
2017-06-03 14:16:34.291197 EDT | -----------------------  --------------
2017-06-03 14:16:34.291678 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #190 | Training started
2017-06-03 14:16:53.156817 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #190 | Training finished
2017-06-03 14:16:53.157491 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #190 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 14:16:53.157854 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #190 | Collecting samples for evaluation
2017-06-03 14:17:02.385383 EDT | -----------------------  --------------
2017-06-03 14:17:02.386273 EDT | Epoch                     190
2017-06-03 14:17:02.386543 EDT | Iteration                 190
2017-06-03 14:17:02.386813 EDT | AverageReturn            1000
2017-06-03 14:17:02.387052 EDT | StdReturn                   0
2017-06-03 14:17:02.387287 EDT | MaxReturn                1000
2017-06-03 14:17:02.387546 EDT | MinReturn                1000
2017-06-03 14:17:02.387778 EDT | AverageEsReturn            18.8868
2017-06-03 14:17:02.388020 EDT | StdEsReturn                15.4513
2017-06-03 14:17:02.388257 EDT | MaxEsReturn                70
2017-06-03 14:17:02.388485 EDT | MinEsReturn                 3
2017-06-03 14:17:02.388727 EDT | AverageDiscountedReturn    99.9957
2017-06-03 14:17:02.388957 EDT | AverageQLoss                0.000208343
2017-06-03 14:17:02.389187 EDT | AveragePolicySurr          -0.234935
2017-06-03 14:17:02.389436 EDT | AverageQ                    0.222057
2017-06-03 14:17:02.389669 EDT | AverageAbsQ                 0.22282
2017-06-03 14:17:02.389936 EDT | AverageY                    0.222053
2017-06-03 14:17:02.390190 EDT | AverageAbsY                 0.222215
2017-06-03 14:17:02.390434 EDT | AverageAbsQYDiff            0.00415463
2017-06-03 14:17:02.390674 EDT | AverageAction               0.0148953
2017-06-03 14:17:02.390933 EDT | PolicyRegParamNorm         50.0263
2017-06-03 14:17:02.391176 EDT | QFunRegParamNorm           25.1476
2017-06-03 14:17:02.391426 EDT | -----------------------  --------------
2017-06-03 14:17:02.391783 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #191 | Training started
2017-06-03 14:17:21.288862 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #191 | Training finished
2017-06-03 14:17:21.289753 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #191 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 14:17:21.290056 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #191 | Collecting samples for evaluation
2017-06-03 14:17:30.026862 EDT | -----------------------  -------------
2017-06-03 14:17:30.027257 EDT | Epoch                     191
2017-06-03 14:17:30.027522 EDT | Iteration                 191
2017-06-03 14:17:30.027805 EDT | AverageReturn            1000
2017-06-03 14:17:30.028098 EDT | StdReturn                   0
2017-06-03 14:17:30.028358 EDT | MaxReturn                1000
2017-06-03 14:17:30.028610 EDT | MinReturn                1000
2017-06-03 14:17:30.028855 EDT | AverageEsReturn            30.4848
2017-06-03 14:17:30.029102 EDT | StdEsReturn                25.4905
2017-06-03 14:17:30.029347 EDT | MaxEsReturn                84
2017-06-03 14:17:30.029599 EDT | MinEsReturn                 4
2017-06-03 14:17:30.029856 EDT | AverageDiscountedReturn    99.9957
2017-06-03 14:17:30.030100 EDT | AverageQLoss                0.00021348
2017-06-03 14:17:30.030341 EDT | AveragePolicySurr          -0.233846
2017-06-03 14:17:30.030584 EDT | AverageQ                    0.220666
2017-06-03 14:17:30.030826 EDT | AverageAbsQ                 0.221581
2017-06-03 14:17:30.031086 EDT | AverageY                    0.220668
2017-06-03 14:17:30.031376 EDT | AverageAbsY                 0.220838
2017-06-03 14:17:30.031631 EDT | AverageAbsQYDiff            0.00430178
2017-06-03 14:17:30.031894 EDT | AverageAction               0.697277
2017-06-03 14:17:30.032151 EDT | PolicyRegParamNorm         50.2149
2017-06-03 14:17:30.032409 EDT | QFunRegParamNorm           25.1589
2017-06-03 14:17:30.032655 EDT | -----------------------  -------------
2017-06-03 14:17:30.033015 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #192 | Training started
2017-06-03 14:17:48.167442 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #192 | Training finished
2017-06-03 14:17:48.169330 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #192 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 14:17:48.169626 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #192 | Collecting samples for evaluation
2017-06-03 14:17:57.353479 EDT | -----------------------  --------------
2017-06-03 14:17:57.354320 EDT | Epoch                     192
2017-06-03 14:17:57.354591 EDT | Iteration                 192
2017-06-03 14:17:57.354825 EDT | AverageReturn            1000
2017-06-03 14:17:57.355089 EDT | StdReturn                   0
2017-06-03 14:17:57.355331 EDT | MaxReturn                1000
2017-06-03 14:17:57.355552 EDT | MinReturn                1000
2017-06-03 14:17:57.355768 EDT | AverageEsReturn            23.8333
2017-06-03 14:17:57.355983 EDT | StdEsReturn                18.8325
2017-06-03 14:17:57.356197 EDT | MaxEsReturn                86
2017-06-03 14:17:57.356409 EDT | MinEsReturn                 3
2017-06-03 14:17:57.356623 EDT | AverageDiscountedReturn    99.9957
2017-06-03 14:17:57.356837 EDT | AverageQLoss                0.000218712
2017-06-03 14:17:57.357054 EDT | AveragePolicySurr          -0.232462
2017-06-03 14:17:57.357267 EDT | AverageQ                    0.21962
2017-06-03 14:17:57.357493 EDT | AverageAbsQ                 0.220334
2017-06-03 14:17:57.357778 EDT | AverageY                    0.219621
2017-06-03 14:17:57.358010 EDT | AverageAbsY                 0.219772
2017-06-03 14:17:57.358237 EDT | AverageAbsQYDiff            0.00396574
2017-06-03 14:17:57.358463 EDT | AverageAction               0.650109
2017-06-03 14:17:57.358687 EDT | PolicyRegParamNorm         50.226
2017-06-03 14:17:57.358924 EDT | QFunRegParamNorm           25.1785
2017-06-03 14:17:57.359147 EDT | -----------------------  --------------
2017-06-03 14:17:57.359518 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #193 | Training started
2017-06-03 14:18:16.441535 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #193 | Training finished
2017-06-03 14:18:16.442415 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #193 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 14:18:16.442730 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #193 | Collecting samples for evaluation
2017-06-03 14:18:27.691395 EDT | -----------------------  --------------
2017-06-03 14:18:27.692242 EDT | Epoch                     193
2017-06-03 14:18:27.692512 EDT | Iteration                 193
2017-06-03 14:18:27.692756 EDT | AverageReturn            1000
2017-06-03 14:18:27.692993 EDT | StdReturn                   0
2017-06-03 14:18:27.693237 EDT | MaxReturn                1000
2017-06-03 14:18:27.693471 EDT | MinReturn                1000
2017-06-03 14:18:27.693717 EDT | AverageEsReturn            26.3421
2017-06-03 14:18:27.693960 EDT | StdEsReturn                21.3039
2017-06-03 14:18:27.694193 EDT | MaxEsReturn               100
2017-06-03 14:18:27.694452 EDT | MinEsReturn                 4
2017-06-03 14:18:27.694686 EDT | AverageDiscountedReturn    99.9957
2017-06-03 14:18:27.694926 EDT | AverageQLoss                0.000186716
2017-06-03 14:18:27.695161 EDT | AveragePolicySurr          -0.230882
2017-06-03 14:18:27.695392 EDT | AverageQ                    0.217714
2017-06-03 14:18:27.695626 EDT | AverageAbsQ                 0.218489
2017-06-03 14:18:27.695868 EDT | AverageY                    0.217712
2017-06-03 14:18:27.696102 EDT | AverageAbsY                 0.21787
2017-06-03 14:18:27.696333 EDT | AverageAbsQYDiff            0.00380224
2017-06-03 14:18:27.696590 EDT | AverageAction               0.334534
2017-06-03 14:18:27.696823 EDT | PolicyRegParamNorm         50.2716
2017-06-03 14:18:27.697056 EDT | QFunRegParamNorm           25.1873
2017-06-03 14:18:27.697300 EDT | -----------------------  --------------
2017-06-03 14:18:27.697665 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #194 | Training started
2017-06-03 14:18:46.815060 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #194 | Training finished
2017-06-03 14:18:46.816164 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #194 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 14:18:46.816432 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #194 | Collecting samples for evaluation
2017-06-03 14:18:55.633193 EDT | -----------------------  --------------
2017-06-03 14:18:55.634186 EDT | Epoch                     194
2017-06-03 14:18:55.634468 EDT | Iteration                 194
2017-06-03 14:18:55.634717 EDT | AverageReturn            1000
2017-06-03 14:18:55.634966 EDT | StdReturn                   0
2017-06-03 14:18:55.635206 EDT | MaxReturn                1000
2017-06-03 14:18:55.635454 EDT | MinReturn                1000
2017-06-03 14:18:55.635702 EDT | AverageEsReturn            23.5238
2017-06-03 14:18:55.635953 EDT | StdEsReturn                22.2467
2017-06-03 14:18:55.636198 EDT | MaxEsReturn               107
2017-06-03 14:18:55.636429 EDT | MinEsReturn                 3
2017-06-03 14:18:55.636681 EDT | AverageDiscountedReturn    99.9957
2017-06-03 14:18:55.636930 EDT | AverageQLoss                0.000185623
2017-06-03 14:18:55.637184 EDT | AveragePolicySurr          -0.230047
2017-06-03 14:18:55.637416 EDT | AverageQ                    0.217848
2017-06-03 14:18:55.637653 EDT | AverageAbsQ                 0.218624
2017-06-03 14:18:55.638009 EDT | AverageY                    0.21785
2017-06-03 14:18:55.638267 EDT | AverageAbsY                 0.218015
2017-06-03 14:18:55.638537 EDT | AverageAbsQYDiff            0.00368538
2017-06-03 14:18:55.638786 EDT | AverageAction               0.822647
2017-06-03 14:18:55.639066 EDT | PolicyRegParamNorm         50.3705
2017-06-03 14:18:55.639329 EDT | QFunRegParamNorm           25.2255
2017-06-03 14:18:55.639585 EDT | -----------------------  --------------
2017-06-03 14:18:55.639972 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #195 | Training started
2017-06-03 14:19:14.186080 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #195 | Training finished
2017-06-03 14:19:14.200048 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #195 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 14:19:14.200598 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #195 | Collecting samples for evaluation
2017-06-03 14:19:23.840627 EDT | -----------------------  --------------
2017-06-03 14:19:23.841467 EDT | Epoch                     195
2017-06-03 14:19:23.841739 EDT | Iteration                 195
2017-06-03 14:19:23.841983 EDT | AverageReturn            1000
2017-06-03 14:19:23.842220 EDT | StdReturn                   0
2017-06-03 14:19:23.842464 EDT | MaxReturn                1000
2017-06-03 14:19:23.842697 EDT | MinReturn                1000
2017-06-03 14:19:23.842933 EDT | AverageEsReturn            20.16
2017-06-03 14:19:23.843173 EDT | StdEsReturn                19.1597
2017-06-03 14:19:23.843406 EDT | MaxEsReturn                98
2017-06-03 14:19:23.843638 EDT | MinEsReturn                 3
2017-06-03 14:19:23.843878 EDT | AverageDiscountedReturn    99.9957
2017-06-03 14:19:23.844112 EDT | AverageQLoss                0.000165189
2017-06-03 14:19:23.844354 EDT | AveragePolicySurr          -0.228968
2017-06-03 14:19:23.844609 EDT | AverageQ                    0.216628
2017-06-03 14:19:23.844864 EDT | AverageAbsQ                 0.217231
2017-06-03 14:19:23.845095 EDT | AverageY                    0.216636
2017-06-03 14:19:23.845331 EDT | AverageAbsY                 0.216779
2017-06-03 14:19:23.845568 EDT | AverageAbsQYDiff            0.00335614
2017-06-03 14:19:23.845825 EDT | AverageAction               0.268623
2017-06-03 14:19:23.846058 EDT | PolicyRegParamNorm         50.4059
2017-06-03 14:19:23.846295 EDT | QFunRegParamNorm           25.247
2017-06-03 14:19:23.846526 EDT | -----------------------  --------------
2017-06-03 14:19:23.847062 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #196 | Training started
2017-06-03 14:19:41.782400 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #196 | Training finished
2017-06-03 14:19:41.783253 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #196 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 14:19:41.783533 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #196 | Collecting samples for evaluation
2017-06-03 14:19:51.114620 EDT | -----------------------  --------------
2017-06-03 14:19:51.115660 EDT | Epoch                     196
2017-06-03 14:19:51.116025 EDT | Iteration                 196
2017-06-03 14:19:51.116348 EDT | AverageReturn            1000
2017-06-03 14:19:51.116665 EDT | StdReturn                   0
2017-06-03 14:19:51.116978 EDT | MaxReturn                1000
2017-06-03 14:19:51.117291 EDT | MinReturn                1000
2017-06-03 14:19:51.117625 EDT | AverageEsReturn            28.6
2017-06-03 14:19:51.117949 EDT | StdEsReturn                31.2018
2017-06-03 14:19:51.118286 EDT | MaxEsReturn               156
2017-06-03 14:19:51.118601 EDT | MinEsReturn                 3
2017-06-03 14:19:51.118939 EDT | AverageDiscountedReturn    99.9957
2017-06-03 14:19:51.119251 EDT | AverageQLoss                0.000198515
2017-06-03 14:19:51.119564 EDT | AveragePolicySurr          -0.228207
2017-06-03 14:19:51.119877 EDT | AverageQ                    0.215891
2017-06-03 14:19:51.120193 EDT | AverageAbsQ                 0.216627
2017-06-03 14:19:51.120502 EDT | AverageY                    0.215882
2017-06-03 14:19:51.120812 EDT | AverageAbsY                 0.216045
2017-06-03 14:19:51.121119 EDT | AverageAbsQYDiff            0.00393968
2017-06-03 14:19:51.121455 EDT | AverageAction               0.577459
2017-06-03 14:19:51.121772 EDT | PolicyRegParamNorm         50.4385
2017-06-03 14:19:51.122081 EDT | QFunRegParamNorm           25.2482
2017-06-03 14:19:51.122549 EDT | -----------------------  --------------
2017-06-03 14:19:51.123261 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #197 | Training started
2017-06-03 14:20:10.608914 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #197 | Training finished
2017-06-03 14:20:10.609780 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #197 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 14:20:10.610068 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #197 | Collecting samples for evaluation
2017-06-03 14:20:21.012953 EDT | -----------------------  --------------
2017-06-03 14:20:21.013807 EDT | Epoch                     197
2017-06-03 14:20:21.014086 EDT | Iteration                 197
2017-06-03 14:20:21.014330 EDT | AverageReturn            1000
2017-06-03 14:20:21.014567 EDT | StdReturn                   0
2017-06-03 14:20:21.014809 EDT | MaxReturn                1000
2017-06-03 14:20:21.015053 EDT | MinReturn                1000
2017-06-03 14:20:21.015291 EDT | AverageEsReturn            21.6304
2017-06-03 14:20:21.015523 EDT | StdEsReturn                18.8014
2017-06-03 14:20:21.015756 EDT | MaxEsReturn                60
2017-06-03 14:20:21.015988 EDT | MinEsReturn                 3
2017-06-03 14:20:21.016218 EDT | AverageDiscountedReturn    99.9957
2017-06-03 14:20:21.016446 EDT | AverageQLoss                0.000198594
2017-06-03 14:20:21.016677 EDT | AveragePolicySurr          -0.226969
2017-06-03 14:20:21.016908 EDT | AverageQ                    0.214266
2017-06-03 14:20:21.017135 EDT | AverageAbsQ                 0.215089
2017-06-03 14:20:21.017365 EDT | AverageY                    0.214266
2017-06-03 14:20:21.017596 EDT | AverageAbsY                 0.214423
2017-06-03 14:20:21.017862 EDT | AverageAbsQYDiff            0.00382055
2017-06-03 14:20:21.018096 EDT | AverageAction               0.483514
2017-06-03 14:20:21.018328 EDT | PolicyRegParamNorm         50.4683
2017-06-03 14:20:21.018559 EDT | QFunRegParamNorm           25.2718
2017-06-03 14:20:21.018788 EDT | -----------------------  --------------
2017-06-03 14:20:21.019246 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #198 | Training started
2017-06-03 14:20:38.944353 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #198 | Training finished
2017-06-03 14:20:38.947275 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #198 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 14:20:38.947546 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #198 | Collecting samples for evaluation
2017-06-03 14:20:48.781183 EDT | -----------------------  --------------
2017-06-03 14:20:48.782114 EDT | Epoch                     198
2017-06-03 14:20:48.782412 EDT | Iteration                 198
2017-06-03 14:20:48.782692 EDT | AverageReturn            1000
2017-06-03 14:20:48.782965 EDT | StdReturn                   0
2017-06-03 14:20:48.783227 EDT | MaxReturn                1000
2017-06-03 14:20:48.783464 EDT | MinReturn                1000
2017-06-03 14:20:48.783703 EDT | AverageEsReturn            22.3333
2017-06-03 14:20:48.783950 EDT | StdEsReturn                19.874
2017-06-03 14:20:48.784203 EDT | MaxEsReturn                83
2017-06-03 14:20:48.784442 EDT | MinEsReturn                 3
2017-06-03 14:20:48.784674 EDT | AverageDiscountedReturn    99.9957
2017-06-03 14:20:48.784905 EDT | AverageQLoss                0.000185095
2017-06-03 14:20:48.785137 EDT | AveragePolicySurr          -0.22604
2017-06-03 14:20:48.785368 EDT | AverageQ                    0.213221
2017-06-03 14:20:48.785616 EDT | AverageAbsQ                 0.21394
2017-06-03 14:20:48.785912 EDT | AverageY                    0.213227
2017-06-03 14:20:48.786144 EDT | AverageAbsY                 0.213335
2017-06-03 14:20:48.786375 EDT | AverageAbsQYDiff            0.0037053
2017-06-03 14:20:48.786615 EDT | AverageAction               0.487764
2017-06-03 14:20:48.786844 EDT | PolicyRegParamNorm         50.6132
2017-06-03 14:20:48.787074 EDT | QFunRegParamNorm           25.3076
2017-06-03 14:20:48.787303 EDT | -----------------------  --------------
2017-06-03 14:20:48.787806 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #199 | Training started
2017-06-03 14:21:07.004441 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #199 | Training finished
2017-06-03 14:21:07.005351 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #199 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 14:21:07.005636 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #199 | Collecting samples for evaluation
2017-06-03 14:21:16.521289 EDT | -----------------------  --------------
2017-06-03 14:21:16.522329 EDT | Epoch                     199
2017-06-03 14:21:16.522674 EDT | Iteration                 199
2017-06-03 14:21:16.522994 EDT | AverageReturn            1000
2017-06-03 14:21:16.523329 EDT | StdReturn                   0
2017-06-03 14:21:16.523639 EDT | MaxReturn                1000
2017-06-03 14:21:16.523948 EDT | MinReturn                1000
2017-06-03 14:21:16.524259 EDT | AverageEsReturn            26.2632
2017-06-03 14:21:16.524578 EDT | StdEsReturn                21.4583
2017-06-03 14:21:16.524886 EDT | MaxEsReturn                93
2017-06-03 14:21:16.525191 EDT | MinEsReturn                 3
2017-06-03 14:21:16.525494 EDT | AverageDiscountedReturn    99.9957
2017-06-03 14:21:16.525819 EDT | AverageQLoss                0.000149014
2017-06-03 14:21:16.526133 EDT | AveragePolicySurr          -0.225623
2017-06-03 14:21:16.526442 EDT | AverageQ                    0.212843
2017-06-03 14:21:16.526747 EDT | AverageAbsQ                 0.213481
2017-06-03 14:21:16.527061 EDT | AverageY                    0.21284
2017-06-03 14:21:16.527364 EDT | AverageAbsY                 0.213007
2017-06-03 14:21:16.527671 EDT | AverageAbsQYDiff            0.00320131
2017-06-03 14:21:16.527976 EDT | AverageAction               0.385821
2017-06-03 14:21:16.528283 EDT | PolicyRegParamNorm         50.6876
2017-06-03 14:21:16.528743 EDT | QFunRegParamNorm           25.3292
2017-06-03 14:21:16.529259 EDT | -----------------------  --------------
2017-06-03 14:21:16.529993 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #200 | Training started
2017-06-03 14:21:34.910917 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #200 | Training finished
2017-06-03 14:21:34.911786 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #200 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 14:21:34.912059 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #200 | Collecting samples for evaluation
2017-06-03 14:21:44.490725 EDT | -----------------------  --------------
2017-06-03 14:21:44.491656 EDT | Epoch                     200
2017-06-03 14:21:44.491928 EDT | Iteration                 200
2017-06-03 14:21:44.492184 EDT | AverageReturn            1000
2017-06-03 14:21:44.492420 EDT | StdReturn                   0
2017-06-03 14:21:44.492651 EDT | MaxReturn                1000
2017-06-03 14:21:44.492881 EDT | MinReturn                1000
2017-06-03 14:21:44.493137 EDT | AverageEsReturn            24.3415
2017-06-03 14:21:44.493373 EDT | StdEsReturn                24.8994
2017-06-03 14:21:44.493607 EDT | MaxEsReturn               117
2017-06-03 14:21:44.493895 EDT | MinEsReturn                 3
2017-06-03 14:21:44.494132 EDT | AverageDiscountedReturn    99.9957
2017-06-03 14:21:44.494378 EDT | AverageQLoss                0.000172718
2017-06-03 14:21:44.494614 EDT | AveragePolicySurr          -0.224596
2017-06-03 14:21:44.494846 EDT | AverageQ                    0.212111
2017-06-03 14:21:44.495087 EDT | AverageAbsQ                 0.212932
2017-06-03 14:21:44.495321 EDT | AverageY                    0.212127
2017-06-03 14:21:44.495556 EDT | AverageAbsY                 0.212326
2017-06-03 14:21:44.495786 EDT | AverageAbsQYDiff            0.00361145
2017-06-03 14:21:44.496016 EDT | AverageAction               0.531314
2017-06-03 14:21:44.496246 EDT | PolicyRegParamNorm         50.7315
2017-06-03 14:21:44.496476 EDT | QFunRegParamNorm           25.3566
2017-06-03 14:21:44.496706 EDT | -----------------------  --------------
2017-06-03 14:21:44.497210 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #201 | Training started
2017-06-03 14:22:02.890939 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #201 | Training finished
2017-06-03 14:22:02.891809 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #201 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 14:22:02.892103 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #201 | Collecting samples for evaluation
2017-06-03 14:22:12.635428 EDT | -----------------------  --------------
2017-06-03 14:22:12.636250 EDT | Epoch                     201
2017-06-03 14:22:12.636679 EDT | Iteration                 201
2017-06-03 14:22:12.637054 EDT | AverageReturn            1000
2017-06-03 14:22:12.637386 EDT | StdReturn                   0
2017-06-03 14:22:12.637753 EDT | MaxReturn                1000
2017-06-03 14:22:12.638126 EDT | MinReturn                1000
2017-06-03 14:22:12.638448 EDT | AverageEsReturn            40.6087
2017-06-03 14:22:12.638792 EDT | StdEsReturn                42.2567
2017-06-03 14:22:12.639122 EDT | MaxEsReturn               177
2017-06-03 14:22:12.639459 EDT | MinEsReturn                 3
2017-06-03 14:22:12.639810 EDT | AverageDiscountedReturn    99.9957
2017-06-03 14:22:12.640123 EDT | AverageQLoss                0.000177863
2017-06-03 14:22:12.640470 EDT | AveragePolicySurr          -0.222918
2017-06-03 14:22:12.640806 EDT | AverageQ                    0.210849
2017-06-03 14:22:12.641126 EDT | AverageAbsQ                 0.211636
2017-06-03 14:22:12.641466 EDT | AverageY                    0.210839
2017-06-03 14:22:12.641797 EDT | AverageAbsY                 0.211028
2017-06-03 14:22:12.642141 EDT | AverageAbsQYDiff            0.00364216
2017-06-03 14:22:12.642485 EDT | AverageAction               0.361543
2017-06-03 14:22:12.642793 EDT | PolicyRegParamNorm         50.7822
2017-06-03 14:22:12.643132 EDT | QFunRegParamNorm           25.3754
2017-06-03 14:22:12.643463 EDT | -----------------------  --------------
2017-06-03 14:22:12.643912 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #202 | Training started
2017-06-03 14:22:30.367200 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #202 | Training finished
2017-06-03 14:22:30.373087 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #202 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 14:22:30.373378 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #202 | Collecting samples for evaluation
2017-06-03 14:22:39.543936 EDT | -----------------------  --------------
2017-06-03 14:22:39.544295 EDT | Epoch                     202
2017-06-03 14:22:39.544538 EDT | Iteration                 202
2017-06-03 14:22:39.544799 EDT | AverageReturn            1000
2017-06-03 14:22:39.545036 EDT | StdReturn                   0
2017-06-03 14:22:39.545260 EDT | MaxReturn                1000
2017-06-03 14:22:39.545483 EDT | MinReturn                1000
2017-06-03 14:22:39.545712 EDT | AverageEsReturn            25.3659
2017-06-03 14:22:39.545949 EDT | StdEsReturn                22.054
2017-06-03 14:22:39.546175 EDT | MaxEsReturn                90
2017-06-03 14:22:39.546401 EDT | MinEsReturn                 4
2017-06-03 14:22:39.546626 EDT | AverageDiscountedReturn    99.9957
2017-06-03 14:22:39.546852 EDT | AverageQLoss                0.000183474
2017-06-03 14:22:39.547075 EDT | AveragePolicySurr          -0.221289
2017-06-03 14:22:39.547300 EDT | AverageQ                    0.209508
2017-06-03 14:22:39.547526 EDT | AverageAbsQ                 0.210196
2017-06-03 14:22:39.547751 EDT | AverageY                    0.209505
2017-06-03 14:22:39.547972 EDT | AverageAbsY                 0.20962
2017-06-03 14:22:39.548192 EDT | AverageAbsQYDiff            0.00347357
2017-06-03 14:22:39.548412 EDT | AverageAction               0.494364
2017-06-03 14:22:39.548635 EDT | PolicyRegParamNorm         50.8168
2017-06-03 14:22:39.548860 EDT | QFunRegParamNorm           25.3951
2017-06-03 14:22:39.549084 EDT | -----------------------  --------------
2017-06-03 14:22:39.549457 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #203 | Training started
2017-06-03 14:22:57.767497 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #203 | Training finished
2017-06-03 14:22:57.770657 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #203 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 14:22:57.770936 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #203 | Collecting samples for evaluation
2017-06-03 14:23:06.535347 EDT | -----------------------  --------------
2017-06-03 14:23:06.536344 EDT | Epoch                     203
2017-06-03 14:23:06.536694 EDT | Iteration                 203
2017-06-03 14:23:06.537031 EDT | AverageReturn            1000
2017-06-03 14:23:06.537352 EDT | StdReturn                   0
2017-06-03 14:23:06.537670 EDT | MaxReturn                1000
2017-06-03 14:23:06.537997 EDT | MinReturn                1000
2017-06-03 14:23:06.538327 EDT | AverageEsReturn            29.5588
2017-06-03 14:23:06.538645 EDT | StdEsReturn                31.0722
2017-06-03 14:23:06.538965 EDT | MaxEsReturn               165
2017-06-03 14:23:06.539276 EDT | MinEsReturn                 3
2017-06-03 14:23:06.539588 EDT | AverageDiscountedReturn    99.9957
2017-06-03 14:23:06.539901 EDT | AverageQLoss                0.000194501
2017-06-03 14:23:06.540216 EDT | AveragePolicySurr          -0.220001
2017-06-03 14:23:06.540529 EDT | AverageQ                    0.207902
2017-06-03 14:23:06.540842 EDT | AverageAbsQ                 0.208748
2017-06-03 14:23:06.541158 EDT | AverageY                    0.20789
2017-06-03 14:23:06.541470 EDT | AverageAbsY                 0.207994
2017-06-03 14:23:06.541791 EDT | AverageAbsQYDiff            0.00389712
2017-06-03 14:23:06.542108 EDT | AverageAction               0.322117
2017-06-03 14:23:06.542421 EDT | PolicyRegParamNorm         50.9058
2017-06-03 14:23:06.542733 EDT | QFunRegParamNorm           25.4064
2017-06-03 14:23:06.543045 EDT | -----------------------  --------------
2017-06-03 14:23:06.543471 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #204 | Training started
2017-06-03 14:23:25.303930 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #204 | Training finished
2017-06-03 14:23:25.304836 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #204 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 14:23:25.305207 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #204 | Collecting samples for evaluation
2017-06-03 14:23:35.051513 EDT | -----------------------  --------------
2017-06-03 14:23:35.052401 EDT | Epoch                     204
2017-06-03 14:23:35.052672 EDT | Iteration                 204
2017-06-03 14:23:35.052933 EDT | AverageReturn            1000
2017-06-03 14:23:35.053193 EDT | StdReturn                   0
2017-06-03 14:23:35.053436 EDT | MaxReturn                1000
2017-06-03 14:23:35.054618 EDT | MinReturn                1000
2017-06-03 14:23:35.054922 EDT | AverageEsReturn            27.5946
2017-06-03 14:23:35.055190 EDT | StdEsReturn                24.2682
2017-06-03 14:23:35.055471 EDT | MaxEsReturn                86
2017-06-03 14:23:35.056005 EDT | MinEsReturn                 5
2017-06-03 14:23:35.056646 EDT | AverageDiscountedReturn    99.9957
2017-06-03 14:23:35.056974 EDT | AverageQLoss                0.000153361
2017-06-03 14:23:35.057215 EDT | AveragePolicySurr          -0.218862
2017-06-03 14:23:35.057458 EDT | AverageQ                    0.207482
2017-06-03 14:23:35.057738 EDT | AverageAbsQ                 0.207998
2017-06-03 14:23:35.058000 EDT | AverageY                    0.207487
2017-06-03 14:23:35.058235 EDT | AverageAbsY                 0.207541
2017-06-03 14:23:35.058482 EDT | AverageAbsQYDiff            0.00294406
2017-06-03 14:23:35.058719 EDT | AverageAction               0.462797
2017-06-03 14:23:35.058952 EDT | PolicyRegParamNorm         51.0464
2017-06-03 14:23:35.059202 EDT | QFunRegParamNorm           25.4445
2017-06-03 14:23:35.059438 EDT | -----------------------  --------------
2017-06-03 14:23:35.059841 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #205 | Training started
2017-06-03 14:23:53.266728 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #205 | Training finished
2017-06-03 14:23:53.267663 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #205 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 14:23:53.267941 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #205 | Collecting samples for evaluation
2017-06-03 14:24:03.384009 EDT | -----------------------  --------------
2017-06-03 14:24:03.384835 EDT | Epoch                     205
2017-06-03 14:24:03.385089 EDT | Iteration                 205
2017-06-03 14:24:03.385326 EDT | AverageReturn            1000
2017-06-03 14:24:03.385557 EDT | StdReturn                   0
2017-06-03 14:24:03.385797 EDT | MaxReturn                1000
2017-06-03 14:24:03.386027 EDT | MinReturn                1000
2017-06-03 14:24:03.386255 EDT | AverageEsReturn            25.8205
2017-06-03 14:24:03.386485 EDT | StdEsReturn                20.2001
2017-06-03 14:24:03.386712 EDT | MaxEsReturn               105
2017-06-03 14:24:03.386958 EDT | MinEsReturn                 4
2017-06-03 14:24:03.387186 EDT | AverageDiscountedReturn    99.9957
2017-06-03 14:24:03.387412 EDT | AverageQLoss                0.000162067
2017-06-03 14:24:03.387639 EDT | AveragePolicySurr          -0.217619
2017-06-03 14:24:03.387866 EDT | AverageQ                    0.205505
2017-06-03 14:24:03.388103 EDT | AverageAbsQ                 0.206209
2017-06-03 14:24:03.388328 EDT | AverageY                    0.205501
2017-06-03 14:24:03.388554 EDT | AverageAbsY                 0.205598
2017-06-03 14:24:03.388780 EDT | AverageAbsQYDiff            0.00317966
2017-06-03 14:24:03.389004 EDT | AverageAction               0.458512
2017-06-03 14:24:03.389232 EDT | PolicyRegParamNorm         51.0365
2017-06-03 14:24:03.389457 EDT | QFunRegParamNorm           25.4556
2017-06-03 14:24:03.389682 EDT | -----------------------  --------------
2017-06-03 14:24:03.390065 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #206 | Training started
2017-06-03 14:24:21.952637 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #206 | Training finished
2017-06-03 14:24:21.953516 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #206 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 14:24:21.953877 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #206 | Collecting samples for evaluation
2017-06-03 14:24:32.451332 EDT | -----------------------  --------------
2017-06-03 14:24:32.452194 EDT | Epoch                     206
2017-06-03 14:24:32.452598 EDT | Iteration                 206
2017-06-03 14:24:32.452936 EDT | AverageReturn            1000
2017-06-03 14:24:32.453274 EDT | StdReturn                   0
2017-06-03 14:24:32.453605 EDT | MaxReturn                1000
2017-06-03 14:24:32.453970 EDT | MinReturn                1000
2017-06-03 14:24:32.454312 EDT | AverageEsReturn            24.75
2017-06-03 14:24:32.454636 EDT | StdEsReturn                21.8709
2017-06-03 14:24:32.454968 EDT | MaxEsReturn               103
2017-06-03 14:24:32.455300 EDT | MinEsReturn                 3
2017-06-03 14:24:32.455617 EDT | AverageDiscountedReturn    99.9957
2017-06-03 14:24:32.455949 EDT | AverageQLoss                0.000157906
2017-06-03 14:24:32.456329 EDT | AveragePolicySurr          -0.216552
2017-06-03 14:24:32.456654 EDT | AverageQ                    0.204902
2017-06-03 14:24:32.457000 EDT | AverageAbsQ                 0.205545
2017-06-03 14:24:32.457313 EDT | AverageY                    0.204894
2017-06-03 14:24:32.457642 EDT | AverageAbsY                 0.204981
2017-06-03 14:24:32.457969 EDT | AverageAbsQYDiff            0.00304299
2017-06-03 14:24:32.458288 EDT | AverageAction               0.0067526
2017-06-03 14:24:32.458641 EDT | PolicyRegParamNorm         51.0455
2017-06-03 14:24:32.458957 EDT | QFunRegParamNorm           25.442
2017-06-03 14:24:32.459280 EDT | -----------------------  --------------
2017-06-03 14:24:32.459727 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #207 | Training started
2017-06-03 14:24:51.851005 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #207 | Training finished
2017-06-03 14:24:51.851910 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #207 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 14:24:51.852164 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #207 | Collecting samples for evaluation
2017-06-03 14:25:00.881366 EDT | -----------------------  --------------
2017-06-03 14:25:00.882375 EDT | Epoch                     207
2017-06-03 14:25:00.882723 EDT | Iteration                 207
2017-06-03 14:25:00.883043 EDT | AverageReturn            1000
2017-06-03 14:25:00.883363 EDT | StdReturn                   0
2017-06-03 14:25:00.883687 EDT | MaxReturn                1000
2017-06-03 14:25:00.883997 EDT | MinReturn                1000
2017-06-03 14:25:00.884311 EDT | AverageEsReturn            21.0638
2017-06-03 14:25:00.884577 EDT | StdEsReturn                12.1049
2017-06-03 14:25:00.884822 EDT | MaxEsReturn                59
2017-06-03 14:25:00.885062 EDT | MinEsReturn                 3
2017-06-03 14:25:00.885299 EDT | AverageDiscountedReturn    99.9957
2017-06-03 14:25:00.885535 EDT | AverageQLoss                0.000150093
2017-06-03 14:25:00.885793 EDT | AveragePolicySurr          -0.215164
2017-06-03 14:25:00.886030 EDT | AverageQ                    0.204034
2017-06-03 14:25:00.886266 EDT | AverageAbsQ                 0.20468
2017-06-03 14:25:00.886501 EDT | AverageY                    0.204041
2017-06-03 14:25:00.886740 EDT | AverageAbsY                 0.204137
2017-06-03 14:25:00.886976 EDT | AverageAbsQYDiff            0.00303695
2017-06-03 14:25:00.887213 EDT | AverageAction               0.00606896
2017-06-03 14:25:00.887447 EDT | PolicyRegParamNorm         51.0549
2017-06-03 14:25:00.887683 EDT | QFunRegParamNorm           25.4552
2017-06-03 14:25:00.887918 EDT | -----------------------  --------------
2017-06-03 14:25:00.888317 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #208 | Training started
2017-06-03 14:25:19.950858 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #208 | Training finished
2017-06-03 14:25:19.951698 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #208 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 14:25:19.951960 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #208 | Collecting samples for evaluation
2017-06-03 14:25:29.958894 EDT | -----------------------  --------------
2017-06-03 14:25:29.959431 EDT | Epoch                     208
2017-06-03 14:25:29.959710 EDT | Iteration                 208
2017-06-03 14:25:29.959988 EDT | AverageReturn            1000
2017-06-03 14:25:29.960248 EDT | StdReturn                   0
2017-06-03 14:25:29.960494 EDT | MaxReturn                1000
2017-06-03 14:25:29.960738 EDT | MinReturn                1000
2017-06-03 14:25:29.960994 EDT | AverageEsReturn            28.3611
2017-06-03 14:25:29.961243 EDT | StdEsReturn                24.3917
2017-06-03 14:25:29.961488 EDT | MaxEsReturn               120
2017-06-03 14:25:29.961738 EDT | MinEsReturn                 4
2017-06-03 14:25:29.961983 EDT | AverageDiscountedReturn    99.9957
2017-06-03 14:25:29.962224 EDT | AverageQLoss                0.000190813
2017-06-03 14:25:29.962464 EDT | AveragePolicySurr          -0.213534
2017-06-03 14:25:29.962705 EDT | AverageQ                    0.202457
2017-06-03 14:25:29.962945 EDT | AverageAbsQ                 0.203218
2017-06-03 14:25:29.963185 EDT | AverageY                    0.202451
2017-06-03 14:25:29.963427 EDT | AverageAbsY                 0.20255
2017-06-03 14:25:29.963669 EDT | AverageAbsQYDiff            0.00343346
2017-06-03 14:25:29.963911 EDT | AverageAction               0.00647311
2017-06-03 14:25:29.964150 EDT | PolicyRegParamNorm         51.035
2017-06-03 14:25:29.964388 EDT | QFunRegParamNorm           25.4817
2017-06-03 14:25:29.964627 EDT | -----------------------  --------------
2017-06-03 14:25:29.964977 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #209 | Training started
2017-06-03 14:25:48.492744 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #209 | Training finished
2017-06-03 14:25:48.493633 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #209 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 14:25:48.494023 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #209 | Collecting samples for evaluation
2017-06-03 14:25:59.110809 EDT | -----------------------  --------------
2017-06-03 14:25:59.111652 EDT | Epoch                     209
2017-06-03 14:25:59.111920 EDT | Iteration                 209
2017-06-03 14:25:59.112201 EDT | AverageReturn            1000
2017-06-03 14:25:59.112438 EDT | StdReturn                   0
2017-06-03 14:25:59.112672 EDT | MaxReturn                1000
2017-06-03 14:25:59.112910 EDT | MinReturn                1000
2017-06-03 14:25:59.113141 EDT | AverageEsReturn            17.2586
2017-06-03 14:25:59.113383 EDT | StdEsReturn                15.6068
2017-06-03 14:25:59.113615 EDT | MaxEsReturn                72
2017-06-03 14:25:59.113867 EDT | MinEsReturn                 3
2017-06-03 14:25:59.114103 EDT | AverageDiscountedReturn    99.9957
2017-06-03 14:25:59.114334 EDT | AverageQLoss                0.000131022
2017-06-03 14:25:59.114564 EDT | AveragePolicySurr          -0.212424
2017-06-03 14:25:59.114794 EDT | AverageQ                    0.201084
2017-06-03 14:25:59.115025 EDT | AverageAbsQ                 0.201626
2017-06-03 14:25:59.115256 EDT | AverageY                    0.201077
2017-06-03 14:25:59.115484 EDT | AverageAbsY                 0.201171
2017-06-03 14:25:59.115713 EDT | AverageAbsQYDiff            0.00275652
2017-06-03 14:25:59.115942 EDT | AverageAction               0.00037174
2017-06-03 14:25:59.116171 EDT | PolicyRegParamNorm         51.0904
2017-06-03 14:25:59.116399 EDT | QFunRegParamNorm           25.4908
2017-06-03 14:25:59.116629 EDT | -----------------------  --------------
2017-06-03 14:25:59.116968 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #210 | Training started
2017-06-03 14:26:18.277049 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #210 | Training finished
2017-06-03 14:26:18.277962 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #210 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 14:26:18.278236 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #210 | Collecting samples for evaluation
2017-06-03 14:26:29.202057 EDT | -----------------------  --------------
2017-06-03 14:26:29.202906 EDT | Epoch                     210
2017-06-03 14:26:29.203163 EDT | Iteration                 210
2017-06-03 14:26:29.203406 EDT | AverageReturn            1000
2017-06-03 14:26:29.203682 EDT | StdReturn                   0
2017-06-03 14:26:29.203911 EDT | MaxReturn                1000
2017-06-03 14:26:29.204137 EDT | MinReturn                1000
2017-06-03 14:26:29.204361 EDT | AverageEsReturn            16.9153
2017-06-03 14:26:29.204585 EDT | StdEsReturn                11.42
2017-06-03 14:26:29.204821 EDT | MaxEsReturn                43
2017-06-03 14:26:29.205040 EDT | MinEsReturn                 2
2017-06-03 14:26:29.205261 EDT | AverageDiscountedReturn    99.9957
2017-06-03 14:26:29.205482 EDT | AverageQLoss                0.000193299
2017-06-03 14:26:29.205712 EDT | AveragePolicySurr          -0.211042
2017-06-03 14:26:29.205947 EDT | AverageQ                    0.199906
2017-06-03 14:26:29.206170 EDT | AverageAbsQ                 0.200747
2017-06-03 14:26:29.206392 EDT | AverageY                    0.199904
2017-06-03 14:26:29.206612 EDT | AverageAbsY                 0.200028
2017-06-03 14:26:29.206834 EDT | AverageAbsQYDiff            0.00350936
2017-06-03 14:26:29.207054 EDT | AverageAction               0.00892267
2017-06-03 14:26:29.207275 EDT | PolicyRegParamNorm         51.1235
2017-06-03 14:26:29.207496 EDT | QFunRegParamNorm           25.5067
2017-06-03 14:26:29.207716 EDT | -----------------------  --------------
2017-06-03 14:26:29.208079 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #211 | Training started
2017-06-03 14:26:49.076724 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #211 | Training finished
2017-06-03 14:26:49.077634 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #211 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 14:26:49.078021 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #211 | Collecting samples for evaluation
2017-06-03 14:26:59.529290 EDT | -----------------------  --------------
2017-06-03 14:26:59.530264 EDT | Epoch                     211
2017-06-03 14:26:59.530531 EDT | Iteration                 211
2017-06-03 14:26:59.530769 EDT | AverageReturn            1000
2017-06-03 14:26:59.531001 EDT | StdReturn                   0
2017-06-03 14:26:59.531246 EDT | MaxReturn                1000
2017-06-03 14:26:59.531477 EDT | MinReturn                1000
2017-06-03 14:26:59.531705 EDT | AverageEsReturn            17.8393
2017-06-03 14:26:59.531933 EDT | StdEsReturn                14.5194
2017-06-03 14:26:59.532162 EDT | MaxEsReturn                69
2017-06-03 14:26:59.532401 EDT | MinEsReturn                 3
2017-06-03 14:26:59.532640 EDT | AverageDiscountedReturn    99.9957
2017-06-03 14:26:59.532878 EDT | AverageQLoss                0.000148121
2017-06-03 14:26:59.533117 EDT | AveragePolicySurr          -0.209887
2017-06-03 14:26:59.533358 EDT | AverageQ                    0.198773
2017-06-03 14:26:59.533594 EDT | AverageAbsQ                 0.199338
2017-06-03 14:26:59.534314 EDT | AverageY                    0.198773
2017-06-03 14:26:59.534637 EDT | AverageAbsY                 0.198894
2017-06-03 14:26:59.534956 EDT | AverageAbsQYDiff            0.00283976
2017-06-03 14:26:59.535300 EDT | AverageAction               0.00720657
2017-06-03 14:26:59.535677 EDT | PolicyRegParamNorm         51.1287
2017-06-03 14:26:59.536001 EDT | QFunRegParamNorm           25.52
2017-06-03 14:26:59.536310 EDT | -----------------------  --------------
2017-06-03 14:26:59.536735 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #212 | Training started
2017-06-03 14:27:17.937380 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #212 | Training finished
2017-06-03 14:27:17.938422 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #212 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 14:27:17.938774 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #212 | Collecting samples for evaluation
2017-06-03 14:27:27.529377 EDT | -----------------------  --------------
2017-06-03 14:27:27.530256 EDT | Epoch                     212
2017-06-03 14:27:27.530547 EDT | Iteration                 212
2017-06-03 14:27:27.530828 EDT | AverageReturn            1000
2017-06-03 14:27:27.531112 EDT | StdReturn                   0
2017-06-03 14:27:27.531363 EDT | MaxReturn                1000
2017-06-03 14:27:27.531609 EDT | MinReturn                1000
2017-06-03 14:27:27.531854 EDT | AverageEsReturn            15.6719
2017-06-03 14:27:27.532098 EDT | StdEsReturn                10.3804
2017-06-03 14:27:27.532352 EDT | MaxEsReturn                43
2017-06-03 14:27:27.532595 EDT | MinEsReturn                 3
2017-06-03 14:27:27.532842 EDT | AverageDiscountedReturn    99.9957
2017-06-03 14:27:27.533085 EDT | AverageQLoss                0.000160725
2017-06-03 14:27:27.533326 EDT | AveragePolicySurr          -0.208504
2017-06-03 14:27:27.533566 EDT | AverageQ                    0.197185
2017-06-03 14:27:27.533835 EDT | AverageAbsQ                 0.19792
2017-06-03 14:27:27.534078 EDT | AverageY                    0.197174
2017-06-03 14:27:27.534321 EDT | AverageAbsY                 0.197257
2017-06-03 14:27:27.534563 EDT | AverageAbsQYDiff            0.00309757
2017-06-03 14:27:27.534814 EDT | AverageAction               0.000415803
2017-06-03 14:27:27.535056 EDT | PolicyRegParamNorm         51.116
2017-06-03 14:27:27.535298 EDT | QFunRegParamNorm           25.5249
2017-06-03 14:27:27.535545 EDT | -----------------------  --------------
2017-06-03 14:27:27.535932 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #213 | Training started
2017-06-03 14:27:46.586203 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #213 | Training finished
2017-06-03 14:27:46.587049 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #213 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 14:27:46.587352 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #213 | Collecting samples for evaluation
2017-06-03 14:27:55.396173 EDT | -----------------------  --------------
2017-06-03 14:27:55.397401 EDT | Epoch                     213
2017-06-03 14:27:55.397783 EDT | Iteration                 213
2017-06-03 14:27:55.398122 EDT | AverageReturn            1000
2017-06-03 14:27:55.398951 EDT | StdReturn                   0
2017-06-03 14:27:55.399309 EDT | MaxReturn                1000
2017-06-03 14:27:55.399706 EDT | MinReturn                1000
2017-06-03 14:27:55.400096 EDT | AverageEsReturn            20.7292
2017-06-03 14:27:55.400575 EDT | StdEsReturn                16.3615
2017-06-03 14:27:55.400978 EDT | MaxEsReturn                67
2017-06-03 14:27:55.401441 EDT | MinEsReturn                 2
2017-06-03 14:27:55.401874 EDT | AverageDiscountedReturn    99.9957
2017-06-03 14:27:55.402295 EDT | AverageQLoss                0.000131828
2017-06-03 14:27:55.402719 EDT | AveragePolicySurr          -0.207606
2017-06-03 14:27:55.403042 EDT | AverageQ                    0.196516
2017-06-03 14:27:55.403421 EDT | AverageAbsQ                 0.197073
2017-06-03 14:27:55.403811 EDT | AverageY                    0.196524
2017-06-03 14:27:55.404135 EDT | AverageAbsY                 0.196614
2017-06-03 14:27:55.404452 EDT | AverageAbsQYDiff            0.00266186
2017-06-03 14:27:55.404765 EDT | AverageAction               0.00217676
2017-06-03 14:27:55.405078 EDT | PolicyRegParamNorm         51.1582
2017-06-03 14:27:55.405392 EDT | QFunRegParamNorm           25.5542
2017-06-03 14:27:55.405742 EDT | -----------------------  --------------
2017-06-03 14:27:55.406209 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #214 | Training started
2017-06-03 14:28:13.763022 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #214 | Training finished
2017-06-03 14:28:13.763922 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #214 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 14:28:13.764338 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #214 | Collecting samples for evaluation
2017-06-03 14:28:23.121604 EDT | -----------------------  --------------
2017-06-03 14:28:23.122578 EDT | Epoch                     214
2017-06-03 14:28:23.122843 EDT | Iteration                 214
2017-06-03 14:28:23.123079 EDT | AverageReturn            1000
2017-06-03 14:28:23.123377 EDT | StdReturn                   0
2017-06-03 14:28:23.123611 EDT | MaxReturn                1000
2017-06-03 14:28:23.123850 EDT | MinReturn                1000
2017-06-03 14:28:23.124079 EDT | AverageEsReturn            17.4737
2017-06-03 14:28:23.124361 EDT | StdEsReturn                18.6605
2017-06-03 14:28:23.124739 EDT | MaxEsReturn               108
2017-06-03 14:28:23.125120 EDT | MinEsReturn                 3
2017-06-03 14:28:23.125459 EDT | AverageDiscountedReturn    99.9957
2017-06-03 14:28:23.126336 EDT | AverageQLoss                0.000173905
2017-06-03 14:28:23.126882 EDT | AveragePolicySurr          -0.20568
2017-06-03 14:28:23.127349 EDT | AverageQ                    0.194846
2017-06-03 14:28:23.127845 EDT | AverageAbsQ                 0.195623
2017-06-03 14:28:23.128168 EDT | AverageY                    0.194833
2017-06-03 14:28:23.128484 EDT | AverageAbsY                 0.194899
2017-06-03 14:28:23.128798 EDT | AverageAbsQYDiff            0.00319843
2017-06-03 14:28:23.129115 EDT | AverageAction               0.00185553
2017-06-03 14:28:23.129422 EDT | PolicyRegParamNorm         51.1808
2017-06-03 14:28:23.129735 EDT | QFunRegParamNorm           25.56
2017-06-03 14:28:23.130049 EDT | -----------------------  --------------
2017-06-03 14:28:23.130519 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #215 | Training started
2017-06-03 14:28:42.574533 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #215 | Training finished
2017-06-03 14:28:42.575449 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #215 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 14:28:42.575819 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #215 | Collecting samples for evaluation
2017-06-03 14:28:53.391076 EDT | -----------------------  --------------
2017-06-03 14:28:53.391912 EDT | Epoch                     215
2017-06-03 14:28:53.392182 EDT | Iteration                 215
2017-06-03 14:28:53.392423 EDT | AverageReturn            1000
2017-06-03 14:28:53.392654 EDT | StdReturn                   0
2017-06-03 14:28:53.392893 EDT | MaxReturn                1000
2017-06-03 14:28:53.393127 EDT | MinReturn                1000
2017-06-03 14:28:53.393355 EDT | AverageEsReturn            18.6667
2017-06-03 14:28:53.393588 EDT | StdEsReturn                17.0348
2017-06-03 14:28:53.393827 EDT | MaxEsReturn                81
2017-06-03 14:28:53.394055 EDT | MinEsReturn                 3
2017-06-03 14:28:53.394282 EDT | AverageDiscountedReturn    99.9957
2017-06-03 14:28:53.394508 EDT | AverageQLoss                0.000157226
2017-06-03 14:28:53.394735 EDT | AveragePolicySurr          -0.20487
2017-06-03 14:28:53.394963 EDT | AverageQ                    0.193891
2017-06-03 14:28:53.395189 EDT | AverageAbsQ                 0.194408
2017-06-03 14:28:53.395415 EDT | AverageY                    0.193899
2017-06-03 14:28:53.395640 EDT | AverageAbsY                 0.193993
2017-06-03 14:28:53.395866 EDT | AverageAbsQYDiff            0.00280728
2017-06-03 14:28:53.396091 EDT | AverageAction               0.00329079
2017-06-03 14:28:53.396323 EDT | PolicyRegParamNorm         51.167
2017-06-03 14:28:53.396551 EDT | QFunRegParamNorm           25.5778
2017-06-03 14:28:53.396787 EDT | -----------------------  --------------
2017-06-03 14:28:53.397125 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #216 | Training started
2017-06-03 14:29:13.444591 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #216 | Training finished
2017-06-03 14:29:13.445532 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #216 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 14:29:13.445826 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #216 | Collecting samples for evaluation
2017-06-03 14:29:22.441178 EDT | -----------------------  --------------
2017-06-03 14:29:22.442179 EDT | Epoch                     216
2017-06-03 14:29:22.442458 EDT | Iteration                 216
2017-06-03 14:29:22.442707 EDT | AverageReturn            1000
2017-06-03 14:29:22.442951 EDT | StdReturn                   0
2017-06-03 14:29:22.443194 EDT | MaxReturn                1000
2017-06-03 14:29:22.443427 EDT | MinReturn                1000
2017-06-03 14:29:22.443662 EDT | AverageEsReturn            14.5588
2017-06-03 14:29:22.443917 EDT | StdEsReturn                10.532
2017-06-03 14:29:22.444148 EDT | MaxEsReturn                52
2017-06-03 14:29:22.444392 EDT | MinEsReturn                 3
2017-06-03 14:29:22.444622 EDT | AverageDiscountedReturn    99.9957
2017-06-03 14:29:22.444866 EDT | AverageQLoss                0.000149063
2017-06-03 14:29:22.445111 EDT | AveragePolicySurr          -0.203709
2017-06-03 14:29:22.445343 EDT | AverageQ                    0.192693
2017-06-03 14:29:22.445591 EDT | AverageAbsQ                 0.193345
2017-06-03 14:29:22.446347 EDT | AverageY                    0.192687
2017-06-03 14:29:22.446751 EDT | AverageAbsY                 0.192819
2017-06-03 14:29:22.447077 EDT | AverageAbsQYDiff            0.00292287
2017-06-03 14:29:22.447429 EDT | AverageAction               0.0134346
2017-06-03 14:29:22.447744 EDT | PolicyRegParamNorm         51.2991
2017-06-03 14:29:22.448067 EDT | QFunRegParamNorm           25.6004
2017-06-03 14:29:22.448383 EDT | -----------------------  --------------
2017-06-03 14:29:22.448878 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #217 | Training started
2017-06-03 14:29:41.023501 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #217 | Training finished
2017-06-03 14:29:41.024517 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #217 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 14:29:41.024866 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #217 | Collecting samples for evaluation
2017-06-03 14:29:50.107284 EDT | -----------------------  --------------
2017-06-03 14:29:50.108145 EDT | Epoch                     217
2017-06-03 14:29:50.108436 EDT | Iteration                 217
2017-06-03 14:29:50.108674 EDT | AverageReturn            1000
2017-06-03 14:29:50.108915 EDT | StdReturn                   0
2017-06-03 14:29:50.109144 EDT | MaxReturn                1000
2017-06-03 14:29:50.109371 EDT | MinReturn                1000
2017-06-03 14:29:50.109618 EDT | AverageEsReturn            17.5088
2017-06-03 14:29:50.109895 EDT | StdEsReturn                15.5215
2017-06-03 14:29:50.110163 EDT | MaxEsReturn                90
2017-06-03 14:29:50.110419 EDT | MinEsReturn                 3
2017-06-03 14:29:50.110649 EDT | AverageDiscountedReturn    99.9957
2017-06-03 14:29:50.110895 EDT | AverageQLoss                0.000149869
2017-06-03 14:29:50.111159 EDT | AveragePolicySurr          -0.202672
2017-06-03 14:29:50.111401 EDT | AverageQ                    0.191862
2017-06-03 14:29:50.111639 EDT | AverageAbsQ                 0.192608
2017-06-03 14:29:50.111866 EDT | AverageY                    0.191853
2017-06-03 14:29:50.112094 EDT | AverageAbsY                 0.191954
2017-06-03 14:29:50.112331 EDT | AverageAbsQYDiff            0.00301007
2017-06-03 14:29:50.112590 EDT | AverageAction               0.039574
2017-06-03 14:29:50.112860 EDT | PolicyRegParamNorm         51.3661
2017-06-03 14:29:50.113119 EDT | QFunRegParamNorm           25.608
2017-06-03 14:29:50.113351 EDT | -----------------------  --------------
2017-06-03 14:29:50.113739 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #218 | Training started
2017-06-03 14:30:08.308674 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #218 | Training finished
2017-06-03 14:30:08.309613 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #218 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 14:30:08.309905 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #218 | Collecting samples for evaluation
2017-06-03 14:30:18.131826 EDT | -----------------------  --------------
2017-06-03 14:30:18.132779 EDT | Epoch                     218
2017-06-03 14:30:18.133058 EDT | Iteration                 218
2017-06-03 14:30:18.133429 EDT | AverageReturn            1000
2017-06-03 14:30:18.133774 EDT | StdReturn                   0
2017-06-03 14:30:18.134093 EDT | MaxReturn                1000
2017-06-03 14:30:18.134415 EDT | MinReturn                1000
2017-06-03 14:30:18.134728 EDT | AverageEsReturn            18.6731
2017-06-03 14:30:18.135062 EDT | StdEsReturn                13.5657
2017-06-03 14:30:18.135375 EDT | MaxEsReturn                59
2017-06-03 14:30:18.135686 EDT | MinEsReturn                 3
2017-06-03 14:30:18.135994 EDT | AverageDiscountedReturn    99.9957
2017-06-03 14:30:18.136314 EDT | AverageQLoss                0.000159041
2017-06-03 14:30:18.136625 EDT | AveragePolicySurr          -0.20127
2017-06-03 14:30:18.136937 EDT | AverageQ                    0.190503
2017-06-03 14:30:18.137245 EDT | AverageAbsQ                 0.191244
2017-06-03 14:30:18.137553 EDT | AverageY                    0.190507
2017-06-03 14:30:18.137874 EDT | AverageAbsY                 0.190619
2017-06-03 14:30:18.138183 EDT | AverageAbsQYDiff            0.00295106
2017-06-03 14:30:18.138492 EDT | AverageAction               0.00467906
2017-06-03 14:30:18.138800 EDT | PolicyRegParamNorm         51.4365
2017-06-03 14:30:18.139107 EDT | QFunRegParamNorm           25.6306
2017-06-03 14:30:18.139416 EDT | -----------------------  --------------
2017-06-03 14:30:18.139994 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #219 | Training started
2017-06-03 14:30:39.300580 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #219 | Training finished
2017-06-03 14:30:39.301623 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #219 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 14:30:39.303066 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #219 | Collecting samples for evaluation
2017-06-03 14:30:49.542541 EDT | -----------------------  --------------
2017-06-03 14:30:49.543402 EDT | Epoch                     219
2017-06-03 14:30:49.543665 EDT | Iteration                 219
2017-06-03 14:30:49.543905 EDT | AverageReturn            1000
2017-06-03 14:30:49.544147 EDT | StdReturn                   0
2017-06-03 14:30:49.544378 EDT | MaxReturn                1000
2017-06-03 14:30:49.544608 EDT | MinReturn                1000
2017-06-03 14:30:49.544837 EDT | AverageEsReturn            29.1429
2017-06-03 14:30:49.545067 EDT | StdEsReturn                21.3584
2017-06-03 14:30:49.545322 EDT | MaxEsReturn                79
2017-06-03 14:30:49.545561 EDT | MinEsReturn                 4
2017-06-03 14:30:49.545804 EDT | AverageDiscountedReturn    99.9957
2017-06-03 14:30:49.546029 EDT | AverageQLoss                0.000160185
2017-06-03 14:30:49.546253 EDT | AveragePolicySurr          -0.199926
2017-06-03 14:30:49.546485 EDT | AverageQ                    0.189368
2017-06-03 14:30:49.546717 EDT | AverageAbsQ                 0.190027
2017-06-03 14:30:49.546943 EDT | AverageY                    0.189353
2017-06-03 14:30:49.547168 EDT | AverageAbsY                 0.189485
2017-06-03 14:30:49.547390 EDT | AverageAbsQYDiff            0.00301675
2017-06-03 14:30:49.547615 EDT | AverageAction               0.00802565
2017-06-03 14:30:49.547840 EDT | PolicyRegParamNorm         51.4969
2017-06-03 14:30:49.548065 EDT | QFunRegParamNorm           25.648
2017-06-03 14:30:49.548287 EDT | -----------------------  --------------
2017-06-03 14:30:49.548635 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #220 | Training started
2017-06-03 14:31:07.921640 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #220 | Training finished
2017-06-03 14:31:07.924258 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #220 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 14:31:07.924573 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #220 | Collecting samples for evaluation
2017-06-03 14:31:17.131864 EDT | -----------------------  --------------
2017-06-03 14:31:17.133466 EDT | Epoch                     220
2017-06-03 14:31:17.133769 EDT | Iteration                 220
2017-06-03 14:31:17.134013 EDT | AverageReturn            1000
2017-06-03 14:31:17.134248 EDT | StdReturn                   0
2017-06-03 14:31:17.134480 EDT | MaxReturn                1000
2017-06-03 14:31:17.134724 EDT | MinReturn                1000
2017-06-03 14:31:17.134959 EDT | AverageEsReturn            23.6279
2017-06-03 14:31:17.135189 EDT | StdEsReturn                21.3335
2017-06-03 14:31:17.135419 EDT | MaxEsReturn               100
2017-06-03 14:31:17.135647 EDT | MinEsReturn                 3
2017-06-03 14:31:17.135876 EDT | AverageDiscountedReturn    99.9957
2017-06-03 14:31:17.136104 EDT | AverageQLoss                0.000133936
2017-06-03 14:31:17.136332 EDT | AveragePolicySurr          -0.198538
2017-06-03 14:31:17.136560 EDT | AverageQ                    0.188042
2017-06-03 14:31:17.136788 EDT | AverageAbsQ                 0.188724
2017-06-03 14:31:17.137037 EDT | AverageY                    0.188049
2017-06-03 14:31:17.137293 EDT | AverageAbsY                 0.188126
2017-06-03 14:31:17.137524 EDT | AverageAbsQYDiff            0.00285046
2017-06-03 14:31:17.138340 EDT | AverageAction               0.00556394
2017-06-03 14:31:17.138664 EDT | PolicyRegParamNorm         51.4959
2017-06-03 14:31:17.139027 EDT | QFunRegParamNorm           25.6657
2017-06-03 14:31:17.139337 EDT | -----------------------  --------------
2017-06-03 14:31:17.139715 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #221 | Training started
2017-06-03 14:31:35.087607 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #221 | Training finished
2017-06-03 14:31:35.088537 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #221 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 14:31:35.088809 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #221 | Collecting samples for evaluation
2017-06-03 14:31:44.219536 EDT | -----------------------  --------------
2017-06-03 14:31:44.219952 EDT | Epoch                     221
2017-06-03 14:31:44.220183 EDT | Iteration                 221
2017-06-03 14:31:44.220408 EDT | AverageReturn            1000
2017-06-03 14:31:44.220625 EDT | StdReturn                   0
2017-06-03 14:31:44.220849 EDT | MaxReturn                1000
2017-06-03 14:31:44.221063 EDT | MinReturn                1000
2017-06-03 14:31:44.221283 EDT | AverageEsReturn            21.3043
2017-06-03 14:31:44.221497 EDT | StdEsReturn                17.9284
2017-06-03 14:31:44.221729 EDT | MaxEsReturn                67
2017-06-03 14:31:44.221948 EDT | MinEsReturn                 3
2017-06-03 14:31:44.222162 EDT | AverageDiscountedReturn    99.9957
2017-06-03 14:31:44.222408 EDT | AverageQLoss                0.000136153
2017-06-03 14:31:44.222673 EDT | AveragePolicySurr          -0.197764
2017-06-03 14:31:44.222914 EDT | AverageQ                    0.187448
2017-06-03 14:31:44.223151 EDT | AverageAbsQ                 0.187955
2017-06-03 14:31:44.223381 EDT | AverageY                    0.187444
2017-06-03 14:31:44.223608 EDT | AverageAbsY                 0.187522
2017-06-03 14:31:44.223845 EDT | AverageAbsQYDiff            0.00273855
2017-06-03 14:31:44.224071 EDT | AverageAction               0.012397
2017-06-03 14:31:44.224305 EDT | PolicyRegParamNorm         51.4768
2017-06-03 14:31:44.224536 EDT | QFunRegParamNorm           25.6619
2017-06-03 14:31:44.224767 EDT | -----------------------  --------------
2017-06-03 14:31:44.225152 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #222 | Training started
2017-06-03 14:32:02.474745 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #222 | Training finished
2017-06-03 14:32:02.475596 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #222 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 14:32:02.475887 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #222 | Collecting samples for evaluation
2017-06-03 14:32:11.947702 EDT | -----------------------  --------------
2017-06-03 14:32:11.948244 EDT | Epoch                     222
2017-06-03 14:32:11.948580 EDT | Iteration                 222
2017-06-03 14:32:11.948922 EDT | AverageReturn            1000
2017-06-03 14:32:11.949261 EDT | StdReturn                   0
2017-06-03 14:32:11.949591 EDT | MaxReturn                1000
2017-06-03 14:32:11.949920 EDT | MinReturn                1000
2017-06-03 14:32:11.950232 EDT | AverageEsReturn            18.2321
2017-06-03 14:32:11.950547 EDT | StdEsReturn                12.8633
2017-06-03 14:32:11.950873 EDT | MaxEsReturn                62
2017-06-03 14:32:11.951197 EDT | MinEsReturn                 3
2017-06-03 14:32:11.951511 EDT | AverageDiscountedReturn    99.9957
2017-06-03 14:32:11.951831 EDT | AverageQLoss                0.000164451
2017-06-03 14:32:11.952171 EDT | AveragePolicySurr          -0.196206
2017-06-03 14:32:11.952481 EDT | AverageQ                    0.186222
2017-06-03 14:32:11.952818 EDT | AverageAbsQ                 0.186935
2017-06-03 14:32:11.953130 EDT | AverageY                    0.18622
2017-06-03 14:32:11.953440 EDT | AverageAbsY                 0.186324
2017-06-03 14:32:11.953762 EDT | AverageAbsQYDiff            0.00328347
2017-06-03 14:32:11.954087 EDT | AverageAction               0.0209819
2017-06-03 14:32:11.954399 EDT | PolicyRegParamNorm         51.483
2017-06-03 14:32:11.954709 EDT | QFunRegParamNorm           25.6692
2017-06-03 14:32:11.955028 EDT | -----------------------  --------------
2017-06-03 14:32:11.955467 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #223 | Training started
2017-06-03 14:32:29.916782 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #223 | Training finished
2017-06-03 14:32:29.917590 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #223 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 14:32:29.917880 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #223 | Collecting samples for evaluation
2017-06-03 14:32:40.404993 EDT | -----------------------  --------------
2017-06-03 14:32:40.405835 EDT | Epoch                     223
2017-06-03 14:32:40.406098 EDT | Iteration                 223
2017-06-03 14:32:40.406340 EDT | AverageReturn            1000
2017-06-03 14:32:40.406576 EDT | StdReturn                   0
2017-06-03 14:32:40.406812 EDT | MaxReturn                1000
2017-06-03 14:32:40.407065 EDT | MinReturn                1000
2017-06-03 14:32:40.407308 EDT | AverageEsReturn            20.3469
2017-06-03 14:32:40.407578 EDT | StdEsReturn                21.6178
2017-06-03 14:32:40.407819 EDT | MaxEsReturn               117
2017-06-03 14:32:40.408059 EDT | MinEsReturn                 3
2017-06-03 14:32:40.408298 EDT | AverageDiscountedReturn    99.9957
2017-06-03 14:32:40.408540 EDT | AverageQLoss                0.000115876
2017-06-03 14:32:40.408780 EDT | AveragePolicySurr          -0.195151
2017-06-03 14:32:40.409033 EDT | AverageQ                    0.184743
2017-06-03 14:32:40.409278 EDT | AverageAbsQ                 0.185366
2017-06-03 14:32:40.409519 EDT | AverageY                    0.184742
2017-06-03 14:32:40.409773 EDT | AverageAbsY                 0.184839
2017-06-03 14:32:40.410016 EDT | AverageAbsQYDiff            0.00269052
2017-06-03 14:32:40.410265 EDT | AverageAction               0.00712664
2017-06-03 14:32:40.410512 EDT | PolicyRegParamNorm         51.4705
2017-06-03 14:32:40.410751 EDT | QFunRegParamNorm           25.6977
2017-06-03 14:32:40.410991 EDT | -----------------------  --------------
2017-06-03 14:32:40.411512 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #224 | Training started
2017-06-03 14:32:58.863577 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #224 | Training finished
2017-06-03 14:32:58.864898 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #224 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 14:32:58.865204 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #224 | Collecting samples for evaluation
2017-06-03 14:33:08.610139 EDT | -----------------------  -------------
2017-06-03 14:33:08.610979 EDT | Epoch                    224
2017-06-03 14:33:08.611246 EDT | Iteration                224
2017-06-03 14:33:08.611489 EDT | AverageReturn             57.0852
2017-06-03 14:33:08.611726 EDT | StdReturn                  0.592192
2017-06-03 14:33:08.611959 EDT | MaxReturn                 58
2017-06-03 14:33:08.612192 EDT | MinReturn                 56
2017-06-03 14:33:08.612434 EDT | AverageEsReturn           18.0943
2017-06-03 14:33:08.612665 EDT | StdEsReturn               15.0962
2017-06-03 14:33:08.612896 EDT | MaxEsReturn               68
2017-06-03 14:33:08.613128 EDT | MinEsReturn                3
2017-06-03 14:33:08.613359 EDT | AverageDiscountedReturn   43.6568
2017-06-03 14:33:08.613589 EDT | AverageQLoss               0.000147352
2017-06-03 14:33:08.613832 EDT | AveragePolicySurr         -0.194219
2017-06-03 14:33:08.614062 EDT | AverageQ                   0.183767
2017-06-03 14:33:08.614292 EDT | AverageAbsQ                0.184455
2017-06-03 14:33:08.614523 EDT | AverageY                   0.183768
2017-06-03 14:33:08.614753 EDT | AverageAbsY                0.183885
2017-06-03 14:33:08.614983 EDT | AverageAbsQYDiff           0.00309257
2017-06-03 14:33:08.615212 EDT | AverageAction              0.293904
2017-06-03 14:33:08.615440 EDT | PolicyRegParamNorm        51.5309
2017-06-03 14:33:08.615669 EDT | QFunRegParamNorm          25.7029
2017-06-03 14:33:08.615897 EDT | -----------------------  -------------
2017-06-03 14:33:08.616287 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #225 | Training started
2017-06-03 14:33:27.068475 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #225 | Training finished
2017-06-03 14:33:27.069417 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #225 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 14:33:27.069691 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #225 | Collecting samples for evaluation
2017-06-03 14:33:36.914461 EDT | -----------------------  --------------
2017-06-03 14:33:36.915319 EDT | Epoch                     225
2017-06-03 14:33:36.915581 EDT | Iteration                 225
2017-06-03 14:33:36.915823 EDT | AverageReturn            1000
2017-06-03 14:33:36.916063 EDT | StdReturn                   0
2017-06-03 14:33:36.916297 EDT | MaxReturn                1000
2017-06-03 14:33:36.916539 EDT | MinReturn                1000
2017-06-03 14:33:36.916783 EDT | AverageEsReturn            19.7736
2017-06-03 14:33:36.917020 EDT | StdEsReturn                18.1946
2017-06-03 14:33:36.917256 EDT | MaxEsReturn                95
2017-06-03 14:33:36.917489 EDT | MinEsReturn                 3
2017-06-03 14:33:36.917733 EDT | AverageDiscountedReturn    99.9957
2017-06-03 14:33:36.917969 EDT | AverageQLoss                0.000150912
2017-06-03 14:33:36.918200 EDT | AveragePolicySurr          -0.193101
2017-06-03 14:33:36.918432 EDT | AverageQ                    0.182856
2017-06-03 14:33:36.918663 EDT | AverageAbsQ                 0.183517
2017-06-03 14:33:36.918895 EDT | AverageY                    0.182857
2017-06-03 14:33:36.919127 EDT | AverageAbsY                 0.182984
2017-06-03 14:33:36.919357 EDT | AverageAbsQYDiff            0.0030236
2017-06-03 14:33:36.919588 EDT | AverageAction               0.0161598
2017-06-03 14:33:36.919820 EDT | PolicyRegParamNorm         51.5473
2017-06-03 14:33:36.920050 EDT | QFunRegParamNorm           25.7402
2017-06-03 14:33:36.920280 EDT | -----------------------  --------------
2017-06-03 14:33:36.920652 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #226 | Training started
2017-06-03 14:33:55.350467 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #226 | Training finished
2017-06-03 14:33:55.351417 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #226 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 14:33:55.351949 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #226 | Collecting samples for evaluation
2017-06-03 14:34:05.151157 EDT | -----------------------  --------------
2017-06-03 14:34:05.152216 EDT | Epoch                     226
2017-06-03 14:34:05.152568 EDT | Iteration                 226
2017-06-03 14:34:05.152894 EDT | AverageReturn            1000
2017-06-03 14:34:05.153218 EDT | StdReturn                   0
2017-06-03 14:34:05.153541 EDT | MaxReturn                1000
2017-06-03 14:34:05.153921 EDT | MinReturn                1000
2017-06-03 14:34:05.154240 EDT | AverageEsReturn            19.1667
2017-06-03 14:34:05.154559 EDT | StdEsReturn                16.5332
2017-06-03 14:34:05.154880 EDT | MaxEsReturn                68
2017-06-03 14:34:05.155208 EDT | MinEsReturn                 3
2017-06-03 14:34:05.155520 EDT | AverageDiscountedReturn    99.9957
2017-06-03 14:34:05.155833 EDT | AverageQLoss                0.000128247
2017-06-03 14:34:05.156152 EDT | AveragePolicySurr          -0.191391
2017-06-03 14:34:05.156462 EDT | AverageQ                    0.181592
2017-06-03 14:34:05.156773 EDT | AverageAbsQ                 0.182141
2017-06-03 14:34:05.157087 EDT | AverageY                    0.181575
2017-06-03 14:34:05.157433 EDT | AverageAbsY                 0.181692
2017-06-03 14:34:05.157691 EDT | AverageAbsQYDiff            0.00257877
2017-06-03 14:34:05.157947 EDT | AverageAction               0.00707347
2017-06-03 14:34:05.158193 EDT | PolicyRegParamNorm         51.6263
2017-06-03 14:34:05.158437 EDT | QFunRegParamNorm           25.7381
2017-06-03 14:34:05.158681 EDT | -----------------------  --------------
2017-06-03 14:34:05.159135 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #227 | Training started
2017-06-03 14:34:25.248419 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #227 | Training finished
2017-06-03 14:34:25.249340 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #227 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 14:34:25.249627 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #227 | Collecting samples for evaluation
2017-06-03 14:34:35.081896 EDT | -----------------------  -------------
2017-06-03 14:34:35.082769 EDT | Epoch                     227
2017-06-03 14:34:35.083042 EDT | Iteration                 227
2017-06-03 14:34:35.083284 EDT | AverageReturn            1000
2017-06-03 14:34:35.083541 EDT | StdReturn                   0
2017-06-03 14:34:35.083819 EDT | MaxReturn                1000
2017-06-03 14:34:35.084056 EDT | MinReturn                1000
2017-06-03 14:34:35.084293 EDT | AverageEsReturn            27.5641
2017-06-03 14:34:35.084531 EDT | StdEsReturn                31.3784
2017-06-03 14:34:35.084760 EDT | MaxEsReturn               173
2017-06-03 14:34:35.085001 EDT | MinEsReturn                 3
2017-06-03 14:34:35.085241 EDT | AverageDiscountedReturn    99.9957
2017-06-03 14:34:35.085478 EDT | AverageQLoss                0.00013249
2017-06-03 14:34:35.085724 EDT | AveragePolicySurr          -0.190539
2017-06-03 14:34:35.085962 EDT | AverageQ                    0.180574
2017-06-03 14:34:35.086194 EDT | AverageAbsQ                 0.181147
2017-06-03 14:34:35.086426 EDT | AverageY                    0.180565
2017-06-03 14:34:35.086658 EDT | AverageAbsY                 0.180675
2017-06-03 14:34:35.086888 EDT | AverageAbsQYDiff            0.00262965
2017-06-03 14:34:35.087115 EDT | AverageAction               0.00589324
2017-06-03 14:34:35.087347 EDT | PolicyRegParamNorm         51.6695
2017-06-03 14:34:35.087577 EDT | QFunRegParamNorm           25.737
2017-06-03 14:34:35.087808 EDT | -----------------------  -------------
2017-06-03 14:34:35.088186 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #228 | Training started
2017-06-03 14:34:54.198174 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #228 | Training finished
2017-06-03 14:34:54.199026 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #228 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 14:34:54.199304 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #228 | Collecting samples for evaluation
2017-06-03 14:35:03.446208 EDT | -----------------------  --------------
2017-06-03 14:35:03.447021 EDT | Epoch                     228
2017-06-03 14:35:03.447277 EDT | Iteration                 228
2017-06-03 14:35:03.447513 EDT | AverageReturn            1000
2017-06-03 14:35:03.447745 EDT | StdReturn                   0
2017-06-03 14:35:03.447975 EDT | MaxReturn                1000
2017-06-03 14:35:03.448202 EDT | MinReturn                1000
2017-06-03 14:35:03.448429 EDT | AverageEsReturn            22.6977
2017-06-03 14:35:03.448665 EDT | StdEsReturn                21.7315
2017-06-03 14:35:03.448917 EDT | MaxEsReturn               102
2017-06-03 14:35:03.449145 EDT | MinEsReturn                 3
2017-06-03 14:35:03.449372 EDT | AverageDiscountedReturn    99.9957
2017-06-03 14:35:03.449599 EDT | AverageQLoss                0.000131575
2017-06-03 14:35:03.449841 EDT | AveragePolicySurr          -0.189515
2017-06-03 14:35:03.450081 EDT | AverageQ                    0.179904
2017-06-03 14:35:03.450307 EDT | AverageAbsQ                 0.180588
2017-06-03 14:35:03.450532 EDT | AverageY                    0.179905
2017-06-03 14:35:03.450758 EDT | AverageAbsY                 0.179987
2017-06-03 14:35:03.450991 EDT | AverageAbsQYDiff            0.00290133
2017-06-03 14:35:03.451218 EDT | AverageAction               0.0225559
2017-06-03 14:35:03.451443 EDT | PolicyRegParamNorm         51.6706
2017-06-03 14:35:03.451669 EDT | QFunRegParamNorm           25.7418
2017-06-03 14:35:03.451894 EDT | -----------------------  --------------
2017-06-03 14:35:03.452231 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #229 | Training started
2017-06-03 14:35:21.906660 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #229 | Training finished
2017-06-03 14:35:21.909473 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #229 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 14:35:21.909891 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #229 | Collecting samples for evaluation
2017-06-03 14:35:32.891767 EDT | -----------------------  --------------
2017-06-03 14:35:32.892791 EDT | Epoch                     229
2017-06-03 14:35:32.893164 EDT | Iteration                 229
2017-06-03 14:35:32.893481 EDT | AverageReturn            1000
2017-06-03 14:35:32.893789 EDT | StdReturn                   0
2017-06-03 14:35:32.894086 EDT | MaxReturn                1000
2017-06-03 14:35:32.894383 EDT | MinReturn                1000
2017-06-03 14:35:32.894681 EDT | AverageEsReturn            20.8571
2017-06-03 14:35:32.894988 EDT | StdEsReturn                18.8203
2017-06-03 14:35:32.895356 EDT | MaxEsReturn               115
2017-06-03 14:35:32.895652 EDT | MinEsReturn                 3
2017-06-03 14:35:32.895945 EDT | AverageDiscountedReturn    99.9957
2017-06-03 14:35:32.896238 EDT | AverageQLoss                0.000131539
2017-06-03 14:35:32.896535 EDT | AveragePolicySurr          -0.188352
2017-06-03 14:35:32.896828 EDT | AverageQ                    0.178725
2017-06-03 14:35:32.897119 EDT | AverageAbsQ                 0.179359
2017-06-03 14:35:32.897406 EDT | AverageY                    0.178738
2017-06-03 14:35:32.897726 EDT | AverageAbsY                 0.178801
2017-06-03 14:35:32.898070 EDT | AverageAbsQYDiff            0.00274856
2017-06-03 14:35:32.898375 EDT | AverageAction               0.00473778
2017-06-03 14:35:32.898675 EDT | PolicyRegParamNorm         51.7375
2017-06-03 14:35:32.898975 EDT | QFunRegParamNorm           25.7596
2017-06-03 14:35:32.899282 EDT | -----------------------  --------------
2017-06-03 14:35:32.899739 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #230 | Training started
2017-06-03 14:35:51.096083 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #230 | Training finished
2017-06-03 14:35:51.097080 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #230 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 14:35:51.097432 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #230 | Collecting samples for evaluation
2017-06-03 14:36:00.837685 EDT | -----------------------  --------------
2017-06-03 14:36:00.838105 EDT | Epoch                     230
2017-06-03 14:36:00.838366 EDT | Iteration                 230
2017-06-03 14:36:00.838619 EDT | AverageReturn            1000
2017-06-03 14:36:00.839036 EDT | StdReturn                   0
2017-06-03 14:36:00.839394 EDT | MaxReturn                1000
2017-06-03 14:36:00.839814 EDT | MinReturn                1000
2017-06-03 14:36:00.840207 EDT | AverageEsReturn            20.4167
2017-06-03 14:36:00.840566 EDT | StdEsReturn                15.8046
2017-06-03 14:36:00.840906 EDT | MaxEsReturn                64
2017-06-03 14:36:00.841253 EDT | MinEsReturn                 3
2017-06-03 14:36:00.841675 EDT | AverageDiscountedReturn    99.9957
2017-06-03 14:36:00.842029 EDT | AverageQLoss                0.000133299
2017-06-03 14:36:00.842401 EDT | AveragePolicySurr          -0.186986
2017-06-03 14:36:00.842872 EDT | AverageQ                    0.177281
2017-06-03 14:36:00.843406 EDT | AverageAbsQ                 0.177918
2017-06-03 14:36:00.843868 EDT | AverageY                    0.177266
2017-06-03 14:36:00.844405 EDT | AverageAbsY                 0.177307
2017-06-03 14:36:00.844908 EDT | AverageAbsQYDiff            0.00289082
2017-06-03 14:36:00.845392 EDT | AverageAction               0.00388873
2017-06-03 14:36:00.845904 EDT | PolicyRegParamNorm         51.7711
2017-06-03 14:36:00.846264 EDT | QFunRegParamNorm           25.7718
2017-06-03 14:36:00.846593 EDT | -----------------------  --------------
2017-06-03 14:36:00.847044 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #231 | Training started
2017-06-03 14:36:20.704893 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #231 | Training finished
2017-06-03 14:36:20.705803 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #231 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 14:36:20.706094 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #231 | Collecting samples for evaluation
2017-06-03 14:36:30.431165 EDT | -----------------------  --------------
2017-06-03 14:36:30.432042 EDT | Epoch                     231
2017-06-03 14:36:30.432353 EDT | Iteration                 231
2017-06-03 14:36:30.432603 EDT | AverageReturn            1000
2017-06-03 14:36:30.432842 EDT | StdReturn                   0
2017-06-03 14:36:30.433079 EDT | MaxReturn                1000
2017-06-03 14:36:30.433313 EDT | MinReturn                1000
2017-06-03 14:36:30.433557 EDT | AverageEsReturn            21.1042
2017-06-03 14:36:30.433821 EDT | StdEsReturn                20.9297
2017-06-03 14:36:30.434070 EDT | MaxEsReturn               110
2017-06-03 14:36:30.434315 EDT | MinEsReturn                 3
2017-06-03 14:36:30.434569 EDT | AverageDiscountedReturn    99.9957
2017-06-03 14:36:30.434822 EDT | AverageQLoss                0.000137384
2017-06-03 14:36:30.435064 EDT | AveragePolicySurr          -0.185864
2017-06-03 14:36:30.435315 EDT | AverageQ                    0.176442
2017-06-03 14:36:30.435592 EDT | AverageAbsQ                 0.177065
2017-06-03 14:36:30.435849 EDT | AverageY                    0.176442
2017-06-03 14:36:30.436121 EDT | AverageAbsY                 0.176492
2017-06-03 14:36:30.436370 EDT | AverageAbsQYDiff            0.00283355
2017-06-03 14:36:30.436640 EDT | AverageAction               0.00295805
2017-06-03 14:36:30.436918 EDT | PolicyRegParamNorm         51.8487
2017-06-03 14:36:30.437191 EDT | QFunRegParamNorm           25.7739
2017-06-03 14:36:30.437435 EDT | -----------------------  --------------
2017-06-03 14:36:30.437864 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #232 | Training started
2017-06-03 14:36:49.068449 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #232 | Training finished
2017-06-03 14:36:49.069317 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #232 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 14:36:49.069588 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #232 | Collecting samples for evaluation
2017-06-03 14:36:58.263738 EDT | -----------------------  --------------
2017-06-03 14:36:58.264639 EDT | Epoch                     232
2017-06-03 14:36:58.264923 EDT | Iteration                 232
2017-06-03 14:36:58.265181 EDT | AverageReturn            1000
2017-06-03 14:36:58.265445 EDT | StdReturn                   0
2017-06-03 14:36:58.265691 EDT | MaxReturn                1000
2017-06-03 14:36:58.265949 EDT | MinReturn                1000
2017-06-03 14:36:58.266218 EDT | AverageEsReturn            20.0816
2017-06-03 14:36:58.266472 EDT | StdEsReturn                17.5043
2017-06-03 14:36:58.266719 EDT | MaxEsReturn                93
2017-06-03 14:36:58.266961 EDT | MinEsReturn                 3
2017-06-03 14:36:58.267213 EDT | AverageDiscountedReturn    99.9957
2017-06-03 14:36:58.267456 EDT | AverageQLoss                0.000126963
2017-06-03 14:36:58.267700 EDT | AveragePolicySurr          -0.185046
2017-06-03 14:36:58.267945 EDT | AverageQ                    0.175211
2017-06-03 14:36:58.268185 EDT | AverageAbsQ                 0.175847
2017-06-03 14:36:58.268452 EDT | AverageY                    0.175196
2017-06-03 14:36:58.268693 EDT | AverageAbsY                 0.175292
2017-06-03 14:36:58.268942 EDT | AverageAbsQYDiff            0.00276938
2017-06-03 14:36:58.269184 EDT | AverageAction               0.00597771
2017-06-03 14:36:58.269525 EDT | PolicyRegParamNorm         51.8297
2017-06-03 14:36:58.269860 EDT | QFunRegParamNorm           25.7906
2017-06-03 14:36:58.270185 EDT | -----------------------  --------------
2017-06-03 14:36:58.270630 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #233 | Training started
2017-06-03 14:37:16.015730 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #233 | Training finished
2017-06-03 14:37:16.016661 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #233 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 14:37:16.016937 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #233 | Collecting samples for evaluation
2017-06-03 14:37:25.955785 EDT | -----------------------  --------------
2017-06-03 14:37:25.956687 EDT | Epoch                     233
2017-06-03 14:37:25.957021 EDT | Iteration                 233
2017-06-03 14:37:25.957373 EDT | AverageReturn            1000
2017-06-03 14:37:25.957638 EDT | StdReturn                   0
2017-06-03 14:37:25.957949 EDT | MaxReturn                1000
2017-06-03 14:37:25.958254 EDT | MinReturn                1000
2017-06-03 14:37:25.958572 EDT | AverageEsReturn            26.359
2017-06-03 14:37:25.958901 EDT | StdEsReturn                22.7511
2017-06-03 14:37:25.959168 EDT | MaxEsReturn               116
2017-06-03 14:37:25.959448 EDT | MinEsReturn                 3
2017-06-03 14:37:25.959781 EDT | AverageDiscountedReturn    99.9957
2017-06-03 14:37:25.960065 EDT | AverageQLoss                0.000127769
2017-06-03 14:37:25.960319 EDT | AveragePolicySurr          -0.183874
2017-06-03 14:37:25.960575 EDT | AverageQ                    0.174596
2017-06-03 14:37:25.960820 EDT | AverageAbsQ                 0.175301
2017-06-03 14:37:25.961066 EDT | AverageY                    0.174591
2017-06-03 14:37:25.961310 EDT | AverageAbsY                 0.174704
2017-06-03 14:37:25.961552 EDT | AverageAbsQYDiff            0.00284699
2017-06-03 14:37:25.961820 EDT | AverageAction               0.0449863
2017-06-03 14:37:25.962079 EDT | PolicyRegParamNorm         51.9123
2017-06-03 14:37:25.962321 EDT | QFunRegParamNorm           25.8014
2017-06-03 14:37:25.962609 EDT | -----------------------  --------------
2017-06-03 14:37:25.963112 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #234 | Training started
2017-06-03 14:37:45.725866 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #234 | Training finished
2017-06-03 14:37:45.726785 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #234 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 14:37:45.727054 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #234 | Collecting samples for evaluation
2017-06-03 14:37:56.360557 EDT | -----------------------  -------------
2017-06-03 14:37:56.361499 EDT | Epoch                    234
2017-06-03 14:37:56.361778 EDT | Iteration                234
2017-06-03 14:37:56.362016 EDT | AverageReturn             52.0259
2017-06-03 14:37:56.362264 EDT | StdReturn                  0.722942
2017-06-03 14:37:56.362493 EDT | MaxReturn                 54
2017-06-03 14:37:56.362722 EDT | MinReturn                 50
2017-06-03 14:37:56.362948 EDT | AverageEsReturn           20.4082
2017-06-03 14:37:56.363172 EDT | StdEsReturn               16.2492
2017-06-03 14:37:56.363399 EDT | MaxEsReturn               64
2017-06-03 14:37:56.363627 EDT | MinEsReturn                3
2017-06-03 14:37:56.363854 EDT | AverageDiscountedReturn   40.7172
2017-06-03 14:37:56.364081 EDT | AverageQLoss               0.000117181
2017-06-03 14:37:56.364309 EDT | AveragePolicySurr         -0.183171
2017-06-03 14:37:56.364536 EDT | AverageQ                   0.173117
2017-06-03 14:37:56.364762 EDT | AverageAbsQ                0.173734
2017-06-03 14:37:56.364988 EDT | AverageY                   0.173127
2017-06-03 14:37:56.365213 EDT | AverageAbsY                0.173227
2017-06-03 14:37:56.365438 EDT | AverageAbsQYDiff           0.00265911
2017-06-03 14:37:56.365664 EDT | AverageAction              0.277511
2017-06-03 14:37:56.365905 EDT | PolicyRegParamNorm        51.8765
2017-06-03 14:37:56.366132 EDT | QFunRegParamNorm          25.8003
2017-06-03 14:37:56.366359 EDT | -----------------------  -------------
2017-06-03 14:37:56.366732 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #235 | Training started
2017-06-03 14:38:14.160971 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #235 | Training finished
2017-06-03 14:38:14.161883 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #235 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 14:38:14.162158 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #235 | Collecting samples for evaluation
2017-06-03 14:38:23.933258 EDT | -----------------------  --------------
2017-06-03 14:38:23.934103 EDT | Epoch                     235
2017-06-03 14:38:23.934367 EDT | Iteration                 235
2017-06-03 14:38:23.934606 EDT | AverageReturn            1000
2017-06-03 14:38:23.934838 EDT | StdReturn                   0
2017-06-03 14:38:23.935068 EDT | MaxReturn                1000
2017-06-03 14:38:23.935320 EDT | MinReturn                1000
2017-06-03 14:38:23.935550 EDT | AverageEsReturn            19.64
2017-06-03 14:38:23.935780 EDT | StdEsReturn                17.042
2017-06-03 14:38:23.936012 EDT | MaxEsReturn                77
2017-06-03 14:38:23.936243 EDT | MinEsReturn                 3
2017-06-03 14:38:23.936469 EDT | AverageDiscountedReturn    99.9957
2017-06-03 14:38:23.936706 EDT | AverageQLoss                0.000110972
2017-06-03 14:38:23.936937 EDT | AveragePolicySurr          -0.181972
2017-06-03 14:38:23.937162 EDT | AverageQ                    0.172809
2017-06-03 14:38:23.937387 EDT | AverageAbsQ                 0.173346
2017-06-03 14:38:23.937612 EDT | AverageY                    0.172829
2017-06-03 14:38:23.937877 EDT | AverageAbsY                 0.172887
2017-06-03 14:38:23.938116 EDT | AverageAbsQYDiff            0.00253641
2017-06-03 14:38:23.938359 EDT | AverageAction               0.0148663
2017-06-03 14:38:23.938600 EDT | PolicyRegParamNorm         51.8978
2017-06-03 14:38:23.938841 EDT | QFunRegParamNorm           25.788
2017-06-03 14:38:23.939083 EDT | -----------------------  --------------
2017-06-03 14:38:23.939448 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #236 | Training started
2017-06-03 14:38:41.836488 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #236 | Training finished
2017-06-03 14:38:41.837383 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #236 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 14:38:41.837664 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #236 | Collecting samples for evaluation
2017-06-03 14:38:51.846939 EDT | -----------------------  --------------
2017-06-03 14:38:51.847817 EDT | Epoch                     236
2017-06-03 14:38:51.848080 EDT | Iteration                 236
2017-06-03 14:38:51.848339 EDT | AverageReturn            1000
2017-06-03 14:38:51.848580 EDT | StdReturn                   0
2017-06-03 14:38:51.848812 EDT | MaxReturn                1000
2017-06-03 14:38:51.849044 EDT | MinReturn                1000
2017-06-03 14:38:51.849276 EDT | AverageEsReturn            19.3529
2017-06-03 14:38:51.849518 EDT | StdEsReturn                22.3289
2017-06-03 14:38:51.849765 EDT | MaxEsReturn               137
2017-06-03 14:38:51.849997 EDT | MinEsReturn                 3
2017-06-03 14:38:51.850230 EDT | AverageDiscountedReturn    99.9957
2017-06-03 14:38:51.850461 EDT | AverageQLoss                0.000132624
2017-06-03 14:38:51.850728 EDT | AveragePolicySurr          -0.181168
2017-06-03 14:38:51.850959 EDT | AverageQ                    0.171443
2017-06-03 14:38:51.851190 EDT | AverageAbsQ                 0.172148
2017-06-03 14:38:51.851420 EDT | AverageY                    0.171416
2017-06-03 14:38:51.851649 EDT | AverageAbsY                 0.17148
2017-06-03 14:38:51.851891 EDT | AverageAbsQYDiff            0.00285433
2017-06-03 14:38:51.852123 EDT | AverageAction               0.0225706
2017-06-03 14:38:51.852352 EDT | PolicyRegParamNorm         51.9725
2017-06-03 14:38:51.852582 EDT | QFunRegParamNorm           25.7852
2017-06-03 14:38:51.852811 EDT | -----------------------  --------------
2017-06-03 14:38:51.853190 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #237 | Training started
2017-06-03 14:39:09.884309 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #237 | Training finished
2017-06-03 14:39:09.885155 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #237 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 14:39:09.885426 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #237 | Collecting samples for evaluation
2017-06-03 14:39:19.797199 EDT | -----------------------  -------------
2017-06-03 14:39:19.797944 EDT | Epoch                    237
2017-06-03 14:39:19.798301 EDT | Iteration                237
2017-06-03 14:39:19.798627 EDT | AverageReturn             50.8528
2017-06-03 14:39:19.798941 EDT | StdReturn                  0.407611
2017-06-03 14:39:19.799263 EDT | MaxReturn                 52
2017-06-03 14:39:19.799573 EDT | MinReturn                 50
2017-06-03 14:39:19.799883 EDT | AverageEsReturn           17.6667
2017-06-03 14:39:19.800197 EDT | StdEsReturn               16.0091
2017-06-03 14:39:19.800504 EDT | MaxEsReturn               80
2017-06-03 14:39:19.800809 EDT | MinEsReturn                3
2017-06-03 14:39:19.801114 EDT | AverageDiscountedReturn   40.0152
2017-06-03 14:39:19.801419 EDT | AverageQLoss               0.000118605
2017-06-03 14:39:19.801732 EDT | AveragePolicySurr         -0.179715
2017-06-03 14:39:19.802039 EDT | AverageQ                   0.170255
2017-06-03 14:39:19.802344 EDT | AverageAbsQ                0.170753
2017-06-03 14:39:19.802647 EDT | AverageY                   0.170263
2017-06-03 14:39:19.802950 EDT | AverageAbsY                0.170353
2017-06-03 14:39:19.803252 EDT | AverageAbsQYDiff           0.00254829
2017-06-03 14:39:19.803553 EDT | AverageAction              0.221113
2017-06-03 14:39:19.803853 EDT | PolicyRegParamNorm        52.0432
2017-06-03 14:39:19.804152 EDT | QFunRegParamNorm          25.7906
2017-06-03 14:39:19.804453 EDT | -----------------------  -------------
2017-06-03 14:39:19.804869 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #238 | Training started
2017-06-03 14:39:38.069867 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #238 | Training finished
2017-06-03 14:39:38.070904 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #238 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 14:39:38.071168 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #238 | Collecting samples for evaluation
2017-06-03 14:39:47.719922 EDT | -----------------------  -------------
2017-06-03 14:39:47.720773 EDT | Epoch                    238
2017-06-03 14:39:47.721047 EDT | Iteration                238
2017-06-03 14:39:47.721287 EDT | AverageReturn             57.815
2017-06-03 14:39:47.721537 EDT | StdReturn                  0.768156
2017-06-03 14:39:47.721811 EDT | MaxReturn                 60
2017-06-03 14:39:47.722046 EDT | MinReturn                 57
2017-06-03 14:39:47.722280 EDT | AverageEsReturn           20.8958
2017-06-03 14:39:47.722512 EDT | StdEsReturn               15.7351
2017-06-03 14:39:47.722742 EDT | MaxEsReturn               68
2017-06-03 14:39:47.722982 EDT | MinEsReturn                3
2017-06-03 14:39:47.723212 EDT | AverageDiscountedReturn   44.0678
2017-06-03 14:39:47.723442 EDT | AverageQLoss               0.000131119
2017-06-03 14:39:47.723671 EDT | AveragePolicySurr         -0.178476
2017-06-03 14:39:47.723902 EDT | AverageQ                   0.169413
2017-06-03 14:39:47.724131 EDT | AverageAbsQ                0.170094
2017-06-03 14:39:47.724361 EDT | AverageY                   0.169394
2017-06-03 14:39:47.724591 EDT | AverageAbsY                0.169482
2017-06-03 14:39:47.724819 EDT | AverageAbsQYDiff           0.00280753
2017-06-03 14:39:47.725047 EDT | AverageAction              0.316369
2017-06-03 14:39:47.725275 EDT | PolicyRegParamNorm        52.0581
2017-06-03 14:39:47.725504 EDT | QFunRegParamNorm          25.8048
2017-06-03 14:39:47.725745 EDT | -----------------------  -------------
2017-06-03 14:39:47.726092 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #239 | Training started
2017-06-03 14:40:06.133430 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #239 | Training finished
2017-06-03 14:40:06.133886 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #239 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 14:40:06.134229 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #239 | Collecting samples for evaluation
2017-06-03 14:40:16.390249 EDT | -----------------------  ------------
2017-06-03 14:40:16.391131 EDT | Epoch                    239
2017-06-03 14:40:16.391417 EDT | Iteration                239
2017-06-03 14:40:16.391673 EDT | AverageReturn             50.195
2017-06-03 14:40:16.391923 EDT | StdReturn                  0.544954
2017-06-03 14:40:16.392184 EDT | MaxReturn                 51
2017-06-03 14:40:16.392437 EDT | MinReturn                 49
2017-06-03 14:40:16.392680 EDT | AverageEsReturn           26.2895
2017-06-03 14:40:16.392923 EDT | StdEsReturn               18.8092
2017-06-03 14:40:16.393165 EDT | MaxEsReturn               77
2017-06-03 14:40:16.393407 EDT | MinEsReturn                3
2017-06-03 14:40:16.393650 EDT | AverageDiscountedReturn   39.6169
2017-06-03 14:40:16.393906 EDT | AverageQLoss               0.0001066
2017-06-03 14:40:16.394148 EDT | AveragePolicySurr         -0.177502
2017-06-03 14:40:16.394442 EDT | AverageQ                   0.168236
2017-06-03 14:40:16.394684 EDT | AverageAbsQ                0.168839
2017-06-03 14:40:16.394913 EDT | AverageY                   0.168237
2017-06-03 14:40:16.395139 EDT | AverageAbsY                0.168295
2017-06-03 14:40:16.395365 EDT | AverageAbsQYDiff           0.00256991
2017-06-03 14:40:16.395589 EDT | AverageAction              0.304139
2017-06-03 14:40:16.395820 EDT | PolicyRegParamNorm        52.0864
2017-06-03 14:40:16.396045 EDT | QFunRegParamNorm          25.8149
2017-06-03 14:40:16.396274 EDT | -----------------------  ------------
2017-06-03 14:40:16.396640 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #240 | Training started
2017-06-03 14:40:35.313071 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #240 | Training finished
2017-06-03 14:40:35.313950 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #240 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 14:40:35.314240 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #240 | Collecting samples for evaluation
2017-06-03 14:40:44.703972 EDT | -----------------------  -------------
2017-06-03 14:40:44.704857 EDT | Epoch                     240
2017-06-03 14:40:44.705120 EDT | Iteration                 240
2017-06-03 14:40:44.705341 EDT | AverageReturn            1000
2017-06-03 14:40:44.705559 EDT | StdReturn                   0
2017-06-03 14:40:44.705798 EDT | MaxReturn                1000
2017-06-03 14:40:44.706039 EDT | MinReturn                1000
2017-06-03 14:40:44.706264 EDT | AverageEsReturn            28.2
2017-06-03 14:40:44.706477 EDT | StdEsReturn                26.413
2017-06-03 14:40:44.706725 EDT | MaxEsReturn               123
2017-06-03 14:40:44.706981 EDT | MinEsReturn                 3
2017-06-03 14:40:44.707219 EDT | AverageDiscountedReturn    99.9957
2017-06-03 14:40:44.707443 EDT | AverageQLoss                0.0001102
2017-06-03 14:40:44.707701 EDT | AveragePolicySurr          -0.176667
2017-06-03 14:40:44.707930 EDT | AverageQ                    0.167393
2017-06-03 14:40:44.708196 EDT | AverageAbsQ                 0.167946
2017-06-03 14:40:44.708450 EDT | AverageY                    0.167396
2017-06-03 14:40:44.708665 EDT | AverageAbsY                 0.167446
2017-06-03 14:40:44.708879 EDT | AverageAbsQYDiff            0.00255055
2017-06-03 14:40:44.709098 EDT | AverageAction               0.0769245
2017-06-03 14:40:44.709313 EDT | PolicyRegParamNorm         52.121
2017-06-03 14:40:44.709532 EDT | QFunRegParamNorm           25.8296
2017-06-03 14:40:44.709788 EDT | -----------------------  -------------
2017-06-03 14:40:44.710140 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #241 | Training started
2017-06-03 14:41:03.535115 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #241 | Training finished
2017-06-03 14:41:03.535962 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #241 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 14:41:03.536230 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #241 | Collecting samples for evaluation
2017-06-03 14:41:12.668609 EDT | -----------------------  --------------
2017-06-03 14:41:12.669634 EDT | Epoch                     241
2017-06-03 14:41:12.669990 EDT | Iteration                 241
2017-06-03 14:41:12.670319 EDT | AverageReturn            1000
2017-06-03 14:41:12.670635 EDT | StdReturn                   0
2017-06-03 14:41:12.670951 EDT | MaxReturn                1000
2017-06-03 14:41:12.671275 EDT | MinReturn                1000
2017-06-03 14:41:12.671585 EDT | AverageEsReturn            33.5667
2017-06-03 14:41:12.671894 EDT | StdEsReturn                23.7679
2017-06-03 14:41:12.672202 EDT | MaxEsReturn               125
2017-06-03 14:41:12.672509 EDT | MinEsReturn                 5
2017-06-03 14:41:12.672815 EDT | AverageDiscountedReturn    99.9957
2017-06-03 14:41:12.673120 EDT | AverageQLoss                0.000138229
2017-06-03 14:41:12.673426 EDT | AveragePolicySurr          -0.175478
2017-06-03 14:41:12.673741 EDT | AverageQ                    0.166376
2017-06-03 14:41:12.674049 EDT | AverageAbsQ                 0.166973
2017-06-03 14:41:12.674359 EDT | AverageY                    0.16637
2017-06-03 14:41:12.674664 EDT | AverageAbsY                 0.166427
2017-06-03 14:41:12.674968 EDT | AverageAbsQYDiff            0.00294376
2017-06-03 14:41:12.675400 EDT | AverageAction               0.0332437
2017-06-03 14:41:12.675913 EDT | PolicyRegParamNorm         52.1761
2017-06-03 14:41:12.676435 EDT | QFunRegParamNorm           25.8663
2017-06-03 14:41:12.676936 EDT | -----------------------  --------------
2017-06-03 14:41:12.677604 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #242 | Training started
2017-06-03 14:41:31.180409 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #242 | Training finished
2017-06-03 14:41:31.181425 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #242 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 14:41:31.181706 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #242 | Collecting samples for evaluation
2017-06-03 14:41:41.512154 EDT | -----------------------  --------------
2017-06-03 14:41:41.513227 EDT | Epoch                     242
2017-06-03 14:41:41.513502 EDT | Iteration                 242
2017-06-03 14:41:41.513758 EDT | AverageReturn            1000
2017-06-03 14:41:41.514024 EDT | StdReturn                   0
2017-06-03 14:41:41.514262 EDT | MaxReturn                1000
2017-06-03 14:41:41.514497 EDT | MinReturn                1000
2017-06-03 14:41:41.514730 EDT | AverageEsReturn            27.6757
2017-06-03 14:41:41.514963 EDT | StdEsReturn                25.5576
2017-06-03 14:41:41.515205 EDT | MaxEsReturn               111
2017-06-03 14:41:41.515437 EDT | MinEsReturn                 3
2017-06-03 14:41:41.515678 EDT | AverageDiscountedReturn    99.9957
2017-06-03 14:41:41.515942 EDT | AverageQLoss                0.000119842
2017-06-03 14:41:41.516176 EDT | AveragePolicySurr          -0.174535
2017-06-03 14:41:41.516405 EDT | AverageQ                    0.165514
2017-06-03 14:41:41.516634 EDT | AverageAbsQ                 0.166241
2017-06-03 14:41:41.516863 EDT | AverageY                    0.165517
2017-06-03 14:41:41.517100 EDT | AverageAbsY                 0.165593
2017-06-03 14:41:41.517328 EDT | AverageAbsQYDiff            0.00273214
2017-06-03 14:41:41.517592 EDT | AverageAction               0.128557
2017-06-03 14:41:41.518491 EDT | PolicyRegParamNorm         52.1782
2017-06-03 14:41:41.518842 EDT | QFunRegParamNorm           25.8461
2017-06-03 14:41:41.519158 EDT | -----------------------  --------------
2017-06-03 14:41:41.519597 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #243 | Training started
2017-06-03 14:42:00.655188 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #243 | Training finished
2017-06-03 14:42:00.656049 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #243 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 14:42:00.656324 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #243 | Collecting samples for evaluation
2017-06-03 14:42:10.230959 EDT | -----------------------  --------------
2017-06-03 14:42:10.235455 EDT | Epoch                     243
2017-06-03 14:42:10.235811 EDT | Iteration                 243
2017-06-03 14:42:10.236063 EDT | AverageReturn            1000
2017-06-03 14:42:10.236307 EDT | StdReturn                   0
2017-06-03 14:42:10.236546 EDT | MaxReturn                1000
2017-06-03 14:42:10.236785 EDT | MinReturn                1000
2017-06-03 14:42:10.237028 EDT | AverageEsReturn            25.1538
2017-06-03 14:42:10.237302 EDT | StdEsReturn                15.6361
2017-06-03 14:42:10.237537 EDT | MaxEsReturn                54
2017-06-03 14:42:10.237792 EDT | MinEsReturn                 3
2017-06-03 14:42:10.238028 EDT | AverageDiscountedReturn    99.9957
2017-06-03 14:42:10.238270 EDT | AverageQLoss                0.000106596
2017-06-03 14:42:10.238505 EDT | AveragePolicySurr          -0.173523
2017-06-03 14:42:10.238746 EDT | AverageQ                    0.164642
2017-06-03 14:42:10.239004 EDT | AverageAbsQ                 0.165268
2017-06-03 14:42:10.239242 EDT | AverageY                    0.164647
2017-06-03 14:42:10.239487 EDT | AverageAbsY                 0.164737
2017-06-03 14:42:10.239720 EDT | AverageAbsQYDiff            0.00256936
2017-06-03 14:42:10.239952 EDT | AverageAction               0.0905071
2017-06-03 14:42:10.240184 EDT | PolicyRegParamNorm         52.1928
2017-06-03 14:42:10.240416 EDT | QFunRegParamNorm           25.8544
2017-06-03 14:42:10.240659 EDT | -----------------------  --------------
2017-06-03 14:42:10.241043 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #244 | Training started
2017-06-03 14:42:29.661078 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #244 | Training finished
2017-06-03 14:42:29.661948 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #244 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 14:42:29.662219 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #244 | Collecting samples for evaluation
2017-06-03 14:42:40.057682 EDT | -----------------------  --------------
2017-06-03 14:42:40.058545 EDT | Epoch                     244
2017-06-03 14:42:40.058810 EDT | Iteration                 244
2017-06-03 14:42:40.059057 EDT | AverageReturn            1000
2017-06-03 14:42:40.059302 EDT | StdReturn                   0
2017-06-03 14:42:40.059553 EDT | MaxReturn                1000
2017-06-03 14:42:40.059797 EDT | MinReturn                1000
2017-06-03 14:42:40.060041 EDT | AverageEsReturn            26.8421
2017-06-03 14:42:40.060285 EDT | StdEsReturn                19.2128
2017-06-03 14:42:40.060525 EDT | MaxEsReturn                68
2017-06-03 14:42:40.060764 EDT | MinEsReturn                 3
2017-06-03 14:42:40.061001 EDT | AverageDiscountedReturn    99.9957
2017-06-03 14:42:40.061239 EDT | AverageQLoss                0.000118628
2017-06-03 14:42:40.061476 EDT | AveragePolicySurr          -0.172384
2017-06-03 14:42:40.061721 EDT | AverageQ                    0.163493
2017-06-03 14:42:40.061961 EDT | AverageAbsQ                 0.164154
2017-06-03 14:42:40.062199 EDT | AverageY                    0.163476
2017-06-03 14:42:40.062435 EDT | AverageAbsY                 0.163593
2017-06-03 14:42:40.062671 EDT | AverageAbsQYDiff            0.00270494
2017-06-03 14:42:40.062906 EDT | AverageAction               0.108657
2017-06-03 14:42:40.063142 EDT | PolicyRegParamNorm         52.2824
2017-06-03 14:42:40.063378 EDT | QFunRegParamNorm           25.856
2017-06-03 14:42:40.063614 EDT | -----------------------  --------------
2017-06-03 14:42:40.063966 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #245 | Training started
2017-06-03 14:42:59.240041 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #245 | Training finished
2017-06-03 14:42:59.240949 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #245 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 14:42:59.241216 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #245 | Collecting samples for evaluation
2017-06-03 14:43:08.475516 EDT | -----------------------  --------------
2017-06-03 14:43:08.475913 EDT | Epoch                     245
2017-06-03 14:43:08.476178 EDT | Iteration                 245
2017-06-03 14:43:08.476427 EDT | AverageReturn            1000
2017-06-03 14:43:08.476677 EDT | StdReturn                   0
2017-06-03 14:43:08.476931 EDT | MaxReturn                1000
2017-06-03 14:43:08.477174 EDT | MinReturn                1000
2017-06-03 14:43:08.477420 EDT | AverageEsReturn            24.375
2017-06-03 14:43:08.477663 EDT | StdEsReturn                16.0619
2017-06-03 14:43:08.477922 EDT | MaxEsReturn                64
2017-06-03 14:43:08.478165 EDT | MinEsReturn                 3
2017-06-03 14:43:08.478407 EDT | AverageDiscountedReturn    99.9957
2017-06-03 14:43:08.478647 EDT | AverageQLoss                0.000118814
2017-06-03 14:43:08.478888 EDT | AveragePolicySurr          -0.171828
2017-06-03 14:43:08.479133 EDT | AverageQ                    0.162579
2017-06-03 14:43:08.479376 EDT | AverageAbsQ                 0.163217
2017-06-03 14:43:08.479818 EDT | AverageY                    0.162578
2017-06-03 14:43:08.480274 EDT | AverageAbsY                 0.162687
2017-06-03 14:43:08.480727 EDT | AverageAbsQYDiff            0.00268777
2017-06-03 14:43:08.481212 EDT | AverageAction               0.0785661
2017-06-03 14:43:08.481706 EDT | PolicyRegParamNorm         52.2334
2017-06-03 14:43:08.482167 EDT | QFunRegParamNorm           25.8626
2017-06-03 14:43:08.482621 EDT | -----------------------  --------------
2017-06-03 14:43:08.483261 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #246 | Training started
2017-06-03 14:43:25.794207 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #246 | Training finished
2017-06-03 14:43:25.795087 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #246 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 14:43:25.795350 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #246 | Collecting samples for evaluation
2017-06-03 14:43:34.580987 EDT | -----------------------  --------------
2017-06-03 14:43:34.581852 EDT | Epoch                     246
2017-06-03 14:43:34.582119 EDT | Iteration                 246
2017-06-03 14:43:34.582358 EDT | AverageReturn            1000
2017-06-03 14:43:34.582593 EDT | StdReturn                   0
2017-06-03 14:43:34.582836 EDT | MaxReturn                1000
2017-06-03 14:43:34.583102 EDT | MinReturn                1000
2017-06-03 14:43:34.583364 EDT | AverageEsReturn            23.3182
2017-06-03 14:43:34.583601 EDT | StdEsReturn                20.34
2017-06-03 14:43:34.583833 EDT | MaxEsReturn               119
2017-06-03 14:43:34.584063 EDT | MinEsReturn                 3
2017-06-03 14:43:34.584369 EDT | AverageDiscountedReturn    99.9957
2017-06-03 14:43:34.584614 EDT | AverageQLoss                0.000114418
2017-06-03 14:43:34.584857 EDT | AveragePolicySurr          -0.17043
2017-06-03 14:43:34.585118 EDT | AverageQ                    0.161565
2017-06-03 14:43:34.585386 EDT | AverageAbsQ                 0.162275
2017-06-03 14:43:34.585633 EDT | AverageY                    0.16158
2017-06-03 14:43:34.586204 EDT | AverageAbsY                 0.161699
2017-06-03 14:43:34.586453 EDT | AverageAbsQYDiff            0.00275754
2017-06-03 14:43:34.586697 EDT | AverageAction               0.102924
2017-06-03 14:43:34.586940 EDT | PolicyRegParamNorm         52.2775
2017-06-03 14:43:34.587192 EDT | QFunRegParamNorm           25.8789
2017-06-03 14:43:34.587434 EDT | -----------------------  --------------
2017-06-03 14:43:34.587820 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #247 | Training started
2017-06-03 14:43:54.308111 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #247 | Training finished
2017-06-03 14:43:54.309124 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #247 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 14:43:54.309536 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #247 | Collecting samples for evaluation
2017-06-03 14:44:01.820223 EDT | -----------------------  --------------
2017-06-03 14:44:01.821044 EDT | Epoch                     247
2017-06-03 14:44:01.821311 EDT | Iteration                 247
2017-06-03 14:44:01.821643 EDT | AverageReturn            1000
2017-06-03 14:44:01.821985 EDT | StdReturn                   0
2017-06-03 14:44:01.822301 EDT | MaxReturn                1000
2017-06-03 14:44:01.822619 EDT | MinReturn                1000
2017-06-03 14:44:01.822927 EDT | AverageEsReturn            25.0513
2017-06-03 14:44:01.823235 EDT | StdEsReturn                20.6173
2017-06-03 14:44:01.823545 EDT | MaxEsReturn                84
2017-06-03 14:44:01.823852 EDT | MinEsReturn                 3
2017-06-03 14:44:01.824157 EDT | AverageDiscountedReturn    99.9957
2017-06-03 14:44:01.824461 EDT | AverageQLoss                9.31615e-05
2017-06-03 14:44:01.824768 EDT | AveragePolicySurr          -0.17005
2017-06-03 14:44:01.825073 EDT | AverageQ                    0.161528
2017-06-03 14:44:01.825376 EDT | AverageAbsQ                 0.162115
2017-06-03 14:44:01.825680 EDT | AverageY                    0.161517
2017-06-03 14:44:01.825996 EDT | AverageAbsY                 0.161628
2017-06-03 14:44:01.826302 EDT | AverageAbsQYDiff            0.00240349
2017-06-03 14:44:01.826605 EDT | AverageAction               0.0917941
2017-06-03 14:44:01.826908 EDT | PolicyRegParamNorm         52.3527
2017-06-03 14:44:01.827209 EDT | QFunRegParamNorm           25.8751
2017-06-03 14:44:01.827509 EDT | -----------------------  --------------
2017-06-03 14:44:01.827957 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #248 | Training started
2017-06-03 14:44:21.635560 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #248 | Training finished
2017-06-03 14:44:21.636425 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #248 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 14:44:21.636692 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #248 | Collecting samples for evaluation
2017-06-03 14:44:30.465416 EDT | -----------------------  --------------
2017-06-03 14:44:30.466423 EDT | Epoch                     248
2017-06-03 14:44:30.466682 EDT | Iteration                 248
2017-06-03 14:44:30.466916 EDT | AverageReturn            1000
2017-06-03 14:44:30.467149 EDT | StdReturn                   0
2017-06-03 14:44:30.467387 EDT | MaxReturn                1000
2017-06-03 14:44:30.467633 EDT | MinReturn                1000
2017-06-03 14:44:30.467858 EDT | AverageEsReturn            37.7778
2017-06-03 14:44:30.468081 EDT | StdEsReturn                26.437
2017-06-03 14:44:30.468304 EDT | MaxEsReturn               111
2017-06-03 14:44:30.468526 EDT | MinEsReturn                 3
2017-06-03 14:44:30.468757 EDT | AverageDiscountedReturn    99.9957
2017-06-03 14:44:30.468978 EDT | AverageQLoss                9.72089e-05
2017-06-03 14:44:30.469200 EDT | AveragePolicySurr          -0.168661
2017-06-03 14:44:30.469423 EDT | AverageQ                    0.160133
2017-06-03 14:44:30.469644 EDT | AverageAbsQ                 0.160803
2017-06-03 14:44:30.470363 EDT | AverageY                    0.160118
2017-06-03 14:44:30.470674 EDT | AverageAbsY                 0.160242
2017-06-03 14:44:30.470982 EDT | AverageAbsQYDiff            0.00249107
2017-06-03 14:44:30.471293 EDT | AverageAction               0.00407498
2017-06-03 14:44:30.471599 EDT | PolicyRegParamNorm         52.4439
2017-06-03 14:44:30.471902 EDT | QFunRegParamNorm           25.8784
2017-06-03 14:44:30.472204 EDT | -----------------------  --------------
2017-06-03 14:44:30.472635 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #249 | Training started
2017-06-03 14:44:49.661720 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #249 | Training finished
2017-06-03 14:44:49.662389 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #249 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 14:44:49.662663 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #249 | Collecting samples for evaluation
2017-06-03 14:44:59.146261 EDT | -----------------------  --------------
2017-06-03 14:44:59.147125 EDT | Epoch                     249
2017-06-03 14:44:59.147389 EDT | Iteration                 249
2017-06-03 14:44:59.147631 EDT | AverageReturn            1000
2017-06-03 14:44:59.147898 EDT | StdReturn                   0
2017-06-03 14:44:59.148134 EDT | MaxReturn                1000
2017-06-03 14:44:59.148369 EDT | MinReturn                1000
2017-06-03 14:44:59.148602 EDT | AverageEsReturn            25.6923
2017-06-03 14:44:59.148842 EDT | StdEsReturn                23.545
2017-06-03 14:44:59.149085 EDT | MaxEsReturn               116
2017-06-03 14:44:59.149318 EDT | MinEsReturn                 4
2017-06-03 14:44:59.149551 EDT | AverageDiscountedReturn    99.9957
2017-06-03 14:44:59.149797 EDT | AverageQLoss                0.00010014
2017-06-03 14:44:59.150030 EDT | AveragePolicySurr          -0.167436
2017-06-03 14:44:59.150291 EDT | AverageQ                    0.15918
2017-06-03 14:44:59.150524 EDT | AverageAbsQ                 0.159777
2017-06-03 14:44:59.150753 EDT | AverageY                    0.159179
2017-06-03 14:44:59.150989 EDT | AverageAbsY                 0.159303
2017-06-03 14:44:59.151219 EDT | AverageAbsQYDiff            0.00254193
2017-06-03 14:44:59.151459 EDT | AverageAction               1.51878e-06
2017-06-03 14:44:59.151690 EDT | PolicyRegParamNorm         52.4824
2017-06-03 14:44:59.151920 EDT | QFunRegParamNorm           25.9025
2017-06-03 14:44:59.152156 EDT | -----------------------  --------------
2017-06-03 14:44:59.152511 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #250 | Training started
2017-06-03 14:45:17.758916 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #250 | Training finished
2017-06-03 14:45:17.759576 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #250 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 14:45:17.759838 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #250 | Collecting samples for evaluation
2017-06-03 14:45:27.515648 EDT | -----------------------  --------------
2017-06-03 14:45:27.516750 EDT | Epoch                     250
2017-06-03 14:45:27.517019 EDT | Iteration                 250
2017-06-03 14:45:27.517293 EDT | AverageReturn            1000
2017-06-03 14:45:27.517528 EDT | StdReturn                   0
2017-06-03 14:45:27.517818 EDT | MaxReturn                1000
2017-06-03 14:45:27.518064 EDT | MinReturn                1000
2017-06-03 14:45:27.518297 EDT | AverageEsReturn            28.5143
2017-06-03 14:45:27.518564 EDT | StdEsReturn                17.1387
2017-06-03 14:45:27.518797 EDT | MaxEsReturn                62
2017-06-03 14:45:27.519065 EDT | MinEsReturn                 3
2017-06-03 14:45:27.519296 EDT | AverageDiscountedReturn    99.9957
2017-06-03 14:45:27.519524 EDT | AverageQLoss                9.88018e-05
2017-06-03 14:45:27.519757 EDT | AveragePolicySurr          -0.167121
2017-06-03 14:45:27.519984 EDT | AverageQ                    0.158768
2017-06-03 14:45:27.520222 EDT | AverageAbsQ                 0.159435
2017-06-03 14:45:27.520495 EDT | AverageY                    0.158772
2017-06-03 14:45:27.520764 EDT | AverageAbsY                 0.158898
2017-06-03 14:45:27.520995 EDT | AverageAbsQYDiff            0.0025232
2017-06-03 14:45:27.521228 EDT | AverageAction               7.86241e-06
2017-06-03 14:45:27.521459 EDT | PolicyRegParamNorm         52.5566
2017-06-03 14:45:27.521684 EDT | QFunRegParamNorm           25.9206
2017-06-03 14:45:27.521979 EDT | -----------------------  --------------
2017-06-03 14:45:27.522356 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #251 | Training started
2017-06-03 14:45:46.498132 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #251 | Training finished
2017-06-03 14:45:46.499054 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #251 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 14:45:46.499376 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #251 | Collecting samples for evaluation
2017-06-03 14:45:56.202840 EDT | -----------------------  --------------
2017-06-03 14:45:56.204286 EDT | Epoch                     251
2017-06-03 14:45:56.204676 EDT | Iteration                 251
2017-06-03 14:45:56.205113 EDT | AverageReturn            1000
2017-06-03 14:45:56.205530 EDT | StdReturn                   0
2017-06-03 14:45:56.205948 EDT | MaxReturn                1000
2017-06-03 14:45:56.206340 EDT | MinReturn                1000
2017-06-03 14:45:56.206695 EDT | AverageEsReturn            29.1765
2017-06-03 14:45:56.207052 EDT | StdEsReturn                24.6618
2017-06-03 14:45:56.207455 EDT | MaxEsReturn               119
2017-06-03 14:45:56.207828 EDT | MinEsReturn                 3
2017-06-03 14:45:56.208205 EDT | AverageDiscountedReturn    99.9957
2017-06-03 14:45:56.208628 EDT | AverageQLoss                8.95991e-05
2017-06-03 14:45:56.209047 EDT | AveragePolicySurr          -0.166539
2017-06-03 14:45:56.209442 EDT | AverageQ                    0.158173
2017-06-03 14:45:56.209806 EDT | AverageAbsQ                 0.158702
2017-06-03 14:45:56.210137 EDT | AverageY                    0.158172
2017-06-03 14:45:56.210458 EDT | AverageAbsY                 0.158293
2017-06-03 14:45:56.210793 EDT | AverageAbsQYDiff            0.0023701
2017-06-03 14:45:56.211106 EDT | AverageAction               2.47112e-05
2017-06-03 14:45:56.211419 EDT | PolicyRegParamNorm         52.5956
2017-06-03 14:45:56.211730 EDT | QFunRegParamNorm           25.9355
2017-06-03 14:45:56.212038 EDT | -----------------------  --------------
2017-06-03 14:45:56.212505 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #252 | Training started
2017-06-03 14:46:14.904051 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #252 | Training finished
2017-06-03 14:46:14.904901 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #252 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 14:46:14.905163 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #252 | Collecting samples for evaluation
2017-06-03 14:46:24.958648 EDT | -----------------------  --------------
2017-06-03 14:46:24.961919 EDT | Epoch                     252
2017-06-03 14:46:24.962266 EDT | Iteration                 252
2017-06-03 14:46:24.962611 EDT | AverageReturn            1000
2017-06-03 14:46:24.962898 EDT | StdReturn                   0
2017-06-03 14:46:24.963229 EDT | MaxReturn                1000
2017-06-03 14:46:24.963521 EDT | MinReturn                1000
2017-06-03 14:46:24.963851 EDT | AverageEsReturn            26.4054
2017-06-03 14:46:24.964148 EDT | StdEsReturn                25.197
2017-06-03 14:46:24.964483 EDT | MaxEsReturn               109
2017-06-03 14:46:24.964786 EDT | MinEsReturn                 3
2017-06-03 14:46:24.965108 EDT | AverageDiscountedReturn    99.9957
2017-06-03 14:46:24.965422 EDT | AverageQLoss                0.000119988
2017-06-03 14:46:24.965778 EDT | AveragePolicySurr          -0.165858
2017-06-03 14:46:24.966113 EDT | AverageQ                    0.157488
2017-06-03 14:46:24.966457 EDT | AverageAbsQ                 0.158158
2017-06-03 14:46:24.966787 EDT | AverageY                    0.157491
2017-06-03 14:46:24.967129 EDT | AverageAbsY                 0.157568
2017-06-03 14:46:24.967483 EDT | AverageAbsQYDiff            0.00286247
2017-06-03 14:46:24.967831 EDT | AverageAction               0.000103269
2017-06-03 14:46:24.968150 EDT | PolicyRegParamNorm         52.603
2017-06-03 14:46:24.968500 EDT | QFunRegParamNorm           25.9335
2017-06-03 14:46:24.968832 EDT | -----------------------  --------------
2017-06-03 14:46:24.969317 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #253 | Training started
2017-06-03 14:46:43.806321 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #253 | Training finished
2017-06-03 14:46:43.807996 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #253 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 14:46:43.808270 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #253 | Collecting samples for evaluation
2017-06-03 14:46:52.732119 EDT | -----------------------  --------------
2017-06-03 14:46:52.732984 EDT | Epoch                     253
2017-06-03 14:46:52.733245 EDT | Iteration                 253
2017-06-03 14:46:52.733486 EDT | AverageReturn            1000
2017-06-03 14:46:52.733749 EDT | StdReturn                   0
2017-06-03 14:46:52.733986 EDT | MaxReturn                1000
2017-06-03 14:46:52.734220 EDT | MinReturn                1000
2017-06-03 14:46:52.734454 EDT | AverageEsReturn            43.1304
2017-06-03 14:46:52.734687 EDT | StdEsReturn                46.5975
2017-06-03 14:46:52.734924 EDT | MaxEsReturn               161
2017-06-03 14:46:52.735176 EDT | MinEsReturn                 4
2017-06-03 14:46:52.735409 EDT | AverageDiscountedReturn    99.9957
2017-06-03 14:46:52.735642 EDT | AverageQLoss                0.000107306
2017-06-03 14:46:52.735874 EDT | AveragePolicySurr          -0.164679
2017-06-03 14:46:52.736113 EDT | AverageQ                    0.156114
2017-06-03 14:46:52.736343 EDT | AverageAbsQ                 0.156673
2017-06-03 14:46:52.736574 EDT | AverageY                    0.156111
2017-06-03 14:46:52.736803 EDT | AverageAbsY                 0.156181
2017-06-03 14:46:52.737033 EDT | AverageAbsQYDiff            0.0025578
2017-06-03 14:46:52.737263 EDT | AverageAction               0.00442065
2017-06-03 14:46:52.737494 EDT | PolicyRegParamNorm         52.6622
2017-06-03 14:46:52.737735 EDT | QFunRegParamNorm           25.9566
2017-06-03 14:46:52.737970 EDT | -----------------------  --------------
2017-06-03 14:46:52.738349 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #254 | Training started
2017-06-03 14:47:12.379148 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #254 | Training finished
2017-06-03 14:47:12.380211 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #254 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 14:47:12.380541 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #254 | Collecting samples for evaluation
2017-06-03 14:47:22.955949 EDT | -----------------------  --------------
2017-06-03 14:47:22.956815 EDT | Epoch                     254
2017-06-03 14:47:22.957219 EDT | Iteration                 254
2017-06-03 14:47:22.957582 EDT | AverageReturn            1000
2017-06-03 14:47:22.957913 EDT | StdReturn                   0
2017-06-03 14:47:22.958232 EDT | MaxReturn                1000
2017-06-03 14:47:22.958559 EDT | MinReturn                1000
2017-06-03 14:47:22.958868 EDT | AverageEsReturn            23.3636
2017-06-03 14:47:22.959179 EDT | StdEsReturn                19.1122
2017-06-03 14:47:22.959499 EDT | MaxEsReturn                94
2017-06-03 14:47:22.959820 EDT | MinEsReturn                 4
2017-06-03 14:47:22.960125 EDT | AverageDiscountedReturn    99.9957
2017-06-03 14:47:22.960436 EDT | AverageQLoss                9.85255e-05
2017-06-03 14:47:22.960765 EDT | AveragePolicySurr          -0.164218
2017-06-03 14:47:22.961076 EDT | AverageQ                    0.156061
2017-06-03 14:47:22.961383 EDT | AverageAbsQ                 0.156591
2017-06-03 14:47:22.961687 EDT | AverageY                    0.156066
2017-06-03 14:47:22.962004 EDT | AverageAbsY                 0.156107
2017-06-03 14:47:22.962315 EDT | AverageAbsQYDiff            0.00246027
2017-06-03 14:47:22.962620 EDT | AverageAction               0.153431
2017-06-03 14:47:22.962924 EDT | PolicyRegParamNorm         52.6533
2017-06-03 14:47:22.963228 EDT | QFunRegParamNorm           25.9865
2017-06-03 14:47:22.963533 EDT | -----------------------  --------------
2017-06-03 14:47:22.963983 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #255 | Training started
2017-06-03 14:47:42.468777 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #255 | Training finished
2017-06-03 14:47:42.469664 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #255 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 14:47:42.470061 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #255 | Collecting samples for evaluation
2017-06-03 14:47:53.199752 EDT | -----------------------  --------------
2017-06-03 14:47:53.200611 EDT | Epoch                     255
2017-06-03 14:47:53.200882 EDT | Iteration                 255
2017-06-03 14:47:53.201137 EDT | AverageReturn            1000
2017-06-03 14:47:53.201400 EDT | StdReturn                   0
2017-06-03 14:47:53.201645 EDT | MaxReturn                1000
2017-06-03 14:47:53.201904 EDT | MinReturn                1000
2017-06-03 14:47:53.202149 EDT | AverageEsReturn            18.7407
2017-06-03 14:47:53.202406 EDT | StdEsReturn                16.7035
2017-06-03 14:47:53.202649 EDT | MaxEsReturn               108
2017-06-03 14:47:53.202891 EDT | MinEsReturn                 3
2017-06-03 14:47:53.203134 EDT | AverageDiscountedReturn    99.9957
2017-06-03 14:47:53.203376 EDT | AverageQLoss                9.25403e-05
2017-06-03 14:47:53.203618 EDT | AveragePolicySurr          -0.163129
2017-06-03 14:47:53.203887 EDT | AverageQ                    0.155006
2017-06-03 14:47:53.204127 EDT | AverageAbsQ                 0.155624
2017-06-03 14:47:53.204369 EDT | AverageY                    0.154998
2017-06-03 14:47:53.204614 EDT | AverageAbsY                 0.155066
2017-06-03 14:47:53.204854 EDT | AverageAbsQYDiff            0.0025251
2017-06-03 14:47:53.205103 EDT | AverageAction               0.0655305
2017-06-03 14:47:53.205343 EDT | PolicyRegParamNorm         52.7402
2017-06-03 14:47:53.205583 EDT | QFunRegParamNorm           25.988
2017-06-03 14:47:53.205840 EDT | -----------------------  --------------
2017-06-03 14:47:53.206194 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #256 | Training started
2017-06-03 14:48:10.484735 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #256 | Training finished
2017-06-03 14:48:10.485643 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #256 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 14:48:10.485934 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #256 | Collecting samples for evaluation
2017-06-03 14:48:19.321594 EDT | -----------------------  ------------
2017-06-03 14:48:19.322214 EDT | Epoch                    256
2017-06-03 14:48:19.322670 EDT | Iteration                256
2017-06-03 14:48:19.323008 EDT | AverageReturn             55.8
2017-06-03 14:48:19.323448 EDT | StdReturn                  1.7901
2017-06-03 14:48:19.323819 EDT | MaxReturn                 59
2017-06-03 14:48:19.324219 EDT | MinReturn                 53
2017-06-03 14:48:19.324626 EDT | AverageEsReturn           16.678
2017-06-03 14:48:19.324997 EDT | StdEsReturn               12.398
2017-06-03 14:48:19.325411 EDT | MaxEsReturn               57
2017-06-03 14:48:19.325762 EDT | MinEsReturn                3
2017-06-03 14:48:19.326183 EDT | AverageDiscountedReturn   42.916
2017-06-03 14:48:19.326527 EDT | AverageQLoss               9.3961e-05
2017-06-03 14:48:19.326947 EDT | AveragePolicySurr         -0.162323
2017-06-03 14:48:19.327325 EDT | AverageQ                   0.154092
2017-06-03 14:48:19.327715 EDT | AverageAbsQ                0.15456
2017-06-03 14:48:19.328116 EDT | AverageY                   0.154085
2017-06-03 14:48:19.328470 EDT | AverageAbsY                0.154173
2017-06-03 14:48:19.328898 EDT | AverageAbsQYDiff           0.00234594
2017-06-03 14:48:19.329236 EDT | AverageAction              0.351904
2017-06-03 14:48:19.329660 EDT | PolicyRegParamNorm        52.8161
2017-06-03 14:48:19.330061 EDT | QFunRegParamNorm          25.9862
2017-06-03 14:48:19.330464 EDT | -----------------------  ------------
2017-06-03 14:48:19.331023 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #257 | Training started
2017-06-03 14:48:38.516180 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #257 | Training finished
2017-06-03 14:48:38.517082 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #257 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 14:48:38.517372 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #257 | Collecting samples for evaluation
2017-06-03 14:48:49.079904 EDT | -----------------------  --------------
2017-06-03 14:48:49.080304 EDT | Epoch                     257
2017-06-03 14:48:49.080568 EDT | Iteration                 257
2017-06-03 14:48:49.080818 EDT | AverageReturn            1000
2017-06-03 14:48:49.081064 EDT | StdReturn                   0
2017-06-03 14:48:49.081307 EDT | MaxReturn                1000
2017-06-03 14:48:49.081549 EDT | MinReturn                1000
2017-06-03 14:48:49.081804 EDT | AverageEsReturn            16.8644
2017-06-03 14:48:49.082081 EDT | StdEsReturn                12.6912
2017-06-03 14:48:49.082357 EDT | MaxEsReturn                67
2017-06-03 14:48:49.082683 EDT | MinEsReturn                 3
2017-06-03 14:48:49.082938 EDT | AverageDiscountedReturn    99.9957
2017-06-03 14:48:49.083182 EDT | AverageQLoss                0.000106232
2017-06-03 14:48:49.083424 EDT | AveragePolicySurr          -0.161031
2017-06-03 14:48:49.083666 EDT | AverageQ                    0.152286
2017-06-03 14:48:49.083918 EDT | AverageAbsQ                 0.15291
2017-06-03 14:48:49.084185 EDT | AverageY                    0.152279
2017-06-03 14:48:49.084428 EDT | AverageAbsY                 0.152394
2017-06-03 14:48:49.084671 EDT | AverageAbsQYDiff            0.00258154
2017-06-03 14:48:49.084914 EDT | AverageAction               0.271478
2017-06-03 14:48:49.085157 EDT | PolicyRegParamNorm         52.8174
2017-06-03 14:48:49.085472 EDT | QFunRegParamNorm           25.9835
2017-06-03 14:48:49.085724 EDT | -----------------------  --------------
2017-06-03 14:48:49.086100 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #258 | Training started
2017-06-03 14:49:08.123953 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #258 | Training finished
2017-06-03 14:49:08.124880 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #258 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 14:49:08.125157 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #258 | Collecting samples for evaluation
2017-06-03 14:49:17.964293 EDT | -----------------------  --------------
2017-06-03 14:49:17.965549 EDT | Epoch                     258
2017-06-03 14:49:17.965851 EDT | Iteration                 258
2017-06-03 14:49:17.966093 EDT | AverageReturn            1000
2017-06-03 14:49:17.966343 EDT | StdReturn                   0
2017-06-03 14:49:17.966570 EDT | MaxReturn                1000
2017-06-03 14:49:17.966795 EDT | MinReturn                1000
2017-06-03 14:49:17.967019 EDT | AverageEsReturn            20.098
2017-06-03 14:49:17.967244 EDT | StdEsReturn                14.57
2017-06-03 14:49:17.967467 EDT | MaxEsReturn                61
2017-06-03 14:49:17.967690 EDT | MinEsReturn                 3
2017-06-03 14:49:17.967917 EDT | AverageDiscountedReturn    99.9957
2017-06-03 14:49:17.968140 EDT | AverageQLoss                8.05698e-05
2017-06-03 14:49:17.968361 EDT | AveragePolicySurr          -0.160497
2017-06-03 14:49:17.968583 EDT | AverageQ                    0.15238
2017-06-03 14:49:17.968805 EDT | AverageAbsQ                 0.15293
2017-06-03 14:49:17.969025 EDT | AverageY                    0.152379
2017-06-03 14:49:17.969246 EDT | AverageAbsY                 0.152472
2017-06-03 14:49:17.969468 EDT | AverageAbsQYDiff            0.00234303
2017-06-03 14:49:17.969689 EDT | AverageAction               0.0481997
2017-06-03 14:49:17.969946 EDT | PolicyRegParamNorm         52.8494
2017-06-03 14:49:17.970181 EDT | QFunRegParamNorm           25.9806
2017-06-03 14:49:17.970418 EDT | -----------------------  --------------
2017-06-03 14:49:17.970808 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #259 | Training started
2017-06-03 14:49:36.812937 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #259 | Training finished
2017-06-03 14:49:36.813873 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #259 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 14:49:36.814182 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #259 | Collecting samples for evaluation
2017-06-03 14:49:45.905494 EDT | -----------------------  --------------
2017-06-03 14:49:45.906360 EDT | Epoch                     259
2017-06-03 14:49:45.906637 EDT | Iteration                 259
2017-06-03 14:49:45.906875 EDT | AverageReturn            1000
2017-06-03 14:49:45.907115 EDT | StdReturn                   0
2017-06-03 14:49:45.907356 EDT | MaxReturn                1000
2017-06-03 14:49:45.907587 EDT | MinReturn                1000
2017-06-03 14:49:45.907817 EDT | AverageEsReturn            23.1429
2017-06-03 14:49:45.908047 EDT | StdEsReturn                24.4215
2017-06-03 14:49:45.908276 EDT | MaxEsReturn               145
2017-06-03 14:49:45.908504 EDT | MinEsReturn                 3
2017-06-03 14:49:45.908738 EDT | AverageDiscountedReturn    99.9957
2017-06-03 14:49:45.908966 EDT | AverageQLoss                0.000110392
2017-06-03 14:49:45.909191 EDT | AveragePolicySurr          -0.159908
2017-06-03 14:49:45.909418 EDT | AverageQ                    0.151952
2017-06-03 14:49:45.909645 EDT | AverageAbsQ                 0.15259
2017-06-03 14:49:45.909925 EDT | AverageY                    0.15195
2017-06-03 14:49:45.910170 EDT | AverageAbsY                 0.152051
2017-06-03 14:49:45.910413 EDT | AverageAbsQYDiff            0.00268035
2017-06-03 14:49:45.910657 EDT | AverageAction               0.0313714
2017-06-03 14:49:45.910898 EDT | PolicyRegParamNorm         52.8746
2017-06-03 14:49:45.911140 EDT | QFunRegParamNorm           25.9688
2017-06-03 14:49:45.911380 EDT | -----------------------  --------------
2017-06-03 14:49:45.911785 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #260 | Training started
2017-06-03 14:50:04.696263 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #260 | Training finished
2017-06-03 14:50:04.697326 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #260 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 14:50:04.697602 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #260 | Collecting samples for evaluation
2017-06-03 14:50:14.098902 EDT | -----------------------  --------------
2017-06-03 14:50:14.100401 EDT | Epoch                     260
2017-06-03 14:50:14.100703 EDT | Iteration                 260
2017-06-03 14:50:14.100946 EDT | AverageReturn            1000
2017-06-03 14:50:14.101176 EDT | StdReturn                   0
2017-06-03 14:50:14.101407 EDT | MaxReturn                1000
2017-06-03 14:50:14.101637 EDT | MinReturn                1000
2017-06-03 14:50:14.101882 EDT | AverageEsReturn            24.5366
2017-06-03 14:50:14.102114 EDT | StdEsReturn                16.1579
2017-06-03 14:50:14.102345 EDT | MaxEsReturn                71
2017-06-03 14:50:14.102581 EDT | MinEsReturn                 3
2017-06-03 14:50:14.102832 EDT | AverageDiscountedReturn    99.9957
2017-06-03 14:50:14.103060 EDT | AverageQLoss                9.04722e-05
2017-06-03 14:50:14.103287 EDT | AveragePolicySurr          -0.159057
2017-06-03 14:50:14.103514 EDT | AverageQ                    0.150934
2017-06-03 14:50:14.103739 EDT | AverageAbsQ                 0.151508
2017-06-03 14:50:14.103974 EDT | AverageY                    0.150941
2017-06-03 14:50:14.104200 EDT | AverageAbsY                 0.151061
2017-06-03 14:50:14.104427 EDT | AverageAbsQYDiff            0.00242776
2017-06-03 14:50:14.104652 EDT | AverageAction               0.255758
2017-06-03 14:50:14.104877 EDT | PolicyRegParamNorm         52.9261
2017-06-03 14:50:14.105103 EDT | QFunRegParamNorm           25.9772
2017-06-03 14:50:14.105328 EDT | -----------------------  --------------
2017-06-03 14:50:14.105722 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #261 | Training started
2017-06-03 14:50:33.258369 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #261 | Training finished
2017-06-03 14:50:33.259295 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #261 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 14:50:33.259578 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #261 | Collecting samples for evaluation
2017-06-03 14:50:43.133137 EDT | -----------------------  -------------
2017-06-03 14:50:43.135029 EDT | Epoch                    261
2017-06-03 14:50:43.135336 EDT | Iteration                261
2017-06-03 14:50:43.135578 EDT | AverageReturn             66.84
2017-06-03 14:50:43.135815 EDT | StdReturn                  1.7169
2017-06-03 14:50:43.136050 EDT | MaxReturn                 72
2017-06-03 14:50:43.136292 EDT | MinReturn                 64
2017-06-03 14:50:43.136527 EDT | AverageEsReturn           28.8571
2017-06-03 14:50:43.136759 EDT | StdEsReturn               24.4974
2017-06-03 14:50:43.136990 EDT | MaxEsReturn              105
2017-06-03 14:50:43.137220 EDT | MinEsReturn                4
2017-06-03 14:50:43.137452 EDT | AverageDiscountedReturn   48.9117
2017-06-03 14:50:43.137682 EDT | AverageQLoss               9.14926e-05
2017-06-03 14:50:43.137964 EDT | AveragePolicySurr         -0.158195
2017-06-03 14:50:43.138198 EDT | AverageQ                   0.150343
2017-06-03 14:50:43.138430 EDT | AverageAbsQ                0.150883
2017-06-03 14:50:43.138684 EDT | AverageY                   0.150328
2017-06-03 14:50:43.138916 EDT | AverageAbsY                0.150433
2017-06-03 14:50:43.139148 EDT | AverageAbsQYDiff           0.00234738
2017-06-03 14:50:43.139380 EDT | AverageAction              0.380948
2017-06-03 14:50:43.139612 EDT | PolicyRegParamNorm        52.9916
2017-06-03 14:50:43.139853 EDT | QFunRegParamNorm          25.9922
2017-06-03 14:50:43.140088 EDT | -----------------------  -------------
2017-06-03 14:50:43.140468 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #262 | Training started
2017-06-03 14:51:04.045692 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #262 | Training finished
2017-06-03 14:51:04.047718 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #262 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 14:51:04.047984 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #262 | Collecting samples for evaluation
2017-06-03 14:51:12.695468 EDT | -----------------------  --------------
2017-06-03 14:51:12.696295 EDT | Epoch                     262
2017-06-03 14:51:12.696554 EDT | Iteration                 262
2017-06-03 14:51:12.696798 EDT | AverageReturn            1000
2017-06-03 14:51:12.697034 EDT | StdReturn                   0
2017-06-03 14:51:12.697269 EDT | MaxReturn                1000
2017-06-03 14:51:12.697501 EDT | MinReturn                1000
2017-06-03 14:51:12.697743 EDT | AverageEsReturn            24.5366
2017-06-03 14:51:12.697979 EDT | StdEsReturn                23.1665
2017-06-03 14:51:12.698211 EDT | MaxEsReturn               122
2017-06-03 14:51:12.698442 EDT | MinEsReturn                 3
2017-06-03 14:51:12.698674 EDT | AverageDiscountedReturn    99.9957
2017-06-03 14:51:12.698905 EDT | AverageQLoss                0.000114748
2017-06-03 14:51:12.699136 EDT | AveragePolicySurr          -0.1575
2017-06-03 14:51:12.699365 EDT | AverageQ                    0.149553
2017-06-03 14:51:12.699595 EDT | AverageAbsQ                 0.150128
2017-06-03 14:51:12.699825 EDT | AverageY                    0.149561
2017-06-03 14:51:12.700055 EDT | AverageAbsY                 0.149619
2017-06-03 14:51:12.700285 EDT | AverageAbsQYDiff            0.00273845
2017-06-03 14:51:12.700516 EDT | AverageAction               0.24928
2017-06-03 14:51:12.700746 EDT | PolicyRegParamNorm         53.0589
2017-06-03 14:51:12.700986 EDT | QFunRegParamNorm           26.0076
2017-06-03 14:51:12.701216 EDT | -----------------------  --------------
2017-06-03 14:51:12.701559 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #263 | Training started
2017-06-03 14:51:31.553114 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #263 | Training finished
2017-06-03 14:51:31.553950 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #263 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 14:51:31.554230 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #263 | Collecting samples for evaluation
2017-06-03 14:51:41.255321 EDT | -----------------------  --------------
2017-06-03 14:51:41.256307 EDT | Epoch                     263
2017-06-03 14:51:41.256587 EDT | Iteration                 263
2017-06-03 14:51:41.256835 EDT | AverageReturn            1000
2017-06-03 14:51:41.257068 EDT | StdReturn                   0
2017-06-03 14:51:41.257299 EDT | MaxReturn                1000
2017-06-03 14:51:41.257529 EDT | MinReturn                1000
2017-06-03 14:51:41.257781 EDT | AverageEsReturn            22.6818
2017-06-03 14:51:41.258011 EDT | StdEsReturn                24.1997
2017-06-03 14:51:41.258241 EDT | MaxEsReturn               116
2017-06-03 14:51:41.258471 EDT | MinEsReturn                 3
2017-06-03 14:51:41.258698 EDT | AverageDiscountedReturn    99.9957
2017-06-03 14:51:41.258924 EDT | AverageQLoss                9.67595e-05
2017-06-03 14:51:41.259150 EDT | AveragePolicySurr          -0.156413
2017-06-03 14:51:41.259377 EDT | AverageQ                    0.148354
2017-06-03 14:51:41.259605 EDT | AverageAbsQ                 0.148946
2017-06-03 14:51:41.259832 EDT | AverageY                    0.148351
2017-06-03 14:51:41.260059 EDT | AverageAbsY                 0.148406
2017-06-03 14:51:41.260286 EDT | AverageAbsQYDiff            0.00254981
2017-06-03 14:51:41.260512 EDT | AverageAction               0.290796
2017-06-03 14:51:41.260745 EDT | PolicyRegParamNorm         53.0889
2017-06-03 14:51:41.260973 EDT | QFunRegParamNorm           25.9891
2017-06-03 14:51:41.261199 EDT | -----------------------  --------------
2017-06-03 14:51:41.261578 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #264 | Training started
2017-06-03 14:51:59.487343 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #264 | Training finished
2017-06-03 14:51:59.488269 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #264 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 14:51:59.488558 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #264 | Collecting samples for evaluation
2017-06-03 14:52:10.974272 EDT | -----------------------  -------------
2017-06-03 14:52:10.975088 EDT | Epoch                    264
2017-06-03 14:52:10.975371 EDT | Iteration                264
2017-06-03 14:52:10.975602 EDT | AverageReturn             61.5276
2017-06-03 14:52:10.975829 EDT | StdReturn                 15.9794
2017-06-03 14:52:10.976113 EDT | MaxReturn                164
2017-06-03 14:52:10.976336 EDT | MinReturn                 56
2017-06-03 14:52:10.976555 EDT | AverageEsReturn           22.9318
2017-06-03 14:52:10.976773 EDT | StdEsReturn               21.1718
2017-06-03 14:52:10.976991 EDT | MaxEsReturn              128
2017-06-03 14:52:10.977203 EDT | MinEsReturn                3
2017-06-03 14:52:10.977415 EDT | AverageDiscountedReturn   45.5975
2017-06-03 14:52:10.977627 EDT | AverageQLoss               8.04212e-05
2017-06-03 14:52:10.977864 EDT | AveragePolicySurr         -0.155822
2017-06-03 14:52:10.978078 EDT | AverageQ                   0.148078
2017-06-03 14:52:10.978291 EDT | AverageAbsQ                0.148581
2017-06-03 14:52:10.978503 EDT | AverageY                   0.14808
2017-06-03 14:52:10.978758 EDT | AverageAbsY                0.148164
2017-06-03 14:52:10.979020 EDT | AverageAbsQYDiff           0.00224245
2017-06-03 14:52:10.979278 EDT | AverageAction              0.436097
2017-06-03 14:52:10.979544 EDT | PolicyRegParamNorm        53.1148
2017-06-03 14:52:10.979806 EDT | QFunRegParamNorm          26.001
2017-06-03 14:52:10.980067 EDT | -----------------------  -------------
2017-06-03 14:52:10.980493 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #265 | Training started
2017-06-03 14:52:28.799273 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #265 | Training finished
2017-06-03 14:52:28.800159 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #265 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 14:52:28.800444 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #265 | Collecting samples for evaluation
2017-06-03 14:52:37.723848 EDT | -----------------------  --------------
2017-06-03 14:52:37.724822 EDT | Epoch                     265
2017-06-03 14:52:37.725085 EDT | Iteration                 265
2017-06-03 14:52:37.725319 EDT | AverageReturn            1000
2017-06-03 14:52:37.725605 EDT | StdReturn                   0
2017-06-03 14:52:37.725882 EDT | MaxReturn                1000
2017-06-03 14:52:37.726117 EDT | MinReturn                1000
2017-06-03 14:52:37.726380 EDT | AverageEsReturn            21.087
2017-06-03 14:52:37.726605 EDT | StdEsReturn                15.918
2017-06-03 14:52:37.726845 EDT | MaxEsReturn                65
2017-06-03 14:52:37.727074 EDT | MinEsReturn                 3
2017-06-03 14:52:37.727298 EDT | AverageDiscountedReturn    99.9957
2017-06-03 14:52:37.727524 EDT | AverageQLoss                9.48875e-05
2017-06-03 14:52:37.727748 EDT | AveragePolicySurr          -0.155014
2017-06-03 14:52:37.727970 EDT | AverageQ                    0.147038
2017-06-03 14:52:37.728191 EDT | AverageAbsQ                 0.147639
2017-06-03 14:52:37.728420 EDT | AverageY                    0.14703
2017-06-03 14:52:37.728654 EDT | AverageAbsY                 0.14709
2017-06-03 14:52:37.728875 EDT | AverageAbsQYDiff            0.00255582
2017-06-03 14:52:37.729137 EDT | AverageAction               0.382313
2017-06-03 14:52:37.729367 EDT | PolicyRegParamNorm         53.1649
2017-06-03 14:52:37.729589 EDT | QFunRegParamNorm           26.0247
2017-06-03 14:52:37.730452 EDT | -----------------------  --------------
2017-06-03 14:52:37.730919 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #266 | Training started
2017-06-03 14:52:56.026606 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #266 | Training finished
2017-06-03 14:52:56.027865 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #266 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 14:52:56.028137 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #266 | Collecting samples for evaluation
2017-06-03 14:53:05.776241 EDT | -----------------------  --------------
2017-06-03 14:53:05.776647 EDT | Epoch                     266
2017-06-03 14:53:05.776922 EDT | Iteration                 266
2017-06-03 14:53:05.777193 EDT | AverageReturn            1000
2017-06-03 14:53:05.777450 EDT | StdReturn                   0
2017-06-03 14:53:05.777720 EDT | MaxReturn                1000
2017-06-03 14:53:05.777979 EDT | MinReturn                1000
2017-06-03 14:53:05.778232 EDT | AverageEsReturn            23.5814
2017-06-03 14:53:05.778487 EDT | StdEsReturn                16.9681
2017-06-03 14:53:05.778740 EDT | MaxEsReturn                70
2017-06-03 14:53:05.778993 EDT | MinEsReturn                 4
2017-06-03 14:53:05.779246 EDT | AverageDiscountedReturn    99.9957
2017-06-03 14:53:05.779499 EDT | AverageQLoss                9.24406e-05
2017-06-03 14:53:05.779749 EDT | AveragePolicySurr          -0.154245
2017-06-03 14:53:05.780001 EDT | AverageQ                    0.146599
2017-06-03 14:53:05.780252 EDT | AverageAbsQ                 0.147197
2017-06-03 14:53:05.780502 EDT | AverageY                    0.146609
2017-06-03 14:53:05.780754 EDT | AverageAbsY                 0.146676
2017-06-03 14:53:05.781014 EDT | AverageAbsQYDiff            0.00253967
2017-06-03 14:53:05.781264 EDT | AverageAction               0.311378
2017-06-03 14:53:05.781514 EDT | PolicyRegParamNorm         53.1483
2017-06-03 14:53:05.781786 EDT | QFunRegParamNorm           26.0215
2017-06-03 14:53:05.782039 EDT | -----------------------  --------------
2017-06-03 14:53:05.782489 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #267 | Training started
2017-06-03 14:53:27.073882 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #267 | Training finished
2017-06-03 14:53:27.074777 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #267 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 14:53:27.075044 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #267 | Collecting samples for evaluation
2017-06-03 14:53:36.960547 EDT | -----------------------  --------------
2017-06-03 14:53:36.960967 EDT | Epoch                     267
2017-06-03 14:53:36.961225 EDT | Iteration                 267
2017-06-03 14:53:36.961454 EDT | AverageReturn            1000
2017-06-03 14:53:36.961680 EDT | StdReturn                   0
2017-06-03 14:53:36.961926 EDT | MaxReturn                1000
2017-06-03 14:53:36.962184 EDT | MinReturn                1000
2017-06-03 14:53:36.962418 EDT | AverageEsReturn            33.9655
2017-06-03 14:53:36.962647 EDT | StdEsReturn                25.0565
2017-06-03 14:53:36.962881 EDT | MaxEsReturn                97
2017-06-03 14:53:36.963108 EDT | MinEsReturn                 6
2017-06-03 14:53:36.963352 EDT | AverageDiscountedReturn    99.9957
2017-06-03 14:53:36.963581 EDT | AverageQLoss                8.96182e-05
2017-06-03 14:53:36.963805 EDT | AveragePolicySurr          -0.153509
2017-06-03 14:53:36.964030 EDT | AverageQ                    0.145808
2017-06-03 14:53:36.964256 EDT | AverageAbsQ                 0.146346
2017-06-03 14:53:36.964483 EDT | AverageY                    0.145805
2017-06-03 14:53:36.964709 EDT | AverageAbsY                 0.145872
2017-06-03 14:53:36.964936 EDT | AverageAbsQYDiff            0.00239274
2017-06-03 14:53:36.965162 EDT | AverageAction               0.238711
2017-06-03 14:53:36.965388 EDT | PolicyRegParamNorm         53.1943
2017-06-03 14:53:36.965614 EDT | QFunRegParamNorm           26.0203
2017-06-03 14:53:36.965862 EDT | -----------------------  --------------
2017-06-03 14:53:36.966248 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #268 | Training started
2017-06-03 14:53:56.757420 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #268 | Training finished
2017-06-03 14:53:56.758331 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #268 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 14:53:56.758607 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #268 | Collecting samples for evaluation
2017-06-03 14:54:07.135746 EDT | -----------------------  --------------
2017-06-03 14:54:07.136195 EDT | Epoch                     268
2017-06-03 14:54:07.136498 EDT | Iteration                 268
2017-06-03 14:54:07.136734 EDT | AverageReturn            1000
2017-06-03 14:54:07.136968 EDT | StdReturn                   0
2017-06-03 14:54:07.137202 EDT | MaxReturn                1000
2017-06-03 14:54:07.137432 EDT | MinReturn                1000
2017-06-03 14:54:07.137676 EDT | AverageEsReturn            28.9143
2017-06-03 14:54:07.137922 EDT | StdEsReturn                21.7707
2017-06-03 14:54:07.138156 EDT | MaxEsReturn                95
2017-06-03 14:54:07.138385 EDT | MinEsReturn                 3
2017-06-03 14:54:07.138615 EDT | AverageDiscountedReturn    99.9957
2017-06-03 14:54:07.138843 EDT | AverageQLoss                9.62523e-05
2017-06-03 14:54:07.139073 EDT | AveragePolicySurr          -0.152861
2017-06-03 14:54:07.139302 EDT | AverageQ                    0.144969
2017-06-03 14:54:07.139530 EDT | AverageAbsQ                 0.145555
2017-06-03 14:54:07.139759 EDT | AverageY                    0.144966
2017-06-03 14:54:07.139998 EDT | AverageAbsY                 0.145049
2017-06-03 14:54:07.140226 EDT | AverageAbsQYDiff            0.00257924
2017-06-03 14:54:07.140453 EDT | AverageAction               0.167279
2017-06-03 14:54:07.140680 EDT | PolicyRegParamNorm         53.2068
2017-06-03 14:54:07.140909 EDT | QFunRegParamNorm           26.035
2017-06-03 14:54:07.141137 EDT | -----------------------  --------------
2017-06-03 14:54:07.141521 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #269 | Training started
2017-06-03 14:54:26.573261 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #269 | Training finished
2017-06-03 14:54:26.574169 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #269 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 14:54:26.574580 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #269 | Collecting samples for evaluation
2017-06-03 14:54:35.763103 EDT | -----------------------  --------------
2017-06-03 14:54:35.763528 EDT | Epoch                     269
2017-06-03 14:54:35.763788 EDT | Iteration                 269
2017-06-03 14:54:35.764037 EDT | AverageReturn            1000
2017-06-03 14:54:35.764272 EDT | StdReturn                   0
2017-06-03 14:54:35.764516 EDT | MaxReturn                1000
2017-06-03 14:54:35.764751 EDT | MinReturn                1000
2017-06-03 14:54:35.764991 EDT | AverageEsReturn            26.0769
2017-06-03 14:54:35.765227 EDT | StdEsReturn                21.7885
2017-06-03 14:54:35.765458 EDT | MaxEsReturn               116
2017-06-03 14:54:35.765690 EDT | MinEsReturn                 3
2017-06-03 14:54:35.765934 EDT | AverageDiscountedReturn    99.9957
2017-06-03 14:54:35.766167 EDT | AverageQLoss                9.45084e-05
2017-06-03 14:54:35.766398 EDT | AveragePolicySurr          -0.15163
2017-06-03 14:54:35.766629 EDT | AverageQ                    0.143971
2017-06-03 14:54:35.766862 EDT | AverageAbsQ                 0.144576
2017-06-03 14:54:35.767093 EDT | AverageY                    0.143963
2017-06-03 14:54:35.767325 EDT | AverageAbsY                 0.144049
2017-06-03 14:54:35.767556 EDT | AverageAbsQYDiff            0.00252508
2017-06-03 14:54:35.767787 EDT | AverageAction               0.0477863
2017-06-03 14:54:35.768017 EDT | PolicyRegParamNorm         53.2579
2017-06-03 14:54:35.768247 EDT | QFunRegParamNorm           26.0319
2017-06-03 14:54:35.768478 EDT | -----------------------  --------------
2017-06-03 14:54:35.768895 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #270 | Training started
2017-06-03 14:54:54.883584 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #270 | Training finished
2017-06-03 14:54:54.970480 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #270 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 14:54:54.970824 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #270 | Collecting samples for evaluation
2017-06-03 14:55:04.682568 EDT | -----------------------  --------------
2017-06-03 14:55:04.683444 EDT | Epoch                     270
2017-06-03 14:55:04.683704 EDT | Iteration                 270
2017-06-03 14:55:04.683951 EDT | AverageReturn            1000
2017-06-03 14:55:04.684197 EDT | StdReturn                   0
2017-06-03 14:55:04.684431 EDT | MaxReturn                1000
2017-06-03 14:55:04.684663 EDT | MinReturn                1000
2017-06-03 14:55:04.684895 EDT | AverageEsReturn            21.7826
2017-06-03 14:55:04.685132 EDT | StdEsReturn                16.4699
2017-06-03 14:55:04.685365 EDT | MaxEsReturn                73
2017-06-03 14:55:04.685595 EDT | MinEsReturn                 4
2017-06-03 14:55:04.685836 EDT | AverageDiscountedReturn    99.9957
2017-06-03 14:55:04.686070 EDT | AverageQLoss                9.18102e-05
2017-06-03 14:55:04.686302 EDT | AveragePolicySurr          -0.151076
2017-06-03 14:55:04.686539 EDT | AverageQ                    0.143421
2017-06-03 14:55:04.686771 EDT | AverageAbsQ                 0.143975
2017-06-03 14:55:04.687001 EDT | AverageY                    0.14342
2017-06-03 14:55:04.687232 EDT | AverageAbsY                 0.143511
2017-06-03 14:55:04.687463 EDT | AverageAbsQYDiff            0.00247516
2017-06-03 14:55:04.687693 EDT | AverageAction               0.0188421
2017-06-03 14:55:04.687928 EDT | PolicyRegParamNorm         53.2728
2017-06-03 14:55:04.688158 EDT | QFunRegParamNorm           26.0431
2017-06-03 14:55:04.688386 EDT | -----------------------  --------------
2017-06-03 14:55:04.688752 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #271 | Training started
2017-06-03 14:55:22.943046 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #271 | Training finished
2017-06-03 14:55:22.944167 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #271 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 14:55:22.944565 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #271 | Collecting samples for evaluation
2017-06-03 14:55:32.058923 EDT | -----------------------  --------------
2017-06-03 14:55:32.059788 EDT | Epoch                     271
2017-06-03 14:55:32.060056 EDT | Iteration                 271
2017-06-03 14:55:32.060294 EDT | AverageReturn            1000
2017-06-03 14:55:32.060537 EDT | StdReturn                   0
2017-06-03 14:55:32.060767 EDT | MaxReturn                1000
2017-06-03 14:55:32.061001 EDT | MinReturn                1000
2017-06-03 14:55:32.061230 EDT | AverageEsReturn            25.5789
2017-06-03 14:55:32.061459 EDT | StdEsReturn                20.2947
2017-06-03 14:55:32.061686 EDT | MaxEsReturn                90
2017-06-03 14:55:32.061944 EDT | MinEsReturn                 4
2017-06-03 14:55:32.062172 EDT | AverageDiscountedReturn    99.9957
2017-06-03 14:55:32.062399 EDT | AverageQLoss                7.67552e-05
2017-06-03 14:55:32.062625 EDT | AveragePolicySurr          -0.15031
2017-06-03 14:55:32.062851 EDT | AverageQ                    0.142485
2017-06-03 14:55:32.063077 EDT | AverageAbsQ                 0.142959
2017-06-03 14:55:32.063302 EDT | AverageY                    0.142485
2017-06-03 14:55:32.063528 EDT | AverageAbsY                 0.142561
2017-06-03 14:55:32.063754 EDT | AverageAbsQYDiff            0.00221605
2017-06-03 14:55:32.063984 EDT | AverageAction               0.0632595
2017-06-03 14:55:32.064214 EDT | PolicyRegParamNorm         53.3378
2017-06-03 14:55:32.064623 EDT | QFunRegParamNorm           26.0418
2017-06-03 14:55:32.064884 EDT | -----------------------  --------------
2017-06-03 14:55:32.065833 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #272 | Training started
2017-06-03 14:55:50.631718 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #272 | Training finished
2017-06-03 14:55:50.632614 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #272 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 14:55:50.632884 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #272 | Collecting samples for evaluation
2017-06-03 14:55:59.682591 EDT | -----------------------  --------------
2017-06-03 14:55:59.682963 EDT | Epoch                     272
2017-06-03 14:55:59.683223 EDT | Iteration                 272
2017-06-03 14:55:59.683474 EDT | AverageReturn            1000
2017-06-03 14:55:59.683719 EDT | StdReturn                   0
2017-06-03 14:55:59.683964 EDT | MaxReturn                1000
2017-06-03 14:55:59.684208 EDT | MinReturn                1000
2017-06-03 14:55:59.684451 EDT | AverageEsReturn            21.0217
2017-06-03 14:55:59.684694 EDT | StdEsReturn                15.8176
2017-06-03 14:55:59.684946 EDT | MaxEsReturn                66
2017-06-03 14:55:59.685209 EDT | MinEsReturn                 3
2017-06-03 14:55:59.685451 EDT | AverageDiscountedReturn    99.9957
2017-06-03 14:55:59.685697 EDT | AverageQLoss                7.99422e-05
2017-06-03 14:55:59.685944 EDT | AveragePolicySurr          -0.149756
2017-06-03 14:55:59.686276 EDT | AverageQ                    0.14232
2017-06-03 14:55:59.686624 EDT | AverageAbsQ                 0.142868
2017-06-03 14:55:59.686946 EDT | AverageY                    0.142311
2017-06-03 14:55:59.687258 EDT | AverageAbsY                 0.142373
2017-06-03 14:55:59.687577 EDT | AverageAbsQYDiff            0.00236967
2017-06-03 14:55:59.687892 EDT | AverageAction               0.0357818
2017-06-03 14:55:59.688200 EDT | PolicyRegParamNorm         53.4031
2017-06-03 14:55:59.688506 EDT | QFunRegParamNorm           26.0616
2017-06-03 14:55:59.688846 EDT | -----------------------  --------------
2017-06-03 14:55:59.689275 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #273 | Training started
2017-06-03 14:56:18.086064 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #273 | Training finished
2017-06-03 14:56:18.086697 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #273 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 14:56:18.086974 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #273 | Collecting samples for evaluation
2017-06-03 14:56:28.201060 EDT | -----------------------  --------------
2017-06-03 14:56:28.201894 EDT | Epoch                     273
2017-06-03 14:56:28.202149 EDT | Iteration                 273
2017-06-03 14:56:28.202387 EDT | AverageReturn            1000
2017-06-03 14:56:28.202624 EDT | StdReturn                   0
2017-06-03 14:56:28.202852 EDT | MaxReturn                1000
2017-06-03 14:56:28.203172 EDT | MinReturn                1000
2017-06-03 14:56:28.203496 EDT | AverageEsReturn            27.9189
2017-06-03 14:56:28.203809 EDT | StdEsReturn                19.8608
2017-06-03 14:56:28.204119 EDT | MaxEsReturn                66
2017-06-03 14:56:28.204426 EDT | MinEsReturn                 3
2017-06-03 14:56:28.204731 EDT | AverageDiscountedReturn    99.9957
2017-06-03 14:56:28.205035 EDT | AverageQLoss                0.000103438
2017-06-03 14:56:28.205339 EDT | AveragePolicySurr          -0.148751
2017-06-03 14:56:28.205643 EDT | AverageQ                    0.141364
2017-06-03 14:56:28.205957 EDT | AverageAbsQ                 0.141965
2017-06-03 14:56:28.206260 EDT | AverageY                    0.141369
2017-06-03 14:56:28.206563 EDT | AverageAbsY                 0.141446
2017-06-03 14:56:28.206866 EDT | AverageAbsQYDiff            0.00275024
2017-06-03 14:56:28.207207 EDT | AverageAction               0.0243715
2017-06-03 14:56:28.207456 EDT | PolicyRegParamNorm         53.4754
2017-06-03 14:56:28.207695 EDT | QFunRegParamNorm           26.0732
2017-06-03 14:56:28.207933 EDT | -----------------------  --------------
2017-06-03 14:56:28.208296 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #274 | Training started
2017-06-03 14:56:47.060717 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #274 | Training finished
2017-06-03 14:56:47.061755 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #274 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 14:56:47.062049 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #274 | Collecting samples for evaluation
2017-06-03 14:56:56.486184 EDT | -----------------------  --------------
2017-06-03 14:56:56.487201 EDT | Epoch                     274
2017-06-03 14:56:56.487476 EDT | Iteration                 274
2017-06-03 14:56:56.487716 EDT | AverageReturn            1000
2017-06-03 14:56:56.487959 EDT | StdReturn                   0
2017-06-03 14:56:56.488190 EDT | MaxReturn                1000
2017-06-03 14:56:56.488419 EDT | MinReturn                1000
2017-06-03 14:56:56.488649 EDT | AverageEsReturn            25.3
2017-06-03 14:56:56.488877 EDT | StdEsReturn                21.7798
2017-06-03 14:56:56.489105 EDT | MaxEsReturn               103
2017-06-03 14:56:56.489332 EDT | MinEsReturn                 3
2017-06-03 14:56:56.489559 EDT | AverageDiscountedReturn    99.9957
2017-06-03 14:56:56.490180 EDT | AverageQLoss                7.75504e-05
2017-06-03 14:56:56.490502 EDT | AveragePolicySurr          -0.147963
2017-06-03 14:56:56.490820 EDT | AverageQ                    0.140657
2017-06-03 14:56:56.491133 EDT | AverageAbsQ                 0.141201
2017-06-03 14:56:56.491445 EDT | AverageY                    0.140649
2017-06-03 14:56:56.491762 EDT | AverageAbsY                 0.140747
2017-06-03 14:56:56.492114 EDT | AverageAbsQYDiff            0.00233052
2017-06-03 14:56:56.492426 EDT | AverageAction               0.143774
2017-06-03 14:56:56.492735 EDT | PolicyRegParamNorm         53.5051
2017-06-03 14:56:56.493051 EDT | QFunRegParamNorm           26.0753
2017-06-03 14:56:56.493363 EDT | -----------------------  --------------
2017-06-03 14:56:56.493880 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #275 | Training started
2017-06-03 14:57:14.701982 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #275 | Training finished
2017-06-03 14:57:14.703106 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #275 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 14:57:14.703388 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #275 | Collecting samples for evaluation
2017-06-03 14:57:24.559527 EDT | -----------------------  -------------
2017-06-03 14:57:24.560391 EDT | Epoch                     275
2017-06-03 14:57:24.560656 EDT | Iteration                 275
2017-06-03 14:57:24.560903 EDT | AverageReturn            1000
2017-06-03 14:57:24.561140 EDT | StdReturn                   0
2017-06-03 14:57:24.561392 EDT | MaxReturn                1000
2017-06-03 14:57:24.561627 EDT | MinReturn                1000
2017-06-03 14:57:24.561878 EDT | AverageEsReturn            37.1852
2017-06-03 14:57:24.562115 EDT | StdEsReturn                29.1281
2017-06-03 14:57:24.562355 EDT | MaxEsReturn               141
2017-06-03 14:57:24.562588 EDT | MinEsReturn                 4
2017-06-03 14:57:24.562824 EDT | AverageDiscountedReturn    99.9957
2017-06-03 14:57:24.563072 EDT | AverageQLoss                8.338e-05
2017-06-03 14:57:24.563317 EDT | AveragePolicySurr          -0.147533
2017-06-03 14:57:24.563561 EDT | AverageQ                    0.140167
2017-06-03 14:57:24.563803 EDT | AverageAbsQ                 0.140705
2017-06-03 14:57:24.564050 EDT | AverageY                    0.140166
2017-06-03 14:57:24.564291 EDT | AverageAbsY                 0.140278
2017-06-03 14:57:24.564533 EDT | AverageAbsQYDiff            0.00244055
2017-06-03 14:57:24.564779 EDT | AverageAction               0.0703808
2017-06-03 14:57:24.565142 EDT | PolicyRegParamNorm         53.5454
2017-06-03 14:57:24.565459 EDT | QFunRegParamNorm           26.0883
2017-06-03 14:57:24.565780 EDT | -----------------------  -------------
2017-06-03 14:57:24.566258 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #276 | Training started
2017-06-03 14:57:42.979975 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #276 | Training finished
2017-06-03 14:57:42.981042 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #276 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 14:57:42.981320 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #276 | Collecting samples for evaluation
2017-06-03 14:57:51.839460 EDT | -----------------------  --------------
2017-06-03 14:57:51.840290 EDT | Epoch                     276
2017-06-03 14:57:51.840555 EDT | Iteration                 276
2017-06-03 14:57:51.840809 EDT | AverageReturn            1000
2017-06-03 14:57:51.841065 EDT | StdReturn                   0
2017-06-03 14:57:51.841325 EDT | MaxReturn                1000
2017-06-03 14:57:51.841591 EDT | MinReturn                1000
2017-06-03 14:57:51.841848 EDT | AverageEsReturn            28.8857
2017-06-03 14:57:51.842096 EDT | StdEsReturn                21.0289
2017-06-03 14:57:51.842344 EDT | MaxEsReturn                95
2017-06-03 14:57:51.842601 EDT | MinEsReturn                 4
2017-06-03 14:57:51.842850 EDT | AverageDiscountedReturn    99.9957
2017-06-03 14:57:51.843096 EDT | AverageQLoss                8.42422e-05
2017-06-03 14:57:51.843343 EDT | AveragePolicySurr          -0.146937
2017-06-03 14:57:51.843630 EDT | AverageQ                    0.139602
2017-06-03 14:57:51.843877 EDT | AverageAbsQ                 0.140138
2017-06-03 14:57:51.844122 EDT | AverageY                    0.13961
2017-06-03 14:57:51.844367 EDT | AverageAbsY                 0.139678
2017-06-03 14:57:51.844630 EDT | AverageAbsQYDiff            0.00233948
2017-06-03 14:57:51.844896 EDT | AverageAction               0.0466445
2017-06-03 14:57:51.845142 EDT | PolicyRegParamNorm         53.5835
2017-06-03 14:57:51.845386 EDT | QFunRegParamNorm           26.1031
2017-06-03 14:57:51.845631 EDT | -----------------------  --------------
2017-06-03 14:57:51.846011 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #277 | Training started
2017-06-03 14:58:09.639254 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #277 | Training finished
2017-06-03 14:58:09.639762 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #277 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 14:58:09.640152 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #277 | Collecting samples for evaluation
2017-06-03 14:58:20.238887 EDT | -----------------------  --------------
2017-06-03 14:58:20.240094 EDT | Epoch                     277
2017-06-03 14:58:20.241086 EDT | Iteration                 277
2017-06-03 14:58:20.241437 EDT | AverageReturn            1000
2017-06-03 14:58:20.241713 EDT | StdReturn                   0
2017-06-03 14:58:20.241977 EDT | MaxReturn                1000
2017-06-03 14:58:20.242267 EDT | MinReturn                1000
2017-06-03 14:58:20.242547 EDT | AverageEsReturn            33.1
2017-06-03 14:58:20.242803 EDT | StdEsReturn                32.366
2017-06-03 14:58:20.243057 EDT | MaxEsReturn               144
2017-06-03 14:58:20.243335 EDT | MinEsReturn                 5
2017-06-03 14:58:20.243587 EDT | AverageDiscountedReturn    99.9957
2017-06-03 14:58:20.243838 EDT | AverageQLoss                8.29219e-05
2017-06-03 14:58:20.244089 EDT | AveragePolicySurr          -0.145818
2017-06-03 14:58:20.244359 EDT | AverageQ                    0.138532
2017-06-03 14:58:20.244609 EDT | AverageAbsQ                 0.139094
2017-06-03 14:58:20.244859 EDT | AverageY                    0.138528
2017-06-03 14:58:20.245110 EDT | AverageAbsY                 0.138591
2017-06-03 14:58:20.245378 EDT | AverageAbsQYDiff            0.00238473
2017-06-03 14:58:20.245629 EDT | AverageAction               0.236781
2017-06-03 14:58:20.245891 EDT | PolicyRegParamNorm         53.6643
2017-06-03 14:58:20.246141 EDT | QFunRegParamNorm           26.1087
2017-06-03 14:58:20.246411 EDT | -----------------------  --------------
2017-06-03 14:58:20.246839 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #278 | Training started
2017-06-03 14:58:39.394818 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #278 | Training finished
2017-06-03 14:58:39.395153 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #278 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 14:58:39.395407 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #278 | Collecting samples for evaluation
2017-06-03 14:58:49.161987 EDT | -----------------------  -------------
2017-06-03 14:58:49.162961 EDT | Epoch                     278
2017-06-03 14:58:49.163225 EDT | Iteration                 278
2017-06-03 14:58:49.163462 EDT | AverageReturn            1000
2017-06-03 14:58:49.163693 EDT | StdReturn                   0
2017-06-03 14:58:49.163932 EDT | MaxReturn                1000
2017-06-03 14:58:49.164165 EDT | MinReturn                1000
2017-06-03 14:58:49.164392 EDT | AverageEsReturn            34.8276
2017-06-03 14:58:49.164620 EDT | StdEsReturn                24.2758
2017-06-03 14:58:49.164847 EDT | MaxEsReturn                85
2017-06-03 14:58:49.165105 EDT | MinEsReturn                 3
2017-06-03 14:58:49.165345 EDT | AverageDiscountedReturn    99.9957
2017-06-03 14:58:49.165571 EDT | AverageQLoss                7.9945e-05
2017-06-03 14:58:49.166004 EDT | AveragePolicySurr          -0.145515
2017-06-03 14:58:49.166272 EDT | AverageQ                    0.138252
2017-06-03 14:58:49.166518 EDT | AverageAbsQ                 0.138732
2017-06-03 14:58:49.166761 EDT | AverageY                    0.138252
2017-06-03 14:58:49.167009 EDT | AverageAbsY                 0.138326
2017-06-03 14:58:49.167251 EDT | AverageAbsQYDiff            0.00225075
2017-06-03 14:58:49.167493 EDT | AverageAction               0.124689
2017-06-03 14:58:49.167753 EDT | PolicyRegParamNorm         53.7445
2017-06-03 14:58:49.167996 EDT | QFunRegParamNorm           26.1133
2017-06-03 14:58:49.168238 EDT | -----------------------  -------------
2017-06-03 14:58:49.168604 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #279 | Training started
2017-06-03 14:59:07.995937 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #279 | Training finished
2017-06-03 14:59:07.996282 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #279 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 14:59:07.996535 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #279 | Collecting samples for evaluation
2017-06-03 14:59:17.961459 EDT | -----------------------  --------------
2017-06-03 14:59:17.962466 EDT | Epoch                     279
2017-06-03 14:59:17.962813 EDT | Iteration                 279
2017-06-03 14:59:17.963143 EDT | AverageReturn            1000
2017-06-03 14:59:17.963467 EDT | StdReturn                   0
2017-06-03 14:59:17.963790 EDT | MaxReturn                1000
2017-06-03 14:59:17.964144 EDT | MinReturn                1000
2017-06-03 14:59:17.964461 EDT | AverageEsReturn            22.1778
2017-06-03 14:59:17.964780 EDT | StdEsReturn                15.6067
2017-06-03 14:59:17.965097 EDT | MaxEsReturn                61
2017-06-03 14:59:17.965429 EDT | MinEsReturn                 2
2017-06-03 14:59:17.965748 EDT | AverageDiscountedReturn    99.9957
2017-06-03 14:59:17.966091 EDT | AverageQLoss                7.67963e-05
2017-06-03 14:59:17.966407 EDT | AveragePolicySurr          -0.144747
2017-06-03 14:59:17.966723 EDT | AverageQ                    0.13789
2017-06-03 14:59:17.967085 EDT | AverageAbsQ                 0.138348
2017-06-03 14:59:17.967344 EDT | AverageY                    0.137886
2017-06-03 14:59:17.967591 EDT | AverageAbsY                 0.137928
2017-06-03 14:59:17.967856 EDT | AverageAbsQYDiff            0.00218809
2017-06-03 14:59:17.968102 EDT | AverageAction               0.103213
2017-06-03 14:59:17.968347 EDT | PolicyRegParamNorm         53.8049
2017-06-03 14:59:17.968590 EDT | QFunRegParamNorm           26.1348
2017-06-03 14:59:17.968843 EDT | -----------------------  --------------
2017-06-03 14:59:17.969242 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #280 | Training started
2017-06-03 14:59:36.139086 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #280 | Training finished
2017-06-03 14:59:36.140798 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #280 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 14:59:36.141204 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #280 | Collecting samples for evaluation
2017-06-03 14:59:45.708409 EDT | -----------------------  --------------
2017-06-03 14:59:45.709259 EDT | Epoch                     280
2017-06-03 14:59:45.709526 EDT | Iteration                 280
2017-06-03 14:59:45.709799 EDT | AverageReturn            1000
2017-06-03 14:59:45.710048 EDT | StdReturn                   0
2017-06-03 14:59:45.710294 EDT | MaxReturn                1000
2017-06-03 14:59:45.710539 EDT | MinReturn                1000
2017-06-03 14:59:45.710784 EDT | AverageEsReturn            17.2241
2017-06-03 14:59:45.711046 EDT | StdEsReturn                12.5025
2017-06-03 14:59:45.711296 EDT | MaxEsReturn                59
2017-06-03 14:59:45.711540 EDT | MinEsReturn                 3
2017-06-03 14:59:45.711783 EDT | AverageDiscountedReturn    99.9957
2017-06-03 14:59:45.712025 EDT | AverageQLoss                8.28538e-05
2017-06-03 14:59:45.712267 EDT | AveragePolicySurr          -0.14462
2017-06-03 14:59:45.712508 EDT | AverageQ                    0.137312
2017-06-03 14:59:45.712749 EDT | AverageAbsQ                 0.137847
2017-06-03 14:59:45.712991 EDT | AverageY                    0.13731
2017-06-03 14:59:45.713232 EDT | AverageAbsY                 0.137359
2017-06-03 14:59:45.713496 EDT | AverageAbsQYDiff            0.00252371
2017-06-03 14:59:45.713756 EDT | AverageAction               0.0602613
2017-06-03 14:59:45.714016 EDT | PolicyRegParamNorm         53.8777
2017-06-03 14:59:45.714259 EDT | QFunRegParamNorm           26.1485
2017-06-03 14:59:45.714501 EDT | -----------------------  --------------
2017-06-03 14:59:45.714861 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #281 | Training started
2017-06-03 15:00:05.038430 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #281 | Training finished
2017-06-03 15:00:05.039421 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #281 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 15:00:05.039814 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #281 | Collecting samples for evaluation
2017-06-03 15:00:14.544110 EDT | -----------------------  --------------
2017-06-03 15:00:14.545621 EDT | Epoch                     281
2017-06-03 15:00:14.545929 EDT | Iteration                 281
2017-06-03 15:00:14.546171 EDT | AverageReturn            1000
2017-06-03 15:00:14.546470 EDT | StdReturn                   0
2017-06-03 15:00:14.546746 EDT | MaxReturn                1000
2017-06-03 15:00:14.547015 EDT | MinReturn                1000
2017-06-03 15:00:14.547279 EDT | AverageEsReturn            24.9
2017-06-03 15:00:14.547560 EDT | StdEsReturn                20.6262
2017-06-03 15:00:14.547848 EDT | MaxEsReturn                92
2017-06-03 15:00:14.548126 EDT | MinEsReturn                 3
2017-06-03 15:00:14.548385 EDT | AverageDiscountedReturn    99.9957
2017-06-03 15:00:14.548683 EDT | AverageQLoss                7.76818e-05
2017-06-03 15:00:14.548924 EDT | AveragePolicySurr          -0.143879
2017-06-03 15:00:14.549163 EDT | AverageQ                    0.136928
2017-06-03 15:00:14.549400 EDT | AverageAbsQ                 0.137333
2017-06-03 15:00:14.549675 EDT | AverageY                    0.136932
2017-06-03 15:00:14.549924 EDT | AverageAbsY                 0.136977
2017-06-03 15:00:14.550187 EDT | AverageAbsQYDiff            0.0022074
2017-06-03 15:00:14.550431 EDT | AverageAction               0.157728
2017-06-03 15:00:14.550687 EDT | PolicyRegParamNorm         53.9485
2017-06-03 15:00:14.551035 EDT | QFunRegParamNorm           26.152
2017-06-03 15:00:14.551275 EDT | -----------------------  --------------
2017-06-03 15:00:14.551820 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #282 | Training started
2017-06-03 15:00:33.068588 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #282 | Training finished
2017-06-03 15:00:33.188679 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #282 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 15:00:33.189068 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #282 | Collecting samples for evaluation
2017-06-03 15:00:43.575624 EDT | -----------------------  -------------
2017-06-03 15:00:43.576599 EDT | Epoch                    282
2017-06-03 15:00:43.576886 EDT | Iteration                282
2017-06-03 15:00:43.577123 EDT | AverageReturn             53.6898
2017-06-03 15:00:43.577351 EDT | StdReturn                  0.462559
2017-06-03 15:00:43.577577 EDT | MaxReturn                 54
2017-06-03 15:00:43.578068 EDT | MinReturn                 53
2017-06-03 15:00:43.578383 EDT | AverageEsReturn           20.14
2017-06-03 15:00:43.578718 EDT | StdEsReturn               18.5203
2017-06-03 15:00:43.579035 EDT | MaxEsReturn               90
2017-06-03 15:00:43.579350 EDT | MinEsReturn                3
2017-06-03 15:00:43.579656 EDT | AverageDiscountedReturn   41.7013
2017-06-03 15:00:43.579963 EDT | AverageQLoss               7.73891e-05
2017-06-03 15:00:43.580274 EDT | AveragePolicySurr         -0.143325
2017-06-03 15:00:43.580580 EDT | AverageQ                   0.136276
2017-06-03 15:00:43.580884 EDT | AverageAbsQ                0.136759
2017-06-03 15:00:43.581197 EDT | AverageY                   0.136266
2017-06-03 15:00:43.581501 EDT | AverageAbsY                0.136311
2017-06-03 15:00:43.581818 EDT | AverageAbsQYDiff           0.00236426
2017-06-03 15:00:43.582139 EDT | AverageAction              0.253279
2017-06-03 15:00:43.582447 EDT | PolicyRegParamNorm        53.9818
2017-06-03 15:00:43.582751 EDT | QFunRegParamNorm          26.1442
2017-06-03 15:00:43.583189 EDT | -----------------------  -------------
2017-06-03 15:00:43.583638 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #283 | Training started
2017-06-03 15:01:02.125766 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #283 | Training finished
2017-06-03 15:01:02.127571 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #283 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 15:01:02.127857 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #283 | Collecting samples for evaluation
2017-06-03 15:01:13.131207 EDT | -----------------------  --------------
2017-06-03 15:01:13.132095 EDT | Epoch                     283
2017-06-03 15:01:13.132360 EDT | Iteration                 283
2017-06-03 15:01:13.132601 EDT | AverageReturn            1000
2017-06-03 15:01:13.132836 EDT | StdReturn                   0
2017-06-03 15:01:13.133070 EDT | MaxReturn                1000
2017-06-03 15:01:13.133319 EDT | MinReturn                1000
2017-06-03 15:01:13.133552 EDT | AverageEsReturn            23.2558
2017-06-03 15:01:13.133800 EDT | StdEsReturn                15.7215
2017-06-03 15:01:13.134035 EDT | MaxEsReturn                65
2017-06-03 15:01:13.134268 EDT | MinEsReturn                 2
2017-06-03 15:01:13.134503 EDT | AverageDiscountedReturn    99.9957
2017-06-03 15:01:13.134734 EDT | AverageQLoss                6.11324e-05
2017-06-03 15:01:13.134964 EDT | AveragePolicySurr          -0.142859
2017-06-03 15:01:13.135195 EDT | AverageQ                    0.135684
2017-06-03 15:01:13.135426 EDT | AverageAbsQ                 0.136052
2017-06-03 15:01:13.135656 EDT | AverageY                    0.135687
2017-06-03 15:01:13.135887 EDT | AverageAbsY                 0.135721
2017-06-03 15:01:13.136117 EDT | AverageAbsQYDiff            0.00208359
2017-06-03 15:01:13.136347 EDT | AverageAction               0.25398
2017-06-03 15:01:13.136577 EDT | PolicyRegParamNorm         54.0109
2017-06-03 15:01:13.136809 EDT | QFunRegParamNorm           26.1615
2017-06-03 15:01:13.137039 EDT | -----------------------  --------------
2017-06-03 15:01:13.137432 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #284 | Training started
2017-06-03 15:01:32.085116 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #284 | Training finished
2017-06-03 15:01:32.086022 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #284 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 15:01:32.086455 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #284 | Collecting samples for evaluation
2017-06-03 15:01:42.583181 EDT | -----------------------  -------------
2017-06-03 15:01:42.583995 EDT | Epoch                    284
2017-06-03 15:01:42.584262 EDT | Iteration                284
2017-06-03 15:01:42.584520 EDT | AverageReturn             47.9713
2017-06-03 15:01:42.584781 EDT | StdReturn                  0.166985
2017-06-03 15:01:42.585031 EDT | MaxReturn                 48
2017-06-03 15:01:42.585280 EDT | MinReturn                 47
2017-06-03 15:01:42.585528 EDT | AverageEsReturn           29.3636
2017-06-03 15:01:42.585802 EDT | StdEsReturn               25.0851
2017-06-03 15:01:42.586068 EDT | MaxEsReturn              131
2017-06-03 15:01:42.586323 EDT | MinEsReturn                2
2017-06-03 15:01:42.586573 EDT | AverageDiscountedReturn   38.2531
2017-06-03 15:01:42.586821 EDT | AverageQLoss               7.52889e-05
2017-06-03 15:01:42.587082 EDT | AveragePolicySurr         -0.141853
2017-06-03 15:01:42.587341 EDT | AverageQ                   0.134736
2017-06-03 15:01:42.587605 EDT | AverageAbsQ                0.135256
2017-06-03 15:01:42.587850 EDT | AverageY                   0.134742
2017-06-03 15:01:42.588103 EDT | AverageAbsY                0.134782
2017-06-03 15:01:42.588347 EDT | AverageAbsQYDiff           0.00236841
2017-06-03 15:01:42.588608 EDT | AverageAction              0.20606
2017-06-03 15:01:42.588852 EDT | PolicyRegParamNorm        54.0946
2017-06-03 15:01:42.589097 EDT | QFunRegParamNorm          26.1749
2017-06-03 15:01:42.589360 EDT | -----------------------  -------------
2017-06-03 15:01:42.589739 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #285 | Training started
2017-06-03 15:02:01.093247 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #285 | Training finished
2017-06-03 15:02:01.094454 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #285 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 15:02:01.094803 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #285 | Collecting samples for evaluation
2017-06-03 15:02:10.703567 EDT | -----------------------  --------------
2017-06-03 15:02:10.704410 EDT | Epoch                     285
2017-06-03 15:02:10.704677 EDT | Iteration                 285
2017-06-03 15:02:10.704928 EDT | AverageReturn            1000
2017-06-03 15:02:10.705168 EDT | StdReturn                   0
2017-06-03 15:02:10.705402 EDT | MaxReturn                1000
2017-06-03 15:02:10.705631 EDT | MinReturn                1000
2017-06-03 15:02:10.705898 EDT | AverageEsReturn            21.5652
2017-06-03 15:02:10.706154 EDT | StdEsReturn                16.6403
2017-06-03 15:02:10.706387 EDT | MaxEsReturn                83
2017-06-03 15:02:10.706618 EDT | MinEsReturn                 3
2017-06-03 15:02:10.706848 EDT | AverageDiscountedReturn    99.9957
2017-06-03 15:02:10.707087 EDT | AverageQLoss                8.42732e-05
2017-06-03 15:02:10.707328 EDT | AveragePolicySurr          -0.141192
2017-06-03 15:02:10.707559 EDT | AverageQ                    0.134204
2017-06-03 15:02:10.707789 EDT | AverageAbsQ                 0.134724
2017-06-03 15:02:10.708019 EDT | AverageY                    0.134188
2017-06-03 15:02:10.708247 EDT | AverageAbsY                 0.134235
2017-06-03 15:02:10.708475 EDT | AverageAbsQYDiff            0.00249057
2017-06-03 15:02:10.708705 EDT | AverageAction               0.0897307
2017-06-03 15:02:10.708933 EDT | PolicyRegParamNorm         54.1704
2017-06-03 15:02:10.709162 EDT | QFunRegParamNorm           26.18
2017-06-03 15:02:10.709390 EDT | -----------------------  --------------
2017-06-03 15:02:10.709747 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #286 | Training started
2017-06-03 15:02:30.075521 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #286 | Training finished
2017-06-03 15:02:30.077565 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #286 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 15:02:30.077870 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #286 | Collecting samples for evaluation
2017-06-03 15:02:41.738099 EDT | -----------------------  -------------
2017-06-03 15:02:41.739115 EDT | Epoch                     286
2017-06-03 15:02:41.739474 EDT | Iteration                 286
2017-06-03 15:02:41.739806 EDT | AverageReturn            1000
2017-06-03 15:02:41.740141 EDT | StdReturn                   0
2017-06-03 15:02:41.740466 EDT | MaxReturn                1000
2017-06-03 15:02:41.740782 EDT | MinReturn                1000
2017-06-03 15:02:41.741103 EDT | AverageEsReturn            21.8
2017-06-03 15:02:41.741461 EDT | StdEsReturn                16.0036
2017-06-03 15:02:41.741783 EDT | MaxEsReturn                83
2017-06-03 15:02:41.742099 EDT | MinEsReturn                 3
2017-06-03 15:02:41.742421 EDT | AverageDiscountedReturn    99.9957
2017-06-03 15:02:41.742745 EDT | AverageQLoss                7.9609e-05
2017-06-03 15:02:41.743086 EDT | AveragePolicySurr          -0.140871
2017-06-03 15:02:41.743403 EDT | AverageQ                    0.133979
2017-06-03 15:02:41.743718 EDT | AverageAbsQ                 0.134443
2017-06-03 15:02:41.744038 EDT | AverageY                    0.133976
2017-06-03 15:02:41.744354 EDT | AverageAbsY                 0.134017
2017-06-03 15:02:41.744665 EDT | AverageAbsQYDiff            0.00239065
2017-06-03 15:02:41.744985 EDT | AverageAction               0.174212
2017-06-03 15:02:41.745299 EDT | PolicyRegParamNorm         54.207
2017-06-03 15:02:41.745652 EDT | QFunRegParamNorm           26.177
2017-06-03 15:02:41.745976 EDT | -----------------------  -------------
2017-06-03 15:02:41.746561 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #287 | Training started
2017-06-03 15:02:59.877037 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #287 | Training finished
2017-06-03 15:02:59.877900 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #287 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 15:02:59.878172 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #287 | Collecting samples for evaluation
2017-06-03 15:03:09.747768 EDT | -----------------------  --------------
2017-06-03 15:03:09.748596 EDT | Epoch                     287
2017-06-03 15:03:09.748857 EDT | Iteration                 287
2017-06-03 15:03:09.749093 EDT | AverageReturn            1000
2017-06-03 15:03:09.749326 EDT | StdReturn                   0
2017-06-03 15:03:09.749557 EDT | MaxReturn                1000
2017-06-03 15:03:09.749819 EDT | MinReturn                1000
2017-06-03 15:03:09.750051 EDT | AverageEsReturn            34.9667
2017-06-03 15:03:09.750284 EDT | StdEsReturn                33.4509
2017-06-03 15:03:09.750533 EDT | MaxEsReturn               147
2017-06-03 15:03:09.750760 EDT | MinEsReturn                 5
2017-06-03 15:03:09.750987 EDT | AverageDiscountedReturn    99.9957
2017-06-03 15:03:09.751214 EDT | AverageQLoss                7.90004e-05
2017-06-03 15:03:09.751439 EDT | AveragePolicySurr          -0.140342
2017-06-03 15:03:09.751674 EDT | AverageQ                    0.133346
2017-06-03 15:03:09.751904 EDT | AverageAbsQ                 0.133939
2017-06-03 15:03:09.752130 EDT | AverageY                    0.133346
2017-06-03 15:03:09.752355 EDT | AverageAbsY                 0.133392
2017-06-03 15:03:09.752580 EDT | AverageAbsQYDiff            0.00234653
2017-06-03 15:03:09.752804 EDT | AverageAction               0.126982
2017-06-03 15:03:09.753028 EDT | PolicyRegParamNorm         54.2995
2017-06-03 15:03:09.753263 EDT | QFunRegParamNorm           26.1974
2017-06-03 15:03:09.753491 EDT | -----------------------  --------------
2017-06-03 15:03:09.753852 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #288 | Training started
2017-06-03 15:03:29.069067 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #288 | Training finished
2017-06-03 15:03:29.070199 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #288 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 15:03:29.070495 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #288 | Collecting samples for evaluation
2017-06-03 15:03:38.146345 EDT | -----------------------  --------------
2017-06-03 15:03:38.146924 EDT | Epoch                     288
2017-06-03 15:03:38.147267 EDT | Iteration                 288
2017-06-03 15:03:38.147598 EDT | AverageReturn            1000
2017-06-03 15:03:38.147922 EDT | StdReturn                   0
2017-06-03 15:03:38.148287 EDT | MaxReturn                1000
2017-06-03 15:03:38.148605 EDT | MinReturn                1000
2017-06-03 15:03:38.148923 EDT | AverageEsReturn            28.1714
2017-06-03 15:03:38.149256 EDT | StdEsReturn                23.5693
2017-06-03 15:03:38.149573 EDT | MaxEsReturn               101
2017-06-03 15:03:38.149919 EDT | MinEsReturn                 3
2017-06-03 15:03:38.150232 EDT | AverageDiscountedReturn    99.9957
2017-06-03 15:03:38.150545 EDT | AverageQLoss                6.61746e-05
2017-06-03 15:03:38.150859 EDT | AveragePolicySurr          -0.139407
2017-06-03 15:03:38.151172 EDT | AverageQ                    0.13225
2017-06-03 15:03:38.151592 EDT | AverageAbsQ                 0.132674
2017-06-03 15:03:38.152030 EDT | AverageY                    0.13226
2017-06-03 15:03:38.152543 EDT | AverageAbsY                 0.132298
2017-06-03 15:03:38.153049 EDT | AverageAbsQYDiff            0.00212321
2017-06-03 15:03:38.153555 EDT | AverageAction               0.189976
2017-06-03 15:03:38.154172 EDT | PolicyRegParamNorm         54.3273
2017-06-03 15:03:38.154615 EDT | QFunRegParamNorm           26.1751
2017-06-03 15:03:38.155142 EDT | -----------------------  --------------
2017-06-03 15:03:38.155778 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #289 | Training started
2017-06-03 15:03:56.677179 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #289 | Training finished
2017-06-03 15:03:56.678027 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #289 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 15:03:56.678333 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #289 | Collecting samples for evaluation
2017-06-03 15:04:05.875697 EDT | -----------------------  --------------
2017-06-03 15:04:05.876645 EDT | Epoch                     289
2017-06-03 15:04:05.876971 EDT | Iteration                 289
2017-06-03 15:04:05.877285 EDT | AverageReturn            1000
2017-06-03 15:04:05.877589 EDT | StdReturn                   0
2017-06-03 15:04:05.877942 EDT | MaxReturn                1000
2017-06-03 15:04:05.878221 EDT | MinReturn                1000
2017-06-03 15:04:05.878500 EDT | AverageEsReturn            26
2017-06-03 15:04:05.878820 EDT | StdEsReturn                19.369
2017-06-03 15:04:05.879100 EDT | MaxEsReturn                98
2017-06-03 15:04:05.879333 EDT | MinEsReturn                 3
2017-06-03 15:04:05.879581 EDT | AverageDiscountedReturn    99.9957
2017-06-03 15:04:05.879897 EDT | AverageQLoss                7.73367e-05
2017-06-03 15:04:05.880221 EDT | AveragePolicySurr          -0.138923
2017-06-03 15:04:05.880502 EDT | AverageQ                    0.132179
2017-06-03 15:04:05.880755 EDT | AverageAbsQ                 0.132603
2017-06-03 15:04:05.881046 EDT | AverageY                    0.132167
2017-06-03 15:04:05.881297 EDT | AverageAbsY                 0.132229
2017-06-03 15:04:05.881527 EDT | AverageAbsQYDiff            0.00223013
2017-06-03 15:04:05.881809 EDT | AverageAction               0.0952021
2017-06-03 15:04:05.882070 EDT | PolicyRegParamNorm         54.3877
2017-06-03 15:04:05.882334 EDT | QFunRegParamNorm           26.1863
2017-06-03 15:04:05.882584 EDT | -----------------------  --------------
2017-06-03 15:04:05.882974 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #290 | Training started
2017-06-03 15:04:24.091097 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #290 | Training finished
2017-06-03 15:04:24.093066 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #290 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 15:04:24.093433 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #290 | Collecting samples for evaluation
2017-06-03 15:04:32.798877 EDT | -----------------------  --------------
2017-06-03 15:04:32.799729 EDT | Epoch                     290
2017-06-03 15:04:32.799996 EDT | Iteration                 290
2017-06-03 15:04:32.800245 EDT | AverageReturn            1000
2017-06-03 15:04:32.800492 EDT | StdReturn                   0
2017-06-03 15:04:32.800728 EDT | MaxReturn                1000
2017-06-03 15:04:32.800963 EDT | MinReturn                1000
2017-06-03 15:04:32.801194 EDT | AverageEsReturn            36.7037
2017-06-03 15:04:32.801428 EDT | StdEsReturn                32.8654
2017-06-03 15:04:32.801662 EDT | MaxEsReturn               177
2017-06-03 15:04:32.801906 EDT | MinEsReturn                 6
2017-06-03 15:04:32.802138 EDT | AverageDiscountedReturn    99.9957
2017-06-03 15:04:32.802371 EDT | AverageQLoss                7.60174e-05
2017-06-03 15:04:32.802602 EDT | AveragePolicySurr          -0.138393
2017-06-03 15:04:32.802831 EDT | AverageQ                    0.131302
2017-06-03 15:04:32.803058 EDT | AverageAbsQ                 0.131869
2017-06-03 15:04:32.803284 EDT | AverageY                    0.131318
2017-06-03 15:04:32.803515 EDT | AverageAbsY                 0.131378
2017-06-03 15:04:32.803747 EDT | AverageAbsQYDiff            0.00243782
2017-06-03 15:04:32.803978 EDT | AverageAction               0.196197
2017-06-03 15:04:32.804210 EDT | PolicyRegParamNorm         54.4165
2017-06-03 15:04:32.804442 EDT | QFunRegParamNorm           26.1775
2017-06-03 15:04:32.804673 EDT | -----------------------  --------------
2017-06-03 15:04:32.805043 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #291 | Training started
2017-06-03 15:04:51.312529 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #291 | Training finished
2017-06-03 15:04:51.313477 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #291 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 15:04:51.313860 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #291 | Collecting samples for evaluation
2017-06-03 15:05:00.312127 EDT | -----------------------  --------------
2017-06-03 15:05:00.313115 EDT | Epoch                     291
2017-06-03 15:05:00.313603 EDT | Iteration                 291
2017-06-03 15:05:00.313951 EDT | AverageReturn            1000
2017-06-03 15:05:00.314268 EDT | StdReturn                   0
2017-06-03 15:05:00.314593 EDT | MaxReturn                1000
2017-06-03 15:05:00.314939 EDT | MinReturn                1000
2017-06-03 15:05:00.315293 EDT | AverageEsReturn            29.7941
2017-06-03 15:05:00.315546 EDT | StdEsReturn                17.9931
2017-06-03 15:05:00.315812 EDT | MaxEsReturn                66
2017-06-03 15:05:00.316132 EDT | MinEsReturn                 5
2017-06-03 15:05:00.316449 EDT | AverageDiscountedReturn    99.9957
2017-06-03 15:05:00.316761 EDT | AverageQLoss                7.48902e-05
2017-06-03 15:05:00.317072 EDT | AveragePolicySurr          -0.138056
2017-06-03 15:05:00.317382 EDT | AverageQ                    0.131131
2017-06-03 15:05:00.317689 EDT | AverageAbsQ                 0.131598
2017-06-03 15:05:00.318047 EDT | AverageY                    0.131117
2017-06-03 15:05:00.318385 EDT | AverageAbsY                 0.131164
2017-06-03 15:05:00.318706 EDT | AverageAbsQYDiff            0.00232742
2017-06-03 15:05:00.319048 EDT | AverageAction               0.0264794
2017-06-03 15:05:00.319362 EDT | PolicyRegParamNorm         54.4336
2017-06-03 15:05:00.319685 EDT | QFunRegParamNorm           26.1737
2017-06-03 15:05:00.320000 EDT | -----------------------  --------------
2017-06-03 15:05:00.320476 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #292 | Training started
2017-06-03 15:05:18.567519 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #292 | Training finished
2017-06-03 15:05:18.568409 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #292 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 15:05:18.568762 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #292 | Collecting samples for evaluation
2017-06-03 15:05:27.795134 EDT | -----------------------  --------------
2017-06-03 15:05:27.796153 EDT | Epoch                     292
2017-06-03 15:05:27.796419 EDT | Iteration                 292
2017-06-03 15:05:27.796658 EDT | AverageReturn            1000
2017-06-03 15:05:27.796892 EDT | StdReturn                   0
2017-06-03 15:05:27.797123 EDT | MaxReturn                1000
2017-06-03 15:05:27.797360 EDT | MinReturn                1000
2017-06-03 15:05:27.797592 EDT | AverageEsReturn            30.75
2017-06-03 15:05:27.797834 EDT | StdEsReturn                41.6736
2017-06-03 15:05:27.798063 EDT | MaxEsReturn               225
2017-06-03 15:05:27.798296 EDT | MinEsReturn                 3
2017-06-03 15:05:27.798529 EDT | AverageDiscountedReturn    99.9957
2017-06-03 15:05:27.798756 EDT | AverageQLoss                6.59963e-05
2017-06-03 15:05:27.798987 EDT | AveragePolicySurr          -0.137322
2017-06-03 15:05:27.799214 EDT | AverageQ                    0.130569
2017-06-03 15:05:27.799441 EDT | AverageAbsQ                 0.131016
2017-06-03 15:05:27.799667 EDT | AverageY                    0.130569
2017-06-03 15:05:27.799893 EDT | AverageAbsY                 0.130613
2017-06-03 15:05:27.800120 EDT | AverageAbsQYDiff            0.00216517
2017-06-03 15:05:27.800346 EDT | AverageAction               3.22656e-05
2017-06-03 15:05:27.800571 EDT | PolicyRegParamNorm         54.53
2017-06-03 15:05:27.800797 EDT | QFunRegParamNorm           26.1846
2017-06-03 15:05:27.801034 EDT | -----------------------  --------------
2017-06-03 15:05:27.801389 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #293 | Training started
2017-06-03 15:05:47.154897 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #293 | Training finished
2017-06-03 15:05:47.155970 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #293 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 15:05:47.156242 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #293 | Collecting samples for evaluation
2017-06-03 15:05:58.696920 EDT | -----------------------  --------------
2017-06-03 15:05:58.697880 EDT | Epoch                     293
2017-06-03 15:05:58.698168 EDT | Iteration                 293
2017-06-03 15:05:58.698423 EDT | AverageReturn            1000
2017-06-03 15:05:58.698672 EDT | StdReturn                   0
2017-06-03 15:05:58.698937 EDT | MaxReturn                1000
2017-06-03 15:05:58.699184 EDT | MinReturn                1000
2017-06-03 15:05:58.699429 EDT | AverageEsReturn            29.6176
2017-06-03 15:05:58.699675 EDT | StdEsReturn                32.0716
2017-06-03 15:05:58.699919 EDT | MaxEsReturn               143
2017-06-03 15:05:58.700163 EDT | MinEsReturn                 3
2017-06-03 15:05:58.700406 EDT | AverageDiscountedReturn    99.9957
2017-06-03 15:05:58.700649 EDT | AverageQLoss                6.93201e-05
2017-06-03 15:05:58.700925 EDT | AveragePolicySurr          -0.136807
2017-06-03 15:05:58.701185 EDT | AverageQ                    0.130064
2017-06-03 15:05:58.701441 EDT | AverageAbsQ                 0.130568
2017-06-03 15:05:58.701703 EDT | AverageY                    0.130066
2017-06-03 15:05:58.701970 EDT | AverageAbsY                 0.130107
2017-06-03 15:05:58.702235 EDT | AverageAbsQYDiff            0.00231754
2017-06-03 15:05:58.702492 EDT | AverageAction               2.84192e-05
2017-06-03 15:05:58.702743 EDT | PolicyRegParamNorm         54.6167
2017-06-03 15:05:58.702991 EDT | QFunRegParamNorm           26.2026
2017-06-03 15:05:58.703241 EDT | -----------------------  --------------
2017-06-03 15:05:58.703663 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #294 | Training started
2017-06-03 15:06:17.077349 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #294 | Training finished
2017-06-03 15:06:17.081983 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #294 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 15:06:17.082305 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #294 | Collecting samples for evaluation
2017-06-03 15:06:27.159620 EDT | -----------------------  --------------
2017-06-03 15:06:27.160455 EDT | Epoch                     294
2017-06-03 15:06:27.160714 EDT | Iteration                 294
2017-06-03 15:06:27.160957 EDT | AverageReturn            1000
2017-06-03 15:06:27.161194 EDT | StdReturn                   0
2017-06-03 15:06:27.161428 EDT | MaxReturn                1000
2017-06-03 15:06:27.161663 EDT | MinReturn                1000
2017-06-03 15:06:27.161925 EDT | AverageEsReturn            32.4839
2017-06-03 15:06:27.162175 EDT | StdEsReturn                21.5794
2017-06-03 15:06:27.162417 EDT | MaxEsReturn                85
2017-06-03 15:06:27.162659 EDT | MinEsReturn                 4
2017-06-03 15:06:27.162902 EDT | AverageDiscountedReturn    99.9957
2017-06-03 15:06:27.163158 EDT | AverageQLoss                7.98991e-05
2017-06-03 15:06:27.163403 EDT | AveragePolicySurr          -0.136754
2017-06-03 15:06:27.163694 EDT | AverageQ                    0.129741
2017-06-03 15:06:27.163941 EDT | AverageAbsQ                 0.130165
2017-06-03 15:06:27.164181 EDT | AverageY                    0.129722
2017-06-03 15:06:27.164420 EDT | AverageAbsY                 0.129754
2017-06-03 15:06:27.164659 EDT | AverageAbsQYDiff            0.00241192
2017-06-03 15:06:27.164912 EDT | AverageAction               9.0836e-06
2017-06-03 15:06:27.165152 EDT | PolicyRegParamNorm         54.62
2017-06-03 15:06:27.165393 EDT | QFunRegParamNorm           26.2038
2017-06-03 15:06:27.165633 EDT | -----------------------  --------------
2017-06-03 15:06:27.166006 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #295 | Training started
2017-06-03 15:06:45.593600 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #295 | Training finished
2017-06-03 15:06:45.594555 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #295 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 15:06:45.595089 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #295 | Collecting samples for evaluation
2017-06-03 15:06:55.374609 EDT | -----------------------  --------------
2017-06-03 15:06:55.375613 EDT | Epoch                     295
2017-06-03 15:06:55.376023 EDT | Iteration                 295
2017-06-03 15:06:55.376378 EDT | AverageReturn            1000
2017-06-03 15:06:55.376760 EDT | StdReturn                   0
2017-06-03 15:06:55.377154 EDT | MaxReturn                1000
2017-06-03 15:06:55.377518 EDT | MinReturn                1000
2017-06-03 15:06:55.377803 EDT | AverageEsReturn            31.7812
2017-06-03 15:06:55.378057 EDT | StdEsReturn                22.5385
2017-06-03 15:06:55.378306 EDT | MaxEsReturn                96
2017-06-03 15:06:55.378559 EDT | MinEsReturn                 3
2017-06-03 15:06:55.378807 EDT | AverageDiscountedReturn    99.9957
2017-06-03 15:06:55.379066 EDT | AverageQLoss                6.95241e-05
2017-06-03 15:06:55.379310 EDT | AveragePolicySurr          -0.135607
2017-06-03 15:06:55.379555 EDT | AverageQ                    0.128809
2017-06-03 15:06:55.379803 EDT | AverageAbsQ                 0.129307
2017-06-03 15:06:55.380048 EDT | AverageY                    0.128821
2017-06-03 15:06:55.380306 EDT | AverageAbsY                 0.128859
2017-06-03 15:06:55.380554 EDT | AverageAbsQYDiff            0.00225729
2017-06-03 15:06:55.380798 EDT | AverageAction               0.119292
2017-06-03 15:06:55.381042 EDT | PolicyRegParamNorm         54.6812
2017-06-03 15:06:55.381283 EDT | QFunRegParamNorm           26.1909
2017-06-03 15:06:55.381539 EDT | -----------------------  --------------
2017-06-03 15:06:55.382058 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #296 | Training started
2017-06-03 15:07:13.629984 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #296 | Training finished
2017-06-03 15:07:13.630894 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #296 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 15:07:13.631246 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #296 | Collecting samples for evaluation
2017-06-03 15:07:23.125197 EDT | -----------------------  --------------
2017-06-03 15:07:23.125761 EDT | Epoch                     296
2017-06-03 15:07:23.126084 EDT | Iteration                 296
2017-06-03 15:07:23.126329 EDT | AverageReturn            1000
2017-06-03 15:07:23.126566 EDT | StdReturn                   0
2017-06-03 15:07:23.126811 EDT | MaxReturn                1000
2017-06-03 15:07:23.127053 EDT | MinReturn                1000
2017-06-03 15:07:23.127286 EDT | AverageEsReturn            24.2683
2017-06-03 15:07:23.127524 EDT | StdEsReturn                16.0107
2017-06-03 15:07:23.127753 EDT | MaxEsReturn                62
2017-06-03 15:07:23.127981 EDT | MinEsReturn                 3
2017-06-03 15:07:23.128208 EDT | AverageDiscountedReturn    99.9957
2017-06-03 15:07:23.128436 EDT | AverageQLoss                6.65343e-05
2017-06-03 15:07:23.128664 EDT | AveragePolicySurr          -0.135207
2017-06-03 15:07:23.128893 EDT | AverageQ                    0.128595
2017-06-03 15:07:23.129120 EDT | AverageAbsQ                 0.129004
2017-06-03 15:07:23.129348 EDT | AverageY                    0.128604
2017-06-03 15:07:23.129575 EDT | AverageAbsY                 0.128636
2017-06-03 15:07:23.129814 EDT | AverageAbsQYDiff            0.00211151
2017-06-03 15:07:23.130043 EDT | AverageAction               0.169793
2017-06-03 15:07:23.130271 EDT | PolicyRegParamNorm         54.739
2017-06-03 15:07:23.130497 EDT | QFunRegParamNorm           26.1728
2017-06-03 15:07:23.130725 EDT | -----------------------  --------------
2017-06-03 15:07:23.131074 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #297 | Training started
2017-06-03 15:07:41.624139 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #297 | Training finished
2017-06-03 15:07:41.627804 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #297 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 15:07:41.628078 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #297 | Collecting samples for evaluation
2017-06-03 15:07:51.313469 EDT | -----------------------  --------------
2017-06-03 15:07:51.313866 EDT | Epoch                     297
2017-06-03 15:07:51.314139 EDT | Iteration                 297
2017-06-03 15:07:51.314410 EDT | AverageReturn            1000
2017-06-03 15:07:51.314696 EDT | StdReturn                   0
2017-06-03 15:07:51.314948 EDT | MaxReturn                1000
2017-06-03 15:07:51.315215 EDT | MinReturn                1000
2017-06-03 15:07:51.315442 EDT | AverageEsReturn            38.7692
2017-06-03 15:07:51.315706 EDT | StdEsReturn                26.4391
2017-06-03 15:07:51.315977 EDT | MaxEsReturn                91
2017-06-03 15:07:51.316202 EDT | MinEsReturn                 3
2017-06-03 15:07:51.316427 EDT | AverageDiscountedReturn    99.9957
2017-06-03 15:07:51.316655 EDT | AverageQLoss                7.24301e-05
2017-06-03 15:07:51.316883 EDT | AveragePolicySurr          -0.134328
2017-06-03 15:07:51.317125 EDT | AverageQ                    0.12806
2017-06-03 15:07:51.317362 EDT | AverageAbsQ                 0.128554
2017-06-03 15:07:51.317632 EDT | AverageY                    0.128052
2017-06-03 15:07:51.317871 EDT | AverageAbsY                 0.128085
2017-06-03 15:07:51.318083 EDT | AverageAbsQYDiff            0.00233248
2017-06-03 15:07:51.318293 EDT | AverageAction               0.0453558
2017-06-03 15:07:51.318504 EDT | PolicyRegParamNorm         54.8122
2017-06-03 15:07:51.318713 EDT | QFunRegParamNorm           26.1905
2017-06-03 15:07:51.318925 EDT | -----------------------  --------------
2017-06-03 15:07:51.319248 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #298 | Training started
2017-06-03 15:08:10.774128 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #298 | Training finished
2017-06-03 15:08:10.775119 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #298 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 15:08:10.775498 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #298 | Collecting samples for evaluation
2017-06-03 15:08:22.371020 EDT | -----------------------  --------------
2017-06-03 15:08:22.371410 EDT | Epoch                     298
2017-06-03 15:08:22.371683 EDT | Iteration                 298
2017-06-03 15:08:22.371950 EDT | AverageReturn            1000
2017-06-03 15:08:22.372221 EDT | StdReturn                   0
2017-06-03 15:08:22.372489 EDT | MaxReturn                1000
2017-06-03 15:08:22.372794 EDT | MinReturn                1000
2017-06-03 15:08:22.373112 EDT | AverageEsReturn            28
2017-06-03 15:08:22.373368 EDT | StdEsReturn                19.7554
2017-06-03 15:08:22.373669 EDT | MaxEsReturn                86
2017-06-03 15:08:22.373951 EDT | MinEsReturn                 4
2017-06-03 15:08:22.374227 EDT | AverageDiscountedReturn    99.9957
2017-06-03 15:08:22.374494 EDT | AverageQLoss                6.89865e-05
2017-06-03 15:08:22.374761 EDT | AveragePolicySurr          -0.133849
2017-06-03 15:08:22.375019 EDT | AverageQ                    0.126939
2017-06-03 15:08:22.375310 EDT | AverageAbsQ                 0.127382
2017-06-03 15:08:22.375568 EDT | AverageY                    0.126939
2017-06-03 15:08:22.375821 EDT | AverageAbsY                 0.126972
2017-06-03 15:08:22.376082 EDT | AverageAbsQYDiff            0.00229539
2017-06-03 15:08:22.376349 EDT | AverageAction               0.122353
2017-06-03 15:08:22.376604 EDT | PolicyRegParamNorm         54.8516
2017-06-03 15:08:22.376859 EDT | QFunRegParamNorm           26.1726
2017-06-03 15:08:22.377115 EDT | -----------------------  --------------
2017-06-03 15:08:22.377550 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #299 | Training started
2017-06-03 15:08:40.775385 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #299 | Training finished
2017-06-03 15:08:40.776352 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #299 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 15:08:40.776886 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #299 | Collecting samples for evaluation
2017-06-03 15:08:50.669684 EDT | -----------------------  --------------
2017-06-03 15:08:50.670540 EDT | Epoch                     299
2017-06-03 15:08:50.670805 EDT | Iteration                 299
2017-06-03 15:08:50.671056 EDT | AverageReturn            1000
2017-06-03 15:08:50.671293 EDT | StdReturn                   0
2017-06-03 15:08:50.671528 EDT | MaxReturn                1000
2017-06-03 15:08:50.671763 EDT | MinReturn                1000
2017-06-03 15:08:50.671997 EDT | AverageEsReturn            29.5455
2017-06-03 15:08:50.672237 EDT | StdEsReturn                33.2967
2017-06-03 15:08:50.672469 EDT | MaxEsReturn               130
2017-06-03 15:08:50.672703 EDT | MinEsReturn                 3
2017-06-03 15:08:50.672936 EDT | AverageDiscountedReturn    99.9957
2017-06-03 15:08:50.673169 EDT | AverageQLoss                7.45178e-05
2017-06-03 15:08:50.673401 EDT | AveragePolicySurr          -0.133517
2017-06-03 15:08:50.673632 EDT | AverageQ                    0.126811
2017-06-03 15:08:50.673880 EDT | AverageAbsQ                 0.127299
2017-06-03 15:08:50.674111 EDT | AverageY                    0.126804
2017-06-03 15:08:50.674342 EDT | AverageAbsY                 0.126837
2017-06-03 15:08:50.674593 EDT | AverageAbsQYDiff            0.00243225
2017-06-03 15:08:50.674826 EDT | AverageAction               0.101837
2017-06-03 15:08:50.675057 EDT | PolicyRegParamNorm         54.8621
2017-06-03 15:08:50.675288 EDT | QFunRegParamNorm           26.1735
2017-06-03 15:08:50.675519 EDT | -----------------------  --------------
2017-06-03 15:08:50.675886 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #300 | Training started
2017-06-03 15:09:09.116789 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #300 | Training finished
2017-06-03 15:09:09.119757 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #300 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 15:09:09.120109 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #300 | Collecting samples for evaluation
2017-06-03 15:09:18.833580 EDT | -----------------------  -------------
2017-06-03 15:09:18.834453 EDT | Epoch                     300
2017-06-03 15:09:18.834718 EDT | Iteration                 300
2017-06-03 15:09:18.834949 EDT | AverageReturn            1000
2017-06-03 15:09:18.835175 EDT | StdReturn                   0
2017-06-03 15:09:18.835407 EDT | MaxReturn                1000
2017-06-03 15:09:18.835634 EDT | MinReturn                1000
2017-06-03 15:09:18.835859 EDT | AverageEsReturn            23.7209
2017-06-03 15:09:18.836086 EDT | StdEsReturn                20.2051
2017-06-03 15:09:18.836304 EDT | MaxEsReturn               107
2017-06-03 15:09:18.836523 EDT | MinEsReturn                 4
2017-06-03 15:09:18.836741 EDT | AverageDiscountedReturn    99.9957
2017-06-03 15:09:18.836962 EDT | AverageQLoss                6.1317e-05
2017-06-03 15:09:18.837181 EDT | AveragePolicySurr          -0.132977
2017-06-03 15:09:18.837401 EDT | AverageQ                    0.12642
2017-06-03 15:09:18.837624 EDT | AverageAbsQ                 0.126786
2017-06-03 15:09:18.837911 EDT | AverageY                    0.126429
2017-06-03 15:09:18.838149 EDT | AverageAbsY                 0.126469
2017-06-03 15:09:18.838399 EDT | AverageAbsQYDiff            0.00205464
2017-06-03 15:09:18.838639 EDT | AverageAction               0.00979508
2017-06-03 15:09:18.838883 EDT | PolicyRegParamNorm         54.8658
2017-06-03 15:09:18.839119 EDT | QFunRegParamNorm           26.1934
2017-06-03 15:09:18.839355 EDT | -----------------------  -------------
2017-06-03 15:09:18.839749 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #301 | Training started
2017-06-03 15:09:38.258498 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #301 | Training finished
2017-06-03 15:09:38.259343 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #301 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 15:09:38.259607 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #301 | Collecting samples for evaluation
2017-06-03 15:09:47.625754 EDT | -----------------------  --------------
2017-06-03 15:09:47.626602 EDT | Epoch                     301
2017-06-03 15:09:47.626855 EDT | Iteration                 301
2017-06-03 15:09:47.627097 EDT | AverageReturn            1000
2017-06-03 15:09:47.627327 EDT | StdReturn                   0
2017-06-03 15:09:47.627556 EDT | MaxReturn                1000
2017-06-03 15:09:47.627784 EDT | MinReturn                1000
2017-06-03 15:09:47.628018 EDT | AverageEsReturn            22.4
2017-06-03 15:09:47.628257 EDT | StdEsReturn                19.5237
2017-06-03 15:09:47.628485 EDT | MaxEsReturn                92
2017-06-03 15:09:47.628910 EDT | MinEsReturn                 3
2017-06-03 15:09:47.629143 EDT | AverageDiscountedReturn    99.9957
2017-06-03 15:09:47.629372 EDT | AverageQLoss                6.40454e-05
2017-06-03 15:09:47.629600 EDT | AveragePolicySurr          -0.132738
2017-06-03 15:09:47.629837 EDT | AverageQ                    0.126673
2017-06-03 15:09:47.630064 EDT | AverageAbsQ                 0.127063
2017-06-03 15:09:47.630289 EDT | AverageY                    0.126667
2017-06-03 15:09:47.630514 EDT | AverageAbsY                 0.126681
2017-06-03 15:09:47.630740 EDT | AverageAbsQYDiff            0.00212971
2017-06-03 15:09:47.630966 EDT | AverageAction               0.0165635
2017-06-03 15:09:47.631191 EDT | PolicyRegParamNorm         54.8615
2017-06-03 15:09:47.631416 EDT | QFunRegParamNorm           26.1899
2017-06-03 15:09:47.631641 EDT | -----------------------  --------------
2017-06-03 15:09:47.631983 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #302 | Training started
2017-06-03 15:10:07.168631 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #302 | Training finished
2017-06-03 15:10:07.170176 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #302 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 15:10:07.170540 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #302 | Collecting samples for evaluation
2017-06-03 15:10:16.784550 EDT | -----------------------  --------------
2017-06-03 15:10:16.785457 EDT | Epoch                     302
2017-06-03 15:10:16.785742 EDT | Iteration                 302
2017-06-03 15:10:16.785987 EDT | AverageReturn            1000
2017-06-03 15:10:16.786224 EDT | StdReturn                   0
2017-06-03 15:10:16.786459 EDT | MaxReturn                1000
2017-06-03 15:10:16.786692 EDT | MinReturn                1000
2017-06-03 15:10:16.786949 EDT | AverageEsReturn            22.5227
2017-06-03 15:10:16.787194 EDT | StdEsReturn                17.0087
2017-06-03 15:10:16.787429 EDT | MaxEsReturn                90
2017-06-03 15:10:16.787662 EDT | MinEsReturn                 3
2017-06-03 15:10:16.787893 EDT | AverageDiscountedReturn    99.9957
2017-06-03 15:10:16.788124 EDT | AverageQLoss                6.90345e-05
2017-06-03 15:10:16.788366 EDT | AveragePolicySurr          -0.131966
2017-06-03 15:10:16.788606 EDT | AverageQ                    0.125389
2017-06-03 15:10:16.788847 EDT | AverageAbsQ                 0.125872
2017-06-03 15:10:16.789080 EDT | AverageY                    0.12539
2017-06-03 15:10:16.789332 EDT | AverageAbsY                 0.125421
2017-06-03 15:10:16.789566 EDT | AverageAbsQYDiff            0.00229025
2017-06-03 15:10:16.789812 EDT | AverageAction               0.0398989
2017-06-03 15:10:16.790046 EDT | PolicyRegParamNorm         54.8587
2017-06-03 15:10:16.790291 EDT | QFunRegParamNorm           26.1868
2017-06-03 15:10:16.790533 EDT | -----------------------  --------------
2017-06-03 15:10:16.790941 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #303 | Training started
2017-06-03 15:10:34.949354 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #303 | Training finished
2017-06-03 15:10:34.950270 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #303 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 15:10:34.950621 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #303 | Collecting samples for evaluation
2017-06-03 15:10:44.470618 EDT | -----------------------  --------------
2017-06-03 15:10:44.471495 EDT | Epoch                     303
2017-06-03 15:10:44.471766 EDT | Iteration                 303
2017-06-03 15:10:44.472140 EDT | AverageReturn             654
2017-06-03 15:10:44.472479 EDT | StdReturn                 446.687
2017-06-03 15:10:44.472801 EDT | MaxReturn                1000
2017-06-03 15:10:44.473120 EDT | MinReturn                  74
2017-06-03 15:10:44.473437 EDT | AverageEsReturn            24.5122
2017-06-03 15:10:44.473765 EDT | StdEsReturn                17.1139
2017-06-03 15:10:44.474087 EDT | MaxEsReturn                78
2017-06-03 15:10:44.474403 EDT | MinEsReturn                 4
2017-06-03 15:10:44.474718 EDT | AverageDiscountedReturn    82.7539
2017-06-03 15:10:44.475047 EDT | AverageQLoss                7.17484e-05
2017-06-03 15:10:44.475365 EDT | AveragePolicySurr          -0.131737
2017-06-03 15:10:44.475680 EDT | AverageQ                    0.125246
2017-06-03 15:10:44.476004 EDT | AverageAbsQ                 0.125729
2017-06-03 15:10:44.476321 EDT | AverageY                    0.125244
2017-06-03 15:10:44.476631 EDT | AverageAbsY                 0.12528
2017-06-03 15:10:44.476941 EDT | AverageAbsQYDiff            0.00230342
2017-06-03 15:10:44.477254 EDT | AverageAction               0.143374
2017-06-03 15:10:44.477563 EDT | PolicyRegParamNorm         54.8552
2017-06-03 15:10:44.477883 EDT | QFunRegParamNorm           26.1759
2017-06-03 15:10:44.478194 EDT | -----------------------  --------------
2017-06-03 15:10:44.478648 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #304 | Training started
2017-06-03 15:11:03.698578 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #304 | Training finished
2017-06-03 15:11:03.699565 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #304 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 15:11:03.699840 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #304 | Collecting samples for evaluation
2017-06-03 15:11:14.018863 EDT | -----------------------  --------------
2017-06-03 15:11:14.019776 EDT | Epoch                     304
2017-06-03 15:11:14.020043 EDT | Iteration                 304
2017-06-03 15:11:14.020277 EDT | AverageReturn            1000
2017-06-03 15:11:14.020505 EDT | StdReturn                   0
2017-06-03 15:11:14.020732 EDT | MaxReturn                1000
2017-06-03 15:11:14.020967 EDT | MinReturn                1000
2017-06-03 15:11:14.021191 EDT | AverageEsReturn            20.12
2017-06-03 15:11:14.021423 EDT | StdEsReturn                13.4218
2017-06-03 15:11:14.021650 EDT | MaxEsReturn                51
2017-06-03 15:11:14.021895 EDT | MinEsReturn                 3
2017-06-03 15:11:14.022123 EDT | AverageDiscountedReturn    99.9957
2017-06-03 15:11:14.022347 EDT | AverageQLoss                6.16786e-05
2017-06-03 15:11:14.022572 EDT | AveragePolicySurr          -0.131144
2017-06-03 15:11:14.022795 EDT | AverageQ                    0.12455
2017-06-03 15:11:14.023042 EDT | AverageAbsQ                 0.124928
2017-06-03 15:11:14.023285 EDT | AverageY                    0.124552
2017-06-03 15:11:14.023545 EDT | AverageAbsY                 0.124594
2017-06-03 15:11:14.023771 EDT | AverageAbsQYDiff            0.0019948
2017-06-03 15:11:14.023997 EDT | AverageAction               0.0708894
2017-06-03 15:11:14.024219 EDT | PolicyRegParamNorm         54.8558
2017-06-03 15:11:14.024440 EDT | QFunRegParamNorm           26.1879
2017-06-03 15:11:14.024672 EDT | -----------------------  --------------
2017-06-03 15:11:14.025062 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #305 | Training started
2017-06-03 15:11:32.592908 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #305 | Training finished
2017-06-03 15:11:32.593769 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #305 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 15:11:32.594056 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #305 | Collecting samples for evaluation
2017-06-03 15:11:41.537178 EDT | -----------------------  --------------
2017-06-03 15:11:41.538029 EDT | Epoch                     305
2017-06-03 15:11:41.538331 EDT | Iteration                 305
2017-06-03 15:11:41.538649 EDT | AverageReturn            1000
2017-06-03 15:11:41.538998 EDT | StdReturn                   0
2017-06-03 15:11:41.539269 EDT | MaxReturn                1000
2017-06-03 15:11:41.539606 EDT | MinReturn                1000
2017-06-03 15:11:41.539955 EDT | AverageEsReturn            18.2593
2017-06-03 15:11:41.540235 EDT | StdEsReturn                20.7152
2017-06-03 15:11:41.540509 EDT | MaxEsReturn               127
2017-06-03 15:11:41.540861 EDT | MinEsReturn                 2
2017-06-03 15:11:41.541169 EDT | AverageDiscountedReturn    99.9957
2017-06-03 15:11:41.541422 EDT | AverageQLoss                5.99862e-05
2017-06-03 15:11:41.541766 EDT | AveragePolicySurr          -0.130697
2017-06-03 15:11:41.542097 EDT | AverageQ                    0.124359
2017-06-03 15:11:41.542353 EDT | AverageAbsQ                 0.124741
2017-06-03 15:11:41.542677 EDT | AverageY                    0.124353
2017-06-03 15:11:41.543021 EDT | AverageAbsY                 0.124387
2017-06-03 15:11:41.543283 EDT | AverageAbsQYDiff            0.00203649
2017-06-03 15:11:41.543585 EDT | AverageAction               0.138117
2017-06-03 15:11:41.543925 EDT | PolicyRegParamNorm         54.918
2017-06-03 15:11:41.544200 EDT | QFunRegParamNorm           26.2042
2017-06-03 15:11:41.544481 EDT | -----------------------  --------------
2017-06-03 15:11:41.544958 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #306 | Training started
2017-06-03 15:12:00.100278 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #306 | Training finished
2017-06-03 15:12:00.101191 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #306 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 15:12:00.101540 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #306 | Collecting samples for evaluation
2017-06-03 15:12:10.663734 EDT | -----------------------  -------------
2017-06-03 15:12:10.664098 EDT | Epoch                     306
2017-06-03 15:12:10.664368 EDT | Iteration                 306
2017-06-03 15:12:10.664620 EDT | AverageReturn             920.545
2017-06-03 15:12:10.664869 EDT | StdReturn                 251.257
2017-06-03 15:12:10.665117 EDT | MaxReturn                1000
2017-06-03 15:12:10.665367 EDT | MinReturn                 126
2017-06-03 15:12:10.665614 EDT | AverageEsReturn            22.5333
2017-06-03 15:12:10.665874 EDT | StdEsReturn                17.107
2017-06-03 15:12:10.666118 EDT | MaxEsReturn                62
2017-06-03 15:12:10.666367 EDT | MinEsReturn                 3
2017-06-03 15:12:10.666610 EDT | AverageDiscountedReturn    97.4337
2017-06-03 15:12:10.666858 EDT | AverageQLoss                7.227e-05
2017-06-03 15:12:10.667100 EDT | AveragePolicySurr          -0.130399
2017-06-03 15:12:10.667343 EDT | AverageQ                    0.123964
2017-06-03 15:12:10.667585 EDT | AverageAbsQ                 0.124453
2017-06-03 15:12:10.667828 EDT | AverageY                    0.123971
2017-06-03 15:12:10.668070 EDT | AverageAbsY                 0.124005
2017-06-03 15:12:10.668312 EDT | AverageAbsQYDiff            0.00230083
2017-06-03 15:12:10.668554 EDT | AverageAction               0.27435
2017-06-03 15:12:10.668794 EDT | PolicyRegParamNorm         54.9187
2017-06-03 15:12:10.669038 EDT | QFunRegParamNorm           26.2159
2017-06-03 15:12:10.669280 EDT | -----------------------  -------------
2017-06-03 15:12:10.669637 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #307 | Training started
2017-06-03 15:12:29.583752 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #307 | Training finished
2017-06-03 15:12:29.584706 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #307 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 15:12:29.585061 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #307 | Collecting samples for evaluation
2017-06-03 15:12:39.457181 EDT | -----------------------  --------------
2017-06-03 15:12:39.457674 EDT | Epoch                     307
2017-06-03 15:12:39.457934 EDT | Iteration                 307
2017-06-03 15:12:39.458170 EDT | AverageReturn            1000
2017-06-03 15:12:39.458406 EDT | StdReturn                   0
2017-06-03 15:12:39.458660 EDT | MaxReturn                1000
2017-06-03 15:12:39.458922 EDT | MinReturn                1000
2017-06-03 15:12:39.459187 EDT | AverageEsReturn            21.4348
2017-06-03 15:12:39.459448 EDT | StdEsReturn                19.726
2017-06-03 15:12:39.459681 EDT | MaxEsReturn               102
2017-06-03 15:12:39.459914 EDT | MinEsReturn                 2
2017-06-03 15:12:39.460148 EDT | AverageDiscountedReturn    99.9957
2017-06-03 15:12:39.460377 EDT | AverageQLoss                6.57085e-05
2017-06-03 15:12:39.460615 EDT | AveragePolicySurr          -0.129646
2017-06-03 15:12:39.460843 EDT | AverageQ                    0.123381
2017-06-03 15:12:39.461072 EDT | AverageAbsQ                 0.123776
2017-06-03 15:12:39.461300 EDT | AverageY                    0.123375
2017-06-03 15:12:39.461528 EDT | AverageAbsY                 0.123412
2017-06-03 15:12:39.461770 EDT | AverageAbsQYDiff            0.00213155
2017-06-03 15:12:39.462000 EDT | AverageAction               0.188326
2017-06-03 15:12:39.462228 EDT | PolicyRegParamNorm         54.9394
2017-06-03 15:12:39.462462 EDT | QFunRegParamNorm           26.2216
2017-06-03 15:12:39.462693 EDT | -----------------------  --------------
2017-06-03 15:12:39.463071 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #308 | Training started
2017-06-03 15:12:57.502463 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #308 | Training finished
2017-06-03 15:12:57.506029 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #308 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 15:12:57.506323 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #308 | Collecting samples for evaluation
2017-06-03 15:13:06.797912 EDT | -----------------------  --------------
2017-06-03 15:13:06.798769 EDT | Epoch                     308
2017-06-03 15:13:06.799038 EDT | Iteration                 308
2017-06-03 15:13:06.799288 EDT | AverageReturn            1000
2017-06-03 15:13:06.799530 EDT | StdReturn                   0
2017-06-03 15:13:06.799768 EDT | MaxReturn                1000
2017-06-03 15:13:06.800006 EDT | MinReturn                1000
2017-06-03 15:13:06.800236 EDT | AverageEsReturn            21.913
2017-06-03 15:13:06.800470 EDT | StdEsReturn                14.3948
2017-06-03 15:13:06.800713 EDT | MaxEsReturn                55
2017-06-03 15:13:06.800942 EDT | MinEsReturn                 3
2017-06-03 15:13:06.801172 EDT | AverageDiscountedReturn    99.9957
2017-06-03 15:13:06.801407 EDT | AverageQLoss                5.67349e-05
2017-06-03 15:13:06.801642 EDT | AveragePolicySurr          -0.128996
2017-06-03 15:13:06.801888 EDT | AverageQ                    0.122669
2017-06-03 15:13:06.802122 EDT | AverageAbsQ                 0.123114
2017-06-03 15:13:06.802356 EDT | AverageY                    0.122671
2017-06-03 15:13:06.802588 EDT | AverageAbsY                 0.122721
2017-06-03 15:13:06.802817 EDT | AverageAbsQYDiff            0.00201751
2017-06-03 15:13:06.803052 EDT | AverageAction               0.326273
2017-06-03 15:13:06.803284 EDT | PolicyRegParamNorm         54.9698
2017-06-03 15:13:06.803515 EDT | QFunRegParamNorm           26.2349
2017-06-03 15:13:06.803743 EDT | -----------------------  --------------
2017-06-03 15:13:06.804097 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #309 | Training started
2017-06-03 15:13:25.647299 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #309 | Training finished
2017-06-03 15:13:25.648207 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #309 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 15:13:25.648479 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #309 | Collecting samples for evaluation
2017-06-03 15:13:34.889974 EDT | -----------------------  --------------
2017-06-03 15:13:34.890818 EDT | Epoch                     309
2017-06-03 15:13:34.891076 EDT | Iteration                 309
2017-06-03 15:13:34.891315 EDT | AverageReturn            1000
2017-06-03 15:13:34.891574 EDT | StdReturn                   0
2017-06-03 15:13:34.891813 EDT | MaxReturn                1000
2017-06-03 15:13:34.892046 EDT | MinReturn                1000
2017-06-03 15:13:34.892275 EDT | AverageEsReturn            26.5946
2017-06-03 15:13:34.892507 EDT | StdEsReturn                21.3661
2017-06-03 15:13:34.892752 EDT | MaxEsReturn                89
2017-06-03 15:13:34.893017 EDT | MinEsReturn                 3
2017-06-03 15:13:34.893259 EDT | AverageDiscountedReturn    99.9957
2017-06-03 15:13:34.893492 EDT | AverageQLoss                6.55181e-05
2017-06-03 15:13:34.893733 EDT | AveragePolicySurr          -0.12873
2017-06-03 15:13:34.893970 EDT | AverageQ                    0.122265
2017-06-03 15:13:34.894208 EDT | AverageAbsQ                 0.122762
2017-06-03 15:13:34.894458 EDT | AverageY                    0.122267
2017-06-03 15:13:34.894688 EDT | AverageAbsY                 0.12231
2017-06-03 15:13:34.894920 EDT | AverageAbsQYDiff            0.00229251
2017-06-03 15:13:34.895152 EDT | AverageAction               0.131785
2017-06-03 15:13:34.895390 EDT | PolicyRegParamNorm         55.0207
2017-06-03 15:13:34.895634 EDT | QFunRegParamNorm           26.2218
2017-06-03 15:13:34.895869 EDT | -----------------------  --------------
2017-06-03 15:13:34.896252 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #310 | Training started
2017-06-03 15:13:53.085564 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #310 | Training finished
2017-06-03 15:13:53.086438 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #310 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 15:13:53.086708 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #310 | Collecting samples for evaluation
2017-06-03 15:14:02.215153 EDT | -----------------------  --------------
2017-06-03 15:14:02.216022 EDT | Epoch                     310
2017-06-03 15:14:02.216286 EDT | Iteration                 310
2017-06-03 15:14:02.216522 EDT | AverageReturn            1000
2017-06-03 15:14:02.216757 EDT | StdReturn                   0
2017-06-03 15:14:02.216984 EDT | MaxReturn                1000
2017-06-03 15:14:02.217274 EDT | MinReturn                1000
2017-06-03 15:14:02.217520 EDT | AverageEsReturn            20.38
2017-06-03 15:14:02.217763 EDT | StdEsReturn                15.4659
2017-06-03 15:14:02.217993 EDT | MaxEsReturn                75
2017-06-03 15:14:02.218220 EDT | MinEsReturn                 3
2017-06-03 15:14:02.218457 EDT | AverageDiscountedReturn    99.9957
2017-06-03 15:14:02.218688 EDT | AverageQLoss                5.86834e-05
2017-06-03 15:14:02.218913 EDT | AveragePolicySurr          -0.128227
2017-06-03 15:14:02.219137 EDT | AverageQ                    0.121662
2017-06-03 15:14:02.219361 EDT | AverageAbsQ                 0.122019
2017-06-03 15:14:02.219585 EDT | AverageY                    0.121656
2017-06-03 15:14:02.219809 EDT | AverageAbsY                 0.121698
2017-06-03 15:14:02.220034 EDT | AverageAbsQYDiff            0.00202907
2017-06-03 15:14:02.220257 EDT | AverageAction               0.0187555
2017-06-03 15:14:02.220484 EDT | PolicyRegParamNorm         55.0507
2017-06-03 15:14:02.220709 EDT | QFunRegParamNorm           26.2329
2017-06-03 15:14:02.220956 EDT | -----------------------  --------------
2017-06-03 15:14:02.221308 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #311 | Training started
2017-06-03 15:14:21.332307 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #311 | Training finished
2017-06-03 15:14:21.333303 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #311 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 15:14:21.333690 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #311 | Collecting samples for evaluation
2017-06-03 15:14:32.289324 EDT | -----------------------  --------------
2017-06-03 15:14:32.290178 EDT | Epoch                     311
2017-06-03 15:14:32.290446 EDT | Iteration                 311
2017-06-03 15:14:32.290696 EDT | AverageReturn            1000
2017-06-03 15:14:32.290935 EDT | StdReturn                   0
2017-06-03 15:14:32.291170 EDT | MaxReturn                1000
2017-06-03 15:14:32.291403 EDT | MinReturn                1000
2017-06-03 15:14:32.291637 EDT | AverageEsReturn            30.3636
2017-06-03 15:14:32.291907 EDT | StdEsReturn                24.7164
2017-06-03 15:14:32.292139 EDT | MaxEsReturn               130
2017-06-03 15:14:32.292370 EDT | MinEsReturn                 5
2017-06-03 15:14:32.292602 EDT | AverageDiscountedReturn    99.9957
2017-06-03 15:14:32.292842 EDT | AverageQLoss                6.87309e-05
2017-06-03 15:14:32.293091 EDT | AveragePolicySurr          -0.127714
2017-06-03 15:14:32.293327 EDT | AverageQ                    0.121563
2017-06-03 15:14:32.293558 EDT | AverageAbsQ                 0.122027
2017-06-03 15:14:32.293811 EDT | AverageY                    0.12156
2017-06-03 15:14:32.294046 EDT | AverageAbsY                 0.121592
2017-06-03 15:14:32.294278 EDT | AverageAbsQYDiff            0.00225431
2017-06-03 15:14:32.294510 EDT | AverageAction               0.0085304
2017-06-03 15:14:32.294761 EDT | PolicyRegParamNorm         55.0679
2017-06-03 15:14:32.294995 EDT | QFunRegParamNorm           26.2436
2017-06-03 15:14:32.295227 EDT | -----------------------  --------------
2017-06-03 15:14:32.295625 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #312 | Training started
2017-06-03 15:14:53.145640 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #312 | Training finished
2017-06-03 15:14:53.146502 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #312 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 15:14:53.146904 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #312 | Collecting samples for evaluation
2017-06-03 15:15:02.464911 EDT | -----------------------  --------------
2017-06-03 15:15:02.465938 EDT | Epoch                     312
2017-06-03 15:15:02.466268 EDT | Iteration                 312
2017-06-03 15:15:02.466574 EDT | AverageReturn            1000
2017-06-03 15:15:02.466957 EDT | StdReturn                   0
2017-06-03 15:15:02.467278 EDT | MaxReturn                1000
2017-06-03 15:15:02.467588 EDT | MinReturn                1000
2017-06-03 15:15:02.467898 EDT | AverageEsReturn            23.1628
2017-06-03 15:15:02.468216 EDT | StdEsReturn                27.021
2017-06-03 15:15:02.468523 EDT | MaxEsReturn               140
2017-06-03 15:15:02.468827 EDT | MinEsReturn                 3
2017-06-03 15:15:02.469130 EDT | AverageDiscountedReturn    99.9957
2017-06-03 15:15:02.469436 EDT | AverageQLoss                6.09563e-05
2017-06-03 15:15:02.469754 EDT | AveragePolicySurr          -0.127284
2017-06-03 15:15:02.470064 EDT | AverageQ                    0.121292
2017-06-03 15:15:02.470370 EDT | AverageAbsQ                 0.121632
2017-06-03 15:15:02.470690 EDT | AverageY                    0.121294
2017-06-03 15:15:02.470997 EDT | AverageAbsY                 0.121327
2017-06-03 15:15:02.471302 EDT | AverageAbsQYDiff            0.00198342
2017-06-03 15:15:02.471606 EDT | AverageAction               0.00306511
2017-06-03 15:15:02.471920 EDT | PolicyRegParamNorm         55.0872
2017-06-03 15:15:02.472223 EDT | QFunRegParamNorm           26.241
2017-06-03 15:15:02.472528 EDT | -----------------------  --------------
2017-06-03 15:15:02.472969 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #313 | Training started
2017-06-03 15:15:23.176721 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #313 | Training finished
2017-06-03 15:15:23.177811 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #313 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 15:15:23.178225 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #313 | Collecting samples for evaluation
2017-06-03 15:15:32.176855 EDT | -----------------------  --------------
2017-06-03 15:15:32.177732 EDT | Epoch                     313
2017-06-03 15:15:32.178007 EDT | Iteration                 313
2017-06-03 15:15:32.178244 EDT | AverageReturn            1000
2017-06-03 15:15:32.178475 EDT | StdReturn                   0
2017-06-03 15:15:32.178711 EDT | MaxReturn                1000
2017-06-03 15:15:32.178933 EDT | MinReturn                1000
2017-06-03 15:15:32.179165 EDT | AverageEsReturn            21.7778
2017-06-03 15:15:32.179392 EDT | StdEsReturn                18.7366
2017-06-03 15:15:32.179618 EDT | MaxEsReturn                76
2017-06-03 15:15:32.179845 EDT | MinEsReturn                 5
2017-06-03 15:15:32.180070 EDT | AverageDiscountedReturn    99.9957
2017-06-03 15:15:32.180295 EDT | AverageQLoss                5.84136e-05
2017-06-03 15:15:32.180520 EDT | AveragePolicySurr          -0.126894
2017-06-03 15:15:32.180744 EDT | AverageQ                    0.12058
2017-06-03 15:15:32.180975 EDT | AverageAbsQ                 0.120986
2017-06-03 15:15:32.181203 EDT | AverageY                    0.120581
2017-06-03 15:15:32.181427 EDT | AverageAbsY                 0.120595
2017-06-03 15:15:32.181652 EDT | AverageAbsQYDiff            0.00204117
2017-06-03 15:15:32.181899 EDT | AverageAction               1.01289e-05
2017-06-03 15:15:32.182132 EDT | PolicyRegParamNorm         55.1161
2017-06-03 15:15:32.182364 EDT | QFunRegParamNorm           26.2404
2017-06-03 15:15:32.182594 EDT | -----------------------  --------------
2017-06-03 15:15:32.182972 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #314 | Training started
2017-06-03 15:15:51.577155 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #314 | Training finished
2017-06-03 15:15:51.578064 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #314 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 15:15:51.578338 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #314 | Collecting samples for evaluation
2017-06-03 15:16:02.306329 EDT | -----------------------  --------------
2017-06-03 15:16:02.306785 EDT | Epoch                     314
2017-06-03 15:16:02.307051 EDT | Iteration                 314
2017-06-03 15:16:02.307321 EDT | AverageReturn            1000
2017-06-03 15:16:02.307574 EDT | StdReturn                   0
2017-06-03 15:16:02.307824 EDT | MaxReturn                1000
2017-06-03 15:16:02.308069 EDT | MinReturn                1000
2017-06-03 15:16:02.308317 EDT | AverageEsReturn            27.6757
2017-06-03 15:16:02.308561 EDT | StdEsReturn                16.5089
2017-06-03 15:16:02.308827 EDT | MaxEsReturn                62
2017-06-03 15:16:02.309070 EDT | MinEsReturn                 3
2017-06-03 15:16:02.309312 EDT | AverageDiscountedReturn    99.9957
2017-06-03 15:16:02.309554 EDT | AverageQLoss                6.09188e-05
2017-06-03 15:16:02.309834 EDT | AveragePolicySurr          -0.126649
2017-06-03 15:16:02.310079 EDT | AverageQ                    0.120324
2017-06-03 15:16:02.310323 EDT | AverageAbsQ                 0.120743
2017-06-03 15:16:02.310566 EDT | AverageY                    0.120314
2017-06-03 15:16:02.310829 EDT | AverageAbsY                 0.120338
2017-06-03 15:16:02.311072 EDT | AverageAbsQYDiff            0.00216263
2017-06-03 15:16:02.311314 EDT | AverageAction               0.00134074
2017-06-03 15:16:02.311557 EDT | PolicyRegParamNorm         55.1638
2017-06-03 15:16:02.311818 EDT | QFunRegParamNorm           26.2504
2017-06-03 15:16:02.312060 EDT | -----------------------  --------------
2017-06-03 15:16:02.312455 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #315 | Training started
2017-06-03 15:16:19.922405 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #315 | Training finished
2017-06-03 15:16:19.931279 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #315 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 15:16:19.931825 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #315 | Collecting samples for evaluation
2017-06-03 15:16:30.375161 EDT | -----------------------  --------------
2017-06-03 15:16:30.376021 EDT | Epoch                     315
2017-06-03 15:16:30.376294 EDT | Iteration                 315
2017-06-03 15:16:30.376560 EDT | AverageReturn            1000
2017-06-03 15:16:30.376799 EDT | StdReturn                   0
2017-06-03 15:16:30.377035 EDT | MaxReturn                1000
2017-06-03 15:16:30.377271 EDT | MinReturn                1000
2017-06-03 15:16:30.377513 EDT | AverageEsReturn            18.537
2017-06-03 15:16:30.377768 EDT | StdEsReturn                13.0295
2017-06-03 15:16:30.378003 EDT | MaxEsReturn                58
2017-06-03 15:16:30.378248 EDT | MinEsReturn                 3
2017-06-03 15:16:30.378483 EDT | AverageDiscountedReturn    99.9957
2017-06-03 15:16:30.378740 EDT | AverageQLoss                5.84561e-05
2017-06-03 15:16:30.378974 EDT | AveragePolicySurr          -0.12607
2017-06-03 15:16:30.379206 EDT | AverageQ                    0.119977
2017-06-03 15:16:30.379436 EDT | AverageAbsQ                 0.120393
2017-06-03 15:16:30.379667 EDT | AverageY                    0.119982
2017-06-03 15:16:30.379907 EDT | AverageAbsY                 0.120017
2017-06-03 15:16:30.380138 EDT | AverageAbsQYDiff            0.00208401
2017-06-03 15:16:30.380368 EDT | AverageAction               0.00418999
2017-06-03 15:16:30.380599 EDT | PolicyRegParamNorm         55.2203
2017-06-03 15:16:30.380831 EDT | QFunRegParamNorm           26.2406
2017-06-03 15:16:30.381061 EDT | -----------------------  --------------
2017-06-03 15:16:30.381454 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #316 | Training started
2017-06-03 15:16:50.013378 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #316 | Training finished
2017-06-03 15:16:50.014338 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #316 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 15:16:50.014616 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #316 | Collecting samples for evaluation
2017-06-03 15:17:01.115716 EDT | -----------------------  --------------
2017-06-03 15:17:01.116580 EDT | Epoch                     316
2017-06-03 15:17:01.116865 EDT | Iteration                 316
2017-06-03 15:17:01.117106 EDT | AverageReturn             288.229
2017-06-03 15:17:01.117338 EDT | StdReturn                 387.476
2017-06-03 15:17:01.117564 EDT | MaxReturn                1000
2017-06-03 15:17:01.117802 EDT | MinReturn                  71
2017-06-03 15:17:01.118028 EDT | AverageEsReturn            22.3256
2017-06-03 15:17:01.118253 EDT | StdEsReturn                16.1903
2017-06-03 15:17:01.118477 EDT | MaxEsReturn                76
2017-06-03 15:17:01.118701 EDT | MinEsReturn                 2
2017-06-03 15:17:01.118925 EDT | AverageDiscountedReturn    64.4735
2017-06-03 15:17:01.119148 EDT | AverageQLoss                6.96655e-05
2017-06-03 15:17:01.119370 EDT | AveragePolicySurr          -0.125297
2017-06-03 15:17:01.119592 EDT | AverageQ                    0.11897
2017-06-03 15:17:01.119814 EDT | AverageAbsQ                 0.119472
2017-06-03 15:17:01.120036 EDT | AverageY                    0.118971
2017-06-03 15:17:01.120265 EDT | AverageAbsY                 0.118995
2017-06-03 15:17:01.120493 EDT | AverageAbsQYDiff            0.00231049
2017-06-03 15:17:01.120715 EDT | AverageAction               0.166223
2017-06-03 15:17:01.120937 EDT | PolicyRegParamNorm         55.2728
2017-06-03 15:17:01.121158 EDT | QFunRegParamNorm           26.2554
2017-06-03 15:17:01.121379 EDT | -----------------------  --------------
2017-06-03 15:17:01.121755 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #317 | Training started
2017-06-03 15:17:19.543469 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #317 | Training finished
2017-06-03 15:17:19.544370 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #317 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 15:17:19.544621 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #317 | Collecting samples for evaluation
2017-06-03 15:17:29.062521 EDT | -----------------------  --------------
2017-06-03 15:17:29.063562 EDT | Epoch                     317
2017-06-03 15:17:29.063916 EDT | Iteration                 317
2017-06-03 15:17:29.064261 EDT | AverageReturn            1000
2017-06-03 15:17:29.064626 EDT | StdReturn                   0
2017-06-03 15:17:29.064974 EDT | MaxReturn                1000
2017-06-03 15:17:29.065298 EDT | MinReturn                1000
2017-06-03 15:17:29.065649 EDT | AverageEsReturn            32.0645
2017-06-03 15:17:29.065942 EDT | StdEsReturn                25.3007
2017-06-03 15:17:29.066172 EDT | MaxEsReturn               102
2017-06-03 15:17:29.066398 EDT | MinEsReturn                 5
2017-06-03 15:17:29.066621 EDT | AverageDiscountedReturn    99.9957
2017-06-03 15:17:29.066852 EDT | AverageQLoss                5.28947e-05
2017-06-03 15:17:29.067082 EDT | AveragePolicySurr          -0.124911
2017-06-03 15:17:29.067304 EDT | AverageQ                    0.11878
2017-06-03 15:17:29.067525 EDT | AverageAbsQ                 0.11915
2017-06-03 15:17:29.067745 EDT | AverageY                    0.11878
2017-06-03 15:17:29.067965 EDT | AverageAbsY                 0.118807
2017-06-03 15:17:29.068185 EDT | AverageAbsQYDiff            0.00194052
2017-06-03 15:17:29.068406 EDT | AverageAction               0.0679056
2017-06-03 15:17:29.068627 EDT | PolicyRegParamNorm         55.2711
2017-06-03 15:17:29.068847 EDT | QFunRegParamNorm           26.2452
2017-06-03 15:17:29.069067 EDT | -----------------------  --------------
2017-06-03 15:17:29.069431 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #318 | Training started
2017-06-03 15:17:49.665784 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #318 | Training finished
2017-06-03 15:17:49.666697 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #318 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 15:17:49.667097 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #318 | Collecting samples for evaluation
2017-06-03 15:17:59.737708 EDT | -----------------------  --------------
2017-06-03 15:17:59.738535 EDT | Epoch                     318
2017-06-03 15:17:59.738794 EDT | Iteration                 318
2017-06-03 15:17:59.739044 EDT | AverageReturn            1000
2017-06-03 15:17:59.739312 EDT | StdReturn                   0
2017-06-03 15:17:59.739552 EDT | MaxReturn                1000
2017-06-03 15:17:59.739787 EDT | MinReturn                1000
2017-06-03 15:17:59.740021 EDT | AverageEsReturn            21.625
2017-06-03 15:17:59.740255 EDT | StdEsReturn                16.3269
2017-06-03 15:17:59.740496 EDT | MaxEsReturn                67
2017-06-03 15:17:59.740743 EDT | MinEsReturn                 3
2017-06-03 15:17:59.740975 EDT | AverageDiscountedReturn    99.9957
2017-06-03 15:17:59.741204 EDT | AverageQLoss                5.72474e-05
2017-06-03 15:17:59.741440 EDT | AveragePolicySurr          -0.124444
2017-06-03 15:17:59.741672 EDT | AverageQ                    0.118651
2017-06-03 15:17:59.741925 EDT | AverageAbsQ                 0.11904
2017-06-03 15:17:59.742155 EDT | AverageY                    0.118646
2017-06-03 15:17:59.742397 EDT | AverageAbsY                 0.11869
2017-06-03 15:17:59.742656 EDT | AverageAbsQYDiff            0.00198937
2017-06-03 15:17:59.742885 EDT | AverageAction               0.013024
2017-06-03 15:17:59.743113 EDT | PolicyRegParamNorm         55.3191
2017-06-03 15:17:59.743341 EDT | QFunRegParamNorm           26.265
2017-06-03 15:17:59.743577 EDT | -----------------------  --------------
2017-06-03 15:17:59.743947 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #319 | Training started
2017-06-03 15:18:18.522359 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #319 | Training finished
2017-06-03 15:18:18.523260 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #319 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 15:18:18.523542 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #319 | Collecting samples for evaluation
2017-06-03 15:18:27.691825 EDT | -----------------------  --------------
2017-06-03 15:18:27.692837 EDT | Epoch                     319
2017-06-03 15:18:27.693193 EDT | Iteration                 319
2017-06-03 15:18:27.693529 EDT | AverageReturn            1000
2017-06-03 15:18:27.693861 EDT | StdReturn                   0
2017-06-03 15:18:27.694181 EDT | MaxReturn                1000
2017-06-03 15:18:27.694496 EDT | MinReturn                1000
2017-06-03 15:18:27.694813 EDT | AverageEsReturn            29.7419
2017-06-03 15:18:27.695131 EDT | StdEsReturn                20.5457
2017-06-03 15:18:27.695445 EDT | MaxEsReturn               105
2017-06-03 15:18:27.695760 EDT | MinEsReturn                 5
2017-06-03 15:18:27.696072 EDT | AverageDiscountedReturn    99.9957
2017-06-03 15:18:27.696384 EDT | AverageQLoss                5.12794e-05
2017-06-03 15:18:27.696702 EDT | AveragePolicySurr          -0.124342
2017-06-03 15:18:27.697012 EDT | AverageQ                    0.118155
2017-06-03 15:18:27.697322 EDT | AverageAbsQ                 0.118563
2017-06-03 15:18:27.697634 EDT | AverageY                    0.118154
2017-06-03 15:18:27.697956 EDT | AverageAbsY                 0.118208
2017-06-03 15:18:27.698268 EDT | AverageAbsQYDiff            0.00195019
2017-06-03 15:18:27.698576 EDT | AverageAction               0.00588939
2017-06-03 15:18:27.698886 EDT | PolicyRegParamNorm         55.3419
2017-06-03 15:18:27.699195 EDT | QFunRegParamNorm           26.2606
2017-06-03 15:18:27.699507 EDT | -----------------------  --------------
2017-06-03 15:18:27.699988 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #320 | Training started
2017-06-03 15:18:45.427487 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #320 | Training finished
2017-06-03 15:18:45.428351 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #320 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 15:18:45.428618 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #320 | Collecting samples for evaluation
2017-06-03 15:18:55.788289 EDT | -----------------------  --------------
2017-06-03 15:18:55.789422 EDT | Epoch                     320
2017-06-03 15:18:55.789872 EDT | Iteration                 320
2017-06-03 15:18:55.790233 EDT | AverageReturn            1000
2017-06-03 15:18:55.790566 EDT | StdReturn                   0
2017-06-03 15:18:55.790914 EDT | MaxReturn                1000
2017-06-03 15:18:55.791246 EDT | MinReturn                1000
2017-06-03 15:18:55.791587 EDT | AverageEsReturn            27.6154
2017-06-03 15:18:55.791934 EDT | StdEsReturn                24.9138
2017-06-03 15:18:55.792346 EDT | MaxEsReturn               114
2017-06-03 15:18:55.792829 EDT | MinEsReturn                 4
2017-06-03 15:18:55.793226 EDT | AverageDiscountedReturn    99.9957
2017-06-03 15:18:55.793691 EDT | AverageQLoss                6.10014e-05
2017-06-03 15:18:55.794132 EDT | AveragePolicySurr          -0.123865
2017-06-03 15:18:55.794541 EDT | AverageQ                    0.117571
2017-06-03 15:18:55.794953 EDT | AverageAbsQ                 0.118009
2017-06-03 15:18:55.795375 EDT | AverageY                    0.117569
2017-06-03 15:18:55.795783 EDT | AverageAbsY                 0.117614
2017-06-03 15:18:55.796104 EDT | AverageAbsQYDiff            0.00215041
2017-06-03 15:18:55.796418 EDT | AverageAction               0.0134712
2017-06-03 15:18:55.796743 EDT | PolicyRegParamNorm         55.4098
2017-06-03 15:18:55.797145 EDT | QFunRegParamNorm           26.2836
2017-06-03 15:18:55.797514 EDT | -----------------------  --------------
2017-06-03 15:18:55.798029 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #321 | Training started
2017-06-03 15:19:16.169869 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #321 | Training finished
2017-06-03 15:19:16.175341 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #321 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 15:19:16.175943 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #321 | Collecting samples for evaluation
2017-06-03 15:19:27.320070 EDT | -----------------------  --------------
2017-06-03 15:19:27.320930 EDT | Epoch                     321
2017-06-03 15:19:27.321198 EDT | Iteration                 321
2017-06-03 15:19:27.321439 EDT | AverageReturn            1000
2017-06-03 15:19:27.321673 EDT | StdReturn                   0
2017-06-03 15:19:27.321929 EDT | MaxReturn                1000
2017-06-03 15:19:27.322163 EDT | MinReturn                1000
2017-06-03 15:19:27.322396 EDT | AverageEsReturn            31.4194
2017-06-03 15:19:27.322626 EDT | StdEsReturn                19.1173
2017-06-03 15:19:27.322856 EDT | MaxEsReturn                79
2017-06-03 15:19:27.323095 EDT | MinEsReturn                 4
2017-06-03 15:19:27.323332 EDT | AverageDiscountedReturn    99.9957
2017-06-03 15:19:27.323571 EDT | AverageQLoss                6.75189e-05
2017-06-03 15:19:27.323810 EDT | AveragePolicySurr          -0.123263
2017-06-03 15:19:27.324048 EDT | AverageQ                    0.116908
2017-06-03 15:19:27.324286 EDT | AverageAbsQ                 0.117336
2017-06-03 15:19:27.324522 EDT | AverageY                    0.116906
2017-06-03 15:19:27.324778 EDT | AverageAbsY                 0.116965
2017-06-03 15:19:27.325063 EDT | AverageAbsQYDiff            0.00226469
2017-06-03 15:19:27.325291 EDT | AverageAction               0.02567
2017-06-03 15:19:27.325514 EDT | PolicyRegParamNorm         55.5005
2017-06-03 15:19:27.325746 EDT | QFunRegParamNorm           26.2787
2017-06-03 15:19:27.325978 EDT | -----------------------  --------------
2017-06-03 15:19:27.326340 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #322 | Training started
2017-06-03 15:19:46.307862 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #322 | Training finished
2017-06-03 15:19:46.308779 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #322 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 15:19:46.309050 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #322 | Collecting samples for evaluation
2017-06-03 15:19:55.792104 EDT | -----------------------  --------------
2017-06-03 15:19:55.792958 EDT | Epoch                     322
2017-06-03 15:19:55.793346 EDT | Iteration                 322
2017-06-03 15:19:55.793672 EDT | AverageReturn            1000
2017-06-03 15:19:55.794008 EDT | StdReturn                   0
2017-06-03 15:19:55.794324 EDT | MaxReturn                1000
2017-06-03 15:19:55.794650 EDT | MinReturn                1000
2017-06-03 15:19:55.794963 EDT | AverageEsReturn            20.9184
2017-06-03 15:19:55.795277 EDT | StdEsReturn                12.9707
2017-06-03 15:19:55.795590 EDT | MaxEsReturn                56
2017-06-03 15:19:55.795897 EDT | MinEsReturn                 3
2017-06-03 15:19:55.796207 EDT | AverageDiscountedReturn    99.9957
2017-06-03 15:19:55.796515 EDT | AverageQLoss                5.38072e-05
2017-06-03 15:19:55.796827 EDT | AveragePolicySurr          -0.123063
2017-06-03 15:19:55.797137 EDT | AverageQ                    0.116994
2017-06-03 15:19:55.797445 EDT | AverageAbsQ                 0.117322
2017-06-03 15:19:55.797759 EDT | AverageY                    0.117
2017-06-03 15:19:55.798069 EDT | AverageAbsY                 0.117031
2017-06-03 15:19:55.798375 EDT | AverageAbsQYDiff            0.0019228
2017-06-03 15:19:55.798678 EDT | AverageAction               0.018715
2017-06-03 15:19:55.798984 EDT | PolicyRegParamNorm         55.5317
2017-06-03 15:19:55.799289 EDT | QFunRegParamNorm           26.3061
2017-06-03 15:19:55.799600 EDT | -----------------------  --------------
2017-06-03 15:19:55.800227 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #323 | Training started
2017-06-03 15:20:14.582475 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #323 | Training finished
2017-06-03 15:20:14.583367 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #323 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 15:20:14.583638 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #323 | Collecting samples for evaluation
2017-06-03 15:20:24.821210 EDT | -----------------------  --------------
2017-06-03 15:20:24.822050 EDT | Epoch                     323
2017-06-03 15:20:24.822311 EDT | Iteration                 323
2017-06-03 15:20:24.822552 EDT | AverageReturn            1000
2017-06-03 15:20:24.822789 EDT | StdReturn                   0
2017-06-03 15:20:24.823023 EDT | MaxReturn                1000
2017-06-03 15:20:24.823272 EDT | MinReturn                1000
2017-06-03 15:20:24.823560 EDT | AverageEsReturn            21.3404
2017-06-03 15:20:24.823794 EDT | StdEsReturn                16.3372
2017-06-03 15:20:24.824032 EDT | MaxEsReturn                73
2017-06-03 15:20:24.824264 EDT | MinEsReturn                 3
2017-06-03 15:20:24.824499 EDT | AverageDiscountedReturn    99.9957
2017-06-03 15:20:24.824739 EDT | AverageQLoss                5.17785e-05
2017-06-03 15:20:24.824971 EDT | AveragePolicySurr          -0.122787
2017-06-03 15:20:24.825202 EDT | AverageQ                    0.1169
2017-06-03 15:20:24.825435 EDT | AverageAbsQ                 0.117323
2017-06-03 15:20:24.825666 EDT | AverageY                    0.116896
2017-06-03 15:20:24.825914 EDT | AverageAbsY                 0.11692
2017-06-03 15:20:24.826147 EDT | AverageAbsQYDiff            0.00202314
2017-06-03 15:20:24.826379 EDT | AverageAction               0.0284618
2017-06-03 15:20:24.826611 EDT | PolicyRegParamNorm         55.576
2017-06-03 15:20:24.826843 EDT | QFunRegParamNorm           26.2965
2017-06-03 15:20:24.827074 EDT | -----------------------  --------------
2017-06-03 15:20:24.827418 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #324 | Training started
2017-06-03 15:20:43.319716 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #324 | Training finished
2017-06-03 15:20:43.320557 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #324 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 15:20:43.320827 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #324 | Collecting samples for evaluation
2017-06-03 15:20:52.728260 EDT | -----------------------  --------------
2017-06-03 15:20:52.729092 EDT | Epoch                     324
2017-06-03 15:20:52.729368 EDT | Iteration                 324
2017-06-03 15:20:52.729625 EDT | AverageReturn            1000
2017-06-03 15:20:52.729892 EDT | StdReturn                   0
2017-06-03 15:20:52.730148 EDT | MaxReturn                1000
2017-06-03 15:20:52.730397 EDT | MinReturn                1000
2017-06-03 15:20:52.730648 EDT | AverageEsReturn            17.7321
2017-06-03 15:20:52.730899 EDT | StdEsReturn                15.0588
2017-06-03 15:20:52.731149 EDT | MaxEsReturn                89
2017-06-03 15:20:52.731400 EDT | MinEsReturn                 3
2017-06-03 15:20:52.731681 EDT | AverageDiscountedReturn    99.9957
2017-06-03 15:20:52.731917 EDT | AverageQLoss                5.79521e-05
2017-06-03 15:20:52.732156 EDT | AveragePolicySurr          -0.121873
2017-06-03 15:20:52.732388 EDT | AverageQ                    0.115834
2017-06-03 15:20:52.732620 EDT | AverageAbsQ                 0.116209
2017-06-03 15:20:52.732861 EDT | AverageY                    0.115829
2017-06-03 15:20:52.733100 EDT | AverageAbsY                 0.115863
2017-06-03 15:20:52.733344 EDT | AverageAbsQYDiff            0.0020456
2017-06-03 15:20:52.733574 EDT | AverageAction               0.00989342
2017-06-03 15:20:52.733820 EDT | PolicyRegParamNorm         55.6427
2017-06-03 15:20:52.734053 EDT | QFunRegParamNorm           26.3099
2017-06-03 15:20:52.734284 EDT | -----------------------  --------------
2017-06-03 15:20:52.734629 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #325 | Training started
2017-06-03 15:21:11.717158 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #325 | Training finished
2017-06-03 15:21:11.717961 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #325 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 15:21:11.718242 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #325 | Collecting samples for evaluation
2017-06-03 15:21:21.493728 EDT | -----------------------  --------------
2017-06-03 15:21:21.496469 EDT | Epoch                     325
2017-06-03 15:21:21.496733 EDT | Iteration                 325
2017-06-03 15:21:21.496985 EDT | AverageReturn            1000
2017-06-03 15:21:21.497223 EDT | StdReturn                   0
2017-06-03 15:21:21.497511 EDT | MaxReturn                1000
2017-06-03 15:21:21.497759 EDT | MinReturn                1000
2017-06-03 15:21:21.497996 EDT | AverageEsReturn            25.8718
2017-06-03 15:21:21.498231 EDT | StdEsReturn                14.1116
2017-06-03 15:21:21.498468 EDT | MaxEsReturn                63
2017-06-03 15:21:21.498716 EDT | MinEsReturn                 3
2017-06-03 15:21:21.498953 EDT | AverageDiscountedReturn    99.9957
2017-06-03 15:21:21.499185 EDT | AverageQLoss                5.98812e-05
2017-06-03 15:21:21.499416 EDT | AveragePolicySurr          -0.121676
2017-06-03 15:21:21.499647 EDT | AverageQ                    0.115854
2017-06-03 15:21:21.499877 EDT | AverageAbsQ                 0.116279
2017-06-03 15:21:21.500106 EDT | AverageY                    0.11585
2017-06-03 15:21:21.500338 EDT | AverageAbsY                 0.115872
2017-06-03 15:21:21.500568 EDT | AverageAbsQYDiff            0.00218151
2017-06-03 15:21:21.500799 EDT | AverageAction               0.0491464
2017-06-03 15:21:21.501034 EDT | PolicyRegParamNorm         55.6695
2017-06-03 15:21:21.501264 EDT | QFunRegParamNorm           26.3202
2017-06-03 15:21:21.501495 EDT | -----------------------  --------------
2017-06-03 15:21:21.501878 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #326 | Training started
2017-06-03 15:21:39.651258 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #326 | Training finished
2017-06-03 15:21:39.652282 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #326 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 15:21:39.652595 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #326 | Collecting samples for evaluation
2017-06-03 15:21:49.750891 EDT | -----------------------  --------------
2017-06-03 15:21:49.751888 EDT | Epoch                     326
2017-06-03 15:21:49.752235 EDT | Iteration                 326
2017-06-03 15:21:49.752569 EDT | AverageReturn            1000
2017-06-03 15:21:49.752891 EDT | StdReturn                   0
2017-06-03 15:21:49.753210 EDT | MaxReturn                1000
2017-06-03 15:21:49.753535 EDT | MinReturn                1000
2017-06-03 15:21:49.753924 EDT | AverageEsReturn            21.3617
2017-06-03 15:21:49.754248 EDT | StdEsReturn                17.262
2017-06-03 15:21:49.754567 EDT | MaxEsReturn                78
2017-06-03 15:21:49.754881 EDT | MinEsReturn                 3
2017-06-03 15:21:49.755206 EDT | AverageDiscountedReturn    99.9957
2017-06-03 15:21:49.755527 EDT | AverageQLoss                5.51528e-05
2017-06-03 15:21:49.755845 EDT | AveragePolicySurr          -0.121091
2017-06-03 15:21:49.756161 EDT | AverageQ                    0.115439
2017-06-03 15:21:49.756472 EDT | AverageAbsQ                 0.115816
2017-06-03 15:21:49.756783 EDT | AverageY                    0.115441
2017-06-03 15:21:49.757116 EDT | AverageAbsY                 0.11546
2017-06-03 15:21:49.757452 EDT | AverageAbsQYDiff            0.00197869
2017-06-03 15:21:49.757779 EDT | AverageAction               0.0506939
2017-06-03 15:21:49.758096 EDT | PolicyRegParamNorm         55.7359
2017-06-03 15:21:49.758411 EDT | QFunRegParamNorm           26.3164
2017-06-03 15:21:49.758730 EDT | -----------------------  --------------
2017-06-03 15:21:49.759208 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #327 | Training started
2017-06-03 15:22:09.037580 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #327 | Training finished
2017-06-03 15:22:09.038519 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #327 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 15:22:09.038803 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #327 | Collecting samples for evaluation
2017-06-03 15:22:18.422219 EDT | -----------------------  --------------
2017-06-03 15:22:18.423151 EDT | Epoch                     327
2017-06-03 15:22:18.423408 EDT | Iteration                 327
2017-06-03 15:22:18.423631 EDT | AverageReturn            1000
2017-06-03 15:22:18.423851 EDT | StdReturn                   0
2017-06-03 15:22:18.424067 EDT | MaxReturn                1000
2017-06-03 15:22:18.424280 EDT | MinReturn                1000
2017-06-03 15:22:18.424495 EDT | AverageEsReturn            18.4151
2017-06-03 15:22:18.424709 EDT | StdEsReturn                14.4528
2017-06-03 15:22:18.424928 EDT | MaxEsReturn                79
2017-06-03 15:22:18.425180 EDT | MinEsReturn                 3
2017-06-03 15:22:18.425421 EDT | AverageDiscountedReturn    99.9957
2017-06-03 15:22:18.425651 EDT | AverageQLoss                5.12219e-05
2017-06-03 15:22:18.425962 EDT | AveragePolicySurr          -0.120915
2017-06-03 15:22:18.426235 EDT | AverageQ                    0.115263
2017-06-03 15:22:18.426476 EDT | AverageAbsQ                 0.115664
2017-06-03 15:22:18.426714 EDT | AverageY                    0.11527
2017-06-03 15:22:18.426952 EDT | AverageAbsY                 0.115297
2017-06-03 15:22:18.427199 EDT | AverageAbsQYDiff            0.00199429
2017-06-03 15:22:18.427468 EDT | AverageAction               0.0571718
2017-06-03 15:22:18.427743 EDT | PolicyRegParamNorm         55.7937
2017-06-03 15:22:18.427968 EDT | QFunRegParamNorm           26.3126
2017-06-03 15:22:18.428190 EDT | -----------------------  --------------
2017-06-03 15:22:18.428584 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #328 | Training started
2017-06-03 15:22:36.857286 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #328 | Training finished
2017-06-03 15:22:36.858203 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #328 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 15:22:36.858476 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #328 | Collecting samples for evaluation
2017-06-03 15:22:47.484979 EDT | -----------------------  --------------
2017-06-03 15:22:47.486086 EDT | Epoch                     328
2017-06-03 15:22:47.486361 EDT | Iteration                 328
2017-06-03 15:22:47.486606 EDT | AverageReturn            1000
2017-06-03 15:22:47.486929 EDT | StdReturn                   0
2017-06-03 15:22:47.487277 EDT | MaxReturn                1000
2017-06-03 15:22:47.487608 EDT | MinReturn                1000
2017-06-03 15:22:47.487850 EDT | AverageEsReturn            27.1429
2017-06-03 15:22:47.488080 EDT | StdEsReturn                20.4243
2017-06-03 15:22:47.488307 EDT | MaxEsReturn                82
2017-06-03 15:22:47.488534 EDT | MinEsReturn                 6
2017-06-03 15:22:47.488770 EDT | AverageDiscountedReturn    99.9957
2017-06-03 15:22:47.488996 EDT | AverageQLoss                5.08436e-05
2017-06-03 15:22:47.489222 EDT | AveragePolicySurr          -0.120442
2017-06-03 15:22:47.489447 EDT | AverageQ                    0.114535
2017-06-03 15:22:47.489672 EDT | AverageAbsQ                 0.114893
2017-06-03 15:22:47.490414 EDT | AverageY                    0.114536
2017-06-03 15:22:47.490728 EDT | AverageAbsY                 0.114548
2017-06-03 15:22:47.491046 EDT | AverageAbsQYDiff            0.00194649
2017-06-03 15:22:47.491358 EDT | AverageAction               0.081349
2017-06-03 15:22:47.491666 EDT | PolicyRegParamNorm         55.8836
2017-06-03 15:22:47.491972 EDT | QFunRegParamNorm           26.3185
2017-06-03 15:22:47.492278 EDT | -----------------------  --------------
2017-06-03 15:22:47.492748 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #329 | Training started
2017-06-03 15:23:05.989106 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #329 | Training finished
2017-06-03 15:23:05.989971 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #329 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 15:23:05.990237 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #329 | Collecting samples for evaluation
2017-06-03 15:23:16.134349 EDT | -----------------------  --------------
2017-06-03 15:23:16.134917 EDT | Epoch                     329
2017-06-03 15:23:16.135264 EDT | Iteration                 329
2017-06-03 15:23:16.135597 EDT | AverageReturn            1000
2017-06-03 15:23:16.135946 EDT | StdReturn                   0
2017-06-03 15:23:16.136287 EDT | MaxReturn                1000
2017-06-03 15:23:16.136638 EDT | MinReturn                1000
2017-06-03 15:23:16.137021 EDT | AverageEsReturn            38.7778
2017-06-03 15:23:16.137902 EDT | StdEsReturn                32.2264
2017-06-03 15:23:16.138368 EDT | MaxEsReturn               121
2017-06-03 15:23:16.139695 EDT | MinEsReturn                 3
2017-06-03 15:23:16.140049 EDT | AverageDiscountedReturn    99.9957
2017-06-03 15:23:16.140365 EDT | AverageQLoss                5.05754e-05
2017-06-03 15:23:16.140681 EDT | AveragePolicySurr          -0.120239
2017-06-03 15:23:16.140995 EDT | AverageQ                    0.114497
2017-06-03 15:23:16.141326 EDT | AverageAbsQ                 0.11487
2017-06-03 15:23:16.141673 EDT | AverageY                    0.114491
2017-06-03 15:23:16.142004 EDT | AverageAbsY                 0.114503
2017-06-03 15:23:16.142372 EDT | AverageAbsQYDiff            0.00192561
2017-06-03 15:23:16.143220 EDT | AverageAction               0.0947711
2017-06-03 15:23:16.143582 EDT | PolicyRegParamNorm         55.918
2017-06-03 15:23:16.144220 EDT | QFunRegParamNorm           26.3208
2017-06-03 15:23:16.144583 EDT | -----------------------  --------------
2017-06-03 15:23:16.145167 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #330 | Training started
2017-06-03 15:23:37.138455 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #330 | Training finished
2017-06-03 15:23:37.139346 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #330 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 15:23:37.139694 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #330 | Collecting samples for evaluation
2017-06-03 15:23:47.081604 EDT | -----------------------  --------------
2017-06-03 15:23:47.082512 EDT | Epoch                     330
2017-06-03 15:23:47.082789 EDT | Iteration                 330
2017-06-03 15:23:47.083167 EDT | AverageReturn            1000
2017-06-03 15:23:47.083490 EDT | StdReturn                   0
2017-06-03 15:23:47.083806 EDT | MaxReturn                1000
2017-06-03 15:23:47.084121 EDT | MinReturn                1000
2017-06-03 15:23:47.084434 EDT | AverageEsReturn            31.0303
2017-06-03 15:23:47.084749 EDT | StdEsReturn                20.4976
2017-06-03 15:23:47.085061 EDT | MaxEsReturn                92
2017-06-03 15:23:47.085371 EDT | MinEsReturn                 5
2017-06-03 15:23:47.085676 EDT | AverageDiscountedReturn    99.9957
2017-06-03 15:23:47.085997 EDT | AverageQLoss                4.61062e-05
2017-06-03 15:23:47.086310 EDT | AveragePolicySurr          -0.119904
2017-06-03 15:23:47.086618 EDT | AverageQ                    0.114392
2017-06-03 15:23:47.086926 EDT | AverageAbsQ                 0.114718
2017-06-03 15:23:47.087238 EDT | AverageY                    0.114394
2017-06-03 15:23:47.087564 EDT | AverageAbsY                 0.114411
2017-06-03 15:23:47.087871 EDT | AverageAbsQYDiff            0.00183369
2017-06-03 15:23:47.088178 EDT | AverageAction               0.00968396
2017-06-03 15:23:47.088485 EDT | PolicyRegParamNorm         55.9752
2017-06-03 15:23:47.088797 EDT | QFunRegParamNorm           26.3348
2017-06-03 15:23:47.089164 EDT | -----------------------  --------------
2017-06-03 15:23:47.089751 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #331 | Training started
2017-06-03 15:24:04.588018 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #331 | Training finished
2017-06-03 15:24:04.588885 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #331 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 15:24:04.589174 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #331 | Collecting samples for evaluation
2017-06-03 15:24:14.333041 EDT | -----------------------  --------------
2017-06-03 15:24:14.333413 EDT | Epoch                     331
2017-06-03 15:24:14.333716 EDT | Iteration                 331
2017-06-03 15:24:14.334001 EDT | AverageReturn            1000
2017-06-03 15:24:14.334254 EDT | StdReturn                   0
2017-06-03 15:24:14.334485 EDT | MaxReturn                1000
2017-06-03 15:24:14.334713 EDT | MinReturn                1000
2017-06-03 15:24:14.334941 EDT | AverageEsReturn            33.5357
2017-06-03 15:24:14.335170 EDT | StdEsReturn                24.3185
2017-06-03 15:24:14.335404 EDT | MaxEsReturn                92
2017-06-03 15:24:14.335638 EDT | MinEsReturn                 4
2017-06-03 15:24:14.335865 EDT | AverageDiscountedReturn    99.9957
2017-06-03 15:24:14.336092 EDT | AverageQLoss                4.92826e-05
2017-06-03 15:24:14.336328 EDT | AveragePolicySurr          -0.119463
2017-06-03 15:24:14.336553 EDT | AverageQ                    0.113791
2017-06-03 15:24:14.336783 EDT | AverageAbsQ                 0.114185
2017-06-03 15:24:14.337013 EDT | AverageY                    0.113787
2017-06-03 15:24:14.337234 EDT | AverageAbsY                 0.113812
2017-06-03 15:24:14.337466 EDT | AverageAbsQYDiff            0.00206294
2017-06-03 15:24:14.337703 EDT | AverageAction               0.270115
2017-06-03 15:24:14.337935 EDT | PolicyRegParamNorm         56.0182
2017-06-03 15:24:14.338159 EDT | QFunRegParamNorm           26.3282
2017-06-03 15:24:14.338431 EDT | -----------------------  --------------
2017-06-03 15:24:14.338852 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #332 | Training started
2017-06-03 15:24:32.915631 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #332 | Training finished
2017-06-03 15:24:32.916551 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #332 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 15:24:32.916955 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #332 | Collecting samples for evaluation
2017-06-03 15:24:42.393406 EDT | -----------------------  -------------
2017-06-03 15:24:42.394260 EDT | Epoch                     332
2017-06-03 15:24:42.394532 EDT | Iteration                 332
2017-06-03 15:24:42.394780 EDT | AverageReturn            1000
2017-06-03 15:24:42.395024 EDT | StdReturn                   0
2017-06-03 15:24:42.395265 EDT | MaxReturn                1000
2017-06-03 15:24:42.395506 EDT | MinReturn                1000
2017-06-03 15:24:42.395744 EDT | AverageEsReturn            28.4054
2017-06-03 15:24:42.395984 EDT | StdEsReturn                24.0545
2017-06-03 15:24:42.396224 EDT | MaxEsReturn                93
2017-06-03 15:24:42.396463 EDT | MinEsReturn                 4
2017-06-03 15:24:42.396716 EDT | AverageDiscountedReturn    99.9957
2017-06-03 15:24:42.396956 EDT | AverageQLoss                5.8293e-05
2017-06-03 15:24:42.397197 EDT | AveragePolicySurr          -0.119199
2017-06-03 15:24:42.397438 EDT | AverageQ                    0.113233
2017-06-03 15:24:42.397684 EDT | AverageAbsQ                 0.113693
2017-06-03 15:24:42.397935 EDT | AverageY                    0.113235
2017-06-03 15:24:42.398181 EDT | AverageAbsY                 0.113247
2017-06-03 15:24:42.398453 EDT | AverageAbsQYDiff            0.00218643
2017-06-03 15:24:42.398694 EDT | AverageAction               0.137544
2017-06-03 15:24:42.398933 EDT | PolicyRegParamNorm         56.0831
2017-06-03 15:24:42.399172 EDT | QFunRegParamNorm           26.3344
2017-06-03 15:24:42.399411 EDT | -----------------------  -------------
2017-06-03 15:24:42.399818 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #333 | Training started
2017-06-03 15:25:00.814307 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #333 | Training finished
2017-06-03 15:25:00.821094 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #333 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 15:25:00.821439 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #333 | Collecting samples for evaluation
2017-06-03 15:25:10.947554 EDT | -----------------------  --------------
2017-06-03 15:25:10.948412 EDT | Epoch                     333
2017-06-03 15:25:10.948688 EDT | Iteration                 333
2017-06-03 15:25:10.948934 EDT | AverageReturn            1000
2017-06-03 15:25:10.949174 EDT | StdReturn                   0
2017-06-03 15:25:10.949414 EDT | MaxReturn                1000
2017-06-03 15:25:10.949659 EDT | MinReturn                1000
2017-06-03 15:25:10.949910 EDT | AverageEsReturn            27.2059
2017-06-03 15:25:10.950148 EDT | StdEsReturn                19.0584
2017-06-03 15:25:10.951394 EDT | MaxEsReturn                92
2017-06-03 15:25:10.951776 EDT | MinEsReturn                 4
2017-06-03 15:25:10.952131 EDT | AverageDiscountedReturn    99.9957
2017-06-03 15:25:10.952471 EDT | AverageQLoss                5.07647e-05
2017-06-03 15:25:10.952797 EDT | AveragePolicySurr          -0.118739
2017-06-03 15:25:10.953119 EDT | AverageQ                    0.113212
2017-06-03 15:25:10.953440 EDT | AverageAbsQ                 0.113542
2017-06-03 15:25:10.953770 EDT | AverageY                    0.113203
2017-06-03 15:25:10.954088 EDT | AverageAbsY                 0.113237
2017-06-03 15:25:10.954413 EDT | AverageAbsQYDiff            0.00189301
2017-06-03 15:25:10.954729 EDT | AverageAction               0.289046
2017-06-03 15:25:10.955043 EDT | PolicyRegParamNorm         56.1133
2017-06-03 15:25:10.955360 EDT | QFunRegParamNorm           26.3423
2017-06-03 15:25:10.955683 EDT | -----------------------  --------------
2017-06-03 15:25:10.956184 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #334 | Training started
2017-06-03 15:25:30.069680 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #334 | Training finished
2017-06-03 15:25:30.070138 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #334 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 15:25:30.070538 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #334 | Collecting samples for evaluation
2017-06-03 15:25:39.983777 EDT | -----------------------  --------------
2017-06-03 15:25:39.984778 EDT | Epoch                     334
2017-06-03 15:25:39.985042 EDT | Iteration                 334
2017-06-03 15:25:39.985276 EDT | AverageReturn            1000
2017-06-03 15:25:39.985514 EDT | StdReturn                   0
2017-06-03 15:25:39.985790 EDT | MaxReturn                1000
2017-06-03 15:25:39.986022 EDT | MinReturn                1000
2017-06-03 15:25:39.986287 EDT | AverageEsReturn            27
2017-06-03 15:25:39.986521 EDT | StdEsReturn                20.4157
2017-06-03 15:25:39.986733 EDT | MaxEsReturn                91
2017-06-03 15:25:39.986941 EDT | MinEsReturn                 4
2017-06-03 15:25:39.987149 EDT | AverageDiscountedReturn    99.9957
2017-06-03 15:25:39.987358 EDT | AverageQLoss                5.21485e-05
2017-06-03 15:25:39.987566 EDT | AveragePolicySurr          -0.118512
2017-06-03 15:25:39.987774 EDT | AverageQ                    0.112868
2017-06-03 15:25:39.987981 EDT | AverageAbsQ                 0.113255
2017-06-03 15:25:39.988193 EDT | AverageY                    0.112871
2017-06-03 15:25:39.988411 EDT | AverageAbsY                 0.112895
2017-06-03 15:25:39.988677 EDT | AverageAbsQYDiff            0.0020246
2017-06-03 15:25:39.988897 EDT | AverageAction               0.107887
2017-06-03 15:25:39.989118 EDT | PolicyRegParamNorm         56.1662
2017-06-03 15:25:39.989341 EDT | QFunRegParamNorm           26.3663
2017-06-03 15:25:39.989563 EDT | -----------------------  --------------
2017-06-03 15:25:39.990664 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #335 | Training started
2017-06-03 15:25:59.637626 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #335 | Training finished
2017-06-03 15:25:59.638548 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #335 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 15:25:59.639124 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #335 | Collecting samples for evaluation
2017-06-03 15:26:10.079417 EDT | -----------------------  --------------
2017-06-03 15:26:10.080270 EDT | Epoch                     335
2017-06-03 15:26:10.080540 EDT | Iteration                 335
2017-06-03 15:26:10.080788 EDT | AverageReturn            1000
2017-06-03 15:26:10.081030 EDT | StdReturn                   0
2017-06-03 15:26:10.081266 EDT | MaxReturn                1000
2017-06-03 15:26:10.081501 EDT | MinReturn                1000
2017-06-03 15:26:10.081744 EDT | AverageEsReturn            17.3214
2017-06-03 15:26:10.082014 EDT | StdEsReturn                14.5493
2017-06-03 15:26:10.082248 EDT | MaxEsReturn                97
2017-06-03 15:26:10.082482 EDT | MinEsReturn                 3
2017-06-03 15:26:10.082715 EDT | AverageDiscountedReturn    99.9957
2017-06-03 15:26:10.082957 EDT | AverageQLoss                4.87601e-05
2017-06-03 15:26:10.083195 EDT | AveragePolicySurr          -0.117942
2017-06-03 15:26:10.083434 EDT | AverageQ                    0.112499
2017-06-03 15:26:10.083665 EDT | AverageAbsQ                 0.112892
2017-06-03 15:26:10.083897 EDT | AverageY                    0.112505
2017-06-03 15:26:10.084128 EDT | AverageAbsY                 0.11252
2017-06-03 15:26:10.084359 EDT | AverageAbsQYDiff            0.00195693
2017-06-03 15:26:10.084599 EDT | AverageAction               0.121593
2017-06-03 15:26:10.084833 EDT | PolicyRegParamNorm         56.2633
2017-06-03 15:26:10.085084 EDT | QFunRegParamNorm           26.3612
2017-06-03 15:26:10.085319 EDT | -----------------------  --------------
2017-06-03 15:26:10.085662 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #336 | Training started
2017-06-03 15:26:29.112211 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #336 | Training finished
2017-06-03 15:26:29.113183 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #336 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 15:26:29.113550 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #336 | Collecting samples for evaluation
2017-06-03 15:26:38.779424 EDT | -----------------------  -------------
2017-06-03 15:26:38.780292 EDT | Epoch                     336
2017-06-03 15:26:38.780554 EDT | Iteration                 336
2017-06-03 15:26:38.780797 EDT | AverageReturn            1000
2017-06-03 15:26:38.781029 EDT | StdReturn                   0
2017-06-03 15:26:38.781291 EDT | MaxReturn                1000
2017-06-03 15:26:38.781522 EDT | MinReturn                1000
2017-06-03 15:26:38.781765 EDT | AverageEsReturn            29.4706
2017-06-03 15:26:38.781996 EDT | StdEsReturn                28.4256
2017-06-03 15:26:38.782224 EDT | MaxEsReturn               155
2017-06-03 15:26:38.782463 EDT | MinEsReturn                 3
2017-06-03 15:26:38.782690 EDT | AverageDiscountedReturn    99.9957
2017-06-03 15:26:38.782920 EDT | AverageQLoss                5.543e-05
2017-06-03 15:26:38.783145 EDT | AveragePolicySurr          -0.11763
2017-06-03 15:26:38.783370 EDT | AverageQ                    0.112042
2017-06-03 15:26:38.783640 EDT | AverageAbsQ                 0.112418
2017-06-03 15:26:38.783868 EDT | AverageY                    0.112037
2017-06-03 15:26:38.784094 EDT | AverageAbsY                 0.112059
2017-06-03 15:26:38.784319 EDT | AverageAbsQYDiff            0.00203964
2017-06-03 15:26:38.784545 EDT | AverageAction               0.027758
2017-06-03 15:26:38.784783 EDT | PolicyRegParamNorm         56.3475
2017-06-03 15:26:38.785008 EDT | QFunRegParamNorm           26.3588
2017-06-03 15:26:38.785237 EDT | -----------------------  -------------
2017-06-03 15:26:38.785618 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #337 | Training started
2017-06-03 15:26:57.111526 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #337 | Training finished
2017-06-03 15:26:57.112430 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #337 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 15:26:57.112778 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #337 | Collecting samples for evaluation
2017-06-03 15:27:07.483554 EDT | -----------------------  --------------
2017-06-03 15:27:07.484150 EDT | Epoch                     337
2017-06-03 15:27:07.484487 EDT | Iteration                 337
2017-06-03 15:27:07.484809 EDT | AverageReturn            1000
2017-06-03 15:27:07.485129 EDT | StdReturn                   0
2017-06-03 15:27:07.485443 EDT | MaxReturn                1000
2017-06-03 15:27:07.485766 EDT | MinReturn                1000
2017-06-03 15:27:07.486080 EDT | AverageEsReturn            32.1
2017-06-03 15:27:07.486391 EDT | StdEsReturn                27.9349
2017-06-03 15:27:07.486706 EDT | MaxEsReturn               115
2017-06-03 15:27:07.487014 EDT | MinEsReturn                 4
2017-06-03 15:27:07.487323 EDT | AverageDiscountedReturn    99.9957
2017-06-03 15:27:07.487630 EDT | AverageQLoss                4.87063e-05
2017-06-03 15:27:07.487938 EDT | AveragePolicySurr          -0.117478
2017-06-03 15:27:07.488245 EDT | AverageQ                    0.111854
2017-06-03 15:27:07.488559 EDT | AverageAbsQ                 0.112201
2017-06-03 15:27:07.488865 EDT | AverageY                    0.111856
2017-06-03 15:27:07.489170 EDT | AverageAbsY                 0.111887
2017-06-03 15:27:07.489475 EDT | AverageAbsQYDiff            0.0019056
2017-06-03 15:27:07.489794 EDT | AverageAction               0.0446087
2017-06-03 15:27:07.490101 EDT | PolicyRegParamNorm         56.4026
2017-06-03 15:27:07.490405 EDT | QFunRegParamNorm           26.3562
2017-06-03 15:27:07.490708 EDT | -----------------------  --------------
2017-06-03 15:27:07.491155 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #338 | Training started
2017-06-03 15:27:25.659644 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #338 | Training finished
2017-06-03 15:27:25.660532 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #338 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 15:27:25.660893 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #338 | Collecting samples for evaluation
2017-06-03 15:27:35.136493 EDT | -----------------------  --------------
2017-06-03 15:27:35.136881 EDT | Epoch                     338
2017-06-03 15:27:35.137130 EDT | Iteration                 338
2017-06-03 15:27:35.137369 EDT | AverageReturn             682.6
2017-06-03 15:27:35.137635 EDT | StdReturn                 277.733
2017-06-03 15:27:35.137886 EDT | MaxReturn                1000
2017-06-03 15:27:35.138122 EDT | MinReturn                 223
2017-06-03 15:27:35.138357 EDT | AverageEsReturn            36.4828
2017-06-03 15:27:35.138591 EDT | StdEsReturn                27.6912
2017-06-03 15:27:35.138833 EDT | MaxEsReturn               112
2017-06-03 15:27:35.139066 EDT | MinEsReturn                 6
2017-06-03 15:27:35.139300 EDT | AverageDiscountedReturn    98.5247
2017-06-03 15:27:35.139532 EDT | AverageQLoss                5.57669e-05
2017-06-03 15:27:35.139800 EDT | AveragePolicySurr          -0.11694
2017-06-03 15:27:35.140039 EDT | AverageQ                    0.110933
2017-06-03 15:27:35.140273 EDT | AverageAbsQ                 0.111364
2017-06-03 15:27:35.140505 EDT | AverageY                    0.110929
2017-06-03 15:27:35.140737 EDT | AverageAbsY                 0.110966
2017-06-03 15:27:35.140973 EDT | AverageAbsQYDiff            0.0021203
2017-06-03 15:27:35.141208 EDT | AverageAction               0.131738
2017-06-03 15:27:35.141440 EDT | PolicyRegParamNorm         56.4414
2017-06-03 15:27:35.141672 EDT | QFunRegParamNorm           26.3591
2017-06-03 15:27:35.141916 EDT | -----------------------  --------------
2017-06-03 15:27:35.142291 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #339 | Training started
2017-06-03 15:27:53.260434 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #339 | Training finished
2017-06-03 15:27:53.261355 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #339 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 15:27:53.261633 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #339 | Collecting samples for evaluation
2017-06-03 15:28:01.633396 EDT | -----------------------  --------------
2017-06-03 15:28:01.634438 EDT | Epoch                     339
2017-06-03 15:28:01.634726 EDT | Iteration                 339
2017-06-03 15:28:01.634970 EDT | AverageReturn            1000
2017-06-03 15:28:01.635300 EDT | StdReturn                   0
2017-06-03 15:28:01.635620 EDT | MaxReturn                1000
2017-06-03 15:28:01.635952 EDT | MinReturn                1000
2017-06-03 15:28:01.636266 EDT | AverageEsReturn            25.3158
2017-06-03 15:28:01.636580 EDT | StdEsReturn                18.9016
2017-06-03 15:28:01.636943 EDT | MaxEsReturn                82
2017-06-03 15:28:01.637259 EDT | MinEsReturn                 5
2017-06-03 15:28:01.637571 EDT | AverageDiscountedReturn    99.9957
2017-06-03 15:28:01.637916 EDT | AverageQLoss                4.79753e-05
2017-06-03 15:28:01.638234 EDT | AveragePolicySurr          -0.116801
2017-06-03 15:28:01.638553 EDT | AverageQ                    0.11127
2017-06-03 15:28:01.638865 EDT | AverageAbsQ                 0.111631
2017-06-03 15:28:01.639173 EDT | AverageY                    0.111273
2017-06-03 15:28:01.639484 EDT | AverageAbsY                 0.111304
2017-06-03 15:28:01.639793 EDT | AverageAbsQYDiff            0.00190069
2017-06-03 15:28:01.640101 EDT | AverageAction               0.0158088
2017-06-03 15:28:01.640407 EDT | PolicyRegParamNorm         56.463
2017-06-03 15:28:01.640716 EDT | QFunRegParamNorm           26.3651
2017-06-03 15:28:01.641024 EDT | -----------------------  --------------
2017-06-03 15:28:01.641491 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #340 | Training started
2017-06-03 15:28:20.163561 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #340 | Training finished
2017-06-03 15:28:20.166954 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #340 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 15:28:20.167283 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #340 | Collecting samples for evaluation
2017-06-03 15:28:31.001827 EDT | -----------------------  -------------
2017-06-03 15:28:31.002678 EDT | Epoch                     340
2017-06-03 15:28:31.002935 EDT | Iteration                 340
2017-06-03 15:28:31.003175 EDT | AverageReturn            1000
2017-06-03 15:28:31.003406 EDT | StdReturn                   0
2017-06-03 15:28:31.003635 EDT | MaxReturn                1000
2017-06-03 15:28:31.003891 EDT | MinReturn                1000
2017-06-03 15:28:31.004188 EDT | AverageEsReturn            37.4286
2017-06-03 15:28:31.004496 EDT | StdEsReturn                27.6914
2017-06-03 15:28:31.004834 EDT | MaxEsReturn                97
2017-06-03 15:28:31.005182 EDT | MinEsReturn                 5
2017-06-03 15:28:31.005526 EDT | AverageDiscountedReturn    99.9957
2017-06-03 15:28:31.005879 EDT | AverageQLoss                5.3017e-05
2017-06-03 15:28:31.006199 EDT | AveragePolicySurr          -0.116636
2017-06-03 15:28:31.006551 EDT | AverageQ                    0.111131
2017-06-03 15:28:31.006843 EDT | AverageAbsQ                 0.111488
2017-06-03 15:28:31.007075 EDT | AverageY                    0.111129
2017-06-03 15:28:31.007305 EDT | AverageAbsY                 0.111164
2017-06-03 15:28:31.007532 EDT | AverageAbsQYDiff            0.00199508
2017-06-03 15:28:31.007768 EDT | AverageAction               0.0115489
2017-06-03 15:28:31.007998 EDT | PolicyRegParamNorm         56.4928
2017-06-03 15:28:31.008228 EDT | QFunRegParamNorm           26.3681
2017-06-03 15:28:31.008452 EDT | -----------------------  -------------
2017-06-03 15:28:31.008797 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #341 | Training started
2017-06-03 15:28:50.774037 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #341 | Training finished
2017-06-03 15:28:50.775015 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #341 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 15:28:50.775418 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #341 | Collecting samples for evaluation
2017-06-03 15:29:00.203522 EDT | -----------------------  --------------
2017-06-03 15:29:00.204633 EDT | Epoch                     341
2017-06-03 15:29:00.204903 EDT | Iteration                 341
2017-06-03 15:29:00.205145 EDT | AverageReturn            1000
2017-06-03 15:29:00.205387 EDT | StdReturn                   0
2017-06-03 15:29:00.205622 EDT | MaxReturn                1000
2017-06-03 15:29:00.205894 EDT | MinReturn                1000
2017-06-03 15:29:00.206125 EDT | AverageEsReturn            19.5294
2017-06-03 15:29:00.206354 EDT | StdEsReturn                13.8498
2017-06-03 15:29:00.206581 EDT | MaxEsReturn                58
2017-06-03 15:29:00.206808 EDT | MinEsReturn                 3
2017-06-03 15:29:00.207043 EDT | AverageDiscountedReturn    99.9957
2017-06-03 15:29:00.207270 EDT | AverageQLoss                4.52417e-05
2017-06-03 15:29:00.207497 EDT | AveragePolicySurr          -0.115994
2017-06-03 15:29:00.207724 EDT | AverageQ                    0.11031
2017-06-03 15:29:00.207951 EDT | AverageAbsQ                 0.110685
2017-06-03 15:29:00.208177 EDT | AverageY                    0.110314
2017-06-03 15:29:00.208402 EDT | AverageAbsY                 0.110352
2017-06-03 15:29:00.208627 EDT | AverageAbsQYDiff            0.0019095
2017-06-03 15:29:00.208864 EDT | AverageAction               0.033464
2017-06-03 15:29:00.209089 EDT | PolicyRegParamNorm         56.551
2017-06-03 15:29:00.209314 EDT | QFunRegParamNorm           26.3641
2017-06-03 15:29:00.209539 EDT | -----------------------  --------------
2017-06-03 15:29:00.209960 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #342 | Training started
2017-06-03 15:29:19.128753 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #342 | Training finished
2017-06-03 15:29:19.129677 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #342 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 15:29:19.130042 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #342 | Collecting samples for evaluation
2017-06-03 15:29:29.074388 EDT | -----------------------  -------------
2017-06-03 15:29:29.075328 EDT | Epoch                     342
2017-06-03 15:29:29.075657 EDT | Iteration                 342
2017-06-03 15:29:29.075963 EDT | AverageReturn            1000
2017-06-03 15:29:29.076303 EDT | StdReturn                   0
2017-06-03 15:29:29.076705 EDT | MaxReturn                1000
2017-06-03 15:29:29.077273 EDT | MinReturn                1000
2017-06-03 15:29:29.077616 EDT | AverageEsReturn            27.9714
2017-06-03 15:29:29.078246 EDT | StdEsReturn                33.3171
2017-06-03 15:29:29.078581 EDT | MaxEsReturn               161
2017-06-03 15:29:29.079203 EDT | MinEsReturn                 3
2017-06-03 15:29:29.079537 EDT | AverageDiscountedReturn    99.9957
2017-06-03 15:29:29.080576 EDT | AverageQLoss                4.0199e-05
2017-06-03 15:29:29.080896 EDT | AveragePolicySurr          -0.11616
2017-06-03 15:29:29.081208 EDT | AverageQ                    0.110454
2017-06-03 15:29:29.081502 EDT | AverageAbsQ                 0.110817
2017-06-03 15:29:29.081806 EDT | AverageY                    0.110451
2017-06-03 15:29:29.082100 EDT | AverageAbsY                 0.110477
2017-06-03 15:29:29.082394 EDT | AverageAbsQYDiff            0.0018016
2017-06-03 15:29:29.082687 EDT | AverageAction               0.0290689
2017-06-03 15:29:29.082975 EDT | PolicyRegParamNorm         56.5886
2017-06-03 15:29:29.083302 EDT | QFunRegParamNorm           26.4016
2017-06-03 15:29:29.083647 EDT | -----------------------  -------------
2017-06-03 15:29:29.084092 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #343 | Training started
2017-06-03 15:29:47.101836 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #343 | Training finished
2017-06-03 15:29:47.102753 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #343 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 15:29:47.103026 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #343 | Collecting samples for evaluation
2017-06-03 15:29:56.399444 EDT | -----------------------  --------------
2017-06-03 15:29:56.400322 EDT | Epoch                     343
2017-06-03 15:29:56.400662 EDT | Iteration                 343
2017-06-03 15:29:56.400975 EDT | AverageReturn            1000
2017-06-03 15:29:56.401295 EDT | StdReturn                   0
2017-06-03 15:29:56.401604 EDT | MaxReturn                1000
2017-06-03 15:29:56.401916 EDT | MinReturn                1000
2017-06-03 15:29:56.402158 EDT | AverageEsReturn            25.7895
2017-06-03 15:29:56.402442 EDT | StdEsReturn                21.1824
2017-06-03 15:29:56.402745 EDT | MaxEsReturn                86
2017-06-03 15:29:56.403007 EDT | MinEsReturn                 3
2017-06-03 15:29:56.403295 EDT | AverageDiscountedReturn    99.9957
2017-06-03 15:29:56.403619 EDT | AverageQLoss                5.10026e-05
2017-06-03 15:29:56.403923 EDT | AveragePolicySurr          -0.115803
2017-06-03 15:29:56.404228 EDT | AverageQ                    0.110288
2017-06-03 15:29:56.404524 EDT | AverageAbsQ                 0.110633
2017-06-03 15:29:56.404775 EDT | AverageY                    0.110293
2017-06-03 15:29:56.405009 EDT | AverageAbsY                 0.110324
2017-06-03 15:29:56.405246 EDT | AverageAbsQYDiff            0.00194499
2017-06-03 15:29:56.405555 EDT | AverageAction               0.307689
2017-06-03 15:29:56.405887 EDT | PolicyRegParamNorm         56.6554
2017-06-03 15:29:56.406132 EDT | QFunRegParamNorm           26.3869
2017-06-03 15:29:56.406423 EDT | -----------------------  --------------
2017-06-03 15:29:56.406903 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #344 | Training started
2017-06-03 15:30:14.588361 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #344 | Training finished
2017-06-03 15:30:14.589271 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #344 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 15:30:14.589636 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #344 | Collecting samples for evaluation
2017-06-03 15:30:24.179965 EDT | -----------------------  --------------
2017-06-03 15:30:24.180821 EDT | Epoch                     344
2017-06-03 15:30:24.181082 EDT | Iteration                 344
2017-06-03 15:30:24.181319 EDT | AverageReturn            1000
2017-06-03 15:30:24.181559 EDT | StdReturn                   0
2017-06-03 15:30:24.181806 EDT | MaxReturn                1000
2017-06-03 15:30:24.182050 EDT | MinReturn                1000
2017-06-03 15:30:24.182279 EDT | AverageEsReturn            28.1429
2017-06-03 15:30:24.182511 EDT | StdEsReturn                26.2724
2017-06-03 15:30:24.182739 EDT | MaxEsReturn               126
2017-06-03 15:30:24.182966 EDT | MinEsReturn                 3
2017-06-03 15:30:24.183194 EDT | AverageDiscountedReturn    99.9957
2017-06-03 15:30:24.183426 EDT | AverageQLoss                5.21133e-05
2017-06-03 15:30:24.183657 EDT | AveragePolicySurr          -0.115384
2017-06-03 15:30:24.183883 EDT | AverageQ                    0.10978
2017-06-03 15:30:24.184111 EDT | AverageAbsQ                 0.110173
2017-06-03 15:30:24.184337 EDT | AverageY                    0.109777
2017-06-03 15:30:24.184563 EDT | AverageAbsY                 0.109797
2017-06-03 15:30:24.184788 EDT | AverageAbsQYDiff            0.00199911
2017-06-03 15:30:24.185013 EDT | AverageAction               0.447931
2017-06-03 15:30:24.185238 EDT | PolicyRegParamNorm         56.6941
2017-06-03 15:30:24.185463 EDT | QFunRegParamNorm           26.4112
2017-06-03 15:30:24.185688 EDT | -----------------------  --------------
2017-06-03 15:30:24.186038 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #345 | Training started
2017-06-03 15:30:44.376854 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #345 | Training finished
2017-06-03 15:30:44.377784 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #345 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 15:30:44.378053 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #345 | Collecting samples for evaluation
2017-06-03 15:30:53.892163 EDT | -----------------------  --------------
2017-06-03 15:30:53.893278 EDT | Epoch                     345
2017-06-03 15:30:53.893643 EDT | Iteration                 345
2017-06-03 15:30:53.893946 EDT | AverageReturn            1000
2017-06-03 15:30:53.894238 EDT | StdReturn                   0
2017-06-03 15:30:53.894575 EDT | MaxReturn                1000
2017-06-03 15:30:53.894845 EDT | MinReturn                1000
2017-06-03 15:30:53.895139 EDT | AverageEsReturn            21.8478
2017-06-03 15:30:53.895475 EDT | StdEsReturn                16.6394
2017-06-03 15:30:53.895741 EDT | MaxEsReturn                68
2017-06-03 15:30:53.896035 EDT | MinEsReturn                 3
2017-06-03 15:30:53.896362 EDT | AverageDiscountedReturn    99.9957
2017-06-03 15:30:53.896652 EDT | AverageQLoss                5.38123e-05
2017-06-03 15:30:53.896937 EDT | AveragePolicySurr          -0.11506
2017-06-03 15:30:53.897266 EDT | AverageQ                    0.109628
2017-06-03 15:30:53.897532 EDT | AverageAbsQ                 0.109962
2017-06-03 15:30:53.897891 EDT | AverageY                    0.109636
2017-06-03 15:30:53.898242 EDT | AverageAbsY                 0.109663
2017-06-03 15:30:53.898540 EDT | AverageAbsQYDiff            0.0019923
2017-06-03 15:30:53.898882 EDT | AverageAction               0.0431792
2017-06-03 15:30:53.899211 EDT | PolicyRegParamNorm         56.7722
2017-06-03 15:30:53.899481 EDT | QFunRegParamNorm           26.4135
2017-06-03 15:30:53.899830 EDT | -----------------------  --------------
2017-06-03 15:30:53.900332 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #346 | Training started
2017-06-03 15:31:12.548261 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #346 | Training finished
2017-06-03 15:31:12.555814 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #346 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 15:31:12.556223 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #346 | Collecting samples for evaluation
2017-06-03 15:31:23.400022 EDT | -----------------------  --------------
2017-06-03 15:31:23.400931 EDT | Epoch                     346
2017-06-03 15:31:23.401195 EDT | Iteration                 346
2017-06-03 15:31:23.401432 EDT | AverageReturn            1000
2017-06-03 15:31:23.401688 EDT | StdReturn                   0
2017-06-03 15:31:23.401935 EDT | MaxReturn                1000
2017-06-03 15:31:23.402169 EDT | MinReturn                1000
2017-06-03 15:31:23.402403 EDT | AverageEsReturn            24.186
2017-06-03 15:31:23.402635 EDT | StdEsReturn                17.8459
2017-06-03 15:31:23.402866 EDT | MaxEsReturn                85
2017-06-03 15:31:23.403097 EDT | MinEsReturn                 5
2017-06-03 15:31:23.403327 EDT | AverageDiscountedReturn    99.9957
2017-06-03 15:31:23.403558 EDT | AverageQLoss                4.69789e-05
2017-06-03 15:31:23.403790 EDT | AveragePolicySurr          -0.114854
2017-06-03 15:31:23.404020 EDT | AverageQ                    0.1094
2017-06-03 15:31:23.404250 EDT | AverageAbsQ                 0.109694
2017-06-03 15:31:23.404481 EDT | AverageY                    0.109386
2017-06-03 15:31:23.404735 EDT | AverageAbsY                 0.1094
2017-06-03 15:31:23.404965 EDT | AverageAbsQYDiff            0.00189749
2017-06-03 15:31:23.405197 EDT | AverageAction               0.0236058
2017-06-03 15:31:23.405444 EDT | PolicyRegParamNorm         56.805
2017-06-03 15:31:23.405675 EDT | QFunRegParamNorm           26.4214
2017-06-03 15:31:23.405921 EDT | -----------------------  --------------
2017-06-03 15:31:23.406299 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #347 | Training started
2017-06-03 15:31:41.770330 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #347 | Training finished
2017-06-03 15:31:41.771293 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #347 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 15:31:41.771693 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #347 | Collecting samples for evaluation
2017-06-03 15:31:51.205484 EDT | -----------------------  --------------
2017-06-03 15:31:51.206401 EDT | Epoch                     347
2017-06-03 15:31:51.206683 EDT | Iteration                 347
2017-06-03 15:31:51.206926 EDT | AverageReturn            1000
2017-06-03 15:31:51.207180 EDT | StdReturn                   0
2017-06-03 15:31:51.207420 EDT | MaxReturn                1000
2017-06-03 15:31:51.207666 EDT | MinReturn                1000
2017-06-03 15:31:51.207901 EDT | AverageEsReturn            25.45
2017-06-03 15:31:51.208160 EDT | StdEsReturn                19.1271
2017-06-03 15:31:51.208395 EDT | MaxEsReturn                90
2017-06-03 15:31:51.208639 EDT | MinEsReturn                 5
2017-06-03 15:31:51.208899 EDT | AverageDiscountedReturn    99.9957
2017-06-03 15:31:51.209135 EDT | AverageQLoss                5.15277e-05
2017-06-03 15:31:51.209395 EDT | AveragePolicySurr          -0.114695
2017-06-03 15:31:51.209629 EDT | AverageQ                    0.10924
2017-06-03 15:31:51.209883 EDT | AverageAbsQ                 0.109572
2017-06-03 15:31:51.210126 EDT | AverageY                    0.109239
2017-06-03 15:31:51.210359 EDT | AverageAbsY                 0.10926
2017-06-03 15:31:51.210616 EDT | AverageAbsQYDiff            0.00190843
2017-06-03 15:31:51.210858 EDT | AverageAction               0.0114549
2017-06-03 15:31:51.211091 EDT | PolicyRegParamNorm         56.8493
2017-06-03 15:31:51.211338 EDT | QFunRegParamNorm           26.4348
2017-06-03 15:31:51.211571 EDT | -----------------------  --------------
2017-06-03 15:31:51.212004 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #348 | Training started
2017-06-03 15:32:10.255032 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #348 | Training finished
2017-06-03 15:32:10.255900 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #348 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 15:32:10.256180 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #348 | Collecting samples for evaluation
2017-06-03 15:32:20.302501 EDT | -----------------------  --------------
2017-06-03 15:32:20.303355 EDT | Epoch                     348
2017-06-03 15:32:20.303653 EDT | Iteration                 348
2017-06-03 15:32:20.303899 EDT | AverageReturn            1000
2017-06-03 15:32:20.304139 EDT | StdReturn                   0
2017-06-03 15:32:20.304376 EDT | MaxReturn                1000
2017-06-03 15:32:20.304623 EDT | MinReturn                1000
2017-06-03 15:32:20.304978 EDT | AverageEsReturn            23.878
2017-06-03 15:32:20.305294 EDT | StdEsReturn                35.1701
2017-06-03 15:32:20.305605 EDT | MaxEsReturn               213
2017-06-03 15:32:20.305938 EDT | MinEsReturn                 3
2017-06-03 15:32:20.306244 EDT | AverageDiscountedReturn    99.9957
2017-06-03 15:32:20.306552 EDT | AverageQLoss                4.90536e-05
2017-06-03 15:32:20.306861 EDT | AveragePolicySurr          -0.114212
2017-06-03 15:32:20.307166 EDT | AverageQ                    0.108725
2017-06-03 15:32:20.307469 EDT | AverageAbsQ                 0.109123
2017-06-03 15:32:20.307772 EDT | AverageY                    0.108734
2017-06-03 15:32:20.308083 EDT | AverageAbsY                 0.108753
2017-06-03 15:32:20.308388 EDT | AverageAbsQYDiff            0.0019853
2017-06-03 15:32:20.308691 EDT | AverageAction               0.08521
2017-06-03 15:32:20.308994 EDT | PolicyRegParamNorm         56.8804
2017-06-03 15:32:20.309294 EDT | QFunRegParamNorm           26.4399
2017-06-03 15:32:20.309594 EDT | -----------------------  --------------
2017-06-03 15:32:20.310035 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #349 | Training started
2017-06-03 15:32:38.368197 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #349 | Training finished
2017-06-03 15:32:38.369691 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #349 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 15:32:38.370141 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #349 | Collecting samples for evaluation
2017-06-03 15:32:48.835484 EDT | -----------------------  --------------
2017-06-03 15:32:48.836327 EDT | Epoch                     349
2017-06-03 15:32:48.836586 EDT | Iteration                 349
2017-06-03 15:32:48.836828 EDT | AverageReturn            1000
2017-06-03 15:32:48.837087 EDT | StdReturn                   0
2017-06-03 15:32:48.837317 EDT | MaxReturn                1000
2017-06-03 15:32:48.837547 EDT | MinReturn                1000
2017-06-03 15:32:48.837790 EDT | AverageEsReturn            21.5652
2017-06-03 15:32:48.838026 EDT | StdEsReturn                18.2634
2017-06-03 15:32:48.838300 EDT | MaxEsReturn                92
2017-06-03 15:32:48.838531 EDT | MinEsReturn                 4
2017-06-03 15:32:48.838764 EDT | AverageDiscountedReturn    99.9957
2017-06-03 15:32:48.838992 EDT | AverageQLoss                3.91952e-05
2017-06-03 15:32:48.839241 EDT | AveragePolicySurr          -0.114032
2017-06-03 15:32:48.839479 EDT | AverageQ                    0.108548
2017-06-03 15:32:48.839710 EDT | AverageAbsQ                 0.108858
2017-06-03 15:32:48.839939 EDT | AverageY                    0.108545
2017-06-03 15:32:48.840176 EDT | AverageAbsY                 0.108563
2017-06-03 15:32:48.840413 EDT | AverageAbsQYDiff            0.00175527
2017-06-03 15:32:48.840641 EDT | AverageAction               0.0607084
2017-06-03 15:32:48.840868 EDT | PolicyRegParamNorm         56.9635
2017-06-03 15:32:48.841094 EDT | QFunRegParamNorm           26.4454
2017-06-03 15:32:48.841340 EDT | -----------------------  --------------
2017-06-03 15:32:48.841722 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #350 | Training started
2017-06-03 15:33:06.850274 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #350 | Training finished
2017-06-03 15:33:06.851142 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #350 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 15:33:06.851405 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #350 | Collecting samples for evaluation
2017-06-03 15:33:17.134856 EDT | -----------------------  --------------
2017-06-03 15:33:17.135522 EDT | Epoch                     350
2017-06-03 15:33:17.135930 EDT | Iteration                 350
2017-06-03 15:33:17.136253 EDT | AverageReturn            1000
2017-06-03 15:33:17.136569 EDT | StdReturn                   0
2017-06-03 15:33:17.136884 EDT | MaxReturn                1000
2017-06-03 15:33:17.137206 EDT | MinReturn                1000
2017-06-03 15:33:17.137519 EDT | AverageEsReturn            29.7353
2017-06-03 15:33:17.137858 EDT | StdEsReturn                28.2908
2017-06-03 15:33:17.138172 EDT | MaxEsReturn               122
2017-06-03 15:33:17.138484 EDT | MinEsReturn                 4
2017-06-03 15:33:17.138796 EDT | AverageDiscountedReturn    99.9957
2017-06-03 15:33:17.139118 EDT | AverageQLoss                4.69699e-05
2017-06-03 15:33:17.139432 EDT | AveragePolicySurr          -0.113809
2017-06-03 15:33:17.139744 EDT | AverageQ                    0.10833
2017-06-03 15:33:17.140053 EDT | AverageAbsQ                 0.108687
2017-06-03 15:33:17.140361 EDT | AverageY                    0.108331
2017-06-03 15:33:17.140668 EDT | AverageAbsY                 0.108352
2017-06-03 15:33:17.140976 EDT | AverageAbsQYDiff            0.00193328
2017-06-03 15:33:17.141286 EDT | AverageAction               0.0132019
2017-06-03 15:33:17.141596 EDT | PolicyRegParamNorm         57.0106
2017-06-03 15:33:17.141919 EDT | QFunRegParamNorm           26.4559
2017-06-03 15:33:17.142229 EDT | -----------------------  --------------
2017-06-03 15:33:17.142718 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #351 | Training started
2017-06-03 15:33:37.500597 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #351 | Training finished
2017-06-03 15:33:37.501434 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #351 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 15:33:37.501721 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #351 | Collecting samples for evaluation
2017-06-03 15:33:46.981164 EDT | -----------------------  --------------
2017-06-03 15:33:46.981719 EDT | Epoch                     351
2017-06-03 15:33:46.982056 EDT | Iteration                 351
2017-06-03 15:33:46.982425 EDT | AverageReturn            1000
2017-06-03 15:33:46.982747 EDT | StdReturn                   0
2017-06-03 15:33:46.983062 EDT | MaxReturn                1000
2017-06-03 15:33:46.983379 EDT | MinReturn                1000
2017-06-03 15:33:46.983708 EDT | AverageEsReturn            26.1579
2017-06-03 15:33:46.984023 EDT | StdEsReturn                18.1985
2017-06-03 15:33:46.984339 EDT | MaxEsReturn                96
2017-06-03 15:33:46.984650 EDT | MinEsReturn                 3
2017-06-03 15:33:46.984966 EDT | AverageDiscountedReturn    99.9957
2017-06-03 15:33:46.985278 EDT | AverageQLoss                4.46229e-05
2017-06-03 15:33:46.985592 EDT | AveragePolicySurr          -0.113447
2017-06-03 15:33:46.985916 EDT | AverageQ                    0.107923
2017-06-03 15:33:46.986227 EDT | AverageAbsQ                 0.108271
2017-06-03 15:33:46.986538 EDT | AverageY                    0.107919
2017-06-03 15:33:46.986847 EDT | AverageAbsY                 0.107937
2017-06-03 15:33:46.987153 EDT | AverageAbsQYDiff            0.00181559
2017-06-03 15:33:46.987459 EDT | AverageAction               0.0255655
2017-06-03 15:33:46.987764 EDT | PolicyRegParamNorm         57.0803
2017-06-03 15:33:46.988069 EDT | QFunRegParamNorm           26.443
2017-06-03 15:33:46.988374 EDT | -----------------------  --------------
2017-06-03 15:33:46.988793 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #352 | Training started
2017-06-03 15:34:05.914714 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #352 | Training finished
2017-06-03 15:34:05.915664 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #352 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 15:34:05.916027 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #352 | Collecting samples for evaluation
2017-06-03 15:34:15.143615 EDT | -----------------------  --------------
2017-06-03 15:34:15.144565 EDT | Epoch                     352
2017-06-03 15:34:15.144857 EDT | Iteration                 352
2017-06-03 15:34:15.145101 EDT | AverageReturn            1000
2017-06-03 15:34:15.145339 EDT | StdReturn                   0
2017-06-03 15:34:15.145589 EDT | MaxReturn                1000
2017-06-03 15:34:15.145868 EDT | MinReturn                1000
2017-06-03 15:34:15.146118 EDT | AverageEsReturn            17.5172
2017-06-03 15:34:15.146367 EDT | StdEsReturn                14.4571
2017-06-03 15:34:15.146608 EDT | MaxEsReturn                66
2017-06-03 15:34:15.146842 EDT | MinEsReturn                 3
2017-06-03 15:34:15.147073 EDT | AverageDiscountedReturn    99.9957
2017-06-03 15:34:15.147313 EDT | AverageQLoss                5.04589e-05
2017-06-03 15:34:15.147579 EDT | AveragePolicySurr          -0.113013
2017-06-03 15:34:15.147820 EDT | AverageQ                    0.107561
2017-06-03 15:34:15.148055 EDT | AverageAbsQ                 0.107905
2017-06-03 15:34:15.148309 EDT | AverageY                    0.107558
2017-06-03 15:34:15.148550 EDT | AverageAbsY                 0.10758
2017-06-03 15:34:15.148783 EDT | AverageAbsQYDiff            0.002019
2017-06-03 15:34:15.149030 EDT | AverageAction               0.0665598
2017-06-03 15:34:15.149314 EDT | PolicyRegParamNorm         57.1561
2017-06-03 15:34:15.149568 EDT | QFunRegParamNorm           26.4463
2017-06-03 15:34:15.149844 EDT | -----------------------  --------------
2017-06-03 15:34:15.150372 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #353 | Training started
2017-06-03 15:34:33.490665 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #353 | Training finished
2017-06-03 15:34:33.491572 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #353 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 15:34:33.491938 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #353 | Collecting samples for evaluation
2017-06-03 15:34:42.839433 EDT | -----------------------  --------------
2017-06-03 15:34:42.841352 EDT | Epoch                     353
2017-06-03 15:34:42.841650 EDT | Iteration                 353
2017-06-03 15:34:42.841901 EDT | AverageReturn            1000
2017-06-03 15:34:42.842137 EDT | StdReturn                   0
2017-06-03 15:34:42.842399 EDT | MaxReturn                1000
2017-06-03 15:34:42.842642 EDT | MinReturn                1000
2017-06-03 15:34:42.842908 EDT | AverageEsReturn            35.963
2017-06-03 15:34:42.843142 EDT | StdEsReturn                24.7019
2017-06-03 15:34:42.843371 EDT | MaxEsReturn                89
2017-06-03 15:34:42.843598 EDT | MinEsReturn                 3
2017-06-03 15:34:42.843854 EDT | AverageDiscountedReturn    99.9957
2017-06-03 15:34:42.844082 EDT | AverageQLoss                4.87792e-05
2017-06-03 15:34:42.844308 EDT | AveragePolicySurr          -0.112799
2017-06-03 15:34:42.844536 EDT | AverageQ                    0.107322
2017-06-03 15:34:42.844785 EDT | AverageAbsQ                 0.10763
2017-06-03 15:34:42.845039 EDT | AverageY                    0.107323
2017-06-03 15:34:42.845280 EDT | AverageAbsY                 0.107353
2017-06-03 15:34:42.845534 EDT | AverageAbsQYDiff            0.00196189
2017-06-03 15:34:42.846339 EDT | AverageAction               0.0878352
2017-06-03 15:34:42.846658 EDT | PolicyRegParamNorm         57.1605
2017-06-03 15:34:42.846986 EDT | QFunRegParamNorm           26.4665
2017-06-03 15:34:42.847297 EDT | -----------------------  --------------
2017-06-03 15:34:42.847741 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #354 | Training started
2017-06-03 15:35:01.068663 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #354 | Training finished
2017-06-03 15:35:01.069662 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #354 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 15:35:01.070036 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #354 | Collecting samples for evaluation
2017-06-03 15:35:11.153453 EDT | -----------------------  --------------
2017-06-03 15:35:11.154474 EDT | Epoch                     354
2017-06-03 15:35:11.154735 EDT | Iteration                 354
2017-06-03 15:35:11.154969 EDT | AverageReturn            1000
2017-06-03 15:35:11.155203 EDT | StdReturn                   0
2017-06-03 15:35:11.155442 EDT | MaxReturn                1000
2017-06-03 15:35:11.155667 EDT | MinReturn                1000
2017-06-03 15:35:11.155891 EDT | AverageEsReturn            27.3158
2017-06-03 15:35:11.156115 EDT | StdEsReturn                17.3237
2017-06-03 15:35:11.156338 EDT | MaxEsReturn                72
2017-06-03 15:35:11.156559 EDT | MinEsReturn                 3
2017-06-03 15:35:11.156781 EDT | AverageDiscountedReturn    99.9957
2017-06-03 15:35:11.157003 EDT | AverageQLoss                4.60285e-05
2017-06-03 15:35:11.157226 EDT | AveragePolicySurr          -0.112621
2017-06-03 15:35:11.157482 EDT | AverageQ                    0.107416
2017-06-03 15:35:11.158128 EDT | AverageAbsQ                 0.107751
2017-06-03 15:35:11.158462 EDT | AverageY                    0.107414
2017-06-03 15:35:11.158781 EDT | AverageAbsY                 0.107443
2017-06-03 15:35:11.159093 EDT | AverageAbsQYDiff            0.00182684
2017-06-03 15:35:11.159401 EDT | AverageAction               0.251655
2017-06-03 15:35:11.159706 EDT | PolicyRegParamNorm         57.1933
2017-06-03 15:35:11.160011 EDT | QFunRegParamNorm           26.4597
2017-06-03 15:35:11.160316 EDT | -----------------------  --------------
2017-06-03 15:35:11.160785 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #355 | Training started
2017-06-03 15:35:28.756145 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #355 | Training finished
2017-06-03 15:35:28.756502 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #355 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 15:35:28.756769 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #355 | Collecting samples for evaluation
2017-06-03 15:35:38.463327 EDT | -----------------------  --------------
2017-06-03 15:35:38.464193 EDT | Epoch                     355
2017-06-03 15:35:38.464452 EDT | Iteration                 355
2017-06-03 15:35:38.464689 EDT | AverageReturn            1000
2017-06-03 15:35:38.464921 EDT | StdReturn                   0
2017-06-03 15:35:38.465166 EDT | MaxReturn                1000
2017-06-03 15:35:38.465402 EDT | MinReturn                1000
2017-06-03 15:35:38.465629 EDT | AverageEsReturn            23.8333
2017-06-03 15:35:38.465892 EDT | StdEsReturn                19.0874
2017-06-03 15:35:38.466116 EDT | MaxEsReturn                98
2017-06-03 15:35:38.466335 EDT | MinEsReturn                 4
2017-06-03 15:35:38.466553 EDT | AverageDiscountedReturn    99.9957
2017-06-03 15:35:38.466776 EDT | AverageQLoss                4.56123e-05
2017-06-03 15:35:38.467017 EDT | AveragePolicySurr          -0.112296
2017-06-03 15:35:38.467239 EDT | AverageQ                    0.106922
2017-06-03 15:35:38.467461 EDT | AverageAbsQ                 0.107234
2017-06-03 15:35:38.467682 EDT | AverageY                    0.106926
2017-06-03 15:35:38.467903 EDT | AverageAbsY                 0.106949
2017-06-03 15:35:38.468133 EDT | AverageAbsQYDiff            0.00181606
2017-06-03 15:35:38.468355 EDT | AverageAction               0.0882902
2017-06-03 15:35:38.468576 EDT | PolicyRegParamNorm         57.2848
2017-06-03 15:35:38.468797 EDT | QFunRegParamNorm           26.4644
2017-06-03 15:35:38.469018 EDT | -----------------------  --------------
2017-06-03 15:35:38.469364 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #356 | Training started
2017-06-03 15:35:56.626720 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #356 | Training finished
2017-06-03 15:35:56.628698 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #356 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 15:35:56.629083 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #356 | Collecting samples for evaluation
2017-06-03 15:36:06.080122 EDT | -----------------------  --------------
2017-06-03 15:36:06.081174 EDT | Epoch                     356
2017-06-03 15:36:06.081464 EDT | Iteration                 356
2017-06-03 15:36:06.081712 EDT | AverageReturn            1000
2017-06-03 15:36:06.081950 EDT | StdReturn                   0
2017-06-03 15:36:06.082193 EDT | MaxReturn                1000
2017-06-03 15:36:06.082475 EDT | MinReturn                1000
2017-06-03 15:36:06.082716 EDT | AverageEsReturn            26.8108
2017-06-03 15:36:06.082950 EDT | StdEsReturn                23.9604
2017-06-03 15:36:06.083174 EDT | MaxEsReturn               127
2017-06-03 15:36:06.083397 EDT | MinEsReturn                 3
2017-06-03 15:36:06.083661 EDT | AverageDiscountedReturn    99.9957
2017-06-03 15:36:06.083900 EDT | AverageQLoss                3.82374e-05
2017-06-03 15:36:06.084131 EDT | AveragePolicySurr          -0.112172
2017-06-03 15:36:06.084359 EDT | AverageQ                    0.106943
2017-06-03 15:36:06.084588 EDT | AverageAbsQ                 0.107251
2017-06-03 15:36:06.084816 EDT | AverageY                    0.106941
2017-06-03 15:36:06.085099 EDT | AverageAbsY                 0.106958
2017-06-03 15:36:06.085343 EDT | AverageAbsQYDiff            0.00167853
2017-06-03 15:36:06.085565 EDT | AverageAction               0.0355159
2017-06-03 15:36:06.086461 EDT | PolicyRegParamNorm         57.3903
2017-06-03 15:36:06.086855 EDT | QFunRegParamNorm           26.4568
2017-06-03 15:36:06.087355 EDT | -----------------------  --------------
2017-06-03 15:36:06.088175 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #357 | Training started
2017-06-03 15:36:25.618954 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #357 | Training finished
2017-06-03 15:36:25.619810 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #357 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 15:36:25.620215 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #357 | Collecting samples for evaluation
2017-06-03 15:36:35.167208 EDT | -----------------------  -------------
2017-06-03 15:36:35.168120 EDT | Epoch                    357
2017-06-03 15:36:35.168401 EDT | Iteration                357
2017-06-03 15:36:35.168656 EDT | AverageReturn             66.9533
2017-06-03 15:36:35.168905 EDT | StdReturn                  1.91603
2017-06-03 15:36:35.169150 EDT | MaxReturn                 75
2017-06-03 15:36:35.169405 EDT | MinReturn                 63
2017-06-03 15:36:35.169654 EDT | AverageEsReturn           20.8542
2017-06-03 15:36:35.169912 EDT | StdEsReturn               15.6272
2017-06-03 15:36:35.170157 EDT | MaxEsReturn               68
2017-06-03 15:36:35.170398 EDT | MinEsReturn                5
2017-06-03 15:36:35.170639 EDT | AverageDiscountedReturn   48.9682
2017-06-03 15:36:35.170882 EDT | AverageQLoss               4.16942e-05
2017-06-03 15:36:35.171124 EDT | AveragePolicySurr         -0.111945
2017-06-03 15:36:35.171365 EDT | AverageQ                   0.106705
2017-06-03 15:36:35.171607 EDT | AverageAbsQ                0.10702
2017-06-03 15:36:35.171848 EDT | AverageY                   0.106703
2017-06-03 15:36:35.172088 EDT | AverageAbsY                0.10673
2017-06-03 15:36:35.172327 EDT | AverageAbsQYDiff           0.00176488
2017-06-03 15:36:35.172568 EDT | AverageAction              0.416265
2017-06-03 15:36:35.172805 EDT | PolicyRegParamNorm        57.4467
2017-06-03 15:36:35.173037 EDT | QFunRegParamNorm          26.4537
2017-06-03 15:36:35.173268 EDT | -----------------------  -------------
2017-06-03 15:36:35.173627 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #358 | Training started
2017-06-03 15:36:53.448209 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #358 | Training finished
2017-06-03 15:36:53.449172 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #358 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 15:36:53.449548 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #358 | Collecting samples for evaluation
2017-06-03 15:37:03.035996 EDT | -----------------------  --------------
2017-06-03 15:37:03.036861 EDT | Epoch                     358
2017-06-03 15:37:03.037131 EDT | Iteration                 358
2017-06-03 15:37:03.037375 EDT | AverageReturn            1000
2017-06-03 15:37:03.037659 EDT | StdReturn                   0
2017-06-03 15:37:03.037912 EDT | MaxReturn                1000
2017-06-03 15:37:03.038147 EDT | MinReturn                1000
2017-06-03 15:37:03.038383 EDT | AverageEsReturn            30.1875
2017-06-03 15:37:03.038664 EDT | StdEsReturn                23.025
2017-06-03 15:37:03.038907 EDT | MaxEsReturn                94
2017-06-03 15:37:03.039140 EDT | MinEsReturn                 3
2017-06-03 15:37:03.039376 EDT | AverageDiscountedReturn    99.9957
2017-06-03 15:37:03.039606 EDT | AverageQLoss                4.34271e-05
2017-06-03 15:37:03.039845 EDT | AveragePolicySurr          -0.11167
2017-06-03 15:37:03.040075 EDT | AverageQ                    0.106626
2017-06-03 15:37:03.040309 EDT | AverageAbsQ                 0.106971
2017-06-03 15:37:03.040538 EDT | AverageY                    0.106624
2017-06-03 15:37:03.040803 EDT | AverageAbsY                 0.106643
2017-06-03 15:37:03.041041 EDT | AverageAbsQYDiff            0.00178476
2017-06-03 15:37:03.041281 EDT | AverageAction               0.0744767
2017-06-03 15:37:03.041516 EDT | PolicyRegParamNorm         57.4805
2017-06-03 15:37:03.041763 EDT | QFunRegParamNorm           26.4577
2017-06-03 15:37:03.042048 EDT | -----------------------  --------------
2017-06-03 15:37:03.042430 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #359 | Training started
2017-06-03 15:37:21.538413 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #359 | Training finished
2017-06-03 15:37:21.541801 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #359 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 15:37:21.542165 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #359 | Collecting samples for evaluation
2017-06-03 15:37:32.830688 EDT | -----------------------  --------------
2017-06-03 15:37:32.831584 EDT | Epoch                     359
2017-06-03 15:37:32.831857 EDT | Iteration                 359
2017-06-03 15:37:32.832094 EDT | AverageReturn            1000
2017-06-03 15:37:32.832325 EDT | StdReturn                   0
2017-06-03 15:37:32.832554 EDT | MaxReturn                1000
2017-06-03 15:37:32.832791 EDT | MinReturn                1000
2017-06-03 15:37:32.833018 EDT | AverageEsReturn            29.7714
2017-06-03 15:37:32.833249 EDT | StdEsReturn                23.8448
2017-06-03 15:37:32.833475 EDT | MaxEsReturn                83
2017-06-03 15:37:32.833710 EDT | MinEsReturn                 3
2017-06-03 15:37:32.833941 EDT | AverageDiscountedReturn    99.9957
2017-06-03 15:37:32.834165 EDT | AverageQLoss                5.12392e-05
2017-06-03 15:37:32.834388 EDT | AveragePolicySurr          -0.111146
2017-06-03 15:37:32.834614 EDT | AverageQ                    0.105823
2017-06-03 15:37:32.834837 EDT | AverageAbsQ                 0.106175
2017-06-03 15:37:32.835061 EDT | AverageY                    0.105827
2017-06-03 15:37:32.835284 EDT | AverageAbsY                 0.105844
2017-06-03 15:37:32.835506 EDT | AverageAbsQYDiff            0.00197955
2017-06-03 15:37:32.835741 EDT | AverageAction               0.00566661
2017-06-03 15:37:32.835976 EDT | PolicyRegParamNorm         57.5433
2017-06-03 15:37:32.836198 EDT | QFunRegParamNorm           26.4904
2017-06-03 15:37:32.836419 EDT | -----------------------  --------------
2017-06-03 15:37:32.836789 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #360 | Training started
2017-06-03 15:37:52.257676 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #360 | Training finished
2017-06-03 15:37:52.258561 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #360 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 15:37:52.258834 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #360 | Collecting samples for evaluation
2017-06-03 15:38:02.551724 EDT | -----------------------  -------------
2017-06-03 15:38:02.552612 EDT | Epoch                    360
2017-06-03 15:38:02.552896 EDT | Iteration                360
2017-06-03 15:38:02.553154 EDT | AverageReturn             53.5668
2017-06-03 15:38:02.553411 EDT | StdReturn                  1.22783
2017-06-03 15:38:02.553643 EDT | MaxReturn                 58
2017-06-03 15:38:02.553904 EDT | MinReturn                 51
2017-06-03 15:38:02.554154 EDT | AverageEsReturn           32.8621
2017-06-03 15:38:02.554443 EDT | StdEsReturn               35.2398
2017-06-03 15:38:02.554665 EDT | MaxEsReturn              155
2017-06-03 15:38:02.554886 EDT | MinEsReturn                2
2017-06-03 15:38:02.555109 EDT | AverageDiscountedReturn   41.6254
2017-06-03 15:38:02.555339 EDT | AverageQLoss               4.84382e-05
2017-06-03 15:38:02.555559 EDT | AveragePolicySurr         -0.110909
2017-06-03 15:38:02.555800 EDT | AverageQ                   0.105718
2017-06-03 15:38:02.556167 EDT | AverageAbsQ                0.106043
2017-06-03 15:38:02.556556 EDT | AverageY                   0.105712
2017-06-03 15:38:02.556908 EDT | AverageAbsY                0.10574
2017-06-03 15:38:02.557265 EDT | AverageAbsQYDiff           0.0019472
2017-06-03 15:38:02.557656 EDT | AverageAction              0.425616
2017-06-03 15:38:02.558061 EDT | PolicyRegParamNorm        57.631
2017-06-03 15:38:02.558450 EDT | QFunRegParamNorm          26.4901
2017-06-03 15:38:02.558817 EDT | -----------------------  -------------
2017-06-03 15:38:02.559353 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #361 | Training started
2017-06-03 15:38:21.408337 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #361 | Training finished
2017-06-03 15:38:21.409310 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #361 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 15:38:21.409682 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #361 | Collecting samples for evaluation
2017-06-03 15:38:31.081995 EDT | -----------------------  -------------
2017-06-03 15:38:31.082576 EDT | Epoch                    361
2017-06-03 15:38:31.082914 EDT | Iteration                361
2017-06-03 15:38:31.083263 EDT | AverageReturn             45.1892
2017-06-03 15:38:31.083693 EDT | StdReturn                  0.493444
2017-06-03 15:38:31.084100 EDT | MaxReturn                 47
2017-06-03 15:38:31.084526 EDT | MinReturn                 44
2017-06-03 15:38:31.084850 EDT | AverageEsReturn           19.6226
2017-06-03 15:38:31.085273 EDT | StdEsReturn               15.8938
2017-06-03 15:38:31.085641 EDT | MaxEsReturn               63
2017-06-03 15:38:31.086006 EDT | MinEsReturn                3
2017-06-03 15:38:31.086424 EDT | AverageDiscountedReturn   36.5015
2017-06-03 15:38:31.086748 EDT | AverageQLoss               4.66006e-05
2017-06-03 15:38:31.087174 EDT | AveragePolicySurr         -0.110771
2017-06-03 15:38:31.087544 EDT | AverageQ                   0.105426
2017-06-03 15:38:31.087906 EDT | AverageAbsQ                0.105748
2017-06-03 15:38:31.088327 EDT | AverageY                   0.105426
2017-06-03 15:38:31.088650 EDT | AverageAbsY                0.105444
2017-06-03 15:38:31.089074 EDT | AverageAbsQYDiff           0.00182787
2017-06-03 15:38:31.089438 EDT | AverageAction              0.267534
2017-06-03 15:38:31.089790 EDT | PolicyRegParamNorm        57.6499
2017-06-03 15:38:31.090209 EDT | QFunRegParamNorm          26.5008
2017-06-03 15:38:31.090527 EDT | -----------------------  -------------
2017-06-03 15:38:31.091140 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #362 | Training started
2017-06-03 15:38:50.289657 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #362 | Training finished
2017-06-03 15:38:50.290578 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #362 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 15:38:50.290851 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #362 | Collecting samples for evaluation
2017-06-03 15:38:59.461392 EDT | -----------------------  -------------
2017-06-03 15:38:59.461945 EDT | Epoch                    362
2017-06-03 15:38:59.462225 EDT | Iteration                362
2017-06-03 15:38:59.462490 EDT | AverageReturn             44.9462
2017-06-03 15:38:59.462749 EDT | StdReturn                  0.294602
2017-06-03 15:38:59.463016 EDT | MaxReturn                 46
2017-06-03 15:38:59.463274 EDT | MinReturn                 44
2017-06-03 15:38:59.463532 EDT | AverageEsReturn           16.3443
2017-06-03 15:38:59.463788 EDT | StdEsReturn               14.9072
2017-06-03 15:38:59.464045 EDT | MaxEsReturn               56
2017-06-03 15:38:59.464300 EDT | MinEsReturn                3
2017-06-03 15:38:59.464554 EDT | AverageDiscountedReturn   36.3468
2017-06-03 15:38:59.464808 EDT | AverageQLoss               4.68786e-05
2017-06-03 15:38:59.465062 EDT | AveragePolicySurr         -0.110529
2017-06-03 15:38:59.465318 EDT | AverageQ                   0.10521
2017-06-03 15:38:59.465572 EDT | AverageAbsQ                0.105519
2017-06-03 15:38:59.465854 EDT | AverageY                   0.105208
2017-06-03 15:38:59.466114 EDT | AverageAbsY                0.105227
2017-06-03 15:38:59.466370 EDT | AverageAbsQYDiff           0.00182297
2017-06-03 15:38:59.466623 EDT | AverageAction              0.160064
2017-06-03 15:38:59.466878 EDT | PolicyRegParamNorm        57.6933
2017-06-03 15:38:59.467130 EDT | QFunRegParamNorm          26.5035
2017-06-03 15:38:59.467384 EDT | -----------------------  -------------
2017-06-03 15:38:59.467916 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #363 | Training started
2017-06-03 15:39:17.592706 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #363 | Training finished
2017-06-03 15:39:17.595762 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #363 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 15:39:17.596086 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #363 | Collecting samples for evaluation
2017-06-03 15:39:27.943332 EDT | -----------------------  -------------
2017-06-03 15:39:27.944205 EDT | Epoch                    363
2017-06-03 15:39:27.944560 EDT | Iteration                363
2017-06-03 15:39:27.944888 EDT | AverageReturn             58.7485
2017-06-03 15:39:27.945215 EDT | StdReturn                  0.911868
2017-06-03 15:39:27.945540 EDT | MaxReturn                 61
2017-06-03 15:39:27.945880 EDT | MinReturn                 57
2017-06-03 15:39:27.946203 EDT | AverageEsReturn           21.7727
2017-06-03 15:39:27.946525 EDT | StdEsReturn               19.5493
2017-06-03 15:39:27.946850 EDT | MaxEsReturn              100
2017-06-03 15:39:27.947175 EDT | MinEsReturn                3
2017-06-03 15:39:27.947488 EDT | AverageDiscountedReturn   44.5895
2017-06-03 15:39:27.947806 EDT | AverageQLoss               4.29487e-05
2017-06-03 15:39:27.948166 EDT | AveragePolicySurr         -0.110296
2017-06-03 15:39:27.948479 EDT | AverageQ                   0.105055
2017-06-03 15:39:27.948789 EDT | AverageAbsQ                0.105422
2017-06-03 15:39:27.949112 EDT | AverageY                   0.105057
2017-06-03 15:39:27.949448 EDT | AverageAbsY                0.105076
2017-06-03 15:39:27.949770 EDT | AverageAbsQYDiff           0.00185634
2017-06-03 15:39:27.950084 EDT | AverageAction              0.326083
2017-06-03 15:39:27.950425 EDT | PolicyRegParamNorm        57.7555
2017-06-03 15:39:27.950739 EDT | QFunRegParamNorm          26.5105
2017-06-03 15:39:27.951056 EDT | -----------------------  -------------
2017-06-03 15:39:27.951499 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #364 | Training started
2017-06-03 15:39:45.877903 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #364 | Training finished
2017-06-03 15:39:45.878812 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #364 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 15:39:45.879199 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #364 | Collecting samples for evaluation
2017-06-03 15:39:54.944721 EDT | -----------------------  --------------
2017-06-03 15:39:54.945597 EDT | Epoch                     364
2017-06-03 15:39:54.946005 EDT | Iteration                 364
2017-06-03 15:39:54.946384 EDT | AverageReturn            1000
2017-06-03 15:39:54.946731 EDT | StdReturn                   0
2017-06-03 15:39:54.947049 EDT | MaxReturn                1000
2017-06-03 15:39:54.947437 EDT | MinReturn                1000
2017-06-03 15:39:54.947770 EDT | AverageEsReturn            38
2017-06-03 15:39:54.948116 EDT | StdEsReturn                37.73
2017-06-03 15:39:54.948457 EDT | MaxEsReturn               152
2017-06-03 15:39:54.948796 EDT | MinEsReturn                 4
2017-06-03 15:39:54.949123 EDT | AverageDiscountedReturn    99.9957
2017-06-03 15:39:54.949438 EDT | AverageQLoss                3.84263e-05
2017-06-03 15:39:54.949775 EDT | AveragePolicySurr          -0.109845
2017-06-03 15:39:54.950094 EDT | AverageQ                    0.104559
2017-06-03 15:39:54.950406 EDT | AverageAbsQ                 0.104898
2017-06-03 15:39:54.950718 EDT | AverageY                    0.104553
2017-06-03 15:39:54.951046 EDT | AverageAbsY                 0.104584
2017-06-03 15:39:54.951359 EDT | AverageAbsQYDiff            0.00174279
2017-06-03 15:39:54.951684 EDT | AverageAction               0.000412299
2017-06-03 15:39:54.951996 EDT | PolicyRegParamNorm         57.7946
2017-06-03 15:39:54.952306 EDT | QFunRegParamNorm           26.5046
2017-06-03 15:39:54.952623 EDT | -----------------------  --------------
2017-06-03 15:39:54.953105 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #365 | Training started
2017-06-03 15:40:13.598029 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #365 | Training finished
2017-06-03 15:40:13.601086 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #365 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 15:40:13.601449 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #365 | Collecting samples for evaluation
2017-06-03 15:40:23.511374 EDT | -----------------------  --------------
2017-06-03 15:40:23.512253 EDT | Epoch                     365
2017-06-03 15:40:23.512522 EDT | Iteration                 365
2017-06-03 15:40:23.512758 EDT | AverageReturn            1000
2017-06-03 15:40:23.513008 EDT | StdReturn                   0
2017-06-03 15:40:23.513243 EDT | MaxReturn                1000
2017-06-03 15:40:23.513472 EDT | MinReturn                1000
2017-06-03 15:40:23.513708 EDT | AverageEsReturn            29.1429
2017-06-03 15:40:23.513941 EDT | StdEsReturn                27.5672
2017-06-03 15:40:23.514169 EDT | MaxEsReturn               131
2017-06-03 15:40:23.514398 EDT | MinEsReturn                 5
2017-06-03 15:40:23.514634 EDT | AverageDiscountedReturn    99.9957
2017-06-03 15:40:23.514893 EDT | AverageQLoss                3.74563e-05
2017-06-03 15:40:23.515120 EDT | AveragePolicySurr          -0.10996
2017-06-03 15:40:23.515346 EDT | AverageQ                    0.10482
2017-06-03 15:40:23.515571 EDT | AverageAbsQ                 0.105116
2017-06-03 15:40:23.515797 EDT | AverageY                    0.104824
2017-06-03 15:40:23.516031 EDT | AverageAbsY                 0.10485
2017-06-03 15:40:23.516257 EDT | AverageAbsQYDiff            0.00164714
2017-06-03 15:40:23.516483 EDT | AverageAction               0.105456
2017-06-03 15:40:23.516708 EDT | PolicyRegParamNorm         57.852
2017-06-03 15:40:23.516933 EDT | QFunRegParamNorm           26.5007
2017-06-03 15:40:23.517157 EDT | -----------------------  --------------
2017-06-03 15:40:23.517506 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #366 | Training started
2017-06-03 15:40:42.587808 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #366 | Training finished
2017-06-03 15:40:42.588842 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #366 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 15:40:42.589117 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #366 | Collecting samples for evaluation
2017-06-03 15:40:52.158771 EDT | -----------------------  --------------
2017-06-03 15:40:52.159632 EDT | Epoch                     366
2017-06-03 15:40:52.159893 EDT | Iteration                 366
2017-06-03 15:40:52.160134 EDT | AverageReturn            1000
2017-06-03 15:40:52.160384 EDT | StdReturn                   0
2017-06-03 15:40:52.160626 EDT | MaxReturn                1000
2017-06-03 15:40:52.160869 EDT | MinReturn                1000
2017-06-03 15:40:52.161102 EDT | AverageEsReturn            29.0294
2017-06-03 15:40:52.161335 EDT | StdEsReturn                23.3924
2017-06-03 15:40:52.161588 EDT | MaxEsReturn                75
2017-06-03 15:40:52.161833 EDT | MinEsReturn                 4
2017-06-03 15:40:52.162075 EDT | AverageDiscountedReturn    99.9957
2017-06-03 15:40:52.162309 EDT | AverageQLoss                4.14219e-05
2017-06-03 15:40:52.162561 EDT | AveragePolicySurr          -0.10928
2017-06-03 15:40:52.162794 EDT | AverageQ                    0.104368
2017-06-03 15:40:52.163025 EDT | AverageAbsQ                 0.104672
2017-06-03 15:40:52.163256 EDT | AverageY                    0.104372
2017-06-03 15:40:52.163487 EDT | AverageAbsY                 0.104397
2017-06-03 15:40:52.163739 EDT | AverageAbsQYDiff            0.00171333
2017-06-03 15:40:52.163970 EDT | AverageAction               0.0133022
2017-06-03 15:40:52.164201 EDT | PolicyRegParamNorm         57.8685
2017-06-03 15:40:52.164430 EDT | QFunRegParamNorm           26.5141
2017-06-03 15:40:52.164681 EDT | -----------------------  --------------
2017-06-03 15:40:52.165075 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #367 | Training started
2017-06-03 15:41:10.609493 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #367 | Training finished
2017-06-03 15:41:10.610361 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #367 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 15:41:10.610621 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #367 | Collecting samples for evaluation
2017-06-03 15:41:20.497685 EDT | -----------------------  -------------
2017-06-03 15:41:20.498549 EDT | Epoch                     367
2017-06-03 15:41:20.498812 EDT | Iteration                 367
2017-06-03 15:41:20.499049 EDT | AverageReturn            1000
2017-06-03 15:41:20.499289 EDT | StdReturn                   0
2017-06-03 15:41:20.499518 EDT | MaxReturn                1000
2017-06-03 15:41:20.499745 EDT | MinReturn                1000
2017-06-03 15:41:20.499974 EDT | AverageEsReturn            23.6047
2017-06-03 15:41:20.500229 EDT | StdEsReturn                17.1154
2017-06-03 15:41:20.500460 EDT | MaxEsReturn                80
2017-06-03 15:41:20.500689 EDT | MinEsReturn                 3
2017-06-03 15:41:20.500915 EDT | AverageDiscountedReturn    99.9957
2017-06-03 15:41:20.501141 EDT | AverageQLoss                4.6386e-05
2017-06-03 15:41:20.501380 EDT | AveragePolicySurr          -0.10932
2017-06-03 15:41:20.501611 EDT | AverageQ                    0.104059
2017-06-03 15:41:20.501881 EDT | AverageAbsQ                 0.104487
2017-06-03 15:41:20.502120 EDT | AverageY                    0.104056
2017-06-03 15:41:20.502361 EDT | AverageAbsY                 0.104095
2017-06-03 15:41:20.502603 EDT | AverageAbsQYDiff            0.00196022
2017-06-03 15:41:20.502844 EDT | AverageAction               0.0559002
2017-06-03 15:41:20.503109 EDT | PolicyRegParamNorm         57.9156
2017-06-03 15:41:20.503353 EDT | QFunRegParamNorm           26.517
2017-06-03 15:41:20.503594 EDT | -----------------------  -------------
2017-06-03 15:41:20.503953 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #368 | Training started
2017-06-03 15:41:39.801606 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #368 | Training finished
2017-06-03 15:41:39.803925 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #368 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 15:41:39.804480 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #368 | Collecting samples for evaluation
2017-06-03 15:41:49.228635 EDT | -----------------------  --------------
2017-06-03 15:41:49.229515 EDT | Epoch                     368
2017-06-03 15:41:49.229796 EDT | Iteration                 368
2017-06-03 15:41:49.230072 EDT | AverageReturn            1000
2017-06-03 15:41:49.230311 EDT | StdReturn                   0
2017-06-03 15:41:49.230547 EDT | MaxReturn                1000
2017-06-03 15:41:49.230783 EDT | MinReturn                1000
2017-06-03 15:41:49.231052 EDT | AverageEsReturn            24.125
2017-06-03 15:41:49.231291 EDT | StdEsReturn                23.7867
2017-06-03 15:41:49.231524 EDT | MaxEsReturn               106
2017-06-03 15:41:49.231777 EDT | MinEsReturn                 4
2017-06-03 15:41:49.232029 EDT | AverageDiscountedReturn    99.9957
2017-06-03 15:41:49.232263 EDT | AverageQLoss                4.43291e-05
2017-06-03 15:41:49.232496 EDT | AveragePolicySurr          -0.108937
2017-06-03 15:41:49.232728 EDT | AverageQ                    0.103807
2017-06-03 15:41:49.232968 EDT | AverageAbsQ                 0.104152
2017-06-03 15:41:49.233220 EDT | AverageY                    0.103801
2017-06-03 15:41:49.233451 EDT | AverageAbsY                 0.103842
2017-06-03 15:41:49.233682 EDT | AverageAbsQYDiff            0.00180684
2017-06-03 15:41:49.233936 EDT | AverageAction               0.142974
2017-06-03 15:41:49.234189 EDT | PolicyRegParamNorm         57.9601
2017-06-03 15:41:49.234422 EDT | QFunRegParamNorm           26.5472
2017-06-03 15:41:49.234651 EDT | -----------------------  --------------
2017-06-03 15:41:49.235003 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #369 | Training started
2017-06-03 15:42:08.800180 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #369 | Training finished
2017-06-03 15:42:08.801087 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #369 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 15:42:08.801361 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #369 | Collecting samples for evaluation
2017-06-03 15:42:17.805483 EDT | -----------------------  --------------
2017-06-03 15:42:17.805893 EDT | Epoch                     369
2017-06-03 15:42:17.806143 EDT | Iteration                 369
2017-06-03 15:42:17.806396 EDT | AverageReturn            1000
2017-06-03 15:42:17.806631 EDT | StdReturn                   0
2017-06-03 15:42:17.806863 EDT | MaxReturn                1000
2017-06-03 15:42:17.807094 EDT | MinReturn                1000
2017-06-03 15:42:17.807324 EDT | AverageEsReturn            28.4242
2017-06-03 15:42:17.807556 EDT | StdEsReturn                31.023
2017-06-03 15:42:17.807787 EDT | MaxEsReturn               123
2017-06-03 15:42:17.808017 EDT | MinEsReturn                 3
2017-06-03 15:42:17.808246 EDT | AverageDiscountedReturn    99.9957
2017-06-03 15:42:17.808476 EDT | AverageQLoss                4.69998e-05
2017-06-03 15:42:17.808706 EDT | AveragePolicySurr          -0.108616
2017-06-03 15:42:17.808936 EDT | AverageQ                    0.103334
2017-06-03 15:42:17.809211 EDT | AverageAbsQ                 0.103633
2017-06-03 15:42:17.809443 EDT | AverageY                    0.103339
2017-06-03 15:42:17.809674 EDT | AverageAbsY                 0.103398
2017-06-03 15:42:17.809982 EDT | AverageAbsQYDiff            0.00177671
2017-06-03 15:42:17.810214 EDT | AverageAction               0.00790722
2017-06-03 15:42:17.810445 EDT | PolicyRegParamNorm         58.0209
2017-06-03 15:42:17.810674 EDT | QFunRegParamNorm           26.5413
2017-06-03 15:42:17.810911 EDT | -----------------------  --------------
2017-06-03 15:42:17.811303 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #370 | Training started
2017-06-03 15:42:36.894800 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #370 | Training finished
2017-06-03 15:42:36.895764 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #370 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 15:42:36.896108 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #370 | Collecting samples for evaluation
2017-06-03 15:42:47.051761 EDT | -----------------------  --------------
2017-06-03 15:42:47.052166 EDT | Epoch                     370
2017-06-03 15:42:47.052422 EDT | Iteration                 370
2017-06-03 15:42:47.052666 EDT | AverageReturn             252.093
2017-06-03 15:42:47.052906 EDT | StdReturn                 384.803
2017-06-03 15:42:47.053160 EDT | MaxReturn                1000
2017-06-03 15:42:47.053415 EDT | MinReturn                  52
2017-06-03 15:42:47.053648 EDT | AverageEsReturn            18.0492
2017-06-03 15:42:47.053898 EDT | StdEsReturn                16.8264
2017-06-03 15:42:47.054131 EDT | MaxEsReturn               103
2017-06-03 15:42:47.054419 EDT | MinEsReturn                 3
2017-06-03 15:42:47.054667 EDT | AverageDiscountedReturn    54.0831
2017-06-03 15:42:47.054914 EDT | AverageQLoss                4.70926e-05
2017-06-03 15:42:47.055155 EDT | AveragePolicySurr          -0.10856
2017-06-03 15:42:47.055397 EDT | AverageQ                    0.103216
2017-06-03 15:42:47.055648 EDT | AverageAbsQ                 0.103541
2017-06-03 15:42:47.055889 EDT | AverageY                    0.103208
2017-06-03 15:42:47.056129 EDT | AverageAbsY                 0.103263
2017-06-03 15:42:47.056368 EDT | AverageAbsQYDiff            0.0017825
2017-06-03 15:42:47.056606 EDT | AverageAction               0.0814523
2017-06-03 15:42:47.056846 EDT | PolicyRegParamNorm         58.0693
2017-06-03 15:42:47.057086 EDT | QFunRegParamNorm           26.5511
2017-06-03 15:42:47.057334 EDT | -----------------------  --------------
2017-06-03 15:42:47.057832 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #371 | Training started
2017-06-03 15:43:08.205726 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #371 | Training finished
2017-06-03 15:43:08.206626 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #371 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 15:43:08.206896 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #371 | Collecting samples for evaluation
2017-06-03 15:43:17.470588 EDT | -----------------------  ------------
2017-06-03 15:43:17.470965 EDT | Epoch                    371
2017-06-03 15:43:17.471223 EDT | Iteration                371
2017-06-03 15:43:17.471464 EDT | AverageReturn             47.4265
2017-06-03 15:43:17.471702 EDT | StdReturn                  0.494574
2017-06-03 15:43:17.471938 EDT | MaxReturn                 48
2017-06-03 15:43:17.472172 EDT | MinReturn                 47
2017-06-03 15:43:17.472411 EDT | AverageEsReturn           24.925
2017-06-03 15:43:17.472645 EDT | StdEsReturn               16.0832
2017-06-03 15:43:17.472880 EDT | MaxEsReturn               71
2017-06-03 15:43:17.473114 EDT | MinEsReturn                2
2017-06-03 15:43:17.473346 EDT | AverageDiscountedReturn   37.9134
2017-06-03 15:43:17.473578 EDT | AverageQLoss               4.8536e-05
2017-06-03 15:43:17.473841 EDT | AveragePolicySurr         -0.108206
2017-06-03 15:43:17.474077 EDT | AverageQ                   0.102861
2017-06-03 15:43:17.474313 EDT | AverageAbsQ                0.103333
2017-06-03 15:43:17.474545 EDT | AverageY                   0.102872
2017-06-03 15:43:17.474776 EDT | AverageAbsY                0.102928
2017-06-03 15:43:17.475019 EDT | AverageAbsQYDiff           0.00203312
2017-06-03 15:43:17.475251 EDT | AverageAction              0.0863327
2017-06-03 15:43:17.475482 EDT | PolicyRegParamNorm        58.1131
2017-06-03 15:43:17.475713 EDT | QFunRegParamNorm          26.5403
2017-06-03 15:43:17.475943 EDT | -----------------------  ------------
2017-06-03 15:43:17.476332 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #372 | Training started
2017-06-03 15:43:36.738345 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #372 | Training finished
2017-06-03 15:43:36.746493 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #372 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 15:43:36.747052 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #372 | Collecting samples for evaluation
2017-06-03 15:43:46.290953 EDT | -----------------------  -------------
2017-06-03 15:43:46.291323 EDT | Epoch                    372
2017-06-03 15:43:46.291605 EDT | Iteration                372
2017-06-03 15:43:46.291888 EDT | AverageReturn             55.1319
2017-06-03 15:43:46.292229 EDT | StdReturn                  0.424751
2017-06-03 15:43:46.292561 EDT | MaxReturn                 56
2017-06-03 15:43:46.292842 EDT | MinReturn                 54
2017-06-03 15:43:46.293125 EDT | AverageEsReturn           21.0426
2017-06-03 15:43:46.293460 EDT | StdEsReturn               13.9573
2017-06-03 15:43:46.293790 EDT | MaxEsReturn               52
2017-06-03 15:43:46.294064 EDT | MinEsReturn                3
2017-06-03 15:43:46.294354 EDT | AverageDiscountedReturn   42.5402
2017-06-03 15:43:46.294687 EDT | AverageQLoss               3.87743e-05
2017-06-03 15:43:46.294997 EDT | AveragePolicySurr         -0.108084
2017-06-03 15:43:46.295268 EDT | AverageQ                   0.102914
2017-06-03 15:43:46.295568 EDT | AverageAbsQ                0.103211
2017-06-03 15:43:46.295902 EDT | AverageY                   0.102913
2017-06-03 15:43:46.296207 EDT | AverageAbsY                0.102976
2017-06-03 15:43:46.296483 EDT | AverageAbsQYDiff           0.00172025
2017-06-03 15:43:46.296797 EDT | AverageAction              0.195858
2017-06-03 15:43:46.297127 EDT | PolicyRegParamNorm        58.1542
2017-06-03 15:43:46.297413 EDT | QFunRegParamNorm          26.5451
2017-06-03 15:43:46.297689 EDT | -----------------------  -------------
2017-06-03 15:43:46.298188 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #373 | Training started
2017-06-03 15:44:05.694867 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #373 | Training finished
2017-06-03 15:44:05.697037 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #373 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 15:44:05.697642 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #373 | Collecting samples for evaluation
2017-06-03 15:44:15.742775 EDT | -----------------------  --------------
2017-06-03 15:44:15.743688 EDT | Epoch                     373
2017-06-03 15:44:15.743969 EDT | Iteration                 373
2017-06-03 15:44:15.744208 EDT | AverageReturn            1000
2017-06-03 15:44:15.744441 EDT | StdReturn                   0
2017-06-03 15:44:15.744671 EDT | MaxReturn                1000
2017-06-03 15:44:15.744913 EDT | MinReturn                1000
2017-06-03 15:44:15.745161 EDT | AverageEsReturn            29.2059
2017-06-03 15:44:15.745389 EDT | StdEsReturn                24.7443
2017-06-03 15:44:15.745616 EDT | MaxEsReturn               137
2017-06-03 15:44:15.745871 EDT | MinEsReturn                 4
2017-06-03 15:44:15.746101 EDT | AverageDiscountedReturn    99.9957
2017-06-03 15:44:15.746330 EDT | AverageQLoss                3.98551e-05
2017-06-03 15:44:15.746571 EDT | AveragePolicySurr          -0.107722
2017-06-03 15:44:15.746798 EDT | AverageQ                    0.102674
2017-06-03 15:44:15.747024 EDT | AverageAbsQ                 0.10302
2017-06-03 15:44:15.747249 EDT | AverageY                    0.102675
2017-06-03 15:44:15.747484 EDT | AverageAbsY                 0.102742
2017-06-03 15:44:15.747720 EDT | AverageAbsQYDiff            0.00177981
2017-06-03 15:44:15.747952 EDT | AverageAction               0.00145038
2017-06-03 15:44:15.748180 EDT | PolicyRegParamNorm         58.1579
2017-06-03 15:44:15.748406 EDT | QFunRegParamNorm           26.5446
2017-06-03 15:44:15.748638 EDT | -----------------------  --------------
2017-06-03 15:44:15.749141 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #374 | Training started
2017-06-03 15:44:34.317020 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #374 | Training finished
2017-06-03 15:44:34.317862 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #374 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 15:44:34.318133 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #374 | Collecting samples for evaluation
2017-06-03 15:44:43.881945 EDT | -----------------------  --------------
2017-06-03 15:44:43.882877 EDT | Epoch                     374
2017-06-03 15:44:43.883228 EDT | Iteration                 374
2017-06-03 15:44:43.883577 EDT | AverageReturn            1000
2017-06-03 15:44:43.883899 EDT | StdReturn                   0
2017-06-03 15:44:43.884229 EDT | MaxReturn                1000
2017-06-03 15:44:43.884541 EDT | MinReturn                1000
2017-06-03 15:44:43.884884 EDT | AverageEsReturn            35.9643
2017-06-03 15:44:43.885180 EDT | StdEsReturn                38.448
2017-06-03 15:44:43.885518 EDT | MaxEsReturn               161
2017-06-03 15:44:43.885825 EDT | MinEsReturn                 3
2017-06-03 15:44:43.886165 EDT | AverageDiscountedReturn    99.9957
2017-06-03 15:44:43.886471 EDT | AverageQLoss                4.39804e-05
2017-06-03 15:44:43.886806 EDT | AveragePolicySurr          -0.107522
2017-06-03 15:44:43.887100 EDT | AverageQ                    0.102379
2017-06-03 15:44:43.887434 EDT | AverageAbsQ                 0.102797
2017-06-03 15:44:43.887740 EDT | AverageY                    0.102373
2017-06-03 15:44:43.888070 EDT | AverageAbsY                 0.102452
2017-06-03 15:44:43.888404 EDT | AverageAbsQYDiff            0.00189638
2017-06-03 15:44:43.888738 EDT | AverageAction               0.000262954
2017-06-03 15:44:43.889055 EDT | PolicyRegParamNorm         58.1967
2017-06-03 15:44:43.889388 EDT | QFunRegParamNorm           26.5406
2017-06-03 15:44:43.889767 EDT | -----------------------  --------------
2017-06-03 15:44:43.890248 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #375 | Training started
2017-06-03 15:45:03.708470 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #375 | Training finished
2017-06-03 15:45:03.709440 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #375 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 15:45:03.709863 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #375 | Collecting samples for evaluation
2017-06-03 15:45:13.846464 EDT | -----------------------  -------------
2017-06-03 15:45:13.847326 EDT | Epoch                    375
2017-06-03 15:45:13.847599 EDT | Iteration                375
2017-06-03 15:45:13.847842 EDT | AverageReturn             55.5833
2017-06-03 15:45:13.848096 EDT | StdReturn                  0.493007
2017-06-03 15:45:13.848350 EDT | MaxReturn                 56
2017-06-03 15:45:13.848607 EDT | MinReturn                 55
2017-06-03 15:45:13.848878 EDT | AverageEsReturn           26.0789
2017-06-03 15:45:13.849127 EDT | StdEsReturn               19.6621
2017-06-03 15:45:13.849374 EDT | MaxEsReturn               67
2017-06-03 15:45:13.849621 EDT | MinEsReturn                4
2017-06-03 15:45:13.849941 EDT | AverageDiscountedReturn   42.8001
2017-06-03 15:45:13.850191 EDT | AverageQLoss               4.46061e-05
2017-06-03 15:45:13.850436 EDT | AveragePolicySurr         -0.107036
2017-06-03 15:45:13.850685 EDT | AverageQ                   0.101903
2017-06-03 15:45:13.850931 EDT | AverageAbsQ                0.102332
2017-06-03 15:45:13.851175 EDT | AverageY                   0.101904
2017-06-03 15:45:13.851424 EDT | AverageAbsY                0.101986
2017-06-03 15:45:13.851690 EDT | AverageAbsQYDiff           0.00194684
2017-06-03 15:45:13.851934 EDT | AverageAction              0.178993
2017-06-03 15:45:13.852177 EDT | PolicyRegParamNorm        58.2343
2017-06-03 15:45:13.852419 EDT | QFunRegParamNorm          26.5347
2017-06-03 15:45:13.852670 EDT | -----------------------  -------------
2017-06-03 15:45:13.853109 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #376 | Training started
2017-06-03 15:45:32.642962 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #376 | Training finished
2017-06-03 15:45:32.643981 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #376 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 15:45:32.644384 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #376 | Collecting samples for evaluation
2017-06-03 15:45:42.182782 EDT | -----------------------  --------------
2017-06-03 15:45:42.183682 EDT | Epoch                     376
2017-06-03 15:45:42.183952 EDT | Iteration                 376
2017-06-03 15:45:42.184204 EDT | AverageReturn            1000
2017-06-03 15:45:42.184452 EDT | StdReturn                   0
2017-06-03 15:45:42.184697 EDT | MaxReturn                1000
2017-06-03 15:45:42.184941 EDT | MinReturn                1000
2017-06-03 15:45:42.185192 EDT | AverageEsReturn            24.7561
2017-06-03 15:45:42.185438 EDT | StdEsReturn                16.532
2017-06-03 15:45:42.185680 EDT | MaxEsReturn                61
2017-06-03 15:45:42.185936 EDT | MinEsReturn                 3
2017-06-03 15:45:42.186179 EDT | AverageDiscountedReturn    99.9957
2017-06-03 15:45:42.186428 EDT | AverageQLoss                4.09951e-05
2017-06-03 15:45:42.186698 EDT | AveragePolicySurr          -0.106908
2017-06-03 15:45:42.186939 EDT | AverageQ                    0.101746
2017-06-03 15:45:42.187181 EDT | AverageAbsQ                 0.102097
2017-06-03 15:45:42.187421 EDT | AverageY                    0.101745
2017-06-03 15:45:42.187662 EDT | AverageAbsY                 0.101814
2017-06-03 15:45:42.187910 EDT | AverageAbsQYDiff            0.00172788
2017-06-03 15:45:42.188150 EDT | AverageAction               0.00952259
2017-06-03 15:45:42.188388 EDT | PolicyRegParamNorm         58.3005
2017-06-03 15:45:42.188636 EDT | QFunRegParamNorm           26.5322
2017-06-03 15:45:42.188873 EDT | -----------------------  --------------
2017-06-03 15:45:42.189259 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #377 | Training started
2017-06-03 15:46:02.377329 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #377 | Training finished
2017-06-03 15:46:02.378280 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #377 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 15:46:02.378579 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #377 | Collecting samples for evaluation
2017-06-03 15:46:12.726362 EDT | -----------------------  -------------
2017-06-03 15:46:12.727211 EDT | Epoch                    377
2017-06-03 15:46:12.727474 EDT | Iteration                377
2017-06-03 15:46:12.727716 EDT | AverageReturn             48.0769
2017-06-03 15:46:12.727967 EDT | StdReturn                  0.266469
2017-06-03 15:46:12.728195 EDT | MaxReturn                 49
2017-06-03 15:46:12.728420 EDT | MinReturn                 48
2017-06-03 15:46:12.728645 EDT | AverageEsReturn           21.8261
2017-06-03 15:46:12.728879 EDT | StdEsReturn               15.4037
2017-06-03 15:46:12.729103 EDT | MaxEsReturn               58
2017-06-03 15:46:12.729325 EDT | MinEsReturn                3
2017-06-03 15:46:12.729548 EDT | AverageDiscountedReturn   38.3185
2017-06-03 15:46:12.729781 EDT | AverageQLoss               3.40386e-05
2017-06-03 15:46:12.730005 EDT | AveragePolicySurr         -0.106722
2017-06-03 15:46:12.730227 EDT | AverageQ                   0.101445
2017-06-03 15:46:12.730449 EDT | AverageAbsQ                0.101781
2017-06-03 15:46:12.730670 EDT | AverageY                   0.101444
2017-06-03 15:46:12.730891 EDT | AverageAbsY                0.101524
2017-06-03 15:46:12.731112 EDT | AverageAbsQYDiff           0.0015526
2017-06-03 15:46:12.731333 EDT | AverageAction              0.27463
2017-06-03 15:46:12.731617 EDT | PolicyRegParamNorm        58.384
2017-06-03 15:46:12.731849 EDT | QFunRegParamNorm          26.5514
2017-06-03 15:46:12.732074 EDT | -----------------------  -------------
2017-06-03 15:46:12.732458 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #378 | Training started
2017-06-03 15:46:30.498242 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #378 | Training finished
2017-06-03 15:46:30.499258 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #378 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 15:46:30.499654 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #378 | Collecting samples for evaluation
2017-06-03 15:46:39.875468 EDT | -----------------------  --------------
2017-06-03 15:46:39.876390 EDT | Epoch                     378
2017-06-03 15:46:39.876686 EDT | Iteration                 378
2017-06-03 15:46:39.876944 EDT | AverageReturn            1000
2017-06-03 15:46:39.877203 EDT | StdReturn                   0
2017-06-03 15:46:39.877452 EDT | MaxReturn                1000
2017-06-03 15:46:39.877715 EDT | MinReturn                1000
2017-06-03 15:46:39.877966 EDT | AverageEsReturn            21.5556
2017-06-03 15:46:39.878213 EDT | StdEsReturn                16.1776
2017-06-03 15:46:39.878457 EDT | MaxEsReturn                66
2017-06-03 15:46:39.878700 EDT | MinEsReturn                 4
2017-06-03 15:46:39.878943 EDT | AverageDiscountedReturn    99.9957
2017-06-03 15:46:39.879192 EDT | AverageQLoss                4.21562e-05
2017-06-03 15:46:39.879435 EDT | AveragePolicySurr          -0.106646
2017-06-03 15:46:39.879678 EDT | AverageQ                    0.101762
2017-06-03 15:46:39.879921 EDT | AverageAbsQ                 0.10216
2017-06-03 15:46:39.880164 EDT | AverageY                    0.101758
2017-06-03 15:46:39.880410 EDT | AverageAbsY                 0.101833
2017-06-03 15:46:39.880653 EDT | AverageAbsQYDiff            0.00181666
2017-06-03 15:46:39.880895 EDT | AverageAction               0.00532583
2017-06-03 15:46:39.881137 EDT | PolicyRegParamNorm         58.4254
2017-06-03 15:46:39.881378 EDT | QFunRegParamNorm           26.541
2017-06-03 15:46:39.881620 EDT | -----------------------  --------------
2017-06-03 15:46:39.882068 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #379 | Training started
2017-06-03 15:46:57.762915 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #379 | Training finished
2017-06-03 15:46:57.765128 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #379 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 15:46:57.765510 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #379 | Collecting samples for evaluation
2017-06-03 15:47:08.987510 EDT | -----------------------  -------------
2017-06-03 15:47:08.988358 EDT | Epoch                    379
2017-06-03 15:47:08.988631 EDT | Iteration                379
2017-06-03 15:47:08.988884 EDT | AverageReturn             42.617
2017-06-03 15:47:08.989133 EDT | StdReturn                  0.49479
2017-06-03 15:47:08.989379 EDT | MaxReturn                 43
2017-06-03 15:47:08.989623 EDT | MinReturn                 41
2017-06-03 15:47:08.989877 EDT | AverageEsReturn           17.1333
2017-06-03 15:47:08.990124 EDT | StdEsReturn               13.0441
2017-06-03 15:47:08.990372 EDT | MaxEsReturn               72
2017-06-03 15:47:08.990616 EDT | MinEsReturn                4
2017-06-03 15:47:08.990858 EDT | AverageDiscountedReturn   34.8386
2017-06-03 15:47:08.991100 EDT | AverageQLoss               4.67592e-05
2017-06-03 15:47:08.991343 EDT | AveragePolicySurr         -0.106196
2017-06-03 15:47:08.991586 EDT | AverageQ                   0.101473
2017-06-03 15:47:08.991829 EDT | AverageAbsQ                0.101895
2017-06-03 15:47:08.992073 EDT | AverageY                   0.101474
2017-06-03 15:47:08.992316 EDT | AverageAbsY                0.101551
2017-06-03 15:47:08.992558 EDT | AverageAbsQYDiff           0.00192078
2017-06-03 15:47:08.992908 EDT | AverageAction              0.184523
2017-06-03 15:47:08.993233 EDT | PolicyRegParamNorm        58.4391
2017-06-03 15:47:08.993553 EDT | QFunRegParamNorm          26.5401
2017-06-03 15:47:08.993881 EDT | -----------------------  -------------
2017-06-03 15:47:08.994323 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #380 | Training started
2017-06-03 15:47:27.386904 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #380 | Training finished
2017-06-03 15:47:27.387823 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #380 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 15:47:27.388110 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #380 | Collecting samples for evaluation
2017-06-03 15:47:36.878022 EDT | -----------------------  --------------
2017-06-03 15:47:36.878902 EDT | Epoch                     380
2017-06-03 15:47:36.879180 EDT | Iteration                 380
2017-06-03 15:47:36.879434 EDT | AverageReturn            1000
2017-06-03 15:47:36.879692 EDT | StdReturn                   0
2017-06-03 15:47:36.879942 EDT | MaxReturn                1000
2017-06-03 15:47:36.880185 EDT | MinReturn                1000
2017-06-03 15:47:36.880429 EDT | AverageEsReturn            18.3148
2017-06-03 15:47:36.880674 EDT | StdEsReturn                15.6535
2017-06-03 15:47:36.880916 EDT | MaxEsReturn                74
2017-06-03 15:47:36.881158 EDT | MinEsReturn                 4
2017-06-03 15:47:36.881400 EDT | AverageDiscountedReturn    99.9957
2017-06-03 15:47:36.881650 EDT | AverageQLoss                3.64728e-05
2017-06-03 15:47:36.881905 EDT | AveragePolicySurr          -0.106147
2017-06-03 15:47:36.882146 EDT | AverageQ                    0.100924
2017-06-03 15:47:36.882387 EDT | AverageAbsQ                 0.10122
2017-06-03 15:47:36.882633 EDT | AverageY                    0.100931
2017-06-03 15:47:36.882874 EDT | AverageAbsY                 0.100998
2017-06-03 15:47:36.883115 EDT | AverageAbsQYDiff            0.00167127
2017-06-03 15:47:36.883355 EDT | AverageAction               0.00747738
2017-06-03 15:47:36.883596 EDT | PolicyRegParamNorm         58.5644
2017-06-03 15:47:36.883837 EDT | QFunRegParamNorm           26.5432
2017-06-03 15:47:36.884077 EDT | -----------------------  --------------
2017-06-03 15:47:36.884468 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #381 | Training started
2017-06-03 15:47:55.347612 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #381 | Training finished
2017-06-03 15:47:55.348525 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #381 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 15:47:55.348835 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #381 | Collecting samples for evaluation
2017-06-03 15:48:05.104910 EDT | -----------------------  --------------
2017-06-03 15:48:05.105377 EDT | Epoch                     381
2017-06-03 15:48:05.105659 EDT | Iteration                 381
2017-06-03 15:48:05.105925 EDT | AverageReturn            1000
2017-06-03 15:48:05.106174 EDT | StdReturn                   0
2017-06-03 15:48:05.106420 EDT | MaxReturn                1000
2017-06-03 15:48:05.106674 EDT | MinReturn                1000
2017-06-03 15:48:05.106918 EDT | AverageEsReturn            25.8462
2017-06-03 15:48:05.107174 EDT | StdEsReturn                19.5272
2017-06-03 15:48:05.107416 EDT | MaxEsReturn                97
2017-06-03 15:48:05.107659 EDT | MinEsReturn                 6
2017-06-03 15:48:05.107901 EDT | AverageDiscountedReturn    99.9957
2017-06-03 15:48:05.108148 EDT | AverageQLoss                4.26127e-05
2017-06-03 15:48:05.108389 EDT | AveragePolicySurr          -0.105935
2017-06-03 15:48:05.108631 EDT | AverageQ                    0.101163
2017-06-03 15:48:05.108871 EDT | AverageAbsQ                 0.101527
2017-06-03 15:48:05.109115 EDT | AverageY                    0.101147
2017-06-03 15:48:05.109355 EDT | AverageAbsY                 0.10122
2017-06-03 15:48:05.109595 EDT | AverageAbsQYDiff            0.00183346
2017-06-03 15:48:05.109853 EDT | AverageAction               0.0275836
2017-06-03 15:48:05.110095 EDT | PolicyRegParamNorm         58.6105
2017-06-03 15:48:05.110335 EDT | QFunRegParamNorm           26.5533
2017-06-03 15:48:05.110578 EDT | -----------------------  --------------
2017-06-03 15:48:05.110963 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #382 | Training started
2017-06-03 15:48:24.156847 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #382 | Training finished
2017-06-03 15:48:24.157553 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #382 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 15:48:24.157962 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #382 | Collecting samples for evaluation
2017-06-03 15:48:33.474312 EDT | -----------------------  --------------
2017-06-03 15:48:33.474746 EDT | Epoch                     382
2017-06-03 15:48:33.475015 EDT | Iteration                 382
2017-06-03 15:48:33.475272 EDT | AverageReturn            1000
2017-06-03 15:48:33.475523 EDT | StdReturn                   0
2017-06-03 15:48:33.475769 EDT | MaxReturn                1000
2017-06-03 15:48:33.476041 EDT | MinReturn                1000
2017-06-03 15:48:33.476287 EDT | AverageEsReturn            21.2553
2017-06-03 15:48:33.476532 EDT | StdEsReturn                16.5638
2017-06-03 15:48:33.476777 EDT | MaxEsReturn                79
2017-06-03 15:48:33.477021 EDT | MinEsReturn                 6
2017-06-03 15:48:33.477280 EDT | AverageDiscountedReturn    99.9957
2017-06-03 15:48:33.477524 EDT | AverageQLoss                4.56751e-05
2017-06-03 15:48:33.477781 EDT | AveragePolicySurr          -0.105628
2017-06-03 15:48:33.478026 EDT | AverageQ                    0.100673
2017-06-03 15:48:33.478271 EDT | AverageAbsQ                 0.100997
2017-06-03 15:48:33.478513 EDT | AverageY                    0.100686
2017-06-03 15:48:33.478755 EDT | AverageAbsY                 0.10074
2017-06-03 15:48:33.478996 EDT | AverageAbsQYDiff            0.0018508
2017-06-03 15:48:33.479238 EDT | AverageAction               0.0199958
2017-06-03 15:48:33.479477 EDT | PolicyRegParamNorm         58.6198
2017-06-03 15:48:33.479718 EDT | QFunRegParamNorm           26.5742
2017-06-03 15:48:33.479958 EDT | -----------------------  --------------
2017-06-03 15:48:33.480373 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #383 | Training started
2017-06-03 15:48:51.574635 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #383 | Training finished
2017-06-03 15:48:51.575541 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #383 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 15:48:51.575914 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #383 | Collecting samples for evaluation
2017-06-03 15:49:00.930610 EDT | -----------------------  --------------
2017-06-03 15:49:00.931467 EDT | Epoch                     383
2017-06-03 15:49:00.931732 EDT | Iteration                 383
2017-06-03 15:49:00.931973 EDT | AverageReturn            1000
2017-06-03 15:49:00.932220 EDT | StdReturn                   0
2017-06-03 15:49:00.932464 EDT | MaxReturn                1000
2017-06-03 15:49:00.932702 EDT | MinReturn                1000
2017-06-03 15:49:00.932932 EDT | AverageEsReturn            18.6481
2017-06-03 15:49:00.933187 EDT | StdEsReturn                12.2884
2017-06-03 15:49:00.933417 EDT | MaxEsReturn                50
2017-06-03 15:49:00.933653 EDT | MinEsReturn                 3
2017-06-03 15:49:00.933915 EDT | AverageDiscountedReturn    99.9957
2017-06-03 15:49:00.934149 EDT | AverageQLoss                4.18798e-05
2017-06-03 15:49:00.934383 EDT | AveragePolicySurr          -0.105198
2017-06-03 15:49:00.934611 EDT | AverageQ                    0.100087
2017-06-03 15:49:00.934842 EDT | AverageAbsQ                 0.100459
2017-06-03 15:49:00.935078 EDT | AverageY                    0.100086
2017-06-03 15:49:00.935308 EDT | AverageAbsY                 0.100146
2017-06-03 15:49:00.935539 EDT | AverageAbsQYDiff            0.00182639
2017-06-03 15:49:00.935775 EDT | AverageAction               0.0213134
2017-06-03 15:49:00.936014 EDT | PolicyRegParamNorm         58.6529
2017-06-03 15:49:00.936242 EDT | QFunRegParamNorm           26.5884
2017-06-03 15:49:00.936472 EDT | -----------------------  --------------
2017-06-03 15:49:00.936818 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #384 | Training started
2017-06-03 15:49:19.665852 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #384 | Training finished
2017-06-03 15:49:19.666808 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #384 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 15:49:19.667209 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #384 | Collecting samples for evaluation
2017-06-03 15:49:29.277382 EDT | -----------------------  --------------
2017-06-03 15:49:29.278313 EDT | Epoch                     384
2017-06-03 15:49:29.278596 EDT | Iteration                 384
2017-06-03 15:49:29.278868 EDT | AverageReturn            1000
2017-06-03 15:49:29.279138 EDT | StdReturn                   0
2017-06-03 15:49:29.279431 EDT | MaxReturn                1000
2017-06-03 15:49:29.279670 EDT | MinReturn                1000
2017-06-03 15:49:29.279940 EDT | AverageEsReturn            23.4762
2017-06-03 15:49:29.280190 EDT | StdEsReturn                19.7511
2017-06-03 15:49:29.280430 EDT | MaxEsReturn                88
2017-06-03 15:49:29.280662 EDT | MinEsReturn                 3
2017-06-03 15:49:29.280889 EDT | AverageDiscountedReturn    99.9957
2017-06-03 15:49:29.281132 EDT | AverageQLoss                3.70715e-05
2017-06-03 15:49:29.281393 EDT | AveragePolicySurr          -0.105319
2017-06-03 15:49:29.281660 EDT | AverageQ                    0.100536
2017-06-03 15:49:29.281931 EDT | AverageAbsQ                 0.100824
2017-06-03 15:49:29.282164 EDT | AverageY                    0.100536
2017-06-03 15:49:29.282427 EDT | AverageAbsY                 0.100568
2017-06-03 15:49:29.282690 EDT | AverageAbsQYDiff            0.00163643
2017-06-03 15:49:29.282931 EDT | AverageAction               0.0427942
2017-06-03 15:49:29.283161 EDT | PolicyRegParamNorm         58.6672
2017-06-03 15:49:29.283389 EDT | QFunRegParamNorm           26.5917
2017-06-03 15:49:29.283628 EDT | -----------------------  --------------
2017-06-03 15:49:29.284044 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #385 | Training started
2017-06-03 15:49:47.568133 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #385 | Training finished
2017-06-03 15:49:47.569049 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #385 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 15:49:47.569531 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #385 | Collecting samples for evaluation
2017-06-03 15:49:58.461954 EDT | -----------------------  --------------
2017-06-03 15:49:58.462907 EDT | Epoch                     385
2017-06-03 15:49:58.463228 EDT | Iteration                 385
2017-06-03 15:49:58.463473 EDT | AverageReturn            1000
2017-06-03 15:49:58.463727 EDT | StdReturn                   0
2017-06-03 15:49:58.463995 EDT | MaxReturn                1000
2017-06-03 15:49:58.464229 EDT | MinReturn                1000
2017-06-03 15:49:58.464491 EDT | AverageEsReturn            17.7143
2017-06-03 15:49:58.464785 EDT | StdEsReturn                12.1827
2017-06-03 15:49:58.465061 EDT | MaxEsReturn                55
2017-06-03 15:49:58.465346 EDT | MinEsReturn                 3
2017-06-03 15:49:58.465608 EDT | AverageDiscountedReturn    99.9957
2017-06-03 15:49:58.465869 EDT | AverageQLoss                4.42365e-05
2017-06-03 15:49:58.466099 EDT | AveragePolicySurr          -0.105115
2017-06-03 15:49:58.466355 EDT | AverageQ                    0.100153
2017-06-03 15:49:58.466624 EDT | AverageAbsQ                 0.10048
2017-06-03 15:49:58.466872 EDT | AverageY                    0.100149
2017-06-03 15:49:58.467101 EDT | AverageAbsY                 0.10017
2017-06-03 15:49:58.467328 EDT | AverageAbsQYDiff            0.00188967
2017-06-03 15:49:58.467560 EDT | AverageAction               0.0154473
2017-06-03 15:49:58.467826 EDT | PolicyRegParamNorm         58.6962
2017-06-03 15:49:58.468095 EDT | QFunRegParamNorm           26.5988
2017-06-03 15:49:58.468355 EDT | -----------------------  --------------
2017-06-03 15:49:58.468723 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #386 | Training started
2017-06-03 15:50:18.138362 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #386 | Training finished
2017-06-03 15:50:18.139348 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #386 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 15:50:18.139714 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #386 | Collecting samples for evaluation
2017-06-03 15:50:27.481055 EDT | -----------------------  --------------
2017-06-03 15:50:27.482082 EDT | Epoch                     386
2017-06-03 15:50:27.482434 EDT | Iteration                 386
2017-06-03 15:50:27.482769 EDT | AverageReturn            1000
2017-06-03 15:50:27.483089 EDT | StdReturn                   0
2017-06-03 15:50:27.483422 EDT | MaxReturn                1000
2017-06-03 15:50:27.483749 EDT | MinReturn                1000
2017-06-03 15:50:27.484093 EDT | AverageEsReturn            22.9302
2017-06-03 15:50:27.484464 EDT | StdEsReturn                14.5161
2017-06-03 15:50:27.484791 EDT | MaxEsReturn                69
2017-06-03 15:50:27.485108 EDT | MinEsReturn                 3
2017-06-03 15:50:27.485420 EDT | AverageDiscountedReturn    99.9957
2017-06-03 15:50:27.485760 EDT | AverageQLoss                3.95823e-05
2017-06-03 15:50:27.486105 EDT | AveragePolicySurr          -0.104654
2017-06-03 15:50:27.486419 EDT | AverageQ                    0.0997152
2017-06-03 15:50:27.486747 EDT | AverageAbsQ                 0.100066
2017-06-03 15:50:27.487066 EDT | AverageY                    0.0997163
2017-06-03 15:50:27.487380 EDT | AverageAbsY                 0.0997526
2017-06-03 15:50:27.487697 EDT | AverageAbsQYDiff            0.00184061
2017-06-03 15:50:27.488019 EDT | AverageAction               0.0157405
2017-06-03 15:50:27.488332 EDT | PolicyRegParamNorm         58.744
2017-06-03 15:50:27.488639 EDT | QFunRegParamNorm           26.6052
2017-06-03 15:50:27.488948 EDT | -----------------------  --------------
2017-06-03 15:50:27.489394 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #387 | Training started
2017-06-03 15:50:46.111567 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #387 | Training finished
2017-06-03 15:50:46.112549 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #387 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 15:50:46.112933 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #387 | Collecting samples for evaluation
2017-06-03 15:50:54.850006 EDT | -----------------------  --------------
2017-06-03 15:50:54.850903 EDT | Epoch                     387
2017-06-03 15:50:54.851177 EDT | Iteration                 387
2017-06-03 15:50:54.851436 EDT | AverageReturn            1000
2017-06-03 15:50:54.851719 EDT | StdReturn                   0
2017-06-03 15:50:54.852191 EDT | MaxReturn                1000
2017-06-03 15:50:54.852434 EDT | MinReturn                1000
2017-06-03 15:50:54.852695 EDT | AverageEsReturn            23.0222
2017-06-03 15:50:54.852933 EDT | StdEsReturn                17.7995
2017-06-03 15:50:54.853169 EDT | MaxEsReturn                82
2017-06-03 15:50:54.853413 EDT | MinEsReturn                 3
2017-06-03 15:50:54.853648 EDT | AverageDiscountedReturn    99.9957
2017-06-03 15:50:54.853899 EDT | AverageQLoss                4.43736e-05
2017-06-03 15:50:54.854133 EDT | AveragePolicySurr          -0.104289
2017-06-03 15:50:54.854366 EDT | AverageQ                    0.099185
2017-06-03 15:50:54.854598 EDT | AverageAbsQ                 0.099561
2017-06-03 15:50:54.854829 EDT | AverageY                    0.0991881
2017-06-03 15:50:54.855060 EDT | AverageAbsY                 0.0992113
2017-06-03 15:50:54.855292 EDT | AverageAbsQYDiff            0.00192604
2017-06-03 15:50:54.855524 EDT | AverageAction               0.0156988
2017-06-03 15:50:54.855756 EDT | PolicyRegParamNorm         58.8599
2017-06-03 15:50:54.855988 EDT | QFunRegParamNorm           26.6091
2017-06-03 15:50:54.856220 EDT | -----------------------  --------------
2017-06-03 15:50:54.856613 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #388 | Training started
2017-06-03 15:51:13.717111 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #388 | Training finished
2017-06-03 15:51:13.717972 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #388 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 15:51:13.718240 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #388 | Collecting samples for evaluation
2017-06-03 15:51:23.541343 EDT | -----------------------  --------------
2017-06-03 15:51:23.542226 EDT | Epoch                     388
2017-06-03 15:51:23.542505 EDT | Iteration                 388
2017-06-03 15:51:23.542764 EDT | AverageReturn            1000
2017-06-03 15:51:23.543017 EDT | StdReturn                   0
2017-06-03 15:51:23.543276 EDT | MaxReturn                1000
2017-06-03 15:51:23.543515 EDT | MinReturn                1000
2017-06-03 15:51:23.543750 EDT | AverageEsReturn            22.7209
2017-06-03 15:51:23.543986 EDT | StdEsReturn                19.4976
2017-06-03 15:51:23.544233 EDT | MaxEsReturn               102
2017-06-03 15:51:23.544467 EDT | MinEsReturn                 3
2017-06-03 15:51:23.544699 EDT | AverageDiscountedReturn    99.9957
2017-06-03 15:51:23.544933 EDT | AverageQLoss                3.71572e-05
2017-06-03 15:51:23.545167 EDT | AveragePolicySurr          -0.104303
2017-06-03 15:51:23.545404 EDT | AverageQ                    0.0995267
2017-06-03 15:51:23.545639 EDT | AverageAbsQ                 0.0998395
2017-06-03 15:51:23.545884 EDT | AverageY                    0.0995349
2017-06-03 15:51:23.546115 EDT | AverageAbsY                 0.0995641
2017-06-03 15:51:23.546347 EDT | AverageAbsQYDiff            0.00168022
2017-06-03 15:51:23.546580 EDT | AverageAction               0.0102411
2017-06-03 15:51:23.546812 EDT | PolicyRegParamNorm         58.9123
2017-06-03 15:51:23.547042 EDT | QFunRegParamNorm           26.6177
2017-06-03 15:51:23.547273 EDT | -----------------------  --------------
2017-06-03 15:51:23.547615 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #389 | Training started
2017-06-03 15:51:41.973569 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #389 | Training finished
2017-06-03 15:51:41.974472 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #389 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 15:51:41.974738 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #389 | Collecting samples for evaluation
2017-06-03 15:51:51.176486 EDT | -----------------------  -------------
2017-06-03 15:51:51.176884 EDT | Epoch                     389
2017-06-03 15:51:51.177320 EDT | Iteration                 389
2017-06-03 15:51:51.177651 EDT | AverageReturn            1000
2017-06-03 15:51:51.177998 EDT | StdReturn                   0
2017-06-03 15:51:51.178315 EDT | MaxReturn                1000
2017-06-03 15:51:51.178635 EDT | MinReturn                1000
2017-06-03 15:51:51.178952 EDT | AverageEsReturn            21.125
2017-06-03 15:51:51.179266 EDT | StdEsReturn                15.8504
2017-06-03 15:51:51.179585 EDT | MaxEsReturn                69
2017-06-03 15:51:51.179897 EDT | MinEsReturn                 3
2017-06-03 15:51:51.180210 EDT | AverageDiscountedReturn    99.9957
2017-06-03 15:51:51.180521 EDT | AverageQLoss                3.5852e-05
2017-06-03 15:51:51.180831 EDT | AveragePolicySurr          -0.104245
2017-06-03 15:51:51.181139 EDT | AverageQ                    0.0993946
2017-06-03 15:51:51.181480 EDT | AverageAbsQ                 0.099686
2017-06-03 15:51:51.181794 EDT | AverageY                    0.0993806
2017-06-03 15:51:51.182107 EDT | AverageAbsY                 0.0994146
2017-06-03 15:51:51.182428 EDT | AverageAbsQYDiff            0.00167963
2017-06-03 15:51:51.182735 EDT | AverageAction               0.0039864
2017-06-03 15:51:51.183041 EDT | PolicyRegParamNorm         59.0066
2017-06-03 15:51:51.183346 EDT | QFunRegParamNorm           26.625
2017-06-03 15:51:51.183650 EDT | -----------------------  -------------
2017-06-03 15:51:51.184141 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #390 | Training started
2017-06-03 15:52:09.220123 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #390 | Training finished
2017-06-03 15:52:09.221229 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #390 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 15:52:09.221612 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #390 | Collecting samples for evaluation
2017-06-03 15:52:18.657554 EDT | -----------------------  -------------
2017-06-03 15:52:18.657956 EDT | Epoch                    390
2017-06-03 15:52:18.658210 EDT | Iteration                390
2017-06-03 15:52:18.658449 EDT | AverageReturn             49.4877
2017-06-03 15:52:18.658687 EDT | StdReturn                  0.499848
2017-06-03 15:52:18.658922 EDT | MaxReturn                 50
2017-06-03 15:52:18.659160 EDT | MinReturn                 49
2017-06-03 15:52:18.659394 EDT | AverageEsReturn           28.5143
2017-06-03 15:52:18.659628 EDT | StdEsReturn               30.9113
2017-06-03 15:52:18.659861 EDT | MaxEsReturn              175
2017-06-03 15:52:18.660094 EDT | MinEsReturn                4
2017-06-03 15:52:18.660326 EDT | AverageDiscountedReturn   39.1863
2017-06-03 15:52:18.660557 EDT | AverageQLoss               3.66624e-05
2017-06-03 15:52:18.660850 EDT | AveragePolicySurr         -0.103738
2017-06-03 15:52:18.661090 EDT | AverageQ                   0.0989687
2017-06-03 15:52:18.661322 EDT | AverageAbsQ                0.0992298
2017-06-03 15:52:18.661553 EDT | AverageY                   0.0989757
2017-06-03 15:52:18.661798 EDT | AverageAbsY                0.0989925
2017-06-03 15:52:18.662031 EDT | AverageAbsQYDiff           0.00162141
2017-06-03 15:52:18.662263 EDT | AverageAction              0.274949
2017-06-03 15:52:18.662493 EDT | PolicyRegParamNorm        59.0668
2017-06-03 15:52:18.662724 EDT | QFunRegParamNorm          26.6319
2017-06-03 15:52:18.662956 EDT | -----------------------  -------------
2017-06-03 15:52:18.663320 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #391 | Training started
2017-06-03 15:52:38.831785 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #391 | Training finished
2017-06-03 15:52:38.832729 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #391 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 15:52:38.833002 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #391 | Collecting samples for evaluation
2017-06-03 15:52:48.538246 EDT | -----------------------  --------------
2017-06-03 15:52:48.539317 EDT | Epoch                     391
2017-06-03 15:52:48.539659 EDT | Iteration                 391
2017-06-03 15:52:48.539986 EDT | AverageReturn            1000
2017-06-03 15:52:48.540330 EDT | StdReturn                   0
2017-06-03 15:52:48.540640 EDT | MaxReturn                1000
2017-06-03 15:52:48.540951 EDT | MinReturn                1000
2017-06-03 15:52:48.541312 EDT | AverageEsReturn            16.0952
2017-06-03 15:52:48.541630 EDT | StdEsReturn                12.4336
2017-06-03 15:52:48.541963 EDT | MaxEsReturn                58
2017-06-03 15:52:48.542272 EDT | MinEsReturn                 3
2017-06-03 15:52:48.542578 EDT | AverageDiscountedReturn    99.9957
2017-06-03 15:52:48.542886 EDT | AverageQLoss                3.81713e-05
2017-06-03 15:52:48.543196 EDT | AveragePolicySurr          -0.103601
2017-06-03 15:52:48.543501 EDT | AverageQ                    0.098428
2017-06-03 15:52:48.543808 EDT | AverageAbsQ                 0.0987745
2017-06-03 15:52:48.544111 EDT | AverageY                    0.0984242
2017-06-03 15:52:48.544416 EDT | AverageAbsY                 0.0984498
2017-06-03 15:52:48.544720 EDT | AverageAbsQYDiff            0.00182693
2017-06-03 15:52:48.545024 EDT | AverageAction               0.00239223
2017-06-03 15:52:48.545343 EDT | PolicyRegParamNorm         59.1804
2017-06-03 15:52:48.545645 EDT | QFunRegParamNorm           26.6289
2017-06-03 15:52:48.545972 EDT | -----------------------  --------------
2017-06-03 15:52:48.546534 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #392 | Training started
2017-06-03 15:53:08.026556 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #392 | Training finished
2017-06-03 15:53:08.027445 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #392 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 15:53:08.027861 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #392 | Collecting samples for evaluation
2017-06-03 15:53:17.742035 EDT | -----------------------  --------------
2017-06-03 15:53:17.742876 EDT | Epoch                     392
2017-06-03 15:53:17.743156 EDT | Iteration                 392
2017-06-03 15:53:17.743399 EDT | AverageReturn            1000
2017-06-03 15:53:17.743636 EDT | StdReturn                   0
2017-06-03 15:53:17.743867 EDT | MaxReturn                1000
2017-06-03 15:53:17.744101 EDT | MinReturn                1000
2017-06-03 15:53:17.744334 EDT | AverageEsReturn            23.3333
2017-06-03 15:53:17.744564 EDT | StdEsReturn                19.4895
2017-06-03 15:53:17.744823 EDT | MaxEsReturn                98
2017-06-03 15:53:17.745105 EDT | MinEsReturn                 2
2017-06-03 15:53:17.745343 EDT | AverageDiscountedReturn    99.9957
2017-06-03 15:53:17.745590 EDT | AverageQLoss                4.64911e-05
2017-06-03 15:53:17.745856 EDT | AveragePolicySurr          -0.103459
2017-06-03 15:53:17.746096 EDT | AverageQ                    0.0984871
2017-06-03 15:53:17.746368 EDT | AverageAbsQ                 0.0988351
2017-06-03 15:53:17.746606 EDT | AverageY                    0.0984932
2017-06-03 15:53:17.746838 EDT | AverageAbsY                 0.0985167
2017-06-03 15:53:17.747133 EDT | AverageAbsQYDiff            0.00198986
2017-06-03 15:53:17.747370 EDT | AverageAction               5.82729e-05
2017-06-03 15:53:17.747603 EDT | PolicyRegParamNorm         59.1935
2017-06-03 15:53:17.747853 EDT | QFunRegParamNorm           26.6555
2017-06-03 15:53:17.748127 EDT | -----------------------  --------------
2017-06-03 15:53:17.748486 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #393 | Training started
2017-06-03 15:53:36.301955 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #393 | Training finished
2017-06-03 15:53:36.303037 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #393 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 15:53:36.303427 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #393 | Collecting samples for evaluation
2017-06-03 15:53:45.687940 EDT | -----------------------  --------------
2017-06-03 15:53:45.691138 EDT | Epoch                     393
2017-06-03 15:53:45.691423 EDT | Iteration                 393
2017-06-03 15:53:45.691677 EDT | AverageReturn            1000
2017-06-03 15:53:45.691916 EDT | StdReturn                   0
2017-06-03 15:53:45.692203 EDT | MaxReturn                1000
2017-06-03 15:53:45.692434 EDT | MinReturn                1000
2017-06-03 15:53:45.692665 EDT | AverageEsReturn            24
2017-06-03 15:53:45.692901 EDT | StdEsReturn                20.6291
2017-06-03 15:53:45.693135 EDT | MaxEsReturn               105
2017-06-03 15:53:45.693367 EDT | MinEsReturn                 3
2017-06-03 15:53:45.693595 EDT | AverageDiscountedReturn    99.9957
2017-06-03 15:53:45.693850 EDT | AverageQLoss                3.67637e-05
2017-06-03 15:53:45.694080 EDT | AveragePolicySurr          -0.103505
2017-06-03 15:53:45.694307 EDT | AverageQ                    0.0987078
2017-06-03 15:53:45.694538 EDT | AverageAbsQ                 0.0990237
2017-06-03 15:53:45.694765 EDT | AverageY                    0.0987027
2017-06-03 15:53:45.694991 EDT | AverageAbsY                 0.0987191
2017-06-03 15:53:45.695217 EDT | AverageAbsQYDiff            0.00178964
2017-06-03 15:53:45.695444 EDT | AverageAction               0.256994
2017-06-03 15:53:45.695670 EDT | PolicyRegParamNorm         59.1997
2017-06-03 15:53:45.695896 EDT | QFunRegParamNorm           26.6643
2017-06-03 15:53:45.696123 EDT | -----------------------  --------------
2017-06-03 15:53:45.696507 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #394 | Training started
2017-06-03 15:54:03.368595 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #394 | Training finished
2017-06-03 15:54:03.369532 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #394 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 15:54:03.369929 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #394 | Collecting samples for evaluation
2017-06-03 15:54:12.904215 EDT | -----------------------  --------------
2017-06-03 15:54:12.905082 EDT | Epoch                     394
2017-06-03 15:54:12.905347 EDT | Iteration                 394
2017-06-03 15:54:12.905582 EDT | AverageReturn            1000
2017-06-03 15:54:12.905822 EDT | StdReturn                   0
2017-06-03 15:54:12.906059 EDT | MaxReturn                1000
2017-06-03 15:54:12.906289 EDT | MinReturn                1000
2017-06-03 15:54:12.906510 EDT | AverageEsReturn            34.2333
2017-06-03 15:54:12.906730 EDT | StdEsReturn                25.8117
2017-06-03 15:54:12.906949 EDT | MaxEsReturn               101
2017-06-03 15:54:12.907168 EDT | MinEsReturn                 4
2017-06-03 15:54:12.907402 EDT | AverageDiscountedReturn    99.9957
2017-06-03 15:54:12.907661 EDT | AverageQLoss                3.80962e-05
2017-06-03 15:54:12.907890 EDT | AveragePolicySurr          -0.103267
2017-06-03 15:54:12.908111 EDT | AverageQ                    0.0985036
2017-06-03 15:54:12.908334 EDT | AverageAbsQ                 0.0987995
2017-06-03 15:54:12.908569 EDT | AverageY                    0.0985028
2017-06-03 15:54:12.908791 EDT | AverageAbsY                 0.0985133
2017-06-03 15:54:12.909012 EDT | AverageAbsQYDiff            0.0018161
2017-06-03 15:54:12.909234 EDT | AverageAction               0.0552711
2017-06-03 15:54:12.909455 EDT | PolicyRegParamNorm         59.2457
2017-06-03 15:54:12.909676 EDT | QFunRegParamNorm           26.6612
2017-06-03 15:54:12.909918 EDT | -----------------------  --------------
2017-06-03 15:54:12.910388 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #395 | Training started
2017-06-03 15:54:31.678828 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #395 | Training finished
2017-06-03 15:54:31.679513 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #395 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 15:54:31.679947 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #395 | Collecting samples for evaluation
2017-06-03 15:54:41.183709 EDT | -----------------------  --------------
2017-06-03 15:54:41.184546 EDT | Epoch                     395
2017-06-03 15:54:41.184838 EDT | Iteration                 395
2017-06-03 15:54:41.185082 EDT | AverageReturn            1000
2017-06-03 15:54:41.185333 EDT | StdReturn                   0
2017-06-03 15:54:41.185571 EDT | MaxReturn                1000
2017-06-03 15:54:41.185824 EDT | MinReturn                1000
2017-06-03 15:54:41.186094 EDT | AverageEsReturn            27.75
2017-06-03 15:54:41.186347 EDT | StdEsReturn                18.3445
2017-06-03 15:54:41.186584 EDT | MaxEsReturn                68
2017-06-03 15:54:41.186840 EDT | MinEsReturn                 5
2017-06-03 15:54:41.187085 EDT | AverageDiscountedReturn    99.9957
2017-06-03 15:54:41.187322 EDT | AverageQLoss                3.30389e-05
2017-06-03 15:54:41.187564 EDT | AveragePolicySurr          -0.103
2017-06-03 15:54:41.187799 EDT | AverageQ                    0.0980314
2017-06-03 15:54:41.188032 EDT | AverageAbsQ                 0.098274
2017-06-03 15:54:41.188269 EDT | AverageY                    0.0980364
2017-06-03 15:54:41.188504 EDT | AverageAbsY                 0.0980469
2017-06-03 15:54:41.188737 EDT | AverageAbsQYDiff            0.00158587
2017-06-03 15:54:41.188974 EDT | AverageAction               0.0242435
2017-06-03 15:54:41.189233 EDT | PolicyRegParamNorm         59.2754
2017-06-03 15:54:41.189469 EDT | QFunRegParamNorm           26.6545
2017-06-03 15:54:41.189719 EDT | -----------------------  --------------
2017-06-03 15:54:41.190088 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #396 | Training started
2017-06-03 15:55:00.017757 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #396 | Training finished
2017-06-03 15:55:00.018761 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #396 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 15:55:00.019199 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #396 | Collecting samples for evaluation
2017-06-03 15:55:09.187041 EDT | -----------------------  --------------
2017-06-03 15:55:09.187896 EDT | Epoch                     396
2017-06-03 15:55:09.188166 EDT | Iteration                 396
2017-06-03 15:55:09.188408 EDT | AverageReturn            1000
2017-06-03 15:55:09.188644 EDT | StdReturn                   0
2017-06-03 15:55:09.188888 EDT | MaxReturn                1000
2017-06-03 15:55:09.189120 EDT | MinReturn                1000
2017-06-03 15:55:09.189352 EDT | AverageEsReturn            25.1026
2017-06-03 15:55:09.189584 EDT | StdEsReturn                20.0254
2017-06-03 15:55:09.189828 EDT | MaxEsReturn                72
2017-06-03 15:55:09.190060 EDT | MinEsReturn                 3
2017-06-03 15:55:09.190290 EDT | AverageDiscountedReturn    99.9957
2017-06-03 15:55:09.190519 EDT | AverageQLoss                3.55025e-05
2017-06-03 15:55:09.190750 EDT | AveragePolicySurr          -0.102774
2017-06-03 15:55:09.190979 EDT | AverageQ                    0.0977297
2017-06-03 15:55:09.191207 EDT | AverageAbsQ                 0.0980699
2017-06-03 15:55:09.191436 EDT | AverageY                    0.097727
2017-06-03 15:55:09.191672 EDT | AverageAbsY                 0.0977378
2017-06-03 15:55:09.191902 EDT | AverageAbsQYDiff            0.00174045
2017-06-03 15:55:09.192131 EDT | AverageAction               0.0151888
2017-06-03 15:55:09.192359 EDT | PolicyRegParamNorm         59.3029
2017-06-03 15:55:09.192587 EDT | QFunRegParamNorm           26.6656
2017-06-03 15:55:09.192815 EDT | -----------------------  --------------
2017-06-03 15:55:09.193201 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #397 | Training started
2017-06-03 15:55:27.408530 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #397 | Training finished
2017-06-03 15:55:27.408881 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #397 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 15:55:27.409132 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #397 | Collecting samples for evaluation
2017-06-03 15:55:37.367793 EDT | -----------------------  --------------
2017-06-03 15:55:37.368683 EDT | Epoch                     397
2017-06-03 15:55:37.368972 EDT | Iteration                 397
2017-06-03 15:55:37.369229 EDT | AverageReturn            1000
2017-06-03 15:55:37.369484 EDT | StdReturn                   0
2017-06-03 15:55:37.369769 EDT | MaxReturn                1000
2017-06-03 15:55:37.370041 EDT | MinReturn                1000
2017-06-03 15:55:37.370291 EDT | AverageEsReturn            23.9767
2017-06-03 15:55:37.370542 EDT | StdEsReturn                21.7881
2017-06-03 15:55:37.370789 EDT | MaxEsReturn                93
2017-06-03 15:55:37.371040 EDT | MinEsReturn                 3
2017-06-03 15:55:37.371283 EDT | AverageDiscountedReturn    99.9957
2017-06-03 15:55:37.371525 EDT | AverageQLoss                4.06323e-05
2017-06-03 15:55:37.371778 EDT | AveragePolicySurr          -0.10292
2017-06-03 15:55:37.372019 EDT | AverageQ                    0.0979635
2017-06-03 15:55:37.372264 EDT | AverageAbsQ                 0.0983215
2017-06-03 15:55:37.372506 EDT | AverageY                    0.0979611
2017-06-03 15:55:37.372746 EDT | AverageAbsY                 0.0979845
2017-06-03 15:55:37.372986 EDT | AverageAbsQYDiff            0.0018905
2017-06-03 15:55:37.373226 EDT | AverageAction               0.010516
2017-06-03 15:55:37.373467 EDT | PolicyRegParamNorm         59.3806
2017-06-03 15:55:37.373713 EDT | QFunRegParamNorm           26.6631
2017-06-03 15:55:37.373957 EDT | -----------------------  --------------
2017-06-03 15:55:37.374339 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #398 | Training started
2017-06-03 15:55:55.870188 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #398 | Training finished
2017-06-03 15:55:55.883663 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #398 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 15:55:55.884037 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #398 | Collecting samples for evaluation
2017-06-03 15:56:05.672443 EDT | -----------------------  --------------
2017-06-03 15:56:05.673295 EDT | Epoch                     398
2017-06-03 15:56:05.673573 EDT | Iteration                 398
2017-06-03 15:56:05.673839 EDT | AverageReturn            1000
2017-06-03 15:56:05.674074 EDT | StdReturn                   0
2017-06-03 15:56:05.674304 EDT | MaxReturn                1000
2017-06-03 15:56:05.674581 EDT | MinReturn                1000
2017-06-03 15:56:05.674815 EDT | AverageEsReturn            30.5938
2017-06-03 15:56:05.675060 EDT | StdEsReturn                27.0761
2017-06-03 15:56:05.675302 EDT | MaxEsReturn               122
2017-06-03 15:56:05.675531 EDT | MinEsReturn                 2
2017-06-03 15:56:05.675762 EDT | AverageDiscountedReturn    99.9957
2017-06-03 15:56:05.676029 EDT | AverageQLoss                3.67743e-05
2017-06-03 15:56:05.676263 EDT | AveragePolicySurr          -0.102704
2017-06-03 15:56:05.676504 EDT | AverageQ                    0.0979485
2017-06-03 15:56:05.676735 EDT | AverageAbsQ                 0.0982202
2017-06-03 15:56:05.676963 EDT | AverageY                    0.0979513
2017-06-03 15:56:05.677222 EDT | AverageAbsY                 0.0979699
2017-06-03 15:56:05.677453 EDT | AverageAbsQYDiff            0.0017737
2017-06-03 15:56:05.677688 EDT | AverageAction               0.272569
2017-06-03 15:56:05.677999 EDT | PolicyRegParamNorm         59.4484
2017-06-03 15:56:05.678249 EDT | QFunRegParamNorm           26.6819
2017-06-03 15:56:05.678505 EDT | -----------------------  --------------
2017-06-03 15:56:05.679030 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #399 | Training started
2017-06-03 15:56:23.522003 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #399 | Training finished
2017-06-03 15:56:23.524603 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #399 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 15:56:23.524970 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #399 | Collecting samples for evaluation
2017-06-03 15:56:33.142468 EDT | -----------------------  --------------
2017-06-03 15:56:33.143465 EDT | Epoch                     399
2017-06-03 15:56:33.143748 EDT | Iteration                 399
2017-06-03 15:56:33.143992 EDT | AverageReturn            1000
2017-06-03 15:56:33.144225 EDT | StdReturn                   0
2017-06-03 15:56:33.144456 EDT | MaxReturn                1000
2017-06-03 15:56:33.144686 EDT | MinReturn                1000
2017-06-03 15:56:33.144915 EDT | AverageEsReturn            27.3714
2017-06-03 15:56:33.145153 EDT | StdEsReturn                22.7836
2017-06-03 15:56:33.145383 EDT | MaxEsReturn               104
2017-06-03 15:56:33.145612 EDT | MinEsReturn                 3
2017-06-03 15:56:33.145883 EDT | AverageDiscountedReturn    99.9957
2017-06-03 15:56:33.146131 EDT | AverageQLoss                3.84943e-05
2017-06-03 15:56:33.146364 EDT | AveragePolicySurr          -0.102641
2017-06-03 15:56:33.146593 EDT | AverageQ                    0.0980871
2017-06-03 15:56:33.146824 EDT | AverageAbsQ                 0.0983778
2017-06-03 15:56:33.147052 EDT | AverageY                    0.098084
2017-06-03 15:56:33.147327 EDT | AverageAbsY                 0.0980952
2017-06-03 15:56:33.147556 EDT | AverageAbsQYDiff            0.00168892
2017-06-03 15:56:33.147784 EDT | AverageAction               0.272511
2017-06-03 15:56:33.148012 EDT | PolicyRegParamNorm         59.4739
2017-06-03 15:56:33.148247 EDT | QFunRegParamNorm           26.6827
2017-06-03 15:56:33.148498 EDT | -----------------------  --------------
2017-06-03 15:56:33.148859 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #400 | Training started
2017-06-03 15:56:51.960979 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #400 | Training finished
2017-06-03 15:56:51.965223 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #400 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 15:56:51.965493 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #400 | Collecting samples for evaluation
2017-06-03 15:57:01.317788 EDT | -----------------------  --------------
2017-06-03 15:57:01.318656 EDT | Epoch                     400
2017-06-03 15:57:01.318929 EDT | Iteration                 400
2017-06-03 15:57:01.319186 EDT | AverageReturn            1000
2017-06-03 15:57:01.319439 EDT | StdReturn                   0
2017-06-03 15:57:01.319695 EDT | MaxReturn                1000
2017-06-03 15:57:01.319967 EDT | MinReturn                1000
2017-06-03 15:57:01.320217 EDT | AverageEsReturn            36.3103
2017-06-03 15:57:01.320467 EDT | StdEsReturn                39.177
2017-06-03 15:57:01.320714 EDT | MaxEsReturn               196
2017-06-03 15:57:01.320961 EDT | MinEsReturn                 4
2017-06-03 15:57:01.321215 EDT | AverageDiscountedReturn    99.9957
2017-06-03 15:57:01.321463 EDT | AverageQLoss                3.53837e-05
2017-06-03 15:57:01.321721 EDT | AveragePolicySurr          -0.102082
2017-06-03 15:57:01.321998 EDT | AverageQ                    0.0972582
2017-06-03 15:57:01.322261 EDT | AverageAbsQ                 0.0975439
2017-06-03 15:57:01.322509 EDT | AverageY                    0.0972609
2017-06-03 15:57:01.322756 EDT | AverageAbsY                 0.0972767
2017-06-03 15:57:01.323002 EDT | AverageAbsQYDiff            0.001657
2017-06-03 15:57:01.323262 EDT | AverageAction               0.391334
2017-06-03 15:57:01.323522 EDT | PolicyRegParamNorm         59.5784
2017-06-03 15:57:01.323770 EDT | QFunRegParamNorm           26.69
2017-06-03 15:57:01.324058 EDT | -----------------------  --------------
2017-06-03 15:57:01.324489 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #401 | Training started
2017-06-03 15:57:19.505391 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #401 | Training finished
2017-06-03 15:57:19.506321 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #401 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 15:57:19.506686 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #401 | Collecting samples for evaluation
2017-06-03 15:57:28.514840 EDT | -----------------------  --------------
2017-06-03 15:57:28.515238 EDT | Epoch                     401
2017-06-03 15:57:28.515500 EDT | Iteration                 401
2017-06-03 15:57:28.515845 EDT | AverageReturn            1000
2017-06-03 15:57:28.516206 EDT | StdReturn                   0
2017-06-03 15:57:28.516565 EDT | MaxReturn                1000
2017-06-03 15:57:28.516922 EDT | MinReturn                1000
2017-06-03 15:57:28.517258 EDT | AverageEsReturn            47.4762
2017-06-03 15:57:28.517598 EDT | StdEsReturn                42.3001
2017-06-03 15:57:28.517991 EDT | MaxEsReturn               143
2017-06-03 15:57:28.518315 EDT | MinEsReturn                 3
2017-06-03 15:57:28.518638 EDT | AverageDiscountedReturn    99.9957
2017-06-03 15:57:28.518955 EDT | AverageQLoss                3.38298e-05
2017-06-03 15:57:28.519267 EDT | AveragePolicySurr          -0.102237
2017-06-03 15:57:28.519579 EDT | AverageQ                    0.0974927
2017-06-03 15:57:28.519909 EDT | AverageAbsQ                 0.0977977
2017-06-03 15:57:28.520218 EDT | AverageY                    0.0974827
2017-06-03 15:57:28.520529 EDT | AverageAbsY                 0.0974916
2017-06-03 15:57:28.520850 EDT | AverageAbsQYDiff            0.00161674
2017-06-03 15:57:28.521330 EDT | AverageAction               0.087765
2017-06-03 15:57:28.521838 EDT | PolicyRegParamNorm         59.6388
2017-06-03 15:57:28.522349 EDT | QFunRegParamNorm           26.6927
2017-06-03 15:57:28.524512 EDT | -----------------------  --------------
2017-06-03 15:57:28.525018 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #402 | Training started
2017-06-03 15:57:47.667695 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #402 | Training finished
2017-06-03 15:57:47.670670 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #402 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 15:57:47.670962 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #402 | Collecting samples for evaluation
2017-06-03 15:57:58.715335 EDT | -----------------------  --------------
2017-06-03 15:57:58.715759 EDT | Epoch                     402
2017-06-03 15:57:58.716021 EDT | Iteration                 402
2017-06-03 15:57:58.716268 EDT | AverageReturn            1000
2017-06-03 15:57:58.716510 EDT | StdReturn                   0
2017-06-03 15:57:58.716760 EDT | MaxReturn                1000
2017-06-03 15:57:58.717007 EDT | MinReturn                1000
2017-06-03 15:57:58.717249 EDT | AverageEsReturn            25.3714
2017-06-03 15:57:58.717618 EDT | StdEsReturn                17.0312
2017-06-03 15:57:58.717953 EDT | MaxEsReturn                67
2017-06-03 15:57:58.718270 EDT | MinEsReturn                 3
2017-06-03 15:57:58.718602 EDT | AverageDiscountedReturn    99.9957
2017-06-03 15:57:58.718917 EDT | AverageQLoss                4.04435e-05
2017-06-03 15:57:58.719229 EDT | AveragePolicySurr          -0.102058
2017-06-03 15:57:58.719543 EDT | AverageQ                    0.0972303
2017-06-03 15:57:58.719877 EDT | AverageAbsQ                 0.0975467
2017-06-03 15:57:58.720195 EDT | AverageY                    0.0972299
2017-06-03 15:57:58.720515 EDT | AverageAbsY                 0.0972502
2017-06-03 15:57:58.720821 EDT | AverageAbsQYDiff            0.00182587
2017-06-03 15:57:58.721137 EDT | AverageAction               0.0101755
2017-06-03 15:57:58.721444 EDT | PolicyRegParamNorm         59.7269
2017-06-03 15:57:58.721761 EDT | QFunRegParamNorm           26.6988
2017-06-03 15:57:58.722070 EDT | -----------------------  --------------
2017-06-03 15:57:58.722530 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #403 | Training started
2017-06-03 15:58:18.594277 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #403 | Training finished
2017-06-03 15:58:18.595183 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #403 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 15:58:18.595598 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #403 | Collecting samples for evaluation
2017-06-03 15:58:28.971422 EDT | -----------------------  --------------
2017-06-03 15:58:28.971941 EDT | Epoch                     403
2017-06-03 15:58:28.972279 EDT | Iteration                 403
2017-06-03 15:58:28.972603 EDT | AverageReturn            1000
2017-06-03 15:58:28.972938 EDT | StdReturn                   0
2017-06-03 15:58:28.973254 EDT | MaxReturn                1000
2017-06-03 15:58:28.973563 EDT | MinReturn                1000
2017-06-03 15:58:28.973897 EDT | AverageEsReturn            44.48
2017-06-03 15:58:28.974218 EDT | StdEsReturn                49.1773
2017-06-03 15:58:28.974530 EDT | MaxEsReturn               238
2017-06-03 15:58:28.974842 EDT | MinEsReturn                 3
2017-06-03 15:58:28.975148 EDT | AverageDiscountedReturn    99.9957
2017-06-03 15:58:28.975475 EDT | AverageQLoss                2.96583e-05
2017-06-03 15:58:28.975794 EDT | AveragePolicySurr          -0.101921
2017-06-03 15:58:28.976100 EDT | AverageQ                    0.0972311
2017-06-03 15:58:28.976407 EDT | AverageAbsQ                 0.097481
2017-06-03 15:58:28.976721 EDT | AverageY                    0.0972374
2017-06-03 15:58:28.977027 EDT | AverageAbsY                 0.0972452
2017-06-03 15:58:28.977335 EDT | AverageAbsQYDiff            0.00146942
2017-06-03 15:58:28.977664 EDT | AverageAction               0.0035589
2017-06-03 15:58:28.978256 EDT | PolicyRegParamNorm         59.7735
2017-06-03 15:58:28.978749 EDT | QFunRegParamNorm           26.7105
2017-06-03 15:58:28.979270 EDT | -----------------------  --------------
2017-06-03 15:58:28.979901 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #404 | Training started
2017-06-03 15:58:46.900140 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #404 | Training finished
2017-06-03 15:58:46.901090 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #404 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 15:58:46.901374 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #404 | Collecting samples for evaluation
2017-06-03 15:58:57.411905 EDT | -----------------------  --------------
2017-06-03 15:58:57.412818 EDT | Epoch                     404
2017-06-03 15:58:57.413086 EDT | Iteration                 404
2017-06-03 15:58:57.413333 EDT | AverageReturn            1000
2017-06-03 15:58:57.413570 EDT | StdReturn                   0
2017-06-03 15:58:57.413819 EDT | MaxReturn                1000
2017-06-03 15:58:57.414054 EDT | MinReturn                1000
2017-06-03 15:58:57.414287 EDT | AverageEsReturn            37.48
2017-06-03 15:58:57.414519 EDT | StdEsReturn                35.8911
2017-06-03 15:58:57.414752 EDT | MaxEsReturn               186
2017-06-03 15:58:57.414984 EDT | MinEsReturn                 7
2017-06-03 15:58:57.415216 EDT | AverageDiscountedReturn    99.9957
2017-06-03 15:58:57.415461 EDT | AverageQLoss                3.59528e-05
2017-06-03 15:58:57.415692 EDT | AveragePolicySurr          -0.101659
2017-06-03 15:58:57.415923 EDT | AverageQ                    0.0971006
2017-06-03 15:58:57.416154 EDT | AverageAbsQ                 0.0973628
2017-06-03 15:58:57.416385 EDT | AverageY                    0.0970949
2017-06-03 15:58:57.416616 EDT | AverageAbsY                 0.0971058
2017-06-03 15:58:57.416846 EDT | AverageAbsQYDiff            0.00160442
2017-06-03 15:58:57.417076 EDT | AverageAction               0.0178873
2017-06-03 15:58:57.417306 EDT | PolicyRegParamNorm         59.8276
2017-06-03 15:58:57.417542 EDT | QFunRegParamNorm           26.7035
2017-06-03 15:58:57.417788 EDT | -----------------------  --------------
2017-06-03 15:58:57.418181 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #405 | Training started
2017-06-03 15:59:15.789068 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #405 | Training finished
2017-06-03 15:59:15.789992 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #405 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 15:59:15.790272 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #405 | Collecting samples for evaluation
2017-06-03 15:59:24.951386 EDT | -----------------------  --------------
2017-06-03 15:59:24.952265 EDT | Epoch                     405
2017-06-03 15:59:24.952527 EDT | Iteration                 405
2017-06-03 15:59:24.952771 EDT | AverageReturn            1000
2017-06-03 15:59:24.953023 EDT | StdReturn                   0
2017-06-03 15:59:24.953276 EDT | MaxReturn                1000
2017-06-03 15:59:24.953529 EDT | MinReturn                1000
2017-06-03 15:59:24.953775 EDT | AverageEsReturn            44
2017-06-03 15:59:24.954010 EDT | StdEsReturn                35.0751
2017-06-03 15:59:24.954244 EDT | MaxEsReturn               114
2017-06-03 15:59:24.954481 EDT | MinEsReturn                 5
2017-06-03 15:59:24.954727 EDT | AverageDiscountedReturn    99.9957
2017-06-03 15:59:24.954963 EDT | AverageQLoss                3.85853e-05
2017-06-03 15:59:24.955196 EDT | AveragePolicySurr          -0.101652
2017-06-03 15:59:24.955427 EDT | AverageQ                    0.0968817
2017-06-03 15:59:24.955663 EDT | AverageAbsQ                 0.0972075
2017-06-03 15:59:24.955895 EDT | AverageY                    0.0968855
2017-06-03 15:59:24.956126 EDT | AverageAbsY                 0.0968993
2017-06-03 15:59:24.956356 EDT | AverageAbsQYDiff            0.00174616
2017-06-03 15:59:24.956587 EDT | AverageAction               0.0115446
2017-06-03 15:59:24.956818 EDT | PolicyRegParamNorm         59.8537
2017-06-03 15:59:24.957048 EDT | QFunRegParamNorm           26.7111
2017-06-03 15:59:24.957279 EDT | -----------------------  --------------
2017-06-03 15:59:24.957688 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #406 | Training started
2017-06-03 15:59:43.619368 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #406 | Training finished
2017-06-03 15:59:43.620231 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #406 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 15:59:43.620502 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #406 | Collecting samples for evaluation
2017-06-03 15:59:54.493866 EDT | -----------------------  --------------
2017-06-03 15:59:54.494858 EDT | Epoch                     406
2017-06-03 15:59:54.495236 EDT | Iteration                 406
2017-06-03 15:59:54.495674 EDT | AverageReturn            1000
2017-06-03 15:59:54.496144 EDT | StdReturn                   0
2017-06-03 15:59:54.496548 EDT | MaxReturn                1000
2017-06-03 15:59:54.496936 EDT | MinReturn                1000
2017-06-03 15:59:54.497352 EDT | AverageEsReturn            37.8214
2017-06-03 15:59:54.497761 EDT | StdEsReturn                33.4451
2017-06-03 15:59:54.498170 EDT | MaxEsReturn               147
2017-06-03 15:59:54.498578 EDT | MinEsReturn                 4
2017-06-03 15:59:54.498990 EDT | AverageDiscountedReturn    99.9957
2017-06-03 15:59:54.499368 EDT | AverageQLoss                3.00062e-05
2017-06-03 15:59:54.499729 EDT | AveragePolicySurr          -0.101461
2017-06-03 15:59:54.500128 EDT | AverageQ                    0.096691
2017-06-03 15:59:54.500505 EDT | AverageAbsQ                 0.0970101
2017-06-03 15:59:54.500874 EDT | AverageY                    0.096692
2017-06-03 15:59:54.501221 EDT | AverageAbsY                 0.0967067
2017-06-03 15:59:54.501560 EDT | AverageAbsQYDiff            0.00165601
2017-06-03 15:59:54.501923 EDT | AverageAction               0.00833037
2017-06-03 15:59:54.502282 EDT | PolicyRegParamNorm         59.8996
2017-06-03 15:59:54.502665 EDT | QFunRegParamNorm           26.7182
2017-06-03 15:59:54.503015 EDT | -----------------------  --------------
2017-06-03 15:59:54.503750 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #407 | Training started
2017-06-03 16:00:13.199125 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #407 | Training finished
2017-06-03 16:00:13.199975 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #407 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 16:00:13.200253 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #407 | Collecting samples for evaluation
2017-06-03 16:00:22.758896 EDT | -----------------------  --------------
2017-06-03 16:00:22.759912 EDT | Epoch                     407
2017-06-03 16:00:22.760185 EDT | Iteration                 407
2017-06-03 16:00:22.760440 EDT | AverageReturn            1000
2017-06-03 16:00:22.760688 EDT | StdReturn                   0
2017-06-03 16:00:22.760938 EDT | MaxReturn                1000
2017-06-03 16:00:22.761176 EDT | MinReturn                1000
2017-06-03 16:00:22.761414 EDT | AverageEsReturn            18.2642
2017-06-03 16:00:22.761654 EDT | StdEsReturn                15.2206
2017-06-03 16:00:22.761908 EDT | MaxEsReturn                59
2017-06-03 16:00:22.762181 EDT | MinEsReturn                 3
2017-06-03 16:00:22.762425 EDT | AverageDiscountedReturn    99.9957
2017-06-03 16:00:22.762666 EDT | AverageQLoss                4.31826e-05
2017-06-03 16:00:22.762907 EDT | AveragePolicySurr          -0.101195
2017-06-03 16:00:22.763148 EDT | AverageQ                    0.0961997
2017-06-03 16:00:22.763397 EDT | AverageAbsQ                 0.096534
2017-06-03 16:00:22.763635 EDT | AverageY                    0.0961999
2017-06-03 16:00:22.763875 EDT | AverageAbsY                 0.0962239
2017-06-03 16:00:22.764123 EDT | AverageAbsQYDiff            0.00184661
2017-06-03 16:00:22.764363 EDT | AverageAction               0.0503479
2017-06-03 16:00:22.764605 EDT | PolicyRegParamNorm         59.9232
2017-06-03 16:00:22.764843 EDT | QFunRegParamNorm           26.7278
2017-06-03 16:00:22.765082 EDT | -----------------------  --------------
2017-06-03 16:00:22.765469 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #408 | Training started
2017-06-03 16:00:41.339678 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #408 | Training finished
2017-06-03 16:00:41.340608 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #408 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 16:00:41.341099 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #408 | Collecting samples for evaluation
2017-06-03 16:00:51.394830 EDT | -----------------------  --------------
2017-06-03 16:00:51.395825 EDT | Epoch                     408
2017-06-03 16:00:51.396132 EDT | Iteration                 408
2017-06-03 16:00:51.396412 EDT | AverageReturn            1000
2017-06-03 16:00:51.396726 EDT | StdReturn                   0
2017-06-03 16:00:51.396994 EDT | MaxReturn                1000
2017-06-03 16:00:51.397228 EDT | MinReturn                1000
2017-06-03 16:00:51.397477 EDT | AverageEsReturn            36.3571
2017-06-03 16:00:51.398141 EDT | StdEsReturn                28.9756
2017-06-03 16:00:51.398478 EDT | MaxEsReturn               122
2017-06-03 16:00:51.398808 EDT | MinEsReturn                 5
2017-06-03 16:00:51.399170 EDT | AverageDiscountedReturn    99.9957
2017-06-03 16:00:51.399484 EDT | AverageQLoss                3.50717e-05
2017-06-03 16:00:51.399796 EDT | AveragePolicySurr          -0.101163
2017-06-03 16:00:51.400128 EDT | AverageQ                    0.0963933
2017-06-03 16:00:51.400456 EDT | AverageAbsQ                 0.0966526
2017-06-03 16:00:51.400771 EDT | AverageY                    0.0963897
2017-06-03 16:00:51.401080 EDT | AverageAbsY                 0.0964117
2017-06-03 16:00:51.401391 EDT | AverageAbsQYDiff            0.00165292
2017-06-03 16:00:51.401776 EDT | AverageAction               0.000128382
2017-06-03 16:00:51.402202 EDT | PolicyRegParamNorm         59.9418
2017-06-03 16:00:51.402652 EDT | QFunRegParamNorm           26.7327
2017-06-03 16:00:51.403027 EDT | -----------------------  --------------
2017-06-03 16:00:51.403640 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #409 | Training started
2017-06-03 16:01:09.613717 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #409 | Training finished
2017-06-03 16:01:09.736229 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #409 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 16:01:09.736617 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #409 | Collecting samples for evaluation
2017-06-03 16:01:19.084207 EDT | -----------------------  --------------
2017-06-03 16:01:19.085057 EDT | Epoch                     409
2017-06-03 16:01:19.085329 EDT | Iteration                 409
2017-06-03 16:01:19.085581 EDT | AverageReturn            1000
2017-06-03 16:01:19.085842 EDT | StdReturn                   0
2017-06-03 16:01:19.086088 EDT | MaxReturn                1000
2017-06-03 16:01:19.086331 EDT | MinReturn                1000
2017-06-03 16:01:19.086573 EDT | AverageEsReturn            40.68
2017-06-03 16:01:19.086817 EDT | StdEsReturn                28.3446
2017-06-03 16:01:19.087059 EDT | MaxEsReturn               117
2017-06-03 16:01:19.087301 EDT | MinEsReturn                 8
2017-06-03 16:01:19.087542 EDT | AverageDiscountedReturn    99.9957
2017-06-03 16:01:19.087870 EDT | AverageQLoss                3.90833e-05
2017-06-03 16:01:19.088201 EDT | AveragePolicySurr          -0.101057
2017-06-03 16:01:19.088521 EDT | AverageQ                    0.0965085
2017-06-03 16:01:19.088838 EDT | AverageAbsQ                 0.0968472
2017-06-03 16:01:19.089154 EDT | AverageY                    0.0965085
2017-06-03 16:01:19.089469 EDT | AverageAbsY                 0.0965251
2017-06-03 16:01:19.089795 EDT | AverageAbsQYDiff            0.00182906
2017-06-03 16:01:19.090109 EDT | AverageAction               0.000339664
2017-06-03 16:01:19.090424 EDT | PolicyRegParamNorm         59.9555
2017-06-03 16:01:19.090733 EDT | QFunRegParamNorm           26.7233
2017-06-03 16:01:19.091043 EDT | -----------------------  --------------
2017-06-03 16:01:19.091518 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #410 | Training started
2017-06-03 16:01:37.400569 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #410 | Training finished
2017-06-03 16:01:37.401441 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #410 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 16:01:37.401724 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #410 | Collecting samples for evaluation
2017-06-03 16:01:46.301272 EDT | -----------------------  --------------
2017-06-03 16:01:46.302308 EDT | Epoch                     410
2017-06-03 16:01:46.302566 EDT | Iteration                 410
2017-06-03 16:01:46.302795 EDT | AverageReturn            1000
2017-06-03 16:01:46.303056 EDT | StdReturn                   0
2017-06-03 16:01:46.303278 EDT | MaxReturn                1000
2017-06-03 16:01:46.303514 EDT | MinReturn                1000
2017-06-03 16:01:46.303762 EDT | AverageEsReturn            25.4615
2017-06-03 16:01:46.303984 EDT | StdEsReturn                18.9735
2017-06-03 16:01:46.304203 EDT | MaxEsReturn                81
2017-06-03 16:01:46.304420 EDT | MinEsReturn                 3
2017-06-03 16:01:46.304631 EDT | AverageDiscountedReturn    99.9957
2017-06-03 16:01:46.304849 EDT | AverageQLoss                3.53257e-05
2017-06-03 16:01:46.305058 EDT | AveragePolicySurr          -0.100764
2017-06-03 16:01:46.305265 EDT | AverageQ                    0.0962328
2017-06-03 16:01:46.305480 EDT | AverageAbsQ                 0.0965276
2017-06-03 16:01:46.306103 EDT | AverageY                    0.0962346
2017-06-03 16:01:46.306442 EDT | AverageAbsY                 0.0962418
2017-06-03 16:01:46.306748 EDT | AverageAbsQYDiff            0.00168338
2017-06-03 16:01:46.307051 EDT | AverageAction               0.000525134
2017-06-03 16:01:46.307354 EDT | PolicyRegParamNorm         60.0208
2017-06-03 16:01:46.307662 EDT | QFunRegParamNorm           26.7227
2017-06-03 16:01:46.307965 EDT | -----------------------  --------------
2017-06-03 16:01:46.308429 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #411 | Training started
2017-06-03 16:02:04.322600 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #411 | Training finished
2017-06-03 16:02:04.323491 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #411 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 16:02:04.323857 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #411 | Collecting samples for evaluation
2017-06-03 16:02:13.766692 EDT | -----------------------  --------------
2017-06-03 16:02:13.767163 EDT | Epoch                     411
2017-06-03 16:02:13.767441 EDT | Iteration                 411
2017-06-03 16:02:13.767712 EDT | AverageReturn            1000
2017-06-03 16:02:13.767980 EDT | StdReturn                   0
2017-06-03 16:02:13.768238 EDT | MaxReturn                1000
2017-06-03 16:02:13.768506 EDT | MinReturn                1000
2017-06-03 16:02:13.768753 EDT | AverageEsReturn            29.5588
2017-06-03 16:02:13.769007 EDT | StdEsReturn                18.5047
2017-06-03 16:02:13.769259 EDT | MaxEsReturn                68
2017-06-03 16:02:13.769502 EDT | MinEsReturn                 3
2017-06-03 16:02:13.769758 EDT | AverageDiscountedReturn    99.9957
2017-06-03 16:02:13.770004 EDT | AverageQLoss                3.65966e-05
2017-06-03 16:02:13.770249 EDT | AveragePolicySurr          -0.100527
2017-06-03 16:02:13.770496 EDT | AverageQ                    0.0958177
2017-06-03 16:02:13.770739 EDT | AverageAbsQ                 0.0961035
2017-06-03 16:02:13.770982 EDT | AverageY                    0.095811
2017-06-03 16:02:13.771225 EDT | AverageAbsY                 0.0958192
2017-06-03 16:02:13.771467 EDT | AverageAbsQYDiff            0.00164964
2017-06-03 16:02:13.771709 EDT | AverageAction               0.000676866
2017-06-03 16:02:13.771950 EDT | PolicyRegParamNorm         60.0732
2017-06-03 16:02:13.772192 EDT | QFunRegParamNorm           26.7239
2017-06-03 16:02:13.772434 EDT | -----------------------  --------------
2017-06-03 16:02:13.772819 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #412 | Training started
2017-06-03 16:02:32.512052 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #412 | Training finished
2017-06-03 16:02:32.513013 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #412 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 16:02:32.513389 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #412 | Collecting samples for evaluation
2017-06-03 16:02:41.635585 EDT | -----------------------  --------------
2017-06-03 16:02:41.636558 EDT | Epoch                     412
2017-06-03 16:02:41.636926 EDT | Iteration                 412
2017-06-03 16:02:41.637271 EDT | AverageReturn            1000
2017-06-03 16:02:41.637595 EDT | StdReturn                   0
2017-06-03 16:02:41.637924 EDT | MaxReturn                1000
2017-06-03 16:02:41.638248 EDT | MinReturn                1000
2017-06-03 16:02:41.638561 EDT | AverageEsReturn            31.3438
2017-06-03 16:02:41.638879 EDT | StdEsReturn                27.5745
2017-06-03 16:02:41.639192 EDT | MaxEsReturn               147
2017-06-03 16:02:41.639509 EDT | MinEsReturn                 3
2017-06-03 16:02:41.639820 EDT | AverageDiscountedReturn    99.9957
2017-06-03 16:02:41.640130 EDT | AverageQLoss                2.78353e-05
2017-06-03 16:02:41.640441 EDT | AveragePolicySurr          -0.100702
2017-06-03 16:02:41.640751 EDT | AverageQ                    0.0961651
2017-06-03 16:02:41.641060 EDT | AverageAbsQ                 0.0964034
2017-06-03 16:02:41.641369 EDT | AverageY                    0.0961706
2017-06-03 16:02:41.641678 EDT | AverageAbsY                 0.096182
2017-06-03 16:02:41.641997 EDT | AverageAbsQYDiff            0.00141225
2017-06-03 16:02:41.642305 EDT | AverageAction               0.000539511
2017-06-03 16:02:41.642615 EDT | PolicyRegParamNorm         60.119
2017-06-03 16:02:41.642921 EDT | QFunRegParamNorm           26.7368
2017-06-03 16:02:41.643228 EDT | -----------------------  --------------
2017-06-03 16:02:41.643680 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #413 | Training started
2017-06-03 16:03:00.064161 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #413 | Training finished
2017-06-03 16:03:00.065066 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #413 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 16:03:00.065432 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #413 | Collecting samples for evaluation
2017-06-03 16:03:10.063981 EDT | -----------------------  --------------
2017-06-03 16:03:10.064994 EDT | Epoch                     413
2017-06-03 16:03:10.065370 EDT | Iteration                 413
2017-06-03 16:03:10.065722 EDT | AverageReturn            1000
2017-06-03 16:03:10.066046 EDT | StdReturn                   0
2017-06-03 16:03:10.066389 EDT | MaxReturn                1000
2017-06-03 16:03:10.066735 EDT | MinReturn                1000
2017-06-03 16:03:10.067033 EDT | AverageEsReturn            30.0625
2017-06-03 16:03:10.067327 EDT | StdEsReturn                31.4175
2017-06-03 16:03:10.067621 EDT | MaxEsReturn               113
2017-06-03 16:03:10.067915 EDT | MinEsReturn                 3
2017-06-03 16:03:10.068209 EDT | AverageDiscountedReturn    99.9957
2017-06-03 16:03:10.068499 EDT | AverageQLoss                3.32679e-05
2017-06-03 16:03:10.068856 EDT | AveragePolicySurr          -0.100457
2017-06-03 16:03:10.069168 EDT | AverageQ                    0.0958342
2017-06-03 16:03:10.069479 EDT | AverageAbsQ                 0.0961187
2017-06-03 16:03:10.069810 EDT | AverageY                    0.0958285
2017-06-03 16:03:10.070127 EDT | AverageAbsY                 0.0958495
2017-06-03 16:03:10.070442 EDT | AverageAbsQYDiff            0.00157783
2017-06-03 16:03:10.070764 EDT | AverageAction               0.000597509
2017-06-03 16:03:10.071072 EDT | PolicyRegParamNorm         60.1559
2017-06-03 16:03:10.071380 EDT | QFunRegParamNorm           26.7578
2017-06-03 16:03:10.071693 EDT | -----------------------  --------------
2017-06-03 16:03:10.072118 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #414 | Training started
2017-06-03 16:03:29.692443 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #414 | Training finished
2017-06-03 16:03:29.693366 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #414 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 16:03:29.693660 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #414 | Collecting samples for evaluation
2017-06-03 16:03:39.777545 EDT | -----------------------  --------------
2017-06-03 16:03:39.778523 EDT | Epoch                     414
2017-06-03 16:03:39.778871 EDT | Iteration                 414
2017-06-03 16:03:39.779191 EDT | AverageReturn            1000
2017-06-03 16:03:39.779515 EDT | StdReturn                   0
2017-06-03 16:03:39.779838 EDT | MaxReturn                1000
2017-06-03 16:03:39.780153 EDT | MinReturn                1000
2017-06-03 16:03:39.780464 EDT | AverageEsReturn            31.6562
2017-06-03 16:03:39.780812 EDT | StdEsReturn                24.5632
2017-06-03 16:03:39.781122 EDT | MaxEsReturn               109
2017-06-03 16:03:39.781432 EDT | MinEsReturn                 5
2017-06-03 16:03:39.781755 EDT | AverageDiscountedReturn    99.9957
2017-06-03 16:03:39.782073 EDT | AverageQLoss                3.89287e-05
2017-06-03 16:03:39.782389 EDT | AveragePolicySurr          -0.100248
2017-06-03 16:03:39.782696 EDT | AverageQ                    0.0954222
2017-06-03 16:03:39.783000 EDT | AverageAbsQ                 0.0957427
2017-06-03 16:03:39.783306 EDT | AverageY                    0.0954268
2017-06-03 16:03:39.783610 EDT | AverageAbsY                 0.0954425
2017-06-03 16:03:39.783914 EDT | AverageAbsQYDiff            0.00179801
2017-06-03 16:03:39.784242 EDT | AverageAction               0.000550854
2017-06-03 16:03:39.784573 EDT | PolicyRegParamNorm         60.2264
2017-06-03 16:03:39.785118 EDT | QFunRegParamNorm           26.745
2017-06-03 16:03:39.785600 EDT | -----------------------  --------------
2017-06-03 16:03:39.786315 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #415 | Training started
2017-06-03 16:03:58.345309 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #415 | Training finished
2017-06-03 16:03:58.346273 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #415 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 16:03:58.346901 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #415 | Collecting samples for evaluation
2017-06-03 16:04:08.072659 EDT | -----------------------  --------------
2017-06-03 16:04:08.073969 EDT | Epoch                     415
2017-06-03 16:04:08.074243 EDT | Iteration                 415
2017-06-03 16:04:08.074484 EDT | AverageReturn            1000
2017-06-03 16:04:08.074720 EDT | StdReturn                   0
2017-06-03 16:04:08.074954 EDT | MaxReturn                1000
2017-06-03 16:04:08.075200 EDT | MinReturn                1000
2017-06-03 16:04:08.075443 EDT | AverageEsReturn            21.5957
2017-06-03 16:04:08.075676 EDT | StdEsReturn                19.2405
2017-06-03 16:04:08.075908 EDT | MaxEsReturn                99
2017-06-03 16:04:08.076139 EDT | MinEsReturn                 3
2017-06-03 16:04:08.076371 EDT | AverageDiscountedReturn    99.9957
2017-06-03 16:04:08.076602 EDT | AverageQLoss                3.58797e-05
2017-06-03 16:04:08.076832 EDT | AveragePolicySurr          -0.0999449
2017-06-03 16:04:08.077063 EDT | AverageQ                    0.0950901
2017-06-03 16:04:08.077314 EDT | AverageAbsQ                 0.0953647
2017-06-03 16:04:08.077546 EDT | AverageY                    0.0950953
2017-06-03 16:04:08.077798 EDT | AverageAbsY                 0.0951119
2017-06-03 16:04:08.078031 EDT | AverageAbsQYDiff            0.00163807
2017-06-03 16:04:08.078272 EDT | AverageAction               0.0985308
2017-06-03 16:04:08.078503 EDT | PolicyRegParamNorm         60.2059
2017-06-03 16:04:08.078733 EDT | QFunRegParamNorm           26.7442
2017-06-03 16:04:08.078971 EDT | -----------------------  --------------
2017-06-03 16:04:08.079333 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #416 | Training started
2017-06-03 16:04:26.673769 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #416 | Training finished
2017-06-03 16:04:26.674639 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #416 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 16:04:26.675039 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #416 | Collecting samples for evaluation
2017-06-03 16:04:35.862737 EDT | -----------------------  --------------
2017-06-03 16:04:35.863587 EDT | Epoch                     416
2017-06-03 16:04:35.863842 EDT | Iteration                 416
2017-06-03 16:04:35.864075 EDT | AverageReturn            1000
2017-06-03 16:04:35.864302 EDT | StdReturn                   0
2017-06-03 16:04:35.864525 EDT | MaxReturn                1000
2017-06-03 16:04:35.864749 EDT | MinReturn                1000
2017-06-03 16:04:35.864976 EDT | AverageEsReturn            13.6901
2017-06-03 16:04:35.865200 EDT | StdEsReturn                10.1129
2017-06-03 16:04:35.865423 EDT | MaxEsReturn                49
2017-06-03 16:04:35.865644 EDT | MinEsReturn                 3
2017-06-03 16:04:35.865901 EDT | AverageDiscountedReturn    99.9957
2017-06-03 16:04:35.866179 EDT | AverageQLoss                3.50147e-05
2017-06-03 16:04:35.866435 EDT | AveragePolicySurr          -0.0996761
2017-06-03 16:04:35.866686 EDT | AverageQ                    0.0949628
2017-06-03 16:04:35.866934 EDT | AverageAbsQ                 0.0952448
2017-06-03 16:04:35.867181 EDT | AverageY                    0.0949679
2017-06-03 16:04:35.867435 EDT | AverageAbsY                 0.0949833
2017-06-03 16:04:35.867681 EDT | AverageAbsQYDiff            0.00169737
2017-06-03 16:04:35.867927 EDT | AverageAction               0.110221
2017-06-03 16:04:35.868172 EDT | PolicyRegParamNorm         60.2657
2017-06-03 16:04:35.868418 EDT | QFunRegParamNorm           26.7384
2017-06-03 16:04:35.868665 EDT | -----------------------  --------------
2017-06-03 16:04:35.869048 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #417 | Training started
2017-06-03 16:04:54.501827 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #417 | Training finished
2017-06-03 16:04:54.502858 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #417 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 16:04:54.503274 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #417 | Collecting samples for evaluation
2017-06-03 16:05:03.011617 EDT | -----------------------  --------------
2017-06-03 16:05:03.012479 EDT | Epoch                     417
2017-06-03 16:05:03.012766 EDT | Iteration                 417
2017-06-03 16:05:03.013010 EDT | AverageReturn            1000
2017-06-03 16:05:03.013247 EDT | StdReturn                   0
2017-06-03 16:05:03.013514 EDT | MaxReturn                1000
2017-06-03 16:05:03.013784 EDT | MinReturn                1000
2017-06-03 16:05:03.014020 EDT | AverageEsReturn            24.7143
2017-06-03 16:05:03.014255 EDT | StdEsReturn                19.0129
2017-06-03 16:05:03.014492 EDT | MaxEsReturn                66
2017-06-03 16:05:03.014735 EDT | MinEsReturn                 3
2017-06-03 16:05:03.014988 EDT | AverageDiscountedReturn    99.9957
2017-06-03 16:05:03.015222 EDT | AverageQLoss                3.40314e-05
2017-06-03 16:05:03.015453 EDT | AveragePolicySurr          -0.0998475
2017-06-03 16:05:03.015685 EDT | AverageQ                    0.0950682
2017-06-03 16:05:03.015938 EDT | AverageAbsQ                 0.0953363
2017-06-03 16:05:03.016171 EDT | AverageY                    0.0950573
2017-06-03 16:05:03.016402 EDT | AverageAbsY                 0.0950801
2017-06-03 16:05:03.016632 EDT | AverageAbsQYDiff            0.00161692
2017-06-03 16:05:03.016863 EDT | AverageAction               0.00772214
2017-06-03 16:05:03.017112 EDT | PolicyRegParamNorm         60.3198
2017-06-03 16:05:03.017344 EDT | QFunRegParamNorm           26.754
2017-06-03 16:05:03.017575 EDT | -----------------------  --------------
2017-06-03 16:05:03.018177 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #418 | Training started
2017-06-03 16:05:21.130284 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #418 | Training finished
2017-06-03 16:05:21.131182 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #418 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 16:05:21.131639 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #418 | Collecting samples for evaluation
2017-06-03 16:05:31.251016 EDT | -----------------------  --------------
2017-06-03 16:05:31.252113 EDT | Epoch                     418
2017-06-03 16:05:31.252484 EDT | Iteration                 418
2017-06-03 16:05:31.252733 EDT | AverageReturn            1000
2017-06-03 16:05:31.252981 EDT | StdReturn                   0
2017-06-03 16:05:31.253221 EDT | MaxReturn                1000
2017-06-03 16:05:31.253467 EDT | MinReturn                1000
2017-06-03 16:05:31.253773 EDT | AverageEsReturn            24.2683
2017-06-03 16:05:31.254019 EDT | StdEsReturn                18.5617
2017-06-03 16:05:31.254311 EDT | MaxEsReturn                80
2017-06-03 16:05:31.254586 EDT | MinEsReturn                 3
2017-06-03 16:05:31.254866 EDT | AverageDiscountedReturn    99.9957
2017-06-03 16:05:31.255121 EDT | AverageQLoss                3.49301e-05
2017-06-03 16:05:31.255365 EDT | AveragePolicySurr          -0.0997959
2017-06-03 16:05:31.255606 EDT | AverageQ                    0.0950682
2017-06-03 16:05:31.255838 EDT | AverageAbsQ                 0.0953693
2017-06-03 16:05:31.256067 EDT | AverageY                    0.0950708
2017-06-03 16:05:31.256295 EDT | AverageAbsY                 0.0950856
2017-06-03 16:05:31.256525 EDT | AverageAbsQYDiff            0.00173368
2017-06-03 16:05:31.256756 EDT | AverageAction               0.00519382
2017-06-03 16:05:31.256993 EDT | PolicyRegParamNorm         60.402
2017-06-03 16:05:31.257222 EDT | QFunRegParamNorm           26.7677
2017-06-03 16:05:31.257449 EDT | -----------------------  --------------
2017-06-03 16:05:31.257809 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #419 | Training started
2017-06-03 16:05:49.314964 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #419 | Training finished
2017-06-03 16:05:49.315818 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #419 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 16:05:49.316077 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #419 | Collecting samples for evaluation
2017-06-03 16:05:59.358297 EDT | -----------------------  --------------
2017-06-03 16:05:59.358688 EDT | Epoch                     419
2017-06-03 16:05:59.359047 EDT | Iteration                 419
2017-06-03 16:05:59.359371 EDT | AverageReturn            1000
2017-06-03 16:05:59.359691 EDT | StdReturn                   0
2017-06-03 16:05:59.360015 EDT | MaxReturn                1000
2017-06-03 16:05:59.360328 EDT | MinReturn                1000
2017-06-03 16:05:59.360641 EDT | AverageEsReturn            23.0465
2017-06-03 16:05:59.360955 EDT | StdEsReturn                18.5007
2017-06-03 16:05:59.361268 EDT | MaxEsReturn               103
2017-06-03 16:05:59.361581 EDT | MinEsReturn                 3
2017-06-03 16:05:59.361905 EDT | AverageDiscountedReturn    99.9957
2017-06-03 16:05:59.362233 EDT | AverageQLoss                3.62105e-05
2017-06-03 16:05:59.362545 EDT | AveragePolicySurr          -0.0995854
2017-06-03 16:05:59.362853 EDT | AverageQ                    0.0950606
2017-06-03 16:05:59.363170 EDT | AverageAbsQ                 0.0953231
2017-06-03 16:05:59.363478 EDT | AverageY                    0.0950594
2017-06-03 16:05:59.363788 EDT | AverageAbsY                 0.0950795
2017-06-03 16:05:59.364093 EDT | AverageAbsQYDiff            0.00162956
2017-06-03 16:05:59.364399 EDT | AverageAction               0.0856891
2017-06-03 16:05:59.364705 EDT | PolicyRegParamNorm         60.4537
2017-06-03 16:05:59.365011 EDT | QFunRegParamNorm           26.7809
2017-06-03 16:05:59.365316 EDT | -----------------------  --------------
2017-06-03 16:05:59.365806 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #420 | Training started
2017-06-03 16:06:18.819481 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #420 | Training finished
2017-06-03 16:06:18.820444 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #420 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 16:06:18.820845 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #420 | Collecting samples for evaluation
2017-06-03 16:06:28.435856 EDT | -----------------------  --------------
2017-06-03 16:06:28.436807 EDT | Epoch                     420
2017-06-03 16:06:28.437155 EDT | Iteration                 420
2017-06-03 16:06:28.437483 EDT | AverageReturn            1000
2017-06-03 16:06:28.437779 EDT | StdReturn                   0
2017-06-03 16:06:28.438015 EDT | MaxReturn                1000
2017-06-03 16:06:28.438273 EDT | MinReturn                1000
2017-06-03 16:06:28.438588 EDT | AverageEsReturn            28.4857
2017-06-03 16:06:28.438901 EDT | StdEsReturn                23.7563
2017-06-03 16:06:28.439252 EDT | MaxEsReturn                96
2017-06-03 16:06:28.439571 EDT | MinEsReturn                 3
2017-06-03 16:06:28.439889 EDT | AverageDiscountedReturn    99.9957
2017-06-03 16:06:28.440213 EDT | AverageQLoss                3.31822e-05
2017-06-03 16:06:28.440484 EDT | AveragePolicySurr          -0.0993619
2017-06-03 16:06:28.440775 EDT | AverageQ                    0.0948441
2017-06-03 16:06:28.441096 EDT | AverageAbsQ                 0.09515
2017-06-03 16:06:28.441399 EDT | AverageY                    0.0948387
2017-06-03 16:06:28.441711 EDT | AverageAbsY                 0.0948593
2017-06-03 16:06:28.442021 EDT | AverageAbsQYDiff            0.00167425
2017-06-03 16:06:28.442345 EDT | AverageAction               0.07651
2017-06-03 16:06:28.442607 EDT | PolicyRegParamNorm         60.4837
2017-06-03 16:06:28.442915 EDT | QFunRegParamNorm           26.7794
2017-06-03 16:06:28.443215 EDT | -----------------------  --------------
2017-06-03 16:06:28.443641 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #421 | Training started
2017-06-03 16:06:46.963207 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #421 | Training finished
2017-06-03 16:06:46.964223 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #421 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 16:06:46.964718 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #421 | Collecting samples for evaluation
2017-06-03 16:06:56.428520 EDT | -----------------------  --------------
2017-06-03 16:06:56.429367 EDT | Epoch                     421
2017-06-03 16:06:56.429635 EDT | Iteration                 421
2017-06-03 16:06:56.429912 EDT | AverageReturn            1000
2017-06-03 16:06:56.430170 EDT | StdReturn                   0
2017-06-03 16:06:56.430415 EDT | MaxReturn                1000
2017-06-03 16:06:56.430654 EDT | MinReturn                1000
2017-06-03 16:06:56.430900 EDT | AverageEsReturn            23.1364
2017-06-03 16:06:56.431137 EDT | StdEsReturn                16.138
2017-06-03 16:06:56.431383 EDT | MaxEsReturn                66
2017-06-03 16:06:56.431618 EDT | MinEsReturn                 3
2017-06-03 16:06:56.431852 EDT | AverageDiscountedReturn    99.9957
2017-06-03 16:06:56.432096 EDT | AverageQLoss                3.75922e-05
2017-06-03 16:06:56.432332 EDT | AveragePolicySurr          -0.0990682
2017-06-03 16:06:56.432565 EDT | AverageQ                    0.0946477
2017-06-03 16:06:56.432801 EDT | AverageAbsQ                 0.0949502
2017-06-03 16:06:56.433035 EDT | AverageY                    0.0946496
2017-06-03 16:06:56.433267 EDT | AverageAbsY                 0.0946725
2017-06-03 16:06:56.433499 EDT | AverageAbsQYDiff            0.00169455
2017-06-03 16:06:56.433747 EDT | AverageAction               0.00331598
2017-06-03 16:06:56.433993 EDT | PolicyRegParamNorm         60.5421
2017-06-03 16:06:56.434226 EDT | QFunRegParamNorm           26.7963
2017-06-03 16:06:56.434467 EDT | -----------------------  --------------
2017-06-03 16:06:56.434845 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #422 | Training started
2017-06-03 16:07:15.247261 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #422 | Training finished
2017-06-03 16:07:15.248825 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #422 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 16:07:15.249157 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #422 | Collecting samples for evaluation
2017-06-03 16:07:24.766980 EDT | -----------------------  -------------
2017-06-03 16:07:24.768060 EDT | Epoch                    422
2017-06-03 16:07:24.768492 EDT | Iteration                422
2017-06-03 16:07:24.768879 EDT | AverageReturn             50.085
2017-06-03 16:07:24.769249 EDT | StdReturn                  0.278882
2017-06-03 16:07:24.769662 EDT | MaxReturn                 51
2017-06-03 16:07:24.770040 EDT | MinReturn                 50
2017-06-03 16:07:24.770386 EDT | AverageEsReturn           25.641
2017-06-03 16:07:24.770729 EDT | StdEsReturn               29.1068
2017-06-03 16:07:24.771084 EDT | MaxEsReturn              174
2017-06-03 16:07:24.771447 EDT | MinEsReturn                2
2017-06-03 16:07:24.771817 EDT | AverageDiscountedReturn   39.5508
2017-06-03 16:07:24.772172 EDT | AverageQLoss               3.35969e-05
2017-06-03 16:07:24.772586 EDT | AveragePolicySurr         -0.0990504
2017-06-03 16:07:24.772938 EDT | AverageQ                   0.0944036
2017-06-03 16:07:24.773340 EDT | AverageAbsQ                0.0946798
2017-06-03 16:07:24.773707 EDT | AverageY                   0.0944105
2017-06-03 16:07:24.774096 EDT | AverageAbsY                0.0944425
2017-06-03 16:07:24.774505 EDT | AverageAbsQYDiff           0.0015741
2017-06-03 16:07:24.774904 EDT | AverageAction              0.140947
2017-06-03 16:07:24.775285 EDT | PolicyRegParamNorm        60.577
2017-06-03 16:07:24.775598 EDT | QFunRegParamNorm          26.8015
2017-06-03 16:07:24.775908 EDT | -----------------------  -------------
2017-06-03 16:07:24.776460 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #423 | Training started
2017-06-03 16:07:43.073307 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #423 | Training finished
2017-06-03 16:07:43.074201 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #423 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 16:07:43.074661 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #423 | Collecting samples for evaluation
2017-06-03 16:07:53.546272 EDT | -----------------------  --------------
2017-06-03 16:07:53.547567 EDT | Epoch                     423
2017-06-03 16:07:53.547839 EDT | Iteration                 423
2017-06-03 16:07:53.548091 EDT | AverageReturn            1000
2017-06-03 16:07:53.548324 EDT | StdReturn                   0
2017-06-03 16:07:53.548552 EDT | MaxReturn                1000
2017-06-03 16:07:53.548784 EDT | MinReturn                1000
2017-06-03 16:07:53.549019 EDT | AverageEsReturn            28.5143
2017-06-03 16:07:53.549246 EDT | StdEsReturn                22.3739
2017-06-03 16:07:53.549473 EDT | MaxEsReturn                87
2017-06-03 16:07:53.549717 EDT | MinEsReturn                 2
2017-06-03 16:07:53.549955 EDT | AverageDiscountedReturn    99.9957
2017-06-03 16:07:53.550183 EDT | AverageQLoss                3.53949e-05
2017-06-03 16:07:53.550409 EDT | AveragePolicySurr          -0.0989944
2017-06-03 16:07:53.550635 EDT | AverageQ                    0.094438
2017-06-03 16:07:53.550861 EDT | AverageAbsQ                 0.0947321
2017-06-03 16:07:53.551086 EDT | AverageY                    0.0944356
2017-06-03 16:07:53.551311 EDT | AverageAbsY                 0.0944599
2017-06-03 16:07:53.551535 EDT | AverageAbsQYDiff            0.00161012
2017-06-03 16:07:53.551764 EDT | AverageAction               0.00415206
2017-06-03 16:07:53.551989 EDT | PolicyRegParamNorm         60.6221
2017-06-03 16:07:53.552215 EDT | QFunRegParamNorm           26.7912
2017-06-03 16:07:53.552468 EDT | -----------------------  --------------
2017-06-03 16:07:53.552841 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #424 | Training started
2017-06-03 16:08:13.114861 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #424 | Training finished
2017-06-03 16:08:13.115719 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #424 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 16:08:13.116122 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #424 | Collecting samples for evaluation
2017-06-03 16:08:22.347781 EDT | -----------------------  -------------
2017-06-03 16:08:22.348770 EDT | Epoch                    424
2017-06-03 16:08:22.349128 EDT | Iteration                424
2017-06-03 16:08:22.349456 EDT | AverageReturn             47.9234
2017-06-03 16:08:22.349803 EDT | StdReturn                  0.265884
2017-06-03 16:08:22.350142 EDT | MaxReturn                 48
2017-06-03 16:08:22.350484 EDT | MinReturn                 47
2017-06-03 16:08:22.350810 EDT | AverageEsReturn           20.0833
2017-06-03 16:08:22.351135 EDT | StdEsReturn               15.3485
2017-06-03 16:08:22.351454 EDT | MaxEsReturn               56
2017-06-03 16:08:22.351798 EDT | MinEsReturn                3
2017-06-03 16:08:22.352113 EDT | AverageDiscountedReturn   38.2233
2017-06-03 16:08:22.352426 EDT | AverageQLoss               4.16766e-05
2017-06-03 16:08:22.352742 EDT | AveragePolicySurr         -0.0990046
2017-06-03 16:08:22.353071 EDT | AverageQ                   0.0944452
2017-06-03 16:08:22.353383 EDT | AverageAbsQ                0.094783
2017-06-03 16:08:22.353698 EDT | AverageY                   0.094435
2017-06-03 16:08:22.354016 EDT | AverageAbsY                0.0944513
2017-06-03 16:08:22.354328 EDT | AverageAbsQYDiff           0.00195332
2017-06-03 16:08:22.354639 EDT | AverageAction              0.134116
2017-06-03 16:08:22.354950 EDT | PolicyRegParamNorm        60.718
2017-06-03 16:08:22.355258 EDT | QFunRegParamNorm          26.7947
2017-06-03 16:08:22.355570 EDT | -----------------------  -------------
2017-06-03 16:08:22.356044 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #425 | Training started
2017-06-03 16:08:40.076707 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #425 | Training finished
2017-06-03 16:08:40.077645 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #425 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 16:08:40.077934 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #425 | Collecting samples for evaluation
2017-06-03 16:08:49.431240 EDT | -----------------------  --------------
2017-06-03 16:08:49.433680 EDT | Epoch                     425
2017-06-03 16:08:49.434041 EDT | Iteration                 425
2017-06-03 16:08:49.434363 EDT | AverageReturn            1000
2017-06-03 16:08:49.434678 EDT | StdReturn                   0
2017-06-03 16:08:49.434998 EDT | MaxReturn                1000
2017-06-03 16:08:49.435310 EDT | MinReturn                1000
2017-06-03 16:08:49.435621 EDT | AverageEsReturn            21.1633
2017-06-03 16:08:49.435931 EDT | StdEsReturn                16.5854
2017-06-03 16:08:49.436242 EDT | MaxEsReturn                64
2017-06-03 16:08:49.436548 EDT | MinEsReturn                 3
2017-06-03 16:08:49.436852 EDT | AverageDiscountedReturn    99.9957
2017-06-03 16:08:49.437156 EDT | AverageQLoss                3.32443e-05
2017-06-03 16:08:49.437461 EDT | AveragePolicySurr          -0.0988517
2017-06-03 16:08:49.437774 EDT | AverageQ                    0.0944105
2017-06-03 16:08:49.438083 EDT | AverageAbsQ                 0.0946441
2017-06-03 16:08:49.438390 EDT | AverageY                    0.0944187
2017-06-03 16:08:49.438698 EDT | AverageAbsY                 0.0944461
2017-06-03 16:08:49.439002 EDT | AverageAbsQYDiff            0.00153384
2017-06-03 16:08:49.439305 EDT | AverageAction               0.00528644
2017-06-03 16:08:49.439611 EDT | PolicyRegParamNorm         60.775
2017-06-03 16:08:49.439911 EDT | QFunRegParamNorm           26.7954
2017-06-03 16:08:49.440211 EDT | -----------------------  --------------
2017-06-03 16:08:49.440662 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #426 | Training started
2017-06-03 16:09:08.809190 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #426 | Training finished
2017-06-03 16:09:08.809939 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #426 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 16:09:08.810345 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #426 | Collecting samples for evaluation
2017-06-03 16:09:19.288759 EDT | -----------------------  --------------
2017-06-03 16:09:19.297139 EDT | Epoch                     426
2017-06-03 16:09:19.297484 EDT | Iteration                 426
2017-06-03 16:09:19.297837 EDT | AverageReturn             100.792
2017-06-03 16:09:19.298192 EDT | StdReturn                 178.128
2017-06-03 16:09:19.298445 EDT | MaxReturn                1000
2017-06-03 16:09:19.298690 EDT | MinReturn                  56
2017-06-03 16:09:19.298928 EDT | AverageEsReturn            19.5
2017-06-03 16:09:19.299165 EDT | StdEsReturn                15.2568
2017-06-03 16:09:19.299409 EDT | MaxEsReturn                71
2017-06-03 16:09:19.299647 EDT | MinEsReturn                 3
2017-06-03 16:09:19.299883 EDT | AverageDiscountedReturn    50.1407
2017-06-03 16:09:19.300116 EDT | AverageQLoss                3.20423e-05
2017-06-03 16:09:19.300348 EDT | AveragePolicySurr          -0.0987581
2017-06-03 16:09:19.300645 EDT | AverageQ                    0.0940913
2017-06-03 16:09:19.300904 EDT | AverageAbsQ                 0.0943496
2017-06-03 16:09:19.301144 EDT | AverageY                    0.0940883
2017-06-03 16:09:19.301382 EDT | AverageAbsY                 0.0941037
2017-06-03 16:09:19.301656 EDT | AverageAbsQYDiff            0.00165808
2017-06-03 16:09:19.301936 EDT | AverageAction               0.106666
2017-06-03 16:09:19.302278 EDT | PolicyRegParamNorm         60.8425
2017-06-03 16:09:19.302659 EDT | QFunRegParamNorm           26.809
2017-06-03 16:09:19.303032 EDT | -----------------------  --------------
2017-06-03 16:09:19.303517 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #427 | Training started
2017-06-03 16:09:38.995598 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #427 | Training finished
2017-06-03 16:09:38.996450 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #427 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 16:09:38.996709 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #427 | Collecting samples for evaluation
2017-06-03 16:09:48.417661 EDT | -----------------------  --------------
2017-06-03 16:09:48.418559 EDT | Epoch                     427
2017-06-03 16:09:48.418876 EDT | Iteration                 427
2017-06-03 16:09:48.419188 EDT | AverageReturn             915.182
2017-06-03 16:09:48.419627 EDT | StdReturn                 268.219
2017-06-03 16:09:48.419975 EDT | MaxReturn                1000
2017-06-03 16:09:48.420302 EDT | MinReturn                  67
2017-06-03 16:09:48.420636 EDT | AverageEsReturn            26.9737
2017-06-03 16:09:48.420976 EDT | StdEsReturn                17.0317
2017-06-03 16:09:48.421299 EDT | MaxEsReturn                79
2017-06-03 16:09:48.421613 EDT | MinEsReturn                 3
2017-06-03 16:09:48.421967 EDT | AverageDiscountedReturn    95.3598
2017-06-03 16:09:48.422288 EDT | AverageQLoss                3.30535e-05
2017-06-03 16:09:48.422608 EDT | AveragePolicySurr          -0.0986535
2017-06-03 16:09:48.422923 EDT | AverageQ                    0.0941377
2017-06-03 16:09:48.423240 EDT | AverageAbsQ                 0.0943647
2017-06-03 16:09:48.423551 EDT | AverageY                    0.0941417
2017-06-03 16:09:48.423864 EDT | AverageAbsY                 0.0941572
2017-06-03 16:09:48.424183 EDT | AverageAbsQYDiff            0.00154092
2017-06-03 16:09:48.424493 EDT | AverageAction               0.00453527
2017-06-03 16:09:48.424802 EDT | PolicyRegParamNorm         60.9639
2017-06-03 16:09:48.425111 EDT | QFunRegParamNorm           26.8148
2017-06-03 16:09:48.425419 EDT | -----------------------  --------------
2017-06-03 16:09:48.425882 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #428 | Training started
2017-06-03 16:10:06.612423 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #428 | Training finished
2017-06-03 16:10:06.613059 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #428 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 16:10:06.613344 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #428 | Collecting samples for evaluation
2017-06-03 16:10:16.730437 EDT | -----------------------  --------------
2017-06-03 16:10:16.731268 EDT | Epoch                     428
2017-06-03 16:10:16.731528 EDT | Iteration                 428
2017-06-03 16:10:16.731779 EDT | AverageReturn            1000
2017-06-03 16:10:16.732016 EDT | StdReturn                   0
2017-06-03 16:10:16.732252 EDT | MaxReturn                1000
2017-06-03 16:10:16.732520 EDT | MinReturn                1000
2017-06-03 16:10:16.732759 EDT | AverageEsReturn            18.3208
2017-06-03 16:10:16.732992 EDT | StdEsReturn                18.2186
2017-06-03 16:10:16.733224 EDT | MaxEsReturn               102
2017-06-03 16:10:16.733456 EDT | MinEsReturn                 3
2017-06-03 16:10:16.733702 EDT | AverageDiscountedReturn    99.9957
2017-06-03 16:10:16.733967 EDT | AverageQLoss                3.40026e-05
2017-06-03 16:10:16.734202 EDT | AveragePolicySurr          -0.0985046
2017-06-03 16:10:16.734436 EDT | AverageQ                    0.0940318
2017-06-03 16:10:16.734667 EDT | AverageAbsQ                 0.0943544
2017-06-03 16:10:16.734908 EDT | AverageY                    0.0940294
2017-06-03 16:10:16.735140 EDT | AverageAbsY                 0.0940429
2017-06-03 16:10:16.735371 EDT | AverageAbsQYDiff            0.00165879
2017-06-03 16:10:16.735602 EDT | AverageAction               0.00164484
2017-06-03 16:10:16.735830 EDT | PolicyRegParamNorm         61.0053
2017-06-03 16:10:16.736057 EDT | QFunRegParamNorm           26.8234
2017-06-03 16:10:16.736287 EDT | -----------------------  --------------
2017-06-03 16:10:16.736639 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #429 | Training started
2017-06-03 16:10:35.275666 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #429 | Training finished
2017-06-03 16:10:35.276541 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #429 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 16:10:35.276806 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #429 | Collecting samples for evaluation
2017-06-03 16:10:45.192865 EDT | -----------------------  --------------
2017-06-03 16:10:45.193860 EDT | Epoch                     429
2017-06-03 16:10:45.194214 EDT | Iteration                 429
2017-06-03 16:10:45.194540 EDT | AverageReturn             844.917
2017-06-03 16:10:45.194871 EDT | StdReturn                 346.78
2017-06-03 16:10:45.195209 EDT | MaxReturn                1000
2017-06-03 16:10:45.195540 EDT | MinReturn                  66
2017-06-03 16:10:45.195867 EDT | AverageEsReturn            15.1029
2017-06-03 16:10:45.196192 EDT | StdEsReturn                13.9137
2017-06-03 16:10:45.196509 EDT | MaxEsReturn                69
2017-06-03 16:10:45.196830 EDT | MinEsReturn                 3
2017-06-03 16:10:45.197143 EDT | AverageDiscountedReturn    91.7024
2017-06-03 16:10:45.197458 EDT | AverageQLoss                3.28053e-05
2017-06-03 16:10:45.197787 EDT | AveragePolicySurr          -0.0985721
2017-06-03 16:10:45.198104 EDT | AverageQ                    0.0942635
2017-06-03 16:10:45.198417 EDT | AverageAbsQ                 0.0944972
2017-06-03 16:10:45.198730 EDT | AverageY                    0.0942594
2017-06-03 16:10:45.199040 EDT | AverageAbsY                 0.0942647
2017-06-03 16:10:45.199351 EDT | AverageAbsQYDiff            0.00160879
2017-06-03 16:10:45.199660 EDT | AverageAction               0.0211828
2017-06-03 16:10:45.199994 EDT | PolicyRegParamNorm         61.0772
2017-06-03 16:10:45.200310 EDT | QFunRegParamNorm           26.8153
2017-06-03 16:10:45.200618 EDT | -----------------------  --------------
2017-06-03 16:10:45.201062 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #430 | Training started
2017-06-03 16:11:05.236853 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #430 | Training finished
2017-06-03 16:11:05.237880 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #430 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 16:11:05.238289 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #430 | Collecting samples for evaluation
2017-06-03 16:11:14.894235 EDT | -----------------------  --------------
2017-06-03 16:11:14.895082 EDT | Epoch                     430
2017-06-03 16:11:14.895367 EDT | Iteration                 430
2017-06-03 16:11:14.895605 EDT | AverageReturn            1000
2017-06-03 16:11:14.895841 EDT | StdReturn                   0
2017-06-03 16:11:14.896082 EDT | MaxReturn                1000
2017-06-03 16:11:14.896310 EDT | MinReturn                1000
2017-06-03 16:11:14.896536 EDT | AverageEsReturn            19.9592
2017-06-03 16:11:14.896765 EDT | StdEsReturn                17.0209
2017-06-03 16:11:14.896992 EDT | MaxEsReturn                76
2017-06-03 16:11:14.897224 EDT | MinEsReturn                 3
2017-06-03 16:11:14.897448 EDT | AverageDiscountedReturn    99.9957
2017-06-03 16:11:14.897682 EDT | AverageQLoss                3.89343e-05
2017-06-03 16:11:14.897971 EDT | AveragePolicySurr          -0.0981326
2017-06-03 16:11:14.898221 EDT | AverageQ                    0.0935288
2017-06-03 16:11:14.898462 EDT | AverageAbsQ                 0.0937703
2017-06-03 16:11:14.898714 EDT | AverageY                    0.0935329
2017-06-03 16:11:14.898956 EDT | AverageAbsY                 0.0935464
2017-06-03 16:11:14.899196 EDT | AverageAbsQYDiff            0.00169678
2017-06-03 16:11:14.899435 EDT | AverageAction               0.00184669
2017-06-03 16:11:14.899684 EDT | PolicyRegParamNorm         61.0926
2017-06-03 16:11:14.899927 EDT | QFunRegParamNorm           26.8108
2017-06-03 16:11:14.900166 EDT | -----------------------  --------------
2017-06-03 16:11:14.900551 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #431 | Training started
2017-06-03 16:11:32.984813 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #431 | Training finished
2017-06-03 16:11:32.985744 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #431 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 16:11:32.986238 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #431 | Collecting samples for evaluation
2017-06-03 16:11:43.555194 EDT | -----------------------  --------------
2017-06-03 16:11:43.556073 EDT | Epoch                     431
2017-06-03 16:11:43.556364 EDT | Iteration                 431
2017-06-03 16:11:43.556604 EDT | AverageReturn            1000
2017-06-03 16:11:43.556841 EDT | StdReturn                   0
2017-06-03 16:11:43.557077 EDT | MaxReturn                1000
2017-06-03 16:11:43.557314 EDT | MinReturn                1000
2017-06-03 16:11:43.557598 EDT | AverageEsReturn            20.48
2017-06-03 16:11:43.557847 EDT | StdEsReturn                17.1397
2017-06-03 16:11:43.558082 EDT | MaxEsReturn                97
2017-06-03 16:11:43.558313 EDT | MinEsReturn                 3
2017-06-03 16:11:43.558548 EDT | AverageDiscountedReturn    99.9957
2017-06-03 16:11:43.558782 EDT | AverageQLoss                3.18971e-05
2017-06-03 16:11:43.559013 EDT | AveragePolicySurr          -0.0982671
2017-06-03 16:11:43.559241 EDT | AverageQ                    0.093679
2017-06-03 16:11:43.559477 EDT | AverageAbsQ                 0.0939614
2017-06-03 16:11:43.559730 EDT | AverageY                    0.0936789
2017-06-03 16:11:43.559970 EDT | AverageAbsY                 0.0936869
2017-06-03 16:11:43.560200 EDT | AverageAbsQYDiff            0.00163436
2017-06-03 16:11:43.560446 EDT | AverageAction               0.0013336
2017-06-03 16:11:43.560693 EDT | PolicyRegParamNorm         61.1393
2017-06-03 16:11:43.560946 EDT | QFunRegParamNorm           26.8121
2017-06-03 16:11:43.561176 EDT | -----------------------  --------------
2017-06-03 16:11:43.561525 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #432 | Training started
2017-06-03 16:12:01.978491 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #432 | Training finished
2017-06-03 16:12:01.979409 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #432 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 16:12:01.979936 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #432 | Collecting samples for evaluation
2017-06-03 16:12:11.771260 EDT | -----------------------  --------------
2017-06-03 16:12:11.771688 EDT | Epoch                     432
2017-06-03 16:12:11.771966 EDT | Iteration                 432
2017-06-03 16:12:11.772260 EDT | AverageReturn            1000
2017-06-03 16:12:11.772510 EDT | StdReturn                   0
2017-06-03 16:12:11.772758 EDT | MaxReturn                1000
2017-06-03 16:12:11.773005 EDT | MinReturn                1000
2017-06-03 16:12:11.773261 EDT | AverageEsReturn            18.5472
2017-06-03 16:12:11.773517 EDT | StdEsReturn                16.4105
2017-06-03 16:12:11.773793 EDT | MaxEsReturn                70
2017-06-03 16:12:11.774051 EDT | MinEsReturn                 3
2017-06-03 16:12:11.774296 EDT | AverageDiscountedReturn    99.9957
2017-06-03 16:12:11.774544 EDT | AverageQLoss                3.62046e-05
2017-06-03 16:12:11.774795 EDT | AveragePolicySurr          -0.0979621
2017-06-03 16:12:11.775241 EDT | AverageQ                    0.0934362
2017-06-03 16:12:11.775521 EDT | AverageAbsQ                 0.0936589
2017-06-03 16:12:11.775794 EDT | AverageY                    0.0934337
2017-06-03 16:12:11.776048 EDT | AverageAbsY                 0.0934414
2017-06-03 16:12:11.776297 EDT | AverageAbsQYDiff            0.00160837
2017-06-03 16:12:11.776548 EDT | AverageAction               0.00712745
2017-06-03 16:12:11.776799 EDT | PolicyRegParamNorm         61.1636
2017-06-03 16:12:11.777041 EDT | QFunRegParamNorm           26.8167
2017-06-03 16:12:11.777283 EDT | -----------------------  --------------
2017-06-03 16:12:11.777653 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #433 | Training started
2017-06-03 16:12:31.289578 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #433 | Training finished
2017-06-03 16:12:31.290939 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #433 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 16:12:31.291215 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #433 | Collecting samples for evaluation
2017-06-03 16:12:41.142518 EDT | -----------------------  --------------
2017-06-03 16:12:41.142888 EDT | Epoch                     433
2017-06-03 16:12:41.143147 EDT | Iteration                 433
2017-06-03 16:12:41.143386 EDT | AverageReturn            1000
2017-06-03 16:12:41.143617 EDT | StdReturn                   0
2017-06-03 16:12:41.143875 EDT | MaxReturn                1000
2017-06-03 16:12:41.144110 EDT | MinReturn                1000
2017-06-03 16:12:41.144338 EDT | AverageEsReturn            16.8833
2017-06-03 16:12:41.144568 EDT | StdEsReturn                12.1038
2017-06-03 16:12:41.144801 EDT | MaxEsReturn                69
2017-06-03 16:12:41.145040 EDT | MinEsReturn                 3
2017-06-03 16:12:41.145276 EDT | AverageDiscountedReturn    99.9957
2017-06-03 16:12:41.145508 EDT | AverageQLoss                3.35974e-05
2017-06-03 16:12:41.145752 EDT | AveragePolicySurr          -0.0979814
2017-06-03 16:12:41.145985 EDT | AverageQ                    0.0932427
2017-06-03 16:12:41.146216 EDT | AverageAbsQ                 0.0934979
2017-06-03 16:12:41.146445 EDT | AverageY                    0.0932464
2017-06-03 16:12:41.146675 EDT | AverageAbsY                 0.0932553
2017-06-03 16:12:41.146904 EDT | AverageAbsQYDiff            0.00158421
2017-06-03 16:12:41.147133 EDT | AverageAction               0.00167615
2017-06-03 16:12:41.147362 EDT | PolicyRegParamNorm         61.2402
2017-06-03 16:12:41.147591 EDT | QFunRegParamNorm           26.8258
2017-06-03 16:12:41.147821 EDT | -----------------------  --------------
2017-06-03 16:12:41.148189 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #434 | Training started
2017-06-03 16:12:59.938331 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #434 | Training finished
2017-06-03 16:12:59.939213 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #434 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 16:12:59.939486 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #434 | Collecting samples for evaluation
2017-06-03 16:13:09.579689 EDT | -----------------------  --------------
2017-06-03 16:13:09.580120 EDT | Epoch                     434
2017-06-03 16:13:09.580406 EDT | Iteration                 434
2017-06-03 16:13:09.580659 EDT | AverageReturn            1000
2017-06-03 16:13:09.580896 EDT | StdReturn                   0
2017-06-03 16:13:09.581133 EDT | MaxReturn                1000
2017-06-03 16:13:09.581372 EDT | MinReturn                1000
2017-06-03 16:13:09.581750 EDT | AverageEsReturn            17.4737
2017-06-03 16:13:09.582018 EDT | StdEsReturn                15.0789
2017-06-03 16:13:09.582266 EDT | MaxEsReturn                56
2017-06-03 16:13:09.582531 EDT | MinEsReturn                 3
2017-06-03 16:13:09.582792 EDT | AverageDiscountedReturn    99.9957
2017-06-03 16:13:09.583039 EDT | AverageQLoss                3.58229e-05
2017-06-03 16:13:09.583287 EDT | AveragePolicySurr          -0.0978237
2017-06-03 16:13:09.583554 EDT | AverageQ                    0.0931992
2017-06-03 16:13:09.583799 EDT | AverageAbsQ                 0.0934845
2017-06-03 16:13:09.584041 EDT | AverageY                    0.0931973
2017-06-03 16:13:09.584577 EDT | AverageAbsY                 0.0932091
2017-06-03 16:13:09.585088 EDT | AverageAbsQYDiff            0.00168863
2017-06-03 16:13:09.585679 EDT | AverageAction               0.00181391
2017-06-03 16:13:09.586192 EDT | PolicyRegParamNorm         61.2699
2017-06-03 16:13:09.586781 EDT | QFunRegParamNorm           26.8286
2017-06-03 16:13:09.587326 EDT | -----------------------  --------------
2017-06-03 16:13:09.588000 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #435 | Training started
2017-06-03 16:13:28.082826 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #435 | Training finished
2017-06-03 16:13:28.083795 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #435 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 16:13:28.084153 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #435 | Collecting samples for evaluation
2017-06-03 16:13:37.810729 EDT | -----------------------  --------------
2017-06-03 16:13:37.811757 EDT | Epoch                     435
2017-06-03 16:13:37.812105 EDT | Iteration                 435
2017-06-03 16:13:37.812446 EDT | AverageReturn            1000
2017-06-03 16:13:37.812770 EDT | StdReturn                   0
2017-06-03 16:13:37.813096 EDT | MaxReturn                1000
2017-06-03 16:13:37.813417 EDT | MinReturn                1000
2017-06-03 16:13:37.813740 EDT | AverageEsReturn            18.8077
2017-06-03 16:13:37.814060 EDT | StdEsReturn                16.0971
2017-06-03 16:13:37.814401 EDT | MaxEsReturn                81
2017-06-03 16:13:37.814715 EDT | MinEsReturn                 3
2017-06-03 16:13:37.815028 EDT | AverageDiscountedReturn    99.9957
2017-06-03 16:13:37.815342 EDT | AverageQLoss                3.37677e-05
2017-06-03 16:13:37.815673 EDT | AveragePolicySurr          -0.0977006
2017-06-03 16:13:37.815991 EDT | AverageQ                    0.0931511
2017-06-03 16:13:37.816302 EDT | AverageAbsQ                 0.0934605
2017-06-03 16:13:37.816620 EDT | AverageY                    0.0931548
2017-06-03 16:13:37.816929 EDT | AverageAbsY                 0.0931735
2017-06-03 16:13:37.817238 EDT | AverageAbsQYDiff            0.00164035
2017-06-03 16:13:37.817549 EDT | AverageAction               0.00215495
2017-06-03 16:13:37.817879 EDT | PolicyRegParamNorm         61.3141
2017-06-03 16:13:37.818192 EDT | QFunRegParamNorm           26.8387
2017-06-03 16:13:37.818501 EDT | -----------------------  --------------
2017-06-03 16:13:37.818975 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #436 | Training started
2017-06-03 16:13:55.761279 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #436 | Training finished
2017-06-03 16:13:55.765020 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #436 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 16:13:55.765347 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #436 | Collecting samples for evaluation
2017-06-03 16:14:06.971433 EDT | -----------------------  --------------
2017-06-03 16:14:06.972284 EDT | Epoch                     436
2017-06-03 16:14:06.972566 EDT | Iteration                 436
2017-06-03 16:14:06.972809 EDT | AverageReturn             111.287
2017-06-03 16:14:06.973047 EDT | StdReturn                 210.69
2017-06-03 16:14:06.973292 EDT | MaxReturn                1000
2017-06-03 16:14:06.973529 EDT | MinReturn                  57
2017-06-03 16:14:06.973780 EDT | AverageEsReturn            23.3488
2017-06-03 16:14:06.974012 EDT | StdEsReturn                18.9882
2017-06-03 16:14:06.974246 EDT | MaxEsReturn                77
2017-06-03 16:14:06.974479 EDT | MinEsReturn                 3
2017-06-03 16:14:06.974723 EDT | AverageDiscountedReturn    48.8475
2017-06-03 16:14:06.974951 EDT | AverageQLoss                3.31866e-05
2017-06-03 16:14:06.975179 EDT | AveragePolicySurr          -0.097766
2017-06-03 16:14:06.975407 EDT | AverageQ                    0.0934374
2017-06-03 16:14:06.975635 EDT | AverageAbsQ                 0.0937089
2017-06-03 16:14:06.975868 EDT | AverageY                    0.0934334
2017-06-03 16:14:06.976109 EDT | AverageAbsY                 0.0934502
2017-06-03 16:14:06.976339 EDT | AverageAbsQYDiff            0.00158488
2017-06-03 16:14:06.976573 EDT | AverageAction               0.0710876
2017-06-03 16:14:06.976801 EDT | PolicyRegParamNorm         61.4267
2017-06-03 16:14:06.977030 EDT | QFunRegParamNorm           26.8554
2017-06-03 16:14:06.977262 EDT | -----------------------  --------------
2017-06-03 16:14:06.977645 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #437 | Training started
2017-06-03 16:14:26.757309 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #437 | Training finished
2017-06-03 16:14:26.760163 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #437 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 16:14:26.760548 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #437 | Collecting samples for evaluation
2017-06-03 16:14:36.870832 EDT | -----------------------  --------------
2017-06-03 16:14:36.871659 EDT | Epoch                     437
2017-06-03 16:14:36.871930 EDT | Iteration                 437
2017-06-03 16:14:36.872172 EDT | AverageReturn             613.941
2017-06-03 16:14:36.872409 EDT | StdReturn                 461.452
2017-06-03 16:14:36.872652 EDT | MaxReturn                1000
2017-06-03 16:14:36.872887 EDT | MinReturn                  56
2017-06-03 16:14:36.873129 EDT | AverageEsReturn            17.6207
2017-06-03 16:14:36.873362 EDT | StdEsReturn                14.3849
2017-06-03 16:14:36.873599 EDT | MaxEsReturn                56
2017-06-03 16:14:36.873844 EDT | MinEsReturn                 3
2017-06-03 16:14:36.874077 EDT | AverageDiscountedReturn    77.9548
2017-06-03 16:14:36.874314 EDT | AverageQLoss                3.39383e-05
2017-06-03 16:14:36.874545 EDT | AveragePolicySurr          -0.09756
2017-06-03 16:14:36.874776 EDT | AverageQ                    0.0930721
2017-06-03 16:14:36.875008 EDT | AverageAbsQ                 0.0933591
2017-06-03 16:14:36.875238 EDT | AverageY                    0.0930705
2017-06-03 16:14:36.875469 EDT | AverageAbsY                 0.0930951
2017-06-03 16:14:36.875701 EDT | AverageAbsQYDiff            0.00159455
2017-06-03 16:14:36.875933 EDT | AverageAction               0.0229237
2017-06-03 16:14:36.876164 EDT | PolicyRegParamNorm         61.4537
2017-06-03 16:14:36.876396 EDT | QFunRegParamNorm           26.8713
2017-06-03 16:14:36.876627 EDT | -----------------------  --------------
2017-06-03 16:14:36.876971 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #438 | Training started
2017-06-03 16:14:55.938414 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #438 | Training finished
2017-06-03 16:14:55.939301 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #438 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 16:14:55.939613 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #438 | Collecting samples for evaluation
2017-06-03 16:15:06.731259 EDT | -----------------------  -------------
2017-06-03 16:15:06.732300 EDT | Epoch                    438
2017-06-03 16:15:06.732645 EDT | Iteration                438
2017-06-03 16:15:06.732968 EDT | AverageReturn             45.3348
2017-06-03 16:15:06.733342 EDT | StdReturn                  0.471935
2017-06-03 16:15:06.733745 EDT | MaxReturn                 46
2017-06-03 16:15:06.734202 EDT | MinReturn                 45
2017-06-03 16:15:06.734658 EDT | AverageEsReturn           12.8077
2017-06-03 16:15:06.735101 EDT | StdEsReturn               10.9299
2017-06-03 16:15:06.735568 EDT | MaxEsReturn               48
2017-06-03 16:15:06.736043 EDT | MinEsReturn                3
2017-06-03 16:15:06.736437 EDT | AverageDiscountedReturn   36.5945
2017-06-03 16:15:06.736757 EDT | AverageQLoss               3.39516e-05
2017-06-03 16:15:06.737074 EDT | AveragePolicySurr         -0.0975737
2017-06-03 16:15:06.737398 EDT | AverageQ                   0.092932
2017-06-03 16:15:06.737717 EDT | AverageAbsQ                0.0931855
2017-06-03 16:15:06.738038 EDT | AverageY                   0.0929314
2017-06-03 16:15:06.738349 EDT | AverageAbsY                0.092951
2017-06-03 16:15:06.738657 EDT | AverageAbsQYDiff           0.00155737
2017-06-03 16:15:06.738965 EDT | AverageAction              0.0570005
2017-06-03 16:15:06.739272 EDT | PolicyRegParamNorm        61.4884
2017-06-03 16:15:06.739645 EDT | QFunRegParamNorm          26.8727
2017-06-03 16:15:06.740021 EDT | -----------------------  -------------
2017-06-03 16:15:06.740527 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #439 | Training started
2017-06-03 16:15:25.027932 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #439 | Training finished
2017-06-03 16:15:25.028804 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #439 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 16:15:25.029087 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #439 | Collecting samples for evaluation
2017-06-03 16:15:33.985109 EDT | -----------------------  -------------
2017-06-03 16:15:33.985998 EDT | Epoch                    439
2017-06-03 16:15:33.986282 EDT | Iteration                439
2017-06-03 16:15:33.986521 EDT | AverageReturn             48
2017-06-03 16:15:33.986755 EDT | StdReturn                  1.4377
2017-06-03 16:15:33.986985 EDT | MaxReturn                 54
2017-06-03 16:15:33.987216 EDT | MinReturn                 46
2017-06-03 16:15:33.987493 EDT | AverageEsReturn           14.3768
2017-06-03 16:15:33.987797 EDT | StdEsReturn               10.4799
2017-06-03 16:15:33.988045 EDT | MaxEsReturn               58
2017-06-03 16:15:33.988274 EDT | MinEsReturn                3
2017-06-03 16:15:33.988504 EDT | AverageDiscountedReturn   38.2646
2017-06-03 16:15:33.988740 EDT | AverageQLoss               3.31733e-05
2017-06-03 16:15:33.988966 EDT | AveragePolicySurr         -0.0973718
2017-06-03 16:15:33.989191 EDT | AverageQ                   0.0929253
2017-06-03 16:15:33.989419 EDT | AverageAbsQ                0.0932355
2017-06-03 16:15:33.989642 EDT | AverageY                   0.0929234
2017-06-03 16:15:33.989900 EDT | AverageAbsY                0.0929563
2017-06-03 16:15:33.990125 EDT | AverageAbsQYDiff           0.00162307
2017-06-03 16:15:33.990349 EDT | AverageAction              0.269137
2017-06-03 16:15:33.990632 EDT | PolicyRegParamNorm        61.5348
2017-06-03 16:15:33.990925 EDT | QFunRegParamNorm          26.8811
2017-06-03 16:15:33.991195 EDT | -----------------------  -------------
2017-06-03 16:15:33.991596 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #440 | Training started
2017-06-03 16:15:52.051647 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #440 | Training finished
2017-06-03 16:15:52.052627 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #440 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 16:15:52.053108 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #440 | Collecting samples for evaluation
2017-06-03 16:16:01.136156 EDT | -----------------------  --------------
2017-06-03 16:16:01.136725 EDT | Epoch                     440
2017-06-03 16:16:01.137096 EDT | Iteration                 440
2017-06-03 16:16:01.137479 EDT | AverageReturn            1000
2017-06-03 16:16:01.137867 EDT | StdReturn                   0
2017-06-03 16:16:01.138236 EDT | MaxReturn                1000
2017-06-03 16:16:01.138601 EDT | MinReturn                1000
2017-06-03 16:16:01.138958 EDT | AverageEsReturn            19.2885
2017-06-03 16:16:01.139289 EDT | StdEsReturn                16.2129
2017-06-03 16:16:01.139664 EDT | MaxEsReturn                69
2017-06-03 16:16:01.139987 EDT | MinEsReturn                 3
2017-06-03 16:16:01.140329 EDT | AverageDiscountedReturn    99.9957
2017-06-03 16:16:01.140670 EDT | AverageQLoss                3.01842e-05
2017-06-03 16:16:01.140988 EDT | AveragePolicySurr          -0.0973331
2017-06-03 16:16:01.141304 EDT | AverageQ                    0.0929012
2017-06-03 16:16:01.141622 EDT | AverageAbsQ                 0.0931445
2017-06-03 16:16:01.141993 EDT | AverageY                    0.0929032
2017-06-03 16:16:01.142353 EDT | AverageAbsY                 0.0929391
2017-06-03 16:16:01.142680 EDT | AverageAbsQYDiff            0.001529
2017-06-03 16:16:01.143024 EDT | AverageAction               0.00507319
2017-06-03 16:16:01.143364 EDT | PolicyRegParamNorm         61.5859
2017-06-03 16:16:01.143677 EDT | QFunRegParamNorm           26.8863
2017-06-03 16:16:01.143997 EDT | -----------------------  --------------
2017-06-03 16:16:01.144468 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #441 | Training started
2017-06-03 16:16:20.307839 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #441 | Training finished
2017-06-03 16:16:20.308809 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #441 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 16:16:20.309199 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #441 | Collecting samples for evaluation
2017-06-03 16:16:29.580867 EDT | -----------------------  --------------
2017-06-03 16:16:29.581777 EDT | Epoch                     441
2017-06-03 16:16:29.582043 EDT | Iteration                 441
2017-06-03 16:16:29.582285 EDT | AverageReturn            1000
2017-06-03 16:16:29.582522 EDT | StdReturn                   0
2017-06-03 16:16:29.582762 EDT | MaxReturn                1000
2017-06-03 16:16:29.582992 EDT | MinReturn                1000
2017-06-03 16:16:29.583231 EDT | AverageEsReturn            17.5455
2017-06-03 16:16:29.583462 EDT | StdEsReturn                13.2416
2017-06-03 16:16:29.583693 EDT | MaxEsReturn                51
2017-06-03 16:16:29.583926 EDT | MinEsReturn                 3
2017-06-03 16:16:29.584157 EDT | AverageDiscountedReturn    99.9957
2017-06-03 16:16:29.584388 EDT | AverageQLoss                3.33501e-05
2017-06-03 16:16:29.584616 EDT | AveragePolicySurr          -0.0971712
2017-06-03 16:16:29.584852 EDT | AverageQ                    0.0925155
2017-06-03 16:16:29.585084 EDT | AverageAbsQ                 0.0927781
2017-06-03 16:16:29.585333 EDT | AverageY                    0.0925142
2017-06-03 16:16:29.585562 EDT | AverageAbsY                 0.0925446
2017-06-03 16:16:29.585805 EDT | AverageAbsQYDiff            0.00157258
2017-06-03 16:16:29.586034 EDT | AverageAction               0.00657785
2017-06-03 16:16:29.586266 EDT | PolicyRegParamNorm         61.6899
2017-06-03 16:16:29.586505 EDT | QFunRegParamNorm           26.8958
2017-06-03 16:16:29.586740 EDT | -----------------------  --------------
2017-06-03 16:16:29.587132 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #442 | Training started
2017-06-03 16:16:49.586628 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #442 | Training finished
2017-06-03 16:16:49.587531 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #442 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 16:16:49.587817 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #442 | Collecting samples for evaluation
2017-06-03 16:16:59.002450 EDT | -----------------------  --------------
2017-06-03 16:16:59.003302 EDT | Epoch                     442
2017-06-03 16:16:59.003588 EDT | Iteration                 442
2017-06-03 16:16:59.003845 EDT | AverageReturn            1000
2017-06-03 16:16:59.004094 EDT | StdReturn                   0
2017-06-03 16:16:59.004339 EDT | MaxReturn                1000
2017-06-03 16:16:59.004584 EDT | MinReturn                1000
2017-06-03 16:16:59.004835 EDT | AverageEsReturn            20.9
2017-06-03 16:16:59.005081 EDT | StdEsReturn                16.523
2017-06-03 16:16:59.005331 EDT | MaxEsReturn                63
2017-06-03 16:16:59.005573 EDT | MinEsReturn                 3
2017-06-03 16:16:59.005923 EDT | AverageDiscountedReturn    99.9957
2017-06-03 16:16:59.006171 EDT | AverageQLoss                3.20295e-05
2017-06-03 16:16:59.006427 EDT | AveragePolicySurr          -0.0971367
2017-06-03 16:16:59.006679 EDT | AverageQ                    0.0927125
2017-06-03 16:16:59.006922 EDT | AverageAbsQ                 0.0930133
2017-06-03 16:16:59.007162 EDT | AverageY                    0.0927151
2017-06-03 16:16:59.007416 EDT | AverageAbsY                 0.0927295
2017-06-03 16:16:59.007658 EDT | AverageAbsQYDiff            0.00160129
2017-06-03 16:16:59.007905 EDT | AverageAction               0.00346318
2017-06-03 16:16:59.008147 EDT | PolicyRegParamNorm         61.698
2017-06-03 16:16:59.008397 EDT | QFunRegParamNorm           26.9016
2017-06-03 16:16:59.008638 EDT | -----------------------  --------------
2017-06-03 16:16:59.009025 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #443 | Training started
2017-06-03 16:17:17.357867 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #443 | Training finished
2017-06-03 16:17:17.358731 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #443 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 16:17:17.359000 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #443 | Collecting samples for evaluation
2017-06-03 16:17:26.633612 EDT | -----------------------  --------------
2017-06-03 16:17:26.634707 EDT | Epoch                     443
2017-06-03 16:17:26.634992 EDT | Iteration                 443
2017-06-03 16:17:26.635265 EDT | AverageReturn            1000
2017-06-03 16:17:26.635535 EDT | StdReturn                   0
2017-06-03 16:17:26.635785 EDT | MaxReturn                1000
2017-06-03 16:17:26.636036 EDT | MinReturn                1000
2017-06-03 16:17:26.636281 EDT | AverageEsReturn            16.7797
2017-06-03 16:17:26.636549 EDT | StdEsReturn                15.5095
2017-06-03 16:17:26.636814 EDT | MaxEsReturn                67
2017-06-03 16:17:26.637088 EDT | MinEsReturn                 3
2017-06-03 16:17:26.637344 EDT | AverageDiscountedReturn    99.9957
2017-06-03 16:17:26.637608 EDT | AverageQLoss                3.24138e-05
2017-06-03 16:17:26.637899 EDT | AveragePolicySurr          -0.0968936
2017-06-03 16:17:26.638146 EDT | AverageQ                    0.0925054
2017-06-03 16:17:26.638399 EDT | AverageAbsQ                 0.0927675
2017-06-03 16:17:26.638672 EDT | AverageY                    0.092505
2017-06-03 16:17:26.638936 EDT | AverageAbsY                 0.0925239
2017-06-03 16:17:26.639189 EDT | AverageAbsQYDiff            0.00164138
2017-06-03 16:17:26.639460 EDT | AverageAction               0.0162279
2017-06-03 16:17:26.639734 EDT | PolicyRegParamNorm         61.696
2017-06-03 16:17:26.640002 EDT | QFunRegParamNorm           26.8831
2017-06-03 16:17:26.640278 EDT | -----------------------  --------------
2017-06-03 16:17:26.640729 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #444 | Training started
2017-06-03 16:17:45.735429 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #444 | Training finished
2017-06-03 16:17:45.736320 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #444 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 16:17:45.736771 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #444 | Collecting samples for evaluation
2017-06-03 16:17:54.816538 EDT | -----------------------  -------------
2017-06-03 16:17:54.817394 EDT | Epoch                    444
2017-06-03 16:17:54.817678 EDT | Iteration                444
2017-06-03 16:17:54.817960 EDT | AverageReturn             79.5159
2017-06-03 16:17:54.818233 EDT | StdReturn                  1.07448
2017-06-03 16:17:54.818498 EDT | MaxReturn                 82
2017-06-03 16:17:54.818756 EDT | MinReturn                 78
2017-06-03 16:17:54.819087 EDT | AverageEsReturn           15.381
2017-06-03 16:17:54.819453 EDT | StdEsReturn               17.4724
2017-06-03 16:17:54.819771 EDT | MaxEsReturn              117
2017-06-03 16:17:54.820087 EDT | MinEsReturn                3
2017-06-03 16:17:54.820409 EDT | AverageDiscountedReturn   55.0268
2017-06-03 16:17:54.820737 EDT | AverageQLoss               3.91453e-05
2017-06-03 16:17:54.821060 EDT | AveragePolicySurr         -0.0967267
2017-06-03 16:17:54.821379 EDT | AverageQ                   0.0922539
2017-06-03 16:17:54.821699 EDT | AverageAbsQ                0.0925433
2017-06-03 16:17:54.822016 EDT | AverageY                   0.0922551
2017-06-03 16:17:54.822330 EDT | AverageAbsY                0.0922817
2017-06-03 16:17:54.822647 EDT | AverageAbsQYDiff           0.00165135
2017-06-03 16:17:54.822958 EDT | AverageAction              0.0226303
2017-06-03 16:17:54.823276 EDT | PolicyRegParamNorm        61.7214
2017-06-03 16:17:54.823584 EDT | QFunRegParamNorm          26.8876
2017-06-03 16:17:54.823892 EDT | -----------------------  -------------
2017-06-03 16:17:54.824321 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #445 | Training started
2017-06-03 16:18:12.365079 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #445 | Training finished
2017-06-03 16:18:12.366056 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #445 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 16:18:12.366320 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #445 | Collecting samples for evaluation
2017-06-03 16:18:23.341494 EDT | -----------------------  --------------
2017-06-03 16:18:23.342373 EDT | Epoch                     445
2017-06-03 16:18:23.342637 EDT | Iteration                 445
2017-06-03 16:18:23.342881 EDT | AverageReturn            1000
2017-06-03 16:18:23.343116 EDT | StdReturn                   0
2017-06-03 16:18:23.343349 EDT | MaxReturn                1000
2017-06-03 16:18:23.343583 EDT | MinReturn                1000
2017-06-03 16:18:23.343817 EDT | AverageEsReturn            16.3333
2017-06-03 16:18:23.344050 EDT | StdEsReturn                13.6638
2017-06-03 16:18:23.344280 EDT | MaxEsReturn                62
2017-06-03 16:18:23.344513 EDT | MinEsReturn                 3
2017-06-03 16:18:23.344776 EDT | AverageDiscountedReturn    99.9957
2017-06-03 16:18:23.345009 EDT | AverageQLoss                3.61795e-05
2017-06-03 16:18:23.345243 EDT | AveragePolicySurr          -0.0965849
2017-06-03 16:18:23.345497 EDT | AverageQ                    0.0921147
2017-06-03 16:18:23.345743 EDT | AverageAbsQ                 0.0924093
2017-06-03 16:18:23.345978 EDT | AverageY                    0.0921176
2017-06-03 16:18:23.346208 EDT | AverageAbsY                 0.0921372
2017-06-03 16:18:23.346447 EDT | AverageAbsQYDiff            0.00171694
2017-06-03 16:18:23.346677 EDT | AverageAction               0.00369824
2017-06-03 16:18:23.346910 EDT | PolicyRegParamNorm         61.7559
2017-06-03 16:18:23.347139 EDT | QFunRegParamNorm           26.8936
2017-06-03 16:18:23.347368 EDT | -----------------------  --------------
2017-06-03 16:18:23.347718 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #446 | Training started
2017-06-03 16:18:43.743469 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #446 | Training finished
2017-06-03 16:18:43.746522 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #446 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 16:18:43.746810 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #446 | Collecting samples for evaluation
2017-06-03 16:18:54.335792 EDT | -----------------------  --------------
2017-06-03 16:18:54.336630 EDT | Epoch                     446
2017-06-03 16:18:54.336889 EDT | Iteration                 446
2017-06-03 16:18:54.337127 EDT | AverageReturn            1000
2017-06-03 16:18:54.337358 EDT | StdReturn                   0
2017-06-03 16:18:54.337596 EDT | MaxReturn                1000
2017-06-03 16:18:54.337852 EDT | MinReturn                1000
2017-06-03 16:18:54.338096 EDT | AverageEsReturn            19.76
2017-06-03 16:18:54.338335 EDT | StdEsReturn                16.7231
2017-06-03 16:18:54.338567 EDT | MaxEsReturn                68
2017-06-03 16:18:54.338796 EDT | MinEsReturn                 3
2017-06-03 16:18:54.339026 EDT | AverageDiscountedReturn    99.9957
2017-06-03 16:18:54.339254 EDT | AverageQLoss                3.40349e-05
2017-06-03 16:18:54.339483 EDT | AveragePolicySurr          -0.0964157
2017-06-03 16:18:54.339711 EDT | AverageQ                    0.0919062
2017-06-03 16:18:54.339941 EDT | AverageAbsQ                 0.0921378
2017-06-03 16:18:54.340196 EDT | AverageY                    0.0919031
2017-06-03 16:18:54.340423 EDT | AverageAbsY                 0.0919254
2017-06-03 16:18:54.340648 EDT | AverageAbsQYDiff            0.00153497
2017-06-03 16:18:54.340871 EDT | AverageAction               0.00219203
2017-06-03 16:18:54.341093 EDT | PolicyRegParamNorm         61.7955
2017-06-03 16:18:54.341329 EDT | QFunRegParamNorm           26.915
2017-06-03 16:18:54.341549 EDT | -----------------------  --------------
2017-06-03 16:18:54.341961 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #447 | Training started
2017-06-03 16:19:14.830554 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #447 | Training finished
2017-06-03 16:19:14.831485 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #447 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 16:19:14.831833 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #447 | Collecting samples for evaluation
2017-06-03 16:19:24.578755 EDT | -----------------------  --------------
2017-06-03 16:19:24.579594 EDT | Epoch                     447
2017-06-03 16:19:24.579853 EDT | Iteration                 447
2017-06-03 16:19:24.580092 EDT | AverageReturn            1000
2017-06-03 16:19:24.580336 EDT | StdReturn                   0
2017-06-03 16:19:24.580565 EDT | MaxReturn                1000
2017-06-03 16:19:24.580801 EDT | MinReturn                1000
2017-06-03 16:19:24.581033 EDT | AverageEsReturn            20.0588
2017-06-03 16:19:24.581261 EDT | StdEsReturn                15.5758
2017-06-03 16:19:24.581487 EDT | MaxEsReturn                68
2017-06-03 16:19:24.581721 EDT | MinEsReturn                 3
2017-06-03 16:19:24.581957 EDT | AverageDiscountedReturn    99.9957
2017-06-03 16:19:24.582194 EDT | AverageQLoss                3.29542e-05
2017-06-03 16:19:24.582426 EDT | AveragePolicySurr          -0.0963711
2017-06-03 16:19:24.582657 EDT | AverageQ                    0.0918362
2017-06-03 16:19:24.582887 EDT | AverageAbsQ                 0.0920608
2017-06-03 16:19:24.583117 EDT | AverageY                    0.0918387
2017-06-03 16:19:24.583346 EDT | AverageAbsY                 0.0918556
2017-06-03 16:19:24.583575 EDT | AverageAbsQYDiff            0.00152795
2017-06-03 16:19:24.583820 EDT | AverageAction               0.0428393
2017-06-03 16:19:24.584087 EDT | PolicyRegParamNorm         61.8167
2017-06-03 16:19:24.584344 EDT | QFunRegParamNorm           26.9155
2017-06-03 16:19:24.584613 EDT | -----------------------  --------------
2017-06-03 16:19:24.585038 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #448 | Training started
2017-06-03 16:19:43.392909 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #448 | Training finished
2017-06-03 16:19:43.393826 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #448 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 16:19:43.394106 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #448 | Collecting samples for evaluation
2017-06-03 16:19:52.750088 EDT | -----------------------  --------------
2017-06-03 16:19:52.752288 EDT | Epoch                     448
2017-06-03 16:19:52.752556 EDT | Iteration                 448
2017-06-03 16:19:52.752793 EDT | AverageReturn            1000
2017-06-03 16:19:52.753025 EDT | StdReturn                   0
2017-06-03 16:19:52.753255 EDT | MaxReturn                1000
2017-06-03 16:19:52.753493 EDT | MinReturn                1000
2017-06-03 16:19:52.753735 EDT | AverageEsReturn            18.9804
2017-06-03 16:19:52.753971 EDT | StdEsReturn                17.1069
2017-06-03 16:19:52.754203 EDT | MaxEsReturn                92
2017-06-03 16:19:52.754432 EDT | MinEsReturn                 3
2017-06-03 16:19:52.754659 EDT | AverageDiscountedReturn    99.9957
2017-06-03 16:19:52.754885 EDT | AverageQLoss                3.48108e-05
2017-06-03 16:19:52.755116 EDT | AveragePolicySurr          -0.0964388
2017-06-03 16:19:52.755343 EDT | AverageQ                    0.0917091
2017-06-03 16:19:52.755572 EDT | AverageAbsQ                 0.0919704
2017-06-03 16:19:52.755797 EDT | AverageY                    0.0917043
2017-06-03 16:19:52.756023 EDT | AverageAbsY                 0.0917186
2017-06-03 16:19:52.756248 EDT | AverageAbsQYDiff            0.00165465
2017-06-03 16:19:52.756473 EDT | AverageAction               0.0557582
2017-06-03 16:19:52.756697 EDT | PolicyRegParamNorm         61.8581
2017-06-03 16:19:52.756923 EDT | QFunRegParamNorm           26.927
2017-06-03 16:19:52.757147 EDT | -----------------------  --------------
2017-06-03 16:19:52.757521 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #449 | Training started
2017-06-03 16:20:11.327145 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #449 | Training finished
2017-06-03 16:20:11.327814 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #449 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 16:20:11.328270 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #449 | Collecting samples for evaluation
2017-06-03 16:20:20.559437 EDT | -----------------------  --------------
2017-06-03 16:20:20.560478 EDT | Epoch                     449
2017-06-03 16:20:20.560923 EDT | Iteration                 449
2017-06-03 16:20:20.561339 EDT | AverageReturn            1000
2017-06-03 16:20:20.561742 EDT | StdReturn                   0
2017-06-03 16:20:20.562146 EDT | MaxReturn                1000
2017-06-03 16:20:20.562495 EDT | MinReturn                1000
2017-06-03 16:20:20.562767 EDT | AverageEsReturn            17.9107
2017-06-03 16:20:20.563050 EDT | StdEsReturn                13.4088
2017-06-03 16:20:20.563371 EDT | MaxEsReturn                60
2017-06-03 16:20:20.563708 EDT | MinEsReturn                 3
2017-06-03 16:20:20.564062 EDT | AverageDiscountedReturn    99.9957
2017-06-03 16:20:20.564423 EDT | AverageQLoss                3.34335e-05
2017-06-03 16:20:20.564779 EDT | AveragePolicySurr          -0.0962388
2017-06-03 16:20:20.565125 EDT | AverageQ                    0.0919317
2017-06-03 16:20:20.565473 EDT | AverageAbsQ                 0.0921853
2017-06-03 16:20:20.565860 EDT | AverageY                    0.0919302
2017-06-03 16:20:20.566111 EDT | AverageAbsY                 0.091951
2017-06-03 16:20:20.566349 EDT | AverageAbsQYDiff            0.00160851
2017-06-03 16:20:20.566584 EDT | AverageAction               0.00277554
2017-06-03 16:20:20.566819 EDT | PolicyRegParamNorm         61.882
2017-06-03 16:20:20.567061 EDT | QFunRegParamNorm           26.9561
2017-06-03 16:20:20.567292 EDT | -----------------------  --------------
2017-06-03 16:20:20.567688 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #450 | Training started
2017-06-03 16:20:40.001394 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #450 | Training finished
2017-06-03 16:20:40.002403 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #450 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 16:20:40.002750 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #450 | Collecting samples for evaluation
2017-06-03 16:20:50.079184 EDT | -----------------------  --------------
2017-06-03 16:20:50.081834 EDT | Epoch                     450
2017-06-03 16:20:50.082115 EDT | Iteration                 450
2017-06-03 16:20:50.082370 EDT | AverageReturn            1000
2017-06-03 16:20:50.082610 EDT | StdReturn                   0
2017-06-03 16:20:50.082854 EDT | MaxReturn                1000
2017-06-03 16:20:50.083097 EDT | MinReturn                1000
2017-06-03 16:20:50.083349 EDT | AverageEsReturn            15.4154
2017-06-03 16:20:50.083585 EDT | StdEsReturn                12.4454
2017-06-03 16:20:50.083835 EDT | MaxEsReturn                50
2017-06-03 16:20:50.084077 EDT | MinEsReturn                 3
2017-06-03 16:20:50.084324 EDT | AverageDiscountedReturn    99.9957
2017-06-03 16:20:50.084558 EDT | AverageQLoss                3.43597e-05
2017-06-03 16:20:50.084791 EDT | AveragePolicySurr          -0.096105
2017-06-03 16:20:50.085024 EDT | AverageQ                    0.0918086
2017-06-03 16:20:50.085271 EDT | AverageAbsQ                 0.0921259
2017-06-03 16:20:50.085502 EDT | AverageY                    0.0918152
2017-06-03 16:20:50.085744 EDT | AverageAbsY                 0.0918389
2017-06-03 16:20:50.085978 EDT | AverageAbsQYDiff            0.00162716
2017-06-03 16:20:50.086210 EDT | AverageAction               0.000875406
2017-06-03 16:20:50.086441 EDT | PolicyRegParamNorm         61.9248
2017-06-03 16:20:50.086672 EDT | QFunRegParamNorm           26.9745
2017-06-03 16:20:50.086905 EDT | -----------------------  --------------
2017-06-03 16:20:50.087290 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #451 | Training started
2017-06-03 16:21:08.734903 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #451 | Training finished
2017-06-03 16:21:08.735792 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #451 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 16:21:08.736098 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #451 | Collecting samples for evaluation
2017-06-03 16:21:17.866626 EDT | -----------------------  -------------
2017-06-03 16:21:17.867465 EDT | Epoch                     451
2017-06-03 16:21:17.867765 EDT | Iteration                 451
2017-06-03 16:21:17.868021 EDT | AverageReturn            1000
2017-06-03 16:21:17.868282 EDT | StdReturn                   0
2017-06-03 16:21:17.868562 EDT | MaxReturn                1000
2017-06-03 16:21:17.868819 EDT | MinReturn                1000
2017-06-03 16:21:17.869064 EDT | AverageEsReturn            21.375
2017-06-03 16:21:17.869307 EDT | StdEsReturn                20.4966
2017-06-03 16:21:17.869563 EDT | MaxEsReturn               123
2017-06-03 16:21:17.869874 EDT | MinEsReturn                 3
2017-06-03 16:21:17.870139 EDT | AverageDiscountedReturn    99.9957
2017-06-03 16:21:17.870457 EDT | AverageQLoss                3.5755e-05
2017-06-03 16:21:17.870736 EDT | AveragePolicySurr          -0.0960524
2017-06-03 16:21:17.871066 EDT | AverageQ                    0.0916564
2017-06-03 16:21:17.871358 EDT | AverageAbsQ                 0.0919077
2017-06-03 16:21:17.871672 EDT | AverageY                    0.091655
2017-06-03 16:21:17.872003 EDT | AverageAbsY                 0.0916721
2017-06-03 16:21:17.872328 EDT | AverageAbsQYDiff            0.00163188
2017-06-03 16:21:17.872643 EDT | AverageAction               0.00577987
2017-06-03 16:21:17.872899 EDT | PolicyRegParamNorm         62.0434
2017-06-03 16:21:17.873145 EDT | QFunRegParamNorm           26.9828
2017-06-03 16:21:17.873387 EDT | -----------------------  -------------
2017-06-03 16:21:17.873774 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #452 | Training started
2017-06-03 16:21:35.836244 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #452 | Training finished
2017-06-03 16:21:35.837096 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #452 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 16:21:35.837366 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #452 | Collecting samples for evaluation
2017-06-03 16:21:45.101655 EDT | -----------------------  --------------
2017-06-03 16:21:45.102079 EDT | Epoch                     452
2017-06-03 16:21:45.102331 EDT | Iteration                 452
2017-06-03 16:21:45.102572 EDT | AverageReturn            1000
2017-06-03 16:21:45.102827 EDT | StdReturn                   0
2017-06-03 16:21:45.103061 EDT | MaxReturn                1000
2017-06-03 16:21:45.103319 EDT | MinReturn                1000
2017-06-03 16:21:45.103554 EDT | AverageEsReturn            20.6383
2017-06-03 16:21:45.103791 EDT | StdEsReturn                14.8931
2017-06-03 16:21:45.104021 EDT | MaxEsReturn                60
2017-06-03 16:21:45.104253 EDT | MinEsReturn                 3
2017-06-03 16:21:45.104489 EDT | AverageDiscountedReturn    99.9957
2017-06-03 16:21:45.104721 EDT | AverageQLoss                3.54238e-05
2017-06-03 16:21:45.104948 EDT | AveragePolicySurr          -0.0958764
2017-06-03 16:21:45.105175 EDT | AverageQ                    0.0915003
2017-06-03 16:21:45.105406 EDT | AverageAbsQ                 0.091754
2017-06-03 16:21:45.105642 EDT | AverageY                    0.0914975
2017-06-03 16:21:45.105887 EDT | AverageAbsY                 0.0915025
2017-06-03 16:21:45.106119 EDT | AverageAbsQYDiff            0.00169726
2017-06-03 16:21:45.106350 EDT | AverageAction               0.00235514
2017-06-03 16:21:45.106581 EDT | PolicyRegParamNorm         62.1088
2017-06-03 16:21:45.106816 EDT | QFunRegParamNorm           26.9928
2017-06-03 16:21:45.107044 EDT | -----------------------  --------------
2017-06-03 16:21:45.107434 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #453 | Training started
2017-06-03 16:22:02.804523 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #453 | Training finished
2017-06-03 16:22:02.806004 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #453 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 16:22:02.806306 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #453 | Collecting samples for evaluation
2017-06-03 16:22:12.143412 EDT | -----------------------  --------------
2017-06-03 16:22:12.144400 EDT | Epoch                     453
2017-06-03 16:22:12.144665 EDT | Iteration                 453
2017-06-03 16:22:12.144905 EDT | AverageReturn            1000
2017-06-03 16:22:12.145139 EDT | StdReturn                   0
2017-06-03 16:22:12.145370 EDT | MaxReturn                1000
2017-06-03 16:22:12.145599 EDT | MinReturn                1000
2017-06-03 16:22:12.145840 EDT | AverageEsReturn            24.9
2017-06-03 16:22:12.146083 EDT | StdEsReturn                16.4253
2017-06-03 16:22:12.146310 EDT | MaxEsReturn                82
2017-06-03 16:22:12.146538 EDT | MinEsReturn                 3
2017-06-03 16:22:12.146765 EDT | AverageDiscountedReturn    99.9957
2017-06-03 16:22:12.146992 EDT | AverageQLoss                3.02749e-05
2017-06-03 16:22:12.147225 EDT | AveragePolicySurr          -0.0957226
2017-06-03 16:22:12.147451 EDT | AverageQ                    0.0913101
2017-06-03 16:22:12.147676 EDT | AverageAbsQ                 0.091559
2017-06-03 16:22:12.147901 EDT | AverageY                    0.0913053
2017-06-03 16:22:12.148127 EDT | AverageAbsY                 0.0913188
2017-06-03 16:22:12.148353 EDT | AverageAbsQYDiff            0.00148709
2017-06-03 16:22:12.148586 EDT | AverageAction               0.00188058
2017-06-03 16:22:12.148814 EDT | PolicyRegParamNorm         62.1369
2017-06-03 16:22:12.149039 EDT | QFunRegParamNorm           26.9988
2017-06-03 16:22:12.149264 EDT | -----------------------  --------------
2017-06-03 16:22:12.149606 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #454 | Training started
2017-06-03 16:22:31.854868 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #454 | Training finished
2017-06-03 16:22:31.855746 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #454 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 16:22:31.856022 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #454 | Collecting samples for evaluation
2017-06-03 16:22:41.252243 EDT | -----------------------  --------------
2017-06-03 16:22:41.253078 EDT | Epoch                     454
2017-06-03 16:22:41.253348 EDT | Iteration                 454
2017-06-03 16:22:41.253579 EDT | AverageReturn            1000
2017-06-03 16:22:41.253827 EDT | StdReturn                   0
2017-06-03 16:22:41.254082 EDT | MaxReturn                1000
2017-06-03 16:22:41.254318 EDT | MinReturn                1000
2017-06-03 16:22:41.254547 EDT | AverageEsReturn            31.3939
2017-06-03 16:22:41.254772 EDT | StdEsReturn                25.2021
2017-06-03 16:22:41.254999 EDT | MaxEsReturn               121
2017-06-03 16:22:41.255235 EDT | MinEsReturn                 3
2017-06-03 16:22:41.255476 EDT | AverageDiscountedReturn    99.9957
2017-06-03 16:22:41.255706 EDT | AverageQLoss                3.39324e-05
2017-06-03 16:22:41.255935 EDT | AveragePolicySurr          -0.0955612
2017-06-03 16:22:41.256173 EDT | AverageQ                    0.0910263
2017-06-03 16:22:41.256403 EDT | AverageAbsQ                 0.091285
2017-06-03 16:22:41.256631 EDT | AverageY                    0.091033
2017-06-03 16:22:41.256859 EDT | AverageAbsY                 0.0910483
2017-06-03 16:22:41.257088 EDT | AverageAbsQYDiff            0.00161632
2017-06-03 16:22:41.257323 EDT | AverageAction               0.00105987
2017-06-03 16:22:41.257556 EDT | PolicyRegParamNorm         62.2124
2017-06-03 16:22:41.257818 EDT | QFunRegParamNorm           27.0254
2017-06-03 16:22:41.258050 EDT | -----------------------  --------------
2017-06-03 16:22:41.258403 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #455 | Training started
2017-06-03 16:22:59.982022 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #455 | Training finished
2017-06-03 16:22:59.982939 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #455 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 16:22:59.983244 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #455 | Collecting samples for evaluation
2017-06-03 16:23:10.010028 EDT | -----------------------  --------------
2017-06-03 16:23:10.011017 EDT | Epoch                     455
2017-06-03 16:23:10.011276 EDT | Iteration                 455
2017-06-03 16:23:10.011512 EDT | AverageReturn            1000
2017-06-03 16:23:10.011745 EDT | StdReturn                   0
2017-06-03 16:23:10.011979 EDT | MaxReturn                1000
2017-06-03 16:23:10.012218 EDT | MinReturn                1000
2017-06-03 16:23:10.012447 EDT | AverageEsReturn            24.525
2017-06-03 16:23:10.012671 EDT | StdEsReturn                24.989
2017-06-03 16:23:10.012893 EDT | MaxEsReturn               121
2017-06-03 16:23:10.013117 EDT | MinEsReturn                 3
2017-06-03 16:23:10.013348 EDT | AverageDiscountedReturn    99.9957
2017-06-03 16:23:10.013575 EDT | AverageQLoss                3.84558e-05
2017-06-03 16:23:10.014275 EDT | AveragePolicySurr          -0.0956649
2017-06-03 16:23:10.014599 EDT | AverageQ                    0.0911189
2017-06-03 16:23:10.014921 EDT | AverageAbsQ                 0.0914125
2017-06-03 16:23:10.015233 EDT | AverageY                    0.0911216
2017-06-03 16:23:10.015561 EDT | AverageAbsY                 0.0911434
2017-06-03 16:23:10.015867 EDT | AverageAbsQYDiff            0.0016004
2017-06-03 16:23:10.016173 EDT | AverageAction               0.00187044
2017-06-03 16:23:10.016488 EDT | PolicyRegParamNorm         62.2377
2017-06-03 16:23:10.016793 EDT | QFunRegParamNorm           27.0141
2017-06-03 16:23:10.017123 EDT | -----------------------  --------------
2017-06-03 16:23:10.017581 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #456 | Training started
2017-06-03 16:23:30.358466 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #456 | Training finished
2017-06-03 16:23:30.359325 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #456 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 16:23:30.359623 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #456 | Collecting samples for evaluation
2017-06-03 16:23:40.054603 EDT | -----------------------  --------------
2017-06-03 16:23:40.055429 EDT | Epoch                     456
2017-06-03 16:23:40.055697 EDT | Iteration                 456
2017-06-03 16:23:40.055938 EDT | AverageReturn            1000
2017-06-03 16:23:40.056182 EDT | StdReturn                   0
2017-06-03 16:23:40.056417 EDT | MaxReturn                1000
2017-06-03 16:23:40.056659 EDT | MinReturn                1000
2017-06-03 16:23:40.056890 EDT | AverageEsReturn            23.9048
2017-06-03 16:23:40.057123 EDT | StdEsReturn                26.5274
2017-06-03 16:23:40.057354 EDT | MaxEsReturn               119
2017-06-03 16:23:40.057585 EDT | MinEsReturn                 3
2017-06-03 16:23:40.057844 EDT | AverageDiscountedReturn    99.9957
2017-06-03 16:23:40.058079 EDT | AverageQLoss                2.77526e-05
2017-06-03 16:23:40.058310 EDT | AveragePolicySurr          -0.095449
2017-06-03 16:23:40.058542 EDT | AverageQ                    0.0910907
2017-06-03 16:23:40.058768 EDT | AverageAbsQ                 0.091284
2017-06-03 16:23:40.058996 EDT | AverageY                    0.0910875
2017-06-03 16:23:40.059225 EDT | AverageAbsY                 0.0911019
2017-06-03 16:23:40.059480 EDT | AverageAbsQYDiff            0.00140651
2017-06-03 16:23:40.059706 EDT | AverageAction               0.00285991
2017-06-03 16:23:40.059930 EDT | PolicyRegParamNorm         62.283
2017-06-03 16:23:40.060154 EDT | QFunRegParamNorm           27.0432
2017-06-03 16:23:40.060383 EDT | -----------------------  --------------
2017-06-03 16:23:40.060739 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #457 | Training started
2017-06-03 16:23:57.873638 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #457 | Training finished
2017-06-03 16:23:57.875957 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #457 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 16:23:57.876262 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #457 | Collecting samples for evaluation
2017-06-03 16:24:07.701750 EDT | -----------------------  --------------
2017-06-03 16:24:07.702591 EDT | Epoch                     457
2017-06-03 16:24:07.702852 EDT | Iteration                 457
2017-06-03 16:24:07.703094 EDT | AverageReturn            1000
2017-06-03 16:24:07.703331 EDT | StdReturn                   0
2017-06-03 16:24:07.703565 EDT | MaxReturn                1000
2017-06-03 16:24:07.703806 EDT | MinReturn                1000
2017-06-03 16:24:07.704037 EDT | AverageEsReturn            27.6111
2017-06-03 16:24:07.704279 EDT | StdEsReturn                23.2131
2017-06-03 16:24:07.704514 EDT | MaxEsReturn                93
2017-06-03 16:24:07.704747 EDT | MinEsReturn                 4
2017-06-03 16:24:07.704980 EDT | AverageDiscountedReturn    99.9957
2017-06-03 16:24:07.705212 EDT | AverageQLoss                3.31101e-05
2017-06-03 16:24:07.705474 EDT | AveragePolicySurr          -0.0956377
2017-06-03 16:24:07.705725 EDT | AverageQ                    0.0911169
2017-06-03 16:24:07.705962 EDT | AverageAbsQ                 0.0913962
2017-06-03 16:24:07.706194 EDT | AverageY                    0.0911165
2017-06-03 16:24:07.706427 EDT | AverageAbsY                 0.0911338
2017-06-03 16:24:07.706666 EDT | AverageAbsQYDiff            0.00163944
2017-06-03 16:24:07.706901 EDT | AverageAction               0.00185963
2017-06-03 16:24:07.707133 EDT | PolicyRegParamNorm         62.3629
2017-06-03 16:24:07.707363 EDT | QFunRegParamNorm           27.0389
2017-06-03 16:24:07.707595 EDT | -----------------------  --------------
2017-06-03 16:24:07.707979 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #458 | Training started
2017-06-03 16:24:25.513294 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #458 | Training finished
2017-06-03 16:24:25.514186 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #458 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 16:24:25.514540 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #458 | Collecting samples for evaluation
2017-06-03 16:24:35.080488 EDT | -----------------------  -------------
2017-06-03 16:24:35.081482 EDT | Epoch                     458
2017-06-03 16:24:35.081838 EDT | Iteration                 458
2017-06-03 16:24:35.082186 EDT | AverageReturn            1000
2017-06-03 16:24:35.082511 EDT | StdReturn                   0
2017-06-03 16:24:35.082835 EDT | MaxReturn                1000
2017-06-03 16:24:35.083161 EDT | MinReturn                1000
2017-06-03 16:24:35.083480 EDT | AverageEsReturn            25.4
2017-06-03 16:24:35.083799 EDT | StdEsReturn                13.9208
2017-06-03 16:24:35.084119 EDT | MaxEsReturn                61
2017-06-03 16:24:35.084435 EDT | MinEsReturn                 4
2017-06-03 16:24:35.084749 EDT | AverageDiscountedReturn    99.9957
2017-06-03 16:24:35.085078 EDT | AverageQLoss                3.3563e-05
2017-06-03 16:24:35.085393 EDT | AveragePolicySurr          -0.0952974
2017-06-03 16:24:35.085743 EDT | AverageQ                    0.0908555
2017-06-03 16:24:35.086067 EDT | AverageAbsQ                 0.0911376
2017-06-03 16:24:35.086384 EDT | AverageY                    0.0908523
2017-06-03 16:24:35.086699 EDT | AverageAbsY                 0.0908738
2017-06-03 16:24:35.087026 EDT | AverageAbsQYDiff            0.00168476
2017-06-03 16:24:35.087340 EDT | AverageAction               0.00525013
2017-06-03 16:24:35.087659 EDT | PolicyRegParamNorm         62.3773
2017-06-03 16:24:35.088019 EDT | QFunRegParamNorm           27.048
2017-06-03 16:24:35.088388 EDT | -----------------------  -------------
2017-06-03 16:24:35.088843 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #459 | Training started
2017-06-03 16:24:54.134007 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #459 | Training finished
2017-06-03 16:24:54.134868 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #459 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 16:24:54.135145 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #459 | Collecting samples for evaluation
2017-06-03 16:25:04.566705 EDT | -----------------------  --------------
2017-06-03 16:25:04.567606 EDT | Epoch                     459
2017-06-03 16:25:04.567914 EDT | Iteration                 459
2017-06-03 16:25:04.568191 EDT | AverageReturn            1000
2017-06-03 16:25:04.568472 EDT | StdReturn                   0
2017-06-03 16:25:04.568753 EDT | MaxReturn                1000
2017-06-03 16:25:04.569052 EDT | MinReturn                1000
2017-06-03 16:25:04.569308 EDT | AverageEsReturn            26.4211
2017-06-03 16:25:04.569578 EDT | StdEsReturn                18.6006
2017-06-03 16:25:04.569871 EDT | MaxEsReturn                65
2017-06-03 16:25:04.570128 EDT | MinEsReturn                 3
2017-06-03 16:25:04.570407 EDT | AverageDiscountedReturn    99.9957
2017-06-03 16:25:04.570682 EDT | AverageQLoss                3.39331e-05
2017-06-03 16:25:04.570942 EDT | AveragePolicySurr          -0.0951737
2017-06-03 16:25:04.571195 EDT | AverageQ                    0.0905913
2017-06-03 16:25:04.571463 EDT | AverageAbsQ                 0.0908322
2017-06-03 16:25:04.571739 EDT | AverageY                    0.0905892
2017-06-03 16:25:04.571984 EDT | AverageAbsY                 0.0906108
2017-06-03 16:25:04.572248 EDT | AverageAbsQYDiff            0.00147418
2017-06-03 16:25:04.572518 EDT | AverageAction               0.00395944
2017-06-03 16:25:04.572777 EDT | PolicyRegParamNorm         62.4352
2017-06-03 16:25:04.573026 EDT | QFunRegParamNorm           27.0626
2017-06-03 16:25:04.573293 EDT | -----------------------  --------------
2017-06-03 16:25:04.573702 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #460 | Training started
2017-06-03 16:25:23.900420 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #460 | Training finished
2017-06-03 16:25:23.901325 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #460 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 16:25:23.901601 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #460 | Collecting samples for evaluation
2017-06-03 16:25:34.407907 EDT | -----------------------  --------------
2017-06-03 16:25:34.408741 EDT | Epoch                     460
2017-06-03 16:25:34.409011 EDT | Iteration                 460
2017-06-03 16:25:34.409253 EDT | AverageReturn            1000
2017-06-03 16:25:34.409500 EDT | StdReturn                   0
2017-06-03 16:25:34.409744 EDT | MaxReturn                1000
2017-06-03 16:25:34.409984 EDT | MinReturn                1000
2017-06-03 16:25:34.410218 EDT | AverageEsReturn            22.1628
2017-06-03 16:25:34.410450 EDT | StdEsReturn                18.5697
2017-06-03 16:25:34.410682 EDT | MaxEsReturn               102
2017-06-03 16:25:34.410920 EDT | MinEsReturn                 3
2017-06-03 16:25:34.411151 EDT | AverageDiscountedReturn    99.9957
2017-06-03 16:25:34.411383 EDT | AverageQLoss                3.27383e-05
2017-06-03 16:25:34.411625 EDT | AveragePolicySurr          -0.095184
2017-06-03 16:25:34.411856 EDT | AverageQ                    0.0907363
2017-06-03 16:25:34.412092 EDT | AverageAbsQ                 0.0910099
2017-06-03 16:25:34.412322 EDT | AverageY                    0.0907365
2017-06-03 16:25:34.412554 EDT | AverageAbsY                 0.0907727
2017-06-03 16:25:34.412787 EDT | AverageAbsQYDiff            0.00156684
2017-06-03 16:25:34.413015 EDT | AverageAction               0.008413
2017-06-03 16:25:34.413252 EDT | PolicyRegParamNorm         62.526
2017-06-03 16:25:34.413494 EDT | QFunRegParamNorm           27.0742
2017-06-03 16:25:34.413735 EDT | -----------------------  --------------
2017-06-03 16:25:34.414111 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #461 | Training started
2017-06-03 16:25:53.460198 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #461 | Training finished
2017-06-03 16:25:53.461126 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #461 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 16:25:53.461515 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #461 | Collecting samples for evaluation
2017-06-03 16:26:02.509004 EDT | -----------------------  --------------
2017-06-03 16:26:02.509386 EDT | Epoch                     461
2017-06-03 16:26:02.509641 EDT | Iteration                 461
2017-06-03 16:26:02.509904 EDT | AverageReturn            1000
2017-06-03 16:26:02.510146 EDT | StdReturn                   0
2017-06-03 16:26:02.510383 EDT | MaxReturn                1000
2017-06-03 16:26:02.510627 EDT | MinReturn                1000
2017-06-03 16:26:02.510863 EDT | AverageEsReturn            24.9524
2017-06-03 16:26:02.511097 EDT | StdEsReturn                19.1895
2017-06-03 16:26:02.511343 EDT | MaxEsReturn                84
2017-06-03 16:26:02.511576 EDT | MinEsReturn                 3
2017-06-03 16:26:02.511817 EDT | AverageDiscountedReturn    99.9957
2017-06-03 16:26:02.512073 EDT | AverageQLoss                3.23279e-05
2017-06-03 16:26:02.512308 EDT | AveragePolicySurr          -0.0952984
2017-06-03 16:26:02.512541 EDT | AverageQ                    0.0910109
2017-06-03 16:26:02.512791 EDT | AverageAbsQ                 0.0912668
2017-06-03 16:26:02.513023 EDT | AverageY                    0.0910121
2017-06-03 16:26:02.513251 EDT | AverageAbsY                 0.0910393
2017-06-03 16:26:02.513479 EDT | AverageAbsQYDiff            0.00156781
2017-06-03 16:26:02.513743 EDT | AverageAction               0.00192631
2017-06-03 16:26:02.513988 EDT | PolicyRegParamNorm         62.6382
2017-06-03 16:26:02.514233 EDT | QFunRegParamNorm           27.077
2017-06-03 16:26:02.514467 EDT | -----------------------  --------------
2017-06-03 16:26:02.514819 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #462 | Training started
2017-06-03 16:26:20.386963 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #462 | Training finished
2017-06-03 16:26:20.402148 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #462 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 16:26:20.402720 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #462 | Collecting samples for evaluation
2017-06-03 16:26:30.580253 EDT | -----------------------  --------------
2017-06-03 16:26:30.581094 EDT | Epoch                     462
2017-06-03 16:26:30.581367 EDT | Iteration                 462
2017-06-03 16:26:30.581599 EDT | AverageReturn            1000
2017-06-03 16:26:30.581835 EDT | StdReturn                   0
2017-06-03 16:26:30.582060 EDT | MaxReturn                1000
2017-06-03 16:26:30.582283 EDT | MinReturn                1000
2017-06-03 16:26:30.582515 EDT | AverageEsReturn            15.5938
2017-06-03 16:26:30.582738 EDT | StdEsReturn                15.2005
2017-06-03 16:26:30.582960 EDT | MaxEsReturn                94
2017-06-03 16:26:30.583182 EDT | MinEsReturn                 3
2017-06-03 16:26:30.583408 EDT | AverageDiscountedReturn    99.9957
2017-06-03 16:26:30.583629 EDT | AverageQLoss                3.67298e-05
2017-06-03 16:26:30.583856 EDT | AveragePolicySurr          -0.0949674
2017-06-03 16:26:30.584077 EDT | AverageQ                    0.0902899
2017-06-03 16:26:30.584298 EDT | AverageAbsQ                 0.0905831
2017-06-03 16:26:30.584519 EDT | AverageY                    0.0902923
2017-06-03 16:26:30.584740 EDT | AverageAbsY                 0.0903134
2017-06-03 16:26:30.584964 EDT | AverageAbsQYDiff            0.00168906
2017-06-03 16:26:30.585185 EDT | AverageAction               0.0229314
2017-06-03 16:26:30.585406 EDT | PolicyRegParamNorm         62.6766
2017-06-03 16:26:30.585626 EDT | QFunRegParamNorm           27.0893
2017-06-03 16:26:30.585892 EDT | -----------------------  --------------
2017-06-03 16:26:30.586289 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #463 | Training started
2017-06-03 16:26:49.616080 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #463 | Training finished
2017-06-03 16:26:49.617140 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #463 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 16:26:49.617547 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #463 | Collecting samples for evaluation
2017-06-03 16:26:58.826336 EDT | -----------------------  --------------
2017-06-03 16:26:58.827221 EDT | Epoch                     463
2017-06-03 16:26:58.827494 EDT | Iteration                 463
2017-06-03 16:26:58.827748 EDT | AverageReturn            1000
2017-06-03 16:26:58.827996 EDT | StdReturn                   0
2017-06-03 16:26:58.828359 EDT | MaxReturn                1000
2017-06-03 16:26:58.828687 EDT | MinReturn                1000
2017-06-03 16:26:58.829013 EDT | AverageEsReturn            14.75
2017-06-03 16:26:58.829352 EDT | StdEsReturn                11.9464
2017-06-03 16:26:58.829672 EDT | MaxEsReturn                59
2017-06-03 16:26:58.830026 EDT | MinEsReturn                 3
2017-06-03 16:26:58.830344 EDT | AverageDiscountedReturn    99.9957
2017-06-03 16:26:58.830665 EDT | AverageQLoss                3.15191e-05
2017-06-03 16:26:58.830984 EDT | AveragePolicySurr          -0.0948694
2017-06-03 16:26:58.831324 EDT | AverageQ                    0.0902845
2017-06-03 16:26:58.831644 EDT | AverageAbsQ                 0.0905096
2017-06-03 16:26:58.831961 EDT | AverageY                    0.0902835
2017-06-03 16:26:58.832276 EDT | AverageAbsY                 0.0902969
2017-06-03 16:26:58.832619 EDT | AverageAbsQYDiff            0.00150679
2017-06-03 16:26:58.832941 EDT | AverageAction               3.11429e-06
2017-06-03 16:26:58.833255 EDT | PolicyRegParamNorm         62.7081
2017-06-03 16:26:58.833573 EDT | QFunRegParamNorm           27.0933
2017-06-03 16:26:58.833900 EDT | -----------------------  --------------
2017-06-03 16:26:58.834368 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #464 | Training started
2017-06-03 16:27:17.520656 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #464 | Training finished
2017-06-03 16:27:17.521609 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #464 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 16:27:17.522030 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #464 | Collecting samples for evaluation
2017-06-03 16:27:28.359816 EDT | -----------------------  --------------
2017-06-03 16:27:28.360676 EDT | Epoch                     464
2017-06-03 16:27:28.360930 EDT | Iteration                 464
2017-06-03 16:27:28.361193 EDT | AverageReturn            1000
2017-06-03 16:27:28.361420 EDT | StdReturn                   0
2017-06-03 16:27:28.361646 EDT | MaxReturn                1000
2017-06-03 16:27:28.361882 EDT | MinReturn                1000
2017-06-03 16:27:28.362115 EDT | AverageEsReturn            23.3
2017-06-03 16:27:28.362340 EDT | StdEsReturn                19.6662
2017-06-03 16:27:28.362562 EDT | MaxEsReturn                86
2017-06-03 16:27:28.362784 EDT | MinEsReturn                 2
2017-06-03 16:27:28.363002 EDT | AverageDiscountedReturn    99.9957
2017-06-03 16:27:28.363219 EDT | AverageQLoss                3.12436e-05
2017-06-03 16:27:28.363441 EDT | AveragePolicySurr          -0.0946278
2017-06-03 16:27:28.363662 EDT | AverageQ                    0.090143
2017-06-03 16:27:28.363884 EDT | AverageAbsQ                 0.0903746
2017-06-03 16:27:28.364104 EDT | AverageY                    0.090143
2017-06-03 16:27:28.364325 EDT | AverageAbsY                 0.0901578
2017-06-03 16:27:28.364548 EDT | AverageAbsQYDiff            0.00151871
2017-06-03 16:27:28.364769 EDT | AverageAction               8.18365e-06
2017-06-03 16:27:28.364997 EDT | PolicyRegParamNorm         62.754
2017-06-03 16:27:28.365220 EDT | QFunRegParamNorm           27.1107
2017-06-03 16:27:28.365441 EDT | -----------------------  --------------
2017-06-03 16:27:28.365814 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #465 | Training started
2017-06-03 16:27:46.806676 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #465 | Training finished
2017-06-03 16:27:46.807684 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #465 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 16:27:46.807950 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #465 | Collecting samples for evaluation
2017-06-03 16:27:56.325361 EDT | -----------------------  --------------
2017-06-03 16:27:56.326365 EDT | Epoch                     465
2017-06-03 16:27:56.326709 EDT | Iteration                 465
2017-06-03 16:27:56.327027 EDT | AverageReturn            1000
2017-06-03 16:27:56.327346 EDT | StdReturn                   0
2017-06-03 16:27:56.327658 EDT | MaxReturn                1000
2017-06-03 16:27:56.327992 EDT | MinReturn                1000
2017-06-03 16:27:56.328439 EDT | AverageEsReturn            24.0909
2017-06-03 16:27:56.328891 EDT | StdEsReturn                17.4874
2017-06-03 16:27:56.329215 EDT | MaxEsReturn                70
2017-06-03 16:27:56.329525 EDT | MinEsReturn                 3
2017-06-03 16:27:56.329865 EDT | AverageDiscountedReturn    99.9957
2017-06-03 16:27:56.330182 EDT | AverageQLoss                3.23604e-05
2017-06-03 16:27:56.330502 EDT | AveragePolicySurr          -0.0947227
2017-06-03 16:27:56.330821 EDT | AverageQ                    0.0904113
2017-06-03 16:27:56.331164 EDT | AverageAbsQ                 0.090675
2017-06-03 16:27:56.331508 EDT | AverageY                    0.0904137
2017-06-03 16:27:56.331821 EDT | AverageAbsY                 0.0904282
2017-06-03 16:27:56.332184 EDT | AverageAbsQYDiff            0.00153624
2017-06-03 16:27:56.332503 EDT | AverageAction               0.0377053
2017-06-03 16:27:56.332867 EDT | PolicyRegParamNorm         62.7788
2017-06-03 16:27:56.333187 EDT | QFunRegParamNorm           27.1004
2017-06-03 16:27:56.333540 EDT | -----------------------  --------------
2017-06-03 16:27:56.334011 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #466 | Training started
2017-06-03 16:28:14.559775 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #466 | Training finished
2017-06-03 16:28:14.560682 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #466 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 16:28:14.560956 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #466 | Collecting samples for evaluation
2017-06-03 16:28:23.690352 EDT | -----------------------  --------------
2017-06-03 16:28:23.691324 EDT | Epoch                     466
2017-06-03 16:28:23.691689 EDT | Iteration                 466
2017-06-03 16:28:23.692044 EDT | AverageReturn            1000
2017-06-03 16:28:23.692379 EDT | StdReturn                   0
2017-06-03 16:28:23.692703 EDT | MaxReturn                1000
2017-06-03 16:28:23.693040 EDT | MinReturn                1000
2017-06-03 16:28:23.693366 EDT | AverageEsReturn            20.2245
2017-06-03 16:28:23.693683 EDT | StdEsReturn                17.3855
2017-06-03 16:28:23.694018 EDT | MaxEsReturn                78
2017-06-03 16:28:23.694341 EDT | MinEsReturn                 3
2017-06-03 16:28:23.694654 EDT | AverageDiscountedReturn    99.9957
2017-06-03 16:28:23.694968 EDT | AverageQLoss                3.17169e-05
2017-06-03 16:28:23.695288 EDT | AveragePolicySurr          -0.0945879
2017-06-03 16:28:23.695603 EDT | AverageQ                    0.0902116
2017-06-03 16:28:23.695925 EDT | AverageAbsQ                 0.0905024
2017-06-03 16:28:23.696239 EDT | AverageY                    0.0902111
2017-06-03 16:28:23.696571 EDT | AverageAbsY                 0.090228
2017-06-03 16:28:23.696882 EDT | AverageAbsQYDiff            0.001537
2017-06-03 16:28:23.697194 EDT | AverageAction               0.0121556
2017-06-03 16:28:23.697513 EDT | PolicyRegParamNorm         62.8194
2017-06-03 16:28:23.697838 EDT | QFunRegParamNorm           27.1108
2017-06-03 16:28:23.698154 EDT | -----------------------  --------------
2017-06-03 16:28:23.698656 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #467 | Training started
2017-06-03 16:28:42.265706 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #467 | Training finished
2017-06-03 16:28:42.266657 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #467 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 16:28:42.266941 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #467 | Collecting samples for evaluation
2017-06-03 16:28:52.404772 EDT | -----------------------  --------------
2017-06-03 16:28:52.405721 EDT | Epoch                     467
2017-06-03 16:28:52.406010 EDT | Iteration                 467
2017-06-03 16:28:52.406305 EDT | AverageReturn            1000
2017-06-03 16:28:52.406586 EDT | StdReturn                   0
2017-06-03 16:28:52.406881 EDT | MaxReturn                1000
2017-06-03 16:28:52.407157 EDT | MinReturn                1000
2017-06-03 16:28:52.407405 EDT | AverageEsReturn            19.3922
2017-06-03 16:28:52.407659 EDT | StdEsReturn                14.6422
2017-06-03 16:28:52.407917 EDT | MaxEsReturn                59
2017-06-03 16:28:52.408171 EDT | MinEsReturn                 3
2017-06-03 16:28:52.408425 EDT | AverageDiscountedReturn    99.9957
2017-06-03 16:28:52.408682 EDT | AverageQLoss                3.23722e-05
2017-06-03 16:28:52.408931 EDT | AveragePolicySurr          -0.094766
2017-06-03 16:28:52.409186 EDT | AverageQ                    0.0902037
2017-06-03 16:28:52.409428 EDT | AverageAbsQ                 0.0904544
2017-06-03 16:28:52.409670 EDT | AverageY                    0.0902059
2017-06-03 16:28:52.409941 EDT | AverageAbsY                 0.0902259
2017-06-03 16:28:52.410198 EDT | AverageAbsQYDiff            0.00161681
2017-06-03 16:28:52.410440 EDT | AverageAction               0.00144757
2017-06-03 16:28:52.410687 EDT | PolicyRegParamNorm         62.8314
2017-06-03 16:28:52.410929 EDT | QFunRegParamNorm           27.1293
2017-06-03 16:28:52.411174 EDT | -----------------------  --------------
2017-06-03 16:28:52.411594 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #468 | Training started
2017-06-03 16:29:12.406121 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #468 | Training finished
2017-06-03 16:29:12.408749 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #468 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 16:29:12.409077 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #468 | Collecting samples for evaluation
2017-06-03 16:29:23.757508 EDT | -----------------------  --------------
2017-06-03 16:29:23.758481 EDT | Epoch                     468
2017-06-03 16:29:23.758871 EDT | Iteration                 468
2017-06-03 16:29:23.759214 EDT | AverageReturn            1000
2017-06-03 16:29:23.759536 EDT | StdReturn                   0
2017-06-03 16:29:23.759789 EDT | MaxReturn                1000
2017-06-03 16:29:23.760034 EDT | MinReturn                1000
2017-06-03 16:29:23.760277 EDT | AverageEsReturn            28.1111
2017-06-03 16:29:23.760520 EDT | StdEsReturn                27.0768
2017-06-03 16:29:23.760776 EDT | MaxEsReturn               153
2017-06-03 16:29:23.761027 EDT | MinEsReturn                 4
2017-06-03 16:29:23.761301 EDT | AverageDiscountedReturn    99.9957
2017-06-03 16:29:23.761544 EDT | AverageQLoss                3.20338e-05
2017-06-03 16:29:23.761797 EDT | AveragePolicySurr          -0.0945815
2017-06-03 16:29:23.762041 EDT | AverageQ                    0.0901633
2017-06-03 16:29:23.762281 EDT | AverageAbsQ                 0.0903953
2017-06-03 16:29:23.762530 EDT | AverageY                    0.09016
2017-06-03 16:29:23.762769 EDT | AverageAbsY                 0.0901905
2017-06-03 16:29:23.763013 EDT | AverageAbsQYDiff            0.00159539
2017-06-03 16:29:23.763252 EDT | AverageAction               0.0138664
2017-06-03 16:29:23.763490 EDT | PolicyRegParamNorm         62.8614
2017-06-03 16:29:23.763729 EDT | QFunRegParamNorm           27.1332
2017-06-03 16:29:23.763967 EDT | -----------------------  --------------
2017-06-03 16:29:23.764348 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #469 | Training started
2017-06-03 16:29:42.721901 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #469 | Training finished
2017-06-03 16:29:42.722751 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #469 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 16:29:42.723028 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #469 | Collecting samples for evaluation
2017-06-03 16:29:52.203684 EDT | -----------------------  --------------
2017-06-03 16:29:52.204807 EDT | Epoch                     469
2017-06-03 16:29:52.205155 EDT | Iteration                 469
2017-06-03 16:29:52.205484 EDT | AverageReturn            1000
2017-06-03 16:29:52.205817 EDT | StdReturn                   0
2017-06-03 16:29:52.206138 EDT | MaxReturn                1000
2017-06-03 16:29:52.206472 EDT | MinReturn                1000
2017-06-03 16:29:52.206793 EDT | AverageEsReturn            24.6098
2017-06-03 16:29:52.207110 EDT | StdEsReturn                19.5297
2017-06-03 16:29:52.207427 EDT | MaxEsReturn                94
2017-06-03 16:29:52.207756 EDT | MinEsReturn                 4
2017-06-03 16:29:52.208070 EDT | AverageDiscountedReturn    99.9957
2017-06-03 16:29:52.208422 EDT | AverageQLoss                3.36167e-05
2017-06-03 16:29:52.208740 EDT | AveragePolicySurr          -0.094362
2017-06-03 16:29:52.209050 EDT | AverageQ                    0.0899613
2017-06-03 16:29:52.209367 EDT | AverageAbsQ                 0.0902275
2017-06-03 16:29:52.209715 EDT | AverageY                    0.0899617
2017-06-03 16:29:52.210061 EDT | AverageAbsY                 0.0899874
2017-06-03 16:29:52.210374 EDT | AverageAbsQYDiff            0.00158675
2017-06-03 16:29:52.210686 EDT | AverageAction               0.0295576
2017-06-03 16:29:52.211020 EDT | PolicyRegParamNorm         62.8845
2017-06-03 16:29:52.211329 EDT | QFunRegParamNorm           27.1455
2017-06-03 16:29:52.211640 EDT | -----------------------  --------------
2017-06-03 16:29:52.212125 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #470 | Training started
2017-06-03 16:30:10.977782 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #470 | Training finished
2017-06-03 16:30:10.978177 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #470 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 16:30:10.978432 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #470 | Collecting samples for evaluation
2017-06-03 16:30:20.994139 EDT | -----------------------  --------------
2017-06-03 16:30:20.994993 EDT | Epoch                     470
2017-06-03 16:30:20.995264 EDT | Iteration                 470
2017-06-03 16:30:20.995528 EDT | AverageReturn            1000
2017-06-03 16:30:20.995778 EDT | StdReturn                   0
2017-06-03 16:30:20.996015 EDT | MaxReturn                1000
2017-06-03 16:30:20.996251 EDT | MinReturn                1000
2017-06-03 16:30:20.996484 EDT | AverageEsReturn            29.1471
2017-06-03 16:30:20.996725 EDT | StdEsReturn                22.5351
2017-06-03 16:30:20.996957 EDT | MaxEsReturn                92
2017-06-03 16:30:20.997216 EDT | MinEsReturn                 4
2017-06-03 16:30:20.997450 EDT | AverageDiscountedReturn    99.9957
2017-06-03 16:30:20.997684 EDT | AverageQLoss                2.95519e-05
2017-06-03 16:30:20.997962 EDT | AveragePolicySurr          -0.0944399
2017-06-03 16:30:20.998196 EDT | AverageQ                    0.0900402
2017-06-03 16:30:20.998428 EDT | AverageAbsQ                 0.0902967
2017-06-03 16:30:20.998664 EDT | AverageY                    0.0900347
2017-06-03 16:30:20.998895 EDT | AverageAbsY                 0.090059
2017-06-03 16:30:20.999140 EDT | AverageAbsQYDiff            0.00148988
2017-06-03 16:30:20.999370 EDT | AverageAction               0.0126627
2017-06-03 16:30:20.999600 EDT | PolicyRegParamNorm         62.9857
2017-06-03 16:30:20.999843 EDT | QFunRegParamNorm           27.1556
2017-06-03 16:30:21.000073 EDT | -----------------------  --------------
2017-06-03 16:30:21.000489 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #471 | Training started
2017-06-03 16:30:39.432252 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #471 | Training finished
2017-06-03 16:30:39.433188 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #471 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 16:30:39.433596 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #471 | Collecting samples for evaluation
2017-06-03 16:30:47.959082 EDT | -----------------------  --------------
2017-06-03 16:30:47.959705 EDT | Epoch                     471
2017-06-03 16:30:47.959983 EDT | Iteration                 471
2017-06-03 16:30:47.960224 EDT | AverageReturn            1000
2017-06-03 16:30:47.960458 EDT | StdReturn                   0
2017-06-03 16:30:47.960687 EDT | MaxReturn                1000
2017-06-03 16:30:47.960925 EDT | MinReturn                1000
2017-06-03 16:30:47.961153 EDT | AverageEsReturn            24.875
2017-06-03 16:30:47.961384 EDT | StdEsReturn                23.4512
2017-06-03 16:30:47.961623 EDT | MaxEsReturn               120
2017-06-03 16:30:47.961868 EDT | MinEsReturn                 3
2017-06-03 16:30:47.962106 EDT | AverageDiscountedReturn    99.9957
2017-06-03 16:30:47.962349 EDT | AverageQLoss                3.41095e-05
2017-06-03 16:30:47.962580 EDT | AveragePolicySurr          -0.094156
2017-06-03 16:30:47.962810 EDT | AverageQ                    0.089689
2017-06-03 16:30:47.963040 EDT | AverageAbsQ                 0.089981
2017-06-03 16:30:47.963267 EDT | AverageY                    0.0896871
2017-06-03 16:30:47.963496 EDT | AverageAbsY                 0.089707
2017-06-03 16:30:47.963730 EDT | AverageAbsQYDiff            0.00161213
2017-06-03 16:30:47.963960 EDT | AverageAction               0.00853951
2017-06-03 16:30:47.964188 EDT | PolicyRegParamNorm         63.0438
2017-06-03 16:30:47.964417 EDT | QFunRegParamNorm           27.1615
2017-06-03 16:30:47.964647 EDT | -----------------------  --------------
2017-06-03 16:30:47.964999 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #472 | Training started
2017-06-03 16:31:06.126586 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #472 | Training finished
2017-06-03 16:31:06.127490 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #472 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 16:31:06.127844 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #472 | Collecting samples for evaluation
2017-06-03 16:31:15.566193 EDT | -----------------------  ------------
2017-06-03 16:31:15.567100 EDT | Epoch                    472
2017-06-03 16:31:15.567367 EDT | Iteration                472
2017-06-03 16:31:15.567609 EDT | AverageReturn            195.827
2017-06-03 16:31:15.567884 EDT | StdReturn                  1.3115
2017-06-03 16:31:15.568118 EDT | MaxReturn                199
2017-06-03 16:31:15.568350 EDT | MinReturn                193
2017-06-03 16:31:15.568589 EDT | AverageEsReturn           20.14
2017-06-03 16:31:15.569551 EDT | StdEsReturn               19.2738
2017-06-03 16:31:15.569816 EDT | MaxEsReturn               90
2017-06-03 16:31:15.570093 EDT | MinEsReturn                3
2017-06-03 16:31:15.570338 EDT | AverageDiscountedReturn   86.0269
2017-06-03 16:31:15.570587 EDT | AverageQLoss               2.7563e-05
2017-06-03 16:31:15.570831 EDT | AveragePolicySurr         -0.0943374
2017-06-03 16:31:15.571089 EDT | AverageQ                   0.0896639
2017-06-03 16:31:15.571334 EDT | AverageAbsQ                0.0898826
2017-06-03 16:31:15.571579 EDT | AverageY                   0.0896682
2017-06-03 16:31:15.571828 EDT | AverageAbsY                0.0896811
2017-06-03 16:31:15.572070 EDT | AverageAbsQYDiff           0.00147035
2017-06-03 16:31:15.572312 EDT | AverageAction              0.0419045
2017-06-03 16:31:15.572607 EDT | PolicyRegParamNorm        63.0713
2017-06-03 16:31:15.572850 EDT | QFunRegParamNorm          27.1655
2017-06-03 16:31:15.573093 EDT | -----------------------  ------------
2017-06-03 16:31:15.573490 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #473 | Training started
2017-06-03 16:31:34.004993 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #473 | Training finished
2017-06-03 16:31:34.005716 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #473 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 16:31:34.006012 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #473 | Collecting samples for evaluation
2017-06-03 16:31:43.574305 EDT | -----------------------  -------------
2017-06-03 16:31:43.574724 EDT | Epoch                    473
2017-06-03 16:31:43.574980 EDT | Iteration                473
2017-06-03 16:31:43.575223 EDT | AverageReturn             87.8684
2017-06-03 16:31:43.575500 EDT | StdReturn                  0.669029
2017-06-03 16:31:43.575798 EDT | MaxReturn                 89
2017-06-03 16:31:43.576048 EDT | MinReturn                 86
2017-06-03 16:31:43.576288 EDT | AverageEsReturn           16.7241
2017-06-03 16:31:43.576538 EDT | StdEsReturn               14.1028
2017-06-03 16:31:43.576782 EDT | MaxEsReturn               84
2017-06-03 16:31:43.577030 EDT | MinEsReturn                3
2017-06-03 16:31:43.577269 EDT | AverageDiscountedReturn   58.6495
2017-06-03 16:31:43.577507 EDT | AverageQLoss               2.99378e-05
2017-06-03 16:31:43.577753 EDT | AveragePolicySurr         -0.0943649
2017-06-03 16:31:43.577991 EDT | AverageQ                   0.089835
2017-06-03 16:31:43.578227 EDT | AverageAbsQ                0.090071
2017-06-03 16:31:43.578463 EDT | AverageY                   0.0898374
2017-06-03 16:31:43.578698 EDT | AverageAbsY                0.0898554
2017-06-03 16:31:43.578934 EDT | AverageAbsQYDiff           0.00153894
2017-06-03 16:31:43.579169 EDT | AverageAction              0.0124319
2017-06-03 16:31:43.579406 EDT | PolicyRegParamNorm        63.1168
2017-06-03 16:31:43.579642 EDT | QFunRegParamNorm          27.1784
2017-06-03 16:31:43.579877 EDT | -----------------------  -------------
2017-06-03 16:31:43.580257 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #474 | Training started
2017-06-03 16:32:01.783878 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #474 | Training finished
2017-06-03 16:32:01.784788 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #474 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 16:32:01.785068 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #474 | Collecting samples for evaluation
2017-06-03 16:32:10.838787 EDT | -----------------------  -------------
2017-06-03 16:32:10.841735 EDT | Epoch                     474
2017-06-03 16:32:10.842009 EDT | Iteration                 474
2017-06-03 16:32:10.842253 EDT | AverageReturn            1000
2017-06-03 16:32:10.842494 EDT | StdReturn                   0
2017-06-03 16:32:10.842732 EDT | MaxReturn                1000
2017-06-03 16:32:10.842969 EDT | MinReturn                1000
2017-06-03 16:32:10.843210 EDT | AverageEsReturn            22.3261
2017-06-03 16:32:10.843444 EDT | StdEsReturn                18.4309
2017-06-03 16:32:10.843707 EDT | MaxEsReturn                77
2017-06-03 16:32:10.843950 EDT | MinEsReturn                 4
2017-06-03 16:32:10.844184 EDT | AverageDiscountedReturn    99.9957
2017-06-03 16:32:10.844417 EDT | AverageQLoss                3.5168e-05
2017-06-03 16:32:10.844650 EDT | AveragePolicySurr          -0.0939878
2017-06-03 16:32:10.844893 EDT | AverageQ                    0.0896873
2017-06-03 16:32:10.845130 EDT | AverageAbsQ                 0.0899916
2017-06-03 16:32:10.845362 EDT | AverageY                    0.0896832
2017-06-03 16:32:10.845595 EDT | AverageAbsY                 0.089698
2017-06-03 16:32:10.845840 EDT | AverageAbsQYDiff            0.00172384
2017-06-03 16:32:10.846074 EDT | AverageAction               0.00657941
2017-06-03 16:32:10.846307 EDT | PolicyRegParamNorm         63.1508
2017-06-03 16:32:10.846539 EDT | QFunRegParamNorm           27.1895
2017-06-03 16:32:10.846771 EDT | -----------------------  -------------
2017-06-03 16:32:10.847154 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #475 | Training started
2017-06-03 16:32:29.026448 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #475 | Training finished
2017-06-03 16:32:29.029686 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #475 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 16:32:29.030358 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #475 | Collecting samples for evaluation
2017-06-03 16:32:39.255954 EDT | -----------------------  --------------
2017-06-03 16:32:39.256793 EDT | Epoch                     475
2017-06-03 16:32:39.257061 EDT | Iteration                 475
2017-06-03 16:32:39.257303 EDT | AverageReturn            1000
2017-06-03 16:32:39.257549 EDT | StdReturn                   0
2017-06-03 16:32:39.257797 EDT | MaxReturn                1000
2017-06-03 16:32:39.258041 EDT | MinReturn                1000
2017-06-03 16:32:39.258276 EDT | AverageEsReturn            23.0682
2017-06-03 16:32:39.258508 EDT | StdEsReturn                16.8191
2017-06-03 16:32:39.258741 EDT | MaxEsReturn                74
2017-06-03 16:32:39.259007 EDT | MinEsReturn                 4
2017-06-03 16:32:39.259239 EDT | AverageDiscountedReturn    99.9957
2017-06-03 16:32:39.259474 EDT | AverageQLoss                3.00969e-05
2017-06-03 16:32:39.259705 EDT | AveragePolicySurr          -0.0939501
2017-06-03 16:32:39.259936 EDT | AverageQ                    0.089518
2017-06-03 16:32:39.260177 EDT | AverageAbsQ                 0.089755
2017-06-03 16:32:39.260408 EDT | AverageY                    0.0895231
2017-06-03 16:32:39.260638 EDT | AverageAbsY                 0.0895347
2017-06-03 16:32:39.260867 EDT | AverageAbsQYDiff            0.00155508
2017-06-03 16:32:39.261097 EDT | AverageAction               0.0122601
2017-06-03 16:32:39.261327 EDT | PolicyRegParamNorm         63.1909
2017-06-03 16:32:39.261557 EDT | QFunRegParamNorm           27.2093
2017-06-03 16:32:39.261808 EDT | -----------------------  --------------
2017-06-03 16:32:39.262197 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #476 | Training started
2017-06-03 16:32:58.319968 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #476 | Training finished
2017-06-03 16:32:58.320851 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #476 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 16:32:58.321109 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #476 | Collecting samples for evaluation
2017-06-03 16:33:08.293529 EDT | -----------------------  -------------
2017-06-03 16:33:08.294392 EDT | Epoch                     476
2017-06-03 16:33:08.294680 EDT | Iteration                 476
2017-06-03 16:33:08.294924 EDT | AverageReturn            1000
2017-06-03 16:33:08.295167 EDT | StdReturn                   0
2017-06-03 16:33:08.295481 EDT | MaxReturn                1000
2017-06-03 16:33:08.295816 EDT | MinReturn                1000
2017-06-03 16:33:08.296115 EDT | AverageEsReturn            25.2368
2017-06-03 16:33:08.296471 EDT | StdEsReturn                18.7637
2017-06-03 16:33:08.296773 EDT | MaxEsReturn                77
2017-06-03 16:33:08.297106 EDT | MinEsReturn                 4
2017-06-03 16:33:08.297416 EDT | AverageDiscountedReturn    99.9957
2017-06-03 16:33:08.297761 EDT | AverageQLoss                3.0706e-05
2017-06-03 16:33:08.298083 EDT | AveragePolicySurr          -0.093953
2017-06-03 16:33:08.298405 EDT | AverageQ                    0.0896265
2017-06-03 16:33:08.298735 EDT | AverageAbsQ                 0.0898432
2017-06-03 16:33:08.299043 EDT | AverageY                    0.0896246
2017-06-03 16:33:08.299376 EDT | AverageAbsY                 0.0896324
2017-06-03 16:33:08.299667 EDT | AverageAbsQYDiff            0.00150664
2017-06-03 16:33:08.300001 EDT | AverageAction               0.0129796
2017-06-03 16:33:08.300299 EDT | PolicyRegParamNorm         63.2785
2017-06-03 16:33:08.300633 EDT | QFunRegParamNorm           27.2031
2017-06-03 16:33:08.300931 EDT | -----------------------  -------------
2017-06-03 16:33:08.301436 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #477 | Training started
2017-06-03 16:33:28.395872 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #477 | Training finished
2017-06-03 16:33:28.396764 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #477 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 16:33:28.397079 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #477 | Collecting samples for evaluation
2017-06-03 16:33:38.612030 EDT | -----------------------  --------------
2017-06-03 16:33:38.612928 EDT | Epoch                     477
2017-06-03 16:33:38.613232 EDT | Iteration                 477
2017-06-03 16:33:38.613490 EDT | AverageReturn            1000
2017-06-03 16:33:38.613757 EDT | StdReturn                   0
2017-06-03 16:33:38.614032 EDT | MaxReturn                1000
2017-06-03 16:33:38.614313 EDT | MinReturn                1000
2017-06-03 16:33:38.614551 EDT | AverageEsReturn            27.6216
2017-06-03 16:33:38.614818 EDT | StdEsReturn                25.7686
2017-06-03 16:33:38.615091 EDT | MaxEsReturn               132
2017-06-03 16:33:38.615349 EDT | MinEsReturn                 3
2017-06-03 16:33:38.615601 EDT | AverageDiscountedReturn    99.9957
2017-06-03 16:33:38.615874 EDT | AverageQLoss                3.53861e-05
2017-06-03 16:33:38.616123 EDT | AveragePolicySurr          -0.0938173
2017-06-03 16:33:38.616360 EDT | AverageQ                    0.089459
2017-06-03 16:33:38.616624 EDT | AverageAbsQ                 0.0897416
2017-06-03 16:33:38.616894 EDT | AverageY                    0.0894547
2017-06-03 16:33:38.617140 EDT | AverageAbsY                 0.089467
2017-06-03 16:33:38.617396 EDT | AverageAbsQYDiff            0.00166415
2017-06-03 16:33:38.617664 EDT | AverageAction               0.0042009
2017-06-03 16:33:38.618040 EDT | PolicyRegParamNorm         63.3411
2017-06-03 16:33:38.618300 EDT | QFunRegParamNorm           27.2161
2017-06-03 16:33:38.618569 EDT | -----------------------  --------------
2017-06-03 16:33:38.619101 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #478 | Training started
2017-06-03 16:33:58.157878 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #478 | Training finished
2017-06-03 16:33:58.159371 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #478 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 16:33:58.159870 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #478 | Collecting samples for evaluation
2017-06-03 16:34:08.349533 EDT | -----------------------  --------------
2017-06-03 16:34:08.350532 EDT | Epoch                     478
2017-06-03 16:34:08.350874 EDT | Iteration                 478
2017-06-03 16:34:08.351140 EDT | AverageReturn            1000
2017-06-03 16:34:08.351475 EDT | StdReturn                   0
2017-06-03 16:34:08.351797 EDT | MaxReturn                1000
2017-06-03 16:34:08.352077 EDT | MinReturn                1000
2017-06-03 16:34:08.352412 EDT | AverageEsReturn            33.0333
2017-06-03 16:34:08.352725 EDT | StdEsReturn                22.8086
2017-06-03 16:34:08.353002 EDT | MaxEsReturn               101
2017-06-03 16:34:08.353336 EDT | MinEsReturn                 4
2017-06-03 16:34:08.353643 EDT | AverageDiscountedReturn    99.9957
2017-06-03 16:34:08.353943 EDT | AverageQLoss                3.52988e-05
2017-06-03 16:34:08.354273 EDT | AveragePolicySurr          -0.0939376
2017-06-03 16:34:08.354586 EDT | AverageQ                    0.0895184
2017-06-03 16:34:08.354884 EDT | AverageAbsQ                 0.0897197
2017-06-03 16:34:08.355212 EDT | AverageY                    0.0895192
2017-06-03 16:34:08.355478 EDT | AverageAbsY                 0.0895289
2017-06-03 16:34:08.355767 EDT | AverageAbsQYDiff            0.00151335
2017-06-03 16:34:08.356097 EDT | AverageAction               0.00639403
2017-06-03 16:34:08.356387 EDT | PolicyRegParamNorm         63.3912
2017-06-03 16:34:08.356678 EDT | QFunRegParamNorm           27.2319
2017-06-03 16:34:08.357007 EDT | -----------------------  --------------
2017-06-03 16:34:08.357376 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #479 | Training started
2017-06-03 16:34:27.092051 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #479 | Training finished
2017-06-03 16:34:27.092933 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #479 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 16:34:27.093204 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #479 | Collecting samples for evaluation
2017-06-03 16:34:36.303783 EDT | -----------------------  --------------
2017-06-03 16:34:36.304652 EDT | Epoch                     479
2017-06-03 16:34:36.304923 EDT | Iteration                 479
2017-06-03 16:34:36.305162 EDT | AverageReturn            1000
2017-06-03 16:34:36.305395 EDT | StdReturn                   0
2017-06-03 16:34:36.305641 EDT | MaxReturn                1000
2017-06-03 16:34:36.305886 EDT | MinReturn                1000
2017-06-03 16:34:36.306117 EDT | AverageEsReturn            24
2017-06-03 16:34:36.306367 EDT | StdEsReturn                23.1476
2017-06-03 16:34:36.306596 EDT | MaxEsReturn                95
2017-06-03 16:34:36.306827 EDT | MinEsReturn                 3
2017-06-03 16:34:36.307053 EDT | AverageDiscountedReturn    99.9957
2017-06-03 16:34:36.307289 EDT | AverageQLoss                3.55141e-05
2017-06-03 16:34:36.307525 EDT | AveragePolicySurr          -0.0937044
2017-06-03 16:34:36.307752 EDT | AverageQ                    0.0892497
2017-06-03 16:34:36.307978 EDT | AverageAbsQ                 0.0895426
2017-06-03 16:34:36.308203 EDT | AverageY                    0.0892531
2017-06-03 16:34:36.308429 EDT | AverageAbsY                 0.0892579
2017-06-03 16:34:36.308685 EDT | AverageAbsQYDiff            0.00162545
2017-06-03 16:34:36.308913 EDT | AverageAction               0.0203014
2017-06-03 16:34:36.309139 EDT | PolicyRegParamNorm         63.4461
2017-06-03 16:34:36.309365 EDT | QFunRegParamNorm           27.2281
2017-06-03 16:34:36.309608 EDT | -----------------------  --------------
2017-06-03 16:34:36.310018 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #480 | Training started
2017-06-03 16:34:55.178177 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #480 | Training finished
2017-06-03 16:34:55.179155 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #480 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 16:34:55.179539 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #480 | Collecting samples for evaluation
2017-06-03 16:35:05.155807 EDT | -----------------------  --------------
2017-06-03 16:35:05.156662 EDT | Epoch                     480
2017-06-03 16:35:05.156920 EDT | Iteration                 480
2017-06-03 16:35:05.157162 EDT | AverageReturn            1000
2017-06-03 16:35:05.157400 EDT | StdReturn                   0
2017-06-03 16:35:05.157635 EDT | MaxReturn                1000
2017-06-03 16:35:05.157886 EDT | MinReturn                1000
2017-06-03 16:35:05.158123 EDT | AverageEsReturn            27.5135
2017-06-03 16:35:05.158361 EDT | StdEsReturn                27.6754
2017-06-03 16:35:05.158597 EDT | MaxEsReturn               147
2017-06-03 16:35:05.158831 EDT | MinEsReturn                 4
2017-06-03 16:35:05.159068 EDT | AverageDiscountedReturn    99.9957
2017-06-03 16:35:05.159300 EDT | AverageQLoss                2.85126e-05
2017-06-03 16:35:05.159531 EDT | AveragePolicySurr          -0.0936718
2017-06-03 16:35:05.159764 EDT | AverageQ                    0.0891927
2017-06-03 16:35:05.159996 EDT | AverageAbsQ                 0.0894145
2017-06-03 16:35:05.160229 EDT | AverageY                    0.0891914
2017-06-03 16:35:05.160490 EDT | AverageAbsY                 0.0892052
2017-06-03 16:35:05.160723 EDT | AverageAbsQYDiff            0.00151822
2017-06-03 16:35:05.160955 EDT | AverageAction               0.0922166
2017-06-03 16:35:05.161186 EDT | PolicyRegParamNorm         63.4475
2017-06-03 16:35:05.161416 EDT | QFunRegParamNorm           27.2474
2017-06-03 16:35:05.161657 EDT | -----------------------  --------------
2017-06-03 16:35:05.162079 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #481 | Training started
2017-06-03 16:35:24.499466 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #481 | Training finished
2017-06-03 16:35:24.500449 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #481 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 16:35:24.500768 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #481 | Collecting samples for evaluation
2017-06-03 16:35:34.222950 EDT | -----------------------  --------------
2017-06-03 16:35:34.223803 EDT | Epoch                     481
2017-06-03 16:35:34.224076 EDT | Iteration                 481
2017-06-03 16:35:34.224339 EDT | AverageReturn            1000
2017-06-03 16:35:34.224586 EDT | StdReturn                   0
2017-06-03 16:35:34.224831 EDT | MaxReturn                1000
2017-06-03 16:35:34.225079 EDT | MinReturn                1000
2017-06-03 16:35:34.225339 EDT | AverageEsReturn            19.6078
2017-06-03 16:35:34.225582 EDT | StdEsReturn                16.433
2017-06-03 16:35:34.225841 EDT | MaxEsReturn                68
2017-06-03 16:35:34.226084 EDT | MinEsReturn                 3
2017-06-03 16:35:34.226326 EDT | AverageDiscountedReturn    99.9957
2017-06-03 16:35:34.226571 EDT | AverageQLoss                3.20755e-05
2017-06-03 16:35:34.226813 EDT | AveragePolicySurr          -0.0936817
2017-06-03 16:35:34.227061 EDT | AverageQ                    0.0893196
2017-06-03 16:35:34.227302 EDT | AverageAbsQ                 0.0895996
2017-06-03 16:35:34.227543 EDT | AverageY                    0.0893209
2017-06-03 16:35:34.227784 EDT | AverageAbsY                 0.0893437
2017-06-03 16:35:34.228026 EDT | AverageAbsQYDiff            0.00155251
2017-06-03 16:35:34.228268 EDT | AverageAction               0.00729748
2017-06-03 16:35:34.228508 EDT | PolicyRegParamNorm         63.4751
2017-06-03 16:35:34.228748 EDT | QFunRegParamNorm           27.2612
2017-06-03 16:35:34.228989 EDT | -----------------------  --------------
2017-06-03 16:35:34.229483 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #482 | Training started
2017-06-03 16:35:52.120130 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #482 | Training finished
2017-06-03 16:35:52.120980 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #482 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 16:35:52.121250 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #482 | Collecting samples for evaluation
2017-06-03 16:36:01.438105 EDT | -----------------------  -------------
2017-06-03 16:36:01.438560 EDT | Epoch                     482
2017-06-03 16:36:01.438827 EDT | Iteration                 482
2017-06-03 16:36:01.439140 EDT | AverageReturn            1000
2017-06-03 16:36:01.439457 EDT | StdReturn                   0
2017-06-03 16:36:01.439721 EDT | MaxReturn                1000
2017-06-03 16:36:01.440056 EDT | MinReturn                1000
2017-06-03 16:36:01.440389 EDT | AverageEsReturn            18.9434
2017-06-03 16:36:01.440717 EDT | StdEsReturn                14.3006
2017-06-03 16:36:01.441031 EDT | MaxEsReturn                53
2017-06-03 16:36:01.441311 EDT | MinEsReturn                 3
2017-06-03 16:36:01.441561 EDT | AverageDiscountedReturn    99.9957
2017-06-03 16:36:01.441853 EDT | AverageQLoss                3.363e-05
2017-06-03 16:36:01.442177 EDT | AveragePolicySurr          -0.0935863
2017-06-03 16:36:01.442518 EDT | AverageQ                    0.0891909
2017-06-03 16:36:01.442915 EDT | AverageAbsQ                 0.0894675
2017-06-03 16:36:01.443309 EDT | AverageY                    0.0891889
2017-06-03 16:36:01.443711 EDT | AverageAbsY                 0.0892004
2017-06-03 16:36:01.444037 EDT | AverageAbsQYDiff            0.00167154
2017-06-03 16:36:01.444432 EDT | AverageAction               0.00621535
2017-06-03 16:36:01.444780 EDT | PolicyRegParamNorm         63.4561
2017-06-03 16:36:01.445122 EDT | QFunRegParamNorm           27.2508
2017-06-03 16:36:01.445534 EDT | -----------------------  -------------
2017-06-03 16:36:01.446026 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #483 | Training started
2017-06-03 16:36:20.308990 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #483 | Training finished
2017-06-03 16:36:20.309918 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #483 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 16:36:20.310190 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #483 | Collecting samples for evaluation
2017-06-03 16:36:29.526682 EDT | -----------------------  -------------
2017-06-03 16:36:29.528564 EDT | Epoch                     483
2017-06-03 16:36:29.528864 EDT | Iteration                 483
2017-06-03 16:36:29.529109 EDT | AverageReturn            1000
2017-06-03 16:36:29.529345 EDT | StdReturn                   0
2017-06-03 16:36:29.529589 EDT | MaxReturn                1000
2017-06-03 16:36:29.529887 EDT | MinReturn                1000
2017-06-03 16:36:29.530172 EDT | AverageEsReturn            24.1463
2017-06-03 16:36:29.530420 EDT | StdEsReturn                27.0902
2017-06-03 16:36:29.530682 EDT | MaxEsReturn               132
2017-06-03 16:36:29.530950 EDT | MinEsReturn                 2
2017-06-03 16:36:29.531211 EDT | AverageDiscountedReturn    99.9957
2017-06-03 16:36:29.531490 EDT | AverageQLoss                2.8247e-05
2017-06-03 16:36:29.531731 EDT | AveragePolicySurr          -0.0935011
2017-06-03 16:36:29.531965 EDT | AverageQ                    0.0893917
2017-06-03 16:36:29.532214 EDT | AverageAbsQ                 0.0896284
2017-06-03 16:36:29.532448 EDT | AverageY                    0.0893886
2017-06-03 16:36:29.532681 EDT | AverageAbsY                 0.0893964
2017-06-03 16:36:29.532940 EDT | AverageAbsQYDiff            0.00147863
2017-06-03 16:36:29.533179 EDT | AverageAction               0.0564635
2017-06-03 16:36:29.533412 EDT | PolicyRegParamNorm         63.4661
2017-06-03 16:36:29.533646 EDT | QFunRegParamNorm           27.2523
2017-06-03 16:36:29.533914 EDT | -----------------------  -------------
2017-06-03 16:36:29.534392 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #484 | Training started
2017-06-03 16:36:49.614821 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #484 | Training finished
2017-06-03 16:36:49.616148 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #484 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 16:36:49.616430 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #484 | Collecting samples for evaluation
2017-06-03 16:37:00.879462 EDT | -----------------------  --------------
2017-06-03 16:37:00.880694 EDT | Epoch                     484
2017-06-03 16:37:00.880960 EDT | Iteration                 484
2017-06-03 16:37:00.881202 EDT | AverageReturn            1000
2017-06-03 16:37:00.881438 EDT | StdReturn                   0
2017-06-03 16:37:00.881673 EDT | MaxReturn                1000
2017-06-03 16:37:00.881990 EDT | MinReturn                1000
2017-06-03 16:37:00.882228 EDT | AverageEsReturn            25.3947
2017-06-03 16:37:00.882463 EDT | StdEsReturn                18.5196
2017-06-03 16:37:00.882697 EDT | MaxEsReturn                71
2017-06-03 16:37:00.882929 EDT | MinEsReturn                 4
2017-06-03 16:37:00.883157 EDT | AverageDiscountedReturn    99.9957
2017-06-03 16:37:00.883384 EDT | AverageQLoss                3.25343e-05
2017-06-03 16:37:00.883615 EDT | AveragePolicySurr          -0.0936062
2017-06-03 16:37:00.883844 EDT | AverageQ                    0.0891831
2017-06-03 16:37:00.884071 EDT | AverageAbsQ                 0.089471
2017-06-03 16:37:00.884297 EDT | AverageY                    0.0891901
2017-06-03 16:37:00.884525 EDT | AverageAbsY                 0.089201
2017-06-03 16:37:00.884756 EDT | AverageAbsQYDiff            0.00169495
2017-06-03 16:37:00.884986 EDT | AverageAction               0.044837
2017-06-03 16:37:00.885213 EDT | PolicyRegParamNorm         63.4553
2017-06-03 16:37:00.885439 EDT | QFunRegParamNorm           27.258
2017-06-03 16:37:00.885668 EDT | -----------------------  --------------
2017-06-03 16:37:00.886059 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #485 | Training started
2017-06-03 16:37:19.460145 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #485 | Training finished
2017-06-03 16:37:19.461630 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #485 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 16:37:19.461941 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #485 | Collecting samples for evaluation
2017-06-03 16:37:28.751306 EDT | -----------------------  --------------
2017-06-03 16:37:28.752197 EDT | Epoch                     485
2017-06-03 16:37:28.752458 EDT | Iteration                 485
2017-06-03 16:37:28.752697 EDT | AverageReturn            1000
2017-06-03 16:37:28.752930 EDT | StdReturn                   0
2017-06-03 16:37:28.753161 EDT | MaxReturn                1000
2017-06-03 16:37:28.753410 EDT | MinReturn                1000
2017-06-03 16:37:28.753642 EDT | AverageEsReturn            31.3448
2017-06-03 16:37:28.753907 EDT | StdEsReturn                23.3508
2017-06-03 16:37:28.754142 EDT | MaxEsReturn                89
2017-06-03 16:37:28.754375 EDT | MinEsReturn                 5
2017-06-03 16:37:28.754607 EDT | AverageDiscountedReturn    99.9957
2017-06-03 16:37:28.754849 EDT | AverageQLoss                3.18668e-05
2017-06-03 16:37:28.755085 EDT | AveragePolicySurr          -0.0933464
2017-06-03 16:37:28.755321 EDT | AverageQ                    0.0891243
2017-06-03 16:37:28.755573 EDT | AverageAbsQ                 0.089374
2017-06-03 16:37:28.755801 EDT | AverageY                    0.0891204
2017-06-03 16:37:28.756032 EDT | AverageAbsY                 0.0891363
2017-06-03 16:37:28.756269 EDT | AverageAbsQYDiff            0.00152098
2017-06-03 16:37:28.756503 EDT | AverageAction               0.158465
2017-06-03 16:37:28.756733 EDT | PolicyRegParamNorm         63.4534
2017-06-03 16:37:28.756967 EDT | QFunRegParamNorm           27.2669
2017-06-03 16:37:28.757197 EDT | -----------------------  --------------
2017-06-03 16:37:28.757600 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #486 | Training started
2017-06-03 16:37:46.811745 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #486 | Training finished
2017-06-03 16:37:46.812674 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #486 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 16:37:46.812988 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #486 | Collecting samples for evaluation
2017-06-03 16:37:56.861589 EDT | -----------------------  --------------
2017-06-03 16:37:56.863649 EDT | Epoch                     486
2017-06-03 16:37:56.863923 EDT | Iteration                 486
2017-06-03 16:37:56.864162 EDT | AverageReturn            1000
2017-06-03 16:37:56.864421 EDT | StdReturn                   0
2017-06-03 16:37:56.864651 EDT | MaxReturn                1000
2017-06-03 16:37:56.864881 EDT | MinReturn                1000
2017-06-03 16:37:56.865109 EDT | AverageEsReturn            29.1316
2017-06-03 16:37:56.865346 EDT | StdEsReturn                26.5044
2017-06-03 16:37:56.865581 EDT | MaxEsReturn               138
2017-06-03 16:37:56.866187 EDT | MinEsReturn                 4
2017-06-03 16:37:56.866504 EDT | AverageDiscountedReturn    99.9957
2017-06-03 16:37:56.866820 EDT | AverageQLoss                3.01556e-05
2017-06-03 16:37:56.867136 EDT | AveragePolicySurr          -0.0933473
2017-06-03 16:37:56.867460 EDT | AverageQ                    0.0889409
2017-06-03 16:37:56.867771 EDT | AverageAbsQ                 0.0891781
2017-06-03 16:37:56.868083 EDT | AverageY                    0.0889386
2017-06-03 16:37:56.868396 EDT | AverageAbsY                 0.0889455
2017-06-03 16:37:56.868706 EDT | AverageAbsQYDiff            0.00148422
2017-06-03 16:37:56.869015 EDT | AverageAction               0.0762374
2017-06-03 16:37:56.869330 EDT | PolicyRegParamNorm         63.4545
2017-06-03 16:37:56.869642 EDT | QFunRegParamNorm           27.2853
2017-06-03 16:37:56.869979 EDT | -----------------------  --------------
2017-06-03 16:37:56.870469 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #487 | Training started
2017-06-03 16:38:16.196310 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #487 | Training finished
2017-06-03 16:38:16.197159 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #487 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 16:38:16.197418 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #487 | Collecting samples for evaluation
2017-06-03 16:38:25.527712 EDT | -----------------------  --------------
2017-06-03 16:38:25.528902 EDT | Epoch                     487
2017-06-03 16:38:25.529172 EDT | Iteration                 487
2017-06-03 16:38:25.529414 EDT | AverageReturn            1000
2017-06-03 16:38:25.529649 EDT | StdReturn                   0
2017-06-03 16:38:25.529899 EDT | MaxReturn                1000
2017-06-03 16:38:25.530139 EDT | MinReturn                1000
2017-06-03 16:38:25.530369 EDT | AverageEsReturn            28.5278
2017-06-03 16:38:25.530601 EDT | StdEsReturn                21.2857
2017-06-03 16:38:25.530830 EDT | MaxEsReturn                72
2017-06-03 16:38:25.531057 EDT | MinEsReturn                 4
2017-06-03 16:38:25.531284 EDT | AverageDiscountedReturn    99.9957
2017-06-03 16:38:25.531511 EDT | AverageQLoss                3.70253e-05
2017-06-03 16:38:25.531737 EDT | AveragePolicySurr          -0.0932971
2017-06-03 16:38:25.531963 EDT | AverageQ                    0.0888412
2017-06-03 16:38:25.532189 EDT | AverageAbsQ                 0.089093
2017-06-03 16:38:25.532420 EDT | AverageY                    0.0888437
2017-06-03 16:38:25.532646 EDT | AverageAbsY                 0.0888522
2017-06-03 16:38:25.532872 EDT | AverageAbsQYDiff            0.00163736
2017-06-03 16:38:25.533098 EDT | AverageAction               0.0691215
2017-06-03 16:38:25.533324 EDT | PolicyRegParamNorm         63.4983
2017-06-03 16:38:25.533550 EDT | QFunRegParamNorm           27.3019
2017-06-03 16:38:25.533790 EDT | -----------------------  --------------
2017-06-03 16:38:25.534160 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #488 | Training started
2017-06-03 16:38:43.983997 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #488 | Training finished
2017-06-03 16:38:43.984751 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #488 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 16:38:43.984929 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #488 | Collecting samples for evaluation
2017-06-03 16:38:52.942549 EDT | -----------------------  --------------
2017-06-03 16:38:52.943402 EDT | Epoch                     488
2017-06-03 16:38:52.943680 EDT | Iteration                 488
2017-06-03 16:38:52.943935 EDT | AverageReturn            1000
2017-06-03 16:38:52.944309 EDT | StdReturn                   0
2017-06-03 16:38:52.944639 EDT | MaxReturn                1000
2017-06-03 16:38:52.944964 EDT | MinReturn                1000
2017-06-03 16:38:52.945287 EDT | AverageEsReturn            26.3158
2017-06-03 16:38:52.945609 EDT | StdEsReturn                27.4333
2017-06-03 16:38:52.945945 EDT | MaxEsReturn               141
2017-06-03 16:38:52.946271 EDT | MinEsReturn                 3
2017-06-03 16:38:52.946589 EDT | AverageDiscountedReturn    99.9957
2017-06-03 16:38:52.946913 EDT | AverageQLoss                2.68353e-05
2017-06-03 16:38:52.947257 EDT | AveragePolicySurr          -0.0930876
2017-06-03 16:38:52.947575 EDT | AverageQ                    0.0887524
2017-06-03 16:38:52.947889 EDT | AverageAbsQ                 0.0889415
2017-06-03 16:38:52.948214 EDT | AverageY                    0.0887523
2017-06-03 16:38:52.948533 EDT | AverageAbsY                 0.0887638
2017-06-03 16:38:52.948880 EDT | AverageAbsQYDiff            0.00137461
2017-06-03 16:38:52.949204 EDT | AverageAction               0.0845753
2017-06-03 16:38:52.949521 EDT | PolicyRegParamNorm         63.5604
2017-06-03 16:38:52.949860 EDT | QFunRegParamNorm           27.3077
2017-06-03 16:38:52.950173 EDT | -----------------------  --------------
2017-06-03 16:38:52.950702 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #489 | Training started
2017-06-03 16:39:10.703819 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #489 | Training finished
2017-06-03 16:39:10.704823 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #489 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 16:39:10.705264 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #489 | Collecting samples for evaluation
2017-06-03 16:39:20.982208 EDT | -----------------------  --------------
2017-06-03 16:39:20.983782 EDT | Epoch                     489
2017-06-03 16:39:20.984072 EDT | Iteration                 489
2017-06-03 16:39:20.984388 EDT | AverageReturn            1000
2017-06-03 16:39:20.984721 EDT | StdReturn                   0
2017-06-03 16:39:20.984978 EDT | MaxReturn                1000
2017-06-03 16:39:20.985232 EDT | MinReturn                1000
2017-06-03 16:39:20.985564 EDT | AverageEsReturn            25.7105
2017-06-03 16:39:20.985880 EDT | StdEsReturn                19.1214
2017-06-03 16:39:20.986126 EDT | MaxEsReturn                69
2017-06-03 16:39:20.986455 EDT | MinEsReturn                 3
2017-06-03 16:39:20.986766 EDT | AverageDiscountedReturn    99.9957
2017-06-03 16:39:20.987007 EDT | AverageQLoss                3.56272e-05
2017-06-03 16:39:20.987312 EDT | AveragePolicySurr          -0.093222
2017-06-03 16:39:20.987633 EDT | AverageQ                    0.0886964
2017-06-03 16:39:20.987882 EDT | AverageAbsQ                 0.0889783
2017-06-03 16:39:20.988166 EDT | AverageY                    0.0886928
2017-06-03 16:39:20.988498 EDT | AverageAbsY                 0.0887097
2017-06-03 16:39:20.988772 EDT | AverageAbsQYDiff            0.00166294
2017-06-03 16:39:20.989037 EDT | AverageAction               0.030275
2017-06-03 16:39:20.989372 EDT | PolicyRegParamNorm         63.6286
2017-06-03 16:39:20.989663 EDT | QFunRegParamNorm           27.3166
2017-06-03 16:39:20.989923 EDT | -----------------------  --------------
2017-06-03 16:39:20.990384 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #490 | Training started
2017-06-03 16:39:39.405385 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #490 | Training finished
2017-06-03 16:39:39.406231 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #490 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 16:39:39.406641 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #490 | Collecting samples for evaluation
2017-06-03 16:39:50.676209 EDT | -----------------------  --------------
2017-06-03 16:39:50.677363 EDT | Epoch                     490
2017-06-03 16:39:50.677768 EDT | Iteration                 490
2017-06-03 16:39:50.678127 EDT | AverageReturn            1000
2017-06-03 16:39:50.678457 EDT | StdReturn                   0
2017-06-03 16:39:50.678815 EDT | MaxReturn                1000
2017-06-03 16:39:50.679168 EDT | MinReturn                1000
2017-06-03 16:39:50.679495 EDT | AverageEsReturn            22.3023
2017-06-03 16:39:50.679848 EDT | StdEsReturn                16.4126
2017-06-03 16:39:50.680176 EDT | MaxEsReturn                82
2017-06-03 16:39:50.680515 EDT | MinEsReturn                 3
2017-06-03 16:39:50.680868 EDT | AverageDiscountedReturn    99.9957
2017-06-03 16:39:50.681177 EDT | AverageQLoss                2.78448e-05
2017-06-03 16:39:50.681534 EDT | AveragePolicySurr          -0.0931961
2017-06-03 16:39:50.681883 EDT | AverageQ                    0.0890677
2017-06-03 16:39:50.682206 EDT | AverageAbsQ                 0.0892979
2017-06-03 16:39:50.682550 EDT | AverageY                    0.0890742
2017-06-03 16:39:50.682864 EDT | AverageAbsY                 0.0890921
2017-06-03 16:39:50.683269 EDT | AverageAbsQYDiff            0.00145839
2017-06-03 16:39:50.683858 EDT | AverageAction               0.0678244
2017-06-03 16:39:50.684544 EDT | PolicyRegParamNorm         63.6956
2017-06-03 16:39:50.685280 EDT | QFunRegParamNorm           27.3165
2017-06-03 16:39:50.685974 EDT | -----------------------  --------------
2017-06-03 16:39:50.686811 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #491 | Training started
2017-06-03 16:40:08.483699 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #491 | Training finished
2017-06-03 16:40:08.484024 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #491 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 16:40:08.484270 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #491 | Collecting samples for evaluation
2017-06-03 16:40:18.053606 EDT | -----------------------  --------------
2017-06-03 16:40:18.054601 EDT | Epoch                     491
2017-06-03 16:40:18.055374 EDT | Iteration                 491
2017-06-03 16:40:18.055731 EDT | AverageReturn            1000
2017-06-03 16:40:18.056054 EDT | StdReturn                   0
2017-06-03 16:40:18.057045 EDT | MaxReturn                1000
2017-06-03 16:40:18.058057 EDT | MinReturn                1000
2017-06-03 16:40:18.060033 EDT | AverageEsReturn            25.875
2017-06-03 16:40:18.060453 EDT | StdEsReturn                16.8496
2017-06-03 16:40:18.060730 EDT | MaxEsReturn                68
2017-06-03 16:40:18.061005 EDT | MinEsReturn                 5
2017-06-03 16:40:18.061257 EDT | AverageDiscountedReturn    99.9957
2017-06-03 16:40:18.061505 EDT | AverageQLoss                3.12804e-05
2017-06-03 16:40:18.061766 EDT | AveragePolicySurr          -0.0931821
2017-06-03 16:40:18.062055 EDT | AverageQ                    0.0887958
2017-06-03 16:40:18.062300 EDT | AverageAbsQ                 0.089048
2017-06-03 16:40:18.062542 EDT | AverageY                    0.0887924
2017-06-03 16:40:18.062784 EDT | AverageAbsY                 0.0888055
2017-06-03 16:40:18.063035 EDT | AverageAbsQYDiff            0.00161898
2017-06-03 16:40:18.063285 EDT | AverageAction               0.103903
2017-06-03 16:40:18.063525 EDT | PolicyRegParamNorm         63.7655
2017-06-03 16:40:18.063765 EDT | QFunRegParamNorm           27.3255
2017-06-03 16:40:18.064009 EDT | -----------------------  --------------
2017-06-03 16:40:18.064422 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #492 | Training started
2017-06-03 16:40:36.055939 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #492 | Training finished
2017-06-03 16:40:36.056962 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #492 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 16:40:36.057378 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #492 | Collecting samples for evaluation
2017-06-03 16:40:44.802242 EDT | -----------------------  --------------
2017-06-03 16:40:44.803237 EDT | Epoch                     492
2017-06-03 16:40:44.803587 EDT | Iteration                 492
2017-06-03 16:40:44.803911 EDT | AverageReturn            1000
2017-06-03 16:40:44.804237 EDT | StdReturn                   0
2017-06-03 16:40:44.804550 EDT | MaxReturn                1000
2017-06-03 16:40:44.804863 EDT | MinReturn                1000
2017-06-03 16:40:44.805176 EDT | AverageEsReturn            25.6053
2017-06-03 16:40:44.805495 EDT | StdEsReturn                16.2522
2017-06-03 16:40:44.805844 EDT | MaxEsReturn                62
2017-06-03 16:40:44.806152 EDT | MinEsReturn                 3
2017-06-03 16:40:44.806463 EDT | AverageDiscountedReturn    99.9957
2017-06-03 16:40:44.806779 EDT | AverageQLoss                3.01439e-05
2017-06-03 16:40:44.807087 EDT | AveragePolicySurr          -0.09305
2017-06-03 16:40:44.807397 EDT | AverageQ                    0.0889575
2017-06-03 16:40:44.807703 EDT | AverageAbsQ                 0.0892359
2017-06-03 16:40:44.808009 EDT | AverageY                    0.0889589
2017-06-03 16:40:44.808314 EDT | AverageAbsY                 0.0889769
2017-06-03 16:40:44.808625 EDT | AverageAbsQYDiff            0.00153095
2017-06-03 16:40:44.808929 EDT | AverageAction               0.0444957
2017-06-03 16:40:44.809233 EDT | PolicyRegParamNorm         63.8084
2017-06-03 16:40:44.809536 EDT | QFunRegParamNorm           27.3441
2017-06-03 16:40:44.809850 EDT | -----------------------  --------------
2017-06-03 16:40:44.810269 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #493 | Training started
2017-06-03 16:41:03.405579 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #493 | Training finished
2017-06-03 16:41:03.406457 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #493 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 16:41:03.406723 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #493 | Collecting samples for evaluation
2017-06-03 16:41:12.677626 EDT | -----------------------  --------------
2017-06-03 16:41:12.678702 EDT | Epoch                     493
2017-06-03 16:41:12.679085 EDT | Iteration                 493
2017-06-03 16:41:12.679416 EDT | AverageReturn            1000
2017-06-03 16:41:12.679737 EDT | StdReturn                   0
2017-06-03 16:41:12.680062 EDT | MaxReturn                1000
2017-06-03 16:41:12.680377 EDT | MinReturn                1000
2017-06-03 16:41:12.680691 EDT | AverageEsReturn            30.1143
2017-06-03 16:41:12.681010 EDT | StdEsReturn                21.9659
2017-06-03 16:41:12.681321 EDT | MaxEsReturn                86
2017-06-03 16:41:12.681629 EDT | MinEsReturn                 4
2017-06-03 16:41:12.681949 EDT | AverageDiscountedReturn    99.9957
2017-06-03 16:41:12.682259 EDT | AverageQLoss                3.03783e-05
2017-06-03 16:41:12.682834 EDT | AveragePolicySurr          -0.0931299
2017-06-03 16:41:12.683428 EDT | AverageQ                    0.0889114
2017-06-03 16:41:12.684021 EDT | AverageAbsQ                 0.0891192
2017-06-03 16:41:12.684601 EDT | AverageY                    0.0889088
2017-06-03 16:41:12.685185 EDT | AverageAbsY                 0.0889297
2017-06-03 16:41:12.685768 EDT | AverageAbsQYDiff            0.00146525
2017-06-03 16:41:12.686338 EDT | AverageAction               0.0419647
2017-06-03 16:41:12.686916 EDT | PolicyRegParamNorm         63.8501
2017-06-03 16:41:12.687482 EDT | QFunRegParamNorm           27.3695
2017-06-03 16:41:12.688066 EDT | -----------------------  --------------
2017-06-03 16:41:12.688836 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #494 | Training started
2017-06-03 16:41:30.390700 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #494 | Training finished
2017-06-03 16:41:30.391594 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #494 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 16:41:30.392027 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #494 | Collecting samples for evaluation
2017-06-03 16:41:39.608937 EDT | -----------------------  --------------
2017-06-03 16:41:39.609383 EDT | Epoch                     494
2017-06-03 16:41:39.609644 EDT | Iteration                 494
2017-06-03 16:41:39.610405 EDT | AverageReturn            1000
2017-06-03 16:41:39.610648 EDT | StdReturn                   0
2017-06-03 16:41:39.610886 EDT | MaxReturn                1000
2017-06-03 16:41:39.611121 EDT | MinReturn                1000
2017-06-03 16:41:39.611556 EDT | AverageEsReturn            31.25
2017-06-03 16:41:39.611792 EDT | StdEsReturn                25.9037
2017-06-03 16:41:39.612046 EDT | MaxEsReturn               122
2017-06-03 16:41:39.612295 EDT | MinEsReturn                 4
2017-06-03 16:41:39.612556 EDT | AverageDiscountedReturn    99.9957
2017-06-03 16:41:39.612792 EDT | AverageQLoss                3.32788e-05
2017-06-03 16:41:39.613025 EDT | AveragePolicySurr          -0.092989
2017-06-03 16:41:39.613257 EDT | AverageQ                    0.0886866
2017-06-03 16:41:39.613529 EDT | AverageAbsQ                 0.0889527
2017-06-03 16:41:39.614512 EDT | AverageY                    0.0886875
2017-06-03 16:41:39.614763 EDT | AverageAbsY                 0.088708
2017-06-03 16:41:39.615001 EDT | AverageAbsQYDiff            0.00160055
2017-06-03 16:41:39.615265 EDT | AverageAction               0.0372347
2017-06-03 16:41:39.615532 EDT | PolicyRegParamNorm         63.96
2017-06-03 16:41:39.615770 EDT | QFunRegParamNorm           27.3477
2017-06-03 16:41:39.616005 EDT | -----------------------  --------------
2017-06-03 16:41:39.616378 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #495 | Training started
2017-06-03 16:41:57.995893 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #495 | Training finished
2017-06-03 16:41:57.996832 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #495 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 16:41:57.997176 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #495 | Collecting samples for evaluation
2017-06-03 16:42:07.498739 EDT | -----------------------  --------------
2017-06-03 16:42:07.499119 EDT | Epoch                     495
2017-06-03 16:42:07.499378 EDT | Iteration                 495
2017-06-03 16:42:07.499621 EDT | AverageReturn            1000
2017-06-03 16:42:07.499858 EDT | StdReturn                   0
2017-06-03 16:42:07.500095 EDT | MaxReturn                1000
2017-06-03 16:42:07.500334 EDT | MinReturn                1000
2017-06-03 16:42:07.500574 EDT | AverageEsReturn            26.7297
2017-06-03 16:42:07.500807 EDT | StdEsReturn                24.3384
2017-06-03 16:42:07.501036 EDT | MaxEsReturn               109
2017-06-03 16:42:07.501282 EDT | MinEsReturn                 5
2017-06-03 16:42:07.501518 EDT | AverageDiscountedReturn    99.9957
2017-06-03 16:42:07.501829 EDT | AverageQLoss                2.99125e-05
2017-06-03 16:42:07.502063 EDT | AveragePolicySurr          -0.0930735
2017-06-03 16:42:07.502293 EDT | AverageQ                    0.0885528
2017-06-03 16:42:07.502529 EDT | AverageAbsQ                 0.0888268
2017-06-03 16:42:07.502765 EDT | AverageY                    0.0885565
2017-06-03 16:42:07.503005 EDT | AverageAbsY                 0.0885752
2017-06-03 16:42:07.503237 EDT | AverageAbsQYDiff            0.00155746
2017-06-03 16:42:07.503467 EDT | AverageAction               0.00216209
2017-06-03 16:42:07.503709 EDT | PolicyRegParamNorm         63.98
2017-06-03 16:42:07.503939 EDT | QFunRegParamNorm           27.3527
2017-06-03 16:42:07.504169 EDT | -----------------------  --------------
2017-06-03 16:42:07.504522 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #496 | Training started
2017-06-03 16:42:25.925272 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #496 | Training finished
2017-06-03 16:42:25.928385 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #496 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 16:42:25.928796 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #496 | Collecting samples for evaluation
2017-06-03 16:42:34.469599 EDT | -----------------------  --------------
2017-06-03 16:42:34.470845 EDT | Epoch                     496
2017-06-03 16:42:34.471113 EDT | Iteration                 496
2017-06-03 16:42:34.471348 EDT | AverageReturn            1000
2017-06-03 16:42:34.471582 EDT | StdReturn                   0
2017-06-03 16:42:34.471810 EDT | MaxReturn                1000
2017-06-03 16:42:34.472044 EDT | MinReturn                1000
2017-06-03 16:42:34.472268 EDT | AverageEsReturn            24.6341
2017-06-03 16:42:34.472492 EDT | StdEsReturn                22.3942
2017-06-03 16:42:34.472715 EDT | MaxEsReturn                90
2017-06-03 16:42:34.472939 EDT | MinEsReturn                 3
2017-06-03 16:42:34.473161 EDT | AverageDiscountedReturn    99.9957
2017-06-03 16:42:34.473384 EDT | AverageQLoss                2.78042e-05
2017-06-03 16:42:34.473605 EDT | AveragePolicySurr          -0.0930126
2017-06-03 16:42:34.473876 EDT | AverageQ                    0.0889543
2017-06-03 16:42:34.474115 EDT | AverageAbsQ                 0.089181
2017-06-03 16:42:34.474355 EDT | AverageY                    0.0889543
2017-06-03 16:42:34.474592 EDT | AverageAbsY                 0.088967
2017-06-03 16:42:34.474830 EDT | AverageAbsQYDiff            0.00142906
2017-06-03 16:42:34.475067 EDT | AverageAction               0.0222453
2017-06-03 16:42:34.475304 EDT | PolicyRegParamNorm         64.0798
2017-06-03 16:42:34.475540 EDT | QFunRegParamNorm           27.3729
2017-06-03 16:42:34.475777 EDT | -----------------------  --------------
2017-06-03 16:42:34.476161 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #497 | Training started
2017-06-03 16:42:53.781891 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #497 | Training finished
2017-06-03 16:42:53.782552 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #497 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 16:42:53.782855 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #497 | Collecting samples for evaluation
2017-06-03 16:43:03.551772 EDT | -----------------------  --------------
2017-06-03 16:43:03.552570 EDT | Epoch                     497
2017-06-03 16:43:03.552845 EDT | Iteration                 497
2017-06-03 16:43:03.553095 EDT | AverageReturn             950.273
2017-06-03 16:43:03.553337 EDT | StdReturn                 150.392
2017-06-03 16:43:03.553583 EDT | MaxReturn                1000
2017-06-03 16:43:03.553849 EDT | MinReturn                 475
2017-06-03 16:43:03.554087 EDT | AverageEsReturn            28.2647
2017-06-03 16:43:03.554324 EDT | StdEsReturn                23.3128
2017-06-03 16:43:03.554563 EDT | MaxEsReturn                96
2017-06-03 16:43:03.554798 EDT | MinEsReturn                 5
2017-06-03 16:43:03.555038 EDT | AverageDiscountedReturn    99.9192
2017-06-03 16:43:03.555273 EDT | AverageQLoss                3.37369e-05
2017-06-03 16:43:03.555512 EDT | AveragePolicySurr          -0.0929865
2017-06-03 16:43:03.555746 EDT | AverageQ                    0.0886969
2017-06-03 16:43:03.555983 EDT | AverageAbsQ                 0.0889826
2017-06-03 16:43:03.556216 EDT | AverageY                    0.0886944
2017-06-03 16:43:03.556448 EDT | AverageAbsY                 0.0887011
2017-06-03 16:43:03.556707 EDT | AverageAbsQYDiff            0.00165236
2017-06-03 16:43:03.556940 EDT | AverageAction               0.0130256
2017-06-03 16:43:03.557173 EDT | PolicyRegParamNorm         64.1215
2017-06-03 16:43:03.557410 EDT | QFunRegParamNorm           27.3732
2017-06-03 16:43:03.557643 EDT | -----------------------  --------------
2017-06-03 16:43:03.558087 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #498 | Training started
2017-06-03 16:43:21.970764 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #498 | Training finished
2017-06-03 16:43:21.972388 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #498 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 16:43:21.972699 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #498 | Collecting samples for evaluation
2017-06-03 16:43:31.623926 EDT | -----------------------  --------------
2017-06-03 16:43:31.624787 EDT | Epoch                     498
2017-06-03 16:43:31.625053 EDT | Iteration                 498
2017-06-03 16:43:31.625296 EDT | AverageReturn            1000
2017-06-03 16:43:31.625534 EDT | StdReturn                   0
2017-06-03 16:43:31.625784 EDT | MaxReturn                1000
2017-06-03 16:43:31.626033 EDT | MinReturn                1000
2017-06-03 16:43:31.626271 EDT | AverageEsReturn            27.3158
2017-06-03 16:43:31.626503 EDT | StdEsReturn                32.7825
2017-06-03 16:43:31.626731 EDT | MaxEsReturn               175
2017-06-03 16:43:31.626964 EDT | MinEsReturn                 4
2017-06-03 16:43:31.627195 EDT | AverageDiscountedReturn    99.9957
2017-06-03 16:43:31.627431 EDT | AverageQLoss                3.01274e-05
2017-06-03 16:43:31.627664 EDT | AveragePolicySurr          -0.0928471
2017-06-03 16:43:31.627896 EDT | AverageQ                    0.0885871
2017-06-03 16:43:31.628123 EDT | AverageAbsQ                 0.0887998
2017-06-03 16:43:31.628358 EDT | AverageY                    0.0885856
2017-06-03 16:43:31.628589 EDT | AverageAbsY                 0.088591
2017-06-03 16:43:31.628821 EDT | AverageAbsQYDiff            0.00146976
2017-06-03 16:43:31.629053 EDT | AverageAction               0.00894425
2017-06-03 16:43:31.629283 EDT | PolicyRegParamNorm         64.1586
2017-06-03 16:43:31.629516 EDT | QFunRegParamNorm           27.387
2017-06-03 16:43:31.629770 EDT | -----------------------  --------------
2017-06-03 16:43:31.630165 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #499 | Training started
2017-06-03 16:43:49.721872 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #499 | Training finished
2017-06-03 16:43:49.722737 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #499 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 16:43:49.723169 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #499 | Collecting samples for evaluation
2017-06-03 16:43:59.489832 EDT | -----------------------  --------------
2017-06-03 16:43:59.490723 EDT | Epoch                     499
2017-06-03 16:43:59.490970 EDT | Iteration                 499
2017-06-03 16:43:59.491196 EDT | AverageReturn            1000
2017-06-03 16:43:59.491437 EDT | StdReturn                   0
2017-06-03 16:43:59.491669 EDT | MaxReturn                1000
2017-06-03 16:43:59.491898 EDT | MinReturn                1000
2017-06-03 16:43:59.492126 EDT | AverageEsReturn            43.2609
2017-06-03 16:43:59.492343 EDT | StdEsReturn                32.9522
2017-06-03 16:43:59.492572 EDT | MaxEsReturn               105
2017-06-03 16:43:59.492791 EDT | MinEsReturn                 5
2017-06-03 16:43:59.493010 EDT | AverageDiscountedReturn    99.9957
2017-06-03 16:43:59.493224 EDT | AverageQLoss                2.89981e-05
2017-06-03 16:43:59.493492 EDT | AveragePolicySurr          -0.0928745
2017-06-03 16:43:59.493733 EDT | AverageQ                    0.0886275
2017-06-03 16:43:59.493966 EDT | AverageAbsQ                 0.0888846
2017-06-03 16:43:59.494190 EDT | AverageY                    0.0886278
2017-06-03 16:43:59.494457 EDT | AverageAbsY                 0.0886326
2017-06-03 16:43:59.494693 EDT | AverageAbsQYDiff            0.00157926
2017-06-03 16:43:59.494950 EDT | AverageAction               0.00686727
2017-06-03 16:43:59.495222 EDT | PolicyRegParamNorm         64.2265
2017-06-03 16:43:59.495456 EDT | QFunRegParamNorm           27.3949
2017-06-03 16:43:59.495702 EDT | -----------------------  --------------
2017-06-03 16:43:59.496254 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #500 | Training started
2017-06-03 16:44:18.918735 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #500 | Training finished
2017-06-03 16:44:18.919668 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #500 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 16:44:18.920108 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #500 | Collecting samples for evaluation
2017-06-03 16:44:28.431976 EDT | -----------------------  --------------
2017-06-03 16:44:28.432836 EDT | Epoch                     500
2017-06-03 16:44:28.433094 EDT | Iteration                 500
2017-06-03 16:44:28.433329 EDT | AverageReturn            1000
2017-06-03 16:44:28.433561 EDT | StdReturn                   0
2017-06-03 16:44:28.433811 EDT | MaxReturn                1000
2017-06-03 16:44:28.434041 EDT | MinReturn                1000
2017-06-03 16:44:28.434292 EDT | AverageEsReturn            30.303
2017-06-03 16:44:28.434520 EDT | StdEsReturn                25.5028
2017-06-03 16:44:28.434763 EDT | MaxEsReturn                98
2017-06-03 16:44:28.434991 EDT | MinEsReturn                 4
2017-06-03 16:44:28.435219 EDT | AverageDiscountedReturn    99.9957
2017-06-03 16:44:28.435447 EDT | AverageQLoss                3.12913e-05
2017-06-03 16:44:28.435674 EDT | AveragePolicySurr          -0.0925624
2017-06-03 16:44:28.435901 EDT | AverageQ                    0.0881674
2017-06-03 16:44:28.436141 EDT | AverageAbsQ                 0.0884139
2017-06-03 16:44:28.436369 EDT | AverageY                    0.0881666
2017-06-03 16:44:28.436596 EDT | AverageAbsY                 0.0881709
2017-06-03 16:44:28.436833 EDT | AverageAbsQYDiff            0.00157084
2017-06-03 16:44:28.437062 EDT | AverageAction               0.023215
2017-06-03 16:44:28.437289 EDT | PolicyRegParamNorm         64.2724
2017-06-03 16:44:28.437516 EDT | QFunRegParamNorm           27.404
2017-06-03 16:44:28.437764 EDT | -----------------------  --------------
2017-06-03 16:44:28.438161 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #501 | Training started
2017-06-03 16:44:46.410195 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #501 | Training finished
2017-06-03 16:44:46.411123 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #501 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 16:44:46.411487 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #501 | Collecting samples for evaluation
2017-06-03 16:44:56.012500 EDT | -----------------------  --------------
2017-06-03 16:44:56.013351 EDT | Epoch                     501
2017-06-03 16:44:56.013653 EDT | Iteration                 501
2017-06-03 16:44:56.013912 EDT | AverageReturn            1000
2017-06-03 16:44:56.014184 EDT | StdReturn                   0
2017-06-03 16:44:56.014462 EDT | MaxReturn                1000
2017-06-03 16:44:56.014709 EDT | MinReturn                1000
2017-06-03 16:44:56.014940 EDT | AverageEsReturn            29.2941
2017-06-03 16:44:56.015189 EDT | StdEsReturn                21.0958
2017-06-03 16:44:56.015451 EDT | MaxEsReturn               104
2017-06-03 16:44:56.015713 EDT | MinEsReturn                 8
2017-06-03 16:44:56.015945 EDT | AverageDiscountedReturn    99.9957
2017-06-03 16:44:56.016211 EDT | AverageQLoss                2.74491e-05
2017-06-03 16:44:56.016481 EDT | AveragePolicySurr          -0.0925297
2017-06-03 16:44:56.016730 EDT | AverageQ                    0.0880685
2017-06-03 16:44:56.016966 EDT | AverageAbsQ                 0.0882774
2017-06-03 16:44:56.017229 EDT | AverageY                    0.0880651
2017-06-03 16:44:56.017499 EDT | AverageAbsY                 0.0880705
2017-06-03 16:44:56.017739 EDT | AverageAbsQYDiff            0.00148029
2017-06-03 16:44:56.018000 EDT | AverageAction               0.0195998
2017-06-03 16:44:56.018277 EDT | PolicyRegParamNorm         64.2781
2017-06-03 16:44:56.018518 EDT | QFunRegParamNorm           27.403
2017-06-03 16:44:56.018768 EDT | -----------------------  --------------
2017-06-03 16:44:56.019154 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #502 | Training started
2017-06-03 16:45:14.925080 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #502 | Training finished
2017-06-03 16:45:14.926864 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #502 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 16:45:14.927231 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #502 | Collecting samples for evaluation
2017-06-03 16:45:24.106255 EDT | -----------------------  --------------
2017-06-03 16:45:24.107120 EDT | Epoch                     502
2017-06-03 16:45:24.107402 EDT | Iteration                 502
2017-06-03 16:45:24.107646 EDT | AverageReturn            1000
2017-06-03 16:45:24.107885 EDT | StdReturn                   0
2017-06-03 16:45:24.108121 EDT | MaxReturn                1000
2017-06-03 16:45:24.108378 EDT | MinReturn                1000
2017-06-03 16:45:24.108619 EDT | AverageEsReturn            30.1818
2017-06-03 16:45:24.108865 EDT | StdEsReturn                23.388
2017-06-03 16:45:24.109097 EDT | MaxEsReturn               107
2017-06-03 16:45:24.109330 EDT | MinEsReturn                 3
2017-06-03 16:45:24.109601 EDT | AverageDiscountedReturn    99.9957
2017-06-03 16:45:24.109851 EDT | AverageQLoss                2.74535e-05
2017-06-03 16:45:24.110091 EDT | AveragePolicySurr          -0.0926409
2017-06-03 16:45:24.110339 EDT | AverageQ                    0.0885502
2017-06-03 16:45:24.110713 EDT | AverageAbsQ                 0.0887754
2017-06-03 16:45:24.110947 EDT | AverageY                    0.0885551
2017-06-03 16:45:24.111180 EDT | AverageAbsY                 0.0885602
2017-06-03 16:45:24.111410 EDT | AverageAbsQYDiff            0.00142431
2017-06-03 16:45:24.112722 EDT | AverageAction               0.00223194
2017-06-03 16:45:24.112955 EDT | PolicyRegParamNorm         64.2945
2017-06-03 16:45:24.113190 EDT | QFunRegParamNorm           27.4333
2017-06-03 16:45:24.113452 EDT | -----------------------  --------------
2017-06-03 16:45:24.115011 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #503 | Training started
2017-06-03 16:45:42.493425 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #503 | Training finished
2017-06-03 16:45:42.494323 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #503 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 16:45:42.494683 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #503 | Collecting samples for evaluation
2017-06-03 16:45:52.266174 EDT | -----------------------  --------------
2017-06-03 16:45:52.266999 EDT | Epoch                     503
2017-06-03 16:45:52.267268 EDT | Iteration                 503
2017-06-03 16:45:52.267529 EDT | AverageReturn            1000
2017-06-03 16:45:52.267767 EDT | StdReturn                   0
2017-06-03 16:45:52.268001 EDT | MaxReturn                1000
2017-06-03 16:45:52.268233 EDT | MinReturn                1000
2017-06-03 16:45:52.268466 EDT | AverageEsReturn            28.9429
2017-06-03 16:45:52.268711 EDT | StdEsReturn                18.7494
2017-06-03 16:45:52.268956 EDT | MaxEsReturn                96
2017-06-03 16:45:52.269188 EDT | MinEsReturn                 4
2017-06-03 16:45:52.269417 EDT | AverageDiscountedReturn    99.9957
2017-06-03 16:45:52.269647 EDT | AverageQLoss                3.26687e-05
2017-06-03 16:45:52.269956 EDT | AveragePolicySurr          -0.0924893
2017-06-03 16:45:52.270196 EDT | AverageQ                    0.0881128
2017-06-03 16:45:52.270429 EDT | AverageAbsQ                 0.0883905
2017-06-03 16:45:52.270662 EDT | AverageY                    0.0881123
2017-06-03 16:45:52.270894 EDT | AverageAbsY                 0.088124
2017-06-03 16:45:52.271140 EDT | AverageAbsQYDiff            0.00163035
2017-06-03 16:45:52.271373 EDT | AverageAction               0.00739698
2017-06-03 16:45:52.271610 EDT | PolicyRegParamNorm         64.2808
2017-06-03 16:45:52.271840 EDT | QFunRegParamNorm           27.439
2017-06-03 16:45:52.272132 EDT | -----------------------  --------------
2017-06-03 16:45:52.272540 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #504 | Training started
2017-06-03 16:46:11.656291 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #504 | Training finished
2017-06-03 16:46:11.657266 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #504 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 16:46:11.657671 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #504 | Collecting samples for evaluation
2017-06-03 16:46:22.290379 EDT | -----------------------  --------------
2017-06-03 16:46:22.291358 EDT | Epoch                     504
2017-06-03 16:46:22.291609 EDT | Iteration                 504
2017-06-03 16:46:22.291836 EDT | AverageReturn            1000
2017-06-03 16:46:22.292055 EDT | StdReturn                   0
2017-06-03 16:46:22.292266 EDT | MaxReturn                1000
2017-06-03 16:46:22.292477 EDT | MinReturn                1000
2017-06-03 16:46:22.292686 EDT | AverageEsReturn            32.4
2017-06-03 16:46:22.292949 EDT | StdEsReturn                29.4817
2017-06-03 16:46:22.293169 EDT | MaxEsReturn               116
2017-06-03 16:46:22.293389 EDT | MinEsReturn                 4
2017-06-03 16:46:22.293607 EDT | AverageDiscountedReturn    99.9957
2017-06-03 16:46:22.294248 EDT | AverageQLoss                3.26764e-05
2017-06-03 16:46:22.294564 EDT | AveragePolicySurr          -0.0924811
2017-06-03 16:46:22.294870 EDT | AverageQ                    0.0882582
2017-06-03 16:46:22.295178 EDT | AverageAbsQ                 0.0885055
2017-06-03 16:46:22.295489 EDT | AverageY                    0.088256
2017-06-03 16:46:22.295790 EDT | AverageAbsY                 0.0882688
2017-06-03 16:46:22.296094 EDT | AverageAbsQYDiff            0.00155325
2017-06-03 16:46:22.296394 EDT | AverageAction               0.0547027
2017-06-03 16:46:22.296698 EDT | PolicyRegParamNorm         64.3126
2017-06-03 16:46:22.297011 EDT | QFunRegParamNorm           27.4532
2017-06-03 16:46:22.297310 EDT | -----------------------  --------------
2017-06-03 16:46:22.297778 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #505 | Training started
2017-06-03 16:46:41.666216 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #505 | Training finished
2017-06-03 16:46:41.667067 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #505 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 16:46:41.667464 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #505 | Collecting samples for evaluation
2017-06-03 16:46:50.973806 EDT | -----------------------  --------------
2017-06-03 16:46:50.974645 EDT | Epoch                     505
2017-06-03 16:46:50.974910 EDT | Iteration                 505
2017-06-03 16:46:50.975146 EDT | AverageReturn            1000
2017-06-03 16:46:50.975386 EDT | StdReturn                   0
2017-06-03 16:46:50.975630 EDT | MaxReturn                1000
2017-06-03 16:46:50.975860 EDT | MinReturn                1000
2017-06-03 16:46:50.976097 EDT | AverageEsReturn            31.0909
2017-06-03 16:46:50.976326 EDT | StdEsReturn                21.4651
2017-06-03 16:46:50.976552 EDT | MaxEsReturn                96
2017-06-03 16:46:50.976779 EDT | MinEsReturn                 5
2017-06-03 16:46:50.977008 EDT | AverageDiscountedReturn    99.9957
2017-06-03 16:46:50.977238 EDT | AverageQLoss                2.71203e-05
2017-06-03 16:46:50.977480 EDT | AveragePolicySurr          -0.0924652
2017-06-03 16:46:50.977720 EDT | AverageQ                    0.0881086
2017-06-03 16:46:50.977953 EDT | AverageAbsQ                 0.088372
2017-06-03 16:46:50.978182 EDT | AverageY                    0.0881105
2017-06-03 16:46:50.978404 EDT | AverageAbsY                 0.0881213
2017-06-03 16:46:50.978638 EDT | AverageAbsQYDiff            0.001466
2017-06-03 16:46:50.978863 EDT | AverageAction               0.0685044
2017-06-03 16:46:50.979087 EDT | PolicyRegParamNorm         64.3514
2017-06-03 16:46:50.979308 EDT | QFunRegParamNorm           27.4728
2017-06-03 16:46:50.979532 EDT | -----------------------  --------------
2017-06-03 16:46:50.979889 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #506 | Training started
2017-06-03 16:47:08.461243 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #506 | Training finished
2017-06-03 16:47:08.462546 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #506 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 16:47:08.462886 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #506 | Collecting samples for evaluation
2017-06-03 16:47:18.578475 EDT | -----------------------  --------------
2017-06-03 16:47:18.579324 EDT | Epoch                     506
2017-06-03 16:47:18.579585 EDT | Iteration                 506
2017-06-03 16:47:18.579822 EDT | AverageReturn            1000
2017-06-03 16:47:18.580052 EDT | StdReturn                   0
2017-06-03 16:47:18.580289 EDT | MaxReturn                1000
2017-06-03 16:47:18.580516 EDT | MinReturn                1000
2017-06-03 16:47:18.580749 EDT | AverageEsReturn            29.6061
2017-06-03 16:47:18.580977 EDT | StdEsReturn                22.7529
2017-06-03 16:47:18.581205 EDT | MaxEsReturn                93
2017-06-03 16:47:18.581489 EDT | MinEsReturn                 5
2017-06-03 16:47:18.581752 EDT | AverageDiscountedReturn    99.9957
2017-06-03 16:47:18.581995 EDT | AverageQLoss                3.78807e-05
2017-06-03 16:47:18.582239 EDT | AveragePolicySurr          -0.0924183
2017-06-03 16:47:18.582485 EDT | AverageQ                    0.0881367
2017-06-03 16:47:18.582736 EDT | AverageAbsQ                 0.088379
2017-06-03 16:47:18.582980 EDT | AverageY                    0.0881419
2017-06-03 16:47:18.583223 EDT | AverageAbsY                 0.0881467
2017-06-03 16:47:18.583464 EDT | AverageAbsQYDiff            0.00164563
2017-06-03 16:47:18.583704 EDT | AverageAction               0.0858398
2017-06-03 16:47:18.583944 EDT | PolicyRegParamNorm         64.405
2017-06-03 16:47:18.584189 EDT | QFunRegParamNorm           27.4729
2017-06-03 16:47:18.584428 EDT | -----------------------  --------------
2017-06-03 16:47:18.584938 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #507 | Training started
2017-06-03 16:47:37.449058 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #507 | Training finished
2017-06-03 16:47:37.449916 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #507 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 16:47:37.450323 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #507 | Collecting samples for evaluation
2017-06-03 16:47:47.037484 EDT | -----------------------  --------------
2017-06-03 16:47:47.038486 EDT | Epoch                     507
2017-06-03 16:47:47.038827 EDT | Iteration                 507
2017-06-03 16:47:47.039153 EDT | AverageReturn            1000
2017-06-03 16:47:47.039480 EDT | StdReturn                   0
2017-06-03 16:47:47.039795 EDT | MaxReturn                1000
2017-06-03 16:47:47.040108 EDT | MinReturn                1000
2017-06-03 16:47:47.040419 EDT | AverageEsReturn            31.5938
2017-06-03 16:47:47.040748 EDT | StdEsReturn                21.7728
2017-06-03 16:47:47.041060 EDT | MaxEsReturn                81
2017-06-03 16:47:47.041370 EDT | MinEsReturn                 4
2017-06-03 16:47:47.041679 EDT | AverageDiscountedReturn    99.9957
2017-06-03 16:47:47.042065 EDT | AverageQLoss                2.79665e-05
2017-06-03 16:47:47.042378 EDT | AveragePolicySurr          -0.092358
2017-06-03 16:47:47.042689 EDT | AverageQ                    0.088087
2017-06-03 16:47:47.043000 EDT | AverageAbsQ                 0.0883353
2017-06-03 16:47:47.043310 EDT | AverageY                    0.0880821
2017-06-03 16:47:47.043633 EDT | AverageAbsY                 0.0880883
2017-06-03 16:47:47.043950 EDT | AverageAbsQYDiff            0.00153504
2017-06-03 16:47:47.044272 EDT | AverageAction               0.0147959
2017-06-03 16:47:47.044580 EDT | PolicyRegParamNorm         64.4093
2017-06-03 16:47:47.044886 EDT | QFunRegParamNorm           27.4841
2017-06-03 16:47:47.045214 EDT | -----------------------  --------------
2017-06-03 16:47:47.045647 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #508 | Training started
2017-06-03 16:48:05.609404 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #508 | Training finished
2017-06-03 16:48:05.610730 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #508 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 16:48:05.611099 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #508 | Collecting samples for evaluation
2017-06-03 16:48:17.319045 EDT | -----------------------  -------------
2017-06-03 16:48:17.319952 EDT | Epoch                    508
2017-06-03 16:48:17.320295 EDT | Iteration                508
2017-06-03 16:48:17.320562 EDT | AverageReturn             63.1006
2017-06-03 16:48:17.320825 EDT | StdReturn                  0.655839
2017-06-03 16:48:17.321150 EDT | MaxReturn                 64
2017-06-03 16:48:17.321416 EDT | MinReturn                 61
2017-06-03 16:48:17.321704 EDT | AverageEsReturn           26.1538
2017-06-03 16:48:17.322003 EDT | StdEsReturn               21.6138
2017-06-03 16:48:17.322300 EDT | MaxEsReturn               84
2017-06-03 16:48:17.322576 EDT | MinEsReturn                4
2017-06-03 16:48:17.322897 EDT | AverageDiscountedReturn   46.962
2017-06-03 16:48:17.323218 EDT | AverageQLoss               2.84444e-05
2017-06-03 16:48:17.323473 EDT | AveragePolicySurr         -0.0924297
2017-06-03 16:48:17.323796 EDT | AverageQ                   0.08818
2017-06-03 16:48:17.324123 EDT | AverageAbsQ                0.0884399
2017-06-03 16:48:17.324387 EDT | AverageY                   0.0881764
2017-06-03 16:48:17.324692 EDT | AverageAbsY                0.0881874
2017-06-03 16:48:17.325013 EDT | AverageAbsQYDiff           0.00153327
2017-06-03 16:48:17.325268 EDT | AverageAction              0.329069
2017-06-03 16:48:17.325581 EDT | PolicyRegParamNorm        64.4184
2017-06-03 16:48:17.325933 EDT | QFunRegParamNorm          27.493
2017-06-03 16:48:17.326187 EDT | -----------------------  -------------
2017-06-03 16:48:17.326680 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #509 | Training started
2017-06-03 16:48:35.846318 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #509 | Training finished
2017-06-03 16:48:35.847294 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #509 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 16:48:35.847683 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #509 | Collecting samples for evaluation
2017-06-03 16:48:45.527314 EDT | -----------------------  --------------
2017-06-03 16:48:45.527834 EDT | Epoch                     509
2017-06-03 16:48:45.528170 EDT | Iteration                 509
2017-06-03 16:48:45.528488 EDT | AverageReturn            1000
2017-06-03 16:48:45.528796 EDT | StdReturn                   0
2017-06-03 16:48:45.529104 EDT | MaxReturn                1000
2017-06-03 16:48:45.529409 EDT | MinReturn                1000
2017-06-03 16:48:45.529720 EDT | AverageEsReturn            37.7308
2017-06-03 16:48:45.530031 EDT | StdEsReturn                25.5261
2017-06-03 16:48:45.530340 EDT | MaxEsReturn                90
2017-06-03 16:48:45.530643 EDT | MinEsReturn                 2
2017-06-03 16:48:45.530945 EDT | AverageDiscountedReturn    99.9957
2017-06-03 16:48:45.531246 EDT | AverageQLoss                3.12712e-05
2017-06-03 16:48:45.531550 EDT | AveragePolicySurr          -0.09236
2017-06-03 16:48:45.531851 EDT | AverageQ                    0.0880068
2017-06-03 16:48:45.532155 EDT | AverageAbsQ                 0.0882726
2017-06-03 16:48:45.532456 EDT | AverageY                    0.0880079
2017-06-03 16:48:45.532758 EDT | AverageAbsY                 0.0880285
2017-06-03 16:48:45.533060 EDT | AverageAbsQYDiff            0.00155149
2017-06-03 16:48:45.533361 EDT | AverageAction               0.0725156
2017-06-03 16:48:45.533662 EDT | PolicyRegParamNorm         64.4396
2017-06-03 16:48:45.533972 EDT | QFunRegParamNorm           27.4899
2017-06-03 16:48:45.534276 EDT | -----------------------  --------------
2017-06-03 16:48:45.534720 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #510 | Training started
2017-06-03 16:49:04.859985 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #510 | Training finished
2017-06-03 16:49:04.860824 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #510 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 16:49:04.861097 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #510 | Collecting samples for evaluation
2017-06-03 16:49:14.549666 EDT | -----------------------  --------------
2017-06-03 16:49:14.550112 EDT | Epoch                     510
2017-06-03 16:49:14.550367 EDT | Iteration                 510
2017-06-03 16:49:14.550610 EDT | AverageReturn            1000
2017-06-03 16:49:14.550847 EDT | StdReturn                   0
2017-06-03 16:49:14.551083 EDT | MaxReturn                1000
2017-06-03 16:49:14.551315 EDT | MinReturn                1000
2017-06-03 16:49:14.551546 EDT | AverageEsReturn            33.3
2017-06-03 16:49:14.551787 EDT | StdEsReturn                35.3838
2017-06-03 16:49:14.552017 EDT | MaxEsReturn               164
2017-06-03 16:49:14.552247 EDT | MinEsReturn                 3
2017-06-03 16:49:14.552478 EDT | AverageDiscountedReturn    99.9957
2017-06-03 16:49:14.552707 EDT | AverageQLoss                3.19882e-05
2017-06-03 16:49:14.552938 EDT | AveragePolicySurr          -0.0922155
2017-06-03 16:49:14.553166 EDT | AverageQ                    0.087957
2017-06-03 16:49:14.553393 EDT | AverageAbsQ                 0.0881923
2017-06-03 16:49:14.553621 EDT | AverageY                    0.0879554
2017-06-03 16:49:14.553880 EDT | AverageAbsY                 0.0879775
2017-06-03 16:49:14.554110 EDT | AverageAbsQYDiff            0.00156998
2017-06-03 16:49:14.554338 EDT | AverageAction               0.000127491
2017-06-03 16:49:14.554566 EDT | PolicyRegParamNorm         64.4844
2017-06-03 16:49:14.554803 EDT | QFunRegParamNorm           27.508
2017-06-03 16:49:14.555040 EDT | -----------------------  --------------
2017-06-03 16:49:14.555420 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #511 | Training started
2017-06-03 16:49:33.313302 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #511 | Training finished
2017-06-03 16:49:33.314168 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #511 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 16:49:33.314578 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #511 | Collecting samples for evaluation
2017-06-03 16:49:42.757428 EDT | -----------------------  --------------
2017-06-03 16:49:42.758431 EDT | Epoch                     511
2017-06-03 16:49:42.758780 EDT | Iteration                 511
2017-06-03 16:49:42.759107 EDT | AverageReturn            1000
2017-06-03 16:49:42.759429 EDT | StdReturn                   0
2017-06-03 16:49:42.759761 EDT | MaxReturn                1000
2017-06-03 16:49:42.760079 EDT | MinReturn                1000
2017-06-03 16:49:42.760396 EDT | AverageEsReturn            29.8529
2017-06-03 16:49:42.760718 EDT | StdEsReturn                28.0861
2017-06-03 16:49:42.761036 EDT | MaxEsReturn               144
2017-06-03 16:49:42.761351 EDT | MinEsReturn                 4
2017-06-03 16:49:42.761663 EDT | AverageDiscountedReturn    99.9957
2017-06-03 16:49:42.761988 EDT | AverageQLoss                3.25014e-05
2017-06-03 16:49:42.762307 EDT | AveragePolicySurr          -0.0920968
2017-06-03 16:49:42.762622 EDT | AverageQ                    0.0878788
2017-06-03 16:49:42.762937 EDT | AverageAbsQ                 0.0881523
2017-06-03 16:49:42.763249 EDT | AverageY                    0.0878826
2017-06-03 16:49:42.763561 EDT | AverageAbsY                 0.0879029
2017-06-03 16:49:42.763872 EDT | AverageAbsQYDiff            0.00163297
2017-06-03 16:49:42.764184 EDT | AverageAction               0.0162523
2017-06-03 16:49:42.764497 EDT | PolicyRegParamNorm         64.5023
2017-06-03 16:49:42.764806 EDT | QFunRegParamNorm           27.507
2017-06-03 16:49:42.765115 EDT | -----------------------  --------------
2017-06-03 16:49:42.765548 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #512 | Training started
2017-06-03 16:50:01.387592 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #512 | Training finished
2017-06-03 16:50:01.388519 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #512 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 16:50:01.388815 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #512 | Collecting samples for evaluation
2017-06-03 16:50:11.808649 EDT | -----------------------  --------------
2017-06-03 16:50:11.809224 EDT | Epoch                     512
2017-06-03 16:50:11.809468 EDT | Iteration                 512
2017-06-03 16:50:11.809725 EDT | AverageReturn            1000
2017-06-03 16:50:11.810073 EDT | StdReturn                   0
2017-06-03 16:50:11.810448 EDT | MaxReturn                1000
2017-06-03 16:50:11.810815 EDT | MinReturn                1000
2017-06-03 16:50:11.811172 EDT | AverageEsReturn            30.2121
2017-06-03 16:50:11.811560 EDT | StdEsReturn                26.6364
2017-06-03 16:50:11.811948 EDT | MaxEsReturn               108
2017-06-03 16:50:11.812341 EDT | MinEsReturn                 3
2017-06-03 16:50:11.812681 EDT | AverageDiscountedReturn    99.9957
2017-06-03 16:50:11.813087 EDT | AverageQLoss                3.15526e-05
2017-06-03 16:50:11.813379 EDT | AveragePolicySurr          -0.0922453
2017-06-03 16:50:11.813611 EDT | AverageQ                    0.088183
2017-06-03 16:50:11.813855 EDT | AverageAbsQ                 0.0884775
2017-06-03 16:50:11.814086 EDT | AverageY                    0.0881926
2017-06-03 16:50:11.814318 EDT | AverageAbsY                 0.0882071
2017-06-03 16:50:11.814540 EDT | AverageAbsQYDiff            0.00160669
2017-06-03 16:50:11.814758 EDT | AverageAction               0.0326202
2017-06-03 16:50:11.814976 EDT | PolicyRegParamNorm         64.5291
2017-06-03 16:50:11.815198 EDT | QFunRegParamNorm           27.5125
2017-06-03 16:50:11.815421 EDT | -----------------------  --------------
2017-06-03 16:50:11.815797 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #513 | Training started
2017-06-03 16:50:30.376160 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #513 | Training finished
2017-06-03 16:50:30.377008 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #513 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 16:50:30.377300 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #513 | Collecting samples for evaluation
2017-06-03 16:50:40.746698 EDT | -----------------------  --------------
2017-06-03 16:50:40.747746 EDT | Epoch                     513
2017-06-03 16:50:40.748117 EDT | Iteration                 513
2017-06-03 16:50:40.748445 EDT | AverageReturn            1000
2017-06-03 16:50:40.748762 EDT | StdReturn                   0
2017-06-03 16:50:40.749078 EDT | MaxReturn                1000
2017-06-03 16:50:40.749407 EDT | MinReturn                1000
2017-06-03 16:50:40.749736 EDT | AverageEsReturn            26.4211
2017-06-03 16:50:40.750059 EDT | StdEsReturn                20.5524
2017-06-03 16:50:40.750384 EDT | MaxEsReturn                88
2017-06-03 16:50:40.750699 EDT | MinEsReturn                 3
2017-06-03 16:50:40.751010 EDT | AverageDiscountedReturn    99.9957
2017-06-03 16:50:40.751327 EDT | AverageQLoss                3.40688e-05
2017-06-03 16:50:40.751680 EDT | AveragePolicySurr          -0.0921362
2017-06-03 16:50:40.752009 EDT | AverageQ                    0.0879683
2017-06-03 16:50:40.752322 EDT | AverageAbsQ                 0.0882213
2017-06-03 16:50:40.752630 EDT | AverageY                    0.0879622
2017-06-03 16:50:40.752954 EDT | AverageAbsY                 0.087974
2017-06-03 16:50:40.753267 EDT | AverageAbsQYDiff            0.0016632
2017-06-03 16:50:40.753576 EDT | AverageAction               0.00825123
2017-06-03 16:50:40.753901 EDT | PolicyRegParamNorm         64.5656
2017-06-03 16:50:40.754209 EDT | QFunRegParamNorm           27.5294
2017-06-03 16:50:40.754520 EDT | -----------------------  --------------
2017-06-03 16:50:40.754997 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #514 | Training started
2017-06-03 16:51:00.312446 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #514 | Training finished
2017-06-03 16:51:00.313309 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #514 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 16:51:00.313576 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #514 | Collecting samples for evaluation
2017-06-03 16:51:10.055171 EDT | -----------------------  --------------
2017-06-03 16:51:10.069176 EDT | Epoch                     514
2017-06-03 16:51:10.069646 EDT | Iteration                 514
2017-06-03 16:51:10.069993 EDT | AverageReturn            1000
2017-06-03 16:51:10.070330 EDT | StdReturn                   0
2017-06-03 16:51:10.070704 EDT | MaxReturn                1000
2017-06-03 16:51:10.071011 EDT | MinReturn                1000
2017-06-03 16:51:10.071318 EDT | AverageEsReturn            36.0741
2017-06-03 16:51:10.071635 EDT | StdEsReturn                27.5734
2017-06-03 16:51:10.071939 EDT | MaxEsReturn               118
2017-06-03 16:51:10.072355 EDT | MinEsReturn                 5
2017-06-03 16:51:10.072868 EDT | AverageDiscountedReturn    99.9957
2017-06-03 16:51:10.073315 EDT | AverageQLoss                3.23105e-05
2017-06-03 16:51:10.073810 EDT | AveragePolicySurr          -0.0920803
2017-06-03 16:51:10.074319 EDT | AverageQ                    0.0877454
2017-06-03 16:51:10.074779 EDT | AverageAbsQ                 0.0879672
2017-06-03 16:51:10.075283 EDT | AverageY                    0.0877422
2017-06-03 16:51:10.075669 EDT | AverageAbsY                 0.0877543
2017-06-03 16:51:10.076031 EDT | AverageAbsQYDiff            0.00153241
2017-06-03 16:51:10.076418 EDT | AverageAction               0.0472479
2017-06-03 16:51:10.076862 EDT | PolicyRegParamNorm         64.5617
2017-06-03 16:51:10.077297 EDT | QFunRegParamNorm           27.5497
2017-06-03 16:51:10.077737 EDT | -----------------------  --------------
2017-06-03 16:51:10.078408 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #515 | Training started
2017-06-03 16:51:28.722507 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #515 | Training finished
2017-06-03 16:51:28.723426 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #515 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 16:51:28.723698 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #515 | Collecting samples for evaluation
2017-06-03 16:51:38.396351 EDT | -----------------------  --------------
2017-06-03 16:51:38.397293 EDT | Epoch                     515
2017-06-03 16:51:38.397575 EDT | Iteration                 515
2017-06-03 16:51:38.397854 EDT | AverageReturn            1000
2017-06-03 16:51:38.398103 EDT | StdReturn                   0
2017-06-03 16:51:38.398360 EDT | MaxReturn                1000
2017-06-03 16:51:38.398725 EDT | MinReturn                1000
2017-06-03 16:51:38.399044 EDT | AverageEsReturn            26.2564
2017-06-03 16:51:38.399364 EDT | StdEsReturn                19.67
2017-06-03 16:51:38.399750 EDT | MaxEsReturn                71
2017-06-03 16:51:38.400075 EDT | MinEsReturn                 3
2017-06-03 16:51:38.400414 EDT | AverageDiscountedReturn    99.9957
2017-06-03 16:51:38.400802 EDT | AverageQLoss                3.33585e-05
2017-06-03 16:51:38.401162 EDT | AveragePolicySurr          -0.0920966
2017-06-03 16:51:38.401522 EDT | AverageQ                    0.0879086
2017-06-03 16:51:38.401882 EDT | AverageAbsQ                 0.0881684
2017-06-03 16:51:38.402215 EDT | AverageY                    0.087909
2017-06-03 16:51:38.402566 EDT | AverageAbsY                 0.0879207
2017-06-03 16:51:38.402891 EDT | AverageAbsQYDiff            0.0015527
2017-06-03 16:51:38.403214 EDT | AverageAction               0.00855847
2017-06-03 16:51:38.403534 EDT | PolicyRegParamNorm         64.6118
2017-06-03 16:51:38.403856 EDT | QFunRegParamNorm           27.5549
2017-06-03 16:51:38.404166 EDT | -----------------------  --------------
2017-06-03 16:51:38.404676 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #516 | Training started
2017-06-03 16:51:58.821642 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #516 | Training finished
2017-06-03 16:51:58.822563 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #516 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 16:51:58.822838 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #516 | Collecting samples for evaluation
2017-06-03 16:52:10.597928 EDT | -----------------------  --------------
2017-06-03 16:52:10.598281 EDT | Epoch                     516
2017-06-03 16:52:10.598529 EDT | Iteration                 516
2017-06-03 16:52:10.598763 EDT | AverageReturn            1000
2017-06-03 16:52:10.598996 EDT | StdReturn                   0
2017-06-03 16:52:10.599235 EDT | MaxReturn                1000
2017-06-03 16:52:10.599464 EDT | MinReturn                1000
2017-06-03 16:52:10.599690 EDT | AverageEsReturn            34.6296
2017-06-03 16:52:10.599923 EDT | StdEsReturn                28.3368
2017-06-03 16:52:10.600148 EDT | MaxEsReturn               114
2017-06-03 16:52:10.600378 EDT | MinEsReturn                 5
2017-06-03 16:52:10.600607 EDT | AverageDiscountedReturn    99.9957
2017-06-03 16:52:10.600837 EDT | AverageQLoss                2.97817e-05
2017-06-03 16:52:10.601084 EDT | AveragePolicySurr          -0.09204
2017-06-03 16:52:10.601319 EDT | AverageQ                    0.0878817
2017-06-03 16:52:10.601550 EDT | AverageAbsQ                 0.088085
2017-06-03 16:52:10.601795 EDT | AverageY                    0.0878799
2017-06-03 16:52:10.602027 EDT | AverageAbsY                 0.0878909
2017-06-03 16:52:10.602258 EDT | AverageAbsQYDiff            0.00143639
2017-06-03 16:52:10.602485 EDT | AverageAction               0.090027
2017-06-03 16:52:10.602719 EDT | PolicyRegParamNorm         64.6252
2017-06-03 16:52:10.602954 EDT | QFunRegParamNorm           27.5575
2017-06-03 16:52:10.603183 EDT | -----------------------  --------------
2017-06-03 16:52:10.603525 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #517 | Training started
2017-06-03 16:52:29.479912 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #517 | Training finished
2017-06-03 16:52:29.480878 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #517 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 16:52:29.481269 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #517 | Collecting samples for evaluation
2017-06-03 16:52:38.745580 EDT | -----------------------  -------------
2017-06-03 16:52:38.746152 EDT | Epoch                     517
2017-06-03 16:52:38.746484 EDT | Iteration                 517
2017-06-03 16:52:38.746823 EDT | AverageReturn            1000
2017-06-03 16:52:38.747138 EDT | StdReturn                   0
2017-06-03 16:52:38.747461 EDT | MaxReturn                1000
2017-06-03 16:52:38.747774 EDT | MinReturn                1000
2017-06-03 16:52:38.748084 EDT | AverageEsReturn            30.5
2017-06-03 16:52:38.748394 EDT | StdEsReturn                21.7448
2017-06-03 16:52:38.748719 EDT | MaxEsReturn                88
2017-06-03 16:52:38.749025 EDT | MinEsReturn                 4
2017-06-03 16:52:38.749338 EDT | AverageDiscountedReturn    99.9957
2017-06-03 16:52:38.749653 EDT | AverageQLoss                2.794e-05
2017-06-03 16:52:38.749999 EDT | AveragePolicySurr          -0.0920086
2017-06-03 16:52:38.750309 EDT | AverageQ                    0.0877256
2017-06-03 16:52:38.750622 EDT | AverageAbsQ                 0.0879637
2017-06-03 16:52:38.750929 EDT | AverageY                    0.0877254
2017-06-03 16:52:38.751240 EDT | AverageAbsY                 0.0877336
2017-06-03 16:52:38.751551 EDT | AverageAbsQYDiff            0.00144221
2017-06-03 16:52:38.751856 EDT | AverageAction               0.0637619
2017-06-03 16:52:38.752178 EDT | PolicyRegParamNorm         64.6458
2017-06-03 16:52:38.752482 EDT | QFunRegParamNorm           27.5654
2017-06-03 16:52:38.752785 EDT | -----------------------  -------------
2017-06-03 16:52:38.753240 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #518 | Training started
2017-06-03 16:52:56.407493 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #518 | Training finished
2017-06-03 16:52:56.408372 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #518 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 16:52:56.408650 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #518 | Collecting samples for evaluation
2017-06-03 16:53:05.898912 EDT | -----------------------  --------------
2017-06-03 16:53:05.899751 EDT | Epoch                     518
2017-06-03 16:53:05.900018 EDT | Iteration                 518
2017-06-03 16:53:05.900271 EDT | AverageReturn            1000
2017-06-03 16:53:05.900521 EDT | StdReturn                   0
2017-06-03 16:53:05.900783 EDT | MaxReturn                1000
2017-06-03 16:53:05.901028 EDT | MinReturn                1000
2017-06-03 16:53:05.901273 EDT | AverageEsReturn            32.5161
2017-06-03 16:53:05.901519 EDT | StdEsReturn                30.5697
2017-06-03 16:53:05.901780 EDT | MaxEsReturn               121
2017-06-03 16:53:05.902026 EDT | MinEsReturn                 3
2017-06-03 16:53:05.902270 EDT | AverageDiscountedReturn    99.9957
2017-06-03 16:53:05.902514 EDT | AverageQLoss                3.38036e-05
2017-06-03 16:53:05.902759 EDT | AveragePolicySurr          -0.0920262
2017-06-03 16:53:05.903009 EDT | AverageQ                    0.0877059
2017-06-03 16:53:05.903253 EDT | AverageAbsQ                 0.0879537
2017-06-03 16:53:05.903495 EDT | AverageY                    0.0877097
2017-06-03 16:53:05.903749 EDT | AverageAbsY                 0.0877175
2017-06-03 16:53:05.903992 EDT | AverageAbsQYDiff            0.00163278
2017-06-03 16:53:05.904234 EDT | AverageAction               0.000570034
2017-06-03 16:53:05.904477 EDT | PolicyRegParamNorm         64.6937
2017-06-03 16:53:05.904721 EDT | QFunRegParamNorm           27.5757
2017-06-03 16:53:05.904973 EDT | -----------------------  --------------
2017-06-03 16:53:05.905338 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #519 | Training started
2017-06-03 16:53:25.330443 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #519 | Training finished
2017-06-03 16:53:25.340364 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #519 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 16:53:25.340769 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #519 | Collecting samples for evaluation
2017-06-03 16:53:36.327640 EDT | -----------------------  --------------
2017-06-03 16:53:36.328508 EDT | Epoch                     519
2017-06-03 16:53:36.328770 EDT | Iteration                 519
2017-06-03 16:53:36.329013 EDT | AverageReturn            1000
2017-06-03 16:53:36.329330 EDT | StdReturn                   0
2017-06-03 16:53:36.329715 EDT | MaxReturn                1000
2017-06-03 16:53:36.329967 EDT | MinReturn                1000
2017-06-03 16:53:36.330315 EDT | AverageEsReturn            30.75
2017-06-03 16:53:36.330660 EDT | StdEsReturn                26.4114
2017-06-03 16:53:36.331063 EDT | MaxEsReturn               113
2017-06-03 16:53:36.331464 EDT | MinEsReturn                 4
2017-06-03 16:53:36.331848 EDT | AverageDiscountedReturn    99.9957
2017-06-03 16:53:36.332226 EDT | AverageQLoss                2.72049e-05
2017-06-03 16:53:36.332588 EDT | AveragePolicySurr          -0.0920716
2017-06-03 16:53:36.332958 EDT | AverageQ                    0.087731
2017-06-03 16:53:36.333252 EDT | AverageAbsQ                 0.087971
2017-06-03 16:53:36.333489 EDT | AverageY                    0.0877266
2017-06-03 16:53:36.333734 EDT | AverageAbsY                 0.0877332
2017-06-03 16:53:36.334024 EDT | AverageAbsQYDiff            0.00145144
2017-06-03 16:53:36.334341 EDT | AverageAction               7.99897e-05
2017-06-03 16:53:36.334674 EDT | PolicyRegParamNorm         64.7475
2017-06-03 16:53:36.335013 EDT | QFunRegParamNorm           27.5752
2017-06-03 16:53:36.335351 EDT | -----------------------  --------------
2017-06-03 16:53:36.335849 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #520 | Training started
2017-06-03 16:53:55.092601 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #520 | Training finished
2017-06-03 16:53:55.093653 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #520 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 16:53:55.094101 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #520 | Collecting samples for evaluation
2017-06-03 16:54:04.169234 EDT | -----------------------  --------------
2017-06-03 16:54:04.170084 EDT | Epoch                     520
2017-06-03 16:54:04.170347 EDT | Iteration                 520
2017-06-03 16:54:04.170601 EDT | AverageReturn            1000
2017-06-03 16:54:04.170836 EDT | StdReturn                   0
2017-06-03 16:54:04.171074 EDT | MaxReturn                1000
2017-06-03 16:54:04.171309 EDT | MinReturn                1000
2017-06-03 16:54:04.171541 EDT | AverageEsReturn            26.2821
2017-06-03 16:54:04.171782 EDT | StdEsReturn                17.3382
2017-06-03 16:54:04.172014 EDT | MaxEsReturn                78
2017-06-03 16:54:04.172253 EDT | MinEsReturn                 3
2017-06-03 16:54:04.172486 EDT | AverageDiscountedReturn    99.9957
2017-06-03 16:54:04.172718 EDT | AverageQLoss                2.96467e-05
2017-06-03 16:54:04.172950 EDT | AveragePolicySurr          -0.0918418
2017-06-03 16:54:04.173181 EDT | AverageQ                    0.0876531
2017-06-03 16:54:04.173412 EDT | AverageAbsQ                 0.0878904
2017-06-03 16:54:04.173644 EDT | AverageY                    0.0876567
2017-06-03 16:54:04.173894 EDT | AverageAbsY                 0.0876666
2017-06-03 16:54:04.174127 EDT | AverageAbsQYDiff            0.00144023
2017-06-03 16:54:04.174358 EDT | AverageAction               0.000147377
2017-06-03 16:54:04.174589 EDT | PolicyRegParamNorm         64.7672
2017-06-03 16:54:04.174820 EDT | QFunRegParamNorm           27.5733
2017-06-03 16:54:04.175055 EDT | -----------------------  --------------
2017-06-03 16:54:04.175432 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #521 | Training started
2017-06-03 16:54:22.228341 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #521 | Training finished
2017-06-03 16:54:22.229204 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #521 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 16:54:22.229483 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #521 | Collecting samples for evaluation
2017-06-03 16:54:32.401517 EDT | -----------------------  --------------
2017-06-03 16:54:32.402420 EDT | Epoch                     521
2017-06-03 16:54:32.402697 EDT | Iteration                 521
2017-06-03 16:54:32.402941 EDT | AverageReturn            1000
2017-06-03 16:54:32.403185 EDT | StdReturn                   0
2017-06-03 16:54:32.403426 EDT | MaxReturn                1000
2017-06-03 16:54:32.403662 EDT | MinReturn                1000
2017-06-03 16:54:32.403899 EDT | AverageEsReturn            31.6562
2017-06-03 16:54:32.404138 EDT | StdEsReturn                24.6686
2017-06-03 16:54:32.404399 EDT | MaxEsReturn                98
2017-06-03 16:54:32.404642 EDT | MinEsReturn                 5
2017-06-03 16:54:32.404877 EDT | AverageDiscountedReturn    99.9957
2017-06-03 16:54:32.405109 EDT | AverageQLoss                2.8904e-05
2017-06-03 16:54:32.405342 EDT | AveragePolicySurr          -0.0916985
2017-06-03 16:54:32.405590 EDT | AverageQ                    0.0874757
2017-06-03 16:54:32.405991 EDT | AverageAbsQ                 0.0876866
2017-06-03 16:54:32.406337 EDT | AverageY                    0.0874741
2017-06-03 16:54:32.406689 EDT | AverageAbsY                 0.0874806
2017-06-03 16:54:32.407031 EDT | AverageAbsQYDiff            0.00145265
2017-06-03 16:54:32.407353 EDT | AverageAction               5.12159e-05
2017-06-03 16:54:32.407696 EDT | PolicyRegParamNorm         64.8122
2017-06-03 16:54:32.408015 EDT | QFunRegParamNorm           27.5697
2017-06-03 16:54:32.408335 EDT | -----------------------  --------------
2017-06-03 16:54:32.408809 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #522 | Training started
2017-06-03 16:54:51.248656 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #522 | Training finished
2017-06-03 16:54:51.249574 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #522 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 16:54:51.249861 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #522 | Collecting samples for evaluation
2017-06-03 16:55:02.258675 EDT | -----------------------  --------------
2017-06-03 16:55:02.262323 EDT | Epoch                     522
2017-06-03 16:55:02.262587 EDT | Iteration                 522
2017-06-03 16:55:02.262826 EDT | AverageReturn            1000
2017-06-03 16:55:02.263055 EDT | StdReturn                   0
2017-06-03 16:55:02.263303 EDT | MaxReturn                1000
2017-06-03 16:55:02.263532 EDT | MinReturn                1000
2017-06-03 16:55:02.263752 EDT | AverageEsReturn            30.75
2017-06-03 16:55:02.263972 EDT | StdEsReturn                36.9188
2017-06-03 16:55:02.264191 EDT | MaxEsReturn               193
2017-06-03 16:55:02.264409 EDT | MinEsReturn                 4
2017-06-03 16:55:02.264638 EDT | AverageDiscountedReturn    99.9957
2017-06-03 16:55:02.264859 EDT | AverageQLoss                2.34056e-05
2017-06-03 16:55:02.265076 EDT | AveragePolicySurr          -0.0920375
2017-06-03 16:55:02.265299 EDT | AverageQ                    0.0878017
2017-06-03 16:55:02.265517 EDT | AverageAbsQ                 0.0880019
2017-06-03 16:55:02.266234 EDT | AverageY                    0.0877963
2017-06-03 16:55:02.266543 EDT | AverageAbsY                 0.087804
2017-06-03 16:55:02.266845 EDT | AverageAbsQYDiff            0.00135593
2017-06-03 16:55:02.267148 EDT | AverageAction               7.29287e-05
2017-06-03 16:55:02.267449 EDT | PolicyRegParamNorm         64.8496
2017-06-03 16:55:02.267748 EDT | QFunRegParamNorm           27.5877
2017-06-03 16:55:02.268049 EDT | -----------------------  --------------
2017-06-03 16:55:02.268499 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #523 | Training started
2017-06-03 16:55:20.022506 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #523 | Training finished
2017-06-03 16:55:20.024235 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #523 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 16:55:20.024563 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #523 | Collecting samples for evaluation
2017-06-03 16:55:28.866750 EDT | -----------------------  --------------
2017-06-03 16:55:28.867632 EDT | Epoch                     523
2017-06-03 16:55:28.867920 EDT | Iteration                 523
2017-06-03 16:55:28.868175 EDT | AverageReturn            1000
2017-06-03 16:55:28.868423 EDT | StdReturn                   0
2017-06-03 16:55:28.868686 EDT | MaxReturn                1000
2017-06-03 16:55:28.868935 EDT | MinReturn                1000
2017-06-03 16:55:28.869179 EDT | AverageEsReturn            27.3143
2017-06-03 16:55:28.869424 EDT | StdEsReturn                27.1365
2017-06-03 16:55:28.869667 EDT | MaxEsReturn               119
2017-06-03 16:55:28.869925 EDT | MinEsReturn                 4
2017-06-03 16:55:28.870169 EDT | AverageDiscountedReturn    99.9957
2017-06-03 16:55:28.870413 EDT | AverageQLoss                2.75133e-05
2017-06-03 16:55:28.870656 EDT | AveragePolicySurr          -0.0916725
2017-06-03 16:55:28.870906 EDT | AverageQ                    0.0874845
2017-06-03 16:55:28.871148 EDT | AverageAbsQ                 0.0877532
2017-06-03 16:55:28.871390 EDT | AverageY                    0.0874821
2017-06-03 16:55:28.871641 EDT | AverageAbsY                 0.0874942
2017-06-03 16:55:28.871887 EDT | AverageAbsQYDiff            0.00163423
2017-06-03 16:55:28.872129 EDT | AverageAction               6.74759e-05
2017-06-03 16:55:28.872371 EDT | PolicyRegParamNorm         64.9121
2017-06-03 16:55:28.872613 EDT | QFunRegParamNorm           27.58
2017-06-03 16:55:28.872854 EDT | -----------------------  --------------
2017-06-03 16:55:28.873236 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #524 | Training started
2017-06-03 16:55:47.745973 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #524 | Training finished
2017-06-03 16:55:47.746833 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #524 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 16:55:47.747101 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #524 | Collecting samples for evaluation
2017-06-03 16:55:56.428612 EDT | -----------------------  --------------
2017-06-03 16:55:56.429011 EDT | Epoch                     524
2017-06-03 16:55:56.429264 EDT | Iteration                 524
2017-06-03 16:55:56.429504 EDT | AverageReturn            1000
2017-06-03 16:55:56.429751 EDT | StdReturn                   0
2017-06-03 16:55:56.429989 EDT | MaxReturn                1000
2017-06-03 16:55:56.430223 EDT | MinReturn                1000
2017-06-03 16:55:56.430456 EDT | AverageEsReturn            28.1622
2017-06-03 16:55:56.430721 EDT | StdEsReturn                20.3888
2017-06-03 16:55:56.430956 EDT | MaxEsReturn                75
2017-06-03 16:55:56.431188 EDT | MinEsReturn                 4
2017-06-03 16:55:56.431420 EDT | AverageDiscountedReturn    99.9957
2017-06-03 16:55:56.431652 EDT | AverageQLoss                2.82208e-05
2017-06-03 16:55:56.431903 EDT | AveragePolicySurr          -0.0917585
2017-06-03 16:55:56.432136 EDT | AverageQ                    0.0875364
2017-06-03 16:55:56.432367 EDT | AverageAbsQ                 0.0877972
2017-06-03 16:55:56.432599 EDT | AverageY                    0.0875436
2017-06-03 16:55:56.432829 EDT | AverageAbsY                 0.0875571
2017-06-03 16:55:56.433076 EDT | AverageAbsQYDiff            0.00152718
2017-06-03 16:55:56.433306 EDT | AverageAction               7.7011e-05
2017-06-03 16:55:56.433536 EDT | PolicyRegParamNorm         64.964
2017-06-03 16:55:56.433779 EDT | QFunRegParamNorm           27.5865
2017-06-03 16:55:56.434011 EDT | -----------------------  --------------
2017-06-03 16:55:56.434385 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #525 | Training started
2017-06-03 16:56:14.504604 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #525 | Training finished
2017-06-03 16:56:14.505582 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #525 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 16:56:14.505887 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #525 | Collecting samples for evaluation
2017-06-03 16:56:24.160301 EDT | -----------------------  --------------
2017-06-03 16:56:24.161143 EDT | Epoch                     525
2017-06-03 16:56:24.161409 EDT | Iteration                 525
2017-06-03 16:56:24.161671 EDT | AverageReturn            1000
2017-06-03 16:56:24.161953 EDT | StdReturn                   0
2017-06-03 16:56:24.162199 EDT | MaxReturn                1000
2017-06-03 16:56:24.162445 EDT | MinReturn                1000
2017-06-03 16:56:24.162688 EDT | AverageEsReturn            33.8333
2017-06-03 16:56:24.162949 EDT | StdEsReturn                26.3807
2017-06-03 16:56:24.163197 EDT | MaxEsReturn               116
2017-06-03 16:56:24.163439 EDT | MinEsReturn                 5
2017-06-03 16:56:24.163680 EDT | AverageDiscountedReturn    99.9957
2017-06-03 16:56:24.163932 EDT | AverageQLoss                2.43718e-05
2017-06-03 16:56:24.164186 EDT | AveragePolicySurr          -0.0917312
2017-06-03 16:56:24.164429 EDT | AverageQ                    0.0875079
2017-06-03 16:56:24.164670 EDT | AverageAbsQ                 0.0877157
2017-06-03 16:56:24.164912 EDT | AverageY                    0.0875123
2017-06-03 16:56:24.165154 EDT | AverageAbsY                 0.087534
2017-06-03 16:56:24.165404 EDT | AverageAbsQYDiff            0.00136202
2017-06-03 16:56:24.165646 EDT | AverageAction               0.00010551
2017-06-03 16:56:24.165900 EDT | PolicyRegParamNorm         65.0008
2017-06-03 16:56:24.166143 EDT | QFunRegParamNorm           27.5794
2017-06-03 16:56:24.166386 EDT | -----------------------  --------------
2017-06-03 16:56:24.166748 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #526 | Training started
2017-06-03 16:56:42.732185 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #526 | Training finished
2017-06-03 16:56:42.733029 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #526 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 16:56:42.733297 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #526 | Collecting samples for evaluation
2017-06-03 16:56:51.544038 EDT | -----------------------  -------------
2017-06-03 16:56:51.545441 EDT | Epoch                     526
2017-06-03 16:56:51.545711 EDT | Iteration                 526
2017-06-03 16:56:51.545962 EDT | AverageReturn            1000
2017-06-03 16:56:51.546231 EDT | StdReturn                   0
2017-06-03 16:56:51.546469 EDT | MaxReturn                1000
2017-06-03 16:56:51.546699 EDT | MinReturn                1000
2017-06-03 16:56:51.546928 EDT | AverageEsReturn            35.8929
2017-06-03 16:56:51.547158 EDT | StdEsReturn                27.5659
2017-06-03 16:56:51.547394 EDT | MaxEsReturn               115
2017-06-03 16:56:51.547625 EDT | MinEsReturn                 4
2017-06-03 16:56:51.547852 EDT | AverageDiscountedReturn    99.9957
2017-06-03 16:56:51.548079 EDT | AverageQLoss                3.1382e-05
2017-06-03 16:56:51.548305 EDT | AveragePolicySurr          -0.0918241
2017-06-03 16:56:51.548533 EDT | AverageQ                    0.0876101
2017-06-03 16:56:51.548765 EDT | AverageAbsQ                 0.0878755
2017-06-03 16:56:51.548992 EDT | AverageY                    0.0876112
2017-06-03 16:56:51.549218 EDT | AverageAbsY                 0.0876265
2017-06-03 16:56:51.549446 EDT | AverageAbsQYDiff            0.00155664
2017-06-03 16:56:51.549671 EDT | AverageAction               0.0103232
2017-06-03 16:56:51.549939 EDT | PolicyRegParamNorm         65.0284
2017-06-03 16:56:51.550180 EDT | QFunRegParamNorm           27.59
2017-06-03 16:56:51.550428 EDT | -----------------------  -------------
2017-06-03 16:56:51.550788 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #527 | Training started
2017-06-03 16:57:08.822218 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #527 | Training finished
2017-06-03 16:57:08.823220 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #527 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 16:57:08.823610 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #527 | Collecting samples for evaluation
2017-06-03 16:57:18.157026 EDT | -----------------------  --------------
2017-06-03 16:57:18.160097 EDT | Epoch                     527
2017-06-03 16:57:18.160359 EDT | Iteration                 527
2017-06-03 16:57:18.160592 EDT | AverageReturn            1000
2017-06-03 16:57:18.160820 EDT | StdReturn                   0
2017-06-03 16:57:18.161045 EDT | MaxReturn                1000
2017-06-03 16:57:18.161268 EDT | MinReturn                1000
2017-06-03 16:57:18.161501 EDT | AverageEsReturn            29.75
2017-06-03 16:57:18.161737 EDT | StdEsReturn                27.4089
2017-06-03 16:57:18.161969 EDT | MaxEsReturn               111
2017-06-03 16:57:18.162202 EDT | MinEsReturn                 4
2017-06-03 16:57:18.162424 EDT | AverageDiscountedReturn    99.9957
2017-06-03 16:57:18.162647 EDT | AverageQLoss                3.06937e-05
2017-06-03 16:57:18.162871 EDT | AveragePolicySurr          -0.0916884
2017-06-03 16:57:18.163094 EDT | AverageQ                    0.0874957
2017-06-03 16:57:18.163317 EDT | AverageAbsQ                 0.0877631
2017-06-03 16:57:18.163541 EDT | AverageY                    0.0874885
2017-06-03 16:57:18.163764 EDT | AverageAbsY                 0.0875113
2017-06-03 16:57:18.163988 EDT | AverageAbsQYDiff            0.00152919
2017-06-03 16:57:18.164216 EDT | AverageAction               0.179917
2017-06-03 16:57:18.164438 EDT | PolicyRegParamNorm         65.1133
2017-06-03 16:57:18.164660 EDT | QFunRegParamNorm           27.6188
2017-06-03 16:57:18.164883 EDT | -----------------------  --------------
2017-06-03 16:57:18.165250 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #528 | Training started
2017-06-03 16:57:36.864708 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #528 | Training finished
2017-06-03 16:57:36.865572 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #528 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 16:57:36.865865 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #528 | Collecting samples for evaluation
2017-06-03 16:57:46.222619 EDT | -----------------------  --------------
2017-06-03 16:57:46.225784 EDT | Epoch                     528
2017-06-03 16:57:46.226074 EDT | Iteration                 528
2017-06-03 16:57:46.226329 EDT | AverageReturn            1000
2017-06-03 16:57:46.226577 EDT | StdReturn                   0
2017-06-03 16:57:46.226823 EDT | MaxReturn                1000
2017-06-03 16:57:46.227106 EDT | MinReturn                1000
2017-06-03 16:57:46.227351 EDT | AverageEsReturn            43.6667
2017-06-03 16:57:46.227600 EDT | StdEsReturn                27.1472
2017-06-03 16:57:46.227844 EDT | MaxEsReturn               111
2017-06-03 16:57:46.228087 EDT | MinEsReturn                 3
2017-06-03 16:57:46.228333 EDT | AverageDiscountedReturn    99.9957
2017-06-03 16:57:46.228574 EDT | AverageQLoss                3.19683e-05
2017-06-03 16:57:46.228855 EDT | AveragePolicySurr          -0.0916094
2017-06-03 16:57:46.229101 EDT | AverageQ                    0.087313
2017-06-03 16:57:46.229344 EDT | AverageAbsQ                 0.0875745
2017-06-03 16:57:46.229586 EDT | AverageY                    0.0873089
2017-06-03 16:57:46.229841 EDT | AverageAbsY                 0.0873283
2017-06-03 16:57:46.230093 EDT | AverageAbsQYDiff            0.00162753
2017-06-03 16:57:46.230339 EDT | AverageAction               0.000396373
2017-06-03 16:57:46.230581 EDT | PolicyRegParamNorm         65.1008
2017-06-03 16:57:46.230822 EDT | QFunRegParamNorm           27.6132
2017-06-03 16:57:46.231063 EDT | -----------------------  --------------
2017-06-03 16:57:46.231459 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #529 | Training started
2017-06-03 16:58:03.873558 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #529 | Training finished
2017-06-03 16:58:03.874420 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #529 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 16:58:03.874696 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #529 | Collecting samples for evaluation
2017-06-03 16:58:14.041477 EDT | -----------------------  --------------
2017-06-03 16:58:14.042524 EDT | Epoch                     529
2017-06-03 16:58:14.042788 EDT | Iteration                 529
2017-06-03 16:58:14.043020 EDT | AverageReturn            1000
2017-06-03 16:58:14.043248 EDT | StdReturn                   0
2017-06-03 16:58:14.043488 EDT | MaxReturn                1000
2017-06-03 16:58:14.043712 EDT | MinReturn                1000
2017-06-03 16:58:14.043945 EDT | AverageEsReturn            37.3077
2017-06-03 16:58:14.044169 EDT | StdEsReturn                33.1926
2017-06-03 16:58:14.044392 EDT | MaxEsReturn               115
2017-06-03 16:58:14.044616 EDT | MinEsReturn                 4
2017-06-03 16:58:14.044838 EDT | AverageDiscountedReturn    99.9957
2017-06-03 16:58:14.045067 EDT | AverageQLoss                2.75226e-05
2017-06-03 16:58:14.045289 EDT | AveragePolicySurr          -0.0914947
2017-06-03 16:58:14.045534 EDT | AverageQ                    0.0873972
2017-06-03 16:58:14.046248 EDT | AverageAbsQ                 0.0876043
2017-06-03 16:58:14.046563 EDT | AverageY                    0.0874049
2017-06-03 16:58:14.046874 EDT | AverageAbsY                 0.0874295
2017-06-03 16:58:14.047181 EDT | AverageAbsQYDiff            0.00140989
2017-06-03 16:58:14.047492 EDT | AverageAction               0.0274781
2017-06-03 16:58:14.047798 EDT | PolicyRegParamNorm         65.14
2017-06-03 16:58:14.048103 EDT | QFunRegParamNorm           27.6257
2017-06-03 16:58:14.048423 EDT | -----------------------  --------------
2017-06-03 16:58:14.048885 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #530 | Training started
2017-06-03 16:58:34.091311 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #530 | Training finished
2017-06-03 16:58:34.092212 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #530 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 16:58:34.092484 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #530 | Collecting samples for evaluation
2017-06-03 16:58:44.450864 EDT | -----------------------  --------------
2017-06-03 16:58:44.451682 EDT | Epoch                     530
2017-06-03 16:58:44.451940 EDT | Iteration                 530
2017-06-03 16:58:44.452182 EDT | AverageReturn            1000
2017-06-03 16:58:44.452419 EDT | StdReturn                   0
2017-06-03 16:58:44.452654 EDT | MaxReturn                1000
2017-06-03 16:58:44.452896 EDT | MinReturn                1000
2017-06-03 16:58:44.453128 EDT | AverageEsReturn            40.8
2017-06-03 16:58:44.453364 EDT | StdEsReturn                25.1364
2017-06-03 16:58:44.453597 EDT | MaxEsReturn               104
2017-06-03 16:58:44.453839 EDT | MinEsReturn                 4
2017-06-03 16:58:44.454068 EDT | AverageDiscountedReturn    99.9957
2017-06-03 16:58:44.454299 EDT | AverageQLoss                3.12368e-05
2017-06-03 16:58:44.454531 EDT | AveragePolicySurr          -0.0914799
2017-06-03 16:58:44.454760 EDT | AverageQ                    0.0875369
2017-06-03 16:58:44.454988 EDT | AverageAbsQ                 0.0877948
2017-06-03 16:58:44.455218 EDT | AverageY                    0.0875375
2017-06-03 16:58:44.455448 EDT | AverageAbsY                 0.087553
2017-06-03 16:58:44.455678 EDT | AverageAbsQYDiff            0.0015353
2017-06-03 16:58:44.455907 EDT | AverageAction               9.56423e-05
2017-06-03 16:58:44.456137 EDT | PolicyRegParamNorm         65.1926
2017-06-03 16:58:44.456367 EDT | QFunRegParamNorm           27.6258
2017-06-03 16:58:44.456596 EDT | -----------------------  --------------
2017-06-03 16:58:44.456936 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #531 | Training started
2017-06-03 16:59:03.239105 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #531 | Training finished
2017-06-03 16:59:03.240049 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #531 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 16:59:03.240405 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #531 | Collecting samples for evaluation
2017-06-03 16:59:12.236597 EDT | -----------------------  --------------
2017-06-03 16:59:12.237449 EDT | Epoch                     531
2017-06-03 16:59:12.237718 EDT | Iteration                 531
2017-06-03 16:59:12.237962 EDT | AverageReturn            1000
2017-06-03 16:59:12.238215 EDT | StdReturn                   0
2017-06-03 16:59:12.238456 EDT | MaxReturn                1000
2017-06-03 16:59:12.238690 EDT | MinReturn                1000
2017-06-03 16:59:12.238932 EDT | AverageEsReturn            31.4062
2017-06-03 16:59:12.239166 EDT | StdEsReturn                23.0717
2017-06-03 16:59:12.239398 EDT | MaxEsReturn               111
2017-06-03 16:59:12.239630 EDT | MinEsReturn                 5
2017-06-03 16:59:12.239861 EDT | AverageDiscountedReturn    99.9957
2017-06-03 16:59:12.240092 EDT | AverageQLoss                2.58558e-05
2017-06-03 16:59:12.240322 EDT | AveragePolicySurr          -0.0914975
2017-06-03 16:59:12.240552 EDT | AverageQ                    0.0873909
2017-06-03 16:59:12.240784 EDT | AverageAbsQ                 0.0875985
2017-06-03 16:59:12.241014 EDT | AverageY                    0.0873865
2017-06-03 16:59:12.241245 EDT | AverageAbsY                 0.0873985
2017-06-03 16:59:12.241484 EDT | AverageAbsQYDiff            0.00138241
2017-06-03 16:59:12.241722 EDT | AverageAction               0.00210451
2017-06-03 16:59:12.241957 EDT | PolicyRegParamNorm         65.1969
2017-06-03 16:59:12.242192 EDT | QFunRegParamNorm           27.6257
2017-06-03 16:59:12.242422 EDT | -----------------------  --------------
2017-06-03 16:59:12.242775 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #532 | Training started
2017-06-03 16:59:29.778715 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #532 | Training finished
2017-06-03 16:59:29.779121 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #532 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 16:59:29.779379 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #532 | Collecting samples for evaluation
2017-06-03 16:59:40.498536 EDT | -----------------------  --------------
2017-06-03 16:59:40.499563 EDT | Epoch                     532
2017-06-03 16:59:40.499922 EDT | Iteration                 532
2017-06-03 16:59:40.500260 EDT | AverageReturn            1000
2017-06-03 16:59:40.500585 EDT | StdReturn                   0
2017-06-03 16:59:40.500904 EDT | MaxReturn                1000
2017-06-03 16:59:40.501290 EDT | MinReturn                1000
2017-06-03 16:59:40.501638 EDT | AverageEsReturn            27.3889
2017-06-03 16:59:40.501974 EDT | StdEsReturn                27.243
2017-06-03 16:59:40.502317 EDT | MaxEsReturn               108
2017-06-03 16:59:40.502644 EDT | MinEsReturn                 3
2017-06-03 16:59:40.502969 EDT | AverageDiscountedReturn    99.9957
2017-06-03 16:59:40.503308 EDT | AverageQLoss                2.89036e-05
2017-06-03 16:59:40.504340 EDT | AveragePolicySurr          -0.0917224
2017-06-03 16:59:40.504691 EDT | AverageQ                    0.0877211
2017-06-03 16:59:40.505019 EDT | AverageAbsQ                 0.0880052
2017-06-03 16:59:40.505362 EDT | AverageY                    0.0877212
2017-06-03 16:59:40.505707 EDT | AverageAbsY                 0.087734
2017-06-03 16:59:40.506034 EDT | AverageAbsQYDiff            0.00150674
2017-06-03 16:59:40.506369 EDT | AverageAction               0.0209105
2017-06-03 16:59:40.506696 EDT | PolicyRegParamNorm         65.2372
2017-06-03 16:59:40.507012 EDT | QFunRegParamNorm           27.637
2017-06-03 16:59:40.507354 EDT | -----------------------  --------------
2017-06-03 16:59:40.507854 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #533 | Training started
2017-06-03 17:00:00.882541 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #533 | Training finished
2017-06-03 17:00:00.882876 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #533 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 17:00:00.883131 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #533 | Collecting samples for evaluation
2017-06-03 17:00:10.937116 EDT | -----------------------  --------------
2017-06-03 17:00:10.937962 EDT | Epoch                     533
2017-06-03 17:00:10.938338 EDT | Iteration                 533
2017-06-03 17:00:10.939727 EDT | AverageReturn            1000
2017-06-03 17:00:10.940656 EDT | StdReturn                   0
2017-06-03 17:00:10.940923 EDT | MaxReturn                1000
2017-06-03 17:00:10.941192 EDT | MinReturn                1000
2017-06-03 17:00:10.941450 EDT | AverageEsReturn            27.1622
2017-06-03 17:00:10.941728 EDT | StdEsReturn                20.345
2017-06-03 17:00:10.941985 EDT | MaxEsReturn               109
2017-06-03 17:00:10.942238 EDT | MinEsReturn                 5
2017-06-03 17:00:10.942489 EDT | AverageDiscountedReturn    99.9957
2017-06-03 17:00:10.942738 EDT | AverageQLoss                2.52452e-05
2017-06-03 17:00:10.942987 EDT | AveragePolicySurr          -0.0915994
2017-06-03 17:00:10.943905 EDT | AverageQ                    0.0875557
2017-06-03 17:00:10.944207 EDT | AverageAbsQ                 0.0877413
2017-06-03 17:00:10.944467 EDT | AverageY                    0.0875623
2017-06-03 17:00:10.944781 EDT | AverageAbsY                 0.0875732
2017-06-03 17:00:10.945033 EDT | AverageAbsQYDiff            0.00131765
2017-06-03 17:00:10.945299 EDT | AverageAction               7.85281e-05
2017-06-03 17:00:10.945553 EDT | PolicyRegParamNorm         65.2368
2017-06-03 17:00:10.945809 EDT | QFunRegParamNorm           27.6378
2017-06-03 17:00:10.946049 EDT | -----------------------  --------------
2017-06-03 17:00:10.946432 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #534 | Training started
2017-06-03 17:00:28.989611 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #534 | Training finished
2017-06-03 17:00:28.992104 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #534 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 17:00:28.992478 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #534 | Collecting samples for evaluation
2017-06-03 17:00:38.151056 EDT | -----------------------  --------------
2017-06-03 17:00:38.151929 EDT | Epoch                     534
2017-06-03 17:00:38.152210 EDT | Iteration                 534
2017-06-03 17:00:38.152456 EDT | AverageReturn            1000
2017-06-03 17:00:38.152702 EDT | StdReturn                   0
2017-06-03 17:00:38.152937 EDT | MaxReturn                1000
2017-06-03 17:00:38.153170 EDT | MinReturn                1000
2017-06-03 17:00:38.153406 EDT | AverageEsReturn            38
2017-06-03 17:00:38.153641 EDT | StdEsReturn                37.2249
2017-06-03 17:00:38.153980 EDT | MaxEsReturn               173
2017-06-03 17:00:38.154336 EDT | MinEsReturn                 7
2017-06-03 17:00:38.154664 EDT | AverageDiscountedReturn    99.9957
2017-06-03 17:00:38.154990 EDT | AverageQLoss                3.15357e-05
2017-06-03 17:00:38.155307 EDT | AveragePolicySurr          -0.0914595
2017-06-03 17:00:38.155621 EDT | AverageQ                    0.087334
2017-06-03 17:00:38.155934 EDT | AverageAbsQ                 0.0875804
2017-06-03 17:00:38.156295 EDT | AverageY                    0.0873281
2017-06-03 17:00:38.156630 EDT | AverageAbsY                 0.0873461
2017-06-03 17:00:38.156949 EDT | AverageAbsQYDiff            0.00151157
2017-06-03 17:00:38.157279 EDT | AverageAction               8.32698e-06
2017-06-03 17:00:38.157618 EDT | PolicyRegParamNorm         65.2571
2017-06-03 17:00:38.157947 EDT | QFunRegParamNorm           27.6485
2017-06-03 17:00:38.158277 EDT | -----------------------  --------------
2017-06-03 17:00:38.158757 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #535 | Training started
2017-06-03 17:00:56.500566 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #535 | Training finished
2017-06-03 17:00:56.501430 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #535 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 17:00:56.501703 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #535 | Collecting samples for evaluation
2017-06-03 17:01:05.987799 EDT | -----------------------  --------------
2017-06-03 17:01:05.989232 EDT | Epoch                     535
2017-06-03 17:01:05.989599 EDT | Iteration                 535
2017-06-03 17:01:05.989982 EDT | AverageReturn            1000
2017-06-03 17:01:05.990318 EDT | StdReturn                   0
2017-06-03 17:01:05.990649 EDT | MaxReturn                1000
2017-06-03 17:01:05.990969 EDT | MinReturn                1000
2017-06-03 17:01:05.991346 EDT | AverageEsReturn            35.8519
2017-06-03 17:01:05.991669 EDT | StdEsReturn                36.5845
2017-06-03 17:01:05.992029 EDT | MaxEsReturn               137
2017-06-03 17:01:05.992366 EDT | MinEsReturn                 4
2017-06-03 17:01:05.992692 EDT | AverageDiscountedReturn    99.9957
2017-06-03 17:01:05.993022 EDT | AverageQLoss                2.79178e-05
2017-06-03 17:01:05.993363 EDT | AveragePolicySurr          -0.0913298
2017-06-03 17:01:05.993686 EDT | AverageQ                    0.0872076
2017-06-03 17:01:05.994033 EDT | AverageAbsQ                 0.0874487
2017-06-03 17:01:05.994372 EDT | AverageY                    0.0872081
2017-06-03 17:01:05.994689 EDT | AverageAbsY                 0.0872284
2017-06-03 17:01:05.995017 EDT | AverageAbsQYDiff            0.00146049
2017-06-03 17:01:05.995370 EDT | AverageAction               0.000141717
2017-06-03 17:01:05.995708 EDT | PolicyRegParamNorm         65.2885
2017-06-03 17:01:05.996030 EDT | QFunRegParamNorm           27.6611
2017-06-03 17:01:05.996360 EDT | -----------------------  --------------
2017-06-03 17:01:05.996856 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #536 | Training started
2017-06-03 17:01:25.175001 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #536 | Training finished
2017-06-03 17:01:25.175859 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #536 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 17:01:25.176131 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #536 | Collecting samples for evaluation
2017-06-03 17:01:35.778988 EDT | -----------------------  --------------
2017-06-03 17:01:35.782443 EDT | Epoch                     536
2017-06-03 17:01:35.782742 EDT | Iteration                 536
2017-06-03 17:01:35.782984 EDT | AverageReturn            1000
2017-06-03 17:01:35.783218 EDT | StdReturn                   0
2017-06-03 17:01:35.783450 EDT | MaxReturn                1000
2017-06-03 17:01:35.783690 EDT | MinReturn                1000
2017-06-03 17:01:35.783919 EDT | AverageEsReturn            32.4839
2017-06-03 17:01:35.784148 EDT | StdEsReturn                29.4814
2017-06-03 17:01:35.784376 EDT | MaxEsReturn               110
2017-06-03 17:01:35.784604 EDT | MinEsReturn                 5
2017-06-03 17:01:35.784831 EDT | AverageDiscountedReturn    99.9957
2017-06-03 17:01:35.785059 EDT | AverageQLoss                3.14339e-05
2017-06-03 17:01:35.785285 EDT | AveragePolicySurr          -0.0911597
2017-06-03 17:01:35.785520 EDT | AverageQ                    0.0868565
2017-06-03 17:01:35.786258 EDT | AverageAbsQ                 0.087138
2017-06-03 17:01:35.786582 EDT | AverageY                    0.0868519
2017-06-03 17:01:35.786899 EDT | AverageAbsY                 0.08688
2017-06-03 17:01:35.787215 EDT | AverageAbsQYDiff            0.00153891
2017-06-03 17:01:35.787532 EDT | AverageAction               0.0878096
2017-06-03 17:01:35.787852 EDT | PolicyRegParamNorm         65.2731
2017-06-03 17:01:35.788162 EDT | QFunRegParamNorm           27.6677
2017-06-03 17:01:35.788474 EDT | -----------------------  --------------
2017-06-03 17:01:35.788915 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #537 | Training started
2017-06-03 17:01:53.834953 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #537 | Training finished
2017-06-03 17:01:53.884225 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #537 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 17:01:53.884575 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #537 | Collecting samples for evaluation
2017-06-03 17:02:03.939325 EDT | -----------------------  --------------
2017-06-03 17:02:03.939869 EDT | Epoch                     537
2017-06-03 17:02:03.940200 EDT | Iteration                 537
2017-06-03 17:02:03.940516 EDT | AverageReturn            1000
2017-06-03 17:02:03.940833 EDT | StdReturn                   0
2017-06-03 17:02:03.941145 EDT | MaxReturn                1000
2017-06-03 17:02:03.941454 EDT | MinReturn                1000
2017-06-03 17:02:03.941772 EDT | AverageEsReturn            46.2273
2017-06-03 17:02:03.942086 EDT | StdEsReturn                25.3914
2017-06-03 17:02:03.942396 EDT | MaxEsReturn               104
2017-06-03 17:02:03.942703 EDT | MinEsReturn                 4
2017-06-03 17:02:03.943008 EDT | AverageDiscountedReturn    99.9957
2017-06-03 17:02:03.943332 EDT | AverageQLoss                3.27082e-05
2017-06-03 17:02:03.943641 EDT | AveragePolicySurr          -0.0912276
2017-06-03 17:02:03.943949 EDT | AverageQ                    0.0870809
2017-06-03 17:02:03.944255 EDT | AverageAbsQ                 0.0873857
2017-06-03 17:02:03.944566 EDT | AverageY                    0.0870813
2017-06-03 17:02:03.944881 EDT | AverageAbsY                 0.0871078
2017-06-03 17:02:03.945186 EDT | AverageAbsQYDiff            0.00162926
2017-06-03 17:02:03.945491 EDT | AverageAction               0.00123725
2017-06-03 17:02:03.945806 EDT | PolicyRegParamNorm         65.3169
2017-06-03 17:02:03.946118 EDT | QFunRegParamNorm           27.6503
2017-06-03 17:02:03.946421 EDT | -----------------------  --------------
2017-06-03 17:02:03.946841 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #538 | Training started
2017-06-03 17:02:22.807726 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #538 | Training finished
2017-06-03 17:02:22.808653 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #538 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 17:02:22.808927 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #538 | Collecting samples for evaluation
2017-06-03 17:02:31.362419 EDT | -----------------------  --------------
2017-06-03 17:02:31.363450 EDT | Epoch                     538
2017-06-03 17:02:31.363719 EDT | Iteration                 538
2017-06-03 17:02:31.363959 EDT | AverageReturn            1000
2017-06-03 17:02:31.364203 EDT | StdReturn                   0
2017-06-03 17:02:31.364434 EDT | MaxReturn                1000
2017-06-03 17:02:31.364665 EDT | MinReturn                1000
2017-06-03 17:02:31.364899 EDT | AverageEsReturn            43.125
2017-06-03 17:02:31.365138 EDT | StdEsReturn                49.4034
2017-06-03 17:02:31.365374 EDT | MaxEsReturn               257
2017-06-03 17:02:31.365603 EDT | MinEsReturn                 6
2017-06-03 17:02:31.366161 EDT | AverageDiscountedReturn    99.9957
2017-06-03 17:02:31.366411 EDT | AverageQLoss                2.77222e-05
2017-06-03 17:02:31.366657 EDT | AveragePolicySurr          -0.0912203
2017-06-03 17:02:31.366903 EDT | AverageQ                    0.0871943
2017-06-03 17:02:31.367169 EDT | AverageAbsQ                 0.0874285
2017-06-03 17:02:31.367413 EDT | AverageY                    0.0871983
2017-06-03 17:02:31.367662 EDT | AverageAbsY                 0.0872092
2017-06-03 17:02:31.367905 EDT | AverageAbsQYDiff            0.00139385
2017-06-03 17:02:31.368148 EDT | AverageAction               0.00182219
2017-06-03 17:02:31.368397 EDT | PolicyRegParamNorm         65.3826
2017-06-03 17:02:31.368653 EDT | QFunRegParamNorm           27.652
2017-06-03 17:02:31.368895 EDT | -----------------------  --------------
2017-06-03 17:02:31.369288 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #539 | Training started
2017-06-03 17:02:50.488224 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #539 | Training finished
2017-06-03 17:02:50.489264 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #539 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 17:02:50.489587 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #539 | Collecting samples for evaluation
2017-06-03 17:03:00.384179 EDT | -----------------------  --------------
2017-06-03 17:03:00.385027 EDT | Epoch                     539
2017-06-03 17:03:00.385362 EDT | Iteration                 539
2017-06-03 17:03:00.385622 EDT | AverageReturn            1000
2017-06-03 17:03:00.386055 EDT | StdReturn                   0
2017-06-03 17:03:00.386488 EDT | MaxReturn                1000
2017-06-03 17:03:00.386844 EDT | MinReturn                1000
2017-06-03 17:03:00.387274 EDT | AverageEsReturn            31.2581
2017-06-03 17:03:00.387631 EDT | StdEsReturn                24.45
2017-06-03 17:03:00.388034 EDT | MaxEsReturn               103
2017-06-03 17:03:00.388447 EDT | MinEsReturn                 3
2017-06-03 17:03:00.388876 EDT | AverageDiscountedReturn    99.9957
2017-06-03 17:03:00.389321 EDT | AverageQLoss                2.76509e-05
2017-06-03 17:03:00.389765 EDT | AveragePolicySurr          -0.0913138
2017-06-03 17:03:00.390182 EDT | AverageQ                    0.0871695
2017-06-03 17:03:00.391221 EDT | AverageAbsQ                 0.0873662
2017-06-03 17:03:00.391634 EDT | AverageY                    0.0871719
2017-06-03 17:03:00.391964 EDT | AverageAbsY                 0.0871818
2017-06-03 17:03:00.392389 EDT | AverageAbsQYDiff            0.00140601
2017-06-03 17:03:00.392765 EDT | AverageAction               0.00155124
2017-06-03 17:03:00.393112 EDT | PolicyRegParamNorm         65.4152
2017-06-03 17:03:00.393534 EDT | QFunRegParamNorm           27.6752
2017-06-03 17:03:00.393883 EDT | -----------------------  --------------
2017-06-03 17:03:00.394407 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #540 | Training started
2017-06-03 17:03:20.468388 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #540 | Training finished
2017-06-03 17:03:20.469348 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #540 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 17:03:20.469801 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #540 | Collecting samples for evaluation
2017-06-03 17:03:30.990076 EDT | -----------------------  --------------
2017-06-03 17:03:30.990945 EDT | Epoch                     540
2017-06-03 17:03:30.991243 EDT | Iteration                 540
2017-06-03 17:03:30.991524 EDT | AverageReturn            1000
2017-06-03 17:03:30.991813 EDT | StdReturn                   0
2017-06-03 17:03:30.992055 EDT | MaxReturn                1000
2017-06-03 17:03:30.992290 EDT | MinReturn                1000
2017-06-03 17:03:30.992528 EDT | AverageEsReturn            40.92
2017-06-03 17:03:30.992831 EDT | StdEsReturn                23.9648
2017-06-03 17:03:30.993097 EDT | MaxEsReturn                95
2017-06-03 17:03:30.993381 EDT | MinEsReturn                11
2017-06-03 17:03:30.993640 EDT | AverageDiscountedReturn    99.9957
2017-06-03 17:03:30.993882 EDT | AverageQLoss                2.77676e-05
2017-06-03 17:03:30.994126 EDT | AveragePolicySurr          -0.0912406
2017-06-03 17:03:30.994356 EDT | AverageQ                    0.0871051
2017-06-03 17:03:30.994586 EDT | AverageAbsQ                 0.0873201
2017-06-03 17:03:30.994826 EDT | AverageY                    0.0871015
2017-06-03 17:03:30.995055 EDT | AverageAbsY                 0.0871167
2017-06-03 17:03:30.995282 EDT | AverageAbsQYDiff            0.00137801
2017-06-03 17:03:30.995507 EDT | AverageAction               0.0572477
2017-06-03 17:03:30.995732 EDT | PolicyRegParamNorm         65.4574
2017-06-03 17:03:30.995958 EDT | QFunRegParamNorm           27.6803
2017-06-03 17:03:30.996202 EDT | -----------------------  --------------
2017-06-03 17:03:30.996603 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #541 | Training started
2017-06-03 17:03:49.904620 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #541 | Training finished
2017-06-03 17:03:49.905444 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #541 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 17:03:49.906052 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #541 | Collecting samples for evaluation
2017-06-03 17:04:00.349954 EDT | -----------------------  -------------
2017-06-03 17:04:00.350816 EDT | Epoch                     541
2017-06-03 17:04:00.351091 EDT | Iteration                 541
2017-06-03 17:04:00.351341 EDT | AverageReturn            1000
2017-06-03 17:04:00.351588 EDT | StdReturn                   0
2017-06-03 17:04:00.351842 EDT | MaxReturn                1000
2017-06-03 17:04:00.352085 EDT | MinReturn                1000
2017-06-03 17:04:00.352332 EDT | AverageEsReturn            31.4375
2017-06-03 17:04:00.352581 EDT | StdEsReturn                26.8444
2017-06-03 17:04:00.352829 EDT | MaxEsReturn               114
2017-06-03 17:04:00.353070 EDT | MinEsReturn                 3
2017-06-03 17:04:00.353311 EDT | AverageDiscountedReturn    99.9957
2017-06-03 17:04:00.353551 EDT | AverageQLoss                3.1208e-05
2017-06-03 17:04:00.353804 EDT | AveragePolicySurr          -0.0911602
2017-06-03 17:04:00.354046 EDT | AverageQ                    0.0869389
2017-06-03 17:04:00.354288 EDT | AverageAbsQ                 0.0872348
2017-06-03 17:04:00.354528 EDT | AverageY                    0.0869417
2017-06-03 17:04:00.354769 EDT | AverageAbsY                 0.0869545
2017-06-03 17:04:00.355010 EDT | AverageAbsQYDiff            0.0014714
2017-06-03 17:04:00.355251 EDT | AverageAction               8.2365e-06
2017-06-03 17:04:00.355571 EDT | PolicyRegParamNorm         65.4408
2017-06-03 17:04:00.355887 EDT | QFunRegParamNorm           27.6805
2017-06-03 17:04:00.356199 EDT | -----------------------  -------------
2017-06-03 17:04:00.356628 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #542 | Training started
2017-06-03 17:04:19.160139 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #542 | Training finished
2017-06-03 17:04:19.162835 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #542 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 17:04:19.163193 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #542 | Collecting samples for evaluation
2017-06-03 17:04:27.488391 EDT | -----------------------  --------------
2017-06-03 17:04:27.489238 EDT | Epoch                     542
2017-06-03 17:04:27.489540 EDT | Iteration                 542
2017-06-03 17:04:27.489803 EDT | AverageReturn            1000
2017-06-03 17:04:27.490051 EDT | StdReturn                   0
2017-06-03 17:04:27.490296 EDT | MaxReturn                1000
2017-06-03 17:04:27.490555 EDT | MinReturn                1000
2017-06-03 17:04:27.490918 EDT | AverageEsReturn            23.0698
2017-06-03 17:04:27.491247 EDT | StdEsReturn                15.6924
2017-06-03 17:04:27.491582 EDT | MaxEsReturn                70
2017-06-03 17:04:27.491902 EDT | MinEsReturn                 4
2017-06-03 17:04:27.492220 EDT | AverageDiscountedReturn    99.9957
2017-06-03 17:04:27.492542 EDT | AverageQLoss                3.03587e-05
2017-06-03 17:04:27.492862 EDT | AveragePolicySurr          -0.0910289
2017-06-03 17:04:27.493181 EDT | AverageQ                    0.0868225
2017-06-03 17:04:27.493495 EDT | AverageAbsQ                 0.0870652
2017-06-03 17:04:27.493823 EDT | AverageY                    0.086821
2017-06-03 17:04:27.494156 EDT | AverageAbsY                 0.0868281
2017-06-03 17:04:27.494488 EDT | AverageAbsQYDiff            0.00154472
2017-06-03 17:04:27.494803 EDT | AverageAction               1.03197e-05
2017-06-03 17:04:27.495122 EDT | PolicyRegParamNorm         65.5043
2017-06-03 17:04:27.495444 EDT | QFunRegParamNorm           27.6732
2017-06-03 17:04:27.495766 EDT | -----------------------  --------------
2017-06-03 17:04:27.496292 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #543 | Training started
2017-06-03 17:04:45.639293 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #543 | Training finished
2017-06-03 17:04:45.640191 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #543 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 17:04:45.640545 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #543 | Collecting samples for evaluation
2017-06-03 17:04:54.830075 EDT | -----------------------  --------------
2017-06-03 17:04:54.830947 EDT | Epoch                     543
2017-06-03 17:04:54.831214 EDT | Iteration                 543
2017-06-03 17:04:54.831463 EDT | AverageReturn            1000
2017-06-03 17:04:54.831726 EDT | StdReturn                   0
2017-06-03 17:04:54.831961 EDT | MaxReturn                1000
2017-06-03 17:04:54.832197 EDT | MinReturn                1000
2017-06-03 17:04:54.832430 EDT | AverageEsReturn            24.175
2017-06-03 17:04:54.832678 EDT | StdEsReturn                20.636
2017-06-03 17:04:54.832916 EDT | MaxEsReturn                89
2017-06-03 17:04:54.833171 EDT | MinEsReturn                 4
2017-06-03 17:04:54.833402 EDT | AverageDiscountedReturn    99.9957
2017-06-03 17:04:54.833637 EDT | AverageQLoss                2.84238e-05
2017-06-03 17:04:54.833885 EDT | AveragePolicySurr          -0.0911756
2017-06-03 17:04:54.834119 EDT | AverageQ                    0.0870524
2017-06-03 17:04:54.834364 EDT | AverageAbsQ                 0.0872819
2017-06-03 17:04:54.834600 EDT | AverageY                    0.0870501
2017-06-03 17:04:54.834852 EDT | AverageAbsY                 0.0870612
2017-06-03 17:04:54.835081 EDT | AverageAbsQYDiff            0.00148614
2017-06-03 17:04:54.835310 EDT | AverageAction               0.000116765
2017-06-03 17:04:54.835540 EDT | PolicyRegParamNorm         65.5558
2017-06-03 17:04:54.835781 EDT | QFunRegParamNorm           27.6817
2017-06-03 17:04:54.836051 EDT | -----------------------  --------------
2017-06-03 17:04:54.836433 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #544 | Training started
2017-06-03 17:05:13.041298 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #544 | Training finished
2017-06-03 17:05:13.042241 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #544 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 17:05:13.042518 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #544 | Collecting samples for evaluation
2017-06-03 17:05:23.099162 EDT | -----------------------  --------------
2017-06-03 17:05:23.100155 EDT | Epoch                     544
2017-06-03 17:05:23.100427 EDT | Iteration                 544
2017-06-03 17:05:23.100666 EDT | AverageReturn            1000
2017-06-03 17:05:23.100910 EDT | StdReturn                   0
2017-06-03 17:05:23.101141 EDT | MaxReturn                1000
2017-06-03 17:05:23.101371 EDT | MinReturn                1000
2017-06-03 17:05:23.101601 EDT | AverageEsReturn            28.1351
2017-06-03 17:05:23.101842 EDT | StdEsReturn                25.0827
2017-06-03 17:05:23.102072 EDT | MaxEsReturn               110
2017-06-03 17:05:23.102304 EDT | MinEsReturn                 4
2017-06-03 17:05:23.102532 EDT | AverageDiscountedReturn    99.9957
2017-06-03 17:05:23.102759 EDT | AverageQLoss                2.94195e-05
2017-06-03 17:05:23.102987 EDT | AveragePolicySurr          -0.091191
2017-06-03 17:05:23.103214 EDT | AverageQ                    0.0869702
2017-06-03 17:05:23.103446 EDT | AverageAbsQ                 0.0872551
2017-06-03 17:05:23.103673 EDT | AverageY                    0.0869758
2017-06-03 17:05:23.103900 EDT | AverageAbsY                 0.0870023
2017-06-03 17:05:23.104126 EDT | AverageAbsQYDiff            0.00153469
2017-06-03 17:05:23.104353 EDT | AverageAction               1.09518e-05
2017-06-03 17:05:23.104581 EDT | PolicyRegParamNorm         65.5934
2017-06-03 17:05:23.104807 EDT | QFunRegParamNorm           27.6993
2017-06-03 17:05:23.105034 EDT | -----------------------  --------------
2017-06-03 17:05:23.105411 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #545 | Training started
2017-06-03 17:05:40.402039 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #545 | Training finished
2017-06-03 17:05:40.402918 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #545 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 17:05:40.403183 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #545 | Collecting samples for evaluation
2017-06-03 17:05:49.590228 EDT | -----------------------  --------------
2017-06-03 17:05:49.591077 EDT | Epoch                     545
2017-06-03 17:05:49.591337 EDT | Iteration                 545
2017-06-03 17:05:49.591587 EDT | AverageReturn            1000
2017-06-03 17:05:49.591824 EDT | StdReturn                   0
2017-06-03 17:05:49.592057 EDT | MaxReturn                1000
2017-06-03 17:05:49.592290 EDT | MinReturn                1000
2017-06-03 17:05:49.592523 EDT | AverageEsReturn            22.7045
2017-06-03 17:05:49.592755 EDT | StdEsReturn                21.6139
2017-06-03 17:05:49.592986 EDT | MaxEsReturn                97
2017-06-03 17:05:49.593234 EDT | MinEsReturn                 4
2017-06-03 17:05:49.593468 EDT | AverageDiscountedReturn    99.9957
2017-06-03 17:05:49.593705 EDT | AverageQLoss                2.57791e-05
2017-06-03 17:05:49.593942 EDT | AveragePolicySurr          -0.0910789
2017-06-03 17:05:49.594174 EDT | AverageQ                    0.0869377
2017-06-03 17:05:49.594404 EDT | AverageAbsQ                 0.0871708
2017-06-03 17:05:49.594635 EDT | AverageY                    0.0869304
2017-06-03 17:05:49.594866 EDT | AverageAbsY                 0.0869464
2017-06-03 17:05:49.595096 EDT | AverageAbsQYDiff            0.00139754
2017-06-03 17:05:49.595327 EDT | AverageAction               2.51015e-05
2017-06-03 17:05:49.595568 EDT | PolicyRegParamNorm         65.6269
2017-06-03 17:05:49.595799 EDT | QFunRegParamNorm           27.7213
2017-06-03 17:05:49.596030 EDT | -----------------------  --------------
2017-06-03 17:05:49.596381 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #546 | Training started
2017-06-03 17:06:09.001155 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #546 | Training finished
2017-06-03 17:06:09.002140 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #546 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 17:06:09.002540 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #546 | Collecting samples for evaluation
2017-06-03 17:06:18.759750 EDT | -----------------------  --------------
2017-06-03 17:06:18.760567 EDT | Epoch                     546
2017-06-03 17:06:18.760806 EDT | Iteration                 546
2017-06-03 17:06:18.761024 EDT | AverageReturn            1000
2017-06-03 17:06:18.761280 EDT | StdReturn                   0
2017-06-03 17:06:18.761506 EDT | MaxReturn                1000
2017-06-03 17:06:18.761752 EDT | MinReturn                1000
2017-06-03 17:06:18.761984 EDT | AverageEsReturn            32.3793
2017-06-03 17:06:18.762205 EDT | StdEsReturn                27.6772
2017-06-03 17:06:18.762434 EDT | MaxEsReturn               127
2017-06-03 17:06:18.762670 EDT | MinEsReturn                 6
2017-06-03 17:06:18.762946 EDT | AverageDiscountedReturn    99.9957
2017-06-03 17:06:18.763163 EDT | AverageQLoss                3.32411e-05
2017-06-03 17:06:18.763380 EDT | AveragePolicySurr          -0.0909799
2017-06-03 17:06:18.763592 EDT | AverageQ                    0.0868844
2017-06-03 17:06:18.763803 EDT | AverageAbsQ                 0.087132
2017-06-03 17:06:18.764015 EDT | AverageY                    0.0868879
2017-06-03 17:06:18.764226 EDT | AverageAbsY                 0.0869017
2017-06-03 17:06:18.764436 EDT | AverageAbsQYDiff            0.00154594
2017-06-03 17:06:18.764653 EDT | AverageAction               0.0816501
2017-06-03 17:06:18.764864 EDT | PolicyRegParamNorm         65.6662
2017-06-03 17:06:18.765075 EDT | QFunRegParamNorm           27.7191
2017-06-03 17:06:18.765286 EDT | -----------------------  --------------
2017-06-03 17:06:18.765715 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #547 | Training started
2017-06-03 17:06:38.098478 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #547 | Training finished
2017-06-03 17:06:38.099384 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #547 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 17:06:38.099655 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #547 | Collecting samples for evaluation
2017-06-03 17:06:47.444014 EDT | -----------------------  --------------
2017-06-03 17:06:47.444879 EDT | Epoch                     547
2017-06-03 17:06:47.445142 EDT | Iteration                 547
2017-06-03 17:06:47.445384 EDT | AverageReturn            1000
2017-06-03 17:06:47.445654 EDT | StdReturn                   0
2017-06-03 17:06:47.445898 EDT | MaxReturn                1000
2017-06-03 17:06:47.446129 EDT | MinReturn                1000
2017-06-03 17:06:47.446357 EDT | AverageEsReturn            25.7073
2017-06-03 17:06:47.446595 EDT | StdEsReturn                22.689
2017-06-03 17:06:47.446835 EDT | MaxEsReturn               124
2017-06-03 17:06:47.447065 EDT | MinEsReturn                 4
2017-06-03 17:06:47.447292 EDT | AverageDiscountedReturn    99.9957
2017-06-03 17:06:47.447518 EDT | AverageQLoss                3.07416e-05
2017-06-03 17:06:47.447746 EDT | AveragePolicySurr          -0.0911563
2017-06-03 17:06:47.447972 EDT | AverageQ                    0.0870159
2017-06-03 17:06:47.448208 EDT | AverageAbsQ                 0.0873156
2017-06-03 17:06:47.448436 EDT | AverageY                    0.087023
2017-06-03 17:06:47.448662 EDT | AverageAbsY                 0.0870406
2017-06-03 17:06:47.448888 EDT | AverageAbsQYDiff            0.00153746
2017-06-03 17:06:47.449112 EDT | AverageAction               6.09941e-05
2017-06-03 17:06:47.449337 EDT | PolicyRegParamNorm         65.6975
2017-06-03 17:06:47.449563 EDT | QFunRegParamNorm           27.7194
2017-06-03 17:06:47.449923 EDT | -----------------------  --------------
2017-06-03 17:06:47.450287 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #548 | Training started
2017-06-03 17:07:06.793133 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #548 | Training finished
2017-06-03 17:07:06.794705 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #548 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 17:07:06.794986 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #548 | Collecting samples for evaluation
2017-06-03 17:07:16.084674 EDT | -----------------------  -------------
2017-06-03 17:07:16.085520 EDT | Epoch                     548
2017-06-03 17:07:16.085791 EDT | Iteration                 548
2017-06-03 17:07:16.086039 EDT | AverageReturn            1000
2017-06-03 17:07:16.086277 EDT | StdReturn                   0
2017-06-03 17:07:16.086522 EDT | MaxReturn                1000
2017-06-03 17:07:16.086756 EDT | MinReturn                1000
2017-06-03 17:07:16.086990 EDT | AverageEsReturn            23.0233
2017-06-03 17:07:16.087224 EDT | StdEsReturn                17.1295
2017-06-03 17:07:16.087459 EDT | MaxEsReturn                65
2017-06-03 17:07:16.087692 EDT | MinEsReturn                 3
2017-06-03 17:07:16.088021 EDT | AverageDiscountedReturn    99.9957
2017-06-03 17:07:16.088343 EDT | AverageQLoss                2.9002e-05
2017-06-03 17:07:16.088660 EDT | AveragePolicySurr          -0.0911523
2017-06-03 17:07:16.088985 EDT | AverageQ                    0.0870543
2017-06-03 17:07:16.089300 EDT | AverageAbsQ                 0.0872753
2017-06-03 17:07:16.089615 EDT | AverageY                    0.087045
2017-06-03 17:07:16.089944 EDT | AverageAbsY                 0.0870637
2017-06-03 17:07:16.090255 EDT | AverageAbsQYDiff            0.00145068
2017-06-03 17:07:16.090567 EDT | AverageAction               0.00011745
2017-06-03 17:07:16.090877 EDT | PolicyRegParamNorm         65.7213
2017-06-03 17:07:16.091185 EDT | QFunRegParamNorm           27.7302
2017-06-03 17:07:16.091502 EDT | -----------------------  -------------
2017-06-03 17:07:16.091930 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #549 | Training started
2017-06-03 17:07:34.139927 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #549 | Training finished
2017-06-03 17:07:34.140989 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #549 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 17:07:34.141390 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #549 | Collecting samples for evaluation
2017-06-03 17:07:42.886170 EDT | -----------------------  --------------
2017-06-03 17:07:42.886702 EDT | Epoch                     549
2017-06-03 17:07:42.887033 EDT | Iteration                 549
2017-06-03 17:07:42.887351 EDT | AverageReturn            1000
2017-06-03 17:07:42.887675 EDT | StdReturn                   0
2017-06-03 17:07:42.887987 EDT | MaxReturn                1000
2017-06-03 17:07:42.888322 EDT | MinReturn                1000
2017-06-03 17:07:42.888632 EDT | AverageEsReturn            33.8333
2017-06-03 17:07:42.888943 EDT | StdEsReturn                27.6888
2017-06-03 17:07:42.889267 EDT | MaxEsReturn               132
2017-06-03 17:07:42.889584 EDT | MinEsReturn                 5
2017-06-03 17:07:42.889923 EDT | AverageDiscountedReturn    99.9957
2017-06-03 17:07:42.890234 EDT | AverageQLoss                2.6356e-05
2017-06-03 17:07:42.890548 EDT | AveragePolicySurr          -0.0910997
2017-06-03 17:07:42.890865 EDT | AverageQ                    0.0870257
2017-06-03 17:07:42.891178 EDT | AverageAbsQ                 0.0872616
2017-06-03 17:07:42.891507 EDT | AverageY                    0.0870297
2017-06-03 17:07:42.891811 EDT | AverageAbsY                 0.0870458
2017-06-03 17:07:42.892116 EDT | AverageAbsQYDiff            0.00147491
2017-06-03 17:07:42.892422 EDT | AverageAction               0.000161273
2017-06-03 17:07:42.892736 EDT | PolicyRegParamNorm         65.7732
2017-06-03 17:07:42.893037 EDT | QFunRegParamNorm           27.7189
2017-06-03 17:07:42.893369 EDT | -----------------------  --------------
2017-06-03 17:07:42.893827 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #550 | Training started
2017-06-03 17:08:00.895863 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #550 | Training finished
2017-06-03 17:08:00.910398 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #550 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 17:08:00.910753 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #550 | Collecting samples for evaluation
2017-06-03 17:08:10.863799 EDT | -----------------------  --------------
2017-06-03 17:08:10.864392 EDT | Epoch                     550
2017-06-03 17:08:10.864658 EDT | Iteration                 550
2017-06-03 17:08:10.864911 EDT | AverageReturn            1000
2017-06-03 17:08:10.865154 EDT | StdReturn                   0
2017-06-03 17:08:10.865392 EDT | MaxReturn                1000
2017-06-03 17:08:10.865629 EDT | MinReturn                1000
2017-06-03 17:08:10.865897 EDT | AverageEsReturn            34.4138
2017-06-03 17:08:10.866138 EDT | StdEsReturn                29.3017
2017-06-03 17:08:10.866403 EDT | MaxEsReturn               119
2017-06-03 17:08:10.866653 EDT | MinEsReturn                 5
2017-06-03 17:08:10.866905 EDT | AverageDiscountedReturn    99.9957
2017-06-03 17:08:10.867240 EDT | AverageQLoss                2.82535e-05
2017-06-03 17:08:10.867573 EDT | AveragePolicySurr          -0.0909782
2017-06-03 17:08:10.867908 EDT | AverageQ                    0.0867705
2017-06-03 17:08:10.868347 EDT | AverageAbsQ                 0.0869869
2017-06-03 17:08:10.868795 EDT | AverageY                    0.0867736
2017-06-03 17:08:10.869125 EDT | AverageAbsY                 0.0867933
2017-06-03 17:08:10.869446 EDT | AverageAbsQYDiff            0.00142734
2017-06-03 17:08:10.869771 EDT | AverageAction               1.10414e-05
2017-06-03 17:08:10.870103 EDT | PolicyRegParamNorm         65.8211
2017-06-03 17:08:10.870461 EDT | QFunRegParamNorm           27.7358
2017-06-03 17:08:10.870776 EDT | -----------------------  --------------
2017-06-03 17:08:10.871244 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #551 | Training started
2017-06-03 17:08:30.241445 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #551 | Training finished
2017-06-03 17:08:30.242432 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #551 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 17:08:30.242836 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #551 | Collecting samples for evaluation
2017-06-03 17:08:40.137737 EDT | -----------------------  --------------
2017-06-03 17:08:40.138561 EDT | Epoch                     551
2017-06-03 17:08:40.138824 EDT | Iteration                 551
2017-06-03 17:08:40.139070 EDT | AverageReturn            1000
2017-06-03 17:08:40.139329 EDT | StdReturn                   0
2017-06-03 17:08:40.139565 EDT | MaxReturn                1000
2017-06-03 17:08:40.139794 EDT | MinReturn                1000
2017-06-03 17:08:40.140022 EDT | AverageEsReturn            30.0303
2017-06-03 17:08:40.140249 EDT | StdEsReturn                21.5259
2017-06-03 17:08:40.140490 EDT | MaxEsReturn                83
2017-06-03 17:08:40.140721 EDT | MinEsReturn                 5
2017-06-03 17:08:40.140945 EDT | AverageDiscountedReturn    99.9957
2017-06-03 17:08:40.141184 EDT | AverageQLoss                3.08815e-05
2017-06-03 17:08:40.141426 EDT | AveragePolicySurr          -0.0908215
2017-06-03 17:08:40.141662 EDT | AverageQ                    0.0866927
2017-06-03 17:08:40.141920 EDT | AverageAbsQ                 0.0869889
2017-06-03 17:08:40.142158 EDT | AverageY                    0.0866875
2017-06-03 17:08:40.142395 EDT | AverageAbsY                 0.0867217
2017-06-03 17:08:40.142631 EDT | AverageAbsQYDiff            0.00156295
2017-06-03 17:08:40.142867 EDT | AverageAction               0.00529851
2017-06-03 17:08:40.143181 EDT | PolicyRegParamNorm         65.887
2017-06-03 17:08:40.143493 EDT | QFunRegParamNorm           27.7311
2017-06-03 17:08:40.143799 EDT | -----------------------  --------------
2017-06-03 17:08:40.144252 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #552 | Training started
2017-06-03 17:08:58.793297 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #552 | Training finished
2017-06-03 17:08:58.794390 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #552 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 17:08:58.794777 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #552 | Collecting samples for evaluation
2017-06-03 17:09:08.226281 EDT | -----------------------  --------------
2017-06-03 17:09:08.227184 EDT | Epoch                     552
2017-06-03 17:09:08.227471 EDT | Iteration                 552
2017-06-03 17:09:08.227776 EDT | AverageReturn            1000
2017-06-03 17:09:08.228032 EDT | StdReturn                   0
2017-06-03 17:09:08.228285 EDT | MaxReturn                1000
2017-06-03 17:09:08.228536 EDT | MinReturn                1000
2017-06-03 17:09:08.228804 EDT | AverageEsReturn            24.975
2017-06-03 17:09:08.229053 EDT | StdEsReturn                15.2307
2017-06-03 17:09:08.229303 EDT | MaxEsReturn                65
2017-06-03 17:09:08.229550 EDT | MinEsReturn                 5
2017-06-03 17:09:08.229853 EDT | AverageDiscountedReturn    99.9957
2017-06-03 17:09:08.230101 EDT | AverageQLoss                2.63205e-05
2017-06-03 17:09:08.230350 EDT | AveragePolicySurr          -0.0909973
2017-06-03 17:09:08.230601 EDT | AverageQ                    0.0868447
2017-06-03 17:09:08.230868 EDT | AverageAbsQ                 0.0870947
2017-06-03 17:09:08.231114 EDT | AverageY                    0.0868428
2017-06-03 17:09:08.231359 EDT | AverageAbsY                 0.0868728
2017-06-03 17:09:08.231604 EDT | AverageAbsQYDiff            0.00145761
2017-06-03 17:09:08.231871 EDT | AverageAction               0.000148882
2017-06-03 17:09:08.232118 EDT | PolicyRegParamNorm         65.9693
2017-06-03 17:09:08.232363 EDT | QFunRegParamNorm           27.7544
2017-06-03 17:09:08.232609 EDT | -----------------------  --------------
2017-06-03 17:09:08.233075 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #553 | Training started
2017-06-03 17:09:27.152012 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #553 | Training finished
2017-06-03 17:09:27.152974 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #553 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 17:09:27.153265 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #553 | Collecting samples for evaluation
2017-06-03 17:09:36.886654 EDT | -----------------------  --------------
2017-06-03 17:09:36.887523 EDT | Epoch                     553
2017-06-03 17:09:36.887789 EDT | Iteration                 553
2017-06-03 17:09:36.888029 EDT | AverageReturn            1000
2017-06-03 17:09:36.888271 EDT | StdReturn                   0
2017-06-03 17:09:36.888502 EDT | MaxReturn                1000
2017-06-03 17:09:36.888733 EDT | MinReturn                1000
2017-06-03 17:09:36.888962 EDT | AverageEsReturn            24.6154
2017-06-03 17:09:36.889193 EDT | StdEsReturn                18.5536
2017-06-03 17:09:36.889423 EDT | MaxEsReturn               101
2017-06-03 17:09:36.889651 EDT | MinEsReturn                 4
2017-06-03 17:09:36.889934 EDT | AverageDiscountedReturn    99.9957
2017-06-03 17:09:36.890201 EDT | AverageQLoss                2.89567e-05
2017-06-03 17:09:36.890461 EDT | AveragePolicySurr          -0.0909715
2017-06-03 17:09:36.890720 EDT | AverageQ                    0.0868699
2017-06-03 17:09:36.890978 EDT | AverageAbsQ                 0.087135
2017-06-03 17:09:36.891235 EDT | AverageY                    0.0868721
2017-06-03 17:09:36.891492 EDT | AverageAbsY                 0.086902
2017-06-03 17:09:36.891781 EDT | AverageAbsQYDiff            0.00147578
2017-06-03 17:09:36.892036 EDT | AverageAction               0.00183171
2017-06-03 17:09:36.892290 EDT | PolicyRegParamNorm         65.9744
2017-06-03 17:09:36.892548 EDT | QFunRegParamNorm           27.7617
2017-06-03 17:09:36.892811 EDT | -----------------------  --------------
2017-06-03 17:09:36.893234 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #554 | Training started
2017-06-03 17:09:55.013677 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #554 | Training finished
2017-06-03 17:09:55.017611 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #554 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 17:09:55.017906 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #554 | Collecting samples for evaluation
2017-06-03 17:10:05.733978 EDT | -----------------------  --------------
2017-06-03 17:10:05.735008 EDT | Epoch                     554
2017-06-03 17:10:05.735365 EDT | Iteration                 554
2017-06-03 17:10:05.735689 EDT | AverageReturn            1000
2017-06-03 17:10:05.736006 EDT | StdReturn                   0
2017-06-03 17:10:05.736331 EDT | MaxReturn                1000
2017-06-03 17:10:05.736643 EDT | MinReturn                1000
2017-06-03 17:10:05.736953 EDT | AverageEsReturn            30.4412
2017-06-03 17:10:05.737269 EDT | StdEsReturn                22.4567
2017-06-03 17:10:05.737580 EDT | MaxEsReturn               113
2017-06-03 17:10:05.737912 EDT | MinEsReturn                 3
2017-06-03 17:10:05.738221 EDT | AverageDiscountedReturn    99.9957
2017-06-03 17:10:05.738528 EDT | AverageQLoss                2.98681e-05
2017-06-03 17:10:05.738837 EDT | AveragePolicySurr          -0.0908149
2017-06-03 17:10:05.739143 EDT | AverageQ                    0.0868133
2017-06-03 17:10:05.739449 EDT | AverageAbsQ                 0.087076
2017-06-03 17:10:05.739753 EDT | AverageY                    0.0868138
2017-06-03 17:10:05.740061 EDT | AverageAbsY                 0.0868507
2017-06-03 17:10:05.740365 EDT | AverageAbsQYDiff            0.00146465
2017-06-03 17:10:05.740669 EDT | AverageAction               0.00569192
2017-06-03 17:10:05.740971 EDT | PolicyRegParamNorm         65.9983
2017-06-03 17:10:05.741273 EDT | QFunRegParamNorm           27.7717
2017-06-03 17:10:05.741576 EDT | -----------------------  --------------
2017-06-03 17:10:05.742054 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #555 | Training started
2017-06-03 17:10:25.113121 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #555 | Training finished
2017-06-03 17:10:25.115863 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #555 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 17:10:25.116151 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #555 | Collecting samples for evaluation
2017-06-03 17:10:34.560811 EDT | -----------------------  --------------
2017-06-03 17:10:34.561699 EDT | Epoch                     555
2017-06-03 17:10:34.561960 EDT | Iteration                 555
2017-06-03 17:10:34.562202 EDT | AverageReturn            1000
2017-06-03 17:10:34.562439 EDT | StdReturn                   0
2017-06-03 17:10:34.562675 EDT | MaxReturn                1000
2017-06-03 17:10:34.562908 EDT | MinReturn                1000
2017-06-03 17:10:34.563141 EDT | AverageEsReturn            27.4865
2017-06-03 17:10:34.563380 EDT | StdEsReturn                20.157
2017-06-03 17:10:34.563612 EDT | MaxEsReturn                80
2017-06-03 17:10:34.563844 EDT | MinEsReturn                 3
2017-06-03 17:10:34.564076 EDT | AverageDiscountedReturn    99.9957
2017-06-03 17:10:34.564308 EDT | AverageQLoss                2.67534e-05
2017-06-03 17:10:34.564545 EDT | AveragePolicySurr          -0.0907389
2017-06-03 17:10:34.564777 EDT | AverageQ                    0.0866504
2017-06-03 17:10:34.565014 EDT | AverageAbsQ                 0.0869001
2017-06-03 17:10:34.565245 EDT | AverageY                    0.0866513
2017-06-03 17:10:34.565477 EDT | AverageAbsY                 0.0866813
2017-06-03 17:10:34.565741 EDT | AverageAbsQYDiff            0.00135148
2017-06-03 17:10:34.565985 EDT | AverageAction               0.00308406
2017-06-03 17:10:34.566224 EDT | PolicyRegParamNorm         66.033
2017-06-03 17:10:34.566458 EDT | QFunRegParamNorm           27.7765
2017-06-03 17:10:34.566708 EDT | -----------------------  --------------
2017-06-03 17:10:34.567097 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #556 | Training started
2017-06-03 17:10:53.555447 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #556 | Training finished
2017-06-03 17:10:53.556290 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #556 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 17:10:53.556565 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #556 | Collecting samples for evaluation
2017-06-03 17:11:04.660833 EDT | -----------------------  --------------
2017-06-03 17:11:04.661209 EDT | Epoch                     556
2017-06-03 17:11:04.661452 EDT | Iteration                 556
2017-06-03 17:11:04.661686 EDT | AverageReturn            1000
2017-06-03 17:11:04.661947 EDT | StdReturn                   0
2017-06-03 17:11:04.662187 EDT | MaxReturn                1000
2017-06-03 17:11:04.662471 EDT | MinReturn                1000
2017-06-03 17:11:04.662711 EDT | AverageEsReturn            26.8378
2017-06-03 17:11:04.662946 EDT | StdEsReturn                22.7412
2017-06-03 17:11:04.663179 EDT | MaxEsReturn                76
2017-06-03 17:11:04.663413 EDT | MinEsReturn                 3
2017-06-03 17:11:04.663657 EDT | AverageDiscountedReturn    99.9957
2017-06-03 17:11:04.663889 EDT | AverageQLoss                3.11875e-05
2017-06-03 17:11:04.664140 EDT | AveragePolicySurr          -0.0907144
2017-06-03 17:11:04.664368 EDT | AverageQ                    0.0866767
2017-06-03 17:11:04.664595 EDT | AverageAbsQ                 0.0869036
2017-06-03 17:11:04.664821 EDT | AverageY                    0.0866759
2017-06-03 17:11:04.665045 EDT | AverageAbsY                 0.0867044
2017-06-03 17:11:04.665308 EDT | AverageAbsQYDiff            0.00153604
2017-06-03 17:11:04.665539 EDT | AverageAction               0.00411777
2017-06-03 17:11:04.665789 EDT | PolicyRegParamNorm         66.1015
2017-06-03 17:11:04.666069 EDT | QFunRegParamNorm           27.7908
2017-06-03 17:11:04.666306 EDT | -----------------------  --------------
2017-06-03 17:11:04.666675 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #557 | Training started
2017-06-03 17:11:23.700932 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #557 | Training finished
2017-06-03 17:11:23.701860 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #557 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 17:11:23.702315 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #557 | Collecting samples for evaluation
2017-06-03 17:11:32.382648 EDT | -----------------------  --------------
2017-06-03 17:11:32.383639 EDT | Epoch                     557
2017-06-03 17:11:32.383973 EDT | Iteration                 557
2017-06-03 17:11:32.384282 EDT | AverageReturn            1000
2017-06-03 17:11:32.384545 EDT | StdReturn                   0
2017-06-03 17:11:32.384785 EDT | MaxReturn                1000
2017-06-03 17:11:32.385023 EDT | MinReturn                1000
2017-06-03 17:11:32.385254 EDT | AverageEsReturn            21.234
2017-06-03 17:11:32.385570 EDT | StdEsReturn                13.7504
2017-06-03 17:11:32.385917 EDT | MaxEsReturn                58
2017-06-03 17:11:32.386273 EDT | MinEsReturn                 3
2017-06-03 17:11:32.386585 EDT | AverageDiscountedReturn    99.9957
2017-06-03 17:11:32.386899 EDT | AverageQLoss                3.06306e-05
2017-06-03 17:11:32.387223 EDT | AveragePolicySurr          -0.0907492
2017-06-03 17:11:32.387536 EDT | AverageQ                    0.0867673
2017-06-03 17:11:32.387848 EDT | AverageAbsQ                 0.0870526
2017-06-03 17:11:32.388158 EDT | AverageY                    0.0867644
2017-06-03 17:11:32.388466 EDT | AverageAbsY                 0.0867971
2017-06-03 17:11:32.388775 EDT | AverageAbsQYDiff            0.00156425
2017-06-03 17:11:32.389085 EDT | AverageAction               0.00952546
2017-06-03 17:11:32.389393 EDT | PolicyRegParamNorm         66.1503
2017-06-03 17:11:32.389705 EDT | QFunRegParamNorm           27.7847
2017-06-03 17:11:32.390016 EDT | -----------------------  --------------
2017-06-03 17:11:32.390444 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #558 | Training started
2017-06-03 17:11:50.855885 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #558 | Training finished
2017-06-03 17:11:50.856852 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #558 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 17:11:50.857200 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #558 | Collecting samples for evaluation
2017-06-03 17:11:59.704784 EDT | -----------------------  --------------
2017-06-03 17:11:59.705616 EDT | Epoch                     558
2017-06-03 17:11:59.705890 EDT | Iteration                 558
2017-06-03 17:11:59.706131 EDT | AverageReturn            1000
2017-06-03 17:11:59.706380 EDT | StdReturn                   0
2017-06-03 17:11:59.706624 EDT | MaxReturn                1000
2017-06-03 17:11:59.706868 EDT | MinReturn                1000
2017-06-03 17:11:59.707103 EDT | AverageEsReturn            28.0571
2017-06-03 17:11:59.707336 EDT | StdEsReturn                24.4177
2017-06-03 17:11:59.707570 EDT | MaxEsReturn               110
2017-06-03 17:11:59.707803 EDT | MinEsReturn                 5
2017-06-03 17:11:59.708040 EDT | AverageDiscountedReturn    99.9957
2017-06-03 17:11:59.708271 EDT | AverageQLoss                2.99221e-05
2017-06-03 17:11:59.708503 EDT | AveragePolicySurr          -0.090844
2017-06-03 17:11:59.708737 EDT | AverageQ                    0.0868628
2017-06-03 17:11:59.708993 EDT | AverageAbsQ                 0.0871025
2017-06-03 17:11:59.709231 EDT | AverageY                    0.0868695
2017-06-03 17:11:59.709464 EDT | AverageAbsY                 0.0869048
2017-06-03 17:11:59.709703 EDT | AverageAbsQYDiff            0.0014807
2017-06-03 17:11:59.709940 EDT | AverageAction               0.00670056
2017-06-03 17:11:59.710186 EDT | PolicyRegParamNorm         66.1796
2017-06-03 17:11:59.710420 EDT | QFunRegParamNorm           27.8009
2017-06-03 17:11:59.710651 EDT | -----------------------  --------------
2017-06-03 17:11:59.711035 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #559 | Training started
2017-06-03 17:12:17.692590 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #559 | Training finished
2017-06-03 17:12:17.693525 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #559 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 17:12:17.693844 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #559 | Collecting samples for evaluation
2017-06-03 17:12:26.600713 EDT | -----------------------  --------------
2017-06-03 17:12:26.601547 EDT | Epoch                     559
2017-06-03 17:12:26.601817 EDT | Iteration                 559
2017-06-03 17:12:26.602059 EDT | AverageReturn            1000
2017-06-03 17:12:26.602311 EDT | StdReturn                   0
2017-06-03 17:12:26.602547 EDT | MaxReturn                1000
2017-06-03 17:12:26.602782 EDT | MinReturn                1000
2017-06-03 17:12:26.603014 EDT | AverageEsReturn            29.2
2017-06-03 17:12:26.603252 EDT | StdEsReturn                30.4103
2017-06-03 17:12:26.603484 EDT | MaxEsReturn               167
2017-06-03 17:12:26.603716 EDT | MinEsReturn                 5
2017-06-03 17:12:26.603957 EDT | AverageDiscountedReturn    99.9957
2017-06-03 17:12:26.604188 EDT | AverageQLoss                2.81231e-05
2017-06-03 17:12:26.604424 EDT | AveragePolicySurr          -0.0907424
2017-06-03 17:12:26.604658 EDT | AverageQ                    0.0867334
2017-06-03 17:12:26.604888 EDT | AverageAbsQ                 0.086975
2017-06-03 17:12:26.605118 EDT | AverageY                    0.0867282
2017-06-03 17:12:26.605388 EDT | AverageAbsY                 0.0867608
2017-06-03 17:12:26.605618 EDT | AverageAbsQYDiff            0.00146632
2017-06-03 17:12:26.605863 EDT | AverageAction               0.0513638
2017-06-03 17:12:26.606096 EDT | PolicyRegParamNorm         66.2171
2017-06-03 17:12:26.606337 EDT | QFunRegParamNorm           27.826
2017-06-03 17:12:26.606567 EDT | -----------------------  --------------
2017-06-03 17:12:26.606914 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #560 | Training started
2017-06-03 17:12:45.919048 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #560 | Training finished
2017-06-03 17:12:45.919911 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #560 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 17:12:45.920182 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #560 | Collecting samples for evaluation
2017-06-03 17:12:55.479906 EDT | -----------------------  --------------
2017-06-03 17:12:55.480785 EDT | Epoch                     560
2017-06-03 17:12:55.481043 EDT | Iteration                 560
2017-06-03 17:12:55.481279 EDT | AverageReturn            1000
2017-06-03 17:12:55.481527 EDT | StdReturn                   0
2017-06-03 17:12:55.481770 EDT | MaxReturn                1000
2017-06-03 17:12:55.482001 EDT | MinReturn                1000
2017-06-03 17:12:55.482231 EDT | AverageEsReturn            36.4815
2017-06-03 17:12:55.482469 EDT | StdEsReturn                30.1384
2017-06-03 17:12:55.482698 EDT | MaxEsReturn               143
2017-06-03 17:12:55.482924 EDT | MinEsReturn                 7
2017-06-03 17:12:55.483160 EDT | AverageDiscountedReturn    99.9957
2017-06-03 17:12:55.483389 EDT | AverageQLoss                2.83539e-05
2017-06-03 17:12:55.483616 EDT | AveragePolicySurr          -0.0906005
2017-06-03 17:12:55.483843 EDT | AverageQ                    0.0866497
2017-06-03 17:12:55.484070 EDT | AverageAbsQ                 0.086908
2017-06-03 17:12:55.484296 EDT | AverageY                    0.0866475
2017-06-03 17:12:55.484523 EDT | AverageAbsY                 0.0866907
2017-06-03 17:12:55.484748 EDT | AverageAbsQYDiff            0.00145587
2017-06-03 17:12:55.484979 EDT | AverageAction               0.0887012
2017-06-03 17:12:55.485205 EDT | PolicyRegParamNorm         66.2774
2017-06-03 17:12:55.485438 EDT | QFunRegParamNorm           27.8311
2017-06-03 17:12:55.485664 EDT | -----------------------  --------------
2017-06-03 17:12:55.486056 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #561 | Training started
2017-06-03 17:13:14.361294 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #561 | Training finished
2017-06-03 17:13:14.362168 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #561 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 17:13:14.362610 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #561 | Collecting samples for evaluation
2017-06-03 17:13:25.393709 EDT | -----------------------  --------------
2017-06-03 17:13:25.394583 EDT | Epoch                     561
2017-06-03 17:13:25.394887 EDT | Iteration                 561
2017-06-03 17:13:25.395131 EDT | AverageReturn            1000
2017-06-03 17:13:25.395370 EDT | StdReturn                   0
2017-06-03 17:13:25.395602 EDT | MaxReturn                1000
2017-06-03 17:13:25.395834 EDT | MinReturn                1000
2017-06-03 17:13:25.396097 EDT | AverageEsReturn            25.9737
2017-06-03 17:13:25.396330 EDT | StdEsReturn                25.2925
2017-06-03 17:13:25.396561 EDT | MaxEsReturn               117
2017-06-03 17:13:25.396797 EDT | MinEsReturn                 3
2017-06-03 17:13:25.397028 EDT | AverageDiscountedReturn    99.9957
2017-06-03 17:13:25.397264 EDT | AverageQLoss                3.25026e-05
2017-06-03 17:13:25.397494 EDT | AveragePolicySurr          -0.0905555
2017-06-03 17:13:25.397757 EDT | AverageQ                    0.0865151
2017-06-03 17:13:25.397991 EDT | AverageAbsQ                 0.08675
2017-06-03 17:13:25.398219 EDT | AverageY                    0.0865198
2017-06-03 17:13:25.398445 EDT | AverageAbsY                 0.0865576
2017-06-03 17:13:25.398698 EDT | AverageAbsQYDiff            0.00157175
2017-06-03 17:13:25.398933 EDT | AverageAction               0.0482286
2017-06-03 17:13:25.399166 EDT | PolicyRegParamNorm         66.3179
2017-06-03 17:13:25.399397 EDT | QFunRegParamNorm           27.8505
2017-06-03 17:13:25.399629 EDT | -----------------------  --------------
2017-06-03 17:13:25.399996 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #562 | Training started
2017-06-03 17:13:44.431185 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #562 | Training finished
2017-06-03 17:13:44.431816 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #562 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 17:13:44.432095 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #562 | Collecting samples for evaluation
2017-06-03 17:13:54.270989 EDT | -----------------------  --------------
2017-06-03 17:13:54.271702 EDT | Epoch                     562
2017-06-03 17:13:54.271982 EDT | Iteration                 562
2017-06-03 17:13:54.272236 EDT | AverageReturn            1000
2017-06-03 17:13:54.272475 EDT | StdReturn                   0
2017-06-03 17:13:54.272717 EDT | MaxReturn                1000
2017-06-03 17:13:54.272951 EDT | MinReturn                1000
2017-06-03 17:13:54.273185 EDT | AverageEsReturn            30.3235
2017-06-03 17:13:54.273432 EDT | StdEsReturn                26.9975
2017-06-03 17:13:54.273666 EDT | MaxEsReturn               141
2017-06-03 17:13:54.273910 EDT | MinEsReturn                 4
2017-06-03 17:13:54.274143 EDT | AverageDiscountedReturn    99.9957
2017-06-03 17:13:54.274375 EDT | AverageQLoss                2.44435e-05
2017-06-03 17:13:54.274606 EDT | AveragePolicySurr          -0.0907467
2017-06-03 17:13:54.274850 EDT | AverageQ                    0.0867311
2017-06-03 17:13:54.275080 EDT | AverageAbsQ                 0.0870169
2017-06-03 17:13:54.275312 EDT | AverageY                    0.086729
2017-06-03 17:13:54.275544 EDT | AverageAbsY                 0.0867747
2017-06-03 17:13:54.275774 EDT | AverageAbsQYDiff            0.00139177
2017-06-03 17:13:54.276005 EDT | AverageAction               0.0466742
2017-06-03 17:13:54.276241 EDT | PolicyRegParamNorm         66.3365
2017-06-03 17:13:54.276472 EDT | QFunRegParamNorm           27.8558
2017-06-03 17:13:54.276703 EDT | -----------------------  --------------
2017-06-03 17:13:54.277074 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #563 | Training started
2017-06-03 17:14:12.863738 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #563 | Training finished
2017-06-03 17:14:12.864661 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #563 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 17:14:12.864945 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #563 | Collecting samples for evaluation
2017-06-03 17:14:23.056441 EDT | -----------------------  --------------
2017-06-03 17:14:23.057294 EDT | Epoch                     563
2017-06-03 17:14:23.057552 EDT | Iteration                 563
2017-06-03 17:14:23.057799 EDT | AverageReturn            1000
2017-06-03 17:14:23.058031 EDT | StdReturn                   0
2017-06-03 17:14:23.058260 EDT | MaxReturn                1000
2017-06-03 17:14:23.058489 EDT | MinReturn                1000
2017-06-03 17:14:23.058717 EDT | AverageEsReturn            23.439
2017-06-03 17:14:23.058957 EDT | StdEsReturn                17.7077
2017-06-03 17:14:23.059184 EDT | MaxEsReturn                69
2017-06-03 17:14:23.059411 EDT | MinEsReturn                 3
2017-06-03 17:14:23.059638 EDT | AverageDiscountedReturn    99.9957
2017-06-03 17:14:23.059865 EDT | AverageQLoss                3.01914e-05
2017-06-03 17:14:23.060095 EDT | AveragePolicySurr          -0.0905647
2017-06-03 17:14:23.060327 EDT | AverageQ                    0.0865447
2017-06-03 17:14:23.060552 EDT | AverageAbsQ                 0.0868043
2017-06-03 17:14:23.060778 EDT | AverageY                    0.0865465
2017-06-03 17:14:23.061002 EDT | AverageAbsY                 0.0865918
2017-06-03 17:14:23.061228 EDT | AverageAbsQYDiff            0.00153098
2017-06-03 17:14:23.061453 EDT | AverageAction               0.0265849
2017-06-03 17:14:23.061678 EDT | PolicyRegParamNorm         66.3673
2017-06-03 17:14:23.061942 EDT | QFunRegParamNorm           27.8661
2017-06-03 17:14:23.062183 EDT | -----------------------  --------------
2017-06-03 17:14:23.062580 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #564 | Training started
2017-06-03 17:14:42.159105 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #564 | Training finished
2017-06-03 17:14:42.159957 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #564 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 17:14:42.160228 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #564 | Collecting samples for evaluation
2017-06-03 17:14:51.438883 EDT | -----------------------  --------------
2017-06-03 17:14:51.439755 EDT | Epoch                     564
2017-06-03 17:14:51.440020 EDT | Iteration                 564
2017-06-03 17:14:51.440264 EDT | AverageReturn            1000
2017-06-03 17:14:51.440502 EDT | StdReturn                   0
2017-06-03 17:14:51.440737 EDT | MaxReturn                1000
2017-06-03 17:14:51.440979 EDT | MinReturn                1000
2017-06-03 17:14:51.441210 EDT | AverageEsReturn            24
2017-06-03 17:14:51.441442 EDT | StdEsReturn                16.1139
2017-06-03 17:14:51.441674 EDT | MaxEsReturn                64
2017-06-03 17:14:51.441924 EDT | MinEsReturn                 3
2017-06-03 17:14:51.442158 EDT | AverageDiscountedReturn    99.9957
2017-06-03 17:14:51.442391 EDT | AverageQLoss                2.85774e-05
2017-06-03 17:14:51.442623 EDT | AveragePolicySurr          -0.0905773
2017-06-03 17:14:51.442855 EDT | AverageQ                    0.0865457
2017-06-03 17:14:51.443089 EDT | AverageAbsQ                 0.0868311
2017-06-03 17:14:51.443328 EDT | AverageY                    0.0865465
2017-06-03 17:14:51.443563 EDT | AverageAbsY                 0.0865945
2017-06-03 17:14:51.443793 EDT | AverageAbsQYDiff            0.00153765
2017-06-03 17:14:51.444024 EDT | AverageAction               0.01069
2017-06-03 17:14:51.444254 EDT | PolicyRegParamNorm         66.3781
2017-06-03 17:14:51.444485 EDT | QFunRegParamNorm           27.8806
2017-06-03 17:14:51.444716 EDT | -----------------------  --------------
2017-06-03 17:14:51.445070 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #565 | Training started
2017-06-03 17:15:10.720209 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #565 | Training finished
2017-06-03 17:15:10.721074 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #565 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 17:15:10.721422 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #565 | Collecting samples for evaluation
2017-06-03 17:15:20.498248 EDT | -----------------------  --------------
2017-06-03 17:15:20.499274 EDT | Epoch                     565
2017-06-03 17:15:20.499545 EDT | Iteration                 565
2017-06-03 17:15:20.499789 EDT | AverageReturn            1000
2017-06-03 17:15:20.500023 EDT | StdReturn                   0
2017-06-03 17:15:20.500254 EDT | MaxReturn                1000
2017-06-03 17:15:20.500484 EDT | MinReturn                1000
2017-06-03 17:15:20.500713 EDT | AverageEsReturn            20
2017-06-03 17:15:20.500950 EDT | StdEsReturn                18.2994
2017-06-03 17:15:20.501226 EDT | MaxEsReturn               100
2017-06-03 17:15:20.501455 EDT | MinEsReturn                 4
2017-06-03 17:15:20.501682 EDT | AverageDiscountedReturn    99.9957
2017-06-03 17:15:20.502339 EDT | AverageQLoss                2.71971e-05
2017-06-03 17:15:20.502662 EDT | AveragePolicySurr          -0.0907608
2017-06-03 17:15:20.502981 EDT | AverageQ                    0.0868146
2017-06-03 17:15:20.503295 EDT | AverageAbsQ                 0.0870486
2017-06-03 17:15:20.503654 EDT | AverageY                    0.0868124
2017-06-03 17:15:20.503967 EDT | AverageAbsY                 0.0868473
2017-06-03 17:15:20.504278 EDT | AverageAbsQYDiff            0.00137402
2017-06-03 17:15:20.504600 EDT | AverageAction               0.0408103
2017-06-03 17:15:20.504919 EDT | PolicyRegParamNorm         66.3993
2017-06-03 17:15:20.505229 EDT | QFunRegParamNorm           27.8758
2017-06-03 17:15:20.505542 EDT | -----------------------  --------------
2017-06-03 17:15:20.506031 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #566 | Training started
2017-06-03 17:15:39.655765 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #566 | Training finished
2017-06-03 17:15:39.656871 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #566 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 17:15:39.657311 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #566 | Collecting samples for evaluation
2017-06-03 17:15:49.127167 EDT | -----------------------  --------------
2017-06-03 17:15:49.128132 EDT | Epoch                     566
2017-06-03 17:15:49.128489 EDT | Iteration                 566
2017-06-03 17:15:49.128811 EDT | AverageReturn            1000
2017-06-03 17:15:49.129131 EDT | StdReturn                   0
2017-06-03 17:15:49.129452 EDT | MaxReturn                1000
2017-06-03 17:15:49.129779 EDT | MinReturn                1000
2017-06-03 17:15:49.130099 EDT | AverageEsReturn            29.1765
2017-06-03 17:15:49.130409 EDT | StdEsReturn                32.159
2017-06-03 17:15:49.130720 EDT | MaxEsReturn               181
2017-06-03 17:15:49.131028 EDT | MinEsReturn                 4
2017-06-03 17:15:49.131334 EDT | AverageDiscountedReturn    99.9957
2017-06-03 17:15:49.131643 EDT | AverageQLoss                2.98704e-05
2017-06-03 17:15:49.131951 EDT | AveragePolicySurr          -0.0906577
2017-06-03 17:15:49.132258 EDT | AverageQ                    0.0865438
2017-06-03 17:15:49.132565 EDT | AverageAbsQ                 0.086781
2017-06-03 17:15:49.132870 EDT | AverageY                    0.0865447
2017-06-03 17:15:49.133175 EDT | AverageAbsY                 0.0865814
2017-06-03 17:15:49.133480 EDT | AverageAbsQYDiff            0.00147018
2017-06-03 17:15:49.133797 EDT | AverageAction               0.0982543
2017-06-03 17:15:49.134104 EDT | PolicyRegParamNorm         66.4304
2017-06-03 17:15:49.134414 EDT | QFunRegParamNorm           27.8718
2017-06-03 17:15:49.134717 EDT | -----------------------  --------------
2017-06-03 17:15:49.135169 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #567 | Training started
2017-06-03 17:16:07.671219 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #567 | Training finished
2017-06-03 17:16:07.672146 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #567 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 17:16:07.672416 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #567 | Collecting samples for evaluation
2017-06-03 17:16:17.391507 EDT | -----------------------  --------------
2017-06-03 17:16:17.392576 EDT | Epoch                     567
2017-06-03 17:16:17.392959 EDT | Iteration                 567
2017-06-03 17:16:17.393289 EDT | AverageReturn            1000
2017-06-03 17:16:17.393658 EDT | StdReturn                   0
2017-06-03 17:16:17.394048 EDT | MaxReturn                1000
2017-06-03 17:16:17.394306 EDT | MinReturn                1000
2017-06-03 17:16:17.394586 EDT | AverageEsReturn            39.2917
2017-06-03 17:16:17.394881 EDT | StdEsReturn                33.5441
2017-06-03 17:16:17.395176 EDT | MaxEsReturn               143
2017-06-03 17:16:17.395443 EDT | MinEsReturn                 4
2017-06-03 17:16:17.395809 EDT | AverageDiscountedReturn    99.9957
2017-06-03 17:16:17.396148 EDT | AverageQLoss                2.69293e-05
2017-06-03 17:16:17.396487 EDT | AveragePolicySurr          -0.0906581
2017-06-03 17:16:17.396866 EDT | AverageQ                    0.0864836
2017-06-03 17:16:17.397212 EDT | AverageAbsQ                 0.0867038
2017-06-03 17:16:17.397557 EDT | AverageY                    0.0864785
2017-06-03 17:16:17.397941 EDT | AverageAbsY                 0.0865063
2017-06-03 17:16:17.398281 EDT | AverageAbsQYDiff            0.0013978
2017-06-03 17:16:17.398636 EDT | AverageAction               0.0492046
2017-06-03 17:16:17.398997 EDT | PolicyRegParamNorm         66.4649
2017-06-03 17:16:17.399333 EDT | QFunRegParamNorm           27.885
2017-06-03 17:16:17.399679 EDT | -----------------------  --------------
2017-06-03 17:16:17.400307 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #568 | Training started
2017-06-03 17:16:35.211478 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #568 | Training finished
2017-06-03 17:16:35.212481 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #568 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 17:16:35.213029 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #568 | Collecting samples for evaluation
2017-06-03 17:16:44.724575 EDT | -----------------------  --------------
2017-06-03 17:16:44.725126 EDT | Epoch                     568
2017-06-03 17:16:44.725499 EDT | Iteration                 568
2017-06-03 17:16:44.725828 EDT | AverageReturn            1000
2017-06-03 17:16:44.726188 EDT | StdReturn                   0
2017-06-03 17:16:44.726547 EDT | MaxReturn                1000
2017-06-03 17:16:44.726877 EDT | MinReturn                1000
2017-06-03 17:16:44.727194 EDT | AverageEsReturn            35.4
2017-06-03 17:16:44.727604 EDT | StdEsReturn                27.6473
2017-06-03 17:16:44.727929 EDT | MaxEsReturn               118
2017-06-03 17:16:44.728279 EDT | MinEsReturn                 4
2017-06-03 17:16:44.728607 EDT | AverageDiscountedReturn    99.9957
2017-06-03 17:16:44.728936 EDT | AverageQLoss                2.44085e-05
2017-06-03 17:16:44.729263 EDT | AveragePolicySurr          -0.0906571
2017-06-03 17:16:44.729590 EDT | AverageQ                    0.0865496
2017-06-03 17:16:44.729926 EDT | AverageAbsQ                 0.0867656
2017-06-03 17:16:44.730247 EDT | AverageY                    0.0865565
2017-06-03 17:16:44.730573 EDT | AverageAbsY                 0.0865764
2017-06-03 17:16:44.730934 EDT | AverageAbsQYDiff            0.00136088
2017-06-03 17:16:44.731275 EDT | AverageAction               0.064779
2017-06-03 17:16:44.731607 EDT | PolicyRegParamNorm         66.5292
2017-06-03 17:16:44.731920 EDT | QFunRegParamNorm           27.8938
2017-06-03 17:16:44.732230 EDT | -----------------------  --------------
2017-06-03 17:16:44.732714 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #569 | Training started
2017-06-03 17:17:03.729950 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #569 | Training finished
2017-06-03 17:17:03.730865 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #569 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 17:17:03.731161 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #569 | Collecting samples for evaluation
2017-06-03 17:17:14.071171 EDT | -----------------------  --------------
2017-06-03 17:17:14.071698 EDT | Epoch                     569
2017-06-03 17:17:14.072046 EDT | Iteration                 569
2017-06-03 17:17:14.077861 EDT | AverageReturn            1000
2017-06-03 17:17:14.078253 EDT | StdReturn                   0
2017-06-03 17:17:14.078583 EDT | MaxReturn                1000
2017-06-03 17:17:14.078905 EDT | MinReturn                1000
2017-06-03 17:17:14.079231 EDT | AverageEsReturn            27.2778
2017-06-03 17:17:14.079560 EDT | StdEsReturn                21.7455
2017-06-03 17:17:14.079879 EDT | MaxEsReturn                99
2017-06-03 17:17:14.080203 EDT | MinEsReturn                 3
2017-06-03 17:17:14.080515 EDT | AverageDiscountedReturn    99.9957
2017-06-03 17:17:14.080829 EDT | AverageQLoss                3.13739e-05
2017-06-03 17:17:14.081145 EDT | AveragePolicySurr          -0.0907121
2017-06-03 17:17:14.081460 EDT | AverageQ                    0.0867769
2017-06-03 17:17:14.081781 EDT | AverageAbsQ                 0.0870388
2017-06-03 17:17:14.082095 EDT | AverageY                    0.086779
2017-06-03 17:17:14.082403 EDT | AverageAbsY                 0.0867931
2017-06-03 17:17:14.082721 EDT | AverageAbsQYDiff            0.00152292
2017-06-03 17:17:14.083033 EDT | AverageAction               0.0958359
2017-06-03 17:17:14.083344 EDT | PolicyRegParamNorm         66.5308
2017-06-03 17:17:14.083652 EDT | QFunRegParamNorm           27.894
2017-06-03 17:17:14.083960 EDT | -----------------------  --------------
2017-06-03 17:17:14.084431 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #570 | Training started
2017-06-03 17:17:32.838611 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #570 | Training finished
2017-06-03 17:17:32.839500 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #570 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 17:17:32.839765 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #570 | Collecting samples for evaluation
2017-06-03 17:17:42.412694 EDT | -----------------------  --------------
2017-06-03 17:17:42.413232 EDT | Epoch                     570
2017-06-03 17:17:42.413670 EDT | Iteration                 570
2017-06-03 17:17:42.414045 EDT | AverageReturn            1000
2017-06-03 17:17:42.414472 EDT | StdReturn                   0
2017-06-03 17:17:42.414858 EDT | MaxReturn                1000
2017-06-03 17:17:42.415204 EDT | MinReturn                1000
2017-06-03 17:17:42.415634 EDT | AverageEsReturn            32.9032
2017-06-03 17:17:42.416003 EDT | StdEsReturn                22.9717
2017-06-03 17:17:42.416398 EDT | MaxEsReturn                88
2017-06-03 17:17:42.416804 EDT | MinEsReturn                 3
2017-06-03 17:17:42.417136 EDT | AverageDiscountedReturn    99.9957
2017-06-03 17:17:42.417570 EDT | AverageQLoss                2.52865e-05
2017-06-03 17:17:42.417952 EDT | AveragePolicySurr          -0.0906248
2017-06-03 17:17:42.418319 EDT | AverageQ                    0.0866168
2017-06-03 17:17:42.418738 EDT | AverageAbsQ                 0.0868461
2017-06-03 17:17:42.419070 EDT | AverageY                    0.086613
2017-06-03 17:17:42.419475 EDT | AverageAbsY                 0.0866286
2017-06-03 17:17:42.419869 EDT | AverageAbsQYDiff            0.00137657
2017-06-03 17:17:42.420211 EDT | AverageAction               0.116632
2017-06-03 17:17:42.420637 EDT | PolicyRegParamNorm         66.5946
2017-06-03 17:17:42.420982 EDT | QFunRegParamNorm           27.9122
2017-06-03 17:17:42.421352 EDT | -----------------------  --------------
2017-06-03 17:17:42.421934 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #571 | Training started
2017-06-03 17:18:01.849349 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #571 | Training finished
2017-06-03 17:18:01.850294 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #571 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 17:18:01.850588 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #571 | Collecting samples for evaluation
2017-06-03 17:18:11.051256 EDT | -----------------------  --------------
2017-06-03 17:18:11.052271 EDT | Epoch                     571
2017-06-03 17:18:11.052615 EDT | Iteration                 571
2017-06-03 17:18:11.052937 EDT | AverageReturn            1000
2017-06-03 17:18:11.053261 EDT | StdReturn                   0
2017-06-03 17:18:11.053585 EDT | MaxReturn                1000
2017-06-03 17:18:11.053908 EDT | MinReturn                1000
2017-06-03 17:18:11.054222 EDT | AverageEsReturn            37.64
2017-06-03 17:18:11.054548 EDT | StdEsReturn                24.8208
2017-06-03 17:18:11.054860 EDT | MaxEsReturn                92
2017-06-03 17:18:11.055171 EDT | MinEsReturn                 4
2017-06-03 17:18:11.055479 EDT | AverageDiscountedReturn    99.9957
2017-06-03 17:18:11.055795 EDT | AverageQLoss                2.56863e-05
2017-06-03 17:18:11.056112 EDT | AveragePolicySurr          -0.0904539
2017-06-03 17:18:11.056421 EDT | AverageQ                    0.0863526
2017-06-03 17:18:11.056732 EDT | AverageAbsQ                 0.0865881
2017-06-03 17:18:11.057038 EDT | AverageY                    0.0863509
2017-06-03 17:18:11.057343 EDT | AverageAbsY                 0.0863622
2017-06-03 17:18:11.057648 EDT | AverageAbsQYDiff            0.00135894
2017-06-03 17:18:11.057969 EDT | AverageAction               0.0772499
2017-06-03 17:18:11.058275 EDT | PolicyRegParamNorm         66.6284
2017-06-03 17:18:11.058579 EDT | QFunRegParamNorm           27.9116
2017-06-03 17:18:11.058906 EDT | -----------------------  --------------
2017-06-03 17:18:11.059362 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #572 | Training started
2017-06-03 17:18:30.154235 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #572 | Training finished
2017-06-03 17:18:30.155065 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #572 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 17:18:30.155327 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #572 | Collecting samples for evaluation
2017-06-03 17:18:39.144475 EDT | -----------------------  --------------
2017-06-03 17:18:39.145478 EDT | Epoch                     572
2017-06-03 17:18:39.145831 EDT | Iteration                 572
2017-06-03 17:18:39.146162 EDT | AverageReturn            1000
2017-06-03 17:18:39.146486 EDT | StdReturn                   0
2017-06-03 17:18:39.146806 EDT | MaxReturn                1000
2017-06-03 17:18:39.147123 EDT | MinReturn                1000
2017-06-03 17:18:39.147438 EDT | AverageEsReturn            28.6944
2017-06-03 17:18:39.147761 EDT | StdEsReturn                25.4742
2017-06-03 17:18:39.148109 EDT | MaxEsReturn                98
2017-06-03 17:18:39.148426 EDT | MinEsReturn                 3
2017-06-03 17:18:39.148743 EDT | AverageDiscountedReturn    99.9957
2017-06-03 17:18:39.149069 EDT | AverageQLoss                3.21594e-05
2017-06-03 17:18:39.149391 EDT | AveragePolicySurr          -0.0905759
2017-06-03 17:18:39.149710 EDT | AverageQ                    0.0864187
2017-06-03 17:18:39.150030 EDT | AverageAbsQ                 0.0867065
2017-06-03 17:18:39.150343 EDT | AverageY                    0.0864207
2017-06-03 17:18:39.150657 EDT | AverageAbsY                 0.0864542
2017-06-03 17:18:39.150968 EDT | AverageAbsQYDiff            0.00157762
2017-06-03 17:18:39.151393 EDT | AverageAction               0.138612
2017-06-03 17:18:39.151909 EDT | PolicyRegParamNorm         66.6503
2017-06-03 17:18:39.152424 EDT | QFunRegParamNorm           27.93
2017-06-03 17:18:39.152933 EDT | -----------------------  --------------
2017-06-03 17:18:39.153567 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #573 | Training started
2017-06-03 17:18:58.052959 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #573 | Training finished
2017-06-03 17:18:58.053824 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #573 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 17:18:58.054094 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #573 | Collecting samples for evaluation
2017-06-03 17:19:08.334038 EDT | -----------------------  --------------
2017-06-03 17:19:08.346821 EDT | Epoch                     573
2017-06-03 17:19:08.347248 EDT | Iteration                 573
2017-06-03 17:19:08.347521 EDT | AverageReturn            1000
2017-06-03 17:19:08.347780 EDT | StdReturn                   0
2017-06-03 17:19:08.348037 EDT | MaxReturn                1000
2017-06-03 17:19:08.348338 EDT | MinReturn                1000
2017-06-03 17:19:08.348614 EDT | AverageEsReturn            35.4643
2017-06-03 17:19:08.348882 EDT | StdEsReturn                24.0557
2017-06-03 17:19:08.349144 EDT | MaxEsReturn               109
2017-06-03 17:19:08.349498 EDT | MinEsReturn                 7
2017-06-03 17:19:08.350598 EDT | AverageDiscountedReturn    99.9957
2017-06-03 17:19:08.350967 EDT | AverageQLoss                2.49228e-05
2017-06-03 17:19:08.351513 EDT | AveragePolicySurr          -0.0905617
2017-06-03 17:19:08.351798 EDT | AverageQ                    0.0866665
2017-06-03 17:19:08.352165 EDT | AverageAbsQ                 0.0868639
2017-06-03 17:19:08.352416 EDT | AverageY                    0.0866663
2017-06-03 17:19:08.352685 EDT | AverageAbsY                 0.086684
2017-06-03 17:19:08.352928 EDT | AverageAbsQYDiff            0.0013756
2017-06-03 17:19:08.353177 EDT | AverageAction               0.121022
2017-06-03 17:19:08.353470 EDT | PolicyRegParamNorm         66.6601
2017-06-03 17:19:08.353742 EDT | QFunRegParamNorm           27.9345
2017-06-03 17:19:08.353985 EDT | -----------------------  --------------
2017-06-03 17:19:08.354374 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #574 | Training started
2017-06-03 17:19:26.826782 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #574 | Training finished
2017-06-03 17:19:26.827702 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #574 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 17:19:26.827970 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #574 | Collecting samples for evaluation
2017-06-03 17:19:36.434712 EDT | -----------------------  -------------
2017-06-03 17:19:36.435695 EDT | Epoch                    574
2017-06-03 17:19:36.436032 EDT | Iteration                574
2017-06-03 17:19:36.436364 EDT | AverageReturn            208.562
2017-06-03 17:19:36.436680 EDT | StdReturn                  1.07831
2017-06-03 17:19:36.436994 EDT | MaxReturn                211
2017-06-03 17:19:36.437313 EDT | MinReturn                206
2017-06-03 17:19:36.437625 EDT | AverageEsReturn           38.3704
2017-06-03 17:19:36.437948 EDT | StdEsReturn               33.6289
2017-06-03 17:19:36.438256 EDT | MaxEsReturn              145
2017-06-03 17:19:36.438561 EDT | MinEsReturn                3
2017-06-03 17:19:36.438866 EDT | AverageDiscountedReturn   87.7061
2017-06-03 17:19:36.439172 EDT | AverageQLoss               2.75467e-05
2017-06-03 17:19:36.439479 EDT | AveragePolicySurr         -0.0906143
2017-06-03 17:19:36.439792 EDT | AverageQ                   0.0865139
2017-06-03 17:19:36.440134 EDT | AverageAbsQ                0.0867374
2017-06-03 17:19:36.440445 EDT | AverageY                   0.0865153
2017-06-03 17:19:36.440750 EDT | AverageAbsY                0.0865367
2017-06-03 17:19:36.441052 EDT | AverageAbsQYDiff           0.00146851
2017-06-03 17:19:36.441357 EDT | AverageAction              0.175539
2017-06-03 17:19:36.441663 EDT | PolicyRegParamNorm        66.609
2017-06-03 17:19:36.441995 EDT | QFunRegParamNorm          27.9359
2017-06-03 17:19:36.442299 EDT | -----------------------  -------------
2017-06-03 17:19:36.442762 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #575 | Training started
2017-06-03 17:19:55.314902 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #575 | Training finished
2017-06-03 17:19:55.315777 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #575 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 17:19:55.316044 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #575 | Collecting samples for evaluation
2017-06-03 17:20:05.935578 EDT | -----------------------  --------------
2017-06-03 17:20:05.936400 EDT | Epoch                     575
2017-06-03 17:20:05.936667 EDT | Iteration                 575
2017-06-03 17:20:05.936912 EDT | AverageReturn            1000
2017-06-03 17:20:05.937170 EDT | StdReturn                   0
2017-06-03 17:20:05.937401 EDT | MaxReturn                1000
2017-06-03 17:20:05.937631 EDT | MinReturn                1000
2017-06-03 17:20:05.937891 EDT | AverageEsReturn            56.7647
2017-06-03 17:20:05.938129 EDT | StdEsReturn                44.5336
2017-06-03 17:20:05.938367 EDT | MaxEsReturn               149
2017-06-03 17:20:05.938626 EDT | MinEsReturn                 3
2017-06-03 17:20:05.938859 EDT | AverageDiscountedReturn    99.9957
2017-06-03 17:20:05.939087 EDT | AverageQLoss                2.90788e-05
2017-06-03 17:20:05.939313 EDT | AveragePolicySurr          -0.0905056
2017-06-03 17:20:05.939542 EDT | AverageQ                    0.0865521
2017-06-03 17:20:05.939787 EDT | AverageAbsQ                 0.0867917
2017-06-03 17:20:05.940016 EDT | AverageY                    0.0865499
2017-06-03 17:20:05.940246 EDT | AverageAbsY                 0.0865641
2017-06-03 17:20:05.940474 EDT | AverageAbsQYDiff            0.00150824
2017-06-03 17:20:05.940703 EDT | AverageAction               0.000158329
2017-06-03 17:20:05.940931 EDT | PolicyRegParamNorm         66.6289
2017-06-03 17:20:05.941159 EDT | QFunRegParamNorm           27.9291
2017-06-03 17:20:05.941388 EDT | -----------------------  --------------
2017-06-03 17:20:05.941786 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #576 | Training started
2017-06-03 17:20:24.096233 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #576 | Training finished
2017-06-03 17:20:24.098926 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #576 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 17:20:24.099347 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #576 | Collecting samples for evaluation
2017-06-03 17:20:33.631516 EDT | -----------------------  --------------
2017-06-03 17:20:33.632560 EDT | Epoch                     576
2017-06-03 17:20:33.632923 EDT | Iteration                 576
2017-06-03 17:20:33.633277 EDT | AverageReturn            1000
2017-06-03 17:20:33.633599 EDT | StdReturn                   0
2017-06-03 17:20:33.633929 EDT | MaxReturn                1000
2017-06-03 17:20:33.634260 EDT | MinReturn                1000
2017-06-03 17:20:33.634576 EDT | AverageEsReturn            32.0938
2017-06-03 17:20:33.634895 EDT | StdEsReturn                26.0736
2017-06-03 17:20:33.635215 EDT | MaxEsReturn               104
2017-06-03 17:20:33.635534 EDT | MinEsReturn                 3
2017-06-03 17:20:33.635845 EDT | AverageDiscountedReturn    99.9957
2017-06-03 17:20:33.636159 EDT | AverageQLoss                2.71226e-05
2017-06-03 17:20:33.636472 EDT | AveragePolicySurr          -0.0904912
2017-06-03 17:20:33.636785 EDT | AverageQ                    0.0864147
2017-06-03 17:20:33.637097 EDT | AverageAbsQ                 0.0866804
2017-06-03 17:20:33.637406 EDT | AverageY                    0.086414
2017-06-03 17:20:33.637733 EDT | AverageAbsY                 0.0864461
2017-06-03 17:20:33.638048 EDT | AverageAbsQYDiff            0.00142253
2017-06-03 17:20:33.638363 EDT | AverageAction               0.1193
2017-06-03 17:20:33.638673 EDT | PolicyRegParamNorm         66.6245
2017-06-03 17:20:33.638981 EDT | QFunRegParamNorm           27.9365
2017-06-03 17:20:33.639298 EDT | -----------------------  --------------
2017-06-03 17:20:33.639772 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #577 | Training started
2017-06-03 17:20:51.710652 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #577 | Training finished
2017-06-03 17:20:51.711257 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #577 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 17:20:51.711553 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #577 | Collecting samples for evaluation
2017-06-03 17:21:00.840453 EDT | -----------------------  --------------
2017-06-03 17:21:00.840828 EDT | Epoch                     577
2017-06-03 17:21:00.841076 EDT | Iteration                 577
2017-06-03 17:21:00.841311 EDT | AverageReturn            1000
2017-06-03 17:21:00.841550 EDT | StdReturn                   0
2017-06-03 17:21:00.841808 EDT | MaxReturn                1000
2017-06-03 17:21:00.842047 EDT | MinReturn                1000
2017-06-03 17:21:00.842280 EDT | AverageEsReturn            35.25
2017-06-03 17:21:00.842510 EDT | StdEsReturn                28.4349
2017-06-03 17:21:00.842742 EDT | MaxEsReturn               136
2017-06-03 17:21:00.842974 EDT | MinEsReturn                 4
2017-06-03 17:21:00.843205 EDT | AverageDiscountedReturn    99.9957
2017-06-03 17:21:00.843437 EDT | AverageQLoss                2.42048e-05
2017-06-03 17:21:00.843668 EDT | AveragePolicySurr          -0.0906614
2017-06-03 17:21:00.843901 EDT | AverageQ                    0.0867887
2017-06-03 17:21:00.844128 EDT | AverageAbsQ                 0.087038
2017-06-03 17:21:00.844362 EDT | AverageY                    0.0867919
2017-06-03 17:21:00.844597 EDT | AverageAbsY                 0.0868073
2017-06-03 17:21:00.844835 EDT | AverageAbsQYDiff            0.00140601
2017-06-03 17:21:00.845066 EDT | AverageAction               0.00400857
2017-06-03 17:21:00.845293 EDT | PolicyRegParamNorm         66.6417
2017-06-03 17:21:00.845523 EDT | QFunRegParamNorm           27.9605
2017-06-03 17:21:00.845778 EDT | -----------------------  --------------
2017-06-03 17:21:00.846132 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #578 | Training started
2017-06-03 17:21:19.777298 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #578 | Training finished
2017-06-03 17:21:19.778193 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #578 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 17:21:19.778462 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #578 | Collecting samples for evaluation
2017-06-03 17:21:29.159571 EDT | -----------------------  --------------
2017-06-03 17:21:29.160793 EDT | Epoch                     578
2017-06-03 17:21:29.161072 EDT | Iteration                 578
2017-06-03 17:21:29.161332 EDT | AverageReturn            1000
2017-06-03 17:21:29.161578 EDT | StdReturn                   0
2017-06-03 17:21:29.161846 EDT | MaxReturn                1000
2017-06-03 17:21:29.162086 EDT | MinReturn                1000
2017-06-03 17:21:29.162318 EDT | AverageEsReturn            40.8261
2017-06-03 17:21:29.162550 EDT | StdEsReturn                42.6642
2017-06-03 17:21:29.162783 EDT | MaxEsReturn               197
2017-06-03 17:21:29.163039 EDT | MinEsReturn                 3
2017-06-03 17:21:29.163273 EDT | AverageDiscountedReturn    99.9957
2017-06-03 17:21:29.163502 EDT | AverageQLoss                3.04145e-05
2017-06-03 17:21:29.163735 EDT | AveragePolicySurr          -0.0903764
2017-06-03 17:21:29.163987 EDT | AverageQ                    0.0864559
2017-06-03 17:21:29.164222 EDT | AverageAbsQ                 0.0867449
2017-06-03 17:21:29.164457 EDT | AverageY                    0.0864557
2017-06-03 17:21:29.164686 EDT | AverageAbsY                 0.0864703
2017-06-03 17:21:29.164921 EDT | AverageAbsQYDiff            0.00151958
2017-06-03 17:21:29.165185 EDT | AverageAction               0.0427604
2017-06-03 17:21:29.165421 EDT | PolicyRegParamNorm         66.6613
2017-06-03 17:21:29.165654 EDT | QFunRegParamNorm           27.9569
2017-06-03 17:21:29.165924 EDT | -----------------------  --------------
2017-06-03 17:21:29.166379 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #579 | Training started
2017-06-03 17:21:47.049172 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #579 | Training finished
2017-06-03 17:21:47.126295 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #579 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 17:21:47.126653 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #579 | Collecting samples for evaluation
2017-06-03 17:21:57.529688 EDT | -----------------------  --------------
2017-06-03 17:21:57.530518 EDT | Epoch                     579
2017-06-03 17:21:57.530907 EDT | Iteration                 579
2017-06-03 17:21:57.531187 EDT | AverageReturn            1000
2017-06-03 17:21:57.531444 EDT | StdReturn                   0
2017-06-03 17:21:57.531695 EDT | MaxReturn                1000
2017-06-03 17:21:57.531943 EDT | MinReturn                1000
2017-06-03 17:21:57.532201 EDT | AverageEsReturn            39.5926
2017-06-03 17:21:57.532450 EDT | StdEsReturn                28.846
2017-06-03 17:21:57.532696 EDT | MaxEsReturn               116
2017-06-03 17:21:57.532942 EDT | MinEsReturn                 5
2017-06-03 17:21:57.533189 EDT | AverageDiscountedReturn    99.9957
2017-06-03 17:21:57.533434 EDT | AverageQLoss                2.57719e-05
2017-06-03 17:21:57.533679 EDT | AveragePolicySurr          -0.0904462
2017-06-03 17:21:57.533943 EDT | AverageQ                    0.0864269
2017-06-03 17:21:57.534189 EDT | AverageAbsQ                 0.0866258
2017-06-03 17:21:57.534433 EDT | AverageY                    0.0864248
2017-06-03 17:21:57.534669 EDT | AverageAbsY                 0.0864341
2017-06-03 17:21:57.534902 EDT | AverageAbsQYDiff            0.00138187
2017-06-03 17:21:57.535135 EDT | AverageAction               0.13959
2017-06-03 17:21:57.535367 EDT | PolicyRegParamNorm         66.6991
2017-06-03 17:21:57.535600 EDT | QFunRegParamNorm           27.9771
2017-06-03 17:21:57.535831 EDT | -----------------------  --------------
2017-06-03 17:21:57.536198 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #580 | Training started
2017-06-03 17:22:16.457322 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #580 | Training finished
2017-06-03 17:22:16.458232 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #580 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 17:22:16.458616 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #580 | Collecting samples for evaluation
2017-06-03 17:22:26.084289 EDT | -----------------------  --------------
2017-06-03 17:22:26.087516 EDT | Epoch                     580
2017-06-03 17:22:26.087782 EDT | Iteration                 580
2017-06-03 17:22:26.088019 EDT | AverageReturn            1000
2017-06-03 17:22:26.088249 EDT | StdReturn                   0
2017-06-03 17:22:26.088489 EDT | MaxReturn                1000
2017-06-03 17:22:26.088714 EDT | MinReturn                1000
2017-06-03 17:22:26.088939 EDT | AverageEsReturn            46.8421
2017-06-03 17:22:26.089166 EDT | StdEsReturn                47.2811
2017-06-03 17:22:26.089390 EDT | MaxEsReturn               201
2017-06-03 17:22:26.089618 EDT | MinEsReturn                 5
2017-06-03 17:22:26.089883 EDT | AverageDiscountedReturn    99.9957
2017-06-03 17:22:26.090114 EDT | AverageQLoss                2.66147e-05
2017-06-03 17:22:26.090343 EDT | AveragePolicySurr          -0.0903775
2017-06-03 17:22:26.090572 EDT | AverageQ                    0.0864364
2017-06-03 17:22:26.090800 EDT | AverageAbsQ                 0.0866543
2017-06-03 17:22:26.091027 EDT | AverageY                    0.0864353
2017-06-03 17:22:26.091255 EDT | AverageAbsY                 0.0864584
2017-06-03 17:22:26.091481 EDT | AverageAbsQYDiff            0.00130325
2017-06-03 17:22:26.091717 EDT | AverageAction               0.000104278
2017-06-03 17:22:26.091945 EDT | PolicyRegParamNorm         66.7594
2017-06-03 17:22:26.092172 EDT | QFunRegParamNorm           27.9814
2017-06-03 17:22:26.092398 EDT | -----------------------  --------------
2017-06-03 17:22:26.092736 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #581 | Training started
2017-06-03 17:22:44.811220 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #581 | Training finished
2017-06-03 17:22:44.812139 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #581 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 17:22:44.812435 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #581 | Collecting samples for evaluation
2017-06-03 17:22:54.199457 EDT | -----------------------  --------------
2017-06-03 17:22:54.200321 EDT | Epoch                     581
2017-06-03 17:22:54.200590 EDT | Iteration                 581
2017-06-03 17:22:54.200831 EDT | AverageReturn            1000
2017-06-03 17:22:54.201064 EDT | StdReturn                   0
2017-06-03 17:22:54.201298 EDT | MaxReturn                1000
2017-06-03 17:22:54.201540 EDT | MinReturn                1000
2017-06-03 17:22:54.201806 EDT | AverageEsReturn            39.7778
2017-06-03 17:22:54.202039 EDT | StdEsReturn                34.9585
2017-06-03 17:22:54.202268 EDT | MaxEsReturn               126
2017-06-03 17:22:54.202503 EDT | MinEsReturn                 3
2017-06-03 17:22:54.202740 EDT | AverageDiscountedReturn    99.9957
2017-06-03 17:22:54.202967 EDT | AverageQLoss                2.93047e-05
2017-06-03 17:22:54.203194 EDT | AveragePolicySurr          -0.0903251
2017-06-03 17:22:54.203461 EDT | AverageQ                    0.0864847
2017-06-03 17:22:54.203689 EDT | AverageAbsQ                 0.0867459
2017-06-03 17:22:54.203915 EDT | AverageY                    0.0864866
2017-06-03 17:22:54.204144 EDT | AverageAbsY                 0.0865047
2017-06-03 17:22:54.204371 EDT | AverageAbsQYDiff            0.0015224
2017-06-03 17:22:54.204597 EDT | AverageAction               0.000355229
2017-06-03 17:22:54.204824 EDT | PolicyRegParamNorm         66.7699
2017-06-03 17:22:54.205054 EDT | QFunRegParamNorm           27.9769
2017-06-03 17:22:54.205291 EDT | -----------------------  --------------
2017-06-03 17:22:54.205666 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #582 | Training started
2017-06-03 17:23:13.399679 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #582 | Training finished
2017-06-03 17:23:13.400582 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #582 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 17:23:13.400988 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #582 | Collecting samples for evaluation
2017-06-03 17:23:23.899852 EDT | -----------------------  --------------
2017-06-03 17:23:23.900712 EDT | Epoch                     582
2017-06-03 17:23:23.900987 EDT | Iteration                 582
2017-06-03 17:23:23.901238 EDT | AverageReturn            1000
2017-06-03 17:23:23.901484 EDT | StdReturn                   0
2017-06-03 17:23:23.901785 EDT | MaxReturn                1000
2017-06-03 17:23:23.902070 EDT | MinReturn                1000
2017-06-03 17:23:23.902350 EDT | AverageEsReturn            45.8182
2017-06-03 17:23:23.902599 EDT | StdEsReturn                38.7141
2017-06-03 17:23:23.902864 EDT | MaxEsReturn               174
2017-06-03 17:23:23.903140 EDT | MinEsReturn                 6
2017-06-03 17:23:23.903384 EDT | AverageDiscountedReturn    99.9957
2017-06-03 17:23:23.903623 EDT | AverageQLoss                2.85128e-05
2017-06-03 17:23:23.903861 EDT | AveragePolicySurr          -0.0903496
2017-06-03 17:23:23.904105 EDT | AverageQ                    0.0863386
2017-06-03 17:23:23.904376 EDT | AverageAbsQ                 0.0866101
2017-06-03 17:23:23.904652 EDT | AverageY                    0.0863393
2017-06-03 17:23:23.904930 EDT | AverageAbsY                 0.0863599
2017-06-03 17:23:23.905189 EDT | AverageAbsQYDiff            0.00149872
2017-06-03 17:23:23.905446 EDT | AverageAction               0.000505511
2017-06-03 17:23:23.905723 EDT | PolicyRegParamNorm         66.7621
2017-06-03 17:23:23.906000 EDT | QFunRegParamNorm           27.9956
2017-06-03 17:23:23.906240 EDT | -----------------------  --------------
2017-06-03 17:23:23.906591 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #583 | Training started
2017-06-03 17:23:43.643120 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #583 | Training finished
2017-06-03 17:23:43.644042 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #583 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 17:23:43.644487 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #583 | Collecting samples for evaluation
2017-06-03 17:23:53.720273 EDT | -----------------------  --------------
2017-06-03 17:23:53.721267 EDT | Epoch                     583
2017-06-03 17:23:53.721541 EDT | Iteration                 583
2017-06-03 17:23:53.721801 EDT | AverageReturn            1000
2017-06-03 17:23:53.722031 EDT | StdReturn                   0
2017-06-03 17:23:53.722254 EDT | MaxReturn                1000
2017-06-03 17:23:53.722496 EDT | MinReturn                1000
2017-06-03 17:23:53.722728 EDT | AverageEsReturn            43.25
2017-06-03 17:23:53.722956 EDT | StdEsReturn                45.3728
2017-06-03 17:23:53.723181 EDT | MaxEsReturn               173
2017-06-03 17:23:53.723407 EDT | MinEsReturn                 4
2017-06-03 17:23:53.723650 EDT | AverageDiscountedReturn    99.9957
2017-06-03 17:23:53.723875 EDT | AverageQLoss                2.64644e-05
2017-06-03 17:23:53.724139 EDT | AveragePolicySurr          -0.0904555
2017-06-03 17:23:53.724368 EDT | AverageQ                    0.0863726
2017-06-03 17:23:53.724593 EDT | AverageAbsQ                 0.0865671
2017-06-03 17:23:53.724819 EDT | AverageY                    0.0863719
2017-06-03 17:23:53.725049 EDT | AverageAbsY                 0.0863986
2017-06-03 17:23:53.725282 EDT | AverageAbsQYDiff            0.0013855
2017-06-03 17:23:53.725506 EDT | AverageAction               0.261938
2017-06-03 17:23:53.726330 EDT | PolicyRegParamNorm         66.755
2017-06-03 17:23:53.726652 EDT | QFunRegParamNorm           28.0067
2017-06-03 17:23:53.726987 EDT | -----------------------  --------------
2017-06-03 17:23:53.727454 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #584 | Training started
2017-06-03 17:24:13.008516 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #584 | Training finished
2017-06-03 17:24:13.009373 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #584 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 17:24:13.009639 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #584 | Collecting samples for evaluation
2017-06-03 17:24:22.509876 EDT | -----------------------  --------------
2017-06-03 17:24:22.510699 EDT | Epoch                     584
2017-06-03 17:24:22.510953 EDT | Iteration                 584
2017-06-03 17:24:22.511189 EDT | AverageReturn            1000
2017-06-03 17:24:22.511420 EDT | StdReturn                   0
2017-06-03 17:24:22.511648 EDT | MaxReturn                1000
2017-06-03 17:24:22.511885 EDT | MinReturn                1000
2017-06-03 17:24:22.512132 EDT | AverageEsReturn            56.0476
2017-06-03 17:24:22.512359 EDT | StdEsReturn                62.5509
2017-06-03 17:24:22.512594 EDT | MaxEsReturn               273
2017-06-03 17:24:22.512822 EDT | MinEsReturn                 6
2017-06-03 17:24:22.513048 EDT | AverageDiscountedReturn    99.9957
2017-06-03 17:24:22.513274 EDT | AverageQLoss                3.01595e-05
2017-06-03 17:24:22.513501 EDT | AveragePolicySurr          -0.0904328
2017-06-03 17:24:22.513733 EDT | AverageQ                    0.0864335
2017-06-03 17:24:22.513962 EDT | AverageAbsQ                 0.0867081
2017-06-03 17:24:22.514187 EDT | AverageY                    0.0864331
2017-06-03 17:24:22.514409 EDT | AverageAbsY                 0.0864627
2017-06-03 17:24:22.514630 EDT | AverageAbsQYDiff            0.00157539
2017-06-03 17:24:22.514850 EDT | AverageAction               0.0042566
2017-06-03 17:24:22.515071 EDT | PolicyRegParamNorm         66.7154
2017-06-03 17:24:22.515296 EDT | QFunRegParamNorm           28.0079
2017-06-03 17:24:22.515521 EDT | -----------------------  --------------
2017-06-03 17:24:22.515870 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #585 | Training started
2017-06-03 17:24:40.321364 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #585 | Training finished
2017-06-03 17:24:40.322033 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #585 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 17:24:40.322300 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #585 | Collecting samples for evaluation
2017-06-03 17:24:49.758200 EDT | -----------------------  --------------
2017-06-03 17:24:49.759024 EDT | Epoch                     585
2017-06-03 17:24:49.759282 EDT | Iteration                 585
2017-06-03 17:24:49.759522 EDT | AverageReturn            1000
2017-06-03 17:24:49.759768 EDT | StdReturn                   0
2017-06-03 17:24:49.760002 EDT | MaxReturn                1000
2017-06-03 17:24:49.760239 EDT | MinReturn                1000
2017-06-03 17:24:49.760472 EDT | AverageEsReturn            31.9333
2017-06-03 17:24:49.760705 EDT | StdEsReturn                25.9589
2017-06-03 17:24:49.761029 EDT | MaxEsReturn                98
2017-06-03 17:24:49.761357 EDT | MinEsReturn                 2
2017-06-03 17:24:49.761707 EDT | AverageDiscountedReturn    99.9957
2017-06-03 17:24:49.762051 EDT | AverageQLoss                3.16679e-05
2017-06-03 17:24:49.762417 EDT | AveragePolicySurr          -0.0904059
2017-06-03 17:24:49.762735 EDT | AverageQ                    0.0862871
2017-06-03 17:24:49.763050 EDT | AverageAbsQ                 0.0865566
2017-06-03 17:24:49.763373 EDT | AverageY                    0.0862908
2017-06-03 17:24:49.763704 EDT | AverageAbsY                 0.08631
2017-06-03 17:24:49.764016 EDT | AverageAbsQYDiff            0.00165361
2017-06-03 17:24:49.764341 EDT | AverageAction               0.10177
2017-06-03 17:24:49.764661 EDT | PolicyRegParamNorm         66.7599
2017-06-03 17:24:49.764973 EDT | QFunRegParamNorm           28.0274
2017-06-03 17:24:49.765282 EDT | -----------------------  --------------
2017-06-03 17:24:49.765723 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #586 | Training started
2017-06-03 17:25:08.904528 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #586 | Training finished
2017-06-03 17:25:08.905463 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #586 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 17:25:08.905750 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #586 | Collecting samples for evaluation
2017-06-03 17:25:16.357741 EDT | -----------------------  --------------
2017-06-03 17:25:16.358778 EDT | Epoch                     586
2017-06-03 17:25:16.359059 EDT | Iteration                 586
2017-06-03 17:25:16.359309 EDT | AverageReturn            1000
2017-06-03 17:25:16.359545 EDT | StdReturn                   0
2017-06-03 17:25:16.359788 EDT | MaxReturn                1000
2017-06-03 17:25:16.360023 EDT | MinReturn                1000
2017-06-03 17:25:16.360253 EDT | AverageEsReturn            29.1515
2017-06-03 17:25:16.360489 EDT | StdEsReturn                27.8482
2017-06-03 17:25:16.360718 EDT | MaxEsReturn               138
2017-06-03 17:25:16.360948 EDT | MinEsReturn                 4
2017-06-03 17:25:16.361175 EDT | AverageDiscountedReturn    99.9957
2017-06-03 17:25:16.361418 EDT | AverageQLoss                2.80172e-05
2017-06-03 17:25:16.361646 EDT | AveragePolicySurr          -0.0902474
2017-06-03 17:25:16.362380 EDT | AverageQ                    0.0864462
2017-06-03 17:25:16.362700 EDT | AverageAbsQ                 0.0866724
2017-06-03 17:25:16.363020 EDT | AverageY                    0.0864358
2017-06-03 17:25:16.363357 EDT | AverageAbsY                 0.0864574
2017-06-03 17:25:16.363670 EDT | AverageAbsQYDiff            0.00140695
2017-06-03 17:25:16.363980 EDT | AverageAction               0.0836178
2017-06-03 17:25:16.364310 EDT | PolicyRegParamNorm         66.7482
2017-06-03 17:25:16.364624 EDT | QFunRegParamNorm           28.0315
2017-06-03 17:25:16.364938 EDT | -----------------------  --------------
2017-06-03 17:25:16.365409 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #587 | Training started
2017-06-03 17:25:35.512770 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #587 | Training finished
2017-06-03 17:25:35.513652 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #587 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 17:25:35.514081 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #587 | Collecting samples for evaluation
2017-06-03 17:25:45.525360 EDT | -----------------------  --------------
2017-06-03 17:25:45.526301 EDT | Epoch                     587
2017-06-03 17:25:45.526675 EDT | Iteration                 587
2017-06-03 17:25:45.526964 EDT | AverageReturn            1000
2017-06-03 17:25:45.527206 EDT | StdReturn                   0
2017-06-03 17:25:45.527468 EDT | MaxReturn                1000
2017-06-03 17:25:45.527708 EDT | MinReturn                1000
2017-06-03 17:25:45.528010 EDT | AverageEsReturn            36.6923
2017-06-03 17:25:45.528438 EDT | StdEsReturn                26.2602
2017-06-03 17:25:45.528816 EDT | MaxEsReturn                91
2017-06-03 17:25:45.529166 EDT | MinEsReturn                 3
2017-06-03 17:25:45.529579 EDT | AverageDiscountedReturn    99.9957
2017-06-03 17:25:45.529958 EDT | AverageQLoss                2.40222e-05
2017-06-03 17:25:45.530284 EDT | AveragePolicySurr          -0.0902036
2017-06-03 17:25:45.530689 EDT | AverageQ                    0.0860672
2017-06-03 17:25:45.531090 EDT | AverageAbsQ                 0.0862847
2017-06-03 17:25:45.531443 EDT | AverageY                    0.0860748
2017-06-03 17:25:45.531848 EDT | AverageAbsY                 0.0861031
2017-06-03 17:25:45.532200 EDT | AverageAbsQYDiff            0.0013411
2017-06-03 17:25:45.532552 EDT | AverageAction               0.420921
2017-06-03 17:25:45.532875 EDT | PolicyRegParamNorm         66.761
2017-06-03 17:25:45.533209 EDT | QFunRegParamNorm           28.0431
2017-06-03 17:25:45.533552 EDT | -----------------------  --------------
2017-06-03 17:25:45.534191 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #588 | Training started
2017-06-03 17:26:03.980680 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #588 | Training finished
2017-06-03 17:26:03.981583 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #588 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 17:26:03.982010 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #588 | Collecting samples for evaluation
2017-06-03 17:26:13.024740 EDT | -----------------------  --------------
2017-06-03 17:26:13.025598 EDT | Epoch                     588
2017-06-03 17:26:13.025879 EDT | Iteration                 588
2017-06-03 17:26:13.026124 EDT | AverageReturn            1000
2017-06-03 17:26:13.026369 EDT | StdReturn                   0
2017-06-03 17:26:13.026604 EDT | MaxReturn                1000
2017-06-03 17:26:13.026840 EDT | MinReturn                1000
2017-06-03 17:26:13.027074 EDT | AverageEsReturn            36.4138
2017-06-03 17:26:13.027320 EDT | StdEsReturn                33.6928
2017-06-03 17:26:13.027578 EDT | MaxEsReturn               128
2017-06-03 17:26:13.027815 EDT | MinEsReturn                 4
2017-06-03 17:26:13.028059 EDT | AverageDiscountedReturn    99.9957
2017-06-03 17:26:13.028292 EDT | AverageQLoss                2.87482e-05
2017-06-03 17:26:13.028524 EDT | AveragePolicySurr          -0.0903508
2017-06-03 17:26:13.028755 EDT | AverageQ                    0.0862291
2017-06-03 17:26:13.028998 EDT | AverageAbsQ                 0.0864888
2017-06-03 17:26:13.029231 EDT | AverageY                    0.0862273
2017-06-03 17:26:13.029461 EDT | AverageAbsY                 0.086247
2017-06-03 17:26:13.029699 EDT | AverageAbsQYDiff            0.00149689
2017-06-03 17:26:13.029937 EDT | AverageAction               0.00581247
2017-06-03 17:26:13.030185 EDT | PolicyRegParamNorm         66.742
2017-06-03 17:26:13.030417 EDT | QFunRegParamNorm           28.0465
2017-06-03 17:26:13.030651 EDT | -----------------------  --------------
2017-06-03 17:26:13.031036 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #589 | Training started
2017-06-03 17:26:31.904287 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #589 | Training finished
2017-06-03 17:26:31.905135 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #589 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 17:26:31.905403 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #589 | Collecting samples for evaluation
2017-06-03 17:26:42.289062 EDT | -----------------------  --------------
2017-06-03 17:26:42.289420 EDT | Epoch                     589
2017-06-03 17:26:42.289674 EDT | Iteration                 589
2017-06-03 17:26:42.289932 EDT | AverageReturn            1000
2017-06-03 17:26:42.290168 EDT | StdReturn                   0
2017-06-03 17:26:42.290406 EDT | MaxReturn                1000
2017-06-03 17:26:42.290639 EDT | MinReturn                1000
2017-06-03 17:26:42.290897 EDT | AverageEsReturn            37.1111
2017-06-03 17:26:42.291132 EDT | StdEsReturn                20.1501
2017-06-03 17:26:42.291364 EDT | MaxEsReturn                76
2017-06-03 17:26:42.291595 EDT | MinEsReturn                 4
2017-06-03 17:26:42.291826 EDT | AverageDiscountedReturn    99.9957
2017-06-03 17:26:42.292091 EDT | AverageQLoss                2.42258e-05
2017-06-03 17:26:42.292326 EDT | AveragePolicySurr          -0.0901758
2017-06-03 17:26:42.292557 EDT | AverageQ                    0.0862971
2017-06-03 17:26:42.292788 EDT | AverageAbsQ                 0.0865076
2017-06-03 17:26:42.293041 EDT | AverageY                    0.0863009
2017-06-03 17:26:42.293272 EDT | AverageAbsY                 0.086321
2017-06-03 17:26:42.293503 EDT | AverageAbsQYDiff            0.00139847
2017-06-03 17:26:42.293744 EDT | AverageAction               0.367554
2017-06-03 17:26:42.293977 EDT | PolicyRegParamNorm         66.763
2017-06-03 17:26:42.294217 EDT | QFunRegParamNorm           28.043
2017-06-03 17:26:42.294471 EDT | -----------------------  --------------
2017-06-03 17:26:42.294816 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #590 | Training started
2017-06-03 17:27:00.659382 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #590 | Training finished
2017-06-03 17:27:00.660221 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #590 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 17:27:00.660554 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #590 | Collecting samples for evaluation
2017-06-03 17:27:11.055594 EDT | -----------------------  --------------
2017-06-03 17:27:11.056021 EDT | Epoch                     590
2017-06-03 17:27:11.056284 EDT | Iteration                 590
2017-06-03 17:27:11.056538 EDT | AverageReturn            1000
2017-06-03 17:27:11.056786 EDT | StdReturn                   0
2017-06-03 17:27:11.057032 EDT | MaxReturn                1000
2017-06-03 17:27:11.057276 EDT | MinReturn                1000
2017-06-03 17:27:11.057521 EDT | AverageEsReturn            39.3704
2017-06-03 17:27:11.057806 EDT | StdEsReturn                41.1052
2017-06-03 17:27:11.058058 EDT | MaxEsReturn               165
2017-06-03 17:27:11.058304 EDT | MinEsReturn                 3
2017-06-03 17:27:11.058546 EDT | AverageDiscountedReturn    99.9957
2017-06-03 17:27:11.058799 EDT | AverageQLoss                2.86776e-05
2017-06-03 17:27:11.059048 EDT | AveragePolicySurr          -0.0902731
2017-06-03 17:27:11.059295 EDT | AverageQ                    0.0863658
2017-06-03 17:27:11.059537 EDT | AverageAbsQ                 0.0866247
2017-06-03 17:27:11.059779 EDT | AverageY                    0.0863629
2017-06-03 17:27:11.060030 EDT | AverageAbsY                 0.0863877
2017-06-03 17:27:11.060271 EDT | AverageAbsQYDiff            0.00148577
2017-06-03 17:27:11.060511 EDT | AverageAction               0.0175614
2017-06-03 17:27:11.060751 EDT | PolicyRegParamNorm         66.7851
2017-06-03 17:27:11.061011 EDT | QFunRegParamNorm           28.0585
2017-06-03 17:27:11.061294 EDT | -----------------------  --------------
2017-06-03 17:27:11.061711 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #591 | Training started
2017-06-03 17:27:29.627112 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #591 | Training finished
2017-06-03 17:27:29.627727 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #591 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 17:27:29.627999 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #591 | Collecting samples for evaluation
2017-06-03 17:27:38.830237 EDT | -----------------------  --------------
2017-06-03 17:27:38.831076 EDT | Epoch                     591
2017-06-03 17:27:38.831335 EDT | Iteration                 591
2017-06-03 17:27:38.831571 EDT | AverageReturn            1000
2017-06-03 17:27:38.831803 EDT | StdReturn                   0
2017-06-03 17:27:38.832032 EDT | MaxReturn                1000
2017-06-03 17:27:38.832260 EDT | MinReturn                1000
2017-06-03 17:27:38.832490 EDT | AverageEsReturn            44.45
2017-06-03 17:27:38.832719 EDT | StdEsReturn                47.6146
2017-06-03 17:27:38.833023 EDT | MaxEsReturn               191
2017-06-03 17:27:38.833328 EDT | MinEsReturn                 4
2017-06-03 17:27:38.833661 EDT | AverageDiscountedReturn    99.9957
2017-06-03 17:27:38.833962 EDT | AverageQLoss                2.64373e-05
2017-06-03 17:27:38.834208 EDT | AveragePolicySurr          -0.0901496
2017-06-03 17:27:38.834460 EDT | AverageQ                    0.0861538
2017-06-03 17:27:38.834708 EDT | AverageAbsQ                 0.0864218
2017-06-03 17:27:38.834954 EDT | AverageY                    0.0861513
2017-06-03 17:27:38.835186 EDT | AverageAbsY                 0.0861696
2017-06-03 17:27:38.835415 EDT | AverageAbsQYDiff            0.00151206
2017-06-03 17:27:38.835644 EDT | AverageAction               0.00635173
2017-06-03 17:27:38.835904 EDT | PolicyRegParamNorm         66.8148
2017-06-03 17:27:38.836155 EDT | QFunRegParamNorm           28.058
2017-06-03 17:27:38.836399 EDT | -----------------------  --------------
2017-06-03 17:27:38.836767 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #592 | Training started
2017-06-03 17:27:57.905555 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #592 | Training finished
2017-06-03 17:27:57.906489 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #592 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 17:27:57.906802 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #592 | Collecting samples for evaluation
2017-06-03 17:28:07.084844 EDT | -----------------------  --------------
2017-06-03 17:28:07.085778 EDT | Epoch                     592
2017-06-03 17:28:07.086053 EDT | Iteration                 592
2017-06-03 17:28:07.086294 EDT | AverageReturn            1000
2017-06-03 17:28:07.086548 EDT | StdReturn                   0
2017-06-03 17:28:07.086780 EDT | MaxReturn                1000
2017-06-03 17:28:07.087011 EDT | MinReturn                1000
2017-06-03 17:28:07.087241 EDT | AverageEsReturn            29.5556
2017-06-03 17:28:07.087471 EDT | StdEsReturn                27.4949
2017-06-03 17:28:07.087700 EDT | MaxEsReturn               118
2017-06-03 17:28:07.087932 EDT | MinEsReturn                 5
2017-06-03 17:28:07.088161 EDT | AverageDiscountedReturn    99.9957
2017-06-03 17:28:07.088390 EDT | AverageQLoss                2.38004e-05
2017-06-03 17:28:07.088618 EDT | AveragePolicySurr          -0.0902469
2017-06-03 17:28:07.088853 EDT | AverageQ                    0.0862361
2017-06-03 17:28:07.089081 EDT | AverageAbsQ                 0.0864346
2017-06-03 17:28:07.089310 EDT | AverageY                    0.0862387
2017-06-03 17:28:07.089541 EDT | AverageAbsY                 0.0862498
2017-06-03 17:28:07.089818 EDT | AverageAbsQYDiff            0.00129399
2017-06-03 17:28:07.090063 EDT | AverageAction               0.0493379
2017-06-03 17:28:07.090308 EDT | PolicyRegParamNorm         66.7944
2017-06-03 17:28:07.090552 EDT | QFunRegParamNorm           28.0698
2017-06-03 17:28:07.090796 EDT | -----------------------  --------------
2017-06-03 17:28:07.091236 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #593 | Training started
2017-06-03 17:28:26.503492 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #593 | Training finished
2017-06-03 17:28:26.504372 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #593 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 17:28:26.504796 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #593 | Collecting samples for evaluation
2017-06-03 17:28:35.765232 EDT | -----------------------  --------------
2017-06-03 17:28:35.766061 EDT | Epoch                     593
2017-06-03 17:28:35.766324 EDT | Iteration                 593
2017-06-03 17:28:35.766563 EDT | AverageReturn            1000
2017-06-03 17:28:35.766799 EDT | StdReturn                   0
2017-06-03 17:28:35.767034 EDT | MaxReturn                1000
2017-06-03 17:28:35.767263 EDT | MinReturn                1000
2017-06-03 17:28:35.767491 EDT | AverageEsReturn            35.7586
2017-06-03 17:28:35.767718 EDT | StdEsReturn                28.2204
2017-06-03 17:28:35.767945 EDT | MaxEsReturn               126
2017-06-03 17:28:35.768173 EDT | MinEsReturn                 3
2017-06-03 17:28:35.768400 EDT | AverageDiscountedReturn    99.9957
2017-06-03 17:28:35.768625 EDT | AverageQLoss                2.75273e-05
2017-06-03 17:28:35.768851 EDT | AveragePolicySurr          -0.0901974
2017-06-03 17:28:35.769077 EDT | AverageQ                    0.0863186
2017-06-03 17:28:35.769334 EDT | AverageAbsQ                 0.086546
2017-06-03 17:28:35.769566 EDT | AverageY                    0.0863185
2017-06-03 17:28:35.769830 EDT | AverageAbsY                 0.0863219
2017-06-03 17:28:35.770071 EDT | AverageAbsQYDiff            0.0014468
2017-06-03 17:28:35.770316 EDT | AverageAction               0.00052503
2017-06-03 17:28:35.770568 EDT | PolicyRegParamNorm         66.8457
2017-06-03 17:28:35.770809 EDT | QFunRegParamNorm           28.077
2017-06-03 17:28:35.771072 EDT | -----------------------  --------------
2017-06-03 17:28:35.771424 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #594 | Training started
2017-06-03 17:28:53.958966 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #594 | Training finished
2017-06-03 17:28:53.960004 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #594 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 17:28:53.960386 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #594 | Collecting samples for evaluation
2017-06-03 17:29:03.027061 EDT | -----------------------  --------------
2017-06-03 17:29:03.027948 EDT | Epoch                     594
2017-06-03 17:29:03.028237 EDT | Iteration                 594
2017-06-03 17:29:03.028482 EDT | AverageReturn            1000
2017-06-03 17:29:03.028721 EDT | StdReturn                   0
2017-06-03 17:29:03.028956 EDT | MaxReturn                1000
2017-06-03 17:29:03.029190 EDT | MinReturn                1000
2017-06-03 17:29:03.029433 EDT | AverageEsReturn            45.8571
2017-06-03 17:29:03.029667 EDT | StdEsReturn                35.7602
2017-06-03 17:29:03.029911 EDT | MaxEsReturn               144
2017-06-03 17:29:03.030144 EDT | MinEsReturn                 4
2017-06-03 17:29:03.030377 EDT | AverageDiscountedReturn    99.9957
2017-06-03 17:29:03.030609 EDT | AverageQLoss                3.02331e-05
2017-06-03 17:29:03.030841 EDT | AveragePolicySurr          -0.090176
2017-06-03 17:29:03.031074 EDT | AverageQ                    0.0862919
2017-06-03 17:29:03.031305 EDT | AverageAbsQ                 0.0865771
2017-06-03 17:29:03.031537 EDT | AverageY                    0.0862904
2017-06-03 17:29:03.031769 EDT | AverageAbsY                 0.0863025
2017-06-03 17:29:03.032001 EDT | AverageAbsQYDiff            0.00154961
2017-06-03 17:29:03.032232 EDT | AverageAction               0.000119161
2017-06-03 17:29:03.032464 EDT | PolicyRegParamNorm         66.8774
2017-06-03 17:29:03.032694 EDT | QFunRegParamNorm           28.0958
2017-06-03 17:29:03.032925 EDT | -----------------------  --------------
2017-06-03 17:29:03.033305 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #595 | Training started
2017-06-03 17:29:22.153368 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #595 | Training finished
2017-06-03 17:29:22.154358 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #595 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 17:29:22.154626 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #595 | Collecting samples for evaluation
2017-06-03 17:29:32.181075 EDT | -----------------------  --------------
2017-06-03 17:29:32.181913 EDT | Epoch                     595
2017-06-03 17:29:32.182181 EDT | Iteration                 595
2017-06-03 17:29:32.182426 EDT | AverageReturn            1000
2017-06-03 17:29:32.182668 EDT | StdReturn                   0
2017-06-03 17:29:32.182906 EDT | MaxReturn                1000
2017-06-03 17:29:32.183149 EDT | MinReturn                1000
2017-06-03 17:29:32.183396 EDT | AverageEsReturn            37.4074
2017-06-03 17:29:32.183633 EDT | StdEsReturn                41.5801
2017-06-03 17:29:32.183869 EDT | MaxEsReturn               172
2017-06-03 17:29:32.184113 EDT | MinEsReturn                 3
2017-06-03 17:29:32.184349 EDT | AverageDiscountedReturn    99.9957
2017-06-03 17:29:32.184584 EDT | AverageQLoss                2.47482e-05
2017-06-03 17:29:32.184835 EDT | AveragePolicySurr          -0.0901726
2017-06-03 17:29:32.185110 EDT | AverageQ                    0.0862501
2017-06-03 17:29:32.185347 EDT | AverageAbsQ                 0.0864882
2017-06-03 17:29:32.185597 EDT | AverageY                    0.0862557
2017-06-03 17:29:32.185860 EDT | AverageAbsY                 0.0862685
2017-06-03 17:29:32.186123 EDT | AverageAbsQYDiff            0.00141495
2017-06-03 17:29:32.186372 EDT | AverageAction               0.00248808
2017-06-03 17:29:32.186622 EDT | PolicyRegParamNorm         66.8776
2017-06-03 17:29:32.186870 EDT | QFunRegParamNorm           28.1053
2017-06-03 17:29:32.187117 EDT | -----------------------  --------------
2017-06-03 17:29:32.187485 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #596 | Training started
2017-06-03 17:29:52.220691 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #596 | Training finished
2017-06-03 17:29:52.221655 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #596 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 17:29:52.222110 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #596 | Collecting samples for evaluation
2017-06-03 17:30:03.000067 EDT | -----------------------  --------------
2017-06-03 17:30:03.000928 EDT | Epoch                     596
2017-06-03 17:30:03.001366 EDT | Iteration                 596
2017-06-03 17:30:03.001720 EDT | AverageReturn            1000
2017-06-03 17:30:03.002087 EDT | StdReturn                   0
2017-06-03 17:30:03.002471 EDT | MaxReturn                1000
2017-06-03 17:30:03.002869 EDT | MinReturn                1000
2017-06-03 17:30:03.003254 EDT | AverageEsReturn            29.3824
2017-06-03 17:30:03.003630 EDT | StdEsReturn                24.3383
2017-06-03 17:30:03.003971 EDT | MaxEsReturn               100
2017-06-03 17:30:03.004213 EDT | MinEsReturn                 3
2017-06-03 17:30:03.004452 EDT | AverageDiscountedReturn    99.9957
2017-06-03 17:30:03.004684 EDT | AverageQLoss                3.15102e-05
2017-06-03 17:30:03.004909 EDT | AveragePolicySurr          -0.0900782
2017-06-03 17:30:03.005147 EDT | AverageQ                    0.0860587
2017-06-03 17:30:03.005370 EDT | AverageAbsQ                 0.0863511
2017-06-03 17:30:03.005592 EDT | AverageY                    0.0860577
2017-06-03 17:30:03.005859 EDT | AverageAbsY                 0.0860685
2017-06-03 17:30:03.006097 EDT | AverageAbsQYDiff            0.00154349
2017-06-03 17:30:03.006345 EDT | AverageAction               0.034171
2017-06-03 17:30:03.006628 EDT | PolicyRegParamNorm         66.8738
2017-06-03 17:30:03.006889 EDT | QFunRegParamNorm           28.1074
2017-06-03 17:30:03.007159 EDT | -----------------------  --------------
2017-06-03 17:30:03.007559 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #597 | Training started
2017-06-03 17:30:21.443317 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #597 | Training finished
2017-06-03 17:30:21.444173 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #597 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 17:30:21.444436 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #597 | Collecting samples for evaluation
2017-06-03 17:30:30.617958 EDT | -----------------------  --------------
2017-06-03 17:30:30.619780 EDT | Epoch                     597
2017-06-03 17:30:30.620601 EDT | Iteration                 597
2017-06-03 17:30:30.620887 EDT | AverageReturn            1000
2017-06-03 17:30:30.621146 EDT | StdReturn                   0
2017-06-03 17:30:30.621451 EDT | MaxReturn                1000
2017-06-03 17:30:30.621721 EDT | MinReturn                1000
2017-06-03 17:30:30.621979 EDT | AverageEsReturn            38.2
2017-06-03 17:30:30.622237 EDT | StdEsReturn                26.1687
2017-06-03 17:30:30.622495 EDT | MaxEsReturn               118
2017-06-03 17:30:30.622765 EDT | MinEsReturn                 3
2017-06-03 17:30:30.623024 EDT | AverageDiscountedReturn    99.9957
2017-06-03 17:30:30.623285 EDT | AverageQLoss                2.89242e-05
2017-06-03 17:30:30.623556 EDT | AveragePolicySurr          -0.0900073
2017-06-03 17:30:30.623841 EDT | AverageQ                    0.0858705
2017-06-03 17:30:30.624093 EDT | AverageAbsQ                 0.0860905
2017-06-03 17:30:30.624364 EDT | AverageY                    0.0858674
2017-06-03 17:30:30.624635 EDT | AverageAbsY                 0.0858854
2017-06-03 17:30:30.624895 EDT | AverageAbsQYDiff            0.00149802
2017-06-03 17:30:30.625161 EDT | AverageAction               0.00143244
2017-06-03 17:30:30.625418 EDT | PolicyRegParamNorm         66.8913
2017-06-03 17:30:30.625690 EDT | QFunRegParamNorm           28.0988
2017-06-03 17:30:30.625956 EDT | -----------------------  --------------
2017-06-03 17:30:30.626386 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #598 | Training started
2017-06-03 17:30:48.240362 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #598 | Training finished
2017-06-03 17:30:48.241289 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #598 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 17:30:48.241761 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #598 | Collecting samples for evaluation
2017-06-03 17:30:58.904468 EDT | -----------------------  --------------
2017-06-03 17:30:58.904987 EDT | Epoch                     598
2017-06-03 17:30:58.905417 EDT | Iteration                 598
2017-06-03 17:30:58.905836 EDT | AverageReturn            1000
2017-06-03 17:30:58.906259 EDT | StdReturn                   0
2017-06-03 17:30:58.906637 EDT | MaxReturn                1000
2017-06-03 17:30:58.907056 EDT | MinReturn                1000
2017-06-03 17:30:58.907352 EDT | AverageEsReturn            32.4545
2017-06-03 17:30:58.907598 EDT | StdEsReturn                25.6055
2017-06-03 17:30:58.907841 EDT | MaxEsReturn               105
2017-06-03 17:30:58.908078 EDT | MinEsReturn                 3
2017-06-03 17:30:58.908327 EDT | AverageDiscountedReturn    99.9957
2017-06-03 17:30:58.908559 EDT | AverageQLoss                2.92596e-05
2017-06-03 17:30:58.908793 EDT | AveragePolicySurr          -0.0899715
2017-06-03 17:30:58.909026 EDT | AverageQ                    0.0860387
2017-06-03 17:30:58.909275 EDT | AverageAbsQ                 0.0862738
2017-06-03 17:30:58.909508 EDT | AverageY                    0.0860414
2017-06-03 17:30:58.909751 EDT | AverageAbsY                 0.0860541
2017-06-03 17:30:58.909986 EDT | AverageAbsQYDiff            0.00145554
2017-06-03 17:30:58.910224 EDT | AverageAction               0.0112002
2017-06-03 17:30:58.910455 EDT | PolicyRegParamNorm         66.8798
2017-06-03 17:30:58.910687 EDT | QFunRegParamNorm           28.1126
2017-06-03 17:30:58.910919 EDT | -----------------------  --------------
2017-06-03 17:30:58.911276 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #599 | Training started
2017-06-03 17:31:17.317316 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #599 | Training finished
2017-06-03 17:31:17.318228 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #599 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 17:31:17.318590 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #599 | Collecting samples for evaluation
2017-06-03 17:31:26.786482 EDT | -----------------------  --------------
2017-06-03 17:31:26.787418 EDT | Epoch                     599
2017-06-03 17:31:26.787705 EDT | Iteration                 599
2017-06-03 17:31:26.787946 EDT | AverageReturn            1000
2017-06-03 17:31:26.788178 EDT | StdReturn                   0
2017-06-03 17:31:26.788404 EDT | MaxReturn                1000
2017-06-03 17:31:26.788629 EDT | MinReturn                1000
2017-06-03 17:31:26.788855 EDT | AverageEsReturn            59.5294
2017-06-03 17:31:26.789096 EDT | StdEsReturn                57.4396
2017-06-03 17:31:26.789329 EDT | MaxEsReturn               237
2017-06-03 17:31:26.789554 EDT | MinEsReturn                 3
2017-06-03 17:31:26.789829 EDT | AverageDiscountedReturn    99.9957
2017-06-03 17:31:26.790102 EDT | AverageQLoss                2.60944e-05
2017-06-03 17:31:26.790374 EDT | AveragePolicySurr          -0.0900018
2017-06-03 17:31:26.790694 EDT | AverageQ                    0.0861719
2017-06-03 17:31:26.790924 EDT | AverageAbsQ                 0.0863939
2017-06-03 17:31:26.791152 EDT | AverageY                    0.0861686
2017-06-03 17:31:26.791378 EDT | AverageAbsY                 0.0861812
2017-06-03 17:31:26.791605 EDT | AverageAbsQYDiff            0.00139937
2017-06-03 17:31:26.791832 EDT | AverageAction               0.0254773
2017-06-03 17:31:26.792069 EDT | PolicyRegParamNorm         66.8978
2017-06-03 17:31:26.792410 EDT | QFunRegParamNorm           28.1209
2017-06-03 17:31:26.792816 EDT | -----------------------  --------------
2017-06-03 17:31:26.793335 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #600 | Training started
2017-06-03 17:31:44.733947 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #600 | Training finished
2017-06-03 17:31:44.734877 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #600 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 17:31:44.735156 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #600 | Collecting samples for evaluation
2017-06-03 17:31:53.785077 EDT | -----------------------  -------------
2017-06-03 17:31:53.785897 EDT | Epoch                     600
2017-06-03 17:31:53.786159 EDT | Iteration                 600
2017-06-03 17:31:53.786402 EDT | AverageReturn            1000
2017-06-03 17:31:53.786646 EDT | StdReturn                   0
2017-06-03 17:31:53.786888 EDT | MaxReturn                1000
2017-06-03 17:31:53.787120 EDT | MinReturn                1000
2017-06-03 17:31:53.787352 EDT | AverageEsReturn            37.0741
2017-06-03 17:31:53.787585 EDT | StdEsReturn                27.6846
2017-06-03 17:31:53.787818 EDT | MaxEsReturn               120
2017-06-03 17:31:53.788050 EDT | MinEsReturn                 4
2017-06-03 17:31:53.788284 EDT | AverageDiscountedReturn    99.9957
2017-06-03 17:31:53.788515 EDT | AverageQLoss                3.5932e-05
2017-06-03 17:31:53.788747 EDT | AveragePolicySurr          -0.0900152
2017-06-03 17:31:53.788978 EDT | AverageQ                    0.085981
2017-06-03 17:31:53.789208 EDT | AverageAbsQ                 0.0862644
2017-06-03 17:31:53.789438 EDT | AverageY                    0.0859836
2017-06-03 17:31:53.789667 EDT | AverageAbsY                 0.0860035
2017-06-03 17:31:53.789915 EDT | AverageAbsQYDiff            0.0016117
2017-06-03 17:31:53.790147 EDT | AverageAction               0.275671
2017-06-03 17:31:53.790378 EDT | PolicyRegParamNorm         66.9258
2017-06-03 17:31:53.790609 EDT | QFunRegParamNorm           28.1368
2017-06-03 17:31:53.790840 EDT | -----------------------  -------------
2017-06-03 17:31:53.791245 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #601 | Training started
2017-06-03 17:32:13.039878 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #601 | Training finished
2017-06-03 17:32:13.040761 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #601 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 17:32:13.041163 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #601 | Collecting samples for evaluation
2017-06-03 17:32:23.758449 EDT | -----------------------  --------------
2017-06-03 17:32:23.759424 EDT | Epoch                     601
2017-06-03 17:32:23.759711 EDT | Iteration                 601
2017-06-03 17:32:23.759950 EDT | AverageReturn            1000
2017-06-03 17:32:23.760183 EDT | StdReturn                   0
2017-06-03 17:32:23.760414 EDT | MaxReturn                1000
2017-06-03 17:32:23.760653 EDT | MinReturn                1000
2017-06-03 17:32:23.760880 EDT | AverageEsReturn            41
2017-06-03 17:32:23.761158 EDT | StdEsReturn                25.8827
2017-06-03 17:32:23.761390 EDT | MaxEsReturn               108
2017-06-03 17:32:23.761633 EDT | MinEsReturn                 4
2017-06-03 17:32:23.762240 EDT | AverageDiscountedReturn    99.9957
2017-06-03 17:32:23.762579 EDT | AverageQLoss                2.69231e-05
2017-06-03 17:32:23.762895 EDT | AveragePolicySurr          -0.0899166
2017-06-03 17:32:23.763229 EDT | AverageQ                    0.0860969
2017-06-03 17:32:23.763546 EDT | AverageAbsQ                 0.0863068
2017-06-03 17:32:23.763862 EDT | AverageY                    0.086093
2017-06-03 17:32:23.764202 EDT | AverageAbsY                 0.0861132
2017-06-03 17:32:23.764527 EDT | AverageAbsQYDiff            0.00145567
2017-06-03 17:32:23.764842 EDT | AverageAction               0.000633401
2017-06-03 17:32:23.765164 EDT | PolicyRegParamNorm         66.9092
2017-06-03 17:32:23.765488 EDT | QFunRegParamNorm           28.1503
2017-06-03 17:32:23.765808 EDT | -----------------------  --------------
2017-06-03 17:32:23.766251 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #602 | Training started
2017-06-03 17:32:42.038816 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #602 | Training finished
2017-06-03 17:32:42.039808 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #602 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 17:32:42.040222 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #602 | Collecting samples for evaluation
2017-06-03 17:32:52.915552 EDT | -----------------------  --------------
2017-06-03 17:32:52.916611 EDT | Epoch                     602
2017-06-03 17:32:52.916943 EDT | Iteration                 602
2017-06-03 17:32:52.917265 EDT | AverageReturn            1000
2017-06-03 17:32:52.917542 EDT | StdReturn                   0
2017-06-03 17:32:52.917810 EDT | MaxReturn                1000
2017-06-03 17:32:52.918135 EDT | MinReturn                1000
2017-06-03 17:32:52.918432 EDT | AverageEsReturn            33.5484
2017-06-03 17:32:52.918677 EDT | StdEsReturn                25.7868
2017-06-03 17:32:52.918914 EDT | MaxEsReturn                94
2017-06-03 17:32:52.919145 EDT | MinEsReturn                 3
2017-06-03 17:32:52.919373 EDT | AverageDiscountedReturn    99.9957
2017-06-03 17:32:52.919599 EDT | AverageQLoss                2.72099e-05
2017-06-03 17:32:52.919827 EDT | AveragePolicySurr          -0.0899597
2017-06-03 17:32:52.920077 EDT | AverageQ                    0.0860188
2017-06-03 17:32:52.920304 EDT | AverageAbsQ                 0.086231
2017-06-03 17:32:52.920596 EDT | AverageY                    0.0860223
2017-06-03 17:32:52.920910 EDT | AverageAbsY                 0.0860323
2017-06-03 17:32:52.921180 EDT | AverageAbsQYDiff            0.00133307
2017-06-03 17:32:52.921446 EDT | AverageAction               0.0030218
2017-06-03 17:32:52.922398 EDT | PolicyRegParamNorm         66.9597
2017-06-03 17:32:52.922824 EDT | QFunRegParamNorm           28.1621
2017-06-03 17:32:52.923178 EDT | -----------------------  --------------
2017-06-03 17:32:52.923702 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #603 | Training started
2017-06-03 17:33:11.724273 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #603 | Training finished
2017-06-03 17:33:11.725167 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #603 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 17:33:11.725439 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #603 | Collecting samples for evaluation
2017-06-03 17:33:22.185888 EDT | -----------------------  --------------
2017-06-03 17:33:22.186907 EDT | Epoch                     603
2017-06-03 17:33:22.187172 EDT | Iteration                 603
2017-06-03 17:33:22.187433 EDT | AverageReturn            1000
2017-06-03 17:33:22.187667 EDT | StdReturn                   0
2017-06-03 17:33:22.187895 EDT | MaxReturn                1000
2017-06-03 17:33:22.188120 EDT | MinReturn                1000
2017-06-03 17:33:22.188343 EDT | AverageEsReturn            41.8696
2017-06-03 17:33:22.188576 EDT | StdEsReturn                33.446
2017-06-03 17:33:22.188799 EDT | MaxEsReturn               141
2017-06-03 17:33:22.189021 EDT | MinEsReturn                 4
2017-06-03 17:33:22.189244 EDT | AverageDiscountedReturn    99.9957
2017-06-03 17:33:22.189466 EDT | AverageQLoss                2.93197e-05
2017-06-03 17:33:22.190072 EDT | AveragePolicySurr          -0.0899105
2017-06-03 17:33:22.190388 EDT | AverageQ                    0.0858571
2017-06-03 17:33:22.190713 EDT | AverageAbsQ                 0.0860878
2017-06-03 17:33:22.191023 EDT | AverageY                    0.0858589
2017-06-03 17:33:22.191335 EDT | AverageAbsY                 0.0858655
2017-06-03 17:33:22.191647 EDT | AverageAbsQYDiff            0.00145137
2017-06-03 17:33:22.191954 EDT | AverageAction               0.0120654
2017-06-03 17:33:22.192265 EDT | PolicyRegParamNorm         66.9732
2017-06-03 17:33:22.192570 EDT | QFunRegParamNorm           28.1647
2017-06-03 17:33:22.192875 EDT | -----------------------  --------------
2017-06-03 17:33:22.193354 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #604 | Training started
2017-06-03 17:33:41.518867 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #604 | Training finished
2017-06-03 17:33:41.520118 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #604 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 17:33:41.520537 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #604 | Collecting samples for evaluation
2017-06-03 17:33:52.744374 EDT | -----------------------  --------------
2017-06-03 17:33:52.745417 EDT | Epoch                     604
2017-06-03 17:33:52.745686 EDT | Iteration                 604
2017-06-03 17:33:52.745939 EDT | AverageReturn            1000
2017-06-03 17:33:52.746171 EDT | StdReturn                   0
2017-06-03 17:33:52.746409 EDT | MaxReturn                1000
2017-06-03 17:33:52.746644 EDT | MinReturn                1000
2017-06-03 17:33:52.747921 EDT | AverageEsReturn            36.7143
2017-06-03 17:33:52.748473 EDT | StdEsReturn                35.3097
2017-06-03 17:33:52.748982 EDT | MaxEsReturn               160
2017-06-03 17:33:52.749306 EDT | MinEsReturn                 4
2017-06-03 17:33:52.749926 EDT | AverageDiscountedReturn    99.9957
2017-06-03 17:33:52.750470 EDT | AverageQLoss                2.71955e-05
2017-06-03 17:33:52.750789 EDT | AveragePolicySurr          -0.0898092
2017-06-03 17:33:52.751105 EDT | AverageQ                    0.0857022
2017-06-03 17:33:52.751422 EDT | AverageAbsQ                 0.085925
2017-06-03 17:33:52.751736 EDT | AverageY                    0.0856968
2017-06-03 17:33:52.752062 EDT | AverageAbsY                 0.0857013
2017-06-03 17:33:52.752374 EDT | AverageAbsQYDiff            0.00138398
2017-06-03 17:33:52.752681 EDT | AverageAction               8.8597e-05
2017-06-03 17:33:52.752998 EDT | PolicyRegParamNorm         67.0426
2017-06-03 17:33:52.753303 EDT | QFunRegParamNorm           28.1659
2017-06-03 17:33:52.753609 EDT | -----------------------  --------------
2017-06-03 17:33:52.754074 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #605 | Training started
2017-06-03 17:34:10.788872 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #605 | Training finished
2017-06-03 17:34:10.789822 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #605 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 17:34:10.790115 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #605 | Collecting samples for evaluation
2017-06-03 17:34:19.755064 EDT | -----------------------  --------------
2017-06-03 17:34:19.755910 EDT | Epoch                     605
2017-06-03 17:34:19.756163 EDT | Iteration                 605
2017-06-03 17:34:19.756398 EDT | AverageReturn            1000
2017-06-03 17:34:19.756629 EDT | StdReturn                   0
2017-06-03 17:34:19.756857 EDT | MaxReturn                1000
2017-06-03 17:34:19.757084 EDT | MinReturn                1000
2017-06-03 17:34:19.757311 EDT | AverageEsReturn            46.5
2017-06-03 17:34:19.757543 EDT | StdEsReturn                42.6345
2017-06-03 17:34:19.757787 EDT | MaxEsReturn               165
2017-06-03 17:34:19.758053 EDT | MinEsReturn                 3
2017-06-03 17:34:19.758280 EDT | AverageDiscountedReturn    99.9957
2017-06-03 17:34:19.758507 EDT | AverageQLoss                3.05965e-05
2017-06-03 17:34:19.758732 EDT | AveragePolicySurr          -0.0898661
2017-06-03 17:34:19.758968 EDT | AverageQ                    0.0861418
2017-06-03 17:34:19.759195 EDT | AverageAbsQ                 0.0863735
2017-06-03 17:34:19.759427 EDT | AverageY                    0.0861435
2017-06-03 17:34:19.759653 EDT | AverageAbsY                 0.0861468
2017-06-03 17:34:19.759881 EDT | AverageAbsQYDiff            0.00147488
2017-06-03 17:34:19.760106 EDT | AverageAction               0.000123877
2017-06-03 17:34:19.760331 EDT | PolicyRegParamNorm         67.0598
2017-06-03 17:34:19.760564 EDT | QFunRegParamNorm           28.1886
2017-06-03 17:34:19.760789 EDT | -----------------------  --------------
2017-06-03 17:34:19.761155 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #606 | Training started
2017-06-03 17:34:38.668392 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #606 | Training finished
2017-06-03 17:34:38.669260 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #606 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 17:34:38.669529 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #606 | Collecting samples for evaluation
2017-06-03 17:34:47.702653 EDT | -----------------------  --------------
2017-06-03 17:34:47.703531 EDT | Epoch                     606
2017-06-03 17:34:47.703805 EDT | Iteration                 606
2017-06-03 17:34:47.704043 EDT | AverageReturn            1000
2017-06-03 17:34:47.704294 EDT | StdReturn                   0
2017-06-03 17:34:47.704579 EDT | MaxReturn                1000
2017-06-03 17:34:47.704855 EDT | MinReturn                1000
2017-06-03 17:34:47.705116 EDT | AverageEsReturn            28.1765
2017-06-03 17:34:47.705378 EDT | StdEsReturn                27.1363
2017-06-03 17:34:47.705629 EDT | MaxEsReturn               112
2017-06-03 17:34:47.705921 EDT | MinEsReturn                 3
2017-06-03 17:34:47.706185 EDT | AverageDiscountedReturn    99.9957
2017-06-03 17:34:47.706456 EDT | AverageQLoss                3.00421e-05
2017-06-03 17:34:47.706729 EDT | AveragePolicySurr          -0.0898196
2017-06-03 17:34:47.706996 EDT | AverageQ                    0.0859003
2017-06-03 17:34:47.707246 EDT | AverageAbsQ                 0.08612
2017-06-03 17:34:47.707496 EDT | AverageY                    0.0859064
2017-06-03 17:34:47.707745 EDT | AverageAbsY                 0.0859086
2017-06-03 17:34:47.707997 EDT | AverageAbsQYDiff            0.00154034
2017-06-03 17:34:47.708244 EDT | AverageAction               0.000215372
2017-06-03 17:34:47.708492 EDT | PolicyRegParamNorm         67.0587
2017-06-03 17:34:47.708739 EDT | QFunRegParamNorm           28.1925
2017-06-03 17:34:47.708986 EDT | -----------------------  --------------
2017-06-03 17:34:47.709394 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #607 | Training started
2017-06-03 17:35:07.421070 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #607 | Training finished
2017-06-03 17:35:07.423988 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #607 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 17:35:07.424279 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #607 | Collecting samples for evaluation
2017-06-03 17:35:16.204728 EDT | -----------------------  --------------
2017-06-03 17:35:16.205611 EDT | Epoch                     607
2017-06-03 17:35:16.205981 EDT | Iteration                 607
2017-06-03 17:35:16.206372 EDT | AverageReturn            1000
2017-06-03 17:35:16.206754 EDT | StdReturn                   0
2017-06-03 17:35:16.207115 EDT | MaxReturn                1000
2017-06-03 17:35:16.207444 EDT | MinReturn                1000
2017-06-03 17:35:16.207792 EDT | AverageEsReturn            40.2692
2017-06-03 17:35:16.208117 EDT | StdEsReturn                53.877
2017-06-03 17:35:16.208458 EDT | MaxEsReturn               256
2017-06-03 17:35:16.208974 EDT | MinEsReturn                 5
2017-06-03 17:35:16.209291 EDT | AverageDiscountedReturn    99.9957
2017-06-03 17:35:16.209608 EDT | AverageQLoss                2.52281e-05
2017-06-03 17:35:16.209950 EDT | AveragePolicySurr          -0.0898006
2017-06-03 17:35:16.210333 EDT | AverageQ                    0.0859527
2017-06-03 17:35:16.210683 EDT | AverageAbsQ                 0.0861417
2017-06-03 17:35:16.211006 EDT | AverageY                    0.0859453
2017-06-03 17:35:16.211352 EDT | AverageAbsY                 0.0859531
2017-06-03 17:35:16.211735 EDT | AverageAbsQYDiff            0.00136518
2017-06-03 17:35:16.212075 EDT | AverageAction               0.000135601
2017-06-03 17:35:16.212416 EDT | PolicyRegParamNorm         67.0712
2017-06-03 17:35:16.212767 EDT | QFunRegParamNorm           28.2084
2017-06-03 17:35:16.213118 EDT | -----------------------  --------------
2017-06-03 17:35:16.213635 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #608 | Training started
2017-06-03 17:35:34.158704 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #608 | Training finished
2017-06-03 17:35:34.159599 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #608 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 17:35:34.159991 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #608 | Collecting samples for evaluation
2017-06-03 17:35:42.795793 EDT | -----------------------  --------------
2017-06-03 17:35:42.796740 EDT | Epoch                     608
2017-06-03 17:35:42.797039 EDT | Iteration                 608
2017-06-03 17:35:42.797271 EDT | AverageReturn            1000
2017-06-03 17:35:42.797494 EDT | StdReturn                   0
2017-06-03 17:35:42.797742 EDT | MaxReturn                1000
2017-06-03 17:35:42.798033 EDT | MinReturn                1000
2017-06-03 17:35:42.798275 EDT | AverageEsReturn            34.5385
2017-06-03 17:35:42.798513 EDT | StdEsReturn                24.4072
2017-06-03 17:35:42.798770 EDT | MaxEsReturn                80
2017-06-03 17:35:42.799047 EDT | MinEsReturn                 3
2017-06-03 17:35:42.799285 EDT | AverageDiscountedReturn    99.9957
2017-06-03 17:35:42.799597 EDT | AverageQLoss                3.02334e-05
2017-06-03 17:35:42.799841 EDT | AveragePolicySurr          -0.0897433
2017-06-03 17:35:42.800078 EDT | AverageQ                    0.0857408
2017-06-03 17:35:42.800314 EDT | AverageAbsQ                 0.0859814
2017-06-03 17:35:42.800563 EDT | AverageY                    0.0857378
2017-06-03 17:35:42.800798 EDT | AverageAbsY                 0.0857407
2017-06-03 17:35:42.801029 EDT | AverageAbsQYDiff            0.00149439
2017-06-03 17:35:42.801283 EDT | AverageAction               0.262784
2017-06-03 17:35:42.801531 EDT | PolicyRegParamNorm         67.1201
2017-06-03 17:35:42.801779 EDT | QFunRegParamNorm           28.2045
2017-06-03 17:35:42.802005 EDT | -----------------------  --------------
2017-06-03 17:35:42.802331 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #609 | Training started
2017-06-03 17:36:01.267311 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #609 | Training finished
2017-06-03 17:36:01.268205 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #609 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 17:36:01.268563 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #609 | Collecting samples for evaluation
2017-06-03 17:36:10.423169 EDT | -----------------------  -------------
2017-06-03 17:36:10.424063 EDT | Epoch                     609
2017-06-03 17:36:10.424322 EDT | Iteration                 609
2017-06-03 17:36:10.424563 EDT | AverageReturn            1000
2017-06-03 17:36:10.424800 EDT | StdReturn                   0
2017-06-03 17:36:10.425044 EDT | MaxReturn                1000
2017-06-03 17:36:10.425278 EDT | MinReturn                1000
2017-06-03 17:36:10.425511 EDT | AverageEsReturn            35.3548
2017-06-03 17:36:10.425753 EDT | StdEsReturn                25.0812
2017-06-03 17:36:10.425988 EDT | MaxEsReturn               106
2017-06-03 17:36:10.426235 EDT | MinEsReturn                 3
2017-06-03 17:36:10.426473 EDT | AverageDiscountedReturn    99.9957
2017-06-03 17:36:10.426705 EDT | AverageQLoss                1.8434e-05
2017-06-03 17:36:10.426937 EDT | AveragePolicySurr          -0.0896337
2017-06-03 17:36:10.427169 EDT | AverageQ                    0.0858078
2017-06-03 17:36:10.427400 EDT | AverageAbsQ                 0.0859835
2017-06-03 17:36:10.427632 EDT | AverageY                    0.0858122
2017-06-03 17:36:10.427862 EDT | AverageAbsY                 0.0858223
2017-06-03 17:36:10.428093 EDT | AverageAbsQYDiff            0.00115474
2017-06-03 17:36:10.428324 EDT | AverageAction               0.195902
2017-06-03 17:36:10.428556 EDT | PolicyRegParamNorm         67.1573
2017-06-03 17:36:10.428788 EDT | QFunRegParamNorm           28.2208
2017-06-03 17:36:10.429019 EDT | -----------------------  -------------
2017-06-03 17:36:10.429418 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #610 | Training started
2017-06-03 17:36:28.351300 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #610 | Training finished
2017-06-03 17:36:28.352190 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #610 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 17:36:28.352474 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #610 | Collecting samples for evaluation
2017-06-03 17:36:38.756248 EDT | -----------------------  --------------
2017-06-03 17:36:38.757094 EDT | Epoch                     610
2017-06-03 17:36:38.757366 EDT | Iteration                 610
2017-06-03 17:36:38.757612 EDT | AverageReturn            1000
2017-06-03 17:36:38.757872 EDT | StdReturn                   0
2017-06-03 17:36:38.758111 EDT | MaxReturn                1000
2017-06-03 17:36:38.758351 EDT | MinReturn                1000
2017-06-03 17:36:38.758587 EDT | AverageEsReturn            46.5714
2017-06-03 17:36:38.758837 EDT | StdEsReturn                26.7859
2017-06-03 17:36:38.759072 EDT | MaxEsReturn                98
2017-06-03 17:36:38.759311 EDT | MinEsReturn                 7
2017-06-03 17:36:38.759548 EDT | AverageDiscountedReturn    99.9957
2017-06-03 17:36:38.759786 EDT | AverageQLoss                2.17867e-05
2017-06-03 17:36:38.760018 EDT | AveragePolicySurr          -0.0897143
2017-06-03 17:36:38.760251 EDT | AverageQ                    0.0859102
2017-06-03 17:36:38.760488 EDT | AverageAbsQ                 0.0861277
2017-06-03 17:36:38.760721 EDT | AverageY                    0.08591
2017-06-03 17:36:38.760955 EDT | AverageAbsY                 0.0859215
2017-06-03 17:36:38.761189 EDT | AverageAbsQYDiff            0.00126446
2017-06-03 17:36:38.761422 EDT | AverageAction               0.671334
2017-06-03 17:36:38.761654 EDT | PolicyRegParamNorm         67.2051
2017-06-03 17:36:38.761902 EDT | QFunRegParamNorm           28.2421
2017-06-03 17:36:38.762173 EDT | -----------------------  --------------
2017-06-03 17:36:38.762531 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #611 | Training started
2017-06-03 17:36:56.959851 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #611 | Training finished
2017-06-03 17:36:56.960899 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #611 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 17:36:56.961307 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #611 | Collecting samples for evaluation
2017-06-03 17:37:07.438252 EDT | -----------------------  -------------
2017-06-03 17:37:07.439164 EDT | Epoch                     611
2017-06-03 17:37:07.439531 EDT | Iteration                 611
2017-06-03 17:37:07.439877 EDT | AverageReturn            1000
2017-06-03 17:37:07.440196 EDT | StdReturn                   0
2017-06-03 17:37:07.440551 EDT | MaxReturn                1000
2017-06-03 17:37:07.440887 EDT | MinReturn                1000
2017-06-03 17:37:07.441125 EDT | AverageEsReturn            50.1
2017-06-03 17:37:07.441360 EDT | StdEsReturn                38.3613
2017-06-03 17:37:07.441599 EDT | MaxEsReturn               140
2017-06-03 17:37:07.441845 EDT | MinEsReturn                 4
2017-06-03 17:37:07.442088 EDT | AverageDiscountedReturn    99.9957
2017-06-03 17:37:07.442317 EDT | AverageQLoss                2.4768e-05
2017-06-03 17:37:07.442547 EDT | AveragePolicySurr          -0.0897413
2017-06-03 17:37:07.442774 EDT | AverageQ                    0.0858782
2017-06-03 17:37:07.443003 EDT | AverageAbsQ                 0.0861351
2017-06-03 17:37:07.443228 EDT | AverageY                    0.0858791
2017-06-03 17:37:07.443481 EDT | AverageAbsY                 0.0858874
2017-06-03 17:37:07.443711 EDT | AverageAbsQYDiff            0.00143838
2017-06-03 17:37:07.443941 EDT | AverageAction               0.0263711
2017-06-03 17:37:07.444171 EDT | PolicyRegParamNorm         67.1755
2017-06-03 17:37:07.444400 EDT | QFunRegParamNorm           28.2306
2017-06-03 17:37:07.444639 EDT | -----------------------  -------------
2017-06-03 17:37:07.444991 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #612 | Training started
2017-06-03 17:37:26.500430 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #612 | Training finished
2017-06-03 17:37:26.501357 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #612 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 17:37:26.501662 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #612 | Collecting samples for evaluation
2017-06-03 17:37:37.461826 EDT | -----------------------  --------------
2017-06-03 17:37:37.462668 EDT | Epoch                     612
2017-06-03 17:37:37.462940 EDT | Iteration                 612
2017-06-03 17:37:37.463178 EDT | AverageReturn            1000
2017-06-03 17:37:37.463410 EDT | StdReturn                   0
2017-06-03 17:37:37.463645 EDT | MaxReturn                1000
2017-06-03 17:37:37.463873 EDT | MinReturn                1000
2017-06-03 17:37:37.464115 EDT | AverageEsReturn            33.8
2017-06-03 17:37:37.464343 EDT | StdEsReturn                27.0091
2017-06-03 17:37:37.464575 EDT | MaxEsReturn               102
2017-06-03 17:37:37.464801 EDT | MinEsReturn                 3
2017-06-03 17:37:37.465028 EDT | AverageDiscountedReturn    99.9957
2017-06-03 17:37:37.465255 EDT | AverageQLoss                2.75983e-05
2017-06-03 17:37:37.465480 EDT | AveragePolicySurr          -0.0896279
2017-06-03 17:37:37.465772 EDT | AverageQ                    0.0857231
2017-06-03 17:37:37.466021 EDT | AverageAbsQ                 0.0859367
2017-06-03 17:37:37.466264 EDT | AverageY                    0.0857176
2017-06-03 17:37:37.466519 EDT | AverageAbsY                 0.0857231
2017-06-03 17:37:37.466766 EDT | AverageAbsQYDiff            0.00149714
2017-06-03 17:37:37.467007 EDT | AverageAction               0.0614013
2017-06-03 17:37:37.467248 EDT | PolicyRegParamNorm         67.2081
2017-06-03 17:37:37.467496 EDT | QFunRegParamNorm           28.2474
2017-06-03 17:37:37.467741 EDT | -----------------------  --------------
2017-06-03 17:37:37.468134 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #613 | Training started
2017-06-03 17:37:56.947336 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #613 | Training finished
2017-06-03 17:37:56.948402 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #613 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 17:37:56.948790 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #613 | Collecting samples for evaluation
2017-06-03 17:38:07.190922 EDT | -----------------------  --------------
2017-06-03 17:38:07.191308 EDT | Epoch                     613
2017-06-03 17:38:07.191559 EDT | Iteration                 613
2017-06-03 17:38:07.191798 EDT | AverageReturn            1000
2017-06-03 17:38:07.192031 EDT | StdReturn                   0
2017-06-03 17:38:07.192265 EDT | MaxReturn                1000
2017-06-03 17:38:07.192500 EDT | MinReturn                1000
2017-06-03 17:38:07.192730 EDT | AverageEsReturn            51
2017-06-03 17:38:07.192962 EDT | StdEsReturn                86.4109
2017-06-03 17:38:07.193193 EDT | MaxEsReturn               408
2017-06-03 17:38:07.193425 EDT | MinEsReturn                 4
2017-06-03 17:38:07.193653 EDT | AverageDiscountedReturn    99.9957
2017-06-03 17:38:07.193898 EDT | AverageQLoss                3.05733e-05
2017-06-03 17:38:07.194131 EDT | AveragePolicySurr          -0.0897456
2017-06-03 17:38:07.194362 EDT | AverageQ                    0.0857612
2017-06-03 17:38:07.194592 EDT | AverageAbsQ                 0.0859945
2017-06-03 17:38:07.194823 EDT | AverageY                    0.0857639
2017-06-03 17:38:07.195054 EDT | AverageAbsY                 0.0857684
2017-06-03 17:38:07.195286 EDT | AverageAbsQYDiff            0.00152172
2017-06-03 17:38:07.195516 EDT | AverageAction               0.000141146
2017-06-03 17:38:07.195747 EDT | PolicyRegParamNorm         67.2147
2017-06-03 17:38:07.195978 EDT | QFunRegParamNorm           28.233
2017-06-03 17:38:07.196208 EDT | -----------------------  --------------
2017-06-03 17:38:07.196561 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #614 | Training started
2017-06-03 17:38:26.271964 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #614 | Training finished
2017-06-03 17:38:26.273031 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #614 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 17:38:26.273310 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #614 | Collecting samples for evaluation
2017-06-03 17:38:37.249880 EDT | -----------------------  --------------
2017-06-03 17:38:37.250236 EDT | Epoch                     614
2017-06-03 17:38:37.250486 EDT | Iteration                 614
2017-06-03 17:38:37.250723 EDT | AverageReturn            1000
2017-06-03 17:38:37.250953 EDT | StdReturn                   0
2017-06-03 17:38:37.251188 EDT | MaxReturn                1000
2017-06-03 17:38:37.251415 EDT | MinReturn                1000
2017-06-03 17:38:37.251641 EDT | AverageEsReturn            35.069
2017-06-03 17:38:37.251868 EDT | StdEsReturn                33.1194
2017-06-03 17:38:37.252099 EDT | MaxEsReturn               156
2017-06-03 17:38:37.252331 EDT | MinEsReturn                 3
2017-06-03 17:38:37.252565 EDT | AverageDiscountedReturn    99.9957
2017-06-03 17:38:37.252800 EDT | AverageQLoss                2.17446e-05
2017-06-03 17:38:37.253031 EDT | AveragePolicySurr          -0.0898672
2017-06-03 17:38:37.253262 EDT | AverageQ                    0.0860609
2017-06-03 17:38:37.253492 EDT | AverageAbsQ                 0.0862342
2017-06-03 17:38:37.253731 EDT | AverageY                    0.0860659
2017-06-03 17:38:37.253965 EDT | AverageAbsY                 0.0860695
2017-06-03 17:38:37.254194 EDT | AverageAbsQYDiff            0.00123569
2017-06-03 17:38:37.254422 EDT | AverageAction               0.217901
2017-06-03 17:38:37.254651 EDT | PolicyRegParamNorm         67.2346
2017-06-03 17:38:37.254883 EDT | QFunRegParamNorm           28.2565
2017-06-03 17:38:37.255108 EDT | -----------------------  --------------
2017-06-03 17:38:37.255488 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #615 | Training started
2017-06-03 17:38:56.708314 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #615 | Training finished
2017-06-03 17:38:56.711716 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #615 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 17:38:56.712038 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #615 | Collecting samples for evaluation
2017-06-03 17:39:05.727297 EDT | -----------------------  --------------
2017-06-03 17:39:05.727689 EDT | Epoch                     615
2017-06-03 17:39:05.727991 EDT | Iteration                 615
2017-06-03 17:39:05.728260 EDT | AverageReturn            1000
2017-06-03 17:39:05.728504 EDT | StdReturn                   0
2017-06-03 17:39:05.728740 EDT | MaxReturn                1000
2017-06-03 17:39:05.728981 EDT | MinReturn                1000
2017-06-03 17:39:05.729258 EDT | AverageEsReturn            67.8
2017-06-03 17:39:05.729495 EDT | StdEsReturn                57.9174
2017-06-03 17:39:05.729776 EDT | MaxEsReturn               232
2017-06-03 17:39:05.730015 EDT | MinEsReturn                10
2017-06-03 17:39:05.730274 EDT | AverageDiscountedReturn    99.9957
2017-06-03 17:39:05.730513 EDT | AverageQLoss                2.91605e-05
2017-06-03 17:39:05.730753 EDT | AveragePolicySurr          -0.0896099
2017-06-03 17:39:05.731006 EDT | AverageQ                    0.085703
2017-06-03 17:39:05.731267 EDT | AverageAbsQ                 0.085935
2017-06-03 17:39:05.731506 EDT | AverageY                    0.0856999
2017-06-03 17:39:05.731739 EDT | AverageAbsY                 0.0857104
2017-06-03 17:39:05.731979 EDT | AverageAbsQYDiff            0.00142449
2017-06-03 17:39:05.732224 EDT | AverageAction               0.000373172
2017-06-03 17:39:05.732478 EDT | PolicyRegParamNorm         67.2695
2017-06-03 17:39:05.732732 EDT | QFunRegParamNorm           28.2535
2017-06-03 17:39:05.732968 EDT | -----------------------  --------------
2017-06-03 17:39:05.733463 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #616 | Training started
2017-06-03 17:39:24.486579 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #616 | Training finished
2017-06-03 17:39:24.490097 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #616 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 17:39:24.490422 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #616 | Collecting samples for evaluation
2017-06-03 17:39:33.751881 EDT | -----------------------  -------------
2017-06-03 17:39:33.753013 EDT | Epoch                     616
2017-06-03 17:39:33.753281 EDT | Iteration                 616
2017-06-03 17:39:33.753549 EDT | AverageReturn            1000
2017-06-03 17:39:33.753807 EDT | StdReturn                   0
2017-06-03 17:39:33.754051 EDT | MaxReturn                1000
2017-06-03 17:39:33.754302 EDT | MinReturn                1000
2017-06-03 17:39:33.754559 EDT | AverageEsReturn            30.871
2017-06-03 17:39:33.754806 EDT | StdEsReturn                27.5526
2017-06-03 17:39:33.755054 EDT | MaxEsReturn               112
2017-06-03 17:39:33.755299 EDT | MinEsReturn                 3
2017-06-03 17:39:33.755549 EDT | AverageDiscountedReturn    99.9957
2017-06-03 17:39:33.755798 EDT | AverageQLoss                2.8508e-05
2017-06-03 17:39:33.756044 EDT | AveragePolicySurr          -0.0897928
2017-06-03 17:39:33.756297 EDT | AverageQ                    0.0859613
2017-06-03 17:39:33.756541 EDT | AverageAbsQ                 0.0861493
2017-06-03 17:39:33.756789 EDT | AverageY                    0.0859638
2017-06-03 17:39:33.757035 EDT | AverageAbsY                 0.085975
2017-06-03 17:39:33.757280 EDT | AverageAbsQYDiff            0.00135117
2017-06-03 17:39:33.757537 EDT | AverageAction               0.229813
2017-06-03 17:39:33.757800 EDT | PolicyRegParamNorm         67.2749
2017-06-03 17:39:33.758050 EDT | QFunRegParamNorm           28.2721
2017-06-03 17:39:33.758299 EDT | -----------------------  -------------
2017-06-03 17:39:33.758670 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #617 | Training started
2017-06-03 17:39:52.492258 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #617 | Training finished
2017-06-03 17:39:52.493515 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #617 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 17:39:52.493902 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #617 | Collecting samples for evaluation
2017-06-03 17:40:03.571792 EDT | -----------------------  --------------
2017-06-03 17:40:03.573096 EDT | Epoch                     617
2017-06-03 17:40:03.573375 EDT | Iteration                 617
2017-06-03 17:40:03.573828 EDT | AverageReturn            1000
2017-06-03 17:40:03.574081 EDT | StdReturn                   0
2017-06-03 17:40:03.574327 EDT | MaxReturn                1000
2017-06-03 17:40:03.574573 EDT | MinReturn                1000
2017-06-03 17:40:03.574821 EDT | AverageEsReturn            45.4783
2017-06-03 17:40:03.575064 EDT | StdEsReturn                37.8726
2017-06-03 17:40:03.575313 EDT | MaxEsReturn               133
2017-06-03 17:40:03.575555 EDT | MinEsReturn                 3
2017-06-03 17:40:03.575797 EDT | AverageDiscountedReturn    99.9957
2017-06-03 17:40:03.576039 EDT | AverageQLoss                2.53122e-05
2017-06-03 17:40:03.576302 EDT | AveragePolicySurr          -0.0897691
2017-06-03 17:40:03.576544 EDT | AverageQ                    0.0858547
2017-06-03 17:40:03.576788 EDT | AverageAbsQ                 0.0860469
2017-06-03 17:40:03.577027 EDT | AverageY                    0.0858562
2017-06-03 17:40:03.577275 EDT | AverageAbsY                 0.0858729
2017-06-03 17:40:03.577516 EDT | AverageAbsQYDiff            0.00126626
2017-06-03 17:40:03.578389 EDT | AverageAction               0.135
2017-06-03 17:40:03.578640 EDT | PolicyRegParamNorm         67.2987
2017-06-03 17:40:03.578877 EDT | QFunRegParamNorm           28.2769
2017-06-03 17:40:03.579108 EDT | -----------------------  --------------
2017-06-03 17:40:03.579497 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #618 | Training started
2017-06-03 17:40:21.398570 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #618 | Training finished
2017-06-03 17:40:21.399569 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #618 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 17:40:21.399965 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #618 | Collecting samples for evaluation
2017-06-03 17:40:31.031372 EDT | -----------------------  --------------
2017-06-03 17:40:31.032418 EDT | Epoch                     618
2017-06-03 17:40:31.032703 EDT | Iteration                 618
2017-06-03 17:40:31.032951 EDT | AverageReturn            1000
2017-06-03 17:40:31.033178 EDT | StdReturn                   0
2017-06-03 17:40:31.033414 EDT | MaxReturn                1000
2017-06-03 17:40:31.033655 EDT | MinReturn                1000
2017-06-03 17:40:31.033920 EDT | AverageEsReturn            48.5
2017-06-03 17:40:31.034172 EDT | StdEsReturn                47.025
2017-06-03 17:40:31.034393 EDT | MaxEsReturn               150
2017-06-03 17:40:31.034613 EDT | MinEsReturn                 3
2017-06-03 17:40:31.034832 EDT | AverageDiscountedReturn    99.9957
2017-06-03 17:40:31.035050 EDT | AverageQLoss                2.13107e-05
2017-06-03 17:40:31.035281 EDT | AveragePolicySurr          -0.0896612
2017-06-03 17:40:31.035501 EDT | AverageQ                    0.0857523
2017-06-03 17:40:31.035719 EDT | AverageAbsQ                 0.0859541
2017-06-03 17:40:31.035936 EDT | AverageY                    0.0857508
2017-06-03 17:40:31.036154 EDT | AverageAbsY                 0.0857604
2017-06-03 17:40:31.036370 EDT | AverageAbsQYDiff            0.00133958
2017-06-03 17:40:31.036587 EDT | AverageAction               0.128609
2017-06-03 17:40:31.036804 EDT | PolicyRegParamNorm         67.2973
2017-06-03 17:40:31.037020 EDT | QFunRegParamNorm           28.3043
2017-06-03 17:40:31.037236 EDT | -----------------------  --------------
2017-06-03 17:40:31.037578 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #619 | Training started
2017-06-03 17:40:49.785743 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #619 | Training finished
2017-06-03 17:40:49.787410 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #619 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 17:40:49.787832 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #619 | Collecting samples for evaluation
2017-06-03 17:40:59.321635 EDT | -----------------------  --------------
2017-06-03 17:40:59.322038 EDT | Epoch                     619
2017-06-03 17:40:59.322298 EDT | Iteration                 619
2017-06-03 17:40:59.322546 EDT | AverageReturn            1000
2017-06-03 17:40:59.322796 EDT | StdReturn                   0
2017-06-03 17:40:59.323043 EDT | MaxReturn                1000
2017-06-03 17:40:59.323287 EDT | MinReturn                1000
2017-06-03 17:40:59.323531 EDT | AverageEsReturn            41.4583
2017-06-03 17:40:59.323788 EDT | StdEsReturn                29.9597
2017-06-03 17:40:59.324032 EDT | MaxEsReturn               117
2017-06-03 17:40:59.324276 EDT | MinEsReturn                 5
2017-06-03 17:40:59.324519 EDT | AverageDiscountedReturn    99.9957
2017-06-03 17:40:59.324767 EDT | AverageQLoss                3.04761e-05
2017-06-03 17:40:59.325009 EDT | AveragePolicySurr          -0.0898047
2017-06-03 17:40:59.325250 EDT | AverageQ                    0.085824
2017-06-03 17:40:59.325495 EDT | AverageAbsQ                 0.0861035
2017-06-03 17:40:59.325754 EDT | AverageY                    0.0858246
2017-06-03 17:40:59.325999 EDT | AverageAbsY                 0.0858333
2017-06-03 17:40:59.326242 EDT | AverageAbsQYDiff            0.00145511
2017-06-03 17:40:59.326489 EDT | AverageAction               0.464103
2017-06-03 17:40:59.326731 EDT | PolicyRegParamNorm         67.3052
2017-06-03 17:40:59.326971 EDT | QFunRegParamNorm           28.2958
2017-06-03 17:40:59.327212 EDT | -----------------------  --------------
2017-06-03 17:40:59.327622 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #620 | Training started
2017-06-03 17:41:17.195049 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #620 | Training finished
2017-06-03 17:41:17.196021 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #620 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 17:41:17.196377 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #620 | Collecting samples for evaluation
2017-06-03 17:41:27.479565 EDT | -----------------------  --------------
2017-06-03 17:41:27.480508 EDT | Epoch                     620
2017-06-03 17:41:27.480778 EDT | Iteration                 620
2017-06-03 17:41:27.481036 EDT | AverageReturn            1000
2017-06-03 17:41:27.481273 EDT | StdReturn                   0
2017-06-03 17:41:27.481525 EDT | MaxReturn                1000
2017-06-03 17:41:27.481774 EDT | MinReturn                1000
2017-06-03 17:41:27.482055 EDT | AverageEsReturn            48.619
2017-06-03 17:41:27.482324 EDT | StdEsReturn                38.1744
2017-06-03 17:41:27.482557 EDT | MaxEsReturn               156
2017-06-03 17:41:27.482786 EDT | MinEsReturn                 3
2017-06-03 17:41:27.483013 EDT | AverageDiscountedReturn    99.9957
2017-06-03 17:41:27.483244 EDT | AverageQLoss                2.72907e-05
2017-06-03 17:41:27.483488 EDT | AveragePolicySurr          -0.0895376
2017-06-03 17:41:27.483716 EDT | AverageQ                    0.085686
2017-06-03 17:41:27.483943 EDT | AverageAbsQ                 0.085903
2017-06-03 17:41:27.484168 EDT | AverageY                    0.0856842
2017-06-03 17:41:27.484395 EDT | AverageAbsY                 0.0856977
2017-06-03 17:41:27.484620 EDT | AverageAbsQYDiff            0.001391
2017-06-03 17:41:27.484848 EDT | AverageAction               0.0891635
2017-06-03 17:41:27.485085 EDT | PolicyRegParamNorm         67.3405
2017-06-03 17:41:27.485310 EDT | QFunRegParamNorm           28.3039
2017-06-03 17:41:27.485539 EDT | -----------------------  --------------
2017-06-03 17:41:27.486085 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #621 | Training started
2017-06-03 17:41:45.740351 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #621 | Training finished
2017-06-03 17:41:45.741240 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #621 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 17:41:45.741601 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #621 | Collecting samples for evaluation
2017-06-03 17:41:56.098581 EDT | -----------------------  --------------
2017-06-03 17:41:56.103692 EDT | Epoch                     621
2017-06-03 17:41:56.104026 EDT | Iteration                 621
2017-06-03 17:41:56.104270 EDT | AverageReturn            1000
2017-06-03 17:41:56.104511 EDT | StdReturn                   0
2017-06-03 17:41:56.104754 EDT | MaxReturn                1000
2017-06-03 17:41:56.104986 EDT | MinReturn                1000
2017-06-03 17:41:56.105218 EDT | AverageEsReturn            39.375
2017-06-03 17:41:56.105450 EDT | StdEsReturn                32.9846
2017-06-03 17:41:56.105730 EDT | MaxEsReturn               162
2017-06-03 17:41:56.105963 EDT | MinEsReturn                 8
2017-06-03 17:41:56.106191 EDT | AverageDiscountedReturn    99.9957
2017-06-03 17:41:56.106418 EDT | AverageQLoss                2.32168e-05
2017-06-03 17:41:56.106648 EDT | AveragePolicySurr          -0.0896682
2017-06-03 17:41:56.106876 EDT | AverageQ                    0.0859496
2017-06-03 17:41:56.107102 EDT | AverageAbsQ                 0.0861438
2017-06-03 17:41:56.107342 EDT | AverageY                    0.0859492
2017-06-03 17:41:56.107571 EDT | AverageAbsY                 0.0859644
2017-06-03 17:41:56.107798 EDT | AverageAbsQYDiff            0.00126519
2017-06-03 17:41:56.108026 EDT | AverageAction               0.00490228
2017-06-03 17:41:56.108250 EDT | PolicyRegParamNorm         67.3934
2017-06-03 17:41:56.108478 EDT | QFunRegParamNorm           28.339
2017-06-03 17:41:56.108716 EDT | -----------------------  --------------
2017-06-03 17:41:56.109086 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #622 | Training started
2017-06-03 17:42:14.492599 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #622 | Training finished
2017-06-03 17:42:14.493542 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #622 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 17:42:14.493828 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #622 | Collecting samples for evaluation
2017-06-03 17:42:24.307715 EDT | -----------------------  --------------
2017-06-03 17:42:24.308551 EDT | Epoch                     622
2017-06-03 17:42:24.308808 EDT | Iteration                 622
2017-06-03 17:42:24.309045 EDT | AverageReturn            1000
2017-06-03 17:42:24.309282 EDT | StdReturn                   0
2017-06-03 17:42:24.309531 EDT | MaxReturn                1000
2017-06-03 17:42:24.309783 EDT | MinReturn                1000
2017-06-03 17:42:24.310039 EDT | AverageEsReturn            61.2941
2017-06-03 17:42:24.310272 EDT | StdEsReturn                41.329
2017-06-03 17:42:24.310509 EDT | MaxEsReturn               165
2017-06-03 17:42:24.310747 EDT | MinEsReturn                 9
2017-06-03 17:42:24.310979 EDT | AverageDiscountedReturn    99.9957
2017-06-03 17:42:24.311211 EDT | AverageQLoss                2.39583e-05
2017-06-03 17:42:24.311442 EDT | AveragePolicySurr          -0.0896656
2017-06-03 17:42:24.311686 EDT | AverageQ                    0.0858097
2017-06-03 17:42:24.311917 EDT | AverageAbsQ                 0.0859815
2017-06-03 17:42:24.312146 EDT | AverageY                    0.0858086
2017-06-03 17:42:24.312377 EDT | AverageAbsY                 0.0858242
2017-06-03 17:42:24.312619 EDT | AverageAbsQYDiff            0.00131917
2017-06-03 17:42:24.312849 EDT | AverageAction               0.448869
2017-06-03 17:42:24.313079 EDT | PolicyRegParamNorm         67.3818
2017-06-03 17:42:24.313310 EDT | QFunRegParamNorm           28.3424
2017-06-03 17:42:24.313547 EDT | -----------------------  --------------
2017-06-03 17:42:24.313949 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #623 | Training started
2017-06-03 17:42:44.181889 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #623 | Training finished
2017-06-03 17:42:44.182823 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #623 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 17:42:44.183195 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #623 | Collecting samples for evaluation
2017-06-03 17:42:53.927669 EDT | -----------------------  --------------
2017-06-03 17:42:53.928540 EDT | Epoch                     623
2017-06-03 17:42:53.928820 EDT | Iteration                 623
2017-06-03 17:42:53.929065 EDT | AverageReturn            1000
2017-06-03 17:42:53.929308 EDT | StdReturn                   0
2017-06-03 17:42:53.929543 EDT | MaxReturn                1000
2017-06-03 17:42:53.929799 EDT | MinReturn                1000
2017-06-03 17:42:53.930035 EDT | AverageEsReturn            37.1923
2017-06-03 17:42:53.930269 EDT | StdEsReturn                26.5446
2017-06-03 17:42:53.930503 EDT | MaxEsReturn               108
2017-06-03 17:42:53.930735 EDT | MinEsReturn                 3
2017-06-03 17:42:53.930966 EDT | AverageDiscountedReturn    99.9957
2017-06-03 17:42:53.931197 EDT | AverageQLoss                2.92332e-05
2017-06-03 17:42:53.931429 EDT | AveragePolicySurr          -0.0896531
2017-06-03 17:42:53.931662 EDT | AverageQ                    0.0858988
2017-06-03 17:42:53.931893 EDT | AverageAbsQ                 0.0861675
2017-06-03 17:42:53.932125 EDT | AverageY                    0.0858981
2017-06-03 17:42:53.932361 EDT | AverageAbsY                 0.0859129
2017-06-03 17:42:53.932592 EDT | AverageAbsQYDiff            0.00154044
2017-06-03 17:42:53.932822 EDT | AverageAction               0.398677
2017-06-03 17:42:53.933054 EDT | PolicyRegParamNorm         67.4401
2017-06-03 17:42:53.933285 EDT | QFunRegParamNorm           28.3595
2017-06-03 17:42:53.933516 EDT | -----------------------  --------------
2017-06-03 17:42:53.933895 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #624 | Training started
2017-06-03 17:43:13.485441 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #624 | Training finished
2017-06-03 17:43:13.486428 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #624 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 17:43:13.486803 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #624 | Collecting samples for evaluation
2017-06-03 17:43:23.879665 EDT | -----------------------  --------------
2017-06-03 17:43:23.880619 EDT | Epoch                     624
2017-06-03 17:43:23.880974 EDT | Iteration                 624
2017-06-03 17:43:23.881291 EDT | AverageReturn            1000
2017-06-03 17:43:23.881541 EDT | StdReturn                   0
2017-06-03 17:43:23.881817 EDT | MaxReturn                1000
2017-06-03 17:43:23.882144 EDT | MinReturn                1000
2017-06-03 17:43:23.882431 EDT | AverageEsReturn            48.2273
2017-06-03 17:43:23.882666 EDT | StdEsReturn                37.4663
2017-06-03 17:43:23.882981 EDT | MaxEsReturn               151
2017-06-03 17:43:23.883290 EDT | MinEsReturn                 5
2017-06-03 17:43:23.883536 EDT | AverageDiscountedReturn    99.9957
2017-06-03 17:43:23.883820 EDT | AverageQLoss                2.33612e-05
2017-06-03 17:43:23.884132 EDT | AveragePolicySurr          -0.0896693
2017-06-03 17:43:23.884389 EDT | AverageQ                    0.0859856
2017-06-03 17:43:23.884644 EDT | AverageAbsQ                 0.0861731
2017-06-03 17:43:23.884959 EDT | AverageY                    0.0859897
2017-06-03 17:43:23.885243 EDT | AverageAbsY                 0.0860005
2017-06-03 17:43:23.885481 EDT | AverageAbsQYDiff            0.0012886
2017-06-03 17:43:23.885837 EDT | AverageAction               0.246978
2017-06-03 17:43:23.886147 EDT | PolicyRegParamNorm         67.4286
2017-06-03 17:43:23.886402 EDT | QFunRegParamNorm           28.3528
2017-06-03 17:43:23.886730 EDT | -----------------------  --------------
2017-06-03 17:43:23.887194 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #625 | Training started
2017-06-03 17:43:41.042211 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #625 | Training finished
2017-06-03 17:43:41.042898 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #625 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 17:43:41.043274 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #625 | Collecting samples for evaluation
2017-06-03 17:43:50.745439 EDT | -----------------------  -------------
2017-06-03 17:43:50.749440 EDT | Epoch                     625
2017-06-03 17:43:50.749689 EDT | Iteration                 625
2017-06-03 17:43:50.749971 EDT | AverageReturn            1000
2017-06-03 17:43:50.750196 EDT | StdReturn                   0
2017-06-03 17:43:50.750417 EDT | MaxReturn                1000
2017-06-03 17:43:50.750636 EDT | MinReturn                1000
2017-06-03 17:43:50.750856 EDT | AverageEsReturn            47.381
2017-06-03 17:43:50.751083 EDT | StdEsReturn                48.1955
2017-06-03 17:43:50.751301 EDT | MaxEsReturn               192
2017-06-03 17:43:50.751519 EDT | MinEsReturn                 6
2017-06-03 17:43:50.751735 EDT | AverageDiscountedReturn    99.9957
2017-06-03 17:43:50.751952 EDT | AverageQLoss                2.9195e-05
2017-06-03 17:43:50.752169 EDT | AveragePolicySurr          -0.0897665
2017-06-03 17:43:50.752386 EDT | AverageQ                    0.0860945
2017-06-03 17:43:50.752622 EDT | AverageAbsQ                 0.0863744
2017-06-03 17:43:50.752838 EDT | AverageY                    0.0860883
2017-06-03 17:43:50.753055 EDT | AverageAbsY                 0.0860994
2017-06-03 17:43:50.753271 EDT | AverageAbsQYDiff            0.00150857
2017-06-03 17:43:50.753487 EDT | AverageAction               0.471458
2017-06-03 17:43:50.754250 EDT | PolicyRegParamNorm         67.5001
2017-06-03 17:43:50.754565 EDT | QFunRegParamNorm           28.3523
2017-06-03 17:43:50.754868 EDT | -----------------------  -------------
2017-06-03 17:43:50.755293 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #626 | Training started
2017-06-03 17:44:09.598085 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #626 | Training finished
2017-06-03 17:44:09.599067 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #626 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 17:44:09.599512 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #626 | Collecting samples for evaluation
2017-06-03 17:44:19.299087 EDT | -----------------------  --------------
2017-06-03 17:44:19.299932 EDT | Epoch                     626
2017-06-03 17:44:19.300228 EDT | Iteration                 626
2017-06-03 17:44:19.300470 EDT | AverageReturn            1000
2017-06-03 17:44:19.300706 EDT | StdReturn                   0
2017-06-03 17:44:19.300939 EDT | MaxReturn                1000
2017-06-03 17:44:19.301176 EDT | MinReturn                1000
2017-06-03 17:44:19.301409 EDT | AverageEsReturn            43.4783
2017-06-03 17:44:19.301642 EDT | StdEsReturn                42.262
2017-06-03 17:44:19.301902 EDT | MaxEsReturn               149
2017-06-03 17:44:19.302135 EDT | MinEsReturn                 3
2017-06-03 17:44:19.302367 EDT | AverageDiscountedReturn    99.9957
2017-06-03 17:44:19.302600 EDT | AverageQLoss                2.67468e-05
2017-06-03 17:44:19.302830 EDT | AveragePolicySurr          -0.0897045
2017-06-03 17:44:19.303061 EDT | AverageQ                    0.0859899
2017-06-03 17:44:19.303292 EDT | AverageAbsQ                 0.0862664
2017-06-03 17:44:19.303523 EDT | AverageY                    0.0859911
2017-06-03 17:44:19.303753 EDT | AverageAbsY                 0.0860353
2017-06-03 17:44:19.303990 EDT | AverageAbsQYDiff            0.00143153
2017-06-03 17:44:19.304225 EDT | AverageAction               0.318437
2017-06-03 17:44:19.304485 EDT | PolicyRegParamNorm         67.5202
2017-06-03 17:44:19.304717 EDT | QFunRegParamNorm           28.3584
2017-06-03 17:44:19.304947 EDT | -----------------------  --------------
2017-06-03 17:44:19.305326 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #627 | Training started
2017-06-03 17:44:36.785390 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #627 | Training finished
2017-06-03 17:44:36.785740 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #627 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 17:44:36.786007 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #627 | Collecting samples for evaluation
2017-06-03 17:44:46.319172 EDT | -----------------------  --------------
2017-06-03 17:44:46.320082 EDT | Epoch                     627
2017-06-03 17:44:46.320400 EDT | Iteration                 627
2017-06-03 17:44:46.320647 EDT | AverageReturn            1000
2017-06-03 17:44:46.320901 EDT | StdReturn                   0
2017-06-03 17:44:46.321143 EDT | MaxReturn                1000
2017-06-03 17:44:46.321379 EDT | MinReturn                1000
2017-06-03 17:44:46.321612 EDT | AverageEsReturn            34.7931
2017-06-03 17:44:46.321858 EDT | StdEsReturn                23.118
2017-06-03 17:44:46.322093 EDT | MaxEsReturn                79
2017-06-03 17:44:46.322384 EDT | MinEsReturn                 5
2017-06-03 17:44:46.322638 EDT | AverageDiscountedReturn    99.9957
2017-06-03 17:44:46.322920 EDT | AverageQLoss                2.43822e-05
2017-06-03 17:44:46.323200 EDT | AveragePolicySurr          -0.0897825
2017-06-03 17:44:46.323509 EDT | AverageQ                    0.0860066
2017-06-03 17:44:46.323816 EDT | AverageAbsQ                 0.086218
2017-06-03 17:44:46.324101 EDT | AverageY                    0.0860067
2017-06-03 17:44:46.324405 EDT | AverageAbsY                 0.0860312
2017-06-03 17:44:46.324704 EDT | AverageAbsQYDiff            0.00137697
2017-06-03 17:44:46.324982 EDT | AverageAction               0.0932849
2017-06-03 17:44:46.325264 EDT | PolicyRegParamNorm         67.5709
2017-06-03 17:44:46.325587 EDT | QFunRegParamNorm           28.3728
2017-06-03 17:44:46.325907 EDT | -----------------------  --------------
2017-06-03 17:44:46.326346 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #628 | Training started
2017-06-03 17:45:05.308763 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #628 | Training finished
2017-06-03 17:45:05.309099 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #628 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 17:45:05.309347 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #628 | Collecting samples for evaluation
2017-06-03 17:45:14.782712 EDT | -----------------------  --------------
2017-06-03 17:45:14.783728 EDT | Epoch                     628
2017-06-03 17:45:14.784016 EDT | Iteration                 628
2017-06-03 17:45:14.784265 EDT | AverageReturn            1000
2017-06-03 17:45:14.784512 EDT | StdReturn                   0
2017-06-03 17:45:14.784756 EDT | MaxReturn                1000
2017-06-03 17:45:14.785010 EDT | MinReturn                1000
2017-06-03 17:45:14.785255 EDT | AverageEsReturn            41.5833
2017-06-03 17:45:14.785496 EDT | StdEsReturn                38.4902
2017-06-03 17:45:14.785773 EDT | MaxEsReturn               167
2017-06-03 17:45:14.786017 EDT | MinEsReturn                 5
2017-06-03 17:45:14.786259 EDT | AverageDiscountedReturn    99.9957
2017-06-03 17:45:14.786501 EDT | AverageQLoss                2.68313e-05
2017-06-03 17:45:14.786751 EDT | AveragePolicySurr          -0.089629
2017-06-03 17:45:14.786992 EDT | AverageQ                    0.0860165
2017-06-03 17:45:14.787244 EDT | AverageAbsQ                 0.0862532
2017-06-03 17:45:14.787487 EDT | AverageY                    0.0860198
2017-06-03 17:45:14.787728 EDT | AverageAbsY                 0.086038
2017-06-03 17:45:14.787969 EDT | AverageAbsQYDiff            0.0014588
2017-06-03 17:45:14.788208 EDT | AverageAction               0.221715
2017-06-03 17:45:14.788448 EDT | PolicyRegParamNorm         67.6218
2017-06-03 17:45:14.788689 EDT | QFunRegParamNorm           28.3853
2017-06-03 17:45:14.788930 EDT | -----------------------  --------------
2017-06-03 17:45:14.789280 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #629 | Training started
2017-06-03 17:45:32.568818 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #629 | Training finished
2017-06-03 17:45:32.570743 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #629 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 17:45:32.571034 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #629 | Collecting samples for evaluation
2017-06-03 17:45:41.832018 EDT | -----------------------  --------------
2017-06-03 17:45:41.833679 EDT | Epoch                     629
2017-06-03 17:45:41.833956 EDT | Iteration                 629
2017-06-03 17:45:41.834194 EDT | AverageReturn            1000
2017-06-03 17:45:41.834449 EDT | StdReturn                   0
2017-06-03 17:45:41.834680 EDT | MaxReturn                1000
2017-06-03 17:45:41.834908 EDT | MinReturn                1000
2017-06-03 17:45:41.835136 EDT | AverageEsReturn            41.8333
2017-06-03 17:45:41.835370 EDT | StdEsReturn                30.9094
2017-06-03 17:45:41.835644 EDT | MaxEsReturn               120
2017-06-03 17:45:41.835874 EDT | MinEsReturn                 4
2017-06-03 17:45:41.836100 EDT | AverageDiscountedReturn    99.9957
2017-06-03 17:45:41.836326 EDT | AverageQLoss                2.49369e-05
2017-06-03 17:45:41.836552 EDT | AveragePolicySurr          -0.08957
2017-06-03 17:45:41.836787 EDT | AverageQ                    0.0857471
2017-06-03 17:45:41.837015 EDT | AverageAbsQ                 0.085988
2017-06-03 17:45:41.837241 EDT | AverageY                    0.0857536
2017-06-03 17:45:41.837466 EDT | AverageAbsY                 0.0857757
2017-06-03 17:45:41.837690 EDT | AverageAbsQYDiff            0.00136769
2017-06-03 17:45:41.837952 EDT | AverageAction               0.114855
2017-06-03 17:45:41.838191 EDT | PolicyRegParamNorm         67.6409
2017-06-03 17:45:41.838433 EDT | QFunRegParamNorm           28.4016
2017-06-03 17:45:41.838673 EDT | -----------------------  --------------
2017-06-03 17:45:41.839061 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #630 | Training started
2017-06-03 17:46:00.281249 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #630 | Training finished
2017-06-03 17:46:00.282129 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #630 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 17:46:00.282408 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #630 | Collecting samples for evaluation
2017-06-03 17:46:09.960667 EDT | -----------------------  -------------
2017-06-03 17:46:09.961513 EDT | Epoch                     630
2017-06-03 17:46:09.961787 EDT | Iteration                 630
2017-06-03 17:46:09.962011 EDT | AverageReturn            1000
2017-06-03 17:46:09.962228 EDT | StdReturn                   0
2017-06-03 17:46:09.962442 EDT | MaxReturn                1000
2017-06-03 17:46:09.962663 EDT | MinReturn                1000
2017-06-03 17:46:09.962881 EDT | AverageEsReturn            36.7037
2017-06-03 17:46:09.963096 EDT | StdEsReturn                25.0227
2017-06-03 17:46:09.963306 EDT | MaxEsReturn                92
2017-06-03 17:46:09.963638 EDT | MinEsReturn                 3
2017-06-03 17:46:09.963874 EDT | AverageDiscountedReturn    99.9957
2017-06-03 17:46:09.964100 EDT | AverageQLoss                2.5976e-05
2017-06-03 17:46:09.964325 EDT | AveragePolicySurr          -0.0896388
2017-06-03 17:46:09.964549 EDT | AverageQ                    0.0858096
2017-06-03 17:46:09.964790 EDT | AverageAbsQ                 0.0860792
2017-06-03 17:46:09.965013 EDT | AverageY                    0.0858022
2017-06-03 17:46:09.965235 EDT | AverageAbsY                 0.0858446
2017-06-03 17:46:09.965458 EDT | AverageAbsQYDiff            0.00136886
2017-06-03 17:46:09.965679 EDT | AverageAction               0.0274069
2017-06-03 17:46:09.965926 EDT | PolicyRegParamNorm         67.6331
2017-06-03 17:46:09.966156 EDT | QFunRegParamNorm           28.3973
2017-06-03 17:46:09.966383 EDT | -----------------------  -------------
2017-06-03 17:46:09.966732 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #631 | Training started
2017-06-03 17:46:29.601188 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #631 | Training finished
2017-06-03 17:46:29.602143 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #631 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 17:46:29.602435 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #631 | Collecting samples for evaluation
2017-06-03 17:46:38.938081 EDT | -----------------------  --------------
2017-06-03 17:46:38.938933 EDT | Epoch                     631
2017-06-03 17:46:38.939209 EDT | Iteration                 631
2017-06-03 17:46:38.939456 EDT | AverageReturn            1000
2017-06-03 17:46:38.939694 EDT | StdReturn                   0
2017-06-03 17:46:38.939947 EDT | MaxReturn                1000
2017-06-03 17:46:38.940181 EDT | MinReturn                1000
2017-06-03 17:46:38.940415 EDT | AverageEsReturn            33.4667
2017-06-03 17:46:38.940650 EDT | StdEsReturn                26.2624
2017-06-03 17:46:38.940882 EDT | MaxEsReturn                99
2017-06-03 17:46:38.941115 EDT | MinEsReturn                 3
2017-06-03 17:46:38.941346 EDT | AverageDiscountedReturn    99.9957
2017-06-03 17:46:38.941578 EDT | AverageQLoss                2.43484e-05
2017-06-03 17:46:38.941830 EDT | AveragePolicySurr          -0.0896797
2017-06-03 17:46:38.942063 EDT | AverageQ                    0.085946
2017-06-03 17:46:38.942295 EDT | AverageAbsQ                 0.0861448
2017-06-03 17:46:38.942527 EDT | AverageY                    0.0859456
2017-06-03 17:46:38.942758 EDT | AverageAbsY                 0.0859839
2017-06-03 17:46:38.942989 EDT | AverageAbsQYDiff            0.0012594
2017-06-03 17:46:38.943229 EDT | AverageAction               0.0223856
2017-06-03 17:46:38.943479 EDT | PolicyRegParamNorm         67.7074
2017-06-03 17:46:38.943713 EDT | QFunRegParamNorm           28.4237
2017-06-03 17:46:38.943945 EDT | -----------------------  --------------
2017-06-03 17:46:38.944332 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #632 | Training started
2017-06-03 17:46:56.504447 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #632 | Training finished
2017-06-03 17:46:56.505359 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #632 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 17:46:56.505644 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #632 | Collecting samples for evaluation
2017-06-03 17:47:05.934051 EDT | -----------------------  --------------
2017-06-03 17:47:05.934503 EDT | Epoch                     632
2017-06-03 17:47:05.934755 EDT | Iteration                 632
2017-06-03 17:47:05.935001 EDT | AverageReturn            1000
2017-06-03 17:47:05.935243 EDT | StdReturn                   0
2017-06-03 17:47:05.935484 EDT | MaxReturn                1000
2017-06-03 17:47:05.935738 EDT | MinReturn                1000
2017-06-03 17:47:05.935970 EDT | AverageEsReturn            31.3438
2017-06-03 17:47:05.936203 EDT | StdEsReturn                34.6632
2017-06-03 17:47:05.936436 EDT | MaxEsReturn               141
2017-06-03 17:47:05.936682 EDT | MinEsReturn                 4
2017-06-03 17:47:05.936915 EDT | AverageDiscountedReturn    99.9957
2017-06-03 17:47:05.937149 EDT | AverageQLoss                2.90051e-05
2017-06-03 17:47:05.937379 EDT | AveragePolicySurr          -0.0895376
2017-06-03 17:47:05.937607 EDT | AverageQ                    0.0855821
2017-06-03 17:47:05.937862 EDT | AverageAbsQ                 0.0858437
2017-06-03 17:47:05.938095 EDT | AverageY                    0.085579
2017-06-03 17:47:05.938338 EDT | AverageAbsY                 0.0856135
2017-06-03 17:47:05.938573 EDT | AverageAbsQYDiff            0.00149833
2017-06-03 17:47:05.938806 EDT | AverageAction               0.0043861
2017-06-03 17:47:05.939036 EDT | PolicyRegParamNorm         67.7997
2017-06-03 17:47:05.939268 EDT | QFunRegParamNorm           28.409
2017-06-03 17:47:05.939500 EDT | -----------------------  --------------
2017-06-03 17:47:05.940019 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #633 | Training started
2017-06-03 17:47:24.569033 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #633 | Training finished
2017-06-03 17:47:24.569916 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #633 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 17:47:24.570209 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #633 | Collecting samples for evaluation
2017-06-03 17:47:33.207727 EDT | -----------------------  --------------
2017-06-03 17:47:33.208709 EDT | Epoch                     633
2017-06-03 17:47:33.209061 EDT | Iteration                 633
2017-06-03 17:47:33.209392 EDT | AverageReturn            1000
2017-06-03 17:47:33.209728 EDT | StdReturn                   0
2017-06-03 17:47:33.210074 EDT | MaxReturn                1000
2017-06-03 17:47:33.210415 EDT | MinReturn                1000
2017-06-03 17:47:33.210728 EDT | AverageEsReturn            31.6
2017-06-03 17:47:33.211065 EDT | StdEsReturn                20.5306
2017-06-03 17:47:33.211378 EDT | MaxEsReturn                90
2017-06-03 17:47:33.211690 EDT | MinEsReturn                 5
2017-06-03 17:47:33.212008 EDT | AverageDiscountedReturn    99.9957
2017-06-03 17:47:33.212331 EDT | AverageQLoss                2.79368e-05
2017-06-03 17:47:33.212674 EDT | AveragePolicySurr          -0.0896151
2017-06-03 17:47:33.212985 EDT | AverageQ                    0.0859149
2017-06-03 17:47:33.213294 EDT | AverageAbsQ                 0.0861815
2017-06-03 17:47:33.213604 EDT | AverageY                    0.0859171
2017-06-03 17:47:33.213940 EDT | AverageAbsY                 0.0859623
2017-06-03 17:47:33.214251 EDT | AverageAbsQYDiff            0.00147599
2017-06-03 17:47:33.214562 EDT | AverageAction               0.10217
2017-06-03 17:47:33.214900 EDT | PolicyRegParamNorm         67.7719
2017-06-03 17:47:33.215225 EDT | QFunRegParamNorm           28.4196
2017-06-03 17:47:33.215533 EDT | -----------------------  --------------
2017-06-03 17:47:33.215968 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #634 | Training started
2017-06-03 17:47:51.715511 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #634 | Training finished
2017-06-03 17:47:51.716559 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #634 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 17:47:51.716859 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #634 | Collecting samples for evaluation
2017-06-03 17:48:01.137167 EDT | -----------------------  --------------
2017-06-03 17:48:01.138058 EDT | Epoch                     634
2017-06-03 17:48:01.138319 EDT | Iteration                 634
2017-06-03 17:48:01.138555 EDT | AverageReturn            1000
2017-06-03 17:48:01.138784 EDT | StdReturn                   0
2017-06-03 17:48:01.139016 EDT | MaxReturn                1000
2017-06-03 17:48:01.139275 EDT | MinReturn                1000
2017-06-03 17:48:01.139497 EDT | AverageEsReturn            40.4231
2017-06-03 17:48:01.139716 EDT | StdEsReturn                27.4285
2017-06-03 17:48:01.139938 EDT | MaxEsReturn                91
2017-06-03 17:48:01.140160 EDT | MinEsReturn                 3
2017-06-03 17:48:01.140388 EDT | AverageDiscountedReturn    99.9957
2017-06-03 17:48:01.140611 EDT | AverageQLoss                2.34e-05
2017-06-03 17:48:01.140830 EDT | AveragePolicySurr          -0.0896142
2017-06-03 17:48:01.141054 EDT | AverageQ                    0.0858647
2017-06-03 17:48:01.141273 EDT | AverageAbsQ                 0.0860691
2017-06-03 17:48:01.141490 EDT | AverageY                    0.0858639
2017-06-03 17:48:01.142153 EDT | AverageAbsY                 0.0858931
2017-06-03 17:48:01.142467 EDT | AverageAbsQYDiff            0.00123007
2017-06-03 17:48:01.142773 EDT | AverageAction               2.01652e-06
2017-06-03 17:48:01.143079 EDT | PolicyRegParamNorm         67.8109
2017-06-03 17:48:01.143382 EDT | QFunRegParamNorm           28.4357
2017-06-03 17:48:01.143681 EDT | -----------------------  --------------
2017-06-03 17:48:01.144134 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #635 | Training started
2017-06-03 17:48:20.393885 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #635 | Training finished
2017-06-03 17:48:20.394781 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #635 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 17:48:20.395161 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #635 | Collecting samples for evaluation
2017-06-03 17:48:30.749188 EDT | -----------------------  --------------
2017-06-03 17:48:30.750134 EDT | Epoch                     635
2017-06-03 17:48:30.750472 EDT | Iteration                 635
2017-06-03 17:48:30.750809 EDT | AverageReturn            1000
2017-06-03 17:48:30.751125 EDT | StdReturn                   0
2017-06-03 17:48:30.751459 EDT | MaxReturn                1000
2017-06-03 17:48:30.751762 EDT | MinReturn                1000
2017-06-03 17:48:30.752098 EDT | AverageEsReturn            30.0606
2017-06-03 17:48:30.752397 EDT | StdEsReturn                23.8682
2017-06-03 17:48:30.752742 EDT | MaxEsReturn                92
2017-06-03 17:48:30.753053 EDT | MinEsReturn                 4
2017-06-03 17:48:30.753386 EDT | AverageDiscountedReturn    99.9957
2017-06-03 17:48:30.753705 EDT | AverageQLoss                2.89565e-05
2017-06-03 17:48:30.754053 EDT | AveragePolicySurr          -0.0893306
2017-06-03 17:48:30.754359 EDT | AverageQ                    0.085651
2017-06-03 17:48:30.754693 EDT | AverageAbsQ                 0.0858863
2017-06-03 17:48:30.754996 EDT | AverageY                    0.0856525
2017-06-03 17:48:30.755326 EDT | AverageAbsY                 0.0856839
2017-06-03 17:48:30.755640 EDT | AverageAbsQYDiff            0.00139894
2017-06-03 17:48:30.755962 EDT | AverageAction               0.0321648
2017-06-03 17:48:30.756304 EDT | PolicyRegParamNorm         67.8151
2017-06-03 17:48:30.756625 EDT | QFunRegParamNorm           28.4276
2017-06-03 17:48:30.756957 EDT | -----------------------  --------------
2017-06-03 17:48:30.757457 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #636 | Training started
2017-06-03 17:48:49.465717 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #636 | Training finished
2017-06-03 17:48:49.468548 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #636 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 17:48:49.468854 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #636 | Collecting samples for evaluation
2017-06-03 17:48:58.797473 EDT | -----------------------  --------------
2017-06-03 17:48:58.798308 EDT | Epoch                     636
2017-06-03 17:48:58.798564 EDT | Iteration                 636
2017-06-03 17:48:58.798801 EDT | AverageReturn            1000
2017-06-03 17:48:58.799054 EDT | StdReturn                   0
2017-06-03 17:48:58.799306 EDT | MaxReturn                1000
2017-06-03 17:48:58.799539 EDT | MinReturn                1000
2017-06-03 17:48:58.799766 EDT | AverageEsReturn            49.7895
2017-06-03 17:48:58.799993 EDT | StdEsReturn                31.2234
2017-06-03 17:48:58.800245 EDT | MaxEsReturn               120
2017-06-03 17:48:58.800482 EDT | MinEsReturn                13
2017-06-03 17:48:58.800713 EDT | AverageDiscountedReturn    99.9957
2017-06-03 17:48:58.800944 EDT | AverageQLoss                2.82066e-05
2017-06-03 17:48:58.801190 EDT | AveragePolicySurr          -0.0895189
2017-06-03 17:48:58.801418 EDT | AverageQ                    0.0855545
2017-06-03 17:48:58.801644 EDT | AverageAbsQ                 0.0858048
2017-06-03 17:48:58.801882 EDT | AverageY                    0.0855581
2017-06-03 17:48:58.802113 EDT | AverageAbsY                 0.0855852
2017-06-03 17:48:58.802368 EDT | AverageAbsQYDiff            0.00148532
2017-06-03 17:48:58.802595 EDT | AverageAction               3.88635e-05
2017-06-03 17:48:58.802820 EDT | PolicyRegParamNorm         67.847
2017-06-03 17:48:58.803045 EDT | QFunRegParamNorm           28.4436
2017-06-03 17:48:58.803301 EDT | -----------------------  --------------
2017-06-03 17:48:58.803654 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #637 | Training started
2017-06-03 17:49:16.237427 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #637 | Training finished
2017-06-03 17:49:16.238430 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #637 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 17:49:16.238700 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #637 | Collecting samples for evaluation
2017-06-03 17:49:26.187467 EDT | -----------------------  --------------
2017-06-03 17:49:26.188319 EDT | Epoch                     637
2017-06-03 17:49:26.188579 EDT | Iteration                 637
2017-06-03 17:49:26.188813 EDT | AverageReturn            1000
2017-06-03 17:49:26.189042 EDT | StdReturn                   0
2017-06-03 17:49:26.189269 EDT | MaxReturn                1000
2017-06-03 17:49:26.189508 EDT | MinReturn                1000
2017-06-03 17:49:26.189744 EDT | AverageEsReturn            45.7273
2017-06-03 17:49:26.189970 EDT | StdEsReturn                54.0582
2017-06-03 17:49:26.190194 EDT | MaxEsReturn               250
2017-06-03 17:49:26.190422 EDT | MinEsReturn                 4
2017-06-03 17:49:26.190656 EDT | AverageDiscountedReturn    99.9957
2017-06-03 17:49:26.190882 EDT | AverageQLoss                2.10893e-05
2017-06-03 17:49:26.191163 EDT | AveragePolicySurr          -0.0895356
2017-06-03 17:49:26.191393 EDT | AverageQ                    0.0858806
2017-06-03 17:49:26.191616 EDT | AverageAbsQ                 0.0861188
2017-06-03 17:49:26.191836 EDT | AverageY                    0.0858774
2017-06-03 17:49:26.192057 EDT | AverageAbsY                 0.0859087
2017-06-03 17:49:26.192298 EDT | AverageAbsQYDiff            0.00124605
2017-06-03 17:49:26.192519 EDT | AverageAction               0.000380788
2017-06-03 17:49:26.192738 EDT | PolicyRegParamNorm         67.8399
2017-06-03 17:49:26.192963 EDT | QFunRegParamNorm           28.4385
2017-06-03 17:49:26.193181 EDT | -----------------------  --------------
2017-06-03 17:49:26.193630 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #638 | Training started
2017-06-03 17:49:45.387283 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #638 | Training finished
2017-06-03 17:49:45.388162 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #638 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 17:49:45.388574 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #638 | Collecting samples for evaluation
2017-06-03 17:49:54.600379 EDT | -----------------------  --------------
2017-06-03 17:49:54.601205 EDT | Epoch                     638
2017-06-03 17:49:54.601460 EDT | Iteration                 638
2017-06-03 17:49:54.601705 EDT | AverageReturn            1000
2017-06-03 17:49:54.601942 EDT | StdReturn                   0
2017-06-03 17:49:54.602185 EDT | MaxReturn                1000
2017-06-03 17:49:54.602411 EDT | MinReturn                1000
2017-06-03 17:49:54.602635 EDT | AverageEsReturn            41.75
2017-06-03 17:49:54.602862 EDT | StdEsReturn                41.8571
2017-06-03 17:49:54.603084 EDT | MaxEsReturn               217
2017-06-03 17:49:54.603306 EDT | MinEsReturn                 3
2017-06-03 17:49:54.603549 EDT | AverageDiscountedReturn    99.9957
2017-06-03 17:49:54.603785 EDT | AverageQLoss                2.89764e-05
2017-06-03 17:49:54.604061 EDT | AveragePolicySurr          -0.089441
2017-06-03 17:49:54.604346 EDT | AverageQ                    0.0854346
2017-06-03 17:49:54.604609 EDT | AverageAbsQ                 0.0857161
2017-06-03 17:49:54.604868 EDT | AverageY                    0.0854356
2017-06-03 17:49:54.605095 EDT | AverageAbsY                 0.0854731
2017-06-03 17:49:54.605318 EDT | AverageAbsQYDiff            0.00152306
2017-06-03 17:49:54.605548 EDT | AverageAction               6.10298e-05
2017-06-03 17:49:54.605808 EDT | PolicyRegParamNorm         67.8461
2017-06-03 17:49:54.606049 EDT | QFunRegParamNorm           28.4489
2017-06-03 17:49:54.606284 EDT | -----------------------  --------------
2017-06-03 17:49:54.606643 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #639 | Training started
2017-06-03 17:50:13.789050 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #639 | Training finished
2017-06-03 17:50:13.790016 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #639 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 17:50:13.790298 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #639 | Collecting samples for evaluation
2017-06-03 17:50:22.958958 EDT | -----------------------  --------------
2017-06-03 17:50:22.959821 EDT | Epoch                     639
2017-06-03 17:50:22.960159 EDT | Iteration                 639
2017-06-03 17:50:22.960443 EDT | AverageReturn            1000
2017-06-03 17:50:22.960686 EDT | StdReturn                   0
2017-06-03 17:50:22.960995 EDT | MaxReturn                1000
2017-06-03 17:50:22.961306 EDT | MinReturn                1000
2017-06-03 17:50:22.961615 EDT | AverageEsReturn            38.7407
2017-06-03 17:50:22.961932 EDT | StdEsReturn                31.815
2017-06-03 17:50:22.962172 EDT | MaxEsReturn               134
2017-06-03 17:50:22.962482 EDT | MinEsReturn                 3
2017-06-03 17:50:22.962794 EDT | AverageDiscountedReturn    99.9957
2017-06-03 17:50:22.963044 EDT | AverageQLoss                2.83766e-05
2017-06-03 17:50:22.963277 EDT | AveragePolicySurr          -0.0895709
2017-06-03 17:50:22.963599 EDT | AverageQ                    0.0856921
2017-06-03 17:50:22.963929 EDT | AverageAbsQ                 0.0859348
2017-06-03 17:50:22.964188 EDT | AverageY                    0.0856906
2017-06-03 17:50:22.964423 EDT | AverageAbsY                 0.0857282
2017-06-03 17:50:22.964656 EDT | AverageAbsQYDiff            0.00142384
2017-06-03 17:50:22.964885 EDT | AverageAction               3.94945e-05
2017-06-03 17:50:22.965113 EDT | PolicyRegParamNorm         67.8662
2017-06-03 17:50:22.965339 EDT | QFunRegParamNorm           28.4557
2017-06-03 17:50:22.965581 EDT | -----------------------  --------------
2017-06-03 17:50:22.966143 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #640 | Training started
2017-06-03 17:50:43.920706 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #640 | Training finished
2017-06-03 17:50:43.921616 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #640 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 17:50:43.921894 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #640 | Collecting samples for evaluation
2017-06-03 17:50:53.734197 EDT | -----------------------  --------------
2017-06-03 17:50:53.735093 EDT | Epoch                     640
2017-06-03 17:50:53.735361 EDT | Iteration                 640
2017-06-03 17:50:53.735604 EDT | AverageReturn            1000
2017-06-03 17:50:53.735842 EDT | StdReturn                   0
2017-06-03 17:50:53.736079 EDT | MaxReturn                1000
2017-06-03 17:50:53.736323 EDT | MinReturn                1000
2017-06-03 17:50:53.736563 EDT | AverageEsReturn            42.0952
2017-06-03 17:50:53.736898 EDT | StdEsReturn                35.3848
2017-06-03 17:50:53.737225 EDT | MaxEsReturn               129
2017-06-03 17:50:53.737575 EDT | MinEsReturn                 5
2017-06-03 17:50:53.737914 EDT | AverageDiscountedReturn    99.9957
2017-06-03 17:50:53.738240 EDT | AverageQLoss                2.69467e-05
2017-06-03 17:50:53.738564 EDT | AveragePolicySurr          -0.0893654
2017-06-03 17:50:53.738881 EDT | AverageQ                    0.08556
2017-06-03 17:50:53.739199 EDT | AverageAbsQ                 0.0857524
2017-06-03 17:50:53.739518 EDT | AverageY                    0.0855562
2017-06-03 17:50:53.739831 EDT | AverageAbsY                 0.085579
2017-06-03 17:50:53.740153 EDT | AverageAbsQYDiff            0.00137365
2017-06-03 17:50:53.740464 EDT | AverageAction               0.00891231
2017-06-03 17:50:53.740799 EDT | PolicyRegParamNorm         67.8574
2017-06-03 17:50:53.741109 EDT | QFunRegParamNorm           28.4719
2017-06-03 17:50:53.741421 EDT | -----------------------  --------------
2017-06-03 17:50:53.741913 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #641 | Training started
2017-06-03 17:51:12.428539 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #641 | Training finished
2017-06-03 17:51:12.429459 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #641 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 17:51:12.429779 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #641 | Collecting samples for evaluation
2017-06-03 17:51:22.627434 EDT | -----------------------  --------------
2017-06-03 17:51:22.628327 EDT | Epoch                     641
2017-06-03 17:51:22.628596 EDT | Iteration                 641
2017-06-03 17:51:22.628852 EDT | AverageReturn            1000
2017-06-03 17:51:22.629104 EDT | StdReturn                   0
2017-06-03 17:51:22.629341 EDT | MaxReturn                1000
2017-06-03 17:51:22.629603 EDT | MinReturn                1000
2017-06-03 17:51:22.629898 EDT | AverageEsReturn            49.3182
2017-06-03 17:51:22.630148 EDT | StdEsReturn                40.261
2017-06-03 17:51:22.630426 EDT | MaxEsReturn               153
2017-06-03 17:51:22.630683 EDT | MinEsReturn                 9
2017-06-03 17:51:22.630949 EDT | AverageDiscountedReturn    99.9957
2017-06-03 17:51:22.631195 EDT | AverageQLoss                2.51966e-05
2017-06-03 17:51:22.631438 EDT | AveragePolicySurr          -0.0894608
2017-06-03 17:51:22.631719 EDT | AverageQ                    0.085816
2017-06-03 17:51:22.631966 EDT | AverageAbsQ                 0.0860486
2017-06-03 17:51:22.632213 EDT | AverageY                    0.0858202
2017-06-03 17:51:22.632468 EDT | AverageAbsY                 0.0858454
2017-06-03 17:51:22.632712 EDT | AverageAbsQYDiff            0.00131414
2017-06-03 17:51:22.632982 EDT | AverageAction               0.000181986
2017-06-03 17:51:22.633229 EDT | PolicyRegParamNorm         67.851
2017-06-03 17:51:22.633474 EDT | QFunRegParamNorm           28.4727
2017-06-03 17:51:22.633756 EDT | -----------------------  --------------
2017-06-03 17:51:22.634163 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #642 | Training started
2017-06-03 17:51:41.211589 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #642 | Training finished
2017-06-03 17:51:41.212495 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #642 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 17:51:41.212785 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #642 | Collecting samples for evaluation
2017-06-03 17:51:50.437004 EDT | -----------------------  --------------
2017-06-03 17:51:50.438065 EDT | Epoch                     642
2017-06-03 17:51:50.438335 EDT | Iteration                 642
2017-06-03 17:51:50.438558 EDT | AverageReturn            1000
2017-06-03 17:51:50.438775 EDT | StdReturn                   0
2017-06-03 17:51:50.438990 EDT | MaxReturn                1000
2017-06-03 17:51:50.439203 EDT | MinReturn                1000
2017-06-03 17:51:50.439414 EDT | AverageEsReturn            41.75
2017-06-03 17:51:50.439632 EDT | StdEsReturn                33.9966
2017-06-03 17:51:50.439847 EDT | MaxEsReturn               126
2017-06-03 17:51:50.440071 EDT | MinEsReturn                 4
2017-06-03 17:51:50.440285 EDT | AverageDiscountedReturn    99.9957
2017-06-03 17:51:50.440561 EDT | AverageQLoss                2.23495e-05
2017-06-03 17:51:50.440797 EDT | AveragePolicySurr          -0.0894135
2017-06-03 17:51:50.441020 EDT | AverageQ                    0.085584
2017-06-03 17:51:50.441239 EDT | AverageAbsQ                 0.0858036
2017-06-03 17:51:50.441457 EDT | AverageY                    0.0855862
2017-06-03 17:51:50.441685 EDT | AverageAbsY                 0.0856199
2017-06-03 17:51:50.442463 EDT | AverageAbsQYDiff            0.00132404
2017-06-03 17:51:50.442774 EDT | AverageAction               0.0402872
2017-06-03 17:51:50.443094 EDT | PolicyRegParamNorm         67.9195
2017-06-03 17:51:50.443395 EDT | QFunRegParamNorm           28.4896
2017-06-03 17:51:50.443695 EDT | -----------------------  --------------
2017-06-03 17:51:50.444176 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #643 | Training started
2017-06-03 17:52:10.014658 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #643 | Training finished
2017-06-03 17:52:10.015301 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #643 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 17:52:10.015569 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #643 | Collecting samples for evaluation
2017-06-03 17:52:19.331044 EDT | -----------------------  --------------
2017-06-03 17:52:19.331417 EDT | Epoch                     643
2017-06-03 17:52:19.331678 EDT | Iteration                 643
2017-06-03 17:52:19.331953 EDT | AverageReturn            1000
2017-06-03 17:52:19.332206 EDT | StdReturn                   0
2017-06-03 17:52:19.332452 EDT | MaxReturn                1000
2017-06-03 17:52:19.332705 EDT | MinReturn                1000
2017-06-03 17:52:19.332951 EDT | AverageEsReturn            35.3103
2017-06-03 17:52:19.333195 EDT | StdEsReturn                22.0064
2017-06-03 17:52:19.333437 EDT | MaxEsReturn                74
2017-06-03 17:52:19.333679 EDT | MinEsReturn                 5
2017-06-03 17:52:19.333952 EDT | AverageDiscountedReturn    99.9957
2017-06-03 17:52:19.334196 EDT | AverageQLoss                2.87895e-05
2017-06-03 17:52:19.334469 EDT | AveragePolicySurr          -0.0894489
2017-06-03 17:52:19.334720 EDT | AverageQ                    0.0856707
2017-06-03 17:52:19.334962 EDT | AverageAbsQ                 0.0859333
2017-06-03 17:52:19.335203 EDT | AverageY                    0.0856696
2017-06-03 17:52:19.335444 EDT | AverageAbsY                 0.0856905
2017-06-03 17:52:19.335700 EDT | AverageAbsQYDiff            0.00147322
2017-06-03 17:52:19.335940 EDT | AverageAction               6.97706e-05
2017-06-03 17:52:19.336180 EDT | PolicyRegParamNorm         68.0144
2017-06-03 17:52:19.336422 EDT | QFunRegParamNorm           28.4944
2017-06-03 17:52:19.336662 EDT | -----------------------  --------------
2017-06-03 17:52:19.337055 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #644 | Training started
2017-06-03 17:52:38.077966 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #644 | Training finished
2017-06-03 17:52:38.078934 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #644 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 17:52:38.079366 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #644 | Collecting samples for evaluation
2017-06-03 17:52:47.807672 EDT | -----------------------  --------------
2017-06-03 17:52:47.808081 EDT | Epoch                     644
2017-06-03 17:52:47.808364 EDT | Iteration                 644
2017-06-03 17:52:47.808606 EDT | AverageReturn            1000
2017-06-03 17:52:47.808867 EDT | StdReturn                   0
2017-06-03 17:52:47.809131 EDT | MaxReturn                1000
2017-06-03 17:52:47.809365 EDT | MinReturn                1000
2017-06-03 17:52:47.809599 EDT | AverageEsReturn            37.2593
2017-06-03 17:52:47.809942 EDT | StdEsReturn                27.9385
2017-06-03 17:52:47.810196 EDT | MaxEsReturn                98
2017-06-03 17:52:47.810461 EDT | MinEsReturn                 4
2017-06-03 17:52:47.810726 EDT | AverageDiscountedReturn    99.9957
2017-06-03 17:52:47.810973 EDT | AverageQLoss                2.35055e-05
2017-06-03 17:52:47.811233 EDT | AveragePolicySurr          -0.0895547
2017-06-03 17:52:47.811474 EDT | AverageQ                    0.0858586
2017-06-03 17:52:47.811732 EDT | AverageAbsQ                 0.0861022
2017-06-03 17:52:47.811995 EDT | AverageY                    0.0858584
2017-06-03 17:52:47.812234 EDT | AverageAbsY                 0.0858764
2017-06-03 17:52:47.812501 EDT | AverageAbsQYDiff            0.00137475
2017-06-03 17:52:47.812755 EDT | AverageAction               0.234224
2017-06-03 17:52:47.813022 EDT | PolicyRegParamNorm         68.057
2017-06-03 17:52:47.813286 EDT | QFunRegParamNorm           28.492
2017-06-03 17:52:47.813541 EDT | -----------------------  --------------
2017-06-03 17:52:47.813986 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #645 | Training started
2017-06-03 17:53:06.307767 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #645 | Training finished
2017-06-03 17:53:06.308789 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #645 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 17:53:06.309060 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #645 | Collecting samples for evaluation
2017-06-03 17:53:17.287801 EDT | -----------------------  --------------
2017-06-03 17:53:17.288214 EDT | Epoch                     645
2017-06-03 17:53:17.288487 EDT | Iteration                 645
2017-06-03 17:53:17.288736 EDT | AverageReturn            1000
2017-06-03 17:53:17.288985 EDT | StdReturn                   0
2017-06-03 17:53:17.289237 EDT | MaxReturn                1000
2017-06-03 17:53:17.289476 EDT | MinReturn                1000
2017-06-03 17:53:17.289824 EDT | AverageEsReturn            37.0769
2017-06-03 17:53:17.290072 EDT | StdEsReturn                31.0817
2017-06-03 17:53:17.290319 EDT | MaxEsReturn               113
2017-06-03 17:53:17.290556 EDT | MinEsReturn                 3
2017-06-03 17:53:17.290793 EDT | AverageDiscountedReturn    99.9957
2017-06-03 17:53:17.291041 EDT | AverageQLoss                2.68343e-05
2017-06-03 17:53:17.291284 EDT | AveragePolicySurr          -0.0894209
2017-06-03 17:53:17.291528 EDT | AverageQ                    0.0856012
2017-06-03 17:53:17.291779 EDT | AverageAbsQ                 0.0858302
2017-06-03 17:53:17.292029 EDT | AverageY                    0.0855991
2017-06-03 17:53:17.292263 EDT | AverageAbsY                 0.0856265
2017-06-03 17:53:17.292498 EDT | AverageAbsQYDiff            0.00142583
2017-06-03 17:53:17.292730 EDT | AverageAction               0.0991676
2017-06-03 17:53:17.292963 EDT | PolicyRegParamNorm         68.041
2017-06-03 17:53:17.293208 EDT | QFunRegParamNorm           28.4913
2017-06-03 17:53:17.293442 EDT | -----------------------  --------------
2017-06-03 17:53:17.293991 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #646 | Training started
2017-06-03 17:53:35.859697 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #646 | Training finished
2017-06-03 17:53:35.861568 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #646 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 17:53:35.861863 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #646 | Collecting samples for evaluation
2017-06-03 17:53:45.039389 EDT | -----------------------  --------------
2017-06-03 17:53:45.040690 EDT | Epoch                     646
2017-06-03 17:53:45.040957 EDT | Iteration                 646
2017-06-03 17:53:45.041193 EDT | AverageReturn            1000
2017-06-03 17:53:45.041446 EDT | StdReturn                   0
2017-06-03 17:53:45.041677 EDT | MaxReturn                1000
2017-06-03 17:53:45.042166 EDT | MinReturn                1000
2017-06-03 17:53:45.042483 EDT | AverageEsReturn            49.7143
2017-06-03 17:53:45.042806 EDT | StdEsReturn                47.1827
2017-06-03 17:53:45.043120 EDT | MaxEsReturn               212
2017-06-03 17:53:45.043428 EDT | MinEsReturn                 3
2017-06-03 17:53:45.044224 EDT | AverageDiscountedReturn    99.9957
2017-06-03 17:53:45.044632 EDT | AverageQLoss                2.41404e-05
2017-06-03 17:53:45.044946 EDT | AveragePolicySurr          -0.089584
2017-06-03 17:53:45.045317 EDT | AverageQ                    0.0858494
2017-06-03 17:53:45.046231 EDT | AverageAbsQ                 0.0860617
2017-06-03 17:53:45.046568 EDT | AverageY                    0.0858544
2017-06-03 17:53:45.046887 EDT | AverageAbsY                 0.0858792
2017-06-03 17:53:45.047199 EDT | AverageAbsQYDiff            0.00131868
2017-06-03 17:53:45.047512 EDT | AverageAction               0.0146289
2017-06-03 17:53:45.047830 EDT | PolicyRegParamNorm         68.0306
2017-06-03 17:53:45.048140 EDT | QFunRegParamNorm           28.4846
2017-06-03 17:53:45.048450 EDT | -----------------------  --------------
2017-06-03 17:53:45.048903 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #647 | Training started
2017-06-03 17:54:04.274523 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #647 | Training finished
2017-06-03 17:54:04.275370 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #647 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 17:54:04.275638 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #647 | Collecting samples for evaluation
2017-06-03 17:54:13.773955 EDT | -----------------------  --------------
2017-06-03 17:54:13.775109 EDT | Epoch                     647
2017-06-03 17:54:13.775374 EDT | Iteration                 647
2017-06-03 17:54:13.775618 EDT | AverageReturn            1000
2017-06-03 17:54:13.775850 EDT | StdReturn                   0
2017-06-03 17:54:13.776078 EDT | MaxReturn                1000
2017-06-03 17:54:13.776307 EDT | MinReturn                1000
2017-06-03 17:54:13.776545 EDT | AverageEsReturn            40.5
2017-06-03 17:54:13.776773 EDT | StdEsReturn                54.4763
2017-06-03 17:54:13.777000 EDT | MaxEsReturn               250
2017-06-03 17:54:13.777232 EDT | MinEsReturn                 3
2017-06-03 17:54:13.777464 EDT | AverageDiscountedReturn    99.9957
2017-06-03 17:54:13.777691 EDT | AverageQLoss                2.55384e-05
2017-06-03 17:54:13.777929 EDT | AveragePolicySurr          -0.0894875
2017-06-03 17:54:13.778163 EDT | AverageQ                    0.0858653
2017-06-03 17:54:13.778389 EDT | AverageAbsQ                 0.0860834
2017-06-03 17:54:13.778614 EDT | AverageY                    0.0858642
2017-06-03 17:54:13.778840 EDT | AverageAbsY                 0.085885
2017-06-03 17:54:13.779066 EDT | AverageAbsQYDiff            0.00138243
2017-06-03 17:54:13.779297 EDT | AverageAction               0.0959866
2017-06-03 17:54:13.779527 EDT | PolicyRegParamNorm         68.0443
2017-06-03 17:54:13.779762 EDT | QFunRegParamNorm           28.4829
2017-06-03 17:54:13.779988 EDT | -----------------------  --------------
2017-06-03 17:54:13.780377 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #648 | Training started
2017-06-03 17:54:33.413015 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #648 | Training finished
2017-06-03 17:54:33.413894 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #648 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 17:54:33.414187 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #648 | Collecting samples for evaluation
2017-06-03 17:54:43.310267 EDT | -----------------------  --------------
2017-06-03 17:54:43.311106 EDT | Epoch                     648
2017-06-03 17:54:43.311366 EDT | Iteration                 648
2017-06-03 17:54:43.311627 EDT | AverageReturn            1000
2017-06-03 17:54:43.311865 EDT | StdReturn                   0
2017-06-03 17:54:43.312110 EDT | MaxReturn                1000
2017-06-03 17:54:43.312358 EDT | MinReturn                1000
2017-06-03 17:54:43.312594 EDT | AverageEsReturn            33.8667
2017-06-03 17:54:43.312827 EDT | StdEsReturn                24.3704
2017-06-03 17:54:43.313059 EDT | MaxEsReturn                91
2017-06-03 17:54:43.313291 EDT | MinEsReturn                 4
2017-06-03 17:54:43.313532 EDT | AverageDiscountedReturn    99.9957
2017-06-03 17:54:43.313774 EDT | AverageQLoss                2.66404e-05
2017-06-03 17:54:43.314007 EDT | AveragePolicySurr          -0.0894853
2017-06-03 17:54:43.314250 EDT | AverageQ                    0.0857139
2017-06-03 17:54:43.314483 EDT | AverageAbsQ                 0.0859973
2017-06-03 17:54:43.314714 EDT | AverageY                    0.0857134
2017-06-03 17:54:43.314945 EDT | AverageAbsY                 0.0857461
2017-06-03 17:54:43.315176 EDT | AverageAbsQYDiff            0.00142322
2017-06-03 17:54:43.315413 EDT | AverageAction               0.268639
2017-06-03 17:54:43.315644 EDT | PolicyRegParamNorm         68.0839
2017-06-03 17:54:43.315878 EDT | QFunRegParamNorm           28.4795
2017-06-03 17:54:43.316108 EDT | -----------------------  --------------
2017-06-03 17:54:43.316470 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #649 | Training started
2017-06-03 17:55:01.037146 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #649 | Training finished
2017-06-03 17:55:01.038089 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #649 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 17:55:01.038475 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #649 | Collecting samples for evaluation
2017-06-03 17:55:10.183340 EDT | -----------------------  --------------
2017-06-03 17:55:10.184169 EDT | Epoch                     649
2017-06-03 17:55:10.184435 EDT | Iteration                 649
2017-06-03 17:55:10.184680 EDT | AverageReturn            1000
2017-06-03 17:55:10.184944 EDT | StdReturn                   0
2017-06-03 17:55:10.185185 EDT | MaxReturn                1000
2017-06-03 17:55:10.185425 EDT | MinReturn                1000
2017-06-03 17:55:10.185663 EDT | AverageEsReturn            31.375
2017-06-03 17:55:10.185924 EDT | StdEsReturn                27.1233
2017-06-03 17:55:10.186168 EDT | MaxEsReturn               108
2017-06-03 17:55:10.186408 EDT | MinEsReturn                 3
2017-06-03 17:55:10.186651 EDT | AverageDiscountedReturn    99.9957
2017-06-03 17:55:10.186890 EDT | AverageQLoss                2.63644e-05
2017-06-03 17:55:10.187129 EDT | AveragePolicySurr          -0.0895623
2017-06-03 17:55:10.187365 EDT | AverageQ                    0.0859796
2017-06-03 17:55:10.187600 EDT | AverageAbsQ                 0.0861999
2017-06-03 17:55:10.187859 EDT | AverageY                    0.0859787
2017-06-03 17:55:10.188094 EDT | AverageAbsY                 0.0860138
2017-06-03 17:55:10.188336 EDT | AverageAbsQYDiff            0.00136345
2017-06-03 17:55:10.188573 EDT | AverageAction               0.0341748
2017-06-03 17:55:10.188809 EDT | PolicyRegParamNorm         68.1
2017-06-03 17:55:10.189045 EDT | QFunRegParamNorm           28.502
2017-06-03 17:55:10.189277 EDT | -----------------------  --------------
2017-06-03 17:55:10.189656 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #650 | Training started
2017-06-03 17:55:28.792516 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #650 | Training finished
2017-06-03 17:55:28.793420 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #650 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 17:55:28.793839 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #650 | Collecting samples for evaluation
2017-06-03 17:55:38.796676 EDT | -----------------------  --------------
2017-06-03 17:55:38.800415 EDT | Epoch                     650
2017-06-03 17:55:38.800782 EDT | Iteration                 650
2017-06-03 17:55:38.801034 EDT | AverageReturn            1000
2017-06-03 17:55:38.801285 EDT | StdReturn                   0
2017-06-03 17:55:38.801551 EDT | MaxReturn                1000
2017-06-03 17:55:38.801808 EDT | MinReturn                1000
2017-06-03 17:55:38.802047 EDT | AverageEsReturn            37.2593
2017-06-03 17:55:38.802289 EDT | StdEsReturn                32.7523
2017-06-03 17:55:38.802544 EDT | MaxEsReturn               140
2017-06-03 17:55:38.802778 EDT | MinEsReturn                 3
2017-06-03 17:55:38.803009 EDT | AverageDiscountedReturn    99.9957
2017-06-03 17:55:38.803271 EDT | AverageQLoss                2.29241e-05
2017-06-03 17:55:38.803529 EDT | AveragePolicySurr          -0.0893399
2017-06-03 17:55:38.803764 EDT | AverageQ                    0.0854663
2017-06-03 17:55:38.804009 EDT | AverageAbsQ                 0.0856574
2017-06-03 17:55:38.804242 EDT | AverageY                    0.085469
2017-06-03 17:55:38.804510 EDT | AverageAbsY                 0.0855084
2017-06-03 17:55:38.804759 EDT | AverageAbsQYDiff            0.00122753
2017-06-03 17:55:38.805015 EDT | AverageAction               0.0265411
2017-06-03 17:55:38.805263 EDT | PolicyRegParamNorm         68.1134
2017-06-03 17:55:38.805519 EDT | QFunRegParamNorm           28.5134
2017-06-03 17:55:38.806758 EDT | -----------------------  --------------
2017-06-03 17:55:38.808243 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #651 | Training started
2017-06-03 17:55:59.376935 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #651 | Training finished
2017-06-03 17:55:59.377276 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #651 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 17:55:59.377526 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #651 | Collecting samples for evaluation
2017-06-03 17:56:10.466856 EDT | -----------------------  --------------
2017-06-03 17:56:10.467979 EDT | Epoch                     651
2017-06-03 17:56:10.468253 EDT | Iteration                 651
2017-06-03 17:56:10.468496 EDT | AverageReturn            1000
2017-06-03 17:56:10.468739 EDT | StdReturn                   0
2017-06-03 17:56:10.468996 EDT | MaxReturn                1000
2017-06-03 17:56:10.469242 EDT | MinReturn                1000
2017-06-03 17:56:10.469496 EDT | AverageEsReturn            29.5
2017-06-03 17:56:10.469749 EDT | StdEsReturn                21.32
2017-06-03 17:56:10.470003 EDT | MaxEsReturn                87
2017-06-03 17:56:10.470243 EDT | MinEsReturn                 4
2017-06-03 17:56:10.470475 EDT | AverageDiscountedReturn    99.9957
2017-06-03 17:56:10.470708 EDT | AverageQLoss                2.44696e-05
2017-06-03 17:56:10.470958 EDT | AveragePolicySurr          -0.0894637
2017-06-03 17:56:10.471191 EDT | AverageQ                    0.0856217
2017-06-03 17:56:10.471430 EDT | AverageAbsQ                 0.0858505
2017-06-03 17:56:10.471671 EDT | AverageY                    0.0856179
2017-06-03 17:56:10.471903 EDT | AverageAbsY                 0.0856491
2017-06-03 17:56:10.472149 EDT | AverageAbsQYDiff            0.00139052
2017-06-03 17:56:10.472385 EDT | AverageAction               0.00211491
2017-06-03 17:56:10.472626 EDT | PolicyRegParamNorm         68.1301
2017-06-03 17:56:10.472856 EDT | QFunRegParamNorm           28.5452
2017-06-03 17:56:10.473083 EDT | -----------------------  --------------
2017-06-03 17:56:10.473443 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #652 | Training started
2017-06-03 17:56:28.366321 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #652 | Training finished
2017-06-03 17:56:28.367307 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #652 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 17:56:28.367858 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #652 | Collecting samples for evaluation
2017-06-03 17:56:37.784987 EDT | -----------------------  --------------
2017-06-03 17:56:37.786756 EDT | Epoch                     652
2017-06-03 17:56:37.787372 EDT | Iteration                 652
2017-06-03 17:56:37.787732 EDT | AverageReturn            1000
2017-06-03 17:56:37.788079 EDT | StdReturn                   0
2017-06-03 17:56:37.788480 EDT | MaxReturn                1000
2017-06-03 17:56:37.788822 EDT | MinReturn                1000
2017-06-03 17:56:37.789168 EDT | AverageEsReturn            31.25
2017-06-03 17:56:37.789515 EDT | StdEsReturn                26.8375
2017-06-03 17:56:37.789881 EDT | MaxEsReturn                90
2017-06-03 17:56:37.790202 EDT | MinEsReturn                 3
2017-06-03 17:56:37.791107 EDT | AverageDiscountedReturn    99.9957
2017-06-03 17:56:37.791435 EDT | AverageQLoss                2.79276e-05
2017-06-03 17:56:37.791795 EDT | AveragePolicySurr          -0.089426
2017-06-03 17:56:37.792160 EDT | AverageQ                    0.0858099
2017-06-03 17:56:37.792515 EDT | AverageAbsQ                 0.086052
2017-06-03 17:56:37.792847 EDT | AverageY                    0.0858136
2017-06-03 17:56:37.793164 EDT | AverageAbsY                 0.0858446
2017-06-03 17:56:37.793484 EDT | AverageAbsQYDiff            0.00143512
2017-06-03 17:56:37.793834 EDT | AverageAction               0.135969
2017-06-03 17:56:37.794153 EDT | PolicyRegParamNorm         68.2187
2017-06-03 17:56:37.794476 EDT | QFunRegParamNorm           28.5421
2017-06-03 17:56:37.794830 EDT | -----------------------  --------------
2017-06-03 17:56:37.795337 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #653 | Training started
2017-06-03 17:56:56.430161 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #653 | Training finished
2017-06-03 17:56:56.431131 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #653 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 17:56:56.431500 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #653 | Collecting samples for evaluation
2017-06-03 17:57:06.414855 EDT | -----------------------  --------------
2017-06-03 17:57:06.418084 EDT | Epoch                     653
2017-06-03 17:57:06.418359 EDT | Iteration                 653
2017-06-03 17:57:06.418605 EDT | AverageReturn            1000
2017-06-03 17:57:06.418844 EDT | StdReturn                   0
2017-06-03 17:57:06.419083 EDT | MaxReturn                1000
2017-06-03 17:57:06.419365 EDT | MinReturn                1000
2017-06-03 17:57:06.419601 EDT | AverageEsReturn            26.8649
2017-06-03 17:57:06.419837 EDT | StdEsReturn                28.4711
2017-06-03 17:57:06.420067 EDT | MaxEsReturn               153
2017-06-03 17:57:06.420301 EDT | MinEsReturn                 3
2017-06-03 17:57:06.420549 EDT | AverageDiscountedReturn    99.9957
2017-06-03 17:57:06.420783 EDT | AverageQLoss                2.92049e-05
2017-06-03 17:57:06.421013 EDT | AveragePolicySurr          -0.0894212
2017-06-03 17:57:06.421245 EDT | AverageQ                    0.0856159
2017-06-03 17:57:06.421473 EDT | AverageAbsQ                 0.0859316
2017-06-03 17:57:06.421710 EDT | AverageY                    0.0856101
2017-06-03 17:57:06.421979 EDT | AverageAbsY                 0.0856432
2017-06-03 17:57:06.422215 EDT | AverageAbsQYDiff            0.00160131
2017-06-03 17:57:06.422448 EDT | AverageAction               0.11686
2017-06-03 17:57:06.422678 EDT | PolicyRegParamNorm         68.2342
2017-06-03 17:57:06.422910 EDT | QFunRegParamNorm           28.5596
2017-06-03 17:57:06.423150 EDT | -----------------------  --------------
2017-06-03 17:57:06.423542 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #654 | Training started
2017-06-03 17:57:24.346035 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #654 | Training finished
2017-06-03 17:57:24.346959 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #654 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 17:57:24.347408 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #654 | Collecting samples for evaluation
2017-06-03 17:57:33.523032 EDT | -----------------------  --------------
2017-06-03 17:57:33.523872 EDT | Epoch                     654
2017-06-03 17:57:33.524203 EDT | Iteration                 654
2017-06-03 17:57:33.524429 EDT | AverageReturn            1000
2017-06-03 17:57:33.524650 EDT | StdReturn                   0
2017-06-03 17:57:33.524906 EDT | MaxReturn                1000
2017-06-03 17:57:33.525131 EDT | MinReturn                1000
2017-06-03 17:57:33.525479 EDT | AverageEsReturn            29.625
2017-06-03 17:57:33.525796 EDT | StdEsReturn                30.084
2017-06-03 17:57:33.526093 EDT | MaxEsReturn               125
2017-06-03 17:57:33.526389 EDT | MinEsReturn                 3
2017-06-03 17:57:33.526681 EDT | AverageDiscountedReturn    99.9957
2017-06-03 17:57:33.527047 EDT | AverageQLoss                2.40332e-05
2017-06-03 17:57:33.527445 EDT | AveragePolicySurr          -0.0895334
2017-06-03 17:57:33.527764 EDT | AverageQ                    0.085801
2017-06-03 17:57:33.528120 EDT | AverageAbsQ                 0.0859972
2017-06-03 17:57:33.528490 EDT | AverageY                    0.0858013
2017-06-03 17:57:33.528809 EDT | AverageAbsY                 0.0858245
2017-06-03 17:57:33.529175 EDT | AverageAbsQYDiff            0.00126854
2017-06-03 17:57:33.529524 EDT | AverageAction               0.158867
2017-06-03 17:57:33.529860 EDT | PolicyRegParamNorm         68.2722
2017-06-03 17:57:33.530218 EDT | QFunRegParamNorm           28.5681
2017-06-03 17:57:33.530559 EDT | -----------------------  --------------
2017-06-03 17:57:33.531061 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #655 | Training started
2017-06-03 17:57:52.016572 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #655 | Training finished
2017-06-03 17:57:52.017541 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #655 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 17:57:52.017932 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #655 | Collecting samples for evaluation
2017-06-03 17:58:01.978514 EDT | -----------------------  --------------
2017-06-03 17:58:01.978886 EDT | Epoch                     655
2017-06-03 17:58:01.979137 EDT | Iteration                 655
2017-06-03 17:58:01.979392 EDT | AverageReturn            1000
2017-06-03 17:58:01.979626 EDT | StdReturn                   0
2017-06-03 17:58:01.979865 EDT | MaxReturn                1000
2017-06-03 17:58:01.980100 EDT | MinReturn                1000
2017-06-03 17:58:01.980330 EDT | AverageEsReturn            36.4483
2017-06-03 17:58:01.980564 EDT | StdEsReturn                30.9344
2017-06-03 17:58:01.980820 EDT | MaxEsReturn               121
2017-06-03 17:58:01.981051 EDT | MinEsReturn                 3
2017-06-03 17:58:01.981279 EDT | AverageDiscountedReturn    99.9957
2017-06-03 17:58:01.981511 EDT | AverageQLoss                2.86333e-05
2017-06-03 17:58:01.981844 EDT | AveragePolicySurr          -0.0892629
2017-06-03 17:58:01.982076 EDT | AverageQ                    0.0854019
2017-06-03 17:58:01.982308 EDT | AverageAbsQ                 0.0856572
2017-06-03 17:58:01.982545 EDT | AverageY                    0.0854042
2017-06-03 17:58:01.982774 EDT | AverageAbsY                 0.0854349
2017-06-03 17:58:01.983006 EDT | AverageAbsQYDiff            0.001471
2017-06-03 17:58:01.983238 EDT | AverageAction               0.000516777
2017-06-03 17:58:01.983469 EDT | PolicyRegParamNorm         68.2831
2017-06-03 17:58:01.983711 EDT | QFunRegParamNorm           28.5784
2017-06-03 17:58:01.983942 EDT | -----------------------  --------------
2017-06-03 17:58:01.984337 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #656 | Training started
2017-06-03 17:58:21.155035 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #656 | Training finished
2017-06-03 17:58:21.155945 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #656 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 17:58:21.156214 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #656 | Collecting samples for evaluation
2017-06-03 17:58:30.221125 EDT | -----------------------  --------------
2017-06-03 17:58:30.221533 EDT | Epoch                     656
2017-06-03 17:58:30.221802 EDT | Iteration                 656
2017-06-03 17:58:30.222044 EDT | AverageReturn            1000
2017-06-03 17:58:30.222280 EDT | StdReturn                   0
2017-06-03 17:58:30.222517 EDT | MaxReturn                1000
2017-06-03 17:58:30.222749 EDT | MinReturn                1000
2017-06-03 17:58:30.222982 EDT | AverageEsReturn            29.2121
2017-06-03 17:58:30.223215 EDT | StdEsReturn                23.3611
2017-06-03 17:58:30.223447 EDT | MaxEsReturn                88
2017-06-03 17:58:30.223676 EDT | MinEsReturn                 3
2017-06-03 17:58:30.223906 EDT | AverageDiscountedReturn    99.9957
2017-06-03 17:58:30.224137 EDT | AverageQLoss                2.11206e-05
2017-06-03 17:58:30.224364 EDT | AveragePolicySurr          -0.0894547
2017-06-03 17:58:30.224591 EDT | AverageQ                    0.0856002
2017-06-03 17:58:30.224820 EDT | AverageAbsQ                 0.0857968
2017-06-03 17:58:30.225050 EDT | AverageY                    0.0855986
2017-06-03 17:58:30.225278 EDT | AverageAbsY                 0.0856341
2017-06-03 17:58:30.225504 EDT | AverageAbsQYDiff            0.00117754
2017-06-03 17:58:30.225743 EDT | AverageAction               0.0107738
2017-06-03 17:58:30.225975 EDT | PolicyRegParamNorm         68.2996
2017-06-03 17:58:30.226206 EDT | QFunRegParamNorm           28.5753
2017-06-03 17:58:30.226437 EDT | -----------------------  --------------
2017-06-03 17:58:30.226817 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #657 | Training started
2017-06-03 17:58:48.698875 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #657 | Training finished
2017-06-03 17:58:48.699928 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #657 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 17:58:48.700330 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #657 | Collecting samples for evaluation
2017-06-03 17:58:58.159257 EDT | -----------------------  --------------
2017-06-03 17:58:58.160157 EDT | Epoch                     657
2017-06-03 17:58:58.160421 EDT | Iteration                 657
2017-06-03 17:58:58.160665 EDT | AverageReturn            1000
2017-06-03 17:58:58.160912 EDT | StdReturn                   0
2017-06-03 17:58:58.161152 EDT | MaxReturn                1000
2017-06-03 17:58:58.161386 EDT | MinReturn                1000
2017-06-03 17:58:58.161619 EDT | AverageEsReturn            30.4118
2017-06-03 17:58:58.161893 EDT | StdEsReturn                22.0189
2017-06-03 17:58:58.162131 EDT | MaxEsReturn               100
2017-06-03 17:58:58.162373 EDT | MinEsReturn                 4
2017-06-03 17:58:58.162604 EDT | AverageDiscountedReturn    99.9957
2017-06-03 17:58:58.162833 EDT | AverageQLoss                2.42187e-05
2017-06-03 17:58:58.163088 EDT | AveragePolicySurr          -0.089494
2017-06-03 17:58:58.163337 EDT | AverageQ                    0.08579
2017-06-03 17:58:58.163584 EDT | AverageAbsQ                 0.086059
2017-06-03 17:58:58.163834 EDT | AverageY                    0.0857905
2017-06-03 17:58:58.164079 EDT | AverageAbsY                 0.0858423
2017-06-03 17:58:58.164329 EDT | AverageAbsQYDiff            0.00132507
2017-06-03 17:58:58.164565 EDT | AverageAction               0.00013238
2017-06-03 17:58:58.164820 EDT | PolicyRegParamNorm         68.3486
2017-06-03 17:58:58.165057 EDT | QFunRegParamNorm           28.5937
2017-06-03 17:58:58.165289 EDT | -----------------------  --------------
2017-06-03 17:58:58.165657 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #658 | Training started
2017-06-03 17:59:16.633143 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #658 | Training finished
2017-06-03 17:59:16.634059 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #658 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 17:59:16.634429 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #658 | Collecting samples for evaluation
2017-06-03 17:59:26.190903 EDT | -----------------------  --------------
2017-06-03 17:59:26.191814 EDT | Epoch                     658
2017-06-03 17:59:26.192081 EDT | Iteration                 658
2017-06-03 17:59:26.192314 EDT | AverageReturn            1000
2017-06-03 17:59:26.192543 EDT | StdReturn                   0
2017-06-03 17:59:26.192777 EDT | MaxReturn                1000
2017-06-03 17:59:26.193005 EDT | MinReturn                1000
2017-06-03 17:59:26.193231 EDT | AverageEsReturn            34.6296
2017-06-03 17:59:26.193455 EDT | StdEsReturn                23.1903
2017-06-03 17:59:26.193719 EDT | MaxEsReturn                87
2017-06-03 17:59:26.193969 EDT | MinEsReturn                 5
2017-06-03 17:59:26.194211 EDT | AverageDiscountedReturn    99.9957
2017-06-03 17:59:26.194450 EDT | AverageQLoss                2.17548e-05
2017-06-03 17:59:26.194689 EDT | AveragePolicySurr          -0.0895224
2017-06-03 17:59:26.194926 EDT | AverageQ                    0.0857927
2017-06-03 17:59:26.195169 EDT | AverageAbsQ                 0.0860222
2017-06-03 17:59:26.195405 EDT | AverageY                    0.0857907
2017-06-03 17:59:26.195641 EDT | AverageAbsY                 0.0858367
2017-06-03 17:59:26.195876 EDT | AverageAbsQYDiff            0.00130216
2017-06-03 17:59:26.196112 EDT | AverageAction               9.30913e-05
2017-06-03 17:59:26.196348 EDT | PolicyRegParamNorm         68.356
2017-06-03 17:59:26.196584 EDT | QFunRegParamNorm           28.6171
2017-06-03 17:59:26.196819 EDT | -----------------------  --------------
2017-06-03 17:59:26.197193 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #659 | Training started
2017-06-03 17:59:45.203554 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #659 | Training finished
2017-06-03 17:59:45.204422 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #659 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 17:59:45.204700 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #659 | Collecting samples for evaluation
2017-06-03 17:59:54.839206 EDT | -----------------------  --------------
2017-06-03 17:59:54.840092 EDT | Epoch                     659
2017-06-03 17:59:54.840369 EDT | Iteration                 659
2017-06-03 17:59:54.840621 EDT | AverageReturn            1000
2017-06-03 17:59:54.840868 EDT | StdReturn                   0
2017-06-03 17:59:54.841113 EDT | MaxReturn                1000
2017-06-03 17:59:54.841357 EDT | MinReturn                1000
2017-06-03 17:59:54.841601 EDT | AverageEsReturn            33.871
2017-06-03 17:59:54.841870 EDT | StdEsReturn                32.3157
2017-06-03 17:59:54.842115 EDT | MaxEsReturn               134
2017-06-03 17:59:54.842361 EDT | MinEsReturn                 4
2017-06-03 17:59:54.842603 EDT | AverageDiscountedReturn    99.9957
2017-06-03 17:59:54.842848 EDT | AverageQLoss                2.81084e-05
2017-06-03 17:59:54.843093 EDT | AveragePolicySurr          -0.0895768
2017-06-03 17:59:54.843370 EDT | AverageQ                    0.0857392
2017-06-03 17:59:54.843614 EDT | AverageAbsQ                 0.0859632
2017-06-03 17:59:54.843855 EDT | AverageY                    0.0857382
2017-06-03 17:59:54.844098 EDT | AverageAbsY                 0.0857728
2017-06-03 17:59:54.844378 EDT | AverageAbsQYDiff            0.00141987
2017-06-03 17:59:54.844623 EDT | AverageAction               0.00998106
2017-06-03 17:59:54.844906 EDT | PolicyRegParamNorm         68.3979
2017-06-03 17:59:54.845149 EDT | QFunRegParamNorm           28.6199
2017-06-03 17:59:54.845407 EDT | -----------------------  --------------
2017-06-03 17:59:54.845848 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #660 | Training started
2017-06-03 18:00:13.701842 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #660 | Training finished
2017-06-03 18:00:13.702688 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #660 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 18:00:13.702955 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #660 | Collecting samples for evaluation
2017-06-03 18:00:23.542752 EDT | -----------------------  --------------
2017-06-03 18:00:23.543802 EDT | Epoch                     660
2017-06-03 18:00:23.544065 EDT | Iteration                 660
2017-06-03 18:00:23.544301 EDT | AverageReturn            1000
2017-06-03 18:00:23.544533 EDT | StdReturn                   0
2017-06-03 18:00:23.544769 EDT | MaxReturn                1000
2017-06-03 18:00:23.544996 EDT | MinReturn                1000
2017-06-03 18:00:23.545228 EDT | AverageEsReturn            28.8529
2017-06-03 18:00:23.545455 EDT | StdEsReturn                30.411
2017-06-03 18:00:23.545682 EDT | MaxEsReturn               128
2017-06-03 18:00:23.545922 EDT | MinEsReturn                 3
2017-06-03 18:00:23.546149 EDT | AverageDiscountedReturn    99.9957
2017-06-03 18:00:23.546374 EDT | AverageQLoss                2.42989e-05
2017-06-03 18:00:23.546600 EDT | AveragePolicySurr          -0.0894674
2017-06-03 18:00:23.546824 EDT | AverageQ                    0.0856857
2017-06-03 18:00:23.547050 EDT | AverageAbsQ                 0.085947
2017-06-03 18:00:23.547275 EDT | AverageY                    0.0856866
2017-06-03 18:00:23.547500 EDT | AverageAbsY                 0.0857235
2017-06-03 18:00:23.547723 EDT | AverageAbsQYDiff            0.00132952
2017-06-03 18:00:23.547947 EDT | AverageAction               0.000671546
2017-06-03 18:00:23.548172 EDT | PolicyRegParamNorm         68.4349
2017-06-03 18:00:23.548396 EDT | QFunRegParamNorm           28.6083
2017-06-03 18:00:23.548620 EDT | -----------------------  --------------
2017-06-03 18:00:23.548959 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #661 | Training started
2017-06-03 18:00:42.688874 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #661 | Training finished
2017-06-03 18:00:42.689793 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #661 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 18:00:42.690081 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #661 | Collecting samples for evaluation
2017-06-03 18:00:52.436085 EDT | -----------------------  --------------
2017-06-03 18:00:52.436923 EDT | Epoch                     661
2017-06-03 18:00:52.437188 EDT | Iteration                 661
2017-06-03 18:00:52.437428 EDT | AverageReturn            1000
2017-06-03 18:00:52.437664 EDT | StdReturn                   0
2017-06-03 18:00:52.437914 EDT | MaxReturn                1000
2017-06-03 18:00:52.438171 EDT | MinReturn                1000
2017-06-03 18:00:52.438407 EDT | AverageEsReturn            34.4
2017-06-03 18:00:52.438656 EDT | StdEsReturn                26.228
2017-06-03 18:00:52.438899 EDT | MaxEsReturn               120
2017-06-03 18:00:52.439133 EDT | MinEsReturn                 5
2017-06-03 18:00:52.439369 EDT | AverageDiscountedReturn    99.9957
2017-06-03 18:00:52.439600 EDT | AverageQLoss                2.43581e-05
2017-06-03 18:00:52.439834 EDT | AveragePolicySurr          -0.0895519
2017-06-03 18:00:52.440069 EDT | AverageQ                    0.0857649
2017-06-03 18:00:52.440302 EDT | AverageAbsQ                 0.0860239
2017-06-03 18:00:52.440571 EDT | AverageY                    0.0857689
2017-06-03 18:00:52.440804 EDT | AverageAbsY                 0.0858125
2017-06-03 18:00:52.441037 EDT | AverageAbsQYDiff            0.00134396
2017-06-03 18:00:52.441282 EDT | AverageAction               0.00138222
2017-06-03 18:00:52.441522 EDT | PolicyRegParamNorm         68.4515
2017-06-03 18:00:52.441780 EDT | QFunRegParamNorm           28.6408
2017-06-03 18:00:52.442018 EDT | -----------------------  --------------
2017-06-03 18:00:52.442406 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #662 | Training started
2017-06-03 18:01:11.295711 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #662 | Training finished
2017-06-03 18:01:11.297482 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #662 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 18:01:11.297855 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #662 | Collecting samples for evaluation
2017-06-03 18:01:20.919183 EDT | -----------------------  --------------
2017-06-03 18:01:20.920083 EDT | Epoch                     662
2017-06-03 18:01:20.920346 EDT | Iteration                 662
2017-06-03 18:01:20.920582 EDT | AverageReturn            1000
2017-06-03 18:01:20.920833 EDT | StdReturn                   0
2017-06-03 18:01:20.921075 EDT | MaxReturn                1000
2017-06-03 18:01:20.921304 EDT | MinReturn                1000
2017-06-03 18:01:20.921536 EDT | AverageEsReturn            34.9259
2017-06-03 18:01:20.921789 EDT | StdEsReturn                32.6575
2017-06-03 18:01:20.922022 EDT | MaxEsReturn               145
2017-06-03 18:01:20.922251 EDT | MinEsReturn                 4
2017-06-03 18:01:20.922479 EDT | AverageDiscountedReturn    99.9957
2017-06-03 18:01:20.922707 EDT | AverageQLoss                3.06609e-05
2017-06-03 18:01:20.922943 EDT | AveragePolicySurr          -0.0895433
2017-06-03 18:01:20.923169 EDT | AverageQ                    0.0858389
2017-06-03 18:01:20.923394 EDT | AverageAbsQ                 0.0860853
2017-06-03 18:01:20.923619 EDT | AverageY                    0.0858358
2017-06-03 18:01:20.923845 EDT | AverageAbsY                 0.0858824
2017-06-03 18:01:20.924070 EDT | AverageAbsQYDiff            0.00154527
2017-06-03 18:01:20.924296 EDT | AverageAction               0.000960474
2017-06-03 18:01:20.924550 EDT | PolicyRegParamNorm         68.4594
2017-06-03 18:01:20.924784 EDT | QFunRegParamNorm           28.6362
2017-06-03 18:01:20.925010 EDT | -----------------------  --------------
2017-06-03 18:01:20.925388 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #663 | Training started
2017-06-03 18:01:39.020969 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #663 | Training finished
2017-06-03 18:01:39.021847 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #663 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 18:01:39.022126 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #663 | Collecting samples for evaluation
2017-06-03 18:01:48.843748 EDT | -----------------------  --------------
2017-06-03 18:01:48.844611 EDT | Epoch                     663
2017-06-03 18:01:48.844868 EDT | Iteration                 663
2017-06-03 18:01:48.845111 EDT | AverageReturn            1000
2017-06-03 18:01:48.845356 EDT | StdReturn                   0
2017-06-03 18:01:48.845589 EDT | MaxReturn                1000
2017-06-03 18:01:48.845848 EDT | MinReturn                1000
2017-06-03 18:01:48.846081 EDT | AverageEsReturn            31.0588
2017-06-03 18:01:48.846314 EDT | StdEsReturn                25.6113
2017-06-03 18:01:48.846545 EDT | MaxEsReturn               109
2017-06-03 18:01:48.846776 EDT | MinEsReturn                 4
2017-06-03 18:01:48.847028 EDT | AverageDiscountedReturn    99.9957
2017-06-03 18:01:48.847259 EDT | AverageQLoss                2.38935e-05
2017-06-03 18:01:48.847492 EDT | AveragePolicySurr          -0.0895574
2017-06-03 18:01:48.847731 EDT | AverageQ                    0.0860568
2017-06-03 18:01:48.847963 EDT | AverageAbsQ                 0.0862509
2017-06-03 18:01:48.848199 EDT | AverageY                    0.0860578
2017-06-03 18:01:48.848429 EDT | AverageAbsY                 0.0860858
2017-06-03 18:01:48.848668 EDT | AverageAbsQYDiff            0.00128939
2017-06-03 18:01:48.848897 EDT | AverageAction               2.33229e-05
2017-06-03 18:01:48.849129 EDT | PolicyRegParamNorm         68.4682
2017-06-03 18:01:48.849363 EDT | QFunRegParamNorm           28.6414
2017-06-03 18:01:48.849592 EDT | -----------------------  --------------
2017-06-03 18:01:48.849965 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #664 | Training started
2017-06-03 18:02:08.222021 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #664 | Training finished
2017-06-03 18:02:08.223044 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #664 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 18:02:08.223415 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #664 | Collecting samples for evaluation
2017-06-03 18:02:17.635396 EDT | -----------------------  --------------
2017-06-03 18:02:17.636499 EDT | Epoch                     664
2017-06-03 18:02:17.636852 EDT | Iteration                 664
2017-06-03 18:02:17.637174 EDT | AverageReturn            1000
2017-06-03 18:02:17.637491 EDT | StdReturn                   0
2017-06-03 18:02:17.637828 EDT | MaxReturn                1000
2017-06-03 18:02:17.638140 EDT | MinReturn                1000
2017-06-03 18:02:17.638453 EDT | AverageEsReturn            25.0513
2017-06-03 18:02:17.638767 EDT | StdEsReturn                25.8863
2017-06-03 18:02:17.639080 EDT | MaxEsReturn               120
2017-06-03 18:02:17.639388 EDT | MinEsReturn                 3
2017-06-03 18:02:17.639708 EDT | AverageDiscountedReturn    99.9957
2017-06-03 18:02:17.640018 EDT | AverageQLoss                2.22849e-05
2017-06-03 18:02:17.640330 EDT | AveragePolicySurr          -0.0895433
2017-06-03 18:02:17.640638 EDT | AverageQ                    0.0858356
2017-06-03 18:02:17.640954 EDT | AverageAbsQ                 0.0860339
2017-06-03 18:02:17.641942 EDT | AverageY                    0.085833
2017-06-03 18:02:17.642269 EDT | AverageAbsY                 0.0858658
2017-06-03 18:02:17.642583 EDT | AverageAbsQYDiff            0.00113194
2017-06-03 18:02:17.642894 EDT | AverageAction               0.0497341
2017-06-03 18:02:17.643201 EDT | PolicyRegParamNorm         68.4374
2017-06-03 18:02:17.643505 EDT | QFunRegParamNorm           28.6412
2017-06-03 18:02:17.643810 EDT | -----------------------  --------------
2017-06-03 18:02:17.644274 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #665 | Training started
2017-06-03 18:02:35.741778 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #665 | Training finished
2017-06-03 18:02:35.742652 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #665 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 18:02:35.742921 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #665 | Collecting samples for evaluation
2017-06-03 18:02:44.867730 EDT | -----------------------  --------------
2017-06-03 18:02:44.868129 EDT | Epoch                     665
2017-06-03 18:02:44.868401 EDT | Iteration                 665
2017-06-03 18:02:44.868645 EDT | AverageReturn            1000
2017-06-03 18:02:44.868881 EDT | StdReturn                   0
2017-06-03 18:02:44.869115 EDT | MaxReturn                1000
2017-06-03 18:02:44.869348 EDT | MinReturn                1000
2017-06-03 18:02:44.869599 EDT | AverageEsReturn            26.359
2017-06-03 18:02:44.869920 EDT | StdEsReturn                28.4853
2017-06-03 18:02:44.870215 EDT | MaxEsReturn               141
2017-06-03 18:02:44.870449 EDT | MinEsReturn                 3
2017-06-03 18:02:44.870683 EDT | AverageDiscountedReturn    99.9957
2017-06-03 18:02:44.870914 EDT | AverageQLoss                2.58567e-05
2017-06-03 18:02:44.871145 EDT | AveragePolicySurr          -0.0895045
2017-06-03 18:02:44.871386 EDT | AverageQ                    0.0857915
2017-06-03 18:02:44.871617 EDT | AverageAbsQ                 0.08603
2017-06-03 18:02:44.871846 EDT | AverageY                    0.0857896
2017-06-03 18:02:44.872073 EDT | AverageAbsY                 0.0858159
2017-06-03 18:02:44.872300 EDT | AverageAbsQYDiff            0.00136029
2017-06-03 18:02:44.872527 EDT | AverageAction               0.00933111
2017-06-03 18:02:44.872774 EDT | PolicyRegParamNorm         68.4053
2017-06-03 18:02:44.873006 EDT | QFunRegParamNorm           28.6635
2017-06-03 18:02:44.873245 EDT | -----------------------  --------------
2017-06-03 18:02:44.873629 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #666 | Training started
2017-06-03 18:03:03.333094 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #666 | Training finished
2017-06-03 18:03:03.334137 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #666 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 18:03:03.334427 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #666 | Collecting samples for evaluation
2017-06-03 18:03:12.890251 EDT | -----------------------  --------------
2017-06-03 18:03:12.891504 EDT | Epoch                     666
2017-06-03 18:03:12.891851 EDT | Iteration                 666
2017-06-03 18:03:12.892187 EDT | AverageReturn            1000
2017-06-03 18:03:12.892515 EDT | StdReturn                   0
2017-06-03 18:03:12.892841 EDT | MaxReturn                1000
2017-06-03 18:03:12.893161 EDT | MinReturn                1000
2017-06-03 18:03:12.893479 EDT | AverageEsReturn            26.1111
2017-06-03 18:03:12.893806 EDT | StdEsReturn                23.5888
2017-06-03 18:03:12.894125 EDT | MaxEsReturn               105
2017-06-03 18:03:12.894439 EDT | MinEsReturn                 4
2017-06-03 18:03:12.894754 EDT | AverageDiscountedReturn    99.9957
2017-06-03 18:03:12.895098 EDT | AverageQLoss                3.05204e-05
2017-06-03 18:03:12.895414 EDT | AveragePolicySurr          -0.0894946
2017-06-03 18:03:12.895747 EDT | AverageQ                    0.0856875
2017-06-03 18:03:12.896068 EDT | AverageAbsQ                 0.0859605
2017-06-03 18:03:12.896387 EDT | AverageY                    0.0856926
2017-06-03 18:03:12.896704 EDT | AverageAbsY                 0.0857231
2017-06-03 18:03:12.897030 EDT | AverageAbsQYDiff            0.00151642
2017-06-03 18:03:12.897348 EDT | AverageAction               7.32761e-05
2017-06-03 18:03:12.897662 EDT | PolicyRegParamNorm         68.4133
2017-06-03 18:03:12.898000 EDT | QFunRegParamNorm           28.6685
2017-06-03 18:03:12.898311 EDT | -----------------------  --------------
2017-06-03 18:03:12.898790 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #667 | Training started
2017-06-03 18:03:31.549123 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #667 | Training finished
2017-06-03 18:03:31.550370 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #667 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 18:03:31.550736 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #667 | Collecting samples for evaluation
2017-06-03 18:03:42.231942 EDT | -----------------------  --------------
2017-06-03 18:03:42.232874 EDT | Epoch                     667
2017-06-03 18:03:42.233160 EDT | Iteration                 667
2017-06-03 18:03:42.233416 EDT | AverageReturn            1000
2017-06-03 18:03:42.233861 EDT | StdReturn                   0
2017-06-03 18:03:42.234112 EDT | MaxReturn                1000
2017-06-03 18:03:42.234352 EDT | MinReturn                1000
2017-06-03 18:03:42.234591 EDT | AverageEsReturn            23
2017-06-03 18:03:42.234841 EDT | StdEsReturn                23.8965
2017-06-03 18:03:42.235216 EDT | MaxEsReturn               121
2017-06-03 18:03:42.235453 EDT | MinEsReturn                 3
2017-06-03 18:03:42.235689 EDT | AverageDiscountedReturn    99.9957
2017-06-03 18:03:42.236033 EDT | AverageQLoss                2.20661e-05
2017-06-03 18:03:42.236350 EDT | AveragePolicySurr          -0.0894977
2017-06-03 18:03:42.236676 EDT | AverageQ                    0.0858099
2017-06-03 18:03:42.237034 EDT | AverageAbsQ                 0.0860285
2017-06-03 18:03:42.237369 EDT | AverageY                    0.0858106
2017-06-03 18:03:42.237720 EDT | AverageAbsY                 0.085826
2017-06-03 18:03:42.238090 EDT | AverageAbsQYDiff            0.00129345
2017-06-03 18:03:42.238410 EDT | AverageAction               0.0810274
2017-06-03 18:03:42.238732 EDT | PolicyRegParamNorm         68.4496
2017-06-03 18:03:42.239051 EDT | QFunRegParamNorm           28.6626
2017-06-03 18:03:42.239366 EDT | -----------------------  --------------
2017-06-03 18:03:42.240012 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #668 | Training started
2017-06-03 18:04:01.833592 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #668 | Training finished
2017-06-03 18:04:01.834730 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #668 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 18:04:01.834999 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #668 | Collecting samples for evaluation
2017-06-03 18:04:11.300556 EDT | -----------------------  --------------
2017-06-03 18:04:11.301448 EDT | Epoch                     668
2017-06-03 18:04:11.301715 EDT | Iteration                 668
2017-06-03 18:04:11.301961 EDT | AverageReturn            1000
2017-06-03 18:04:11.302216 EDT | StdReturn                   0
2017-06-03 18:04:11.302449 EDT | MaxReturn                1000
2017-06-03 18:04:11.302682 EDT | MinReturn                1000
2017-06-03 18:04:11.302914 EDT | AverageEsReturn            20.3878
2017-06-03 18:04:11.303151 EDT | StdEsReturn                17.5125
2017-06-03 18:04:11.303389 EDT | MaxEsReturn                75
2017-06-03 18:04:11.303628 EDT | MinEsReturn                 3
2017-06-03 18:04:11.303858 EDT | AverageDiscountedReturn    99.9957
2017-06-03 18:04:11.304089 EDT | AverageQLoss                2.55632e-05
2017-06-03 18:04:11.304319 EDT | AveragePolicySurr          -0.0895663
2017-06-03 18:04:11.304549 EDT | AverageQ                    0.085835
2017-06-03 18:04:11.304778 EDT | AverageAbsQ                 0.0860042
2017-06-03 18:04:11.305008 EDT | AverageY                    0.0858363
2017-06-03 18:04:11.305237 EDT | AverageAbsY                 0.0858469
2017-06-03 18:04:11.305465 EDT | AverageAbsQYDiff            0.00132448
2017-06-03 18:04:11.305701 EDT | AverageAction               0.0546115
2017-06-03 18:04:11.305936 EDT | PolicyRegParamNorm         68.4556
2017-06-03 18:04:11.306167 EDT | QFunRegParamNorm           28.678
2017-06-03 18:04:11.306395 EDT | -----------------------  --------------
2017-06-03 18:04:11.306739 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #669 | Training started
2017-06-03 18:04:30.459284 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #669 | Training finished
2017-06-03 18:04:30.460301 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #669 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 18:04:30.461364 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #669 | Collecting samples for evaluation
2017-06-03 18:04:39.582957 EDT | -----------------------  --------------
2017-06-03 18:04:39.584010 EDT | Epoch                     669
2017-06-03 18:04:39.584282 EDT | Iteration                 669
2017-06-03 18:04:39.584543 EDT | AverageReturn            1000
2017-06-03 18:04:39.584792 EDT | StdReturn                   0
2017-06-03 18:04:39.585043 EDT | MaxReturn                1000
2017-06-03 18:04:39.585288 EDT | MinReturn                1000
2017-06-03 18:04:39.585531 EDT | AverageEsReturn            30.1515
2017-06-03 18:04:39.585784 EDT | StdEsReturn                33.833
2017-06-03 18:04:39.586029 EDT | MaxEsReturn               144
2017-06-03 18:04:39.586320 EDT | MinEsReturn                 3
2017-06-03 18:04:39.586562 EDT | AverageDiscountedReturn    99.9957
2017-06-03 18:04:39.586809 EDT | AverageQLoss                2.29233e-05
2017-06-03 18:04:39.587051 EDT | AveragePolicySurr          -0.0892981
2017-06-03 18:04:39.587293 EDT | AverageQ                    0.0856564
2017-06-03 18:04:39.587547 EDT | AverageAbsQ                 0.0858864
2017-06-03 18:04:39.587812 EDT | AverageY                    0.0856571
2017-06-03 18:04:39.588057 EDT | AverageAbsY                 0.0856753
2017-06-03 18:04:39.588299 EDT | AverageAbsQYDiff            0.0013429
2017-06-03 18:04:39.588540 EDT | AverageAction               0.00152263
2017-06-03 18:04:39.588781 EDT | PolicyRegParamNorm         68.4841
2017-06-03 18:04:39.589028 EDT | QFunRegParamNorm           28.6946
2017-06-03 18:04:39.589266 EDT | -----------------------  --------------
2017-06-03 18:04:39.589629 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #670 | Training started
2017-06-03 18:04:58.586425 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #670 | Training finished
2017-06-03 18:04:58.587327 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #670 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 18:04:58.587808 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #670 | Collecting samples for evaluation
2017-06-03 18:05:09.181569 EDT | -----------------------  -------------
2017-06-03 18:05:09.182740 EDT | Epoch                     670
2017-06-03 18:05:09.183006 EDT | Iteration                 670
2017-06-03 18:05:09.183247 EDT | AverageReturn            1000
2017-06-03 18:05:09.183485 EDT | StdReturn                   0
2017-06-03 18:05:09.183726 EDT | MaxReturn                1000
2017-06-03 18:05:09.183965 EDT | MinReturn                1000
2017-06-03 18:05:09.184199 EDT | AverageEsReturn            28.0857
2017-06-03 18:05:09.184437 EDT | StdEsReturn                32.671
2017-06-03 18:05:09.184670 EDT | MaxEsReturn               147
2017-06-03 18:05:09.184901 EDT | MinEsReturn                 3
2017-06-03 18:05:09.185133 EDT | AverageDiscountedReturn    99.9957
2017-06-03 18:05:09.185386 EDT | AverageQLoss                2.6365e-05
2017-06-03 18:05:09.185618 EDT | AveragePolicySurr          -0.0893463
2017-06-03 18:05:09.185863 EDT | AverageQ                    0.0857701
2017-06-03 18:05:09.186102 EDT | AverageAbsQ                 0.0860116
2017-06-03 18:05:09.186339 EDT | AverageY                    0.0857685
2017-06-03 18:05:09.186578 EDT | AverageAbsY                 0.0857932
2017-06-03 18:05:09.186809 EDT | AverageAbsQYDiff            0.00140687
2017-06-03 18:05:09.187044 EDT | AverageAction               0.00118888
2017-06-03 18:05:09.187279 EDT | PolicyRegParamNorm         68.4966
2017-06-03 18:05:09.187509 EDT | QFunRegParamNorm           28.7016
2017-06-03 18:05:09.187738 EDT | -----------------------  -------------
2017-06-03 18:05:09.188121 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #671 | Training started
2017-06-03 18:05:28.050371 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #671 | Training finished
2017-06-03 18:05:28.050746 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #671 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 18:05:28.051010 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #671 | Collecting samples for evaluation
2017-06-03 18:05:37.728812 EDT | -----------------------  --------------
2017-06-03 18:05:37.729903 EDT | Epoch                     671
2017-06-03 18:05:37.730170 EDT | Iteration                 671
2017-06-03 18:05:37.730425 EDT | AverageReturn            1000
2017-06-03 18:05:37.730669 EDT | StdReturn                   0
2017-06-03 18:05:37.731101 EDT | MaxReturn                1000
2017-06-03 18:05:37.731350 EDT | MinReturn                1000
2017-06-03 18:05:37.731585 EDT | AverageEsReturn            26.0513
2017-06-03 18:05:37.731821 EDT | StdEsReturn                23.7357
2017-06-03 18:05:37.732055 EDT | MaxEsReturn               125
2017-06-03 18:05:37.732289 EDT | MinEsReturn                 4
2017-06-03 18:05:37.732529 EDT | AverageDiscountedReturn    99.9957
2017-06-03 18:05:37.732761 EDT | AverageQLoss                2.25434e-05
2017-06-03 18:05:37.732994 EDT | AveragePolicySurr          -0.0894412
2017-06-03 18:05:37.733229 EDT | AverageQ                    0.0856724
2017-06-03 18:05:37.733466 EDT | AverageAbsQ                 0.0858601
2017-06-03 18:05:37.733713 EDT | AverageY                    0.0856664
2017-06-03 18:05:37.733960 EDT | AverageAbsY                 0.0856837
2017-06-03 18:05:37.734205 EDT | AverageAbsQYDiff            0.00116094
2017-06-03 18:05:37.734439 EDT | AverageAction               5.43374e-05
2017-06-03 18:05:37.734673 EDT | PolicyRegParamNorm         68.5256
2017-06-03 18:05:37.734908 EDT | QFunRegParamNorm           28.6993
2017-06-03 18:05:37.735144 EDT | -----------------------  --------------
2017-06-03 18:05:37.735661 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #672 | Training started
2017-06-03 18:05:57.058305 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #672 | Training finished
2017-06-03 18:05:57.059422 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #672 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 18:05:57.059699 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #672 | Collecting samples for evaluation
2017-06-03 18:06:06.546011 EDT | -----------------------  --------------
2017-06-03 18:06:06.547228 EDT | Epoch                     672
2017-06-03 18:06:06.547498 EDT | Iteration                 672
2017-06-03 18:06:06.547733 EDT | AverageReturn            1000
2017-06-03 18:06:06.547992 EDT | StdReturn                   0
2017-06-03 18:06:06.548234 EDT | MaxReturn                1000
2017-06-03 18:06:06.548526 EDT | MinReturn                1000
2017-06-03 18:06:06.548839 EDT | AverageEsReturn            27
2017-06-03 18:06:06.549196 EDT | StdEsReturn                24.5302
2017-06-03 18:06:06.549439 EDT | MaxEsReturn               117
2017-06-03 18:06:06.549667 EDT | MinEsReturn                 3
2017-06-03 18:06:06.549929 EDT | AverageDiscountedReturn    99.9957
2017-06-03 18:06:06.550172 EDT | AverageQLoss                2.53097e-05
2017-06-03 18:06:06.550425 EDT | AveragePolicySurr          -0.0893705
2017-06-03 18:06:06.550665 EDT | AverageQ                    0.0856545
2017-06-03 18:06:06.550915 EDT | AverageAbsQ                 0.0858727
2017-06-03 18:06:06.551155 EDT | AverageY                    0.0856588
2017-06-03 18:06:06.551396 EDT | AverageAbsY                 0.0856698
2017-06-03 18:06:06.551635 EDT | AverageAbsQYDiff            0.0013596
2017-06-03 18:06:06.551885 EDT | AverageAction               0.00121204
2017-06-03 18:06:06.552135 EDT | PolicyRegParamNorm         68.511
2017-06-03 18:06:06.552377 EDT | QFunRegParamNorm           28.7048
2017-06-03 18:06:06.552616 EDT | -----------------------  --------------
2017-06-03 18:06:06.553006 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #673 | Training started
2017-06-03 18:06:25.451101 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #673 | Training finished
2017-06-03 18:06:25.452310 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #673 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 18:06:25.452576 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #673 | Collecting samples for evaluation
2017-06-03 18:06:34.380858 EDT | -----------------------  --------------
2017-06-03 18:06:34.381352 EDT | Epoch                     673
2017-06-03 18:06:34.381783 EDT | Iteration                 673
2017-06-03 18:06:34.382062 EDT | AverageReturn            1000
2017-06-03 18:06:34.382313 EDT | StdReturn                   0
2017-06-03 18:06:34.382560 EDT | MaxReturn                1000
2017-06-03 18:06:34.382821 EDT | MinReturn                1000
2017-06-03 18:06:34.383067 EDT | AverageEsReturn            24.0714
2017-06-03 18:06:34.383313 EDT | StdEsReturn                20.086
2017-06-03 18:06:34.383572 EDT | MaxEsReturn                84
2017-06-03 18:06:34.384940 EDT | MinEsReturn                 3
2017-06-03 18:06:34.385215 EDT | AverageDiscountedReturn    99.9957
2017-06-03 18:06:34.385665 EDT | AverageQLoss                2.61906e-05
2017-06-03 18:06:34.385969 EDT | AveragePolicySurr          -0.0893664
2017-06-03 18:06:34.386218 EDT | AverageQ                    0.0855959
2017-06-03 18:06:34.386465 EDT | AverageAbsQ                 0.085819
2017-06-03 18:06:34.386710 EDT | AverageY                    0.0855995
2017-06-03 18:06:34.386972 EDT | AverageAbsY                 0.0856142
2017-06-03 18:06:34.387219 EDT | AverageAbsQYDiff            0.00136902
2017-06-03 18:06:34.387462 EDT | AverageAction               0.00260445
2017-06-03 18:06:34.387719 EDT | PolicyRegParamNorm         68.5461
2017-06-03 18:06:34.387961 EDT | QFunRegParamNorm           28.7151
2017-06-03 18:06:34.388201 EDT | -----------------------  --------------
2017-06-03 18:06:34.388586 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #674 | Training started
2017-06-03 18:06:52.009871 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #674 | Training finished
2017-06-03 18:06:52.011134 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #674 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 18:06:52.011505 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #674 | Collecting samples for evaluation
2017-06-03 18:07:01.462688 EDT | -----------------------  --------------
2017-06-03 18:07:01.463773 EDT | Epoch                     674
2017-06-03 18:07:01.464045 EDT | Iteration                 674
2017-06-03 18:07:01.464288 EDT | AverageReturn            1000
2017-06-03 18:07:01.464536 EDT | StdReturn                   0
2017-06-03 18:07:01.464771 EDT | MaxReturn                1000
2017-06-03 18:07:01.465021 EDT | MinReturn                1000
2017-06-03 18:07:01.465350 EDT | AverageEsReturn            32.9333
2017-06-03 18:07:01.465739 EDT | StdEsReturn                33.138
2017-06-03 18:07:01.466067 EDT | MaxEsReturn               151
2017-06-03 18:07:01.466381 EDT | MinEsReturn                 3
2017-06-03 18:07:01.466694 EDT | AverageDiscountedReturn    99.9957
2017-06-03 18:07:01.467007 EDT | AverageQLoss                2.45498e-05
2017-06-03 18:07:01.467332 EDT | AveragePolicySurr          -0.0895427
2017-06-03 18:07:01.467648 EDT | AverageQ                    0.0857655
2017-06-03 18:07:01.467968 EDT | AverageAbsQ                 0.0859501
2017-06-03 18:07:01.468279 EDT | AverageY                    0.0857646
2017-06-03 18:07:01.468591 EDT | AverageAbsY                 0.0857697
2017-06-03 18:07:01.468900 EDT | AverageAbsQYDiff            0.00136127
2017-06-03 18:07:01.469208 EDT | AverageAction               0.181089
2017-06-03 18:07:01.469514 EDT | PolicyRegParamNorm         68.5991
2017-06-03 18:07:01.469893 EDT | QFunRegParamNorm           28.7138
2017-06-03 18:07:01.470234 EDT | -----------------------  --------------
2017-06-03 18:07:01.470740 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #675 | Training started
2017-06-03 18:07:20.020657 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #675 | Training finished
2017-06-03 18:07:20.023471 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #675 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 18:07:20.023763 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #675 | Collecting samples for evaluation
2017-06-03 18:07:30.331455 EDT | -----------------------  --------------
2017-06-03 18:07:30.333688 EDT | Epoch                     675
2017-06-03 18:07:30.333975 EDT | Iteration                 675
2017-06-03 18:07:30.334230 EDT | AverageReturn            1000
2017-06-03 18:07:30.334485 EDT | StdReturn                   0
2017-06-03 18:07:30.334742 EDT | MaxReturn                1000
2017-06-03 18:07:30.334988 EDT | MinReturn                1000
2017-06-03 18:07:30.335233 EDT | AverageEsReturn            31.8333
2017-06-03 18:07:30.335478 EDT | StdEsReturn                22.9784
2017-06-03 18:07:30.335722 EDT | MaxEsReturn                74
2017-06-03 18:07:30.335971 EDT | MinEsReturn                 3
2017-06-03 18:07:30.336229 EDT | AverageDiscountedReturn    99.9957
2017-06-03 18:07:30.336471 EDT | AverageQLoss                2.63921e-05
2017-06-03 18:07:30.336719 EDT | AveragePolicySurr          -0.0895436
2017-06-03 18:07:30.336962 EDT | AverageQ                    0.085824
2017-06-03 18:07:30.337205 EDT | AverageAbsQ                 0.0859944
2017-06-03 18:07:30.337452 EDT | AverageY                    0.0858208
2017-06-03 18:07:30.337708 EDT | AverageAbsY                 0.0858264
2017-06-03 18:07:30.337955 EDT | AverageAbsQYDiff            0.00130372
2017-06-03 18:07:30.338202 EDT | AverageAction               0.0708796
2017-06-03 18:07:30.338445 EDT | PolicyRegParamNorm         68.6537
2017-06-03 18:07:30.338688 EDT | QFunRegParamNorm           28.7301
2017-06-03 18:07:30.338936 EDT | -----------------------  --------------
2017-06-03 18:07:30.339345 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #676 | Training started
2017-06-03 18:07:49.686393 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #676 | Training finished
2017-06-03 18:07:49.687374 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #676 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 18:07:49.687743 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #676 | Collecting samples for evaluation
2017-06-03 18:08:00.225481 EDT | -----------------------  -------------
2017-06-03 18:08:00.226400 EDT | Epoch                     676
2017-06-03 18:08:00.226682 EDT | Iteration                 676
2017-06-03 18:08:00.226930 EDT | AverageReturn            1000
2017-06-03 18:08:00.227167 EDT | StdReturn                   0
2017-06-03 18:08:00.227412 EDT | MaxReturn                1000
2017-06-03 18:08:00.227667 EDT | MinReturn                1000
2017-06-03 18:08:00.227901 EDT | AverageEsReturn            33.9032
2017-06-03 18:08:00.228144 EDT | StdEsReturn                31.2909
2017-06-03 18:08:00.228378 EDT | MaxEsReturn               145
2017-06-03 18:08:00.228632 EDT | MinEsReturn                 3
2017-06-03 18:08:00.228902 EDT | AverageDiscountedReturn    99.9957
2017-06-03 18:08:00.229137 EDT | AverageQLoss                2.3324e-05
2017-06-03 18:08:00.229372 EDT | AveragePolicySurr          -0.0895463
2017-06-03 18:08:00.229617 EDT | AverageQ                    0.0857987
2017-06-03 18:08:00.229882 EDT | AverageAbsQ                 0.085996
2017-06-03 18:08:00.230137 EDT | AverageY                    0.0857976
2017-06-03 18:08:00.230402 EDT | AverageAbsY                 0.0858062
2017-06-03 18:08:00.230636 EDT | AverageAbsQYDiff            0.00130943
2017-06-03 18:08:00.230896 EDT | AverageAction               0.0143161
2017-06-03 18:08:00.231129 EDT | PolicyRegParamNorm         68.6819
2017-06-03 18:08:00.231376 EDT | QFunRegParamNorm           28.7382
2017-06-03 18:08:00.231606 EDT | -----------------------  -------------
2017-06-03 18:08:00.232016 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #677 | Training started
2017-06-03 18:08:19.078981 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #677 | Training finished
2017-06-03 18:08:19.080168 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #677 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 18:08:19.081742 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #677 | Collecting samples for evaluation
2017-06-03 18:08:29.241449 EDT | -----------------------  --------------
2017-06-03 18:08:29.242575 EDT | Epoch                     677
2017-06-03 18:08:29.242878 EDT | Iteration                 677
2017-06-03 18:08:29.243137 EDT | AverageReturn            1000
2017-06-03 18:08:29.243438 EDT | StdReturn                   0
2017-06-03 18:08:29.243732 EDT | MaxReturn                1000
2017-06-03 18:08:29.243989 EDT | MinReturn                1000
2017-06-03 18:08:29.244238 EDT | AverageEsReturn            36.7778
2017-06-03 18:08:29.244489 EDT | StdEsReturn                20.3767
2017-06-03 18:08:29.244737 EDT | MaxEsReturn                97
2017-06-03 18:08:29.245013 EDT | MinEsReturn                 8
2017-06-03 18:08:29.245253 EDT | AverageDiscountedReturn    99.9957
2017-06-03 18:08:29.245492 EDT | AverageQLoss                2.73081e-05
2017-06-03 18:08:29.245751 EDT | AveragePolicySurr          -0.0894443
2017-06-03 18:08:29.246024 EDT | AverageQ                    0.085768
2017-06-03 18:08:29.246294 EDT | AverageAbsQ                 0.0859518
2017-06-03 18:08:29.246545 EDT | AverageY                    0.0857734
2017-06-03 18:08:29.246809 EDT | AverageAbsY                 0.0857861
2017-06-03 18:08:29.247058 EDT | AverageAbsQYDiff            0.00133046
2017-06-03 18:08:29.247327 EDT | AverageAction               6.14301e-05
2017-06-03 18:08:29.247598 EDT | PolicyRegParamNorm         68.6606
2017-06-03 18:08:29.247870 EDT | QFunRegParamNorm           28.7458
2017-06-03 18:08:29.248121 EDT | -----------------------  --------------
2017-06-03 18:08:29.248704 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #678 | Training started
2017-06-03 18:08:48.531274 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #678 | Training finished
2017-06-03 18:08:48.532279 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #678 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 18:08:48.532702 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #678 | Collecting samples for evaluation
2017-06-03 18:08:58.061616 EDT | -----------------------  --------------
2017-06-03 18:08:58.062867 EDT | Epoch                     678
2017-06-03 18:08:58.063122 EDT | Iteration                 678
2017-06-03 18:08:58.063354 EDT | AverageReturn            1000
2017-06-03 18:08:58.063590 EDT | StdReturn                   0
2017-06-03 18:08:58.063827 EDT | MaxReturn                1000
2017-06-03 18:08:58.064053 EDT | MinReturn                1000
2017-06-03 18:08:58.064277 EDT | AverageEsReturn            36.0714
2017-06-03 18:08:58.064501 EDT | StdEsReturn                31.008
2017-06-03 18:08:58.064726 EDT | MaxEsReturn               132
2017-06-03 18:08:58.064960 EDT | MinEsReturn                 9
2017-06-03 18:08:58.065184 EDT | AverageDiscountedReturn    99.9957
2017-06-03 18:08:58.065407 EDT | AverageQLoss                2.28036e-05
2017-06-03 18:08:58.065633 EDT | AveragePolicySurr          -0.0893845
2017-06-03 18:08:58.065905 EDT | AverageQ                    0.0856359
2017-06-03 18:08:58.066145 EDT | AverageAbsQ                 0.085853
2017-06-03 18:08:58.066384 EDT | AverageY                    0.0856294
2017-06-03 18:08:58.066624 EDT | AverageAbsY                 0.0856406
2017-06-03 18:08:58.066861 EDT | AverageAbsQYDiff            0.00127204
2017-06-03 18:08:58.067099 EDT | AverageAction               0.000521736
2017-06-03 18:08:58.067368 EDT | PolicyRegParamNorm         68.6838
2017-06-03 18:08:58.067610 EDT | QFunRegParamNorm           28.7514
2017-06-03 18:08:58.067847 EDT | -----------------------  --------------
2017-06-03 18:08:58.068248 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #679 | Training started
2017-06-03 18:09:15.519694 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #679 | Training finished
2017-06-03 18:09:15.520785 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #679 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 18:09:15.521196 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #679 | Collecting samples for evaluation
2017-06-03 18:09:24.334242 EDT | -----------------------  --------------
2017-06-03 18:09:24.335071 EDT | Epoch                     679
2017-06-03 18:09:24.335346 EDT | Iteration                 679
2017-06-03 18:09:24.335587 EDT | AverageReturn            1000
2017-06-03 18:09:24.335823 EDT | StdReturn                   0
2017-06-03 18:09:24.336054 EDT | MaxReturn                1000
2017-06-03 18:09:24.336292 EDT | MinReturn                1000
2017-06-03 18:09:24.336531 EDT | AverageEsReturn            58.7059
2017-06-03 18:09:24.336764 EDT | StdEsReturn                47.337
2017-06-03 18:09:24.337004 EDT | MaxEsReturn               193
2017-06-03 18:09:24.337241 EDT | MinEsReturn                 7
2017-06-03 18:09:24.337472 EDT | AverageDiscountedReturn    99.9957
2017-06-03 18:09:24.337728 EDT | AverageQLoss                2.18759e-05
2017-06-03 18:09:24.337967 EDT | AveragePolicySurr          -0.0894635
2017-06-03 18:09:24.338206 EDT | AverageQ                    0.0858857
2017-06-03 18:09:24.338437 EDT | AverageAbsQ                 0.0861125
2017-06-03 18:09:24.338667 EDT | AverageY                    0.0858806
2017-06-03 18:09:24.338898 EDT | AverageAbsY                 0.0858917
2017-06-03 18:09:24.339127 EDT | AverageAbsQYDiff            0.00124187
2017-06-03 18:09:24.339358 EDT | AverageAction               8.73457e-05
2017-06-03 18:09:24.339587 EDT | PolicyRegParamNorm         68.7355
2017-06-03 18:09:24.339814 EDT | QFunRegParamNorm           28.7492
2017-06-03 18:09:24.340044 EDT | -----------------------  --------------
2017-06-03 18:09:24.340521 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #680 | Training started
2017-06-03 18:09:42.576292 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #680 | Training finished
2017-06-03 18:09:42.577153 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #680 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 18:09:42.577562 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #680 | Collecting samples for evaluation
2017-06-03 18:09:52.117377 EDT | -----------------------  --------------
2017-06-03 18:09:52.118312 EDT | Epoch                     680
2017-06-03 18:09:52.118592 EDT | Iteration                 680
2017-06-03 18:09:52.118841 EDT | AverageReturn            1000
2017-06-03 18:09:52.119113 EDT | StdReturn                   0
2017-06-03 18:09:52.119360 EDT | MaxReturn                1000
2017-06-03 18:09:52.119626 EDT | MinReturn                1000
2017-06-03 18:09:52.119905 EDT | AverageEsReturn            43.2381
2017-06-03 18:09:52.120168 EDT | StdEsReturn                39.5413
2017-06-03 18:09:52.120447 EDT | MaxEsReturn               170
2017-06-03 18:09:52.120719 EDT | MinEsReturn                 3
2017-06-03 18:09:52.120984 EDT | AverageDiscountedReturn    99.9957
2017-06-03 18:09:52.121223 EDT | AverageQLoss                3.18162e-05
2017-06-03 18:09:52.121495 EDT | AveragePolicySurr          -0.0894978
2017-06-03 18:09:52.121768 EDT | AverageQ                    0.0857501
2017-06-03 18:09:52.122023 EDT | AverageAbsQ                 0.0859851
2017-06-03 18:09:52.122284 EDT | AverageY                    0.0857573
2017-06-03 18:09:52.122556 EDT | AverageAbsY                 0.0857711
2017-06-03 18:09:52.122832 EDT | AverageAbsQYDiff            0.00141786
2017-06-03 18:09:52.123118 EDT | AverageAction               4.14969e-05
2017-06-03 18:09:52.123391 EDT | PolicyRegParamNorm         68.7431
2017-06-03 18:09:52.123640 EDT | QFunRegParamNorm           28.7504
2017-06-03 18:09:52.123885 EDT | -----------------------  --------------
2017-06-03 18:09:52.124314 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #681 | Training started
2017-06-03 18:10:10.887366 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #681 | Training finished
2017-06-03 18:10:10.888211 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #681 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 18:10:10.888499 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #681 | Collecting samples for evaluation
2017-06-03 18:10:20.205002 EDT | -----------------------  --------------
2017-06-03 18:10:20.205876 EDT | Epoch                     681
2017-06-03 18:10:20.206150 EDT | Iteration                 681
2017-06-03 18:10:20.206403 EDT | AverageReturn            1000
2017-06-03 18:10:20.206661 EDT | StdReturn                   0
2017-06-03 18:10:20.206906 EDT | MaxReturn                1000
2017-06-03 18:10:20.207150 EDT | MinReturn                1000
2017-06-03 18:10:20.207393 EDT | AverageEsReturn            49.4545
2017-06-03 18:10:20.207681 EDT | StdEsReturn                37.8054
2017-06-03 18:10:20.207923 EDT | MaxEsReturn               154
2017-06-03 18:10:20.208166 EDT | MinEsReturn                 8
2017-06-03 18:10:20.208408 EDT | AverageDiscountedReturn    99.9957
2017-06-03 18:10:20.208650 EDT | AverageQLoss                2.00288e-05
2017-06-03 18:10:20.208902 EDT | AveragePolicySurr          -0.0895318
2017-06-03 18:10:20.209143 EDT | AverageQ                    0.0859805
2017-06-03 18:10:20.209385 EDT | AverageAbsQ                 0.0861474
2017-06-03 18:10:20.209626 EDT | AverageY                    0.0859813
2017-06-03 18:10:20.209878 EDT | AverageAbsY                 0.0859908
2017-06-03 18:10:20.210120 EDT | AverageAbsQYDiff            0.00116889
2017-06-03 18:10:20.210360 EDT | AverageAction               0.00501755
2017-06-03 18:10:20.210600 EDT | PolicyRegParamNorm         68.7449
2017-06-03 18:10:20.210840 EDT | QFunRegParamNorm           28.7503
2017-06-03 18:10:20.211079 EDT | -----------------------  --------------
2017-06-03 18:10:20.211432 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #682 | Training started
2017-06-03 18:10:39.250139 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #682 | Training finished
2017-06-03 18:10:39.251850 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #682 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 18:10:39.252148 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #682 | Collecting samples for evaluation
2017-06-03 18:10:50.163020 EDT | -----------------------  -------------
2017-06-03 18:10:50.163848 EDT | Epoch                     682
2017-06-03 18:10:50.164108 EDT | Iteration                 682
2017-06-03 18:10:50.164357 EDT | AverageReturn            1000
2017-06-03 18:10:50.164623 EDT | StdReturn                   0
2017-06-03 18:10:50.165009 EDT | MaxReturn                1000
2017-06-03 18:10:50.165266 EDT | MinReturn                1000
2017-06-03 18:10:50.165553 EDT | AverageEsReturn            31.5806
2017-06-03 18:10:50.165811 EDT | StdEsReturn                24.8476
2017-06-03 18:10:50.166048 EDT | MaxEsReturn               115
2017-06-03 18:10:50.166290 EDT | MinEsReturn                 4
2017-06-03 18:10:50.166561 EDT | AverageDiscountedReturn    99.9957
2017-06-03 18:10:50.166839 EDT | AverageQLoss                2.3647e-05
2017-06-03 18:10:50.167073 EDT | AveragePolicySurr          -0.0893673
2017-06-03 18:10:50.167311 EDT | AverageQ                    0.085825
2017-06-03 18:10:50.167545 EDT | AverageAbsQ                 0.0860438
2017-06-03 18:10:50.167774 EDT | AverageY                    0.0858243
2017-06-03 18:10:50.168014 EDT | AverageAbsY                 0.0858427
2017-06-03 18:10:50.168243 EDT | AverageAbsQYDiff            0.0012788
2017-06-03 18:10:50.168471 EDT | AverageAction               0.00298196
2017-06-03 18:10:50.168700 EDT | PolicyRegParamNorm         68.7984
2017-06-03 18:10:50.168928 EDT | QFunRegParamNorm           28.772
2017-06-03 18:10:50.169193 EDT | -----------------------  -------------
2017-06-03 18:10:50.169580 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #683 | Training started
2017-06-03 18:11:09.072456 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #683 | Training finished
2017-06-03 18:11:09.073340 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #683 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 18:11:09.073718 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #683 | Collecting samples for evaluation
2017-06-03 18:11:18.286643 EDT | -----------------------  --------------
2017-06-03 18:11:18.287526 EDT | Epoch                     683
2017-06-03 18:11:18.287822 EDT | Iteration                 683
2017-06-03 18:11:18.288083 EDT | AverageReturn            1000
2017-06-03 18:11:18.288351 EDT | StdReturn                   0
2017-06-03 18:11:18.288625 EDT | MaxReturn                1000
2017-06-03 18:11:18.288866 EDT | MinReturn                1000
2017-06-03 18:11:18.289413 EDT | AverageEsReturn            39.76
2017-06-03 18:11:18.289682 EDT | StdEsReturn                42.6533
2017-06-03 18:11:18.289939 EDT | MaxEsReturn               218
2017-06-03 18:11:18.290205 EDT | MinEsReturn                 3
2017-06-03 18:11:18.290465 EDT | AverageDiscountedReturn    99.9957
2017-06-03 18:11:18.290743 EDT | AverageQLoss                2.44766e-05
2017-06-03 18:11:18.290988 EDT | AveragePolicySurr          -0.089478
2017-06-03 18:11:18.291345 EDT | AverageQ                    0.0858886
2017-06-03 18:11:18.291706 EDT | AverageAbsQ                 0.0861149
2017-06-03 18:11:18.292026 EDT | AverageY                    0.0858919
2017-06-03 18:11:18.292343 EDT | AverageAbsY                 0.0859126
2017-06-03 18:11:18.292660 EDT | AverageAbsQYDiff            0.00131681
2017-06-03 18:11:18.292975 EDT | AverageAction               0.725282
2017-06-03 18:11:18.293286 EDT | PolicyRegParamNorm         68.8634
2017-06-03 18:11:18.293593 EDT | QFunRegParamNorm           28.778
2017-06-03 18:11:18.293921 EDT | -----------------------  --------------
2017-06-03 18:11:18.294396 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #684 | Training started
2017-06-03 18:11:37.409894 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #684 | Training finished
2017-06-03 18:11:37.410834 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #684 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 18:11:37.411145 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #684 | Collecting samples for evaluation
2017-06-03 18:11:47.020868 EDT | -----------------------  --------------
2017-06-03 18:11:47.021704 EDT | Epoch                     684
2017-06-03 18:11:47.021977 EDT | Iteration                 684
2017-06-03 18:11:47.022259 EDT | AverageReturn            1000
2017-06-03 18:11:47.022497 EDT | StdReturn                   0
2017-06-03 18:11:47.022735 EDT | MaxReturn                1000
2017-06-03 18:11:47.022970 EDT | MinReturn                1000
2017-06-03 18:11:47.023205 EDT | AverageEsReturn            46.4091
2017-06-03 18:11:47.023453 EDT | StdEsReturn                39.9871
2017-06-03 18:11:47.023687 EDT | MaxEsReturn               165
2017-06-03 18:11:47.023920 EDT | MinEsReturn                 3
2017-06-03 18:11:47.024153 EDT | AverageDiscountedReturn    99.9957
2017-06-03 18:11:47.024385 EDT | AverageQLoss                2.64967e-05
2017-06-03 18:11:47.024617 EDT | AveragePolicySurr          -0.089454
2017-06-03 18:11:47.024869 EDT | AverageQ                    0.0857819
2017-06-03 18:11:47.025103 EDT | AverageAbsQ                 0.0860162
2017-06-03 18:11:47.025335 EDT | AverageY                    0.0857791
2017-06-03 18:11:47.025570 EDT | AverageAbsY                 0.0857979
2017-06-03 18:11:47.025814 EDT | AverageAbsQYDiff            0.00136669
2017-06-03 18:11:47.026044 EDT | AverageAction               0.658127
2017-06-03 18:11:47.026276 EDT | PolicyRegParamNorm         68.8672
2017-06-03 18:11:47.026517 EDT | QFunRegParamNorm           28.7759
2017-06-03 18:11:47.026751 EDT | -----------------------  --------------
2017-06-03 18:11:47.027164 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #685 | Training started
2017-06-03 18:12:05.938094 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #685 | Training finished
2017-06-03 18:12:05.938975 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #685 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 18:12:05.939251 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #685 | Collecting samples for evaluation
2017-06-03 18:12:15.172214 EDT | -----------------------  --------------
2017-06-03 18:12:15.173151 EDT | Epoch                     685
2017-06-03 18:12:15.173451 EDT | Iteration                 685
2017-06-03 18:12:15.173723 EDT | AverageReturn            1000
2017-06-03 18:12:15.173981 EDT | StdReturn                   0
2017-06-03 18:12:15.174237 EDT | MaxReturn                1000
2017-06-03 18:12:15.174481 EDT | MinReturn                1000
2017-06-03 18:12:15.174806 EDT | AverageEsReturn            41.3478
2017-06-03 18:12:15.175811 EDT | StdEsReturn                50.0405
2017-06-03 18:12:15.177520 EDT | MaxEsReturn               194
2017-06-03 18:12:15.177833 EDT | MinEsReturn                 3
2017-06-03 18:12:15.178089 EDT | AverageDiscountedReturn    99.9957
2017-06-03 18:12:15.178544 EDT | AverageQLoss                2.26683e-05
2017-06-03 18:12:15.178809 EDT | AveragePolicySurr          -0.0893866
2017-06-03 18:12:15.179049 EDT | AverageQ                    0.0855579
2017-06-03 18:12:15.179283 EDT | AverageAbsQ                 0.085772
2017-06-03 18:12:15.179545 EDT | AverageY                    0.0855559
2017-06-03 18:12:15.179823 EDT | AverageAbsY                 0.0855827
2017-06-03 18:12:15.180092 EDT | AverageAbsQYDiff            0.00126662
2017-06-03 18:12:15.180329 EDT | AverageAction               0.485294
2017-06-03 18:12:15.180590 EDT | PolicyRegParamNorm         68.8683
2017-06-03 18:12:15.180852 EDT | QFunRegParamNorm           28.7991
2017-06-03 18:12:15.181103 EDT | -----------------------  --------------
2017-06-03 18:12:15.181471 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #686 | Training started
2017-06-03 18:12:33.967754 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #686 | Training finished
2017-06-03 18:12:33.968707 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #686 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 18:12:33.968985 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #686 | Collecting samples for evaluation
2017-06-03 18:12:43.656740 EDT | -----------------------  --------------
2017-06-03 18:12:43.657611 EDT | Epoch                     686
2017-06-03 18:12:43.657893 EDT | Iteration                 686
2017-06-03 18:12:43.658131 EDT | AverageReturn            1000
2017-06-03 18:12:43.658364 EDT | StdReturn                   0
2017-06-03 18:12:43.658611 EDT | MaxReturn                1000
2017-06-03 18:12:43.658871 EDT | MinReturn                1000
2017-06-03 18:12:43.659125 EDT | AverageEsReturn            36.963
2017-06-03 18:12:43.659373 EDT | StdEsReturn                34.3786
2017-06-03 18:12:43.659602 EDT | MaxEsReturn               166
2017-06-03 18:12:43.659840 EDT | MinEsReturn                 5
2017-06-03 18:12:43.660067 EDT | AverageDiscountedReturn    99.9957
2017-06-03 18:12:43.660296 EDT | AverageQLoss                2.77546e-05
2017-06-03 18:12:43.660523 EDT | AveragePolicySurr          -0.0893291
2017-06-03 18:12:43.660749 EDT | AverageQ                    0.0856548
2017-06-03 18:12:43.660978 EDT | AverageAbsQ                 0.0859362
2017-06-03 18:12:43.661204 EDT | AverageY                    0.0856573
2017-06-03 18:12:43.661430 EDT | AverageAbsY                 0.0856904
2017-06-03 18:12:43.661657 EDT | AverageAbsQYDiff            0.00150872
2017-06-03 18:12:43.661919 EDT | AverageAction               0.0242298
2017-06-03 18:12:43.662160 EDT | PolicyRegParamNorm         68.93
2017-06-03 18:12:43.662402 EDT | QFunRegParamNorm           28.7917
2017-06-03 18:12:43.662645 EDT | -----------------------  --------------
2017-06-03 18:12:43.663041 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #687 | Training started
2017-06-03 18:13:02.343885 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #687 | Training finished
2017-06-03 18:13:02.344812 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #687 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 18:13:02.345090 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #687 | Collecting samples for evaluation
2017-06-03 18:13:13.363929 EDT | -----------------------  -------------
2017-06-03 18:13:13.364817 EDT | Epoch                     687
2017-06-03 18:13:13.365089 EDT | Iteration                 687
2017-06-03 18:13:13.365344 EDT | AverageReturn            1000
2017-06-03 18:13:13.365599 EDT | StdReturn                   0
2017-06-03 18:13:13.365850 EDT | MaxReturn                1000
2017-06-03 18:13:13.366088 EDT | MinReturn                1000
2017-06-03 18:13:13.366325 EDT | AverageEsReturn            36.8276
2017-06-03 18:13:13.366562 EDT | StdEsReturn                27.4855
2017-06-03 18:13:13.366797 EDT | MaxEsReturn               105
2017-06-03 18:13:13.367032 EDT | MinEsReturn                 6
2017-06-03 18:13:13.367265 EDT | AverageDiscountedReturn    99.9957
2017-06-03 18:13:13.367529 EDT | AverageQLoss                2.4338e-05
2017-06-03 18:13:13.367767 EDT | AveragePolicySurr          -0.089561
2017-06-03 18:13:13.368030 EDT | AverageQ                    0.0858772
2017-06-03 18:13:13.368277 EDT | AverageAbsQ                 0.086074
2017-06-03 18:13:13.368535 EDT | AverageY                    0.0858811
2017-06-03 18:13:13.368781 EDT | AverageAbsY                 0.0859052
2017-06-03 18:13:13.369019 EDT | AverageAbsQYDiff            0.00134266
2017-06-03 18:13:13.369252 EDT | AverageAction               0.131164
2017-06-03 18:13:13.369495 EDT | PolicyRegParamNorm         68.9031
2017-06-03 18:13:13.369767 EDT | QFunRegParamNorm           28.8083
2017-06-03 18:13:13.370003 EDT | -----------------------  -------------
2017-06-03 18:13:13.370412 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #688 | Training started
2017-06-03 18:13:32.239645 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #688 | Training finished
2017-06-03 18:13:32.240611 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #688 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 18:13:32.240909 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #688 | Collecting samples for evaluation
2017-06-03 18:13:43.612855 EDT | -----------------------  --------------
2017-06-03 18:13:43.617416 EDT | Epoch                     688
2017-06-03 18:13:43.617750 EDT | Iteration                 688
2017-06-03 18:13:43.618006 EDT | AverageReturn            1000
2017-06-03 18:13:43.618239 EDT | StdReturn                   0
2017-06-03 18:13:43.618478 EDT | MaxReturn                1000
2017-06-03 18:13:43.618706 EDT | MinReturn                1000
2017-06-03 18:13:43.618933 EDT | AverageEsReturn            51.1053
2017-06-03 18:13:43.619160 EDT | StdEsReturn                42.8877
2017-06-03 18:13:43.619393 EDT | MaxEsReturn               161
2017-06-03 18:13:43.619616 EDT | MinEsReturn                 2
2017-06-03 18:13:43.619838 EDT | AverageDiscountedReturn    99.9957
2017-06-03 18:13:43.620060 EDT | AverageQLoss                2.37846e-05
2017-06-03 18:13:43.620291 EDT | AveragePolicySurr          -0.0893964
2017-06-03 18:13:43.620512 EDT | AverageQ                    0.0857656
2017-06-03 18:13:43.620734 EDT | AverageAbsQ                 0.0859724
2017-06-03 18:13:43.620956 EDT | AverageY                    0.085762
2017-06-03 18:13:43.621178 EDT | AverageAbsY                 0.0857805
2017-06-03 18:13:43.621402 EDT | AverageAbsQYDiff            0.00127855
2017-06-03 18:13:43.621629 EDT | AverageAction               0.0208184
2017-06-03 18:13:43.622528 EDT | PolicyRegParamNorm         68.9442
2017-06-03 18:13:43.622840 EDT | QFunRegParamNorm           28.8299
2017-06-03 18:13:43.623148 EDT | -----------------------  --------------
2017-06-03 18:13:43.623615 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #689 | Training started
2017-06-03 18:14:01.741185 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #689 | Training finished
2017-06-03 18:14:01.742442 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #689 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 18:14:01.742714 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #689 | Collecting samples for evaluation
2017-06-03 18:14:09.799695 EDT | -----------------------  --------------
2017-06-03 18:14:09.800043 EDT | Epoch                     689
2017-06-03 18:14:09.800318 EDT | Iteration                 689
2017-06-03 18:14:09.800561 EDT | AverageReturn            1000
2017-06-03 18:14:09.800799 EDT | StdReturn                   0
2017-06-03 18:14:09.801033 EDT | MaxReturn                1000
2017-06-03 18:14:09.801276 EDT | MinReturn                1000
2017-06-03 18:14:09.801537 EDT | AverageEsReturn            46.7368
2017-06-03 18:14:09.801782 EDT | StdEsReturn                38.0039
2017-06-03 18:14:09.802019 EDT | MaxEsReturn               134
2017-06-03 18:14:09.802254 EDT | MinEsReturn                 4
2017-06-03 18:14:09.802488 EDT | AverageDiscountedReturn    99.9957
2017-06-03 18:14:09.802731 EDT | AverageQLoss                2.54808e-05
2017-06-03 18:14:09.802964 EDT | AveragePolicySurr          -0.0894705
2017-06-03 18:14:09.803201 EDT | AverageQ                    0.0856579
2017-06-03 18:14:09.803433 EDT | AverageAbsQ                 0.085903
2017-06-03 18:14:09.803665 EDT | AverageY                    0.0856567
2017-06-03 18:14:09.803899 EDT | AverageAbsY                 0.0856752
2017-06-03 18:14:09.804131 EDT | AverageAbsQYDiff            0.00138245
2017-06-03 18:14:09.804367 EDT | AverageAction               0.140336
2017-06-03 18:14:09.804599 EDT | PolicyRegParamNorm         68.9735
2017-06-03 18:14:09.804830 EDT | QFunRegParamNorm           28.8409
2017-06-03 18:14:09.805067 EDT | -----------------------  --------------
2017-06-03 18:14:09.805421 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #690 | Training started
2017-06-03 18:14:27.410086 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #690 | Training finished
2017-06-03 18:14:27.413663 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #690 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 18:14:27.414047 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #690 | Collecting samples for evaluation
2017-06-03 18:14:36.746718 EDT | -----------------------  -------------
2017-06-03 18:14:36.747546 EDT | Epoch                     690
2017-06-03 18:14:36.747803 EDT | Iteration                 690
2017-06-03 18:14:36.748054 EDT | AverageReturn            1000
2017-06-03 18:14:36.748292 EDT | StdReturn                   0
2017-06-03 18:14:36.748538 EDT | MaxReturn                1000
2017-06-03 18:14:36.748799 EDT | MinReturn                1000
2017-06-03 18:14:36.749032 EDT | AverageEsReturn            49.6364
2017-06-03 18:14:36.749265 EDT | StdEsReturn                50.211
2017-06-03 18:14:36.749501 EDT | MaxEsReturn               172
2017-06-03 18:14:36.749752 EDT | MinEsReturn                 3
2017-06-03 18:14:36.749986 EDT | AverageDiscountedReturn    99.9957
2017-06-03 18:14:36.750241 EDT | AverageQLoss                2.9498e-05
2017-06-03 18:14:36.750474 EDT | AveragePolicySurr          -0.0893011
2017-06-03 18:14:36.750705 EDT | AverageQ                    0.0854543
2017-06-03 18:14:36.750935 EDT | AverageAbsQ                 0.0857209
2017-06-03 18:14:36.751186 EDT | AverageY                    0.0854597
2017-06-03 18:14:36.751417 EDT | AverageAbsY                 0.0854842
2017-06-03 18:14:36.751649 EDT | AverageAbsQYDiff            0.00153139
2017-06-03 18:14:36.751879 EDT | AverageAction               0.631037
2017-06-03 18:14:36.752122 EDT | PolicyRegParamNorm         68.951
2017-06-03 18:14:36.752352 EDT | QFunRegParamNorm           28.8361
2017-06-03 18:14:36.752582 EDT | -----------------------  -------------
2017-06-03 18:14:36.752953 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #691 | Training started
2017-06-03 18:14:54.347762 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #691 | Training finished
2017-06-03 18:14:54.348487 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #691 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 18:14:54.348755 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #691 | Collecting samples for evaluation
2017-06-03 18:15:04.568782 EDT | -----------------------  --------------
2017-06-03 18:15:04.569995 EDT | Epoch                     691
2017-06-03 18:15:04.570561 EDT | Iteration                 691
2017-06-03 18:15:04.571037 EDT | AverageReturn            1000
2017-06-03 18:15:04.571518 EDT | StdReturn                   0
2017-06-03 18:15:04.571894 EDT | MaxReturn                1000
2017-06-03 18:15:04.572295 EDT | MinReturn                1000
2017-06-03 18:15:04.572760 EDT | AverageEsReturn            51.8333
2017-06-03 18:15:04.573237 EDT | StdEsReturn                28.9736
2017-06-03 18:15:04.573710 EDT | MaxEsReturn               102
2017-06-03 18:15:04.574123 EDT | MinEsReturn                 3
2017-06-03 18:15:04.574569 EDT | AverageDiscountedReturn    99.9957
2017-06-03 18:15:04.574892 EDT | AverageQLoss                2.48597e-05
2017-06-03 18:15:04.575202 EDT | AveragePolicySurr          -0.0892748
2017-06-03 18:15:04.575515 EDT | AverageQ                    0.0856622
2017-06-03 18:15:04.575833 EDT | AverageAbsQ                 0.0859132
2017-06-03 18:15:04.576137 EDT | AverageY                    0.0856578
2017-06-03 18:15:04.576439 EDT | AverageAbsY                 0.0856795
2017-06-03 18:15:04.576739 EDT | AverageAbsQYDiff            0.00141093
2017-06-03 18:15:04.577082 EDT | AverageAction               0.521879
2017-06-03 18:15:04.577389 EDT | PolicyRegParamNorm         68.9899
2017-06-03 18:15:04.577793 EDT | QFunRegParamNorm           28.8462
2017-06-03 18:15:04.578237 EDT | -----------------------  --------------
2017-06-03 18:15:04.578760 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #692 | Training started
2017-06-03 18:15:24.450029 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #692 | Training finished
2017-06-03 18:15:24.451440 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #692 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 18:15:24.451729 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #692 | Collecting samples for evaluation
2017-06-03 18:15:34.762204 EDT | -----------------------  --------------
2017-06-03 18:15:34.763038 EDT | Epoch                     692
2017-06-03 18:15:34.763311 EDT | Iteration                 692
2017-06-03 18:15:34.763578 EDT | AverageReturn            1000
2017-06-03 18:15:34.763833 EDT | StdReturn                   0
2017-06-03 18:15:34.764076 EDT | MaxReturn                1000
2017-06-03 18:15:34.764313 EDT | MinReturn                1000
2017-06-03 18:15:34.764575 EDT | AverageEsReturn            56.8947
2017-06-03 18:15:34.764859 EDT | StdEsReturn                51.2218
2017-06-03 18:15:34.765210 EDT | MaxEsReturn               229
2017-06-03 18:15:34.765514 EDT | MinEsReturn                 6
2017-06-03 18:15:34.765809 EDT | AverageDiscountedReturn    99.9957
2017-06-03 18:15:34.766066 EDT | AverageQLoss                2.50405e-05
2017-06-03 18:15:34.766325 EDT | AveragePolicySurr          -0.0893518
2017-06-03 18:15:34.766575 EDT | AverageQ                    0.0856295
2017-06-03 18:15:34.766822 EDT | AverageAbsQ                 0.0858506
2017-06-03 18:15:34.767069 EDT | AverageY                    0.0856262
2017-06-03 18:15:34.767314 EDT | AverageAbsY                 0.0856589
2017-06-03 18:15:34.767557 EDT | AverageAbsQYDiff            0.00130166
2017-06-03 18:15:34.767800 EDT | AverageAction               0.0950698
2017-06-03 18:15:34.768042 EDT | PolicyRegParamNorm         69.0014
2017-06-03 18:15:34.768287 EDT | QFunRegParamNorm           28.8562
2017-06-03 18:15:34.768530 EDT | -----------------------  --------------
2017-06-03 18:15:34.768951 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #693 | Training started
2017-06-03 18:15:54.573947 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #693 | Training finished
2017-06-03 18:15:54.574607 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #693 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 18:15:54.574900 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #693 | Collecting samples for evaluation
2017-06-03 18:16:04.212289 EDT | -----------------------  --------------
2017-06-03 18:16:04.212660 EDT | Epoch                     693
2017-06-03 18:16:04.212909 EDT | Iteration                 693
2017-06-03 18:16:04.213149 EDT | AverageReturn            1000
2017-06-03 18:16:04.213386 EDT | StdReturn                   0
2017-06-03 18:16:04.213620 EDT | MaxReturn                1000
2017-06-03 18:16:04.213877 EDT | MinReturn                1000
2017-06-03 18:16:04.214111 EDT | AverageEsReturn            67.8667
2017-06-03 18:16:04.214344 EDT | StdEsReturn                50.9966
2017-06-03 18:16:04.214575 EDT | MaxEsReturn               185
2017-06-03 18:16:04.214807 EDT | MinEsReturn                 7
2017-06-03 18:16:04.215039 EDT | AverageDiscountedReturn    99.9957
2017-06-03 18:16:04.215284 EDT | AverageQLoss                2.72018e-05
2017-06-03 18:16:04.215550 EDT | AveragePolicySurr          -0.0892872
2017-06-03 18:16:04.215806 EDT | AverageQ                    0.0854575
2017-06-03 18:16:04.216070 EDT | AverageAbsQ                 0.085699
2017-06-03 18:16:04.216307 EDT | AverageY                    0.0854608
2017-06-03 18:16:04.216541 EDT | AverageAbsY                 0.0854841
2017-06-03 18:16:04.216774 EDT | AverageAbsQYDiff            0.00138748
2017-06-03 18:16:04.217006 EDT | AverageAction               0.271008
2017-06-03 18:16:04.217253 EDT | PolicyRegParamNorm         69.0698
2017-06-03 18:16:04.217484 EDT | QFunRegParamNorm           28.8623
2017-06-03 18:16:04.217776 EDT | -----------------------  --------------
2017-06-03 18:16:04.218147 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #694 | Training started
2017-06-03 18:16:21.619690 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #694 | Training finished
2017-06-03 18:16:21.621109 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #694 | Trained qf 1000 steps, policy 1000 steps
2017-06-03 18:16:21.621390 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #694 | Collecting samples for evaluation
2017-06-03 18:16:29.344793 EDT | -----------------------  --------------
2017-06-03 18:16:29.348036 EDT | Epoch                     694
2017-06-03 18:16:29.348373 EDT | Iteration                 694
2017-06-03 18:16:29.348646 EDT | AverageReturn            1000
2017-06-03 18:16:29.348916 EDT | StdReturn                   0
2017-06-03 18:16:29.349169 EDT | MaxReturn                1000
2017-06-03 18:16:29.349421 EDT | MinReturn                1000
2017-06-03 18:16:29.349673 EDT | AverageEsReturn            38.0769
2017-06-03 18:16:29.349947 EDT | StdEsReturn                29.964
2017-06-03 18:16:29.350195 EDT | MaxEsReturn               115
2017-06-03 18:16:29.350442 EDT | MinEsReturn                 3
2017-06-03 18:16:29.350695 EDT | AverageDiscountedReturn    99.9957
2017-06-03 18:16:29.350939 EDT | AverageQLoss                2.79027e-05
2017-06-03 18:16:29.351184 EDT | AveragePolicySurr          -0.0892982
2017-06-03 18:16:29.351431 EDT | AverageQ                    0.0855193
2017-06-03 18:16:29.351675 EDT | AverageAbsQ                 0.0858046
2017-06-03 18:16:29.351921 EDT | AverageY                    0.0855166
2017-06-03 18:16:29.352174 EDT | AverageAbsY                 0.0855409
2017-06-03 18:16:29.352419 EDT | AverageAbsQYDiff            0.00150286
2017-06-03 18:16:29.352664 EDT | AverageAction               0.100486
2017-06-03 18:16:29.352908 EDT | PolicyRegParamNorm         69.0775
2017-06-03 18:16:29.353161 EDT | QFunRegParamNorm           28.8733
2017-06-03 18:16:29.353405 EDT | -----------------------  --------------
2017-06-03 18:16:29.353995 EDT | [reproducibility_ML/DDPG/InvertedPendulum/Reward_Scale_Tune/Reward_Scale_0.001_Experiment_0] epoch #695 | Training started
